======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-26 06:54:08
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-14b-fp8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX4090
  Compute Capability: cc89
  VRAM: 24.0 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 06:54:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 06:54:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=313801) WARNING 01-26 06:54:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=313801) WARNING 01-26 06:54:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.16 requests/s, 4698.98 total tokens/s, 9.16 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 06:54:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:54:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:54:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:54:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:54:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:54:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:54:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:54:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 06:54:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:54:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:54:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:54:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:54:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:54:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:54:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:54:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:54:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=313801) [2026-01-26 06:54:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=313801) [2026-01-26 06:54:24] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=313801) [2026-01-26 06:54:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=313801) [2026-01-26 06:54:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=313801) [2026-01-26 06:54:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.97s/it]
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:07<00:07,  3.92s/it]
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:09<00:02,  2.69s/it]
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.11s/it]
(EngineCore_DP0 pid=313801) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.21s/it]
(EngineCore_DP0 pid=313801) 
(EngineCore_DP0 pid=313801) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.22it/s]
(EngineCore_DP0 pid=313801) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  32%|███▏      | 41/128 [00:00<00:00, 409.20it/s]
Adding requests:  69%|██████▉   | 88/128 [00:00<00:00, 442.53it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 445.41it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:39,  3.20it/s, est. speed input: 1640.72 toks/s, output: 3.20 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:24,  5.22it/s, est. speed input: 2442.88 toks/s, output: 4.77 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:19,  6.53it/s, est. speed input: 2915.33 toks/s, output: 5.69 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:16,  7.41it/s, est. speed input: 3231.20 toks/s, output: 6.31 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:15,  8.00it/s, est. speed input: 3454.36 toks/s, output: 6.75 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:14,  8.41it/s, est. speed input: 3621.00 toks/s, output: 7.07 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:13,  8.72it/s, est. speed input: 3756.27 toks/s, output: 7.34 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:01<00:13,  8.79it/s, est. speed input: 3842.71 toks/s, output: 7.51 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:13,  8.99it/s, est. speed input: 3932.73 toks/s, output: 7.68 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:12,  9.10it/s, est. speed input: 4004.86 toks/s, output: 7.82 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:12,  9.18it/s, est. speed input: 4065.57 toks/s, output: 7.94 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:12,  9.24it/s, est. speed input: 4118.34 toks/s, output: 8.04 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:12,  9.29it/s, est. speed input: 4164.57 toks/s, output: 8.13 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:12,  9.36it/s, est. speed input: 4208.81 toks/s, output: 8.22 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.43it/s, est. speed input: 4249.27 toks/s, output: 8.30 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:11,  9.42it/s, est. speed input: 4280.92 toks/s, output: 8.36 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:02<00:11,  9.47it/s, est. speed input: 4313.15 toks/s, output: 8.42 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:02<00:11,  9.51it/s, est. speed input: 4342.60 toks/s, output: 8.48 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:11,  9.52it/s, est. speed input: 4368.42 toks/s, output: 8.53 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:02<00:11,  9.53it/s, est. speed input: 4391.91 toks/s, output: 8.58 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:11,  9.53it/s, est. speed input: 4413.09 toks/s, output: 8.62 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:02<00:11,  9.56it/s, est. speed input: 4434.37 toks/s, output: 8.66 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:11,  9.49it/s, est. speed input: 4448.25 toks/s, output: 8.69 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:10,  9.51it/s, est. speed input: 4464.92 toks/s, output: 8.72 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10,  9.50it/s, est. speed input: 4479.07 toks/s, output: 8.75 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10,  9.51it/s, est. speed input: 4493.72 toks/s, output: 8.78 toks/s]
Processed prompts:  21%|██        | 27/128 [00:03<00:10,  9.52it/s, est. speed input: 4507.15 toks/s, output: 8.80 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:03<00:10,  9.58it/s, est. speed input: 4522.12 toks/s, output: 8.83 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:10,  9.63it/s, est. speed input: 4537.03 toks/s, output: 8.86 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:10,  9.67it/s, est. speed input: 4551.22 toks/s, output: 8.89 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:10,  9.63it/s, est. speed input: 4561.22 toks/s, output: 8.91 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:10,  9.57it/s, est. speed input: 4569.27 toks/s, output: 8.92 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.53it/s, est. speed input: 4576.49 toks/s, output: 8.94 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.50it/s, est. speed input: 4583.50 toks/s, output: 8.95 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:03<00:09,  9.49it/s, est. speed input: 4590.63 toks/s, output: 8.97 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:04<00:09,  9.46it/s, est. speed input: 4596.40 toks/s, output: 8.98 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:04<00:09,  9.46it/s, est. speed input: 4602.92 toks/s, output: 8.99 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:09,  9.48it/s, est. speed input: 4609.63 toks/s, output: 9.00 toks/s]
Processed prompts:  30%|███       | 39/128 [00:04<00:09,  9.48it/s, est. speed input: 4615.67 toks/s, output: 9.01 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:09,  9.49it/s, est. speed input: 4621.70 toks/s, output: 9.03 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:09,  9.50it/s, est. speed input: 4627.64 toks/s, output: 9.04 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:04<00:09,  9.49it/s, est. speed input: 4632.68 toks/s, output: 9.05 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:04<00:08,  9.53it/s, est. speed input: 4639.04 toks/s, output: 9.06 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:08,  9.52it/s, est. speed input: 4643.91 toks/s, output: 9.07 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:04<00:08,  9.51it/s, est. speed input: 4648.31 toks/s, output: 9.08 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:05<00:08,  9.49it/s, est. speed input: 4652.47 toks/s, output: 9.09 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:05<00:08,  9.47it/s, est. speed input: 4656.07 toks/s, output: 9.09 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:05<00:08,  9.51it/s, est. speed input: 4661.07 toks/s, output: 9.10 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:05<00:08,  9.53it/s, est. speed input: 4665.87 toks/s, output: 9.11 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:05<00:08,  9.54it/s, est. speed input: 4670.37 toks/s, output: 9.12 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:05<00:08,  9.53it/s, est. speed input: 4673.87 toks/s, output: 9.13 toks/s]
Processed prompts:  41%|████      | 52/128 [00:05<00:07,  9.55it/s, est. speed input: 4678.36 toks/s, output: 9.14 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:05<00:07,  9.53it/s, est. speed input: 4681.58 toks/s, output: 9.14 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:05<00:07,  9.56it/s, est. speed input: 4685.92 toks/s, output: 9.15 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:06<00:07,  9.54it/s, est. speed input: 4689.09 toks/s, output: 9.16 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:06<00:07,  9.52it/s, est. speed input: 4691.72 toks/s, output: 9.16 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:06<00:07,  9.48it/s, est. speed input: 4693.68 toks/s, output: 9.17 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:06<00:07,  9.47it/s, est. speed input: 4696.18 toks/s, output: 9.17 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:06<00:07,  9.50it/s, est. speed input: 4699.56 toks/s, output: 9.18 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:06<00:07,  9.52it/s, est. speed input: 4702.58 toks/s, output: 9.18 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:06<00:07,  9.50it/s, est. speed input: 4704.83 toks/s, output: 9.19 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:06<00:06,  9.50it/s, est. speed input: 4707.38 toks/s, output: 9.19 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:06<00:06,  9.51it/s, est. speed input: 4710.10 toks/s, output: 9.20 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:06<00:06,  9.47it/s, est. speed input: 4711.54 toks/s, output: 9.20 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:07<00:06,  9.48it/s, est. speed input: 4713.85 toks/s, output: 9.21 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:07<00:06,  9.31it/s, est. speed input: 4711.71 toks/s, output: 9.20 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:07<00:06,  9.29it/s, est. speed input: 4711.90 toks/s, output: 9.20 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:07<00:06,  9.33it/s, est. speed input: 4713.66 toks/s, output: 9.21 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:07<00:06,  9.40it/s, est. speed input: 4716.15 toks/s, output: 9.21 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:07<00:06,  9.40it/s, est. speed input: 4717.60 toks/s, output: 9.21 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:07<00:06,  9.43it/s, est. speed input: 4719.62 toks/s, output: 9.22 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:07<00:05,  9.46it/s, est. speed input: 4721.63 toks/s, output: 9.22 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:07<00:05,  9.49it/s, est. speed input: 4724.02 toks/s, output: 9.23 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:08<00:05,  9.52it/s, est. speed input: 4726.32 toks/s, output: 9.23 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:08<00:05,  9.49it/s, est. speed input: 4727.60 toks/s, output: 9.23 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:08<00:05,  9.54it/s, est. speed input: 4730.34 toks/s, output: 9.24 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:08<00:05,  9.50it/s, est. speed input: 4731.51 toks/s, output: 9.24 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:08<00:05,  9.51it/s, est. speed input: 4733.45 toks/s, output: 9.24 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:08<00:05,  9.51it/s, est. speed input: 4735.09 toks/s, output: 9.25 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:08<00:05,  9.55it/s, est. speed input: 4737.43 toks/s, output: 9.25 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:08<00:04,  9.57it/s, est. speed input: 4739.60 toks/s, output: 9.26 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:08<00:04,  9.44it/s, est. speed input: 4739.01 toks/s, output: 9.26 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:08<00:04,  9.48it/s, est. speed input: 4740.88 toks/s, output: 9.26 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:09<00:04,  9.48it/s, est. speed input: 4742.26 toks/s, output: 9.26 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:09<00:04,  9.55it/s, est. speed input: 4744.88 toks/s, output: 9.27 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:09<00:04,  9.58it/s, est. speed input: 4746.95 toks/s, output: 9.27 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:09<00:04,  9.56it/s, est. speed input: 4748.48 toks/s, output: 9.27 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:09<00:04,  9.55it/s, est. speed input: 4749.93 toks/s, output: 9.28 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:09<00:00, 43.70it/s, est. speed input: 5471.64 toks/s, output: 10.69 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:10<00:00, 23.18it/s, est. speed input: 5447.64 toks/s, output: 10.64 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:10<00:01, 17.86it/s, est. speed input: 5431.42 toks/s, output: 10.61 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:10<00:01, 14.89it/s, est. speed input: 5415.82 toks/s, output: 10.58 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:10<00:00, 13.51it/s, est. speed input: 5405.29 toks/s, output: 10.56 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:11<00:00, 12.49it/s, est. speed input: 5396.59 toks/s, output: 10.54 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:11<00:00, 11.72it/s, est. speed input: 5388.71 toks/s, output: 10.52 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:11<00:00, 11.08it/s, est. speed input: 5378.79 toks/s, output: 10.51 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:11<00:00, 10.60it/s, est. speed input: 5368.70 toks/s, output: 10.49 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:11<00:00, 10.24it/s, est. speed input: 5358.71 toks/s, output: 10.47 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:12<00:00, 10.04it/s, est. speed input: 5350.80 toks/s, output: 10.45 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:12<00:00, 10.04it/s, est. speed input: 5347.03 toks/s, output: 10.44 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:12<00:00, 10.44it/s, est. speed input: 5347.03 toks/s, output: 10.44 toks/s]
[rank0]:[W126 06:55:27.871251287 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 82.1s

测试结果:
  Requests/s:   9.16
  Tokens/s:     4698.98
  Total Reqs:   128
  Elapsed:      13.97s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     4689.83

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 06:55:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 06:55:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=315331) WARNING 01-26 06:55:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=315331) WARNING 01-26 06:56:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.24 requests/s, 8443.00 total tokens/s, 8.24 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 06:55:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:55:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:55:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:55:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:55:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:55:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:55:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:55:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 06:55:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:55:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:55:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:55:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:55:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:55:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:55:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:55:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:55:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=315331) [2026-01-26 06:55:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=315331) [2026-01-26 06:55:49] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=315331) [2026-01-26 06:55:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=315331) [2026-01-26 06:55:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=315331) [2026-01-26 06:55:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.04it/s]
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.11s/it]
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.15it/s]
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.08it/s]
(EngineCore_DP0 pid=315331) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.06it/s]
(EngineCore_DP0 pid=315331) 
(EngineCore_DP0 pid=315331) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.61it/s]
(EngineCore_DP0 pid=315331) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 23/128 [00:00<00:00, 229.56it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 239.14it/s]
Adding requests:  58%|█████▊    | 74/128 [00:00<00:00, 248.48it/s]
Adding requests:  77%|███████▋  | 99/128 [00:00<00:00, 246.78it/s]
Adding requests:  98%|█████████▊| 126/128 [00:00<00:00, 251.86it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 247.40it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:04, 28.09it/s, est. speed input: 28773.08 toks/s, output: 28.09 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:10, 11.89it/s, est. speed input: 13331.62 toks/s, output: 13.02 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:11, 10.35it/s, est. speed input: 11721.09 toks/s, output: 11.45 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:12,  9.57it/s, est. speed input: 10908.09 toks/s, output: 10.65 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:12,  9.14it/s, est. speed input: 10436.73 toks/s, output: 10.19 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:12,  8.87it/s, est. speed input: 10116.27 toks/s, output: 9.88 toks/s] 
Processed prompts:  12%|█▏        | 15/128 [00:01<00:12,  8.79it/s, est. speed input: 10001.51 toks/s, output: 9.77 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:12,  8.71it/s, est. speed input: 9902.98 toks/s, output: 9.67 toks/s] 
Processed prompts:  13%|█▎        | 17/128 [00:01<00:12,  8.64it/s, est. speed input: 9818.29 toks/s, output: 9.59 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:12,  8.59it/s, est. speed input: 9744.11 toks/s, output: 9.52 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:12,  8.54it/s, est. speed input: 9676.80 toks/s, output: 9.45 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:02<00:12,  8.50it/s, est. speed input: 9616.66 toks/s, output: 9.39 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:12,  8.48it/s, est. speed input: 9563.23 toks/s, output: 9.34 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:02<00:12,  8.46it/s, est. speed input: 9515.91 toks/s, output: 9.29 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:12,  8.46it/s, est. speed input: 9474.92 toks/s, output: 9.25 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:12,  8.45it/s, est. speed input: 9436.63 toks/s, output: 9.22 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:12,  8.44it/s, est. speed input: 9401.72 toks/s, output: 9.18 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:12,  8.44it/s, est. speed input: 9369.80 toks/s, output: 9.15 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:11,  8.43it/s, est. speed input: 9339.26 toks/s, output: 9.12 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:03<00:11,  8.43it/s, est. speed input: 9311.51 toks/s, output: 9.09 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:11,  8.42it/s, est. speed input: 9285.30 toks/s, output: 9.07 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:11,  8.42it/s, est. speed input: 9261.20 toks/s, output: 9.04 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:11,  8.41it/s, est. speed input: 9237.91 toks/s, output: 9.02 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:11,  8.41it/s, est. speed input: 9217.42 toks/s, output: 9.00 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:11,  8.41it/s, est. speed input: 9198.14 toks/s, output: 8.98 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:11,  8.42it/s, est. speed input: 9180.59 toks/s, output: 8.97 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:03<00:11,  8.42it/s, est. speed input: 9163.80 toks/s, output: 8.95 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:04<00:10,  8.42it/s, est. speed input: 9147.39 toks/s, output: 8.93 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:04<00:10,  8.41it/s, est. speed input: 9132.14 toks/s, output: 8.92 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:10,  8.40it/s, est. speed input: 9116.62 toks/s, output: 8.90 toks/s]
Processed prompts:  30%|███       | 39/128 [00:04<00:10,  8.41it/s, est. speed input: 9103.04 toks/s, output: 8.89 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:10,  8.40it/s, est. speed input: 9089.15 toks/s, output: 8.88 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:10,  8.40it/s, est. speed input: 9076.45 toks/s, output: 8.86 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:04<00:10,  8.40it/s, est. speed input: 9064.66 toks/s, output: 8.85 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:04<00:10,  8.40it/s, est. speed input: 9053.79 toks/s, output: 8.84 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:09,  8.40it/s, est. speed input: 9043.10 toks/s, output: 8.83 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:05<00:09,  8.40it/s, est. speed input: 9032.71 toks/s, output: 8.82 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:05<00:09,  8.39it/s, est. speed input: 9022.00 toks/s, output: 8.81 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:05<00:09,  8.39it/s, est. speed input: 9012.50 toks/s, output: 8.80 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:05<00:09,  8.40it/s, est. speed input: 9003.65 toks/s, output: 8.79 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:05<00:09,  8.40it/s, est. speed input: 8995.54 toks/s, output: 8.78 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:05<00:09,  8.40it/s, est. speed input: 8987.48 toks/s, output: 8.78 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:05<00:09,  8.40it/s, est. speed input: 8979.69 toks/s, output: 8.77 toks/s]
Processed prompts:  41%|████      | 52/128 [00:05<00:09,  8.40it/s, est. speed input: 8972.10 toks/s, output: 8.76 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:06<00:08,  8.39it/s, est. speed input: 8963.91 toks/s, output: 8.75 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:06<00:08,  8.38it/s, est. speed input: 8956.03 toks/s, output: 8.75 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:06<00:08,  8.39it/s, est. speed input: 8949.86 toks/s, output: 8.74 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:06<00:08,  8.40it/s, est. speed input: 8943.83 toks/s, output: 8.73 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:06<00:08,  8.40it/s, est. speed input: 8937.78 toks/s, output: 8.73 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:06<00:08,  8.40it/s, est. speed input: 8931.84 toks/s, output: 8.72 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:06<00:08,  8.41it/s, est. speed input: 8926.28 toks/s, output: 8.72 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:06<00:08,  8.40it/s, est. speed input: 8920.64 toks/s, output: 8.71 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:07<00:07,  8.39it/s, est. speed input: 8914.63 toks/s, output: 8.71 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:07<00:07,  8.40it/s, est. speed input: 8909.41 toks/s, output: 8.70 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:07<00:07,  8.38it/s, est. speed input: 8903.11 toks/s, output: 8.69 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:07<00:07,  8.39it/s, est. speed input: 8898.36 toks/s, output: 8.69 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:07<00:07,  8.38it/s, est. speed input: 8893.15 toks/s, output: 8.68 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:07<00:07,  8.38it/s, est. speed input: 8888.40 toks/s, output: 8.68 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:07<00:07,  8.38it/s, est. speed input: 8883.55 toks/s, output: 8.68 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:07<00:07,  8.38it/s, est. speed input: 8879.19 toks/s, output: 8.67 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:07<00:07,  8.38it/s, est. speed input: 8874.74 toks/s, output: 8.67 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:08<00:06,  8.38it/s, est. speed input: 8870.38 toks/s, output: 8.66 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:08<00:06,  8.38it/s, est. speed input: 8865.99 toks/s, output: 8.66 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:08<00:06,  8.38it/s, est. speed input: 8862.02 toks/s, output: 8.65 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:08<00:06,  8.38it/s, est. speed input: 8858.05 toks/s, output: 8.65 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:08<00:06,  8.38it/s, est. speed input: 8854.16 toks/s, output: 8.65 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:08<00:06,  8.39it/s, est. speed input: 8850.67 toks/s, output: 8.64 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:08<00:06,  8.38it/s, est. speed input: 8847.05 toks/s, output: 8.64 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:08<00:06,  8.39it/s, est. speed input: 8843.72 toks/s, output: 8.64 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:09<00:05,  8.39it/s, est. speed input: 8840.32 toks/s, output: 8.63 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:09<00:05,  8.39it/s, est. speed input: 8837.27 toks/s, output: 8.63 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:09<00:05,  8.39it/s, est. speed input: 8833.85 toks/s, output: 8.63 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:09<00:05,  8.39it/s, est. speed input: 8830.85 toks/s, output: 8.62 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:09<00:05,  8.39it/s, est. speed input: 8827.97 toks/s, output: 8.62 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:09<00:05,  8.38it/s, est. speed input: 8824.35 toks/s, output: 8.62 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:09<00:05,  8.38it/s, est. speed input: 8821.64 toks/s, output: 8.61 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:09<00:05,  8.39it/s, est. speed input: 8818.98 toks/s, output: 8.61 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:09<00:05,  8.39it/s, est. speed input: 8816.35 toks/s, output: 8.61 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:10<00:04,  8.38it/s, est. speed input: 8813.46 toks/s, output: 8.61 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:10<00:04,  8.38it/s, est. speed input: 8810.50 toks/s, output: 8.60 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:10<00:04,  8.38it/s, est. speed input: 8808.10 toks/s, output: 8.60 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:10<00:04,  8.38it/s, est. speed input: 8805.39 toks/s, output: 8.60 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:10<00:04,  8.36it/s, est. speed input: 8802.26 toks/s, output: 8.60 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:10<00:04,  8.35it/s, est. speed input: 8799.23 toks/s, output: 8.59 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:10<00:04,  8.36it/s, est. speed input: 8796.62 toks/s, output: 8.59 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:10<00:04,  8.36it/s, est. speed input: 8794.07 toks/s, output: 8.59 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:11<00:03,  8.36it/s, est. speed input: 8791.74 toks/s, output: 8.59 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:11<00:03,  8.35it/s, est. speed input: 8788.84 toks/s, output: 8.58 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:11<00:03,  8.36it/s, est. speed input: 8786.67 toks/s, output: 8.58 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:11<00:03,  8.36it/s, est. speed input: 8784.39 toks/s, output: 8.58 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:11<00:03,  8.36it/s, est. speed input: 8782.06 toks/s, output: 8.58 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:11<00:03,  8.36it/s, est. speed input: 8779.88 toks/s, output: 8.57 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:11<00:03,  8.35it/s, est. speed input: 8777.32 toks/s, output: 8.57 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:11<00:03,  8.36it/s, est. speed input: 8775.29 toks/s, output: 8.57 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:12<00:02,  8.36it/s, est. speed input: 8773.15 toks/s, output: 8.57 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:12<00:02,  8.36it/s, est. speed input: 8771.15 toks/s, output: 8.57 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:12<00:02,  8.35it/s, est. speed input: 8768.56 toks/s, output: 8.56 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:12<00:02,  8.35it/s, est. speed input: 8766.60 toks/s, output: 8.56 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:12<00:02,  8.36it/s, est. speed input: 8764.72 toks/s, output: 8.56 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:12<00:02,  8.36it/s, est. speed input: 8762.97 toks/s, output: 8.56 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:12<00:02,  8.36it/s, est. speed input: 8760.99 toks/s, output: 8.56 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:12<00:02,  8.35it/s, est. speed input: 8758.73 toks/s, output: 8.55 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:12<00:02,  8.35it/s, est. speed input: 8756.89 toks/s, output: 8.55 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:13<00:01,  8.35it/s, est. speed input: 8754.92 toks/s, output: 8.55 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:13<00:01,  8.34it/s, est. speed input: 8752.85 toks/s, output: 8.55 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:13<00:01,  8.35it/s, est. speed input: 8751.06 toks/s, output: 8.55 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:13<00:01,  8.34it/s, est. speed input: 8749.12 toks/s, output: 8.54 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:13<00:01,  8.34it/s, est. speed input: 8747.34 toks/s, output: 8.54 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:13<00:01,  8.33it/s, est. speed input: 8745.00 toks/s, output: 8.54 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:13<00:01,  8.33it/s, est. speed input: 8743.28 toks/s, output: 8.54 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:13<00:01,  8.32it/s, est. speed input: 8741.21 toks/s, output: 8.54 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:14<00:00,  8.32it/s, est. speed input: 8739.31 toks/s, output: 8.53 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:14<00:00,  8.33it/s, est. speed input: 8737.62 toks/s, output: 8.53 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:14<00:00,  8.33it/s, est. speed input: 8735.80 toks/s, output: 8.53 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:14<00:00,  8.33it/s, est. speed input: 8734.31 toks/s, output: 8.53 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:14<00:00,  8.33it/s, est. speed input: 8732.58 toks/s, output: 8.53 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:14<00:00,  8.33it/s, est. speed input: 8730.95 toks/s, output: 8.53 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:14<00:00,  8.33it/s, est. speed input: 8729.26 toks/s, output: 8.52 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:14<00:00,  8.33it/s, est. speed input: 8727.74 toks/s, output: 8.52 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:15<00:00,  8.33it/s, est. speed input: 8726.23 toks/s, output: 8.52 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:15<00:00,  8.33it/s, est. speed input: 8726.23 toks/s, output: 8.52 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:15<00:00,  8.52it/s, est. speed input: 8726.23 toks/s, output: 8.52 toks/s]
[rank0]:[W126 06:56:43.915595533 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 75.9s

测试结果:
  Requests/s:   8.24
  Tokens/s:     8443.00
  Total Reqs:   128
  Elapsed:      15.54s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     8434.76

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 06:56:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 06:56:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=316655) WARNING 01-26 06:57:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=316655) WARNING 01-26 06:57:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.36 requests/s, 8567.12 total tokens/s, 8.36 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 06:56:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:56:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:56:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:56:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:56:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:56:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:56:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:56:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:56:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 06:57:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:57:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:57:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:57:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:57:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:57:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:57:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:57:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:57:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=316655) [2026-01-26 06:57:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=316655) [2026-01-26 06:57:04] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=316655) [2026-01-26 06:57:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=316655) [2026-01-26 06:57:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=316655) [2026-01-26 06:57:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.05it/s]
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.01it/s]
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.41it/s]
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=316655) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.21it/s]
(EngineCore_DP0 pid=316655) 
(EngineCore_DP0 pid=316655) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.99it/s]
(EngineCore_DP0 pid=316655) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 24/256 [00:00<00:00, 236.54it/s]
Adding requests:  19%|█▉        | 49/256 [00:00<00:00, 241.69it/s]
Adding requests:  29%|██▉       | 75/256 [00:00<00:00, 249.02it/s]
Adding requests:  39%|███▉      | 100/256 [00:00<00:00, 236.69it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 245.85it/s]
Adding requests:  60%|██████    | 154/256 [00:00<00:00, 250.36it/s]
Adding requests:  71%|███████   | 182/256 [00:00<00:00, 256.74it/s]
Adding requests:  82%|████████▏ | 210/256 [00:00<00:00, 263.26it/s]
Adding requests:  93%|█████████▎| 237/256 [00:00<00:00, 261.54it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 253.55it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 6/256 [00:00<00:13, 19.03it/s, est. speed input: 19495.08 toks/s, output: 19.04 toks/s]
Processed prompts:   3%|▎         | 8/256 [00:00<00:18, 13.70it/s, est. speed input: 14968.71 toks/s, output: 14.62 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:21, 11.48it/s, est. speed input: 13085.19 toks/s, output: 12.78 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:01<00:23, 10.38it/s, est. speed input: 12091.66 toks/s, output: 11.81 toks/s]
Processed prompts:   5%|▌         | 14/256 [00:01<00:24,  9.75it/s, est. speed input: 11474.23 toks/s, output: 11.21 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:01<00:25,  9.36it/s, est. speed input: 11053.72 toks/s, output: 10.79 toks/s]
Processed prompts:   7%|▋         | 18/256 [00:01<00:26,  9.11it/s, est. speed input: 10742.51 toks/s, output: 10.49 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:01<00:26,  8.93it/s, est. speed input: 10503.08 toks/s, output: 10.26 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:02<00:26,  8.81it/s, est. speed input: 10317.28 toks/s, output: 10.08 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:02<00:26,  8.74it/s, est. speed input: 10168.99 toks/s, output: 9.93 toks/s] 
Processed prompts:  10%|█         | 26/256 [00:02<00:26,  8.69it/s, est. speed input: 10045.58 toks/s, output: 9.81 toks/s]
Processed prompts:  11%|█         | 28/256 [00:02<00:26,  8.65it/s, est. speed input: 9942.36 toks/s, output: 9.71 toks/s] 
Processed prompts:  12%|█▏        | 30/256 [00:03<00:26,  8.61it/s, est. speed input: 9851.95 toks/s, output: 9.62 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:03<00:26,  8.60it/s, est. speed input: 9777.18 toks/s, output: 9.55 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:03<00:25,  8.59it/s, est. speed input: 9712.51 toks/s, output: 9.48 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:03<00:25,  8.58it/s, est. speed input: 9653.79 toks/s, output: 9.43 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:04<00:25,  8.58it/s, est. speed input: 9603.21 toks/s, output: 9.38 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:04<00:25,  8.58it/s, est. speed input: 9558.71 toks/s, output: 9.33 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:04<00:24,  8.57it/s, est. speed input: 9517.70 toks/s, output: 9.29 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:04<00:24,  8.57it/s, est. speed input: 9480.70 toks/s, output: 9.26 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:04<00:24,  8.56it/s, est. speed input: 9446.85 toks/s, output: 9.23 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:05<00:24,  8.56it/s, est. speed input: 9415.34 toks/s, output: 9.19 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:05<00:24,  8.55it/s, est. speed input: 9386.29 toks/s, output: 9.17 toks/s]
Processed prompts:  20%|██        | 52/256 [00:05<00:23,  8.55it/s, est. speed input: 9359.96 toks/s, output: 9.14 toks/s]
Processed prompts:  21%|██        | 54/256 [00:05<00:23,  8.55it/s, est. speed input: 9336.67 toks/s, output: 9.12 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:06<00:23,  8.55it/s, est. speed input: 9314.59 toks/s, output: 9.10 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:06<00:23,  8.55it/s, est. speed input: 9294.51 toks/s, output: 9.08 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:06<00:22,  8.55it/s, est. speed input: 9275.18 toks/s, output: 9.06 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:06<00:22,  8.55it/s, est. speed input: 9257.51 toks/s, output: 9.04 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:07<00:22,  8.55it/s, est. speed input: 9241.04 toks/s, output: 9.02 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:07<00:22,  8.55it/s, est. speed input: 9224.86 toks/s, output: 9.01 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:07<00:21,  8.55it/s, est. speed input: 9210.32 toks/s, output: 8.99 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:07<00:21,  8.54it/s, est. speed input: 9195.42 toks/s, output: 8.98 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:08<00:21,  8.54it/s, est. speed input: 9182.10 toks/s, output: 8.97 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:08<00:21,  8.53it/s, est. speed input: 9169.33 toks/s, output: 8.95 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:08<00:21,  8.54it/s, est. speed input: 9157.66 toks/s, output: 8.94 toks/s]
Processed prompts:  30%|███       | 78/256 [00:08<00:20,  8.53it/s, est. speed input: 9146.12 toks/s, output: 8.93 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:08<00:20,  8.53it/s, est. speed input: 9134.94 toks/s, output: 8.92 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:09<00:20,  8.53it/s, est. speed input: 9125.04 toks/s, output: 8.91 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:09<00:20,  8.54it/s, est. speed input: 9115.83 toks/s, output: 8.90 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:09<00:19,  8.54it/s, est. speed input: 9107.14 toks/s, output: 8.89 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:09<00:19,  8.53it/s, est. speed input: 9097.84 toks/s, output: 8.88 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:10<00:19,  8.53it/s, est. speed input: 9089.71 toks/s, output: 8.88 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:10<00:19,  8.54it/s, est. speed input: 9081.85 toks/s, output: 8.87 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:10<00:18,  8.53it/s, est. speed input: 9073.89 toks/s, output: 8.86 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:10<00:18,  8.53it/s, est. speed input: 9066.66 toks/s, output: 8.85 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:11<00:18,  8.52it/s, est. speed input: 9058.99 toks/s, output: 8.85 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:11<00:18,  8.52it/s, est. speed input: 9051.99 toks/s, output: 8.84 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:11<00:18,  8.52it/s, est. speed input: 9045.14 toks/s, output: 8.83 toks/s]
Processed prompts:  41%|████      | 104/256 [00:11<00:17,  8.51it/s, est. speed input: 9038.49 toks/s, output: 8.83 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:12<00:17,  8.51it/s, est. speed input: 9031.97 toks/s, output: 8.82 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:12<00:17,  8.51it/s, est. speed input: 9025.90 toks/s, output: 8.81 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:12<00:17,  8.51it/s, est. speed input: 9020.02 toks/s, output: 8.81 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:12<00:16,  8.51it/s, est. speed input: 9014.66 toks/s, output: 8.80 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:12<00:05, 24.34it/s, est. speed input: 9969.97 toks/s, output: 9.74 toks/s]
Processed prompts:  50%|█████     | 129/256 [00:13<00:06, 20.81it/s, est. speed input: 10025.15 toks/s, output: 9.79 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:13<00:08, 14.09it/s, est. speed input: 9904.52 toks/s, output: 9.67 toks/s] 
Processed prompts:  52%|█████▏    | 134/256 [00:13<00:09, 12.69it/s, est. speed input: 9883.91 toks/s, output: 9.65 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:14<00:10, 11.59it/s, est. speed input: 9864.21 toks/s, output: 9.63 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:14<00:10, 10.75it/s, est. speed input: 9845.61 toks/s, output: 9.61 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:14<00:11, 10.12it/s, est. speed input: 9827.18 toks/s, output: 9.60 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:14<00:11,  9.65it/s, est. speed input: 9809.05 toks/s, output: 9.58 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:15<00:12,  9.31it/s, est. speed input: 9791.52 toks/s, output: 9.56 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:15<00:12,  9.08it/s, est. speed input: 9774.84 toks/s, output: 9.55 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:15<00:12,  8.91it/s, est. speed input: 9758.59 toks/s, output: 9.53 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:15<00:12,  8.78it/s, est. speed input: 9742.44 toks/s, output: 9.51 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:16<00:11,  8.69it/s, est. speed input: 9726.73 toks/s, output: 9.50 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:16<00:11,  8.63it/s, est. speed input: 9711.73 toks/s, output: 9.48 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:16<00:11,  8.58it/s, est. speed input: 9697.06 toks/s, output: 9.47 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:16<00:11,  8.55it/s, est. speed input: 9682.66 toks/s, output: 9.46 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:16<00:11,  8.53it/s, est. speed input: 9668.70 toks/s, output: 9.44 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:17<00:11,  8.52it/s, est. speed input: 9655.41 toks/s, output: 9.43 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:17<00:10,  8.51it/s, est. speed input: 9642.28 toks/s, output: 9.42 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:17<00:10,  8.50it/s, est. speed input: 9629.61 toks/s, output: 9.40 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:17<00:10,  8.49it/s, est. speed input: 9616.75 toks/s, output: 9.39 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:18<00:10,  8.48it/s, est. speed input: 9604.54 toks/s, output: 9.38 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:18<00:09,  8.47it/s, est. speed input: 9592.30 toks/s, output: 9.37 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:18<00:09,  8.47it/s, est. speed input: 9580.48 toks/s, output: 9.36 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:18<00:09,  8.47it/s, est. speed input: 9568.92 toks/s, output: 9.34 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:19<00:09,  8.46it/s, est. speed input: 9557.55 toks/s, output: 9.33 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:19<00:08,  8.46it/s, est. speed input: 9546.65 toks/s, output: 9.32 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:19<00:08,  8.45it/s, est. speed input: 9535.62 toks/s, output: 9.31 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:19<00:08,  8.46it/s, est. speed input: 9525.16 toks/s, output: 9.30 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:20<00:08,  8.45it/s, est. speed input: 9514.83 toks/s, output: 9.29 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:20<00:08,  8.45it/s, est. speed input: 9504.71 toks/s, output: 9.28 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:20<00:07,  8.45it/s, est. speed input: 9494.97 toks/s, output: 9.27 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:20<00:07,  8.45it/s, est. speed input: 9485.23 toks/s, output: 9.26 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:20<00:07,  8.45it/s, est. speed input: 9475.91 toks/s, output: 9.25 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:21<00:07,  8.45it/s, est. speed input: 9466.66 toks/s, output: 9.24 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:21<00:06,  8.45it/s, est. speed input: 9457.63 toks/s, output: 9.24 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:21<00:06,  8.45it/s, est. speed input: 9448.99 toks/s, output: 9.23 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:21<00:06,  8.46it/s, est. speed input: 9440.72 toks/s, output: 9.22 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:22<00:06,  8.45it/s, est. speed input: 9432.13 toks/s, output: 9.21 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:22<00:05,  8.45it/s, est. speed input: 9423.83 toks/s, output: 9.20 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:22<00:05,  8.45it/s, est. speed input: 9415.85 toks/s, output: 9.20 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:22<00:05,  8.45it/s, est. speed input: 9407.73 toks/s, output: 9.19 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:23<00:05,  8.45it/s, est. speed input: 9400.03 toks/s, output: 9.18 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:23<00:04,  8.45it/s, est. speed input: 9392.40 toks/s, output: 9.17 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:23<00:04,  8.45it/s, est. speed input: 9384.92 toks/s, output: 9.16 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:23<00:04,  8.45it/s, est. speed input: 9377.76 toks/s, output: 9.16 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:24<00:04,  8.45it/s, est. speed input: 9370.75 toks/s, output: 9.15 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:24<00:04,  8.45it/s, est. speed input: 9363.55 toks/s, output: 9.14 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:24<00:03,  8.45it/s, est. speed input: 9356.78 toks/s, output: 9.14 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:24<00:03,  8.45it/s, est. speed input: 9350.11 toks/s, output: 9.13 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:24<00:03,  8.44it/s, est. speed input: 9343.27 toks/s, output: 9.12 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:25<00:03,  8.44it/s, est. speed input: 9336.60 toks/s, output: 9.12 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:25<00:02,  8.44it/s, est. speed input: 9330.10 toks/s, output: 9.11 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:25<00:02,  8.44it/s, est. speed input: 9323.74 toks/s, output: 9.11 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:25<00:02,  8.44it/s, est. speed input: 9317.48 toks/s, output: 9.10 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:26<00:02,  8.44it/s, est. speed input: 9311.36 toks/s, output: 9.09 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:26<00:01,  8.44it/s, est. speed input: 9305.35 toks/s, output: 9.09 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:26<00:01,  8.44it/s, est. speed input: 9299.36 toks/s, output: 9.08 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:26<00:01,  8.44it/s, est. speed input: 9293.65 toks/s, output: 9.08 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:27<00:01,  8.44it/s, est. speed input: 9288.05 toks/s, output: 9.07 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:27<00:00,  8.44it/s, est. speed input: 9282.43 toks/s, output: 9.06 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:27<00:00,  8.44it/s, est. speed input: 9276.88 toks/s, output: 9.06 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:27<00:00,  8.44it/s, est. speed input: 9271.52 toks/s, output: 9.05 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:28<00:00,  8.44it/s, est. speed input: 9266.28 toks/s, output: 9.05 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:28<00:00,  9.88it/s, est. speed input: 9298.88 toks/s, output: 9.08 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:28<00:00,  9.88it/s, est. speed input: 9298.88 toks/s, output: 9.08 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:28<00:00,  9.08it/s, est. speed input: 9298.88 toks/s, output: 9.08 toks/s]
[rank0]:[W126 06:58:15.875266341 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 91.7s

测试结果:
  Requests/s:   8.36
  Tokens/s:     8567.12
  Total Reqs:   256
  Elapsed:      30.63s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     8558.76

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 06:58:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 06:58:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=318239) WARNING 01-26 06:58:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=318239) WARNING 01-26 06:58:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.27 requests/s, 8476.53 total tokens/s, 8.27 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 06:58:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:58:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:58:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:58:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:58:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:58:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:58:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:58:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 06:58:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 06:58:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:58:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 06:58:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 06:58:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 06:58:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 06:58:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 06:58:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 06:58:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=318239) [2026-01-26 06:58:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=318239) [2026-01-26 06:58:37] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=318239) [2026-01-26 06:58:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=318239) [2026-01-26 06:58:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=318239) [2026-01-26 06:58:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.06it/s]
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.02it/s]
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.44it/s]
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.27it/s]
(EngineCore_DP0 pid=318239) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=318239) 
(EngineCore_DP0 pid=318239) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  4.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  4.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  3.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.05it/s]
(EngineCore_DP0 pid=318239) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  4.54it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  4.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.92it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 232.68it/s]
Adding requests:  10%|▉         | 49/512 [00:00<00:01, 238.73it/s]
Adding requests:  15%|█▍        | 75/512 [00:00<00:01, 248.26it/s]
Adding requests:  20%|█▉        | 100/512 [00:00<00:01, 244.25it/s]
Adding requests:  24%|██▍       | 125/512 [00:00<00:01, 245.36it/s]
Adding requests:  29%|██▉       | 150/512 [00:00<00:01, 245.55it/s]
Adding requests:  35%|███▍      | 177/512 [00:00<00:01, 252.64it/s]
Adding requests:  40%|████      | 205/512 [00:00<00:01, 260.58it/s]
Adding requests:  46%|████▌     | 234/512 [00:00<00:01, 266.33it/s]
Adding requests:  51%|█████     | 261/512 [00:01<00:00, 263.82it/s]
Adding requests:  56%|█████▋    | 288/512 [00:01<00:00, 261.43it/s]
Adding requests:  62%|██████▏   | 317/512 [00:01<00:00, 269.57it/s]
Adding requests:  67%|██████▋   | 345/512 [00:01<00:00, 270.53it/s]
Adding requests:  73%|███████▎  | 373/512 [00:01<00:00, 269.84it/s]
Adding requests:  78%|███████▊  | 400/512 [00:01<00:00, 267.44it/s]
Adding requests:  84%|████████▍ | 429/512 [00:01<00:00, 272.27it/s]
Adding requests:  89%|████████▉ | 457/512 [00:01<00:00, 266.94it/s]
Adding requests:  95%|█████████▌| 488/512 [00:01<00:00, 276.06it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 263.57it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 14/512 [00:00<00:16, 30.42it/s, est. speed input: 31152.59 toks/s, output: 30.42 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:28, 17.29it/s, est. speed input: 19688.16 toks/s, output: 19.23 toks/s]
Processed prompts:   4%|▍         | 22/512 [00:01<00:37, 13.21it/s, est. speed input: 15956.05 toks/s, output: 15.58 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:01<00:43, 11.30it/s, est. speed input: 14100.60 toks/s, output: 13.77 toks/s]
Processed prompts:   6%|▌         | 30/512 [00:02<00:47, 10.25it/s, est. speed input: 12995.85 toks/s, output: 12.69 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:02<00:49,  9.62it/s, est. speed input: 12257.24 toks/s, output: 11.97 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:03<00:51,  9.22it/s, est. speed input: 11734.90 toks/s, output: 11.46 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:03<00:52,  8.96it/s, est. speed input: 11340.98 toks/s, output: 11.08 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:04<00:53,  8.78it/s, est. speed input: 11034.94 toks/s, output: 10.78 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:04<00:53,  8.67it/s, est. speed input: 10792.09 toks/s, output: 10.54 toks/s]
Processed prompts:  11%|█         | 54/512 [00:05<00:53,  8.58it/s, est. speed input: 10591.25 toks/s, output: 10.34 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:05<00:53,  8.52it/s, est. speed input: 10423.55 toks/s, output: 10.18 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:06<00:53,  8.49it/s, est. speed input: 10283.52 toks/s, output: 10.04 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:06<00:52,  8.46it/s, est. speed input: 10161.74 toks/s, output: 9.92 toks/s] 
Processed prompts:  14%|█▎        | 70/512 [00:07<00:52,  8.43it/s, est. speed input: 10056.07 toks/s, output: 9.82 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:07<00:52,  8.42it/s, est. speed input: 9963.60 toks/s, output: 9.73 toks/s] 
Processed prompts:  15%|█▌        | 78/512 [00:08<00:51,  8.41it/s, est. speed input: 9881.89 toks/s, output: 9.65 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:08<00:51,  8.40it/s, est. speed input: 9808.99 toks/s, output: 9.58 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:09<00:50,  8.39it/s, est. speed input: 9743.48 toks/s, output: 9.52 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:09<00:50,  8.38it/s, est. speed input: 9684.26 toks/s, output: 9.46 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:09<00:49,  8.38it/s, est. speed input: 9630.54 toks/s, output: 9.40 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:10<00:49,  8.37it/s, est. speed input: 9581.81 toks/s, output: 9.36 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:10<00:48,  8.37it/s, est. speed input: 9537.34 toks/s, output: 9.31 toks/s]
Processed prompts:  21%|██        | 106/512 [00:11<00:48,  8.36it/s, est. speed input: 9496.16 toks/s, output: 9.27 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:11<00:48,  8.36it/s, est. speed input: 9458.42 toks/s, output: 9.24 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:12<00:24, 15.77it/s, est. speed input: 10406.22 toks/s, output: 10.16 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:12<00:28, 13.56it/s, est. speed input: 10337.20 toks/s, output: 10.09 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:13<00:31, 12.00it/s, est. speed input: 10272.94 toks/s, output: 10.03 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:13<00:34, 10.90it/s, est. speed input: 10213.08 toks/s, output: 9.97 toks/s] 
Processed prompts:  28%|██▊       | 142/512 [00:14<00:36, 10.13it/s, est. speed input: 10156.99 toks/s, output: 9.92 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:14<00:38,  9.60it/s, est. speed input: 10104.89 toks/s, output: 9.87 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:15<00:39,  9.22it/s, est. speed input: 10055.31 toks/s, output: 9.82 toks/s]
Processed prompts:  30%|███       | 154/512 [00:15<00:40,  8.95it/s, est. speed input: 10008.62 toks/s, output: 9.77 toks/s]
Processed prompts:  31%|███       | 158/512 [00:16<00:40,  8.76it/s, est. speed input: 9964.78 toks/s, output: 9.73 toks/s] 
Processed prompts:  32%|███▏      | 162/512 [00:16<00:40,  8.63it/s, est. speed input: 9923.52 toks/s, output: 9.69 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:17<00:40,  8.54it/s, est. speed input: 9884.24 toks/s, output: 9.65 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:17<00:40,  8.48it/s, est. speed input: 9847.51 toks/s, output: 9.62 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:18<00:40,  8.43it/s, est. speed input: 9812.75 toks/s, output: 9.58 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:18<00:39,  8.40it/s, est. speed input: 9779.62 toks/s, output: 9.55 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:19<00:39,  8.38it/s, est. speed input: 9748.27 toks/s, output: 9.52 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:19<00:38,  8.37it/s, est. speed input: 9718.45 toks/s, output: 9.49 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:20<00:38,  8.35it/s, est. speed input: 9689.98 toks/s, output: 9.46 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:20<00:38,  8.35it/s, est. speed input: 9662.89 toks/s, output: 9.44 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:21<00:37,  8.34it/s, est. speed input: 9636.61 toks/s, output: 9.41 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:21<00:37,  8.33it/s, est. speed input: 9611.38 toks/s, output: 9.39 toks/s]
Processed prompts:  40%|████      | 206/512 [00:22<00:36,  8.32it/s, est. speed input: 9587.34 toks/s, output: 9.36 toks/s]
Processed prompts:  41%|████      | 210/512 [00:22<00:36,  8.32it/s, est. speed input: 9564.27 toks/s, output: 9.34 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:22<00:35,  8.32it/s, est. speed input: 9542.30 toks/s, output: 9.32 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:23<00:35,  8.32it/s, est. speed input: 9521.25 toks/s, output: 9.30 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:23<00:34,  8.32it/s, est. speed input: 9500.90 toks/s, output: 9.28 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:24<00:34,  8.31it/s, est. speed input: 9481.39 toks/s, output: 9.26 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:24<00:33,  8.31it/s, est. speed input: 9462.57 toks/s, output: 9.24 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:25<00:33,  8.31it/s, est. speed input: 9444.41 toks/s, output: 9.22 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:25<00:32,  8.31it/s, est. speed input: 9427.01 toks/s, output: 9.21 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:26<00:32,  8.31it/s, est. speed input: 9410.37 toks/s, output: 9.19 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:26<00:32,  8.31it/s, est. speed input: 9394.15 toks/s, output: 9.17 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:27<00:31,  8.31it/s, est. speed input: 9378.45 toks/s, output: 9.16 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:27<00:31,  8.31it/s, est. speed input: 9363.43 toks/s, output: 9.14 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:28<00:30,  8.31it/s, est. speed input: 9348.81 toks/s, output: 9.13 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:28<00:30,  8.31it/s, est. speed input: 9334.81 toks/s, output: 9.12 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:29<00:29,  8.31it/s, est. speed input: 9321.08 toks/s, output: 9.10 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:29<00:29,  8.31it/s, est. speed input: 9307.83 toks/s, output: 9.09 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:30<00:28,  8.31it/s, est. speed input: 9294.97 toks/s, output: 9.08 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:30<00:28,  8.30it/s, est. speed input: 9282.49 toks/s, output: 9.06 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:31<00:27,  8.30it/s, est. speed input: 9270.41 toks/s, output: 9.05 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:31<00:27,  8.30it/s, est. speed input: 9258.62 toks/s, output: 9.04 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:32<00:26,  8.30it/s, est. speed input: 9247.28 toks/s, output: 9.03 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:32<00:26,  8.30it/s, est. speed input: 9236.17 toks/s, output: 9.02 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:33<00:25,  8.30it/s, est. speed input: 9225.48 toks/s, output: 9.01 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:33<00:25,  8.30it/s, est. speed input: 9214.90 toks/s, output: 9.00 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:34<00:24,  8.30it/s, est. speed input: 9204.76 toks/s, output: 8.99 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:34<00:24,  8.30it/s, est. speed input: 9194.94 toks/s, output: 8.98 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:35<00:23,  8.30it/s, est. speed input: 9185.32 toks/s, output: 8.97 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:35<00:23,  8.30it/s, est. speed input: 9176.03 toks/s, output: 8.96 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:35<00:22,  8.30it/s, est. speed input: 9166.93 toks/s, output: 8.95 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:36<00:22,  8.30it/s, est. speed input: 9158.03 toks/s, output: 8.94 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:36<00:21,  8.30it/s, est. speed input: 9149.47 toks/s, output: 8.94 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:37<00:21,  8.30it/s, est. speed input: 9141.06 toks/s, output: 8.93 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:37<00:20,  8.30it/s, est. speed input: 9133.04 toks/s, output: 8.92 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:38<00:20,  8.30it/s, est. speed input: 9125.18 toks/s, output: 8.91 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:38<00:19,  8.30it/s, est. speed input: 9117.50 toks/s, output: 8.90 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:39<00:19,  8.31it/s, est. speed input: 9110.02 toks/s, output: 8.90 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:39<00:19,  8.31it/s, est. speed input: 9102.70 toks/s, output: 8.89 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:40<00:18,  8.30it/s, est. speed input: 9095.53 toks/s, output: 8.88 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:40<00:18,  8.30it/s, est. speed input: 9088.54 toks/s, output: 8.88 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:41<00:17,  8.30it/s, est. speed input: 9081.68 toks/s, output: 8.87 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:41<00:17,  8.30it/s, est. speed input: 9075.01 toks/s, output: 8.86 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:42<00:16,  8.30it/s, est. speed input: 9068.45 toks/s, output: 8.86 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:42<00:16,  8.30it/s, est. speed input: 9062.05 toks/s, output: 8.85 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:43<00:15,  8.30it/s, est. speed input: 9055.76 toks/s, output: 8.84 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:43<00:07, 15.66it/s, est. speed input: 9328.53 toks/s, output: 9.11 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:44<00:08, 13.45it/s, est. speed input: 9319.18 toks/s, output: 9.10 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:44<00:08, 11.89it/s, est. speed input: 9309.75 toks/s, output: 9.09 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:45<00:09, 10.82it/s, est. speed input: 9301.19 toks/s, output: 9.08 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:45<00:09, 10.07it/s, est. speed input: 9292.69 toks/s, output: 9.07 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:46<00:09,  9.54it/s, est. speed input: 9284.51 toks/s, output: 9.07 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:46<00:09,  9.17it/s, est. speed input: 9276.36 toks/s, output: 9.06 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:47<00:09,  8.91it/s, est. speed input: 9268.47 toks/s, output: 9.05 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:47<00:09,  8.73it/s, est. speed input: 9260.66 toks/s, output: 9.04 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:48<00:09,  8.60it/s, est. speed input: 9253.18 toks/s, output: 9.04 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:48<00:08,  8.51it/s, est. speed input: 9245.61 toks/s, output: 9.03 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:48<00:08,  8.45it/s, est. speed input: 9238.36 toks/s, output: 9.02 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:49<00:07,  8.41it/s, est. speed input: 9231.24 toks/s, output: 9.01 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:49<00:07,  8.37it/s, est. speed input: 9224.18 toks/s, output: 9.01 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:50<00:06,  8.35it/s, est. speed input: 9217.27 toks/s, output: 9.00 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:50<00:06,  8.33it/s, est. speed input: 9210.34 toks/s, output: 8.99 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:51<00:06,  8.32it/s, est. speed input: 9203.57 toks/s, output: 8.99 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:51<00:05,  8.31it/s, est. speed input: 9196.92 toks/s, output: 8.98 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:52<00:05,  8.31it/s, est. speed input: 9190.53 toks/s, output: 8.98 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:52<00:04,  8.31it/s, est. speed input: 9184.24 toks/s, output: 8.97 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:53<00:04,  8.28it/s, est. speed input: 9177.37 toks/s, output: 8.96 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:53<00:03,  8.27it/s, est. speed input: 9170.60 toks/s, output: 8.96 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:54<00:03,  8.26it/s, est. speed input: 9163.98 toks/s, output: 8.95 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:54<00:02,  8.25it/s, est. speed input: 9157.48 toks/s, output: 8.94 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:55<00:02,  8.24it/s, est. speed input: 9150.94 toks/s, output: 8.94 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:55<00:01,  8.24it/s, est. speed input: 9144.74 toks/s, output: 8.93 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:56<00:01,  8.24it/s, est. speed input: 9138.51 toks/s, output: 8.92 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:56<00:00,  8.24it/s, est. speed input: 9132.58 toks/s, output: 8.92 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:57<00:00,  8.90it/s, est. speed input: 9145.91 toks/s, output: 8.93 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:57<00:00,  8.90it/s, est. speed input: 9181.74 toks/s, output: 8.97 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:57<00:00,  8.97it/s, est. speed input: 9181.74 toks/s, output: 8.97 toks/s]
[rank0]:[W126 07:00:17.324876583 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 123.1s

测试结果:
  Requests/s:   8.27
  Tokens/s:     8476.53
  Total Reqs:   512
  Elapsed:      61.91s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     8468.26

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:00:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:00:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=320309) WARNING 01-26 07:00:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=320309) WARNING 01-26 07:01:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.24 requests/s, 8450.21 total tokens/s, 8.24 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 07:00:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:00:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:00:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:00:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:00:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:00:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:00:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:00:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:00:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:00:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:00:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:00:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:00:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:00:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:00:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:00:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:00:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=320309) [2026-01-26 07:00:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=320309) [2026-01-26 07:00:44] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=320309) [2026-01-26 07:00:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=320309) [2026-01-26 07:00:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=320309) [2026-01-26 07:00:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.06it/s]
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.03it/s]
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.44it/s]
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.27it/s]
(EngineCore_DP0 pid=320309) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.24it/s]
(EngineCore_DP0 pid=320309) 
(EngineCore_DP0 pid=320309) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  4.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.06it/s]
(EngineCore_DP0 pid=320309) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  4.27it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  4.74it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  4.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.53it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 23/1024 [00:00<00:04, 228.33it/s]
Adding requests:   5%|▍         | 49/1024 [00:00<00:04, 241.23it/s]
Adding requests:   7%|▋         | 76/1024 [00:00<00:03, 251.43it/s]
Adding requests:  10%|▉         | 102/1024 [00:00<00:03, 248.03it/s]
Adding requests:  12%|█▏        | 127/1024 [00:00<00:03, 244.82it/s]
Adding requests:  15%|█▍        | 152/1024 [00:00<00:03, 245.35it/s]
Adding requests:  17%|█▋        | 178/1024 [00:00<00:03, 249.57it/s]
Adding requests:  20%|██        | 205/1024 [00:00<00:03, 253.88it/s]
Adding requests:  23%|██▎       | 232/1024 [00:00<00:03, 257.48it/s]
Adding requests:  25%|██▌       | 258/1024 [00:01<00:03, 251.78it/s]
Adding requests:  28%|██▊       | 285/1024 [00:01<00:02, 254.81it/s]
Adding requests:  31%|███       | 313/1024 [00:01<00:02, 260.40it/s]
Adding requests:  33%|███▎      | 340/1024 [00:01<00:02, 259.76it/s]
Adding requests:  36%|███▌      | 367/1024 [00:01<00:02, 261.18it/s]
Adding requests:  38%|███▊      | 394/1024 [00:01<00:02, 259.04it/s]
Adding requests:  41%|████      | 422/1024 [00:01<00:02, 262.75it/s]
Adding requests:  44%|████▍     | 449/1024 [00:01<00:02, 256.43it/s]
Adding requests:  47%|████▋     | 477/1024 [00:01<00:02, 263.13it/s]
Adding requests:  49%|████▉     | 504/1024 [00:01<00:01, 262.77it/s]
Adding requests:  52%|█████▏    | 534/1024 [00:02<00:01, 272.94it/s]
Adding requests:  55%|█████▍    | 562/1024 [00:02<00:01, 271.26it/s]
Adding requests:  58%|█████▊    | 590/1024 [00:02<00:01, 263.79it/s]
Adding requests:  60%|██████    | 617/1024 [00:02<00:01, 259.67it/s]
Adding requests:  63%|██████▎   | 644/1024 [00:02<00:01, 252.66it/s]
Adding requests:  65%|██████▌   | 670/1024 [00:02<00:01, 252.20it/s]
Adding requests:  68%|██████▊   | 697/1024 [00:02<00:01, 255.47it/s]
Adding requests:  71%|███████   | 724/1024 [00:02<00:01, 256.56it/s]
Adding requests:  73%|███████▎  | 750/1024 [00:02<00:01, 256.60it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:03<00:00, 255.97it/s]
Adding requests:  78%|███████▊  | 803/1024 [00:03<00:00, 258.81it/s]
Adding requests:  81%|████████  | 831/1024 [00:03<00:00, 264.56it/s]
Adding requests:  84%|████████▍ | 858/1024 [00:03<00:00, 263.47it/s]
Adding requests:  86%|████████▋ | 885/1024 [00:03<00:00, 264.96it/s]
Adding requests:  89%|████████▉ | 912/1024 [00:03<00:00, 265.04it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:03<00:00, 259.01it/s]
Adding requests:  94%|█████████▍| 966/1024 [00:03<00:00, 261.96it/s]
Adding requests:  97%|█████████▋| 993/1024 [00:03<00:00, 258.52it/s]
Adding requests: 100%|█████████▉| 1019/1024 [00:03<00:00, 254.66it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 257.60it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 26/1024 [00:00<00:05, 168.22it/s, est. speed input: 172292.51 toks/s, output: 168.23 toks/s]
Processed prompts:   4%|▍         | 43/1024 [00:02<00:56, 17.41it/s, est. speed input: 21295.96 toks/s, output: 20.80 toks/s]   
Processed prompts:   5%|▍         | 51/1024 [00:03<01:10, 13.76it/s, est. speed input: 17267.99 toks/s, output: 16.86 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:03<01:24, 11.40it/s, est. speed input: 14916.13 toks/s, output: 14.57 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:04<01:32, 10.35it/s, est. speed input: 13681.37 toks/s, output: 13.36 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:05<01:38,  9.69it/s, est. speed input: 12845.48 toks/s, output: 12.54 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:06<01:41,  9.26it/s, est. speed input: 12245.14 toks/s, output: 11.96 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:07<01:07, 13.69it/s, est. speed input: 13658.68 toks/s, output: 13.34 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:08<01:17, 11.84it/s, est. speed input: 13067.08 toks/s, output: 12.76 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:09<01:25, 10.68it/s, est. speed input: 12597.41 toks/s, output: 12.30 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:10<01:30,  9.92it/s, est. speed input: 12215.38 toks/s, output: 11.93 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:11<01:34,  9.42it/s, est. speed input: 11898.40 toks/s, output: 11.62 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:12<01:37,  9.08it/s, est. speed input: 11631.16 toks/s, output: 11.36 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:13<01:39,  8.85it/s, est. speed input: 11402.90 toks/s, output: 11.14 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:14<01:40,  8.68it/s, est. speed input: 11205.51 toks/s, output: 10.94 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:15<01:40,  8.57it/s, est. speed input: 11033.00 toks/s, output: 10.77 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:15<01:40,  8.49it/s, est. speed input: 10880.42 toks/s, output: 10.63 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:16<01:40,  8.43it/s, est. speed input: 10744.70 toks/s, output: 10.49 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:17<01:39,  8.39it/s, est. speed input: 10623.44 toks/s, output: 10.37 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:18<01:39,  8.36it/s, est. speed input: 10514.38 toks/s, output: 10.27 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:19<01:38,  8.34it/s, est. speed input: 10415.65 toks/s, output: 10.17 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:20<01:37,  8.32it/s, est. speed input: 10325.75 toks/s, output: 10.08 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:21<01:37,  8.31it/s, est. speed input: 10243.58 toks/s, output: 10.00 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:22<01:36,  8.30it/s, est. speed input: 10168.43 toks/s, output: 9.93 toks/s] 
Processed prompts:  23%|██▎       | 234/1024 [00:23<01:35,  8.29it/s, est. speed input: 10099.54 toks/s, output: 9.86 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:24<01:34,  8.29it/s, est. speed input: 10035.93 toks/s, output: 9.80 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:25<01:33,  8.28it/s, est. speed input: 9976.97 toks/s, output: 9.74 toks/s] 
Processed prompts:  25%|██▌       | 258/1024 [00:26<01:32,  8.28it/s, est. speed input: 9922.25 toks/s, output: 9.69 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:27<01:31,  8.28it/s, est. speed input: 9871.37 toks/s, output: 9.64 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:28<01:30,  8.27it/s, est. speed input: 9823.54 toks/s, output: 9.59 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:29<01:29,  8.27it/s, est. speed input: 9778.65 toks/s, output: 9.55 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:30<01:28,  8.26it/s, est. speed input: 9736.39 toks/s, output: 9.51 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:31<01:27,  8.26it/s, est. speed input: 9696.66 toks/s, output: 9.47 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:32<01:26,  8.26it/s, est. speed input: 9659.49 toks/s, output: 9.43 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:33<01:26,  8.25it/s, est. speed input: 9624.12 toks/s, output: 9.40 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:34<01:25,  8.25it/s, est. speed input: 9590.69 toks/s, output: 9.37 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:35<01:24,  8.25it/s, est. speed input: 9559.34 toks/s, output: 9.34 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:36<01:23,  8.24it/s, est. speed input: 9529.11 toks/s, output: 9.31 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:37<01:22,  8.24it/s, est. speed input: 9500.78 toks/s, output: 9.28 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:37<00:53, 12.46it/s, est. speed input: 9803.78 toks/s, output: 9.57 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:38<00:59, 11.05it/s, est. speed input: 9769.57 toks/s, output: 9.54 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:39<01:03, 10.15it/s, est. speed input: 9737.17 toks/s, output: 9.51 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:40<01:06,  9.55it/s, est. speed input: 9706.00 toks/s, output: 9.48 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:41<01:08,  9.14it/s, est. speed input: 9676.57 toks/s, output: 9.45 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:42<01:10,  8.86it/s, est. speed input: 9648.34 toks/s, output: 9.42 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:43<01:10,  8.67it/s, est. speed input: 9621.30 toks/s, output: 9.40 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:44<01:10,  8.54it/s, est. speed input: 9595.56 toks/s, output: 9.37 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:45<01:10,  8.45it/s, est. speed input: 9570.75 toks/s, output: 9.35 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:46<01:10,  8.38it/s, est. speed input: 9547.01 toks/s, output: 9.32 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:47<01:09,  8.34it/s, est. speed input: 9524.22 toks/s, output: 9.30 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:48<01:09,  8.31it/s, est. speed input: 9502.50 toks/s, output: 9.28 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:49<01:08,  8.28it/s, est. speed input: 9481.28 toks/s, output: 9.26 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:50<01:07,  8.27it/s, est. speed input: 9460.86 toks/s, output: 9.24 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:51<01:06,  8.25it/s, est. speed input: 9441.24 toks/s, output: 9.22 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:52<01:05,  8.25it/s, est. speed input: 9422.38 toks/s, output: 9.20 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:53<01:04,  8.24it/s, est. speed input: 9404.27 toks/s, output: 9.18 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:54<01:03,  8.24it/s, est. speed input: 9386.96 toks/s, output: 9.17 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:55<01:02,  8.24it/s, est. speed input: 9370.09 toks/s, output: 9.15 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:56<01:01,  8.24it/s, est. speed input: 9353.93 toks/s, output: 9.13 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:57<01:00,  8.24it/s, est. speed input: 9338.39 toks/s, output: 9.12 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:58<00:59,  8.24it/s, est. speed input: 9323.17 toks/s, output: 9.10 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:59<00:59,  8.23it/s, est. speed input: 9308.32 toks/s, output: 9.09 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [01:00<00:58,  8.23it/s, est. speed input: 9294.00 toks/s, output: 9.08 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [01:01<00:57,  8.23it/s, est. speed input: 9280.25 toks/s, output: 9.06 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [01:02<00:56,  8.23it/s, est. speed input: 9266.99 toks/s, output: 9.05 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [01:03<00:55,  8.23it/s, est. speed input: 9254.18 toks/s, output: 9.04 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [01:04<00:54,  8.23it/s, est. speed input: 9241.72 toks/s, output: 9.03 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [01:05<00:53,  8.23it/s, est. speed input: 9229.65 toks/s, output: 9.01 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [01:05<00:52,  8.23it/s, est. speed input: 9217.82 toks/s, output: 9.00 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [01:06<00:51,  8.23it/s, est. speed input: 9206.50 toks/s, output: 8.99 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [01:07<00:50,  8.23it/s, est. speed input: 9195.38 toks/s, output: 8.98 toks/s]
Processed prompts:  60%|██████    | 618/1024 [01:08<00:49,  8.23it/s, est. speed input: 9184.63 toks/s, output: 8.97 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [01:09<00:31, 12.42it/s, est. speed input: 9351.37 toks/s, output: 9.13 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [01:10<00:34, 11.03it/s, est. speed input: 9338.64 toks/s, output: 9.12 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [01:11<00:36, 10.13it/s, est. speed input: 9326.35 toks/s, output: 9.11 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [01:12<00:38,  9.53it/s, est. speed input: 9314.33 toks/s, output: 9.10 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [01:13<00:39,  9.13it/s, est. speed input: 9302.60 toks/s, output: 9.08 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [01:14<00:39,  8.85it/s, est. speed input: 9291.07 toks/s, output: 9.07 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [01:15<00:39,  8.66it/s, est. speed input: 9279.92 toks/s, output: 9.06 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [01:16<00:39,  8.53it/s, est. speed input: 9269.05 toks/s, output: 9.05 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [01:17<00:38,  8.44it/s, est. speed input: 9258.52 toks/s, output: 9.04 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [01:18<00:37,  8.38it/s, est. speed input: 9248.16 toks/s, output: 9.03 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [01:19<00:37,  8.33it/s, est. speed input: 9238.09 toks/s, output: 9.02 toks/s]
Processed prompts:  71%|███████   | 722/1024 [01:20<00:36,  8.30it/s, est. speed input: 9228.17 toks/s, output: 9.01 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [01:21<00:35,  8.28it/s, est. speed input: 9218.47 toks/s, output: 9.00 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [01:22<00:34,  8.26it/s, est. speed input: 9209.08 toks/s, output: 8.99 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [01:23<00:33,  8.25it/s, est. speed input: 9199.90 toks/s, output: 8.98 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [01:24<00:32,  8.24it/s, est. speed input: 9190.86 toks/s, output: 8.98 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [01:24<00:31,  8.24it/s, est. speed input: 9182.20 toks/s, output: 8.97 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [01:25<00:30,  8.24it/s, est. speed input: 9173.70 toks/s, output: 8.96 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [01:26<00:29,  8.24it/s, est. speed input: 9165.32 toks/s, output: 8.95 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [01:27<00:28,  8.23it/s, est. speed input: 9157.19 toks/s, output: 8.94 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [01:28<00:27,  8.23it/s, est. speed input: 9149.25 toks/s, output: 8.93 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [01:29<00:26,  8.23it/s, est. speed input: 9141.39 toks/s, output: 8.93 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [01:30<00:26,  8.23it/s, est. speed input: 9133.70 toks/s, output: 8.92 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [01:31<00:25,  8.23it/s, est. speed input: 9126.25 toks/s, output: 8.91 toks/s]
Processed prompts:  81%|████████  | 826/1024 [01:32<00:24,  8.23it/s, est. speed input: 9118.81 toks/s, output: 8.91 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [01:33<00:23,  8.23it/s, est. speed input: 9111.61 toks/s, output: 8.90 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [01:34<00:22,  8.23it/s, est. speed input: 9104.54 toks/s, output: 8.89 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [01:35<00:21,  8.23it/s, est. speed input: 9097.60 toks/s, output: 8.88 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [01:36<00:20,  8.23it/s, est. speed input: 9090.83 toks/s, output: 8.88 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [01:37<00:19,  8.23it/s, est. speed input: 9084.19 toks/s, output: 8.87 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [01:38<00:18,  8.23it/s, est. speed input: 9077.74 toks/s, output: 8.86 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [01:39<00:17,  8.23it/s, est. speed input: 9071.46 toks/s, output: 8.86 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [01:40<00:10, 12.46it/s, est. speed input: 9188.64 toks/s, output: 8.97 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [01:41<00:10, 11.06it/s, est. speed input: 9181.47 toks/s, output: 8.97 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [01:42<00:10, 10.15it/s, est. speed input: 9174.32 toks/s, output: 8.96 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [01:42<00:10,  9.55it/s, est. speed input: 9167.37 toks/s, output: 8.95 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [01:43<00:10,  9.14it/s, est. speed input: 9160.66 toks/s, output: 8.95 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [01:44<00:09,  8.87it/s, est. speed input: 9153.93 toks/s, output: 8.94 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [01:45<00:08,  8.68it/s, est. speed input: 9147.39 toks/s, output: 8.93 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [01:46<00:08,  8.54it/s, est. speed input: 9140.92 toks/s, output: 8.93 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [01:47<00:07,  8.45it/s, est. speed input: 9134.54 toks/s, output: 8.92 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [01:48<00:06,  8.38it/s, est. speed input: 9128.20 toks/s, output: 8.91 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [01:49<00:05,  8.34it/s, est. speed input: 9121.97 toks/s, output: 8.91 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [01:50<00:04,  8.30it/s, est. speed input: 9115.85 toks/s, output: 8.90 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [01:51<00:03,  8.28it/s, est. speed input: 9109.83 toks/s, output: 8.90 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [01:52<00:02,  8.26it/s, est. speed input: 9103.85 toks/s, output: 8.89 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [01:53<00:01,  8.25it/s, est. speed input: 9098.01 toks/s, output: 8.88 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [01:54<00:00,  8.56it/s, est. speed input: 9101.75 toks/s, output: 8.89 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:54<00:00,  8.56it/s, est. speed input: 9155.37 toks/s, output: 8.94 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:54<00:00,  8.94it/s, est. speed input: 9155.37 toks/s, output: 8.94 toks/s]
[rank0]:[W126 07:03:25.091702699 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 187.0s

测试结果:
  Requests/s:   8.24
  Tokens/s:     8450.21
  Total Reqs:   1024
  Elapsed:      124.21s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     8441.96

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:03:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:03:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=323375) WARNING 01-26 07:03:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=323375) WARNING 01-26 07:04:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.22 requests/s, 8423.69 total tokens/s, 8.22 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 07:03:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:03:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:03:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:03:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:03:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:03:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:03:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:03:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:03:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:03:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:03:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:03:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:03:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:03:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:03:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:03:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:03:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=323375) [2026-01-26 07:03:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=323375) [2026-01-26 07:03:59] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=323375) [2026-01-26 07:03:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=323375) [2026-01-26 07:03:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=323375) [2026-01-26 07:03:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.02it/s]
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.01it/s]
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.42it/s]
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.26it/s]
(EngineCore_DP0 pid=323375) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]
(EngineCore_DP0 pid=323375) 
(EngineCore_DP0 pid=323375) [rank0]:W0126 07:04:27.899000 323375 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=323375) [rank0]:W0126 07:04:27.981000 323375 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=323375) [rank0]:W0126 07:04:29.168000 323375 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=323375) [rank0]:W0126 07:04:29.284000 323375 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=323375) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  4.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  4.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:02<00:00,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:02<00:00,  3.48it/s]
(EngineCore_DP0 pid=323375) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  4.49it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  4.89it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  4.97it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  5.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  5.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  5.00it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/2048 [00:00<00:08, 233.96it/s]
Adding requests:   2%|▏         | 49/2048 [00:00<00:08, 241.34it/s]
Adding requests:   4%|▎         | 74/2048 [00:00<00:08, 245.11it/s]
Adding requests:   5%|▍         | 99/2048 [00:00<00:08, 243.62it/s]
Adding requests:   6%|▌         | 125/2048 [00:00<00:07, 248.81it/s]
Adding requests:   7%|▋         | 151/2048 [00:00<00:07, 250.49it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:07, 253.32it/s]
Adding requests:  10%|▉         | 204/2048 [00:00<00:07, 257.40it/s]
Adding requests:  11%|█         | 230/2048 [00:00<00:07, 245.73it/s]
Adding requests:  12%|█▏        | 255/2048 [00:01<00:08, 218.17it/s]
Adding requests:  14%|█▎        | 278/2048 [00:01<00:08, 208.15it/s]
Adding requests:  15%|█▍        | 300/2048 [00:01<00:08, 202.22it/s]
Adding requests:  16%|█▌        | 325/2048 [00:01<00:08, 214.68it/s]
Adding requests:  17%|█▋        | 353/2048 [00:01<00:07, 231.73it/s]
Adding requests:  19%|█▊        | 381/2048 [00:01<00:06, 243.58it/s]
Adding requests:  20%|█▉        | 409/2048 [00:01<00:06, 252.85it/s]
Adding requests:  21%|██▏       | 436/2048 [00:01<00:06, 255.77it/s]
Adding requests:  23%|██▎       | 462/2048 [00:01<00:06, 256.40it/s]
Adding requests:  24%|██▍       | 491/2048 [00:02<00:05, 265.28it/s]
Adding requests:  25%|██▌       | 519/2048 [00:02<00:05, 268.21it/s]
Adding requests:  27%|██▋       | 547/2048 [00:02<00:05, 270.07it/s]
Adding requests:  28%|██▊       | 575/2048 [00:02<00:05, 270.41it/s]
Adding requests:  29%|██▉       | 603/2048 [00:02<00:05, 261.61it/s]
Adding requests:  31%|███       | 630/2048 [00:02<00:05, 260.96it/s]
Adding requests:  32%|███▏      | 657/2048 [00:02<00:05, 252.10it/s]
Adding requests:  33%|███▎      | 683/2048 [00:02<00:05, 248.60it/s]
Adding requests:  52%|█████▏    | 1060/2048 [00:02<00:00, 1240.63it/s]
Adding requests:  58%|█████▊    | 1190/2048 [00:03<00:01, 572.30it/s] 
Adding requests:  63%|██████▎   | 1288/2048 [00:03<00:01, 426.56it/s]
Adding requests:  67%|██████▋   | 1364/2048 [00:04<00:01, 372.43it/s]
Adding requests:  70%|██████▉   | 1425/2048 [00:04<00:01, 339.39it/s]
Adding requests:  72%|███████▏  | 1475/2048 [00:04<00:01, 320.94it/s]
Adding requests:  74%|███████▍  | 1518/2048 [00:04<00:01, 307.26it/s]
Adding requests:  76%|███████▌  | 1556/2048 [00:04<00:01, 289.12it/s]
Adding requests:  78%|███████▊  | 1590/2048 [00:05<00:01, 274.81it/s]
Adding requests:  79%|███████▉  | 1621/2048 [00:05<00:01, 267.38it/s]
Adding requests:  81%|████████  | 1650/2048 [00:05<00:01, 261.99it/s]
Adding requests:  82%|████████▏ | 1678/2048 [00:05<00:01, 257.00it/s]
Adding requests:  83%|████████▎ | 1705/2048 [00:05<00:01, 259.48it/s]
Adding requests:  85%|████████▍ | 1732/2048 [00:05<00:01, 262.06it/s]
Adding requests:  86%|████████▌ | 1759/2048 [00:05<00:01, 261.04it/s]
Adding requests:  87%|████████▋ | 1786/2048 [00:05<00:01, 259.93it/s]
Adding requests:  89%|████████▊ | 1813/2048 [00:05<00:00, 256.44it/s]
Adding requests:  90%|████████▉ | 1839/2048 [00:06<00:00, 256.29it/s]
Adding requests:  91%|█████████ | 1866/2048 [00:06<00:00, 259.24it/s]
Adding requests:  92%|█████████▏| 1893/2048 [00:06<00:00, 260.73it/s]
Adding requests:  94%|█████████▍| 1920/2048 [00:06<00:00, 262.35it/s]
Adding requests:  95%|█████████▌| 1948/2048 [00:06<00:00, 266.92it/s]
Adding requests:  96%|█████████▋| 1975/2048 [00:06<00:00, 266.71it/s]
Adding requests:  98%|█████████▊| 2002/2048 [00:06<00:00, 258.60it/s]
Adding requests:  99%|█████████▉| 2028/2048 [00:06<00:00, 246.52it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 299.41it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 66/2048 [00:00<00:22, 89.18it/s, est. speed input: 91323.31 toks/s, output: 89.18 toks/s]
Processed prompts:   4%|▎         | 75/2048 [00:01<00:52, 37.34it/s, est. speed input: 45166.56 toks/s, output: 44.11 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:02<01:25, 22.87it/s, est. speed input: 31549.68 toks/s, output: 30.81 toks/s]
Processed prompts:   4%|▍         | 90/2048 [00:03<01:55, 16.93it/s, est. speed input: 25433.88 toks/s, output: 24.84 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:04<02:21, 13.76it/s, est. speed input: 21881.39 toks/s, output: 21.37 toks/s]
Processed prompts:   5%|▌         | 106/2048 [00:05<02:43, 11.88it/s, est. speed input: 19561.88 toks/s, output: 19.10 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:06<03:00, 10.70it/s, est. speed input: 17927.46 toks/s, output: 17.51 toks/s]
Processed prompts:   6%|▌         | 122/2048 [00:07<03:13,  9.93it/s, est. speed input: 16713.65 toks/s, output: 16.32 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:08<03:23,  9.42it/s, est. speed input: 15777.70 toks/s, output: 15.41 toks/s]
Processed prompts:   7%|▋         | 138/2048 [00:09<03:30,  9.08it/s, est. speed input: 15032.74 toks/s, output: 14.68 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:10<03:35,  8.84it/s, est. speed input: 14425.88 toks/s, output: 14.09 toks/s]
Processed prompts:   8%|▊         | 154/2048 [00:11<03:38,  8.68it/s, est. speed input: 13921.94 toks/s, output: 13.60 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:12<03:40,  8.56it/s, est. speed input: 13496.89 toks/s, output: 13.18 toks/s]
Processed prompts:   8%|▊         | 170/2048 [00:13<03:41,  8.48it/s, est. speed input: 13132.78 toks/s, output: 12.82 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:14<03:41,  8.42it/s, est. speed input: 12817.59 toks/s, output: 12.52 toks/s]
Processed prompts:   9%|▉         | 186/2048 [00:15<03:42,  8.38it/s, est. speed input: 12541.91 toks/s, output: 12.25 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:16<03:41,  8.35it/s, est. speed input: 12299.73 toks/s, output: 12.01 toks/s]
Processed prompts:  10%|▉         | 202/2048 [00:17<03:41,  8.33it/s, est. speed input: 12084.46 toks/s, output: 11.80 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:18<03:40,  8.32it/s, est. speed input: 11891.81 toks/s, output: 11.61 toks/s]
Processed prompts:  11%|█         | 218/2048 [00:19<03:40,  8.31it/s, est. speed input: 11718.87 toks/s, output: 11.44 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:20<03:39,  8.30it/s, est. speed input: 11562.22 toks/s, output: 11.29 toks/s]
Processed prompts:  11%|█▏        | 234/2048 [00:20<03:38,  8.29it/s, est. speed input: 11420.11 toks/s, output: 11.15 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:21<03:37,  8.29it/s, est. speed input: 11290.19 toks/s, output: 11.03 toks/s]
Processed prompts:  12%|█▏        | 250/2048 [00:22<03:37,  8.28it/s, est. speed input: 11170.72 toks/s, output: 10.91 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:23<03:36,  8.28it/s, est. speed input: 11061.08 toks/s, output: 10.80 toks/s]
Processed prompts:  13%|█▎        | 266/2048 [00:24<03:35,  8.27it/s, est. speed input: 10959.97 toks/s, output: 10.70 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:25<03:34,  8.27it/s, est. speed input: 10866.33 toks/s, output: 10.61 toks/s]
Processed prompts:  14%|█▍        | 282/2048 [00:26<03:33,  8.27it/s, est. speed input: 10779.18 toks/s, output: 10.53 toks/s]
Processed prompts:  15%|█▍        | 298/2048 [00:27<02:19, 12.58it/s, est. speed input: 11183.32 toks/s, output: 10.92 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:28<02:36, 11.14it/s, est. speed input: 11089.86 toks/s, output: 10.83 toks/s]
Processed prompts:  15%|█▌        | 314/2048 [00:29<02:49, 10.20it/s, est. speed input: 11002.30 toks/s, output: 10.74 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:30<03:00,  9.58it/s, est. speed input: 10919.77 toks/s, output: 10.66 toks/s]
Processed prompts:  16%|█▌        | 330/2048 [00:31<03:07,  9.17it/s, est. speed input: 10842.66 toks/s, output: 10.59 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:32<03:12,  8.88it/s, est. speed input: 10770.06 toks/s, output: 10.52 toks/s]
Processed prompts:  17%|█▋        | 346/2048 [00:33<03:15,  8.69it/s, est. speed input: 10701.76 toks/s, output: 10.45 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:34<03:18,  8.55it/s, est. speed input: 10637.40 toks/s, output: 10.39 toks/s]
Processed prompts:  18%|█▊        | 362/2048 [00:35<03:19,  8.46it/s, est. speed input: 10576.70 toks/s, output: 10.33 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:36<03:19,  8.39it/s, est. speed input: 10519.13 toks/s, output: 10.27 toks/s]
Processed prompts:  18%|█▊        | 378/2048 [00:36<03:20,  8.35it/s, est. speed input: 10464.26 toks/s, output: 10.22 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:37<03:19,  8.32it/s, est. speed input: 10412.60 toks/s, output: 10.17 toks/s]
Processed prompts:  19%|█▉        | 394/2048 [00:38<03:19,  8.29it/s, est. speed input: 10363.35 toks/s, output: 10.12 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:39<03:18,  8.28it/s, est. speed input: 10316.47 toks/s, output: 10.07 toks/s]
Processed prompts:  20%|██        | 410/2048 [00:40<03:18,  8.27it/s, est. speed input: 10272.03 toks/s, output: 10.03 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:41<03:17,  8.26it/s, est. speed input: 10229.18 toks/s, output: 9.99 toks/s] 
Processed prompts:  21%|██        | 426/2048 [00:42<03:16,  8.25it/s, est. speed input: 10188.01 toks/s, output: 9.95 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:43<03:15,  8.24it/s, est. speed input: 10148.69 toks/s, output: 9.91 toks/s]
Processed prompts:  22%|██▏       | 442/2048 [00:44<03:15,  8.23it/s, est. speed input: 10110.94 toks/s, output: 9.87 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:45<03:14,  8.23it/s, est. speed input: 10074.81 toks/s, output: 9.84 toks/s]
Processed prompts:  22%|██▏       | 458/2048 [00:46<03:13,  8.23it/s, est. speed input: 10040.45 toks/s, output: 9.81 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:47<03:12,  8.23it/s, est. speed input: 10007.37 toks/s, output: 9.77 toks/s]
Processed prompts:  23%|██▎       | 474/2048 [00:48<03:11,  8.23it/s, est. speed input: 9975.67 toks/s, output: 9.74 toks/s] 
Processed prompts:  24%|██▎       | 482/2048 [00:49<03:10,  8.23it/s, est. speed input: 9945.26 toks/s, output: 9.71 toks/s]
Processed prompts:  24%|██▍       | 490/2048 [00:50<03:09,  8.23it/s, est. speed input: 9915.99 toks/s, output: 9.68 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:51<03:08,  8.23it/s, est. speed input: 9887.85 toks/s, output: 9.66 toks/s]
Processed prompts:  25%|██▍       | 506/2048 [00:52<03:07,  8.23it/s, est. speed input: 9860.77 toks/s, output: 9.63 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:53<03:06,  8.22it/s, est. speed input: 9834.52 toks/s, output: 9.60 toks/s]
Processed prompts:  25%|██▌       | 522/2048 [00:54<03:05,  8.22it/s, est. speed input: 9809.31 toks/s, output: 9.58 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:55<03:04,  8.22it/s, est. speed input: 9784.76 toks/s, output: 9.56 toks/s]
Processed prompts:  26%|██▋       | 538/2048 [00:56<03:03,  8.23it/s, est. speed input: 9761.47 toks/s, output: 9.53 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:57<03:02,  8.22it/s, est. speed input: 9738.69 toks/s, output: 9.51 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:57<01:59, 12.44it/s, est. speed input: 9934.82 toks/s, output: 9.70 toks/s]
Processed prompts:  28%|██▊       | 570/2048 [00:58<02:13, 11.04it/s, est. speed input: 9909.76 toks/s, output: 9.68 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:59<02:25, 10.13it/s, est. speed input: 9885.52 toks/s, output: 9.65 toks/s]
Processed prompts:  29%|██▊       | 586/2048 [01:00<02:33,  9.53it/s, est. speed input: 9861.97 toks/s, output: 9.63 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [01:01<02:39,  9.12it/s, est. speed input: 9839.06 toks/s, output: 9.61 toks/s]
Processed prompts:  29%|██▉       | 602/2048 [01:02<02:43,  8.84it/s, est. speed input: 9817.06 toks/s, output: 9.59 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [01:03<02:46,  8.65it/s, est. speed input: 9795.57 toks/s, output: 9.57 toks/s]
Processed prompts:  30%|███       | 618/2048 [01:04<02:47,  8.52it/s, est. speed input: 9774.73 toks/s, output: 9.55 toks/s]
Processed prompts:  31%|███       | 626/2048 [01:05<02:48,  8.43it/s, est. speed input: 9754.64 toks/s, output: 9.53 toks/s]
Processed prompts:  31%|███       | 634/2048 [01:06<02:48,  8.37it/s, est. speed input: 9735.30 toks/s, output: 9.51 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [01:07<02:48,  8.32it/s, est. speed input: 9716.22 toks/s, output: 9.49 toks/s]
Processed prompts:  32%|███▏      | 650/2048 [01:08<02:48,  8.29it/s, est. speed input: 9697.69 toks/s, output: 9.47 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [01:09<02:48,  8.27it/s, est. speed input: 9679.72 toks/s, output: 9.45 toks/s]
Processed prompts:  33%|███▎      | 666/2048 [01:10<02:47,  8.25it/s, est. speed input: 9662.27 toks/s, output: 9.44 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [01:11<02:46,  8.24it/s, est. speed input: 9645.25 toks/s, output: 9.42 toks/s]
Processed prompts:  33%|███▎      | 682/2048 [01:12<02:45,  8.24it/s, est. speed input: 9628.83 toks/s, output: 9.40 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [01:13<02:45,  8.23it/s, est. speed input: 9612.70 toks/s, output: 9.39 toks/s]
Processed prompts:  34%|███▍      | 698/2048 [01:14<02:44,  8.23it/s, est. speed input: 9597.06 toks/s, output: 9.37 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [01:15<02:43,  8.22it/s, est. speed input: 9581.77 toks/s, output: 9.36 toks/s]
Processed prompts:  35%|███▍      | 714/2048 [01:16<02:42,  8.22it/s, est. speed input: 9566.79 toks/s, output: 9.34 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [01:17<02:41,  8.22it/s, est. speed input: 9552.23 toks/s, output: 9.33 toks/s]
Processed prompts:  36%|███▌      | 730/2048 [01:18<02:40,  8.22it/s, est. speed input: 9538.23 toks/s, output: 9.31 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [01:19<02:39,  8.22it/s, est. speed input: 9524.39 toks/s, output: 9.30 toks/s]
Processed prompts:  36%|███▋      | 746/2048 [01:20<02:38,  8.22it/s, est. speed input: 9510.92 toks/s, output: 9.29 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [01:21<02:37,  8.22it/s, est. speed input: 9497.85 toks/s, output: 9.28 toks/s]
Processed prompts:  37%|███▋      | 762/2048 [01:22<02:36,  8.22it/s, est. speed input: 9484.96 toks/s, output: 9.26 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [01:23<02:35,  8.22it/s, est. speed input: 9472.39 toks/s, output: 9.25 toks/s]
Processed prompts:  38%|███▊      | 778/2048 [01:24<02:34,  8.22it/s, est. speed input: 9460.13 toks/s, output: 9.24 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [01:25<02:33,  8.22it/s, est. speed input: 9448.22 toks/s, output: 9.23 toks/s]
Processed prompts:  39%|███▉      | 794/2048 [01:26<02:32,  8.22it/s, est. speed input: 9436.53 toks/s, output: 9.22 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [01:27<02:31,  8.22it/s, est. speed input: 9425.28 toks/s, output: 9.20 toks/s]
Processed prompts:  40%|███▉      | 810/2048 [01:28<02:30,  8.22it/s, est. speed input: 9414.00 toks/s, output: 9.19 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [01:29<02:29,  8.22it/s, est. speed input: 9403.16 toks/s, output: 9.18 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:29<01:37, 12.41it/s, est. speed input: 9531.31 toks/s, output: 9.31 toks/s]
Processed prompts:  41%|████      | 842/2048 [01:30<01:49, 11.01it/s, est. speed input: 9519.18 toks/s, output: 9.30 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:31<01:58, 10.12it/s, est. speed input: 9507.47 toks/s, output: 9.28 toks/s]
Processed prompts:  42%|████▏     | 858/2048 [01:32<02:05,  9.52it/s, est. speed input: 9496.01 toks/s, output: 9.27 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:33<02:09,  9.12it/s, est. speed input: 9484.82 toks/s, output: 9.26 toks/s]
Processed prompts:  43%|████▎     | 874/2048 [01:34<02:12,  8.84it/s, est. speed input: 9473.85 toks/s, output: 9.25 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [01:35<02:14,  8.65it/s, est. speed input: 9463.05 toks/s, output: 9.24 toks/s]
Processed prompts:  43%|████▎     | 890/2048 [01:36<02:15,  8.52it/s, est. speed input: 9452.39 toks/s, output: 9.23 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:37<02:16,  8.42it/s, est. speed input: 9441.91 toks/s, output: 9.22 toks/s]
Processed prompts:  44%|████▍     | 906/2048 [01:38<02:16,  8.36it/s, est. speed input: 9431.83 toks/s, output: 9.21 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:39<02:16,  8.32it/s, est. speed input: 9421.79 toks/s, output: 9.20 toks/s]
Processed prompts:  45%|████▌     | 922/2048 [01:40<02:15,  8.29it/s, est. speed input: 9411.97 toks/s, output: 9.19 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:41<02:15,  8.26it/s, est. speed input: 9402.34 toks/s, output: 9.18 toks/s]
Processed prompts:  46%|████▌     | 938/2048 [01:42<02:14,  8.25it/s, est. speed input: 9392.88 toks/s, output: 9.17 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:43<02:13,  8.24it/s, est. speed input: 9383.60 toks/s, output: 9.16 toks/s]
Processed prompts:  47%|████▋     | 954/2048 [01:44<02:12,  8.23it/s, est. speed input: 9374.56 toks/s, output: 9.15 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:45<02:12,  8.23it/s, est. speed input: 9365.61 toks/s, output: 9.15 toks/s]
Processed prompts:  47%|████▋     | 970/2048 [01:46<02:11,  8.22it/s, est. speed input: 9356.82 toks/s, output: 9.14 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:47<02:10,  8.22it/s, est. speed input: 9348.25 toks/s, output: 9.13 toks/s]
Processed prompts:  48%|████▊     | 986/2048 [01:48<02:09,  8.22it/s, est. speed input: 9339.80 toks/s, output: 9.12 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:49<02:08,  8.22it/s, est. speed input: 9331.50 toks/s, output: 9.11 toks/s]
Processed prompts:  49%|████▉     | 1002/2048 [01:50<02:07,  8.22it/s, est. speed input: 9323.43 toks/s, output: 9.10 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:51<02:06,  8.22it/s, est. speed input: 9315.39 toks/s, output: 9.10 toks/s]
Processed prompts:  50%|████▉     | 1018/2048 [01:51<02:05,  8.22it/s, est. speed input: 9307.56 toks/s, output: 9.09 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:52<02:04,  8.22it/s, est. speed input: 9299.90 toks/s, output: 9.08 toks/s]
Processed prompts:  50%|█████     | 1034/2048 [01:53<02:03,  8.22it/s, est. speed input: 9292.27 toks/s, output: 9.07 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:54<02:02,  8.22it/s, est. speed input: 9284.84 toks/s, output: 9.07 toks/s]
Processed prompts:  51%|█████▏    | 1050/2048 [01:55<02:01,  8.21it/s, est. speed input: 9277.44 toks/s, output: 9.06 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:56<02:00,  8.21it/s, est. speed input: 9270.17 toks/s, output: 9.05 toks/s]
Processed prompts:  52%|█████▏    | 1066/2048 [01:57<01:59,  8.21it/s, est. speed input: 9262.99 toks/s, output: 9.05 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:58<01:58,  8.21it/s, est. speed input: 9256.03 toks/s, output: 9.04 toks/s]
Processed prompts:  53%|█████▎    | 1082/2048 [01:59<01:57,  8.21it/s, est. speed input: 9249.12 toks/s, output: 9.03 toks/s]
Processed prompts:  54%|█████▎    | 1098/2048 [02:00<01:16, 12.43it/s, est. speed input: 9345.73 toks/s, output: 9.13 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [02:01<01:25, 11.03it/s, est. speed input: 9338.33 toks/s, output: 9.12 toks/s]
Processed prompts:  54%|█████▍    | 1114/2048 [02:02<01:32, 10.13it/s, est. speed input: 9331.00 toks/s, output: 9.11 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [02:03<01:37,  9.53it/s, est. speed input: 9323.76 toks/s, output: 9.11 toks/s]
Processed prompts:  55%|█████▌    | 1130/2048 [02:04<01:40,  9.12it/s, est. speed input: 9316.62 toks/s, output: 9.10 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [02:05<01:42,  8.84it/s, est. speed input: 9309.62 toks/s, output: 9.09 toks/s]
Processed prompts:  56%|█████▌    | 1146/2048 [02:06<01:44,  8.65it/s, est. speed input: 9302.73 toks/s, output: 9.08 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [02:07<01:44,  8.52it/s, est. speed input: 9295.92 toks/s, output: 9.08 toks/s]
Processed prompts:  57%|█████▋    | 1162/2048 [02:08<01:45,  8.43it/s, est. speed input: 9289.20 toks/s, output: 9.07 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [02:09<01:44,  8.36it/s, est. speed input: 9282.54 toks/s, output: 9.06 toks/s]
Processed prompts:  58%|█████▊    | 1178/2048 [02:10<01:44,  8.32it/s, est. speed input: 9275.98 toks/s, output: 9.06 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [02:11<01:44,  8.28it/s, est. speed input: 9269.41 toks/s, output: 9.05 toks/s]
Processed prompts:  58%|█████▊    | 1194/2048 [02:11<01:43,  8.26it/s, est. speed input: 9263.00 toks/s, output: 9.05 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [02:12<01:42,  8.24it/s, est. speed input: 9256.74 toks/s, output: 9.04 toks/s]
Processed prompts:  59%|█████▉    | 1210/2048 [02:13<01:41,  8.23it/s, est. speed input: 9250.59 toks/s, output: 9.03 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [02:14<01:40,  8.23it/s, est. speed input: 9244.51 toks/s, output: 9.03 toks/s]
Processed prompts:  60%|█████▉    | 1226/2048 [02:15<01:39,  8.22it/s, est. speed input: 9238.45 toks/s, output: 9.02 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [02:16<01:39,  8.21it/s, est. speed input: 9232.35 toks/s, output: 9.02 toks/s]
Processed prompts:  61%|██████    | 1242/2048 [02:17<01:38,  8.21it/s, est. speed input: 9226.40 toks/s, output: 9.01 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [02:18<01:37,  8.20it/s, est. speed input: 9220.53 toks/s, output: 9.00 toks/s]
Processed prompts:  61%|██████▏   | 1258/2048 [02:19<01:36,  8.20it/s, est. speed input: 9214.70 toks/s, output: 9.00 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [02:20<01:35,  8.20it/s, est. speed input: 9208.93 toks/s, output: 8.99 toks/s]
Processed prompts:  62%|██████▏   | 1274/2048 [02:21<01:34,  8.20it/s, est. speed input: 9203.36 toks/s, output: 8.99 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [02:22<01:33,  8.20it/s, est. speed input: 9197.79 toks/s, output: 8.98 toks/s]
Processed prompts:  63%|██████▎   | 1290/2048 [02:23<01:32,  8.19it/s, est. speed input: 9192.29 toks/s, output: 8.98 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [02:24<01:31,  8.20it/s, est. speed input: 9186.97 toks/s, output: 8.97 toks/s]
Processed prompts:  64%|██████▍   | 1306/2048 [02:25<01:30,  8.20it/s, est. speed input: 9181.74 toks/s, output: 8.97 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [02:26<01:29,  8.20it/s, est. speed input: 9176.55 toks/s, output: 8.96 toks/s]
Processed prompts:  65%|██████▍   | 1322/2048 [02:27<01:28,  8.20it/s, est. speed input: 9171.46 toks/s, output: 8.96 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [02:28<01:27,  8.20it/s, est. speed input: 9166.41 toks/s, output: 8.95 toks/s]
Processed prompts:  65%|██████▌   | 1338/2048 [02:29<01:26,  8.21it/s, est. speed input: 9161.47 toks/s, output: 8.95 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [02:30<01:25,  8.21it/s, est. speed input: 9156.55 toks/s, output: 8.94 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [02:31<00:55, 12.46it/s, est. speed input: 9234.22 toks/s, output: 9.02 toks/s]
Processed prompts:  67%|██████▋   | 1370/2048 [02:32<01:01, 11.04it/s, est. speed input: 9228.94 toks/s, output: 9.01 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [02:32<01:06, 10.15it/s, est. speed input: 9224.04 toks/s, output: 9.01 toks/s]
Processed prompts:  68%|██████▊   | 1386/2048 [02:33<01:09,  9.55it/s, est. speed input: 9219.20 toks/s, output: 9.00 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [02:34<01:11,  9.15it/s, est. speed input: 9214.45 toks/s, output: 9.00 toks/s]
Processed prompts:  68%|██████▊   | 1402/2048 [02:35<01:12,  8.88it/s, est. speed input: 9209.74 toks/s, output: 8.99 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [02:36<01:13,  8.69it/s, est. speed input: 9205.06 toks/s, output: 8.99 toks/s]
Processed prompts:  69%|██████▉   | 1418/2048 [02:37<01:13,  8.56it/s, est. speed input: 9200.45 toks/s, output: 8.98 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [02:38<01:13,  8.47it/s, est. speed input: 9195.89 toks/s, output: 8.98 toks/s]
Processed prompts:  70%|███████   | 1434/2048 [02:39<01:13,  8.40it/s, est. speed input: 9191.39 toks/s, output: 8.98 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [02:40<01:12,  8.33it/s, est. speed input: 9186.29 toks/s, output: 8.97 toks/s]
Processed prompts:  71%|███████   | 1450/2048 [02:41<01:12,  8.27it/s, est. speed input: 9181.18 toks/s, output: 8.97 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [02:42<01:11,  8.24it/s, est. speed input: 9176.14 toks/s, output: 8.96 toks/s]
Processed prompts:  72%|███████▏  | 1466/2048 [02:43<01:10,  8.21it/s, est. speed input: 9171.17 toks/s, output: 8.96 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [02:44<01:10,  8.19it/s, est. speed input: 9166.27 toks/s, output: 8.95 toks/s]
Processed prompts:  72%|███████▏  | 1482/2048 [02:45<01:09,  8.18it/s, est. speed input: 9161.46 toks/s, output: 8.95 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [02:46<01:08,  8.17it/s, est. speed input: 9156.64 toks/s, output: 8.94 toks/s]
Processed prompts:  73%|███████▎  | 1498/2048 [02:47<01:07,  8.17it/s, est. speed input: 9151.91 toks/s, output: 8.94 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [02:48<01:06,  8.17it/s, est. speed input: 9147.39 toks/s, output: 8.93 toks/s]
Processed prompts:  74%|███████▍  | 1514/2048 [02:49<01:05,  8.17it/s, est. speed input: 9142.96 toks/s, output: 8.93 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [02:50<01:04,  8.18it/s, est. speed input: 9138.58 toks/s, output: 8.92 toks/s]
Processed prompts:  75%|███████▍  | 1530/2048 [02:51<01:03,  8.18it/s, est. speed input: 9134.26 toks/s, output: 8.92 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [02:52<01:02,  8.18it/s, est. speed input: 9129.95 toks/s, output: 8.92 toks/s]
Processed prompts:  75%|███████▌  | 1546/2048 [02:53<01:01,  8.18it/s, est. speed input: 9125.69 toks/s, output: 8.91 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [02:54<01:00,  8.18it/s, est. speed input: 9121.47 toks/s, output: 8.91 toks/s]
Processed prompts:  76%|███████▋  | 1562/2048 [02:55<00:59,  8.18it/s, est. speed input: 9117.26 toks/s, output: 8.90 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [02:56<00:58,  8.18it/s, est. speed input: 9113.30 toks/s, output: 8.90 toks/s]
Processed prompts:  77%|███████▋  | 1578/2048 [02:57<00:57,  8.20it/s, est. speed input: 9109.50 toks/s, output: 8.90 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:58<00:56,  8.21it/s, est. speed input: 9105.76 toks/s, output: 8.89 toks/s]
Processed prompts:  78%|███████▊  | 1594/2048 [02:59<00:55,  8.21it/s, est. speed input: 9102.07 toks/s, output: 8.89 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [03:00<00:54,  8.21it/s, est. speed input: 9098.31 toks/s, output: 8.89 toks/s]
Processed prompts:  79%|███████▊  | 1610/2048 [03:01<00:53,  8.21it/s, est. speed input: 9094.66 toks/s, output: 8.88 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [03:02<00:52,  8.21it/s, est. speed input: 9091.01 toks/s, output: 8.88 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [03:02<00:32, 12.57it/s, est. speed input: 9156.47 toks/s, output: 8.94 toks/s]
Processed prompts:  80%|████████  | 1642/2048 [03:03<00:36, 11.11it/s, est. speed input: 9152.52 toks/s, output: 8.94 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [03:04<00:39, 10.17it/s, est. speed input: 9148.59 toks/s, output: 8.93 toks/s]
Processed prompts:  81%|████████  | 1658/2048 [03:05<00:40,  9.55it/s, est. speed input: 9144.71 toks/s, output: 8.93 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [03:06<00:41,  9.13it/s, est. speed input: 9140.84 toks/s, output: 8.93 toks/s]
Processed prompts:  82%|████████▏ | 1674/2048 [03:07<00:42,  8.85it/s, est. speed input: 9137.03 toks/s, output: 8.92 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [03:08<00:42,  8.66it/s, est. speed input: 9133.29 toks/s, output: 8.92 toks/s]
Processed prompts:  83%|████████▎ | 1690/2048 [03:09<00:42,  8.52it/s, est. speed input: 9129.57 toks/s, output: 8.92 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [03:10<00:41,  8.43it/s, est. speed input: 9125.87 toks/s, output: 8.91 toks/s]
Processed prompts:  83%|████████▎ | 1706/2048 [03:11<00:40,  8.36it/s, est. speed input: 9122.23 toks/s, output: 8.91 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [03:12<00:40,  8.32it/s, est. speed input: 9118.60 toks/s, output: 8.90 toks/s]
Processed prompts:  84%|████████▍ | 1722/2048 [03:13<00:39,  8.28it/s, est. speed input: 9115.03 toks/s, output: 8.90 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [03:14<00:38,  8.26it/s, est. speed input: 9111.47 toks/s, output: 8.90 toks/s]
Processed prompts:  85%|████████▍ | 1738/2048 [03:15<00:37,  8.24it/s, est. speed input: 9107.93 toks/s, output: 8.89 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [03:16<00:36,  8.23it/s, est. speed input: 9104.46 toks/s, output: 8.89 toks/s]
Processed prompts:  86%|████████▌ | 1754/2048 [03:17<00:35,  8.23it/s, est. speed input: 9101.03 toks/s, output: 8.89 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [03:18<00:34,  8.22it/s, est. speed input: 9097.61 toks/s, output: 8.88 toks/s]
Processed prompts:  86%|████████▋ | 1770/2048 [03:19<00:33,  8.22it/s, est. speed input: 9094.28 toks/s, output: 8.88 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [03:20<00:32,  8.22it/s, est. speed input: 9090.95 toks/s, output: 8.88 toks/s]
Processed prompts:  87%|████████▋ | 1786/2048 [03:21<00:31,  8.22it/s, est. speed input: 9087.66 toks/s, output: 8.87 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [03:22<00:30,  8.21it/s, est. speed input: 9084.38 toks/s, output: 8.87 toks/s]
Processed prompts:  88%|████████▊ | 1802/2048 [03:23<00:29,  8.21it/s, est. speed input: 9081.12 toks/s, output: 8.87 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [03:24<00:28,  8.21it/s, est. speed input: 9077.89 toks/s, output: 8.87 toks/s]
Processed prompts:  89%|████████▉ | 1818/2048 [03:25<00:28,  8.21it/s, est. speed input: 9074.69 toks/s, output: 8.86 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [03:26<00:27,  8.21it/s, est. speed input: 9071.52 toks/s, output: 8.86 toks/s]
Processed prompts:  90%|████████▉ | 1834/2048 [03:27<00:26,  8.21it/s, est. speed input: 9068.43 toks/s, output: 8.86 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [03:28<00:25,  8.21it/s, est. speed input: 9065.27 toks/s, output: 8.85 toks/s]
Processed prompts:  90%|█████████ | 1850/2048 [03:29<00:24,  8.21it/s, est. speed input: 9062.21 toks/s, output: 8.85 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [03:30<00:23,  8.21it/s, est. speed input: 9059.21 toks/s, output: 8.85 toks/s]
Processed prompts:  91%|█████████ | 1866/2048 [03:30<00:22,  8.21it/s, est. speed input: 9056.21 toks/s, output: 8.84 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [03:31<00:21,  8.21it/s, est. speed input: 9053.20 toks/s, output: 8.84 toks/s]
Processed prompts:  92%|█████████▏| 1882/2048 [03:32<00:20,  8.21it/s, est. speed input: 9050.23 toks/s, output: 8.84 toks/s]
Processed prompts:  93%|█████████▎| 1898/2048 [03:33<00:12, 12.37it/s, est. speed input: 9104.53 toks/s, output: 8.89 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [03:34<00:12, 10.98it/s, est. speed input: 9101.33 toks/s, output: 8.89 toks/s]
Processed prompts:  93%|█████████▎| 1914/2048 [03:35<00:13, 10.09it/s, est. speed input: 9098.17 toks/s, output: 8.88 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [03:36<00:13,  9.49it/s, est. speed input: 9095.00 toks/s, output: 8.88 toks/s]
Processed prompts:  94%|█████████▍| 1930/2048 [03:37<00:12,  9.10it/s, est. speed input: 9091.90 toks/s, output: 8.88 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [03:38<00:12,  8.82it/s, est. speed input: 9088.82 toks/s, output: 8.88 toks/s]
Processed prompts:  95%|█████████▌| 1946/2048 [03:39<00:11,  8.63it/s, est. speed input: 9085.76 toks/s, output: 8.87 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [03:40<00:11,  8.50it/s, est. speed input: 9082.74 toks/s, output: 8.87 toks/s]
Processed prompts:  96%|█████████▌| 1962/2048 [03:41<00:10,  8.41it/s, est. speed input: 9079.72 toks/s, output: 8.87 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [03:42<00:09,  8.35it/s, est. speed input: 9076.73 toks/s, output: 8.86 toks/s]
Processed prompts:  97%|█████████▋| 1978/2048 [03:43<00:08,  8.30it/s, est. speed input: 9073.76 toks/s, output: 8.86 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [03:44<00:07,  8.28it/s, est. speed input: 9070.87 toks/s, output: 8.86 toks/s]
Processed prompts:  97%|█████████▋| 1994/2048 [03:45<00:06,  8.26it/s, est. speed input: 9067.98 toks/s, output: 8.86 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [03:46<00:05,  8.24it/s, est. speed input: 9065.13 toks/s, output: 8.85 toks/s]
Processed prompts:  98%|█████████▊| 2010/2048 [03:47<00:04,  8.23it/s, est. speed input: 9062.30 toks/s, output: 8.85 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [03:48<00:03,  8.23it/s, est. speed input: 9059.50 toks/s, output: 8.85 toks/s]
Processed prompts:  99%|█████████▉| 2026/2048 [03:49<00:02,  8.22it/s, est. speed input: 9056.73 toks/s, output: 8.84 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [03:50<00:01,  8.22it/s, est. speed input: 9053.97 toks/s, output: 8.84 toks/s]
Processed prompts: 100%|█████████▉| 2042/2048 [03:50<00:00,  8.53it/s, est. speed input: 9055.92 toks/s, output: 8.84 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [03:50<00:00,  8.53it/s, est. speed input: 9082.52 toks/s, output: 8.87 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [03:50<00:00,  8.87it/s, est. speed input: 9082.52 toks/s, output: 8.87 toks/s]
[rank0]:[W126 07:08:38.123275877 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 313.5s

测试结果:
  Requests/s:   8.22
  Tokens/s:     8423.69
  Total Reqs:   2048
  Elapsed:      249.20s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     8415.47

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:09:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:09:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=328393) WARNING 01-26 07:09:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=328393) WARNING 01-26 07:09:44 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=328393) ERROR 01-26 07:10:05 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 07:09:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:09:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:09:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:09:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:09:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:09:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:09:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:09:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:09:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:09:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:09:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:09:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:09:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:09:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:09:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:09:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:09:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=328393) [2026-01-26 07:09:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=328393) [2026-01-26 07:09:27] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=328393) [2026-01-26 07:09:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=328393) [2026-01-26 07:09:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=328393) [2026-01-26 07:09:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.05it/s]
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.02it/s]
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.43it/s]
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.24it/s]
(EngineCore_DP0 pid=328393) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]
(EngineCore_DP0 pid=328393) 
(EngineCore_DP0 pid=328393) [rank0]:W0126 07:09:55.974000 328393 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=328393) [rank0]:W0126 07:09:56.053000 328393 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=328393) [rank0]:W0126 07:09:57.174000 328393 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=328393) [rank0]:W0126 07:09:57.297000 328393 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=328393) Process EngineCore_DP0:
(EngineCore_DP0 pid=328393) Traceback (most recent call last):
(EngineCore_DP0 pid=328393)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=328393)     self.run()
(EngineCore_DP0 pid=328393)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=328393)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=328393)     raise e
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=328393)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=328393)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=328393)     super().__init__(
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=328393)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=328393)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=328393)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=328393)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=328393)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=328393)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=328393)     raise ValueError(
(EngineCore_DP0 pid=328393) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:10:06.313285786 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:11:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:11:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=330336) WARNING 01-26 07:11:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=330336) WARNING 01-26 07:11:43 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=330336) ERROR 01-26 07:18:42 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 07:11:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:11:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:11:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:11:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:11:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:11:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:11:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:11:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:11:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:11:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:11:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:11:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:11:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:11:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:11:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:11:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:11:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:26] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.07it/s]
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.01it/s]
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.43it/s]
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.26it/s]
(EngineCore_DP0 pid=330336) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=330336) 
(EngineCore_DP0 pid=330336) [rank0]:W0126 07:11:57.251000 330336 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=330336) [rank0]:W0126 07:11:57.329000 330336 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=330336) [2026-01-26 07:11:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [rank0]:W0126 07:11:58.661000 330336 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=330336) [rank0]:W0126 07:11:57.338000 330336 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:06] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:31] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:36] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:36] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:36] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:36] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:12:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:16] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:16] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:16] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:16] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:21] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:21] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:21] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:21] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:26] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:26] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:26] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:26] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:40] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:40] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:40] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:40] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:13:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:10] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:10] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:10] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:10] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:15] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:15] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:15] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:15] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:39] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:39] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:39] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:39] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:14:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:04] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:19] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:19] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:19] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:19] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:24] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:24] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:24] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:24] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:29] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:29] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:29] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:29] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:15:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:08] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:08] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:08] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:08] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:13] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:13] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:13] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:13] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:18] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:18] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:18] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:18] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:34] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:38] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:38] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:38] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:38] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:16:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:03] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:03] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:03] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:03] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:09] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:09] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:09] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:09] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:23] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:23] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:23] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:23] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:28] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:28] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:28] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:28] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:33] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:33] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:33] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:33] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:17:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:11] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:17] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:17] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:17] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:17] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=7168, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:27] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=27648, K=5120), falling back to default heuristic
(EngineCore_DP0 pid=330336) [2026-01-26 07:18:40] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=5120, K=13824), falling back to default heuristic
(EngineCore_DP0 pid=330336) Process EngineCore_DP0:
(EngineCore_DP0 pid=330336) Traceback (most recent call last):
(EngineCore_DP0 pid=330336)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=330336)     self.run()
(EngineCore_DP0 pid=330336)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=330336)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=330336)     raise e
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=330336)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=330336)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=330336)     super().__init__(
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=330336)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=330336)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=330336)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=330336)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=330336)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=330336)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=330336)     raise ValueError(
(EngineCore_DP0 pid=330336) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:18:43.870635637 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,9.1598,4698.9850,13.9741
1024,1024,1,128,128,8.2371,8442.9973,15.5395
2048,1024,2,256,128,8.3582,8567.1212,30.6287
4096,1024,4,512,128,8.2698,8476.5326,61.9121
8192,1024,8,1024,128,8.2441,8450.2082,124.2100
16384,1024,16,2048,128,8.2182,8423.6852,249.2021
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 6 成功, 2 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:18:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:18:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=337113) WARNING 01-26 07:19:05 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=337113) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=337113) WARNING 01-26 07:19:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.20 requests/s, 4717.39 total tokens/s, 9.20 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:18:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:18:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:18:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:18:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:18:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:18:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:18:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:18:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:18:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:19:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:19:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:19:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:19:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:19:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:19:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:19:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:19:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:19:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.80s/it]
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:06<00:06,  3.01s/it]
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:07<00:02,  2.19s/it]
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:11<00:00,  2.75s/it]
(EngineCore_DP0 pid=337113) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:11<00:00,  2.77s/it]
(EngineCore_DP0 pid=337113) 
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=337113) [2026-01-26 07:19:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=337113) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=337113) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  33%|███▎      | 42/128 [00:00<00:00, 411.90it/s]
Adding requests:  69%|██████▉   | 88/128 [00:00<00:00, 439.76it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 445.23it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:01,  2.05it/s, est. speed input: 1050.77 toks/s, output: 2.05 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:33,  3.79it/s, est. speed input: 1723.35 toks/s, output: 3.37 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:23,  5.22it/s, est. speed input: 2193.89 toks/s, output: 4.28 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:19,  6.36it/s, est. speed input: 2544.15 toks/s, output: 4.97 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:16,  7.28it/s, est. speed input: 2823.25 toks/s, output: 5.51 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:01<00:14,  8.44it/s, est. speed input: 3236.91 toks/s, output: 6.32 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:13,  9.01it/s, est. speed input: 3521.04 toks/s, output: 6.88 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:12,  9.19it/s, est. speed input: 3631.44 toks/s, output: 7.09 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:12,  9.35it/s, est. speed input: 3726.39 toks/s, output: 7.28 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:11,  9.59it/s, est. speed input: 3887.32 toks/s, output: 7.59 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:11,  9.65it/s, est. speed input: 3952.14 toks/s, output: 7.72 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.72it/s, est. speed input: 4012.08 toks/s, output: 7.84 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:02<00:11,  9.79it/s, est. speed input: 4112.12 toks/s, output: 8.03 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:02<00:11,  9.77it/s, est. speed input: 4152.42 toks/s, output: 8.11 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:11,  9.68it/s, est. speed input: 4182.30 toks/s, output: 8.17 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:02<00:11,  9.63it/s, est. speed input: 4212.16 toks/s, output: 8.23 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:11,  9.65it/s, est. speed input: 4242.87 toks/s, output: 8.29 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:02<00:11,  9.63it/s, est. speed input: 4269.25 toks/s, output: 8.34 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.60it/s, est. speed input: 4292.06 toks/s, output: 8.38 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:10,  9.53it/s, est. speed input: 4311.09 toks/s, output: 8.42 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10,  9.52it/s, est. speed input: 4330.74 toks/s, output: 8.46 toks/s]
Processed prompts:  20%|██        | 26/128 [00:03<00:10,  9.54it/s, est. speed input: 4350.29 toks/s, output: 8.50 toks/s]
Processed prompts:  21%|██        | 27/128 [00:03<00:10,  9.54it/s, est. speed input: 4367.98 toks/s, output: 8.53 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:03<00:10,  9.47it/s, est. speed input: 4381.05 toks/s, output: 8.56 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:10,  9.47it/s, est. speed input: 4395.91 toks/s, output: 8.59 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:10,  9.48it/s, est. speed input: 4410.19 toks/s, output: 8.61 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:10,  9.52it/s, est. speed input: 4424.69 toks/s, output: 8.64 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:10,  9.48it/s, est. speed input: 4435.86 toks/s, output: 8.66 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.53it/s, est. speed input: 4449.53 toks/s, output: 8.69 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.58it/s, est. speed input: 4463.43 toks/s, output: 8.72 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:04<00:09,  9.54it/s, est. speed input: 4473.31 toks/s, output: 8.74 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:04<00:09,  9.57it/s, est. speed input: 4484.96 toks/s, output: 8.76 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:04<00:09,  9.59it/s, est. speed input: 4495.93 toks/s, output: 8.78 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:09,  9.60it/s, est. speed input: 4506.22 toks/s, output: 8.80 toks/s]
Processed prompts:  30%|███       | 39/128 [00:04<00:09,  9.59it/s, est. speed input: 4515.53 toks/s, output: 8.82 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:09,  9.62it/s, est. speed input: 4525.61 toks/s, output: 8.84 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:09,  9.63it/s, est. speed input: 4535.02 toks/s, output: 8.86 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:04<00:08,  9.63it/s, est. speed input: 4543.69 toks/s, output: 8.87 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:04<00:08,  9.62it/s, est. speed input: 4551.72 toks/s, output: 8.89 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:08,  9.62it/s, est. speed input: 4559.49 toks/s, output: 8.91 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:05<00:08,  9.61it/s, est. speed input: 4566.61 toks/s, output: 8.92 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:05<00:08,  9.64it/s, est. speed input: 4574.90 toks/s, output: 8.94 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:05<00:08,  9.67it/s, est. speed input: 4582.79 toks/s, output: 8.95 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:05<00:08,  9.66it/s, est. speed input: 4589.66 toks/s, output: 8.96 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:05<00:08,  9.63it/s, est. speed input: 4595.39 toks/s, output: 8.98 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:05<00:08,  9.62it/s, est. speed input: 4601.57 toks/s, output: 8.99 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:05<00:07,  9.66it/s, est. speed input: 4608.63 toks/s, output: 9.00 toks/s]
Processed prompts:  41%|████      | 52/128 [00:05<00:07,  9.67it/s, est. speed input: 4614.86 toks/s, output: 9.01 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:05<00:07,  9.59it/s, est. speed input: 4618.47 toks/s, output: 9.02 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:05<00:07,  9.57it/s, est. speed input: 4623.00 toks/s, output: 9.03 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:06<00:07,  9.58it/s, est. speed input: 4627.99 toks/s, output: 9.04 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:06<00:07,  9.60it/s, est. speed input: 4633.14 toks/s, output: 9.05 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:06<00:07,  9.60it/s, est. speed input: 4638.02 toks/s, output: 9.06 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:06<00:07,  9.60it/s, est. speed input: 4642.35 toks/s, output: 9.07 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:06<00:07,  9.58it/s, est. speed input: 4646.25 toks/s, output: 9.07 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:06<00:07,  9.58it/s, est. speed input: 4650.27 toks/s, output: 9.08 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:06<00:06,  9.59it/s, est. speed input: 4654.55 toks/s, output: 9.09 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:06<00:06,  9.59it/s, est. speed input: 4658.49 toks/s, output: 9.10 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:06<00:06,  9.59it/s, est. speed input: 4662.33 toks/s, output: 9.11 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:07<00:06,  9.60it/s, est. speed input: 4666.29 toks/s, output: 9.11 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:07<00:06,  9.69it/s, est. speed input: 4672.02 toks/s, output: 9.12 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:07<00:06,  9.70it/s, est. speed input: 4676.43 toks/s, output: 9.13 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:07<00:06,  9.73it/s, est. speed input: 4681.10 toks/s, output: 9.14 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:07<00:06,  9.73it/s, est. speed input: 4685.29 toks/s, output: 9.15 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:07<00:06,  9.69it/s, est. speed input: 4688.36 toks/s, output: 9.16 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:07<00:05,  9.67it/s, est. speed input: 4691.67 toks/s, output: 9.16 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:07<00:05,  9.68it/s, est. speed input: 4695.44 toks/s, output: 9.17 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:07<00:05,  9.69it/s, est. speed input: 4698.92 toks/s, output: 9.18 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:07<00:05,  9.67it/s, est. speed input: 4701.89 toks/s, output: 9.18 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:08<00:05,  9.66it/s, est. speed input: 4704.97 toks/s, output: 9.19 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:08<00:05,  9.68it/s, est. speed input: 4708.42 toks/s, output: 9.20 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:08<00:05,  9.70it/s, est. speed input: 4711.93 toks/s, output: 9.20 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:08<00:05,  9.71it/s, est. speed input: 4715.25 toks/s, output: 9.21 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:08<00:05,  9.66it/s, est. speed input: 4717.42 toks/s, output: 9.21 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:08<00:05,  9.63it/s, est. speed input: 4719.53 toks/s, output: 9.22 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:08<00:04,  9.61it/s, est. speed input: 4721.67 toks/s, output: 9.22 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:08<00:04,  9.60it/s, est. speed input: 4723.82 toks/s, output: 9.23 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:08<00:04,  9.68it/s, est. speed input: 4727.53 toks/s, output: 9.23 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:08<00:04,  9.73it/s, est. speed input: 4731.19 toks/s, output: 9.24 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:09<00:04,  9.75it/s, est. speed input: 4734.31 toks/s, output: 9.25 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:09<00:04,  9.80it/s, est. speed input: 4738.13 toks/s, output: 9.25 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:09<00:04,  9.81it/s, est. speed input: 4741.37 toks/s, output: 9.26 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:09<00:04,  9.85it/s, est. speed input: 4745.04 toks/s, output: 9.27 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:09<00:04,  9.89it/s, est. speed input: 4748.98 toks/s, output: 9.28 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:09<00:03,  9.90it/s, est. speed input: 4752.41 toks/s, output: 9.28 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:09<00:03,  9.87it/s, est. speed input: 4755.27 toks/s, output: 9.29 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:09<00:03,  9.86it/s, est. speed input: 4758.09 toks/s, output: 9.29 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:09<00:03,  9.77it/s, est. speed input: 4759.68 toks/s, output: 9.30 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:10<00:03,  9.69it/s, est. speed input: 4760.78 toks/s, output: 9.30 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:10<00:03,  9.64it/s, est. speed input: 4762.04 toks/s, output: 9.30 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:10<00:03,  9.59it/s, est. speed input: 4762.96 toks/s, output: 9.30 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:10<00:03,  9.60it/s, est. speed input: 4764.56 toks/s, output: 9.31 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:10<00:03,  9.57it/s, est. speed input: 4765.53 toks/s, output: 9.31 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:10<00:03,  9.56it/s, est. speed input: 4766.79 toks/s, output: 9.31 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:10<00:03,  9.59it/s, est. speed input: 4768.50 toks/s, output: 9.31 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:10<00:02,  9.59it/s, est. speed input: 4769.90 toks/s, output: 9.32 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:10<00:02,  9.58it/s, est. speed input: 4771.11 toks/s, output: 9.32 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:10<00:02,  9.64it/s, est. speed input: 4773.34 toks/s, output: 9.32 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:11<00:02,  9.67it/s, est. speed input: 4775.34 toks/s, output: 9.33 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:11<00:02,  9.69it/s, est. speed input: 4777.18 toks/s, output: 9.33 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:11<00:02,  9.68it/s, est. speed input: 4778.72 toks/s, output: 9.33 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:11<00:02,  9.68it/s, est. speed input: 4780.37 toks/s, output: 9.34 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:11<00:02,  9.57it/s, est. speed input: 4780.28 toks/s, output: 9.34 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:11<00:02,  9.60it/s, est. speed input: 4781.89 toks/s, output: 9.34 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:11<00:01,  9.64it/s, est. speed input: 4783.59 toks/s, output: 9.34 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:11<00:01,  9.61it/s, est. speed input: 4784.54 toks/s, output: 9.34 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:11<00:01,  9.62it/s, est. speed input: 4785.84 toks/s, output: 9.35 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:11<00:01,  9.65it/s, est. speed input: 4787.51 toks/s, output: 9.35 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:12<00:01,  9.59it/s, est. speed input: 4787.97 toks/s, output: 9.35 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:12<00:01,  9.60it/s, est. speed input: 4789.19 toks/s, output: 9.35 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:12<00:01,  9.63it/s, est. speed input: 4790.61 toks/s, output: 9.36 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:12<00:01,  9.63it/s, est. speed input: 4791.75 toks/s, output: 9.36 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:12<00:01,  9.63it/s, est. speed input: 4793.01 toks/s, output: 9.36 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:12<00:01,  9.62it/s, est. speed input: 4794.00 toks/s, output: 9.36 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:12<00:00,  9.61it/s, est. speed input: 4794.92 toks/s, output: 9.37 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:12<00:00,  9.61it/s, est. speed input: 4795.92 toks/s, output: 9.37 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:12<00:00,  9.60it/s, est. speed input: 4796.84 toks/s, output: 9.37 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:13<00:00,  9.69it/s, est. speed input: 4798.89 toks/s, output: 9.37 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:13<00:00,  9.75it/s, est. speed input: 4800.97 toks/s, output: 9.38 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:13<00:00,  9.77it/s, est. speed input: 4802.76 toks/s, output: 9.38 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:13<00:00,  9.78it/s, est. speed input: 4804.41 toks/s, output: 9.38 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:13<00:00,  9.73it/s, est. speed input: 4805.28 toks/s, output: 9.39 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:13<00:00,  9.74it/s, est. speed input: 4806.74 toks/s, output: 9.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.74it/s, est. speed input: 4808.11 toks/s, output: 9.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.74it/s, est. speed input: 4808.11 toks/s, output: 9.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.39it/s, est. speed input: 4808.11 toks/s, output: 9.39 toks/s]
[rank0]:[W126 07:20:11.996603128 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 85.7s

测试结果:
  Requests/s:   9.20
  Tokens/s:     4717.39
  Total Reqs:   128
  Elapsed:      13.92s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     4708.20

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:20:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:20:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=338656) WARNING 01-26 07:20:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=338656) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=338656) WARNING 01-26 07:20:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.66 requests/s, 9899.32 total tokens/s, 9.66 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:20:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:20:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:20:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:20:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:20:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:20:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:20:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:20:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:20:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:20:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:20:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:20:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:20:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:20:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:31] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:05,  1.98s/it]
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.53s/it]
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.10s/it]
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
(EngineCore_DP0 pid=338656) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.21s/it]
(EngineCore_DP0 pid=338656) 
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=338656) [2026-01-26 07:20:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=338656) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.88it/s]
(EngineCore_DP0 pid=338656) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 23/128 [00:00<00:00, 229.21it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 235.25it/s]
Adding requests:  58%|█████▊    | 74/128 [00:00<00:00, 246.26it/s]
Adding requests:  78%|███████▊  | 100/128 [00:00<00:00, 249.01it/s]
Adding requests:  98%|█████████▊| 125/128 [00:00<00:00, 241.60it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 239.83it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:05, 20.67it/s, est. speed input: 21169.02 toks/s, output: 20.67 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 13.08it/s, est. speed input: 14298.56 toks/s, output: 13.96 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:10, 11.80it/s, est. speed input: 13083.19 toks/s, output: 12.78 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:10, 11.10it/s, est. speed input: 12417.14 toks/s, output: 12.13 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:10, 10.67it/s, est. speed input: 11984.67 toks/s, output: 11.70 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:10, 10.39it/s, est. speed input: 11687.19 toks/s, output: 11.41 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:10, 10.23it/s, est. speed input: 11478.77 toks/s, output: 11.21 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:10, 10.10it/s, est. speed input: 11308.44 toks/s, output: 11.04 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:10, 10.04it/s, est. speed input: 11184.80 toks/s, output: 10.92 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.96it/s, est. speed input: 11073.28 toks/s, output: 10.81 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:10,  9.95it/s, est. speed input: 11031.21 toks/s, output: 10.77 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10,  9.95it/s, est. speed input: 10994.70 toks/s, output: 10.74 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10,  9.96it/s, est. speed input: 10963.00 toks/s, output: 10.71 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:10,  9.91it/s, est. speed input: 10924.24 toks/s, output: 10.67 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:02, 40.47it/s, est. speed input: 16269.47 toks/s, output: 15.89 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:03, 23.52it/s, est. speed input: 15465.09 toks/s, output: 15.10 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:04, 18.40it/s, est. speed input: 14981.15 toks/s, output: 14.63 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.51it/s, est. speed input: 14597.70 toks/s, output: 14.26 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:05, 14.12it/s, est. speed input: 14368.73 toks/s, output: 14.03 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:04<00:05, 13.03it/s, est. speed input: 14164.77 toks/s, output: 13.83 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:04<00:05, 12.19it/s, est. speed input: 13979.91 toks/s, output: 13.65 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:05, 11.61it/s, est. speed input: 13819.82 toks/s, output: 13.50 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:05, 11.15it/s, est. speed input: 13668.54 toks/s, output: 13.35 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:05, 10.78it/s, est. speed input: 13522.16 toks/s, output: 13.21 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:05<00:05, 10.56it/s, est. speed input: 13395.88 toks/s, output: 13.08 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:05<00:05, 10.34it/s, est. speed input: 13267.56 toks/s, output: 12.96 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:05<00:05, 10.21it/s, est. speed input: 13153.82 toks/s, output: 12.85 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:05<00:05, 10.13it/s, est. speed input: 13049.03 toks/s, output: 12.74 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:05<00:05, 10.06it/s, est. speed input: 12949.48 toks/s, output: 12.65 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:06<00:05, 10.02it/s, est. speed input: 12857.93 toks/s, output: 12.56 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:06<00:04,  9.97it/s, est. speed input: 12770.02 toks/s, output: 12.47 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:06<00:04,  9.96it/s, est. speed input: 12728.66 toks/s, output: 12.43 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:06<00:04,  9.96it/s, est. speed input: 12689.27 toks/s, output: 12.39 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:06<00:04,  9.95it/s, est. speed input: 12651.23 toks/s, output: 12.35 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:06<00:04,  9.94it/s, est. speed input: 12613.53 toks/s, output: 12.32 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:06<00:04,  9.80it/s, est. speed input: 12567.65 toks/s, output: 12.27 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:06<00:04,  9.82it/s, est. speed input: 12532.03 toks/s, output: 12.24 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:07<00:04,  9.83it/s, est. speed input: 12496.97 toks/s, output: 12.20 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:07<00:04,  9.91it/s, est. speed input: 12434.83 toks/s, output: 12.14 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:07<00:03,  9.92it/s, est. speed input: 12404.20 toks/s, output: 12.11 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:07<00:03,  9.95it/s, est. speed input: 12346.76 toks/s, output: 12.06 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:07<00:03,  9.99it/s, est. speed input: 12294.36 toks/s, output: 12.01 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:07<00:03,  9.97it/s, est. speed input: 12266.65 toks/s, output: 11.98 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:07<00:03,  9.94it/s, est. speed input: 12238.37 toks/s, output: 11.95 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:08<00:03,  9.91it/s, est. speed input: 12210.57 toks/s, output: 11.92 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:08<00:03,  9.93it/s, est. speed input: 12186.30 toks/s, output: 11.90 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:08<00:03,  9.89it/s, est. speed input: 12159.67 toks/s, output: 11.87 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:08<00:02,  9.89it/s, est. speed input: 12134.83 toks/s, output: 11.85 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:08<00:02,  9.90it/s, est. speed input: 12111.24 toks/s, output: 11.83 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:08<00:02,  9.90it/s, est. speed input: 12087.97 toks/s, output: 11.80 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:08<00:02,  9.91it/s, est. speed input: 12065.95 toks/s, output: 11.78 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:08<00:02,  9.92it/s, est. speed input: 12044.16 toks/s, output: 11.76 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:08<00:02,  9.90it/s, est. speed input: 12021.70 toks/s, output: 11.74 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:08<00:02,  9.87it/s, est. speed input: 11999.34 toks/s, output: 11.72 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:09<00:02,  9.87it/s, est. speed input: 11977.98 toks/s, output: 11.70 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:09<00:02,  9.85it/s, est. speed input: 11956.59 toks/s, output: 11.68 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:09<00:02,  9.83it/s, est. speed input: 11935.13 toks/s, output: 11.66 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:09<00:01,  9.81it/s, est. speed input: 11913.73 toks/s, output: 11.63 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:09<00:01,  9.83it/s, est. speed input: 11894.41 toks/s, output: 11.62 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:09<00:01,  9.83it/s, est. speed input: 11874.93 toks/s, output: 11.60 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:09<00:01,  9.85it/s, est. speed input: 11857.06 toks/s, output: 11.58 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:09<00:01,  9.87it/s, est. speed input: 11839.47 toks/s, output: 11.56 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:09<00:01,  9.89it/s, est. speed input: 11822.39 toks/s, output: 11.55 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:09<00:01,  9.92it/s, est. speed input: 11806.26 toks/s, output: 11.53 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:10<00:01,  9.98it/s, est. speed input: 11777.02 toks/s, output: 11.50 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:10<00:00,  9.98it/s, est. speed input: 11747.05 toks/s, output: 11.47 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:10<00:00,  9.97it/s, est. speed input: 11731.93 toks/s, output: 11.46 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:10<00:00,  9.96it/s, est. speed input: 11716.78 toks/s, output: 11.44 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:10<00:00,  9.92it/s, est. speed input: 11700.67 toks/s, output: 11.43 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:10<00:00,  9.93it/s, est. speed input: 11686.90 toks/s, output: 11.41 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:10<00:00,  9.91it/s, est. speed input: 11657.73 toks/s, output: 11.38 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:11<00:00,  9.90it/s, est. speed input: 11643.86 toks/s, output: 11.37 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00,  9.90it/s, est. speed input: 11630.32 toks/s, output: 11.36 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.90it/s, est. speed input: 11618.75 toks/s, output: 11.35 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 11.35it/s, est. speed input: 11618.75 toks/s, output: 11.35 toks/s]
[rank0]:[W126 07:21:26.852486689 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 75.7s

测试结果:
  Requests/s:   9.66
  Tokens/s:     9899.32
  Total Reqs:   128
  Elapsed:      13.25s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     9889.66

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:21:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:21:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=339992) WARNING 01-26 07:21:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=339992) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=339992) WARNING 01-26 07:22:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 12.99 requests/s, 13309.89 total tokens/s, 12.99 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 07:21:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:21:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:21:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:21:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:21:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:21:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:21:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:21:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:21:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.00s/it]
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.03s/it]
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.21it/s]
(EngineCore_DP0 pid=339992) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.17it/s]
(EngineCore_DP0 pid=339992) 
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=339992) [2026-01-26 07:21:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=339992) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  5.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  5.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.65it/s]
(EngineCore_DP0 pid=339992) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  2.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 23/256 [00:00<00:01, 227.25it/s]
Adding requests:  19%|█▉        | 49/256 [00:00<00:00, 243.26it/s]
Adding requests:  30%|██▉       | 76/256 [00:00<00:00, 254.35it/s]
Adding requests:  40%|███▉      | 102/256 [00:00<00:00, 239.73it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 241.95it/s]
Adding requests:  59%|█████▉    | 152/256 [00:00<00:00, 243.53it/s]
Adding requests:  70%|██████▉   | 178/256 [00:00<00:00, 248.19it/s]
Adding requests:  80%|███████▉  | 204/256 [00:00<00:00, 250.28it/s]
Adding requests:  90%|████████▉ | 230/256 [00:00<00:00, 252.37it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 247.54it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 246.45it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:00<00:04, 60.34it/s, est. speed input: 61800.76 toks/s, output: 60.35 toks/s]
Processed prompts:   7%|▋         | 19/256 [00:00<00:09, 25.94it/s, est. speed input: 29778.57 toks/s, output: 29.08 toks/s]
Processed prompts:   9%|▉         | 23/256 [00:00<00:11, 20.59it/s, est. speed input: 24643.04 toks/s, output: 24.07 toks/s]
Processed prompts:  10%|█         | 26/256 [00:01<00:13, 16.59it/s, est. speed input: 21173.89 toks/s, output: 20.68 toks/s]
Processed prompts:  11%|█         | 28/256 [00:01<00:14, 15.88it/s, est. speed input: 20356.18 toks/s, output: 19.88 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:01<00:14, 15.26it/s, est. speed input: 19693.45 toks/s, output: 19.23 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:01<00:15, 14.76it/s, est. speed input: 19154.36 toks/s, output: 18.71 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:01<00:15, 14.37it/s, est. speed input: 18701.91 toks/s, output: 18.26 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:02<00:15, 14.07it/s, est. speed input: 18317.73 toks/s, output: 17.89 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:02<00:15, 13.83it/s, est. speed input: 17984.57 toks/s, output: 17.56 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:02<00:15, 13.67it/s, est. speed input: 17696.74 toks/s, output: 17.28 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:02<00:15, 13.55it/s, est. speed input: 17443.82 toks/s, output: 17.03 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:02<00:15, 13.44it/s, est. speed input: 17215.67 toks/s, output: 16.81 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:02<00:15, 13.37it/s, est. speed input: 17014.08 toks/s, output: 16.62 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:02<00:15, 13.33it/s, est. speed input: 16834.29 toks/s, output: 16.44 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:03<00:15, 13.30it/s, est. speed input: 16672.21 toks/s, output: 16.28 toks/s]
Processed prompts:  20%|██        | 52/256 [00:03<00:15, 13.28it/s, est. speed input: 16525.61 toks/s, output: 16.14 toks/s]
Processed prompts:  21%|██        | 54/256 [00:03<00:15, 13.26it/s, est. speed input: 16391.68 toks/s, output: 16.01 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:03<00:15, 13.24it/s, est. speed input: 16266.77 toks/s, output: 15.89 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:03<00:14, 13.22it/s, est. speed input: 16153.14 toks/s, output: 15.77 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:03<00:14, 13.23it/s, est. speed input: 16050.39 toks/s, output: 15.67 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:03<00:14, 13.23it/s, est. speed input: 15955.54 toks/s, output: 15.58 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:04<00:14, 13.22it/s, est. speed input: 15866.41 toks/s, output: 15.49 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:04<00:14, 13.23it/s, est. speed input: 15785.23 toks/s, output: 15.42 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:04<00:14, 13.23it/s, est. speed input: 15709.42 toks/s, output: 15.34 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:04<00:14, 13.24it/s, est. speed input: 15638.61 toks/s, output: 15.27 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:04<00:13, 13.22it/s, est. speed input: 15569.63 toks/s, output: 15.20 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:04<00:13, 13.21it/s, est. speed input: 15505.16 toks/s, output: 15.14 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:05<00:13, 13.21it/s, est. speed input: 15446.68 toks/s, output: 15.08 toks/s]
Processed prompts:  30%|███       | 78/256 [00:05<00:13, 13.21it/s, est. speed input: 15390.70 toks/s, output: 15.03 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:05<00:13, 13.20it/s, est. speed input: 15336.79 toks/s, output: 14.98 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:05<00:13, 13.21it/s, est. speed input: 15287.86 toks/s, output: 14.93 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:05<00:13, 13.21it/s, est. speed input: 15240.30 toks/s, output: 14.88 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:05<00:12, 13.19it/s, est. speed input: 15193.59 toks/s, output: 14.84 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:05<00:12, 13.17it/s, est. speed input: 15148.75 toks/s, output: 14.79 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:06<00:12, 13.18it/s, est. speed input: 15107.96 toks/s, output: 14.75 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:06<00:12, 13.17it/s, est. speed input: 15068.22 toks/s, output: 14.71 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:06<00:12, 13.18it/s, est. speed input: 15031.11 toks/s, output: 14.68 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:06<00:12, 13.18it/s, est. speed input: 14995.44 toks/s, output: 14.64 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:06<00:11, 13.17it/s, est. speed input: 14961.16 toks/s, output: 14.61 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:06<00:11, 13.16it/s, est. speed input: 14927.75 toks/s, output: 14.58 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:07<00:11, 13.17it/s, est. speed input: 14896.70 toks/s, output: 14.55 toks/s]
Processed prompts:  41%|████      | 104/256 [00:07<00:11, 13.18it/s, est. speed input: 14867.86 toks/s, output: 14.52 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:07<00:11, 13.19it/s, est. speed input: 14840.22 toks/s, output: 14.49 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:07<00:11, 13.18it/s, est. speed input: 14812.37 toks/s, output: 14.47 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:07<00:11, 13.19it/s, est. speed input: 14786.62 toks/s, output: 14.44 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:07<00:10, 13.18it/s, est. speed input: 14761.01 toks/s, output: 14.42 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:07<00:10, 13.19it/s, est. speed input: 14737.38 toks/s, output: 14.39 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:08<00:10, 13.19it/s, est. speed input: 14714.51 toks/s, output: 14.37 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:08<00:10, 13.20it/s, est. speed input: 14692.92 toks/s, output: 14.35 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:08<00:10, 13.20it/s, est. speed input: 14671.45 toks/s, output: 14.33 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:08<00:10, 13.19it/s, est. speed input: 14650.18 toks/s, output: 14.31 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:08<00:10, 13.19it/s, est. speed input: 14630.25 toks/s, output: 14.29 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:08<00:09, 13.18it/s, est. speed input: 14610.08 toks/s, output: 14.27 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:08<00:09, 13.16it/s, est. speed input: 14590.45 toks/s, output: 14.25 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:09<00:09, 13.17it/s, est. speed input: 14572.26 toks/s, output: 14.23 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:09<00:09, 13.18it/s, est. speed input: 14555.02 toks/s, output: 14.21 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:09<00:09, 13.18it/s, est. speed input: 14537.95 toks/s, output: 14.20 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:09<00:09, 13.17it/s, est. speed input: 14520.72 toks/s, output: 14.18 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:09<00:08, 13.17it/s, est. speed input: 14504.84 toks/s, output: 14.16 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:09<00:08, 13.16it/s, est. speed input: 14488.63 toks/s, output: 14.15 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:10<00:08, 13.16it/s, est. speed input: 14473.06 toks/s, output: 14.13 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:10<00:08, 13.15it/s, est. speed input: 14457.77 toks/s, output: 14.12 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:10<00:08, 13.14it/s, est. speed input: 14442.91 toks/s, output: 14.10 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:10<00:08, 13.16it/s, est. speed input: 14429.28 toks/s, output: 14.09 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:10<00:08, 13.15it/s, est. speed input: 14415.32 toks/s, output: 14.08 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:10<00:07, 13.16it/s, est. speed input: 14402.69 toks/s, output: 14.07 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:10<00:07, 13.17it/s, est. speed input: 14389.93 toks/s, output: 14.05 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:11<00:07, 13.16it/s, est. speed input: 14377.24 toks/s, output: 14.04 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:11<00:07, 13.17it/s, est. speed input: 14365.72 toks/s, output: 14.03 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:11<00:07, 13.18it/s, est. speed input: 14354.41 toks/s, output: 14.02 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:11<00:07, 13.17it/s, est. speed input: 14342.76 toks/s, output: 14.01 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:11<00:06, 13.16it/s, est. speed input: 14330.96 toks/s, output: 14.00 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:11<00:06, 13.15it/s, est. speed input: 14319.76 toks/s, output: 13.98 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:12<00:06, 13.15it/s, est. speed input: 14309.03 toks/s, output: 13.97 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:12<00:06, 13.14it/s, est. speed input: 14297.83 toks/s, output: 13.96 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:12<00:06, 13.14it/s, est. speed input: 14287.43 toks/s, output: 13.95 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:12<00:06, 13.12it/s, est. speed input: 14276.32 toks/s, output: 13.94 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:12<00:06, 13.13it/s, est. speed input: 14266.72 toks/s, output: 13.93 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:12<00:05, 13.13it/s, est. speed input: 14256.89 toks/s, output: 13.92 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:12<00:05, 13.14it/s, est. speed input: 14247.67 toks/s, output: 13.91 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:13<00:05, 13.13it/s, est. speed input: 14238.23 toks/s, output: 13.90 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:13<00:05, 13.14it/s, est. speed input: 14229.57 toks/s, output: 13.90 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:13<00:05, 13.14it/s, est. speed input: 14220.71 toks/s, output: 13.89 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:13<00:05, 13.16it/s, est. speed input: 14212.74 toks/s, output: 13.88 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:13<00:05, 13.16it/s, est. speed input: 14204.81 toks/s, output: 13.87 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:13<00:04, 13.16it/s, est. speed input: 14196.66 toks/s, output: 13.86 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:14<00:04, 13.15it/s, est. speed input: 14188.57 toks/s, output: 13.86 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:14<00:04, 13.15it/s, est. speed input: 14180.70 toks/s, output: 13.85 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:14<00:04, 13.16it/s, est. speed input: 14173.48 toks/s, output: 13.84 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:14<00:04, 13.15it/s, est. speed input: 14165.88 toks/s, output: 13.83 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:14<00:04, 13.16it/s, est. speed input: 14158.99 toks/s, output: 13.83 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:14<00:03, 13.18it/s, est. speed input: 14152.47 toks/s, output: 13.82 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:14<00:03, 13.17it/s, est. speed input: 14145.48 toks/s, output: 13.81 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:15<00:03, 13.16it/s, est. speed input: 14138.55 toks/s, output: 13.81 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:15<00:03, 13.15it/s, est. speed input: 14131.40 toks/s, output: 13.80 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:15<00:03, 13.13it/s, est. speed input: 14124.29 toks/s, output: 13.79 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:15<00:03, 13.14it/s, est. speed input: 14117.91 toks/s, output: 13.79 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:15<00:03, 13.14it/s, est. speed input: 14111.62 toks/s, output: 13.78 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:15<00:02, 13.15it/s, est. speed input: 14105.51 toks/s, output: 13.77 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:15<00:02, 13.14it/s, est. speed input: 14099.00 toks/s, output: 13.77 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:16<00:02, 13.12it/s, est. speed input: 14092.40 toks/s, output: 13.76 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:16<00:02, 13.13it/s, est. speed input: 14086.47 toks/s, output: 13.76 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:16<00:02, 13.12it/s, est. speed input: 14080.23 toks/s, output: 13.75 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:16<00:02, 13.12it/s, est. speed input: 14074.42 toks/s, output: 13.74 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:16<00:01, 13.13it/s, est. speed input: 14068.90 toks/s, output: 13.74 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:16<00:01, 13.14it/s, est. speed input: 14063.52 toks/s, output: 13.73 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:17<00:01, 13.14it/s, est. speed input: 14058.27 toks/s, output: 13.73 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:17<00:01, 13.14it/s, est. speed input: 14052.92 toks/s, output: 13.72 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:17<00:01, 13.14it/s, est. speed input: 14047.66 toks/s, output: 13.72 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:17<00:01, 13.12it/s, est. speed input: 14041.75 toks/s, output: 13.71 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:17<00:01, 13.12it/s, est. speed input: 14036.73 toks/s, output: 13.71 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:17<00:00, 13.12it/s, est. speed input: 14031.62 toks/s, output: 13.70 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:17<00:00, 13.13it/s, est. speed input: 14026.74 toks/s, output: 13.70 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:18<00:00, 13.11it/s, est. speed input: 14021.19 toks/s, output: 13.69 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:18<00:00, 13.12it/s, est. speed input: 14016.56 toks/s, output: 13.69 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:18<00:00, 13.11it/s, est. speed input: 14011.37 toks/s, output: 13.68 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:18<00:00, 13.10it/s, est. speed input: 14006.41 toks/s, output: 13.68 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:18<00:00, 14.48it/s, est. speed input: 14037.87 toks/s, output: 13.71 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:18<00:00, 14.48it/s, est. speed input: 14037.87 toks/s, output: 13.71 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:18<00:00, 13.71it/s, est. speed input: 14037.87 toks/s, output: 13.71 toks/s]
[rank0]:[W126 07:22:49.261803591 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 81.1s

测试结果:
  Requests/s:   12.99
  Tokens/s:     13309.89
  Total Reqs:   256
  Elapsed:      19.71s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     13296.90

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:23:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:23:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=341408) WARNING 01-26 07:23:11 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=341408) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=341408) WARNING 01-26 07:23:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 13.10 requests/s, 13429.14 total tokens/s, 13.10 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 07:23:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:23:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:23:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:23:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:23:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:23:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:23:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:23:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:23:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:23:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:23:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:23:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:23:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:23:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:23:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:23:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:23:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.03it/s]
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:02,  1.00s/it]
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.39it/s]
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=341408) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.20it/s]
(EngineCore_DP0 pid=341408) 
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=341408) [2026-01-26 07:23:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=341408) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  5.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  5.02it/s]
(EngineCore_DP0 pid=341408) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  3.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.66it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 23/512 [00:00<00:02, 227.72it/s]
Adding requests:   9%|▉         | 48/512 [00:00<00:01, 239.00it/s]
Adding requests:  14%|█▍        | 74/512 [00:00<00:01, 246.11it/s]
Adding requests:  19%|█▉        | 99/512 [00:00<00:01, 235.68it/s]
Adding requests:  24%|██▍       | 124/512 [00:00<00:01, 239.58it/s]
Adding requests:  29%|██▉       | 149/512 [00:00<00:01, 242.95it/s]
Adding requests:  34%|███▍      | 175/512 [00:00<00:01, 245.63it/s]
Adding requests:  39%|███▉      | 202/512 [00:00<00:01, 251.31it/s]
Adding requests:  45%|████▍     | 229/512 [00:00<00:01, 254.44it/s]
Adding requests:  50%|████▉     | 255/512 [00:01<00:01, 249.87it/s]
Adding requests:  55%|█████▍    | 281/512 [00:01<00:00, 252.83it/s]
Adding requests:  60%|█████▉    | 307/512 [00:01<00:00, 254.13it/s]
Adding requests:  65%|██████▌   | 335/512 [00:01<00:00, 259.50it/s]
Adding requests:  71%|███████   | 362/512 [00:01<00:00, 259.72it/s]
Adding requests:  76%|███████▌  | 388/512 [00:01<00:00, 258.44it/s]
Adding requests:  81%|████████  | 415/512 [00:01<00:00, 260.76it/s]
Adding requests:  86%|████████▋ | 442/512 [00:01<00:00, 253.04it/s]
Adding requests:  92%|█████████▏| 470/512 [00:01<00:00, 257.32it/s]
Adding requests:  97%|█████████▋| 499/512 [00:01<00:00, 263.69it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 253.70it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 22/512 [00:00<00:02, 203.01it/s, est. speed input: 207927.40 toks/s, output: 203.02 toks/s]
Processed prompts:   8%|▊         | 43/512 [00:01<00:20, 23.01it/s, est. speed input: 27269.61 toks/s, output: 26.63 toks/s]   
Processed prompts:  10%|█         | 53/512 [00:02<00:22, 20.74it/s, est. speed input: 24472.23 toks/s, output: 23.90 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:02<00:26, 17.13it/s, est. speed input: 21418.31 toks/s, output: 20.92 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:03<00:27, 16.38it/s, est. speed input: 20660.87 toks/s, output: 20.18 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:03<00:29, 14.99it/s, est. speed input: 19737.95 toks/s, output: 19.28 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:03<00:30, 14.58it/s, est. speed input: 19240.74 toks/s, output: 18.79 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:04<00:30, 14.25it/s, est. speed input: 18816.02 toks/s, output: 18.37 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:04<00:31, 13.98it/s, est. speed input: 18449.83 toks/s, output: 18.02 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:04<00:31, 13.78it/s, est. speed input: 18130.69 toks/s, output: 17.71 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:04<00:31, 13.63it/s, est. speed input: 17851.05 toks/s, output: 17.43 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:05<00:31, 13.52it/s, est. speed input: 17603.06 toks/s, output: 17.19 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:05<00:31, 13.44it/s, est. speed input: 17382.23 toks/s, output: 16.97 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:05<00:30, 13.38it/s, est. speed input: 17183.85 toks/s, output: 16.78 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:06<00:30, 13.34it/s, est. speed input: 17005.55 toks/s, output: 16.61 toks/s]
Processed prompts:  21%|██        | 106/512 [00:06<00:30, 13.31it/s, est. speed input: 16844.53 toks/s, output: 16.45 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:06<00:30, 13.29it/s, est. speed input: 16696.61 toks/s, output: 16.31 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:07<00:29, 13.27it/s, est. speed input: 16561.22 toks/s, output: 16.17 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:07<00:29, 13.25it/s, est. speed input: 16437.05 toks/s, output: 16.05 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:07<00:29, 13.25it/s, est. speed input: 16322.80 toks/s, output: 15.94 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:07<00:29, 13.24it/s, est. speed input: 16216.99 toks/s, output: 15.84 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:08<00:28, 13.23it/s, est. speed input: 16118.98 toks/s, output: 15.74 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:08<00:28, 13.23it/s, est. speed input: 16027.59 toks/s, output: 15.65 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:08<00:28, 13.23it/s, est. speed input: 15942.40 toks/s, output: 15.57 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:09<00:27, 13.23it/s, est. speed input: 15863.28 toks/s, output: 15.49 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:09<00:27, 13.22it/s, est. speed input: 15788.92 toks/s, output: 15.42 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:09<00:27, 13.23it/s, est. speed input: 15719.68 toks/s, output: 15.35 toks/s]
Processed prompts:  30%|███       | 154/512 [00:10<00:27, 13.23it/s, est. speed input: 15654.71 toks/s, output: 15.29 toks/s]
Processed prompts:  31%|███       | 158/512 [00:10<00:26, 13.23it/s, est. speed input: 15593.32 toks/s, output: 15.23 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:10<00:26, 13.23it/s, est. speed input: 15535.04 toks/s, output: 15.17 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:10<00:26, 13.22it/s, est. speed input: 15479.95 toks/s, output: 15.12 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:11<00:25, 13.22it/s, est. speed input: 15427.74 toks/s, output: 15.07 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:11<00:25, 13.22it/s, est. speed input: 15377.91 toks/s, output: 15.02 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:11<00:25, 13.21it/s, est. speed input: 15330.76 toks/s, output: 14.97 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:12<00:24, 13.21it/s, est. speed input: 15286.03 toks/s, output: 14.93 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:12<00:24, 13.21it/s, est. speed input: 15242.93 toks/s, output: 14.89 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:12<00:24, 13.21it/s, est. speed input: 15202.47 toks/s, output: 14.85 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:13<00:24, 13.21it/s, est. speed input: 15163.79 toks/s, output: 14.81 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:13<00:23, 13.21it/s, est. speed input: 15127.04 toks/s, output: 14.77 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:13<00:23, 13.21it/s, est. speed input: 15091.64 toks/s, output: 14.74 toks/s]
Processed prompts:  40%|████      | 206/512 [00:14<00:23, 13.21it/s, est. speed input: 15057.51 toks/s, output: 14.70 toks/s]
Processed prompts:  41%|████      | 210/512 [00:14<00:22, 13.20it/s, est. speed input: 15024.41 toks/s, output: 14.67 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:14<00:22, 13.19it/s, est. speed input: 14992.69 toks/s, output: 14.64 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:14<00:22, 13.19it/s, est. speed input: 14962.52 toks/s, output: 14.61 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:15<00:21, 13.19it/s, est. speed input: 14933.28 toks/s, output: 14.58 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:15<00:21, 13.19it/s, est. speed input: 14905.30 toks/s, output: 14.56 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:15<00:21, 13.19it/s, est. speed input: 14878.33 toks/s, output: 14.53 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:16<00:21, 13.19it/s, est. speed input: 14852.61 toks/s, output: 14.50 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:16<00:20, 13.18it/s, est. speed input: 14827.36 toks/s, output: 14.48 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:16<00:20, 13.18it/s, est. speed input: 14802.97 toks/s, output: 14.46 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:17<00:20, 13.18it/s, est. speed input: 14779.55 toks/s, output: 14.43 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:17<00:19, 13.18it/s, est. speed input: 14757.24 toks/s, output: 14.41 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:17<00:19, 13.18it/s, est. speed input: 14735.28 toks/s, output: 14.39 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:17<00:19, 13.17it/s, est. speed input: 14714.03 toks/s, output: 14.37 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:18<00:18, 13.17it/s, est. speed input: 14693.42 toks/s, output: 14.35 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:18<00:18, 13.17it/s, est. speed input: 14673.56 toks/s, output: 14.33 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:18<00:18, 13.16it/s, est. speed input: 14654.15 toks/s, output: 14.31 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:19<00:18, 13.17it/s, est. speed input: 14635.77 toks/s, output: 14.29 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:19<00:17, 13.17it/s, est. speed input: 14618.05 toks/s, output: 14.28 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:19<00:17, 13.17it/s, est. speed input: 14600.45 toks/s, output: 14.26 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:20<00:17, 13.17it/s, est. speed input: 14583.43 toks/s, output: 14.24 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:20<00:16, 13.17it/s, est. speed input: 14567.04 toks/s, output: 14.23 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:20<00:16, 13.16it/s, est. speed input: 14550.92 toks/s, output: 14.21 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:20<00:16, 13.16it/s, est. speed input: 14535.02 toks/s, output: 14.19 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:21<00:15, 13.15it/s, est. speed input: 14519.49 toks/s, output: 14.18 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:21<00:15, 13.15it/s, est. speed input: 14504.61 toks/s, output: 14.16 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:21<00:15, 13.15it/s, est. speed input: 14490.15 toks/s, output: 14.15 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:22<00:15, 13.15it/s, est. speed input: 14476.14 toks/s, output: 14.14 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:22<00:14, 13.15it/s, est. speed input: 14462.30 toks/s, output: 14.12 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:22<00:14, 13.15it/s, est. speed input: 14448.99 toks/s, output: 14.11 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:23<00:14, 13.15it/s, est. speed input: 14436.15 toks/s, output: 14.10 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:23<00:13, 13.15it/s, est. speed input: 14423.52 toks/s, output: 14.09 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:23<00:13, 13.15it/s, est. speed input: 14411.11 toks/s, output: 14.07 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:24<00:13, 13.14it/s, est. speed input: 14398.95 toks/s, output: 14.06 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:24<00:12, 13.14it/s, est. speed input: 14387.06 toks/s, output: 14.05 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:24<00:12, 13.14it/s, est. speed input: 14375.50 toks/s, output: 14.04 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:24<00:12, 13.14it/s, est. speed input: 14364.27 toks/s, output: 14.03 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:25<00:12, 13.14it/s, est. speed input: 14353.28 toks/s, output: 14.02 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:25<00:11, 13.14it/s, est. speed input: 14342.68 toks/s, output: 14.01 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:25<00:11, 13.14it/s, est. speed input: 14332.34 toks/s, output: 14.00 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:26<00:11, 13.14it/s, est. speed input: 14322.15 toks/s, output: 13.99 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:26<00:10, 13.14it/s, est. speed input: 14312.08 toks/s, output: 13.98 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:26<00:10, 13.14it/s, est. speed input: 14302.22 toks/s, output: 13.97 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:27<00:10, 13.13it/s, est. speed input: 14292.40 toks/s, output: 13.96 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:27<00:09, 13.13it/s, est. speed input: 14283.06 toks/s, output: 13.95 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:27<00:09, 13.13it/s, est. speed input: 14273.80 toks/s, output: 13.94 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:27<00:09, 13.13it/s, est. speed input: 14264.77 toks/s, output: 13.93 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:28<00:08, 13.13it/s, est. speed input: 14255.83 toks/s, output: 13.92 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:28<00:08, 13.13it/s, est. speed input: 14247.32 toks/s, output: 13.91 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:28<00:08, 13.13it/s, est. speed input: 14238.86 toks/s, output: 13.91 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:29<00:08, 13.13it/s, est. speed input: 14230.42 toks/s, output: 13.90 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:29<00:02, 30.65it/s, est. speed input: 14879.95 toks/s, output: 14.53 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:29<00:03, 25.67it/s, est. speed input: 14865.84 toks/s, output: 14.52 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:30<00:03, 22.03it/s, est. speed input: 14851.57 toks/s, output: 14.50 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:30<00:03, 19.43it/s, est. speed input: 14837.65 toks/s, output: 14.49 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:30<00:03, 17.58it/s, est. speed input: 14824.26 toks/s, output: 14.48 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:31<00:03, 16.27it/s, est. speed input: 14811.10 toks/s, output: 14.46 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:31<00:03, 15.34it/s, est. speed input: 14797.99 toks/s, output: 14.45 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:31<00:03, 14.69it/s, est. speed input: 14785.30 toks/s, output: 14.44 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:32<00:03, 14.23it/s, est. speed input: 14772.62 toks/s, output: 14.43 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:32<00:03, 13.91it/s, est. speed input: 14760.39 toks/s, output: 14.41 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:32<00:03, 13.68it/s, est. speed input: 14748.19 toks/s, output: 14.40 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:32<00:02, 13.52it/s, est. speed input: 14736.26 toks/s, output: 14.39 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:33<00:02, 13.41it/s, est. speed input: 14724.69 toks/s, output: 14.38 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:33<00:02, 13.33it/s, est. speed input: 14713.28 toks/s, output: 14.37 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:33<00:01, 13.27it/s, est. speed input: 14701.95 toks/s, output: 14.36 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:34<00:01, 13.24it/s, est. speed input: 14690.99 toks/s, output: 14.35 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:34<00:01, 13.21it/s, est. speed input: 14680.06 toks/s, output: 14.34 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:34<00:01, 13.19it/s, est. speed input: 14669.35 toks/s, output: 14.33 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:35<00:00, 13.17it/s, est. speed input: 14658.73 toks/s, output: 14.32 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:35<00:00, 13.17it/s, est. speed input: 14648.56 toks/s, output: 14.31 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:35<00:00, 14.13it/s, est. speed input: 14666.97 toks/s, output: 14.32 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:35<00:00, 14.13it/s, est. speed input: 14724.39 toks/s, output: 14.38 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:35<00:00, 14.38it/s, est. speed input: 14724.39 toks/s, output: 14.38 toks/s]
[rank0]:[W126 07:24:30.548619022 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 102.8s

测试结果:
  Requests/s:   13.10
  Tokens/s:     13429.14
  Total Reqs:   512
  Elapsed:      39.08s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     13416.04

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:24:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:24:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=343189) WARNING 01-26 07:24:56 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=343189) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=343189) WARNING 01-26 07:25:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 12.98 requests/s, 13305.06 total tokens/s, 12.98 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 07:24:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:24:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:24:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:24:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:24:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:24:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:24:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:24:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:24:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:24:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:24:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:24:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:24:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:24:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:24:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:24:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:24:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=343189) [2026-01-26 07:24:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.00s/it]
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.03s/it]
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.36it/s]
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]
(EngineCore_DP0 pid=343189) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.18it/s]
(EngineCore_DP0 pid=343189) 
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=343189) [2026-01-26 07:25:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=343189) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:02,  1.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:01,  2.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:01<00:00,  2.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.20it/s]
(EngineCore_DP0 pid=343189) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.11it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  5.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  5.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 23/1024 [00:00<00:04, 227.26it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 239.38it/s]
Adding requests:   7%|▋         | 74/1024 [00:00<00:03, 246.85it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:03, 241.73it/s]
Adding requests:  12%|█▏        | 125/1024 [00:00<00:03, 246.20it/s]
Adding requests:  15%|█▍        | 150/1024 [00:00<00:03, 247.43it/s]
Adding requests:  17%|█▋        | 177/1024 [00:00<00:03, 253.31it/s]
Adding requests:  20%|██        | 205/1024 [00:00<00:03, 258.84it/s]
Adding requests:  23%|██▎       | 232/1024 [00:00<00:03, 260.18it/s]
Adding requests:  25%|██▌       | 259/1024 [00:01<00:03, 252.86it/s]
Adding requests:  28%|██▊       | 286/1024 [00:01<00:02, 255.97it/s]
Adding requests:  31%|███       | 314/1024 [00:01<00:02, 261.26it/s]
Adding requests:  33%|███▎      | 342/1024 [00:01<00:02, 263.41it/s]
Adding requests:  36%|███▌      | 370/1024 [00:01<00:02, 267.34it/s]
Adding requests:  39%|███▉      | 398/1024 [00:01<00:02, 269.90it/s]
Adding requests:  42%|████▏     | 426/1024 [00:01<00:02, 269.13it/s]
Adding requests:  44%|████▍     | 453/1024 [00:01<00:02, 266.16it/s]
Adding requests:  47%|████▋     | 480/1024 [00:01<00:02, 265.40it/s]
Adding requests:  50%|████▉     | 507/1024 [00:01<00:01, 264.33it/s]
Adding requests:  52%|█████▏    | 534/1024 [00:02<00:01, 265.21it/s]
Adding requests:  55%|█████▍    | 561/1024 [00:02<00:01, 263.45it/s]
Adding requests:  57%|█████▋    | 588/1024 [00:02<00:01, 254.28it/s]
Adding requests:  60%|█████▉    | 614/1024 [00:02<00:01, 254.63it/s]
Adding requests:  62%|██████▎   | 640/1024 [00:02<00:01, 252.36it/s]
Adding requests:  65%|██████▌   | 666/1024 [00:02<00:01, 250.08it/s]
Adding requests:  68%|██████▊   | 694/1024 [00:02<00:01, 256.35it/s]
Adding requests:  70%|███████   | 720/1024 [00:02<00:01, 252.02it/s]
Adding requests:  73%|███████▎  | 746/1024 [00:02<00:01, 247.59it/s]
Adding requests:  75%|███████▌  | 772/1024 [00:03<00:01, 248.97it/s]
Adding requests:  78%|███████▊  | 798/1024 [00:03<00:00, 249.99it/s]
Adding requests:  80%|████████  | 824/1024 [00:03<00:00, 252.74it/s]
Adding requests:  83%|████████▎ | 851/1024 [00:03<00:00, 257.61it/s]
Adding requests:  86%|████████▌ | 877/1024 [00:03<00:00, 257.52it/s]
Adding requests:  88%|████████▊ | 905/1024 [00:03<00:00, 263.92it/s]
Adding requests:  91%|█████████ | 932/1024 [00:03<00:00, 256.28it/s]
Adding requests:  94%|█████████▍| 960/1024 [00:03<00:00, 261.68it/s]
Adding requests:  96%|█████████▋| 987/1024 [00:03<00:00, 259.14it/s]
Adding requests:  99%|█████████▉| 1013/1024 [00:03<00:00, 255.44it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 256.45it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 50/1024 [00:00<00:11, 88.15it/s, est. speed input: 90265.79 toks/s, output: 88.15 toks/s]
Processed prompts:   6%|▌         | 59/1024 [00:01<00:22, 43.73it/s, est. speed input: 51362.07 toks/s, output: 50.16 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:01<00:33, 28.77it/s, est. speed input: 37847.14 toks/s, output: 36.96 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:02<00:42, 22.53it/s, est. speed input: 31632.25 toks/s, output: 30.89 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:03<00:49, 19.12it/s, est. speed input: 27940.26 toks/s, output: 27.29 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:03<00:54, 17.07it/s, est. speed input: 25492.64 toks/s, output: 24.89 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:04<00:58, 15.77it/s, est. speed input: 23751.61 toks/s, output: 23.19 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:04<01:01, 14.92it/s, est. speed input: 22448.51 toks/s, output: 21.92 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:05<01:03, 14.35it/s, est. speed input: 21435.48 toks/s, output: 20.93 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:06<01:04, 13.96it/s, est. speed input: 20626.37 toks/s, output: 20.14 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:06<01:05, 13.70it/s, est. speed input: 19964.99 toks/s, output: 19.50 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:07<01:05, 13.51it/s, est. speed input: 19412.84 toks/s, output: 18.96 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:07<01:05, 13.38it/s, est. speed input: 18945.74 toks/s, output: 18.50 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:08<01:05, 13.29it/s, est. speed input: 18546.12 toks/s, output: 18.11 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:09<01:05, 13.22it/s, est. speed input: 18198.75 toks/s, output: 17.77 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:09<01:04, 13.17it/s, est. speed input: 17894.82 toks/s, output: 17.48 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:10<01:04, 13.14it/s, est. speed input: 17626.76 toks/s, output: 17.21 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:10<01:03, 13.11it/s, est. speed input: 17388.59 toks/s, output: 16.98 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:11<01:03, 13.09it/s, est. speed input: 17174.62 toks/s, output: 16.77 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:12<01:02, 13.07it/s, est. speed input: 16981.49 toks/s, output: 16.58 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:12<01:02, 13.06it/s, est. speed input: 16807.10 toks/s, output: 16.41 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:13<00:34, 23.23it/s, est. speed input: 18150.33 toks/s, output: 17.72 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:13<00:39, 19.93it/s, est. speed input: 17935.85 toks/s, output: 17.52 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:14<00:43, 17.74it/s, est. speed input: 17739.35 toks/s, output: 17.32 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:15<00:47, 16.27it/s, est. speed input: 17559.06 toks/s, output: 17.15 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:15<00:49, 15.27it/s, est. speed input: 17392.49 toks/s, output: 16.98 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:16<00:51, 14.57it/s, est. speed input: 17238.34 toks/s, output: 16.83 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:16<00:52, 14.10it/s, est. speed input: 17095.65 toks/s, output: 16.69 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:17<00:53, 13.76it/s, est. speed input: 16962.41 toks/s, output: 16.56 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:18<00:53, 13.53it/s, est. speed input: 16838.22 toks/s, output: 16.44 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:18<00:53, 13.37it/s, est. speed input: 16722.03 toks/s, output: 16.33 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:19<00:53, 13.26it/s, est. speed input: 16613.22 toks/s, output: 16.22 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:19<00:53, 13.17it/s, est. speed input: 16510.79 toks/s, output: 16.12 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:20<00:52, 13.11it/s, est. speed input: 16414.39 toks/s, output: 16.03 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:21<00:52, 13.07it/s, est. speed input: 16323.47 toks/s, output: 15.94 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:21<00:51, 13.04it/s, est. speed input: 16237.52 toks/s, output: 15.86 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:22<00:51, 13.03it/s, est. speed input: 16156.82 toks/s, output: 15.78 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:23<00:50, 13.01it/s, est. speed input: 16080.20 toks/s, output: 15.70 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:23<00:50, 13.00it/s, est. speed input: 16007.70 toks/s, output: 15.63 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:24<00:49, 13.00it/s, est. speed input: 15938.78 toks/s, output: 15.57 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:24<00:49, 12.99it/s, est. speed input: 15873.26 toks/s, output: 15.50 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:25<00:48, 12.99it/s, est. speed input: 15811.07 toks/s, output: 15.44 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:26<00:47, 12.99it/s, est. speed input: 15751.81 toks/s, output: 15.38 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:26<00:47, 12.99it/s, est. speed input: 15695.39 toks/s, output: 15.33 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:27<00:46, 12.99it/s, est. speed input: 15641.64 toks/s, output: 15.28 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:27<00:46, 12.99it/s, est. speed input: 15590.39 toks/s, output: 15.22 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:28<00:45, 13.00it/s, est. speed input: 15541.37 toks/s, output: 15.18 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:29<00:44, 13.00it/s, est. speed input: 15494.31 toks/s, output: 15.13 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:29<00:44, 13.00it/s, est. speed input: 15449.52 toks/s, output: 15.09 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:30<00:43, 13.00it/s, est. speed input: 15406.44 toks/s, output: 15.05 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:31<00:42, 13.00it/s, est. speed input: 15365.00 toks/s, output: 15.00 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:31<00:42, 13.00it/s, est. speed input: 15325.32 toks/s, output: 14.97 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:32<00:41, 13.00it/s, est. speed input: 15287.00 toks/s, output: 14.93 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:32<00:41, 13.00it/s, est. speed input: 15250.11 toks/s, output: 14.89 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:33<00:40, 13.00it/s, est. speed input: 15214.68 toks/s, output: 14.86 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:34<00:39, 13.00it/s, est. speed input: 15180.42 toks/s, output: 14.82 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:34<00:39, 13.01it/s, est. speed input: 15147.51 toks/s, output: 14.79 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:35<00:38, 13.00it/s, est. speed input: 15115.60 toks/s, output: 14.76 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:35<00:37, 13.00it/s, est. speed input: 15084.69 toks/s, output: 14.73 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:36<00:37, 13.00it/s, est. speed input: 15054.84 toks/s, output: 14.70 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:37<00:36, 13.00it/s, est. speed input: 15026.11 toks/s, output: 14.67 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:37<00:36, 13.00it/s, est. speed input: 14998.20 toks/s, output: 14.65 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:38<00:35, 13.00it/s, est. speed input: 14971.13 toks/s, output: 14.62 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:39<00:34, 13.00it/s, est. speed input: 14944.86 toks/s, output: 14.59 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:39<00:34, 13.00it/s, est. speed input: 14919.39 toks/s, output: 14.57 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:40<00:33, 13.00it/s, est. speed input: 14894.90 toks/s, output: 14.55 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:40<00:33, 13.00it/s, est. speed input: 14870.99 toks/s, output: 14.52 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:41<00:32, 13.00it/s, est. speed input: 14847.77 toks/s, output: 14.50 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:42<00:31, 13.00it/s, est. speed input: 14825.38 toks/s, output: 14.48 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:42<00:31, 13.00it/s, est. speed input: 14803.51 toks/s, output: 14.46 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:43<00:30, 13.00it/s, est. speed input: 14782.29 toks/s, output: 14.44 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:43<00:30, 13.00it/s, est. speed input: 14761.73 toks/s, output: 14.42 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:44<00:15, 23.21it/s, est. speed input: 15181.60 toks/s, output: 14.83 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:44<00:17, 19.92it/s, est. speed input: 15156.39 toks/s, output: 14.80 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:45<00:19, 17.74it/s, est. speed input: 15131.87 toks/s, output: 14.78 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:46<00:21, 16.27it/s, est. speed input: 15107.95 toks/s, output: 14.75 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:46<00:21, 15.27it/s, est. speed input: 15084.63 toks/s, output: 14.73 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:47<00:22, 14.58it/s, est. speed input: 15061.99 toks/s, output: 14.71 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:48<00:22, 14.11it/s, est. speed input: 15039.90 toks/s, output: 14.69 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:48<00:22, 13.78it/s, est. speed input: 15018.32 toks/s, output: 14.67 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:49<00:22, 13.55it/s, est. speed input: 14997.27 toks/s, output: 14.65 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:49<00:21, 13.39it/s, est. speed input: 14976.87 toks/s, output: 14.63 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:50<00:21, 13.28it/s, est. speed input: 14957.01 toks/s, output: 14.61 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:51<00:21, 13.20it/s, est. speed input: 14937.46 toks/s, output: 14.59 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:51<00:20, 13.15it/s, est. speed input: 14918.30 toks/s, output: 14.57 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:52<00:19, 13.11it/s, est. speed input: 14899.62 toks/s, output: 14.55 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:52<00:19, 13.07it/s, est. speed input: 14881.00 toks/s, output: 14.53 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:53<00:18, 13.05it/s, est. speed input: 14862.87 toks/s, output: 14.51 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:54<00:18, 13.03it/s, est. speed input: 14845.04 toks/s, output: 14.50 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:54<00:17, 13.02it/s, est. speed input: 14827.73 toks/s, output: 14.48 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:55<00:17, 13.01it/s, est. speed input: 14810.79 toks/s, output: 14.46 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:56<00:16, 13.00it/s, est. speed input: 14794.24 toks/s, output: 14.45 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:56<00:15, 13.00it/s, est. speed input: 14778.01 toks/s, output: 14.43 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:57<00:15, 13.00it/s, est. speed input: 14762.15 toks/s, output: 14.42 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:57<00:14, 12.99it/s, est. speed input: 14746.59 toks/s, output: 14.40 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:58<00:14, 12.99it/s, est. speed input: 14731.44 toks/s, output: 14.39 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:59<00:13, 12.99it/s, est. speed input: 14716.52 toks/s, output: 14.37 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:59<00:12, 12.99it/s, est. speed input: 14701.94 toks/s, output: 14.36 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [01:00<00:12, 12.99it/s, est. speed input: 14687.64 toks/s, output: 14.34 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [01:00<00:11, 12.99it/s, est. speed input: 14673.54 toks/s, output: 14.33 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [01:01<00:10, 12.98it/s, est. speed input: 14659.66 toks/s, output: 14.32 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [01:02<00:10, 12.98it/s, est. speed input: 14646.03 toks/s, output: 14.30 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [01:02<00:09, 12.98it/s, est. speed input: 14632.72 toks/s, output: 14.29 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [01:03<00:09, 12.98it/s, est. speed input: 14619.65 toks/s, output: 14.28 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [01:04<00:08, 12.98it/s, est. speed input: 14606.84 toks/s, output: 14.26 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [01:04<00:07, 12.98it/s, est. speed input: 14594.25 toks/s, output: 14.25 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [01:05<00:07, 12.98it/s, est. speed input: 14581.88 toks/s, output: 14.24 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [01:05<00:06, 12.97it/s, est. speed input: 14569.70 toks/s, output: 14.23 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [01:06<00:06, 12.97it/s, est. speed input: 14557.78 toks/s, output: 14.22 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [01:07<00:05, 12.97it/s, est. speed input: 14546.07 toks/s, output: 14.21 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [01:07<00:04, 12.97it/s, est. speed input: 14534.52 toks/s, output: 14.19 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [01:08<00:04, 12.97it/s, est. speed input: 14523.25 toks/s, output: 14.18 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [01:09<00:03, 12.98it/s, est. speed input: 14512.39 toks/s, output: 14.17 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [01:09<00:02, 12.98it/s, est. speed input: 14501.72 toks/s, output: 14.16 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [01:10<00:02, 12.98it/s, est. speed input: 14491.18 toks/s, output: 14.15 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [01:10<00:01, 12.99it/s, est. speed input: 14480.84 toks/s, output: 14.14 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [01:11<00:01, 12.99it/s, est. speed input: 14470.76 toks/s, output: 14.13 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [01:12<00:00, 13.46it/s, est. speed input: 14475.26 toks/s, output: 14.14 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:12<00:00, 13.46it/s, est. speed input: 14560.51 toks/s, output: 14.22 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:12<00:00, 14.22it/s, est. speed input: 14560.51 toks/s, output: 14.22 toks/s]
[rank0]:[W126 07:26:56.926455146 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 145.6s

测试结果:
  Requests/s:   12.98
  Tokens/s:     13305.06
  Total Reqs:   1024
  Elapsed:      78.89s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     13292.08

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:27:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:27:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=345595) WARNING 01-26 07:27:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=345595) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=345595) WARNING 01-26 07:27:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 12.89 requests/s, 13209.26 total tokens/s, 12.89 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 07:27:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:27:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:27:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:27:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:27:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:27:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:27:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:27:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:27:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:27:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:27:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:27:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:27:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:27:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:27:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:27:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:27:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.02it/s]
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.00s/it]
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.39it/s]
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=345595) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.20it/s]
(EngineCore_DP0 pid=345595) 
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=345595) [2026-01-26 07:27:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=345595) [rank0]:W0126 07:28:01.496000 345595 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=345595) [rank0]:W0126 07:28:01.575000 345595 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=345595) [rank0]:W0126 07:28:01.454000 345595 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=345595) [rank0]:W0126 07:28:01.572000 345595 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=345595) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  4.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  4.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  3.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  2.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  3.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.56it/s]
(EngineCore_DP0 pid=345595) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  5.02it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  5.21it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  5.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  5.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  5.19it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/2048 [00:00<00:08, 234.83it/s]
Adding requests:   2%|▏         | 49/2048 [00:00<00:08, 242.62it/s]
Adding requests:   4%|▎         | 75/2048 [00:00<00:07, 250.28it/s]
Adding requests:   5%|▍         | 101/2048 [00:00<00:08, 241.43it/s]
Adding requests:   6%|▌         | 126/2048 [00:00<00:08, 227.50it/s]
Adding requests:   7%|▋         | 150/2048 [00:00<00:08, 229.20it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:07, 236.56it/s]
Adding requests:  10%|▉         | 204/2048 [00:00<00:07, 246.86it/s]
Adding requests:  11%|█▏        | 232/2048 [00:00<00:07, 253.13it/s]
Adding requests:  13%|█▎        | 258/2048 [00:01<00:07, 246.05it/s]
Adding requests:  14%|█▍        | 284/2048 [00:01<00:07, 247.88it/s]
Adding requests:  15%|█▌        | 311/2048 [00:01<00:06, 254.10it/s]
Adding requests:  17%|█▋        | 339/2048 [00:01<00:06, 260.04it/s]
Adding requests:  18%|█▊        | 366/2048 [00:01<00:06, 258.51it/s]
Adding requests:  19%|█▉        | 393/2048 [00:01<00:06, 261.56it/s]
Adding requests:  21%|██        | 421/2048 [00:01<00:06, 266.87it/s]
Adding requests:  22%|██▏       | 448/2048 [00:01<00:06, 259.49it/s]
Adding requests:  23%|██▎       | 476/2048 [00:01<00:05, 264.12it/s]
Adding requests:  25%|██▍       | 504/2048 [00:01<00:05, 266.45it/s]
Adding requests:  26%|██▌       | 534/2048 [00:02<00:05, 273.75it/s]
Adding requests:  27%|██▋       | 562/2048 [00:02<00:05, 268.44it/s]
Adding requests:  29%|██▉       | 589/2048 [00:02<00:05, 260.40it/s]
Adding requests:  30%|███       | 616/2048 [00:02<00:05, 255.91it/s]
Adding requests:  31%|███▏      | 642/2048 [00:02<00:05, 253.00it/s]
Adding requests:  33%|███▎      | 668/2048 [00:02<00:05, 248.95it/s]
Adding requests:  34%|███▍      | 695/2048 [00:02<00:05, 254.00it/s]
Adding requests:  35%|███▌      | 721/2048 [00:02<00:05, 251.71it/s]
Adding requests:  36%|███▋      | 747/2048 [00:02<00:05, 250.51it/s]
Adding requests:  38%|███▊      | 773/2048 [00:03<00:05, 246.41it/s]
Adding requests:  39%|███▉      | 799/2048 [00:03<00:05, 249.67it/s]
Adding requests:  40%|████      | 825/2048 [00:03<00:04, 251.72it/s]
Adding requests:  42%|████▏     | 853/2048 [00:03<00:04, 258.64it/s]
Adding requests:  43%|████▎     | 880/2048 [00:03<00:04, 259.77it/s]
Adding requests:  44%|████▍     | 907/2048 [00:03<00:04, 260.60it/s]
Adding requests:  46%|████▌     | 934/2048 [00:03<00:04, 255.53it/s]
Adding requests:  47%|████▋     | 961/2048 [00:03<00:04, 258.80it/s]
Adding requests:  48%|████▊     | 987/2048 [00:03<00:04, 258.55it/s]
Adding requests:  49%|████▉     | 1013/2048 [00:03<00:04, 254.33it/s]
Adding requests:  51%|█████     | 1040/2048 [00:04<00:03, 258.51it/s]
Adding requests:  52%|█████▏    | 1066/2048 [00:04<00:03, 255.62it/s]
Adding requests:  53%|█████▎    | 1092/2048 [00:04<00:03, 252.63it/s]
Adding requests:  55%|█████▍    | 1119/2048 [00:04<00:03, 256.39it/s]
Adding requests:  56%|█████▌    | 1147/2048 [00:04<00:03, 260.16it/s]
Adding requests:  57%|█████▋    | 1174/2048 [00:04<00:03, 258.53it/s]
Adding requests:  59%|█████▊    | 1200/2048 [00:04<00:03, 258.26it/s]
Adding requests:  60%|█████▉    | 1228/2048 [00:04<00:03, 264.10it/s]
Adding requests:  61%|██████▏   | 1255/2048 [00:04<00:03, 259.23it/s]
Adding requests:  63%|██████▎   | 1281/2048 [00:05<00:03, 254.92it/s]
Adding requests:  64%|██████▍   | 1307/2048 [00:05<00:02, 252.55it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:05<00:02, 251.20it/s]
Adding requests:  66%|██████▋   | 1361/2048 [00:05<00:02, 257.86it/s]
Adding requests:  68%|██████▊   | 1387/2048 [00:05<00:02, 255.81it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:05<00:02, 254.56it/s]
Adding requests:  70%|███████   | 1440/2048 [00:05<00:02, 256.42it/s]
Adding requests:  72%|███████▏  | 1466/2048 [00:05<00:02, 254.69it/s]
Adding requests:  73%|███████▎  | 1493/2048 [00:05<00:02, 258.63it/s]
Adding requests:  74%|███████▍  | 1519/2048 [00:05<00:02, 258.00it/s]
Adding requests:  75%|███████▌  | 1545/2048 [00:06<00:01, 255.87it/s]
Adding requests:  77%|███████▋  | 1571/2048 [00:06<00:01, 244.41it/s]
Adding requests:  78%|███████▊  | 1597/2048 [00:06<00:01, 247.35it/s]
Adding requests:  79%|███████▉  | 1622/2048 [00:06<00:01, 246.74it/s]
Adding requests:  80%|████████  | 1647/2048 [00:06<00:01, 245.71it/s]
Adding requests:  82%|████████▏ | 1673/2048 [00:06<00:01, 247.29it/s]
Adding requests:  83%|████████▎ | 1699/2048 [00:06<00:01, 250.82it/s]
Adding requests:  84%|████████▍ | 1727/2048 [00:06<00:01, 257.56it/s]
Adding requests:  86%|████████▌ | 1754/2048 [00:06<00:01, 259.88it/s]
Adding requests:  87%|████████▋ | 1782/2048 [00:06<00:01, 264.20it/s]
Adding requests:  88%|████████▊ | 1809/2048 [00:07<00:00, 262.62it/s]
Adding requests:  90%|████████▉ | 1836/2048 [00:07<00:00, 257.99it/s]
Adding requests:  91%|█████████ | 1863/2048 [00:07<00:00, 259.56it/s]
Adding requests:  92%|█████████▏| 1890/2048 [00:07<00:00, 261.70it/s]
Adding requests:  94%|█████████▎| 1918/2048 [00:07<00:00, 266.22it/s]
Adding requests:  95%|█████████▍| 1945/2048 [00:07<00:00, 257.05it/s]
Adding requests:  96%|█████████▌| 1971/2048 [00:07<00:00, 256.88it/s]
Adding requests:  98%|█████████▊| 1997/2048 [00:07<00:00, 256.19it/s]
Adding requests:  99%|█████████▉| 2023/2048 [00:07<00:00, 254.14it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 254.94it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:00<00:11, 178.63it/s, est. speed input: 182925.18 toks/s, output: 178.63 toks/s]
Processed prompts:   5%|▍         | 100/2048 [00:01<00:39, 48.90it/s, est. speed input: 60965.63 toks/s, output: 59.54 toks/s]  
Processed prompts:   6%|▌         | 114/2048 [00:02<01:06, 29.01it/s, est. speed input: 40221.91 toks/s, output: 39.28 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:04<01:27, 21.80it/s, est. speed input: 31929.52 toks/s, output: 31.18 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:05<01:42, 18.50it/s, est. speed input: 27723.86 toks/s, output: 27.07 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:06<01:53, 16.59it/s, est. speed input: 25067.30 toks/s, output: 24.48 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:07<02:01, 15.41it/s, est. speed input: 23239.89 toks/s, output: 22.70 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:09<02:06, 14.65it/s, est. speed input: 21904.20 toks/s, output: 21.39 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:10<02:09, 14.14it/s, est. speed input: 20885.60 toks/s, output: 20.40 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:11<01:35, 18.87it/s, est. speed input: 21907.80 toks/s, output: 21.39 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:12<01:45, 17.00it/s, est. speed input: 21067.25 toks/s, output: 20.57 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:13<01:52, 15.75it/s, est. speed input: 20376.19 toks/s, output: 19.90 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:14<01:57, 14.90it/s, est. speed input: 19798.08 toks/s, output: 19.33 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:16<02:01, 14.32it/s, est. speed input: 19307.10 toks/s, output: 18.85 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:17<02:04, 13.92it/s, est. speed input: 18883.89 toks/s, output: 18.44 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:18<02:05, 13.64it/s, est. speed input: 18516.25 toks/s, output: 18.08 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:19<02:06, 13.44it/s, est. speed input: 18193.52 toks/s, output: 17.77 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:21<02:06, 13.30it/s, est. speed input: 17907.37 toks/s, output: 17.49 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:22<02:05, 13.20it/s, est. speed input: 17652.62 toks/s, output: 17.24 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:23<02:05, 13.13it/s, est. speed input: 17425.04 toks/s, output: 17.02 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:24<02:04, 13.08it/s, est. speed input: 17219.51 toks/s, output: 16.82 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:26<02:03, 13.05it/s, est. speed input: 17033.34 toks/s, output: 16.63 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:27<02:02, 13.03it/s, est. speed input: 16864.42 toks/s, output: 16.47 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:28<02:01, 13.01it/s, est. speed input: 16710.02 toks/s, output: 16.32 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:29<02:00, 13.00it/s, est. speed input: 16568.76 toks/s, output: 16.18 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:31<01:59, 13.00it/s, est. speed input: 16438.45 toks/s, output: 16.05 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:32<01:58, 12.99it/s, est. speed input: 16318.59 toks/s, output: 15.94 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:33<01:56, 12.99it/s, est. speed input: 16207.41 toks/s, output: 15.83 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:34<01:55, 12.99it/s, est. speed input: 16104.42 toks/s, output: 15.73 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:35<01:54, 12.99it/s, est. speed input: 16008.23 toks/s, output: 15.63 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:37<01:53, 12.99it/s, est. speed input: 15918.60 toks/s, output: 15.55 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:38<01:51, 12.99it/s, est. speed input: 15834.75 toks/s, output: 15.46 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:39<01:50, 12.99it/s, est. speed input: 15756.06 toks/s, output: 15.39 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:40<01:49, 12.98it/s, est. speed input: 15681.40 toks/s, output: 15.31 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:42<01:48, 12.98it/s, est. speed input: 15611.24 toks/s, output: 15.25 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:43<01:17, 17.76it/s, est. speed input: 15998.89 toks/s, output: 15.62 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:44<01:23, 16.27it/s, est. speed input: 15923.21 toks/s, output: 15.55 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:45<01:27, 15.25it/s, est. speed input: 15851.53 toks/s, output: 15.48 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:46<01:31, 14.55it/s, est. speed input: 15783.74 toks/s, output: 15.41 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:48<01:33, 14.07it/s, est. speed input: 15719.36 toks/s, output: 15.35 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:49<01:34, 13.74it/s, est. speed input: 15658.13 toks/s, output: 15.29 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:50<01:34, 13.50it/s, est. speed input: 15599.94 toks/s, output: 15.23 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:51<01:34, 13.34it/s, est. speed input: 15544.42 toks/s, output: 15.18 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:53<01:34, 13.23it/s, est. speed input: 15491.60 toks/s, output: 15.13 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:54<01:33, 13.15it/s, est. speed input: 15441.29 toks/s, output: 15.08 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:55<01:32, 13.09it/s, est. speed input: 15393.12 toks/s, output: 15.03 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:56<01:31, 13.05it/s, est. speed input: 15346.98 toks/s, output: 14.99 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:57<01:30, 13.03it/s, est. speed input: 15302.74 toks/s, output: 14.94 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:59<01:29, 13.01it/s, est. speed input: 15260.39 toks/s, output: 14.90 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:00<01:28, 12.99it/s, est. speed input: 15219.66 toks/s, output: 14.86 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:01<01:27, 12.98it/s, est. speed input: 15180.60 toks/s, output: 14.82 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:02<01:26, 12.98it/s, est. speed input: 15143.23 toks/s, output: 14.79 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:04<01:24, 12.97it/s, est. speed input: 15107.23 toks/s, output: 14.75 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:05<01:23, 12.97it/s, est. speed input: 15072.64 toks/s, output: 14.72 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:06<01:22, 12.97it/s, est. speed input: 15039.26 toks/s, output: 14.69 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:07<01:21, 12.97it/s, est. speed input: 15007.11 toks/s, output: 14.66 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:09<01:20, 12.97it/s, est. speed input: 14976.17 toks/s, output: 14.63 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:10<01:18, 12.96it/s, est. speed input: 14946.17 toks/s, output: 14.60 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:11<01:17, 12.96it/s, est. speed input: 14917.30 toks/s, output: 14.57 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:12<01:16, 12.96it/s, est. speed input: 14889.41 toks/s, output: 14.54 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:13<00:54, 17.73it/s, est. speed input: 15125.54 toks/s, output: 14.77 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:15<00:57, 16.25it/s, est. speed input: 15095.10 toks/s, output: 14.74 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:16<01:00, 15.24it/s, est. speed input: 15065.69 toks/s, output: 14.71 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:17<01:02, 14.54it/s, est. speed input: 15037.13 toks/s, output: 14.68 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:18<01:03, 14.07it/s, est. speed input: 15009.55 toks/s, output: 14.66 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:19<01:03, 13.73it/s, est. speed input: 14982.75 toks/s, output: 14.63 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:21<01:03, 13.50it/s, est. speed input: 14956.64 toks/s, output: 14.61 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:22<01:03, 13.34it/s, est. speed input: 14931.39 toks/s, output: 14.58 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [01:23<01:02, 13.22it/s, est. speed input: 14906.82 toks/s, output: 14.56 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:24<01:01, 13.14it/s, est. speed input: 14882.93 toks/s, output: 14.53 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:26<01:00, 13.08it/s, est. speed input: 14859.75 toks/s, output: 14.51 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:27<00:59, 13.05it/s, est. speed input: 14837.26 toks/s, output: 14.49 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:28<00:58, 13.02it/s, est. speed input: 14815.35 toks/s, output: 14.47 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [01:29<00:57, 13.00it/s, est. speed input: 14794.16 toks/s, output: 14.45 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:31<00:56, 12.99it/s, est. speed input: 14773.43 toks/s, output: 14.43 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:32<00:55, 12.98it/s, est. speed input: 14753.23 toks/s, output: 14.41 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:33<00:54, 12.97it/s, est. speed input: 14733.58 toks/s, output: 14.39 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:34<00:52, 12.96it/s, est. speed input: 14714.40 toks/s, output: 14.37 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:36<00:51, 12.96it/s, est. speed input: 14695.77 toks/s, output: 14.35 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:37<00:50, 12.96it/s, est. speed input: 14677.59 toks/s, output: 14.33 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:38<00:49, 12.96it/s, est. speed input: 14659.91 toks/s, output: 14.32 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:39<00:47, 12.96it/s, est. speed input: 14642.80 toks/s, output: 14.30 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:40<00:46, 12.96it/s, est. speed input: 14625.80 toks/s, output: 14.28 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:42<00:45, 12.96it/s, est. speed input: 14609.36 toks/s, output: 14.27 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:43<00:44, 12.96it/s, est. speed input: 14593.33 toks/s, output: 14.25 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:44<00:30, 17.74it/s, est. speed input: 14763.56 toks/s, output: 14.42 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:45<00:32, 16.26it/s, est. speed input: 14746.28 toks/s, output: 14.40 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:46<00:33, 15.25it/s, est. speed input: 14729.40 toks/s, output: 14.38 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:48<00:33, 14.55it/s, est. speed input: 14712.95 toks/s, output: 14.37 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:49<00:33, 14.07it/s, est. speed input: 14696.81 toks/s, output: 14.35 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:50<00:33, 13.74it/s, est. speed input: 14681.05 toks/s, output: 14.34 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:51<00:33, 13.51it/s, est. speed input: 14665.64 toks/s, output: 14.32 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:53<00:32, 13.34it/s, est. speed input: 14650.33 toks/s, output: 14.31 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:54<00:31, 13.22it/s, est. speed input: 14635.25 toks/s, output: 14.29 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:55<00:30, 13.14it/s, est. speed input: 14620.44 toks/s, output: 14.28 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:56<00:29, 13.08it/s, est. speed input: 14606.05 toks/s, output: 14.26 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:58<00:28, 13.04it/s, est. speed input: 14591.90 toks/s, output: 14.25 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:59<00:26, 13.01it/s, est. speed input: 14578.09 toks/s, output: 14.24 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [02:00<00:25, 12.99it/s, est. speed input: 14564.47 toks/s, output: 14.22 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [02:01<00:24, 12.97it/s, est. speed input: 14551.06 toks/s, output: 14.21 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [02:02<00:23, 12.96it/s, est. speed input: 14537.89 toks/s, output: 14.20 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [02:04<00:22, 12.95it/s, est. speed input: 14525.00 toks/s, output: 14.18 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [02:05<00:20, 12.95it/s, est. speed input: 14512.30 toks/s, output: 14.17 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:06<00:19, 12.94it/s, est. speed input: 14499.95 toks/s, output: 14.16 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:07<00:18, 12.94it/s, est. speed input: 14487.82 toks/s, output: 14.15 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:09<00:17, 12.94it/s, est. speed input: 14476.04 toks/s, output: 14.14 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [02:10<00:15, 12.94it/s, est. speed input: 14464.53 toks/s, output: 14.13 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:11<00:14, 12.95it/s, est. speed input: 14453.23 toks/s, output: 14.11 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:12<00:13, 12.95it/s, est. speed input: 14442.18 toks/s, output: 14.10 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [02:14<00:12, 12.95it/s, est. speed input: 14431.44 toks/s, output: 14.09 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [02:15<00:10, 12.95it/s, est. speed input: 14420.68 toks/s, output: 14.08 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:16<00:06, 17.76it/s, est. speed input: 14552.94 toks/s, output: 14.21 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:17<00:05, 16.28it/s, est. speed input: 14541.96 toks/s, output: 14.20 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:18<00:05, 15.28it/s, est. speed input: 14531.22 toks/s, output: 14.19 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [02:20<00:04, 14.59it/s, est. speed input: 14520.62 toks/s, output: 14.18 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:21<00:03, 14.11it/s, est. speed input: 14510.22 toks/s, output: 14.17 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:22<00:02, 13.78it/s, est. speed input: 14500.04 toks/s, output: 14.16 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:23<00:01, 13.80it/s, est. speed input: 14497.41 toks/s, output: 14.16 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:23<00:00, 13.80it/s, est. speed input: 14597.16 toks/s, output: 14.26 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:23<00:00, 14.26it/s, est. speed input: 14597.16 toks/s, output: 14.26 toks/s]
[rank0]:[W126 07:30:45.227723397 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 229.3s

测试结果:
  Requests/s:   12.89
  Tokens/s:     13209.26
  Total Reqs:   2048
  Elapsed:      158.92s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     13196.37

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:31:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:31:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=349381) WARNING 01-26 07:31:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=349381) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=349381) WARNING 01-26 07:31:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 12.86 requests/s, 13180.18 total tokens/s, 12.86 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 07:31:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:31:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:31:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:31:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:31:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:31:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:31:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:31:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:31:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:31:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:31:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:31:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:31:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:31:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:31:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:31:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:31:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=349381) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=349381) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.39s/it]
(EngineCore_DP0 pid=349381) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.81it/s]
(EngineCore_DP0 pid=349381) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.20it/s]
(EngineCore_DP0 pid=349381) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]
(EngineCore_DP0 pid=349381) 
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=349381) [2026-01-26 07:31:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=349381) [rank0]:W0126 07:32:07.854000 349381 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=349381) [rank0]:W0126 07:32:07.936000 349381 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=349381) [rank0]:W0126 07:32:09.137000 349381 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=349381) [rank0]:W0126 07:32:09.258000 349381 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=349381) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:05,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:03,  2.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:02,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:01<00:01,  4.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:01,  4.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  4.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:02<00:00,  5.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  5.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.36it/s]
(EngineCore_DP0 pid=349381) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:01,  4.42it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:01,  3.77it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:01,  3.96it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:01<00:00,  3.62it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:01<00:00,  4.11it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  4.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.32it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 22/4096 [00:00<00:18, 217.63it/s]
Adding requests:   1%|          | 47/4096 [00:00<00:17, 236.31it/s]
Adding requests:   2%|▏         | 73/4096 [00:00<00:16, 243.35it/s]
Adding requests:   2%|▏         | 98/4096 [00:00<00:16, 242.73it/s]
Adding requests:   3%|▎         | 123/4096 [00:00<00:16, 243.67it/s]
Adding requests:   4%|▎         | 148/4096 [00:00<00:16, 242.16it/s]
Adding requests:   4%|▍         | 174/4096 [00:00<00:15, 246.78it/s]
Adding requests:   5%|▍         | 200/4096 [00:00<00:15, 250.67it/s]
Adding requests:   6%|▌         | 227/4096 [00:00<00:15, 254.13it/s]
Adding requests:   6%|▌         | 253/4096 [00:01<00:15, 253.80it/s]
Adding requests:   7%|▋         | 280/4096 [00:01<00:14, 257.59it/s]
Adding requests:   7%|▋         | 306/4096 [00:01<00:14, 257.03it/s]
Adding requests:   8%|▊         | 333/4096 [00:01<00:14, 260.39it/s]
Adding requests:   9%|▉         | 361/4096 [00:01<00:14, 263.62it/s]
Adding requests:   9%|▉         | 388/4096 [00:01<00:14, 263.64it/s]
Adding requests:  10%|█         | 416/4096 [00:01<00:13, 266.88it/s]
Adding requests:  11%|█         | 443/4096 [00:01<00:13, 261.70it/s]
Adding requests:  11%|█▏        | 471/4096 [00:01<00:13, 265.41it/s]
Adding requests:  12%|█▏        | 499/4096 [00:01<00:13, 268.50it/s]
Adding requests:  13%|█▎        | 529/4096 [00:02<00:12, 274.48it/s]
Adding requests:  14%|█▎        | 557/4096 [00:02<00:13, 270.98it/s]
Adding requests:  14%|█▍        | 585/4096 [00:02<00:13, 265.25it/s]
Adding requests:  15%|█▍        | 612/4096 [00:02<00:13, 261.63it/s]
Adding requests:  16%|█▌        | 640/4096 [00:02<00:13, 264.50it/s]
Adding requests:  16%|█▋        | 667/4096 [00:02<00:13, 257.23it/s]
Adding requests:  17%|█▋        | 695/4096 [00:02<00:13, 261.48it/s]
Adding requests:  18%|█▊        | 722/4096 [00:02<00:13, 258.48it/s]
Adding requests:  18%|█▊        | 748/4096 [00:02<00:13, 255.27it/s]
Adding requests:  19%|█▉        | 774/4096 [00:03<00:13, 255.08it/s]
Adding requests:  20%|█▉        | 800/4096 [00:03<00:12, 256.21it/s]
Adding requests:  20%|██        | 827/4096 [00:03<00:12, 258.80it/s]
Adding requests:  21%|██        | 854/4096 [00:03<00:12, 261.41it/s]
Adding requests:  22%|██▏       | 881/4096 [00:03<00:12, 261.26it/s]
Adding requests:  22%|██▏       | 908/4096 [00:03<00:12, 260.37it/s]
Adding requests:  23%|██▎       | 935/4096 [00:03<00:12, 251.20it/s]
Adding requests:  23%|██▎       | 962/4096 [00:03<00:12, 253.62it/s]
Adding requests:  24%|██▍       | 988/4096 [00:03<00:12, 250.61it/s]
Adding requests:  25%|██▍       | 1014/4096 [00:03<00:12, 246.93it/s]
Adding requests:  25%|██▌       | 1041/4096 [00:04<00:12, 252.18it/s]
Adding requests:  26%|██▌       | 1067/4096 [00:04<00:12, 251.75it/s]
Adding requests:  27%|██▋       | 1093/4096 [00:04<00:11, 253.12it/s]
Adding requests:  27%|██▋       | 1120/4096 [00:04<00:11, 254.86it/s]
Adding requests:  28%|██▊       | 1148/4096 [00:04<00:11, 259.42it/s]
Adding requests:  29%|██▊       | 1175/4096 [00:04<00:11, 260.91it/s]
Adding requests:  29%|██▉       | 1202/4096 [00:04<00:11, 250.69it/s]
Adding requests:  30%|███       | 1230/4096 [00:04<00:11, 257.47it/s]
Adding requests:  31%|███       | 1257/4096 [00:04<00:10, 258.66it/s]
Adding requests:  31%|███▏      | 1283/4096 [00:04<00:11, 254.17it/s]
Adding requests:  32%|███▏      | 1309/4096 [00:05<00:10, 253.67it/s]
Adding requests:  33%|███▎      | 1336/4096 [00:05<00:10, 256.12it/s]
Adding requests:  33%|███▎      | 1362/4096 [00:05<00:10, 251.75it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:05<00:10, 251.61it/s]
Adding requests:  35%|███▍      | 1414/4096 [00:05<00:10, 252.47it/s]
Adding requests:  35%|███▌      | 1442/4096 [00:05<00:10, 257.57it/s]
Adding requests:  36%|███▌      | 1468/4096 [00:05<00:10, 253.71it/s]
Adding requests:  36%|███▋      | 1494/4096 [00:05<00:10, 252.18it/s]
Adding requests:  37%|███▋      | 1520/4096 [00:05<00:10, 253.30it/s]
Adding requests:  38%|███▊      | 1546/4096 [00:06<00:10, 254.67it/s]
Adding requests:  38%|███▊      | 1572/4096 [00:06<00:10, 250.26it/s]
Adding requests:  39%|███▉      | 1598/4096 [00:06<00:10, 249.42it/s]
Adding requests:  40%|███▉      | 1623/4096 [00:06<00:09, 247.39it/s]
Adding requests:  40%|████      | 1648/4096 [00:06<00:09, 246.71it/s]
Adding requests:  41%|████      | 1673/4096 [00:06<00:09, 245.37it/s]
Adding requests:  41%|████▏     | 1698/4096 [00:06<00:09, 246.07it/s]
Adding requests:  42%|████▏     | 1725/4096 [00:06<00:09, 252.67it/s]
Adding requests:  43%|████▎     | 1751/4096 [00:06<00:09, 253.10it/s]
Adding requests:  43%|████▎     | 1777/4096 [00:06<00:09, 253.97it/s]
Adding requests:  44%|████▍     | 1803/4096 [00:07<00:09, 251.53it/s]
Adding requests:  45%|████▍     | 1830/4096 [00:07<00:08, 255.34it/s]
Adding requests:  45%|████▌     | 1857/4096 [00:07<00:08, 259.09it/s]
Adding requests:  46%|████▌     | 1883/4096 [00:07<00:08, 259.22it/s]
Adding requests:  47%|████▋     | 1910/4096 [00:07<00:08, 260.46it/s]
Adding requests:  47%|████▋     | 1938/4096 [00:07<00:08, 265.89it/s]
Adding requests:  48%|████▊     | 1965/4096 [00:07<00:08, 265.36it/s]
Adding requests:  49%|████▊     | 1992/4096 [00:07<00:08, 261.61it/s]
Adding requests:  49%|████▉     | 2019/4096 [00:07<00:08, 253.22it/s]
Adding requests:  50%|████▉     | 2046/4096 [00:08<00:08, 255.04it/s]
Adding requests:  51%|█████     | 2072/4096 [00:08<00:08, 249.23it/s]
Adding requests:  51%|█████     | 2099/4096 [00:08<00:07, 254.21it/s]
Adding requests:  52%|█████▏    | 2126/4096 [00:08<00:07, 257.83it/s]
Adding requests:  53%|█████▎    | 2152/4096 [00:08<00:07, 257.44it/s]
Adding requests:  53%|█████▎    | 2178/4096 [00:08<00:07, 252.49it/s]
Adding requests:  54%|█████▍    | 2204/4096 [00:08<00:07, 251.79it/s]
Adding requests:  54%|█████▍    | 2231/4096 [00:08<00:07, 256.06it/s]
Adding requests:  55%|█████▌    | 2258/4096 [00:08<00:07, 259.88it/s]
Adding requests:  56%|█████▌    | 2285/4096 [00:08<00:07, 255.70it/s]
Adding requests:  56%|█████▋    | 2312/4096 [00:09<00:06, 257.83it/s]
Adding requests:  57%|█████▋    | 2338/4096 [00:09<00:06, 258.11it/s]
Adding requests:  58%|█████▊    | 2365/4096 [00:09<00:06, 258.51it/s]
Adding requests:  58%|█████▊    | 2393/4096 [00:09<00:06, 263.54it/s]
Adding requests:  59%|█████▉    | 2420/4096 [00:09<00:06, 264.05it/s]
Adding requests:  60%|█████▉    | 2447/4096 [00:09<00:06, 250.56it/s]
Adding requests:  60%|██████    | 2474/4096 [00:09<00:06, 254.54it/s]
Adding requests:  61%|██████    | 2501/4096 [00:09<00:06, 257.98it/s]
Adding requests:  62%|██████▏   | 2527/4096 [00:09<00:06, 247.43it/s]
Adding requests:  62%|██████▏   | 2555/4096 [00:09<00:06, 254.09it/s]
Adding requests:  63%|██████▎   | 2581/4096 [00:10<00:05, 255.67it/s]
Adding requests:  64%|██████▎   | 2607/4096 [00:10<00:05, 254.44it/s]
Adding requests:  64%|██████▍   | 2633/4096 [00:10<00:05, 250.04it/s]
Adding requests:  65%|██████▍   | 2659/4096 [00:10<00:05, 250.99it/s]
Adding requests:  66%|██████▌   | 2685/4096 [00:10<00:05, 251.10it/s]
Adding requests:  66%|██████▌   | 2711/4096 [00:10<00:05, 248.10it/s]
Adding requests:  67%|██████▋   | 2738/4096 [00:10<00:05, 252.02it/s]
Adding requests:  68%|██████▊   | 2767/4096 [00:10<00:05, 261.00it/s]
Adding requests:  68%|██████▊   | 2795/4096 [00:10<00:04, 265.78it/s]
Adding requests:  69%|██████▉   | 2822/4096 [00:11<00:04, 265.11it/s]
Adding requests:  70%|██████▉   | 2850/4096 [00:11<00:04, 267.08it/s]
Adding requests:  70%|███████   | 2877/4096 [00:11<00:04, 266.28it/s]
Adding requests:  71%|███████   | 2904/4096 [00:11<00:04, 267.02it/s]
Adding requests:  72%|███████▏  | 2931/4096 [00:11<00:04, 265.14it/s]
Adding requests:  72%|███████▏  | 2960/4096 [00:11<00:04, 272.19it/s]
Adding requests:  73%|███████▎  | 2988/4096 [00:11<00:04, 265.94it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:11<00:04, 265.77it/s]
Adding requests:  74%|███████▍  | 3043/4096 [00:11<00:03, 267.04it/s]
Adding requests:  75%|███████▍  | 3070/4096 [00:11<00:03, 264.79it/s]
Adding requests:  76%|███████▌  | 3097/4096 [00:12<00:03, 261.67it/s]
Adding requests:  76%|███████▋  | 3124/4096 [00:12<00:03, 262.66it/s]
Adding requests:  77%|███████▋  | 3151/4096 [00:12<00:03, 261.71it/s]
Adding requests:  78%|███████▊  | 3178/4096 [00:12<00:03, 256.81it/s]
Adding requests:  78%|███████▊  | 3204/4096 [00:12<00:03, 254.62it/s]
Adding requests:  79%|███████▉  | 3232/4096 [00:12<00:03, 260.16it/s]
Adding requests:  80%|███████▉  | 3259/4096 [00:12<00:03, 256.59it/s]
Adding requests:  80%|████████  | 3285/4096 [00:12<00:03, 248.83it/s]
Adding requests:  81%|████████  | 3310/4096 [00:12<00:03, 241.68it/s]
Adding requests:  81%|████████▏ | 3336/4096 [00:13<00:03, 246.16it/s]
Adding requests:  82%|████████▏ | 3362/4096 [00:13<00:02, 249.91it/s]
Adding requests:  83%|████████▎ | 3389/4096 [00:13<00:02, 254.87it/s]
Adding requests:  83%|████████▎ | 3415/4096 [00:13<00:02, 254.89it/s]
Adding requests:  84%|████████▍ | 3443/4096 [00:13<00:02, 259.34it/s]
Adding requests:  85%|████████▍ | 3470/4096 [00:13<00:02, 260.93it/s]
Adding requests:  85%|████████▌ | 3497/4096 [00:13<00:02, 259.26it/s]
Adding requests:  86%|████████▌ | 3526/4096 [00:13<00:02, 267.85it/s]
Adding requests:  87%|████████▋ | 3554/4096 [00:13<00:01, 271.10it/s]
Adding requests:  87%|████████▋ | 3582/4096 [00:13<00:01, 262.65it/s]
Adding requests:  88%|████████▊ | 3609/4096 [00:14<00:01, 261.18it/s]
Adding requests:  89%|████████▉ | 3637/4096 [00:14<00:01, 263.81it/s]
Adding requests:  89%|████████▉ | 3664/4096 [00:14<00:01, 259.06it/s]
Adding requests:  90%|█████████ | 3690/4096 [00:14<00:01, 256.65it/s]
Adding requests:  91%|█████████ | 3719/4096 [00:14<00:01, 264.85it/s]
Adding requests:  91%|█████████▏| 3746/4096 [00:14<00:01, 262.03it/s]
Adding requests:  92%|█████████▏| 3773/4096 [00:14<00:01, 258.07it/s]
Adding requests:  93%|█████████▎| 3799/4096 [00:14<00:01, 240.94it/s]
Adding requests:  93%|█████████▎| 3824/4096 [00:14<00:01, 241.87it/s]
Adding requests:  94%|█████████▍| 3849/4096 [00:15<00:01, 243.01it/s]
Adding requests:  95%|█████████▍| 3875/4096 [00:15<00:00, 246.84it/s]
Adding requests:  95%|█████████▌| 3900/4096 [00:15<00:00, 246.23it/s]
Adding requests:  96%|█████████▌| 3925/4096 [00:15<00:00, 244.30it/s]
Adding requests:  96%|█████████▋| 3951/4096 [00:15<00:00, 247.38it/s]
Adding requests:  97%|█████████▋| 3976/4096 [00:15<00:00, 247.26it/s]
Adding requests:  98%|█████████▊| 4001/4096 [00:15<00:00, 247.94it/s]
Adding requests:  98%|█████████▊| 4027/4096 [00:15<00:00, 249.98it/s]
Adding requests:  99%|█████████▉| 4053/4096 [00:15<00:00, 250.76it/s]
Adding requests: 100%|█████████▉| 4079/4096 [00:15<00:00, 241.77it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 255.57it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 198/4096 [00:00<00:17, 222.43it/s, est. speed input: 227776.25 toks/s, output: 222.43 toks/s]
Processed prompts:   5%|▌         | 221/4096 [00:01<00:40, 94.80it/s, est. speed input: 114781.62 toks/s, output: 112.09 toks/s] 
Processed prompts:   6%|▌         | 232/4096 [00:03<01:10, 54.55it/s, est. speed input: 77799.78 toks/s, output: 75.98 toks/s]  
Processed prompts:   6%|▌         | 254/4096 [00:03<01:21, 47.13it/s, est. speed input: 68972.03 toks/s, output: 67.36 toks/s]
Processed prompts:   7%|▋         | 268/4096 [00:04<01:54, 33.43it/s, est. speed input: 56548.61 toks/s, output: 55.22 toks/s]
Processed prompts:   7%|▋         | 282/4096 [00:05<02:26, 25.95it/s, est. speed input: 48644.48 toks/s, output: 47.50 toks/s]
Processed prompts:   7%|▋         | 296/4096 [00:07<02:56, 21.49it/s, est. speed input: 43176.88 toks/s, output: 42.16 toks/s]
Processed prompts:   8%|▊         | 310/4096 [00:08<03:22, 18.67it/s, est. speed input: 39170.60 toks/s, output: 38.25 toks/s]
Processed prompts:   8%|▊         | 324/4096 [00:09<03:44, 16.83it/s, est. speed input: 36108.55 toks/s, output: 35.26 toks/s]
Processed prompts:   8%|▊         | 338/4096 [00:10<04:00, 15.60it/s, est. speed input: 33689.86 toks/s, output: 32.90 toks/s]
Processed prompts:   9%|▊         | 352/4096 [00:11<04:13, 14.76it/s, est. speed input: 31732.42 toks/s, output: 30.99 toks/s]
Processed prompts:   9%|▉         | 366/4096 [00:12<04:22, 14.19it/s, est. speed input: 30115.80 toks/s, output: 29.41 toks/s]
Processed prompts:   9%|▉         | 380/4096 [00:13<04:29, 13.80it/s, est. speed input: 28758.51 toks/s, output: 28.08 toks/s]
Processed prompts:  10%|▉         | 394/4096 [00:14<04:33, 13.52it/s, est. speed input: 27601.05 toks/s, output: 26.95 toks/s]
Processed prompts:  10%|▉         | 408/4096 [00:15<04:36, 13.33it/s, est. speed input: 26604.20 toks/s, output: 25.98 toks/s]
Processed prompts:  10%|█         | 422/4096 [00:16<04:38, 13.19it/s, est. speed input: 25736.27 toks/s, output: 25.13 toks/s]
Processed prompts:  11%|█         | 436/4096 [00:17<04:39, 13.10it/s, est. speed input: 24973.71 toks/s, output: 24.39 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:18<04:39, 13.04it/s, est. speed input: 24298.87 toks/s, output: 23.73 toks/s]
Processed prompts:  11%|█▏        | 464/4096 [00:20<04:39, 12.99it/s, est. speed input: 23696.76 toks/s, output: 23.14 toks/s]
Processed prompts:  12%|█▏        | 478/4096 [00:21<04:39, 12.96it/s, est. speed input: 23157.26 toks/s, output: 22.61 toks/s]
Processed prompts:  12%|█▏        | 492/4096 [00:22<04:38, 12.94it/s, est. speed input: 22670.61 toks/s, output: 22.14 toks/s]
Processed prompts:  12%|█▏        | 506/4096 [00:23<04:37, 12.92it/s, est. speed input: 22229.27 toks/s, output: 21.71 toks/s]
Processed prompts:  13%|█▎        | 520/4096 [00:24<04:36, 12.92it/s, est. speed input: 21827.61 toks/s, output: 21.32 toks/s]
Processed prompts:  13%|█▎        | 534/4096 [00:25<04:35, 12.91it/s, est. speed input: 21460.12 toks/s, output: 20.96 toks/s]
Processed prompts:  13%|█▎        | 548/4096 [00:26<04:34, 12.91it/s, est. speed input: 21123.04 toks/s, output: 20.63 toks/s]
Processed prompts:  14%|█▎        | 562/4096 [00:27<04:33, 12.90it/s, est. speed input: 20812.39 toks/s, output: 20.32 toks/s]
Processed prompts:  14%|█▍        | 576/4096 [00:28<04:32, 12.90it/s, est. speed input: 20525.12 toks/s, output: 20.04 toks/s]
Processed prompts:  14%|█▍        | 590/4096 [00:29<04:31, 12.90it/s, est. speed input: 20258.12 toks/s, output: 19.78 toks/s]
Processed prompts:  15%|█▍        | 604/4096 [00:30<04:30, 12.89it/s, est. speed input: 20009.96 toks/s, output: 19.54 toks/s]
Processed prompts:  15%|█▌        | 618/4096 [00:31<04:29, 12.90it/s, est. speed input: 19779.36 toks/s, output: 19.32 toks/s]
Processed prompts:  15%|█▌        | 632/4096 [00:33<04:28, 12.90it/s, est. speed input: 19563.82 toks/s, output: 19.11 toks/s]
Processed prompts:  16%|█▌        | 646/4096 [00:34<04:27, 12.90it/s, est. speed input: 19361.84 toks/s, output: 18.91 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:34<03:03, 18.60it/s, est. speed input: 19779.53 toks/s, output: 19.32 toks/s]
Processed prompts:  17%|█▋        | 688/4096 [00:35<03:23, 16.76it/s, est. speed input: 19581.10 toks/s, output: 19.12 toks/s]
Processed prompts:  17%|█▋        | 702/4096 [00:37<03:38, 15.54it/s, est. speed input: 19394.30 toks/s, output: 18.94 toks/s]
Processed prompts:  17%|█▋        | 716/4096 [00:38<03:49, 14.72it/s, est. speed input: 19218.18 toks/s, output: 18.77 toks/s]
Processed prompts:  18%|█▊        | 730/4096 [00:39<03:57, 14.16it/s, est. speed input: 19051.81 toks/s, output: 18.61 toks/s]
Processed prompts:  18%|█▊        | 744/4096 [00:40<04:03, 13.78it/s, est. speed input: 18894.48 toks/s, output: 18.45 toks/s]
Processed prompts:  19%|█▊        | 758/4096 [00:41<04:07, 13.51it/s, est. speed input: 18745.12 toks/s, output: 18.31 toks/s]
Processed prompts:  19%|█▉        | 772/4096 [00:42<04:09, 13.32it/s, est. speed input: 18603.38 toks/s, output: 18.17 toks/s]
Processed prompts:  19%|█▉        | 786/4096 [00:43<04:10, 13.19it/s, est. speed input: 18468.61 toks/s, output: 18.04 toks/s]
Processed prompts:  20%|█▉        | 800/4096 [00:44<04:11, 13.10it/s, est. speed input: 18340.58 toks/s, output: 17.91 toks/s]
Processed prompts:  20%|█▉        | 814/4096 [00:45<04:11, 13.03it/s, est. speed input: 18218.31 toks/s, output: 17.79 toks/s]
Processed prompts:  20%|██        | 828/4096 [00:46<04:11, 12.99it/s, est. speed input: 18101.85 toks/s, output: 17.68 toks/s]
Processed prompts:  21%|██        | 842/4096 [00:47<04:11, 12.96it/s, est. speed input: 17990.75 toks/s, output: 17.57 toks/s]
Processed prompts:  21%|██        | 856/4096 [00:49<04:10, 12.94it/s, est. speed input: 17884.55 toks/s, output: 17.47 toks/s]
Processed prompts:  21%|██        | 870/4096 [00:50<04:09, 12.92it/s, est. speed input: 17782.84 toks/s, output: 17.37 toks/s]
Processed prompts:  22%|██▏       | 884/4096 [00:51<04:08, 12.91it/s, est. speed input: 17685.62 toks/s, output: 17.27 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:52<04:07, 12.90it/s, est. speed input: 17592.18 toks/s, output: 17.18 toks/s]
Processed prompts:  22%|██▏       | 912/4096 [00:53<04:06, 12.90it/s, est. speed input: 17503.03 toks/s, output: 17.09 toks/s]
Processed prompts:  23%|██▎       | 926/4096 [00:54<04:05, 12.89it/s, est. speed input: 17416.71 toks/s, output: 17.01 toks/s]
Processed prompts:  23%|██▎       | 940/4096 [00:55<04:04, 12.89it/s, est. speed input: 17334.04 toks/s, output: 16.93 toks/s]
Processed prompts:  23%|██▎       | 954/4096 [00:56<04:03, 12.89it/s, est. speed input: 17254.54 toks/s, output: 16.85 toks/s]
Processed prompts:  24%|██▎       | 968/4096 [00:57<04:02, 12.89it/s, est. speed input: 17178.04 toks/s, output: 16.78 toks/s]
Processed prompts:  24%|██▍       | 982/4096 [00:58<04:01, 12.89it/s, est. speed input: 17104.43 toks/s, output: 16.70 toks/s]
Processed prompts:  24%|██▍       | 996/4096 [00:59<04:00, 12.89it/s, est. speed input: 17033.68 toks/s, output: 16.63 toks/s]
Processed prompts:  25%|██▍       | 1010/4096 [01:00<03:59, 12.88it/s, est. speed input: 16964.89 toks/s, output: 16.57 toks/s]
Processed prompts:  25%|██▌       | 1024/4096 [01:02<03:58, 12.88it/s, est. speed input: 16898.73 toks/s, output: 16.50 toks/s]
Processed prompts:  25%|██▌       | 1038/4096 [01:03<03:57, 12.88it/s, est. speed input: 16834.94 toks/s, output: 16.44 toks/s]
Processed prompts:  26%|██▌       | 1052/4096 [01:04<03:56, 12.88it/s, est. speed input: 16773.25 toks/s, output: 16.38 toks/s]
Processed prompts:  26%|██▌       | 1066/4096 [01:05<03:55, 12.88it/s, est. speed input: 16713.69 toks/s, output: 16.32 toks/s]
Processed prompts:  27%|██▋       | 1094/4096 [01:06<02:41, 18.62it/s, est. speed input: 16964.99 toks/s, output: 16.57 toks/s]
Processed prompts:  27%|██▋       | 1108/4096 [01:07<02:58, 16.77it/s, est. speed input: 16904.14 toks/s, output: 16.51 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [01:08<03:11, 15.55it/s, est. speed input: 16845.49 toks/s, output: 16.45 toks/s]
Processed prompts:  28%|██▊       | 1136/4096 [01:09<03:20, 14.73it/s, est. speed input: 16788.59 toks/s, output: 16.40 toks/s]
Processed prompts:  28%|██▊       | 1150/4096 [01:10<03:27, 14.17it/s, est. speed input: 16733.44 toks/s, output: 16.34 toks/s]
Processed prompts:  28%|██▊       | 1164/4096 [01:11<03:32, 13.78it/s, est. speed input: 16680.02 toks/s, output: 16.29 toks/s]
Processed prompts:  29%|██▉       | 1178/4096 [01:12<03:35, 13.52it/s, est. speed input: 16628.13 toks/s, output: 16.24 toks/s]
Processed prompts:  29%|██▉       | 1192/4096 [01:13<03:37, 13.33it/s, est. speed input: 16577.80 toks/s, output: 16.19 toks/s]
Processed prompts:  29%|██▉       | 1206/4096 [01:14<03:39, 13.19it/s, est. speed input: 16528.42 toks/s, output: 16.14 toks/s]
Processed prompts:  30%|██▉       | 1220/4096 [01:15<03:39, 13.10it/s, est. speed input: 16480.46 toks/s, output: 16.09 toks/s]
Processed prompts:  30%|███       | 1234/4096 [01:16<03:39, 13.03it/s, est. speed input: 16433.77 toks/s, output: 16.05 toks/s]
Processed prompts:  30%|███       | 1248/4096 [01:17<03:39, 12.98it/s, est. speed input: 16388.43 toks/s, output: 16.00 toks/s]
Processed prompts:  31%|███       | 1262/4096 [01:19<03:38, 12.95it/s, est. speed input: 16344.34 toks/s, output: 15.96 toks/s]
Processed prompts:  31%|███       | 1276/4096 [01:20<03:38, 12.93it/s, est. speed input: 16301.36 toks/s, output: 15.92 toks/s]
Processed prompts:  31%|███▏      | 1290/4096 [01:21<03:37, 12.91it/s, est. speed input: 16259.69 toks/s, output: 15.88 toks/s]
Processed prompts:  32%|███▏      | 1304/4096 [01:22<03:36, 12.90it/s, est. speed input: 16218.79 toks/s, output: 15.84 toks/s]
Processed prompts:  32%|███▏      | 1318/4096 [01:23<03:35, 12.88it/s, est. speed input: 16178.82 toks/s, output: 15.80 toks/s]
Processed prompts:  33%|███▎      | 1332/4096 [01:24<03:34, 12.88it/s, est. speed input: 16140.03 toks/s, output: 15.76 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [01:25<03:33, 12.87it/s, est. speed input: 16102.23 toks/s, output: 15.72 toks/s]
Processed prompts:  33%|███▎      | 1360/4096 [01:26<03:32, 12.87it/s, est. speed input: 16065.35 toks/s, output: 15.69 toks/s]
Processed prompts:  34%|███▎      | 1374/4096 [01:27<03:31, 12.86it/s, est. speed input: 16029.43 toks/s, output: 15.65 toks/s]
Processed prompts:  34%|███▍      | 1388/4096 [01:28<03:30, 12.86it/s, est. speed input: 15994.36 toks/s, output: 15.62 toks/s]
Processed prompts:  34%|███▍      | 1402/4096 [01:29<03:29, 12.86it/s, est. speed input: 15960.29 toks/s, output: 15.59 toks/s]
Processed prompts:  35%|███▍      | 1416/4096 [01:31<03:28, 12.87it/s, est. speed input: 15927.18 toks/s, output: 15.55 toks/s]
Processed prompts:  35%|███▍      | 1430/4096 [01:32<03:27, 12.88it/s, est. speed input: 15895.05 toks/s, output: 15.52 toks/s]
Processed prompts:  35%|███▌      | 1444/4096 [01:33<03:26, 12.87it/s, est. speed input: 15863.32 toks/s, output: 15.49 toks/s]
Processed prompts:  36%|███▌      | 1458/4096 [01:34<03:24, 12.87it/s, est. speed input: 15832.45 toks/s, output: 15.46 toks/s]
Processed prompts:  36%|███▌      | 1472/4096 [01:35<03:23, 12.88it/s, est. speed input: 15802.37 toks/s, output: 15.43 toks/s]
Processed prompts:  36%|███▋      | 1486/4096 [01:36<03:22, 12.88it/s, est. speed input: 15772.97 toks/s, output: 15.40 toks/s]
Processed prompts:  37%|███▋      | 1514/4096 [01:37<02:18, 18.63it/s, est. speed input: 15951.15 toks/s, output: 15.58 toks/s]
Processed prompts:  37%|███▋      | 1528/4096 [01:38<02:32, 16.79it/s, est. speed input: 15921.25 toks/s, output: 15.55 toks/s]
Processed prompts:  38%|███▊      | 1542/4096 [01:39<02:43, 15.59it/s, est. speed input: 15892.62 toks/s, output: 15.52 toks/s]
Processed prompts:  38%|███▊      | 1556/4096 [01:40<02:51, 14.78it/s, est. speed input: 15864.56 toks/s, output: 15.49 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [01:41<02:57, 14.23it/s, est. speed input: 15837.37 toks/s, output: 15.47 toks/s]
Processed prompts:  39%|███▊      | 1584/4096 [01:42<03:01, 13.84it/s, est. speed input: 15810.35 toks/s, output: 15.44 toks/s]
Processed prompts:  39%|███▉      | 1598/4096 [01:43<03:03, 13.58it/s, est. speed input: 15784.08 toks/s, output: 15.41 toks/s]
Processed prompts:  39%|███▉      | 1612/4096 [01:44<03:05, 13.40it/s, est. speed input: 15758.32 toks/s, output: 15.39 toks/s]
Processed prompts:  40%|███▉      | 1626/4096 [01:45<03:06, 13.26it/s, est. speed input: 15732.90 toks/s, output: 15.36 toks/s]
Processed prompts:  40%|████      | 1640/4096 [01:46<03:07, 13.12it/s, est. speed input: 15705.94 toks/s, output: 15.34 toks/s]
Processed prompts:  40%|████      | 1654/4096 [01:48<03:07, 13.01it/s, est. speed input: 15679.27 toks/s, output: 15.31 toks/s]
Processed prompts:  41%|████      | 1668/4096 [01:49<03:07, 12.95it/s, est. speed input: 15653.31 toks/s, output: 15.29 toks/s]
Processed prompts:  41%|████      | 1682/4096 [01:50<03:07, 12.90it/s, est. speed input: 15627.81 toks/s, output: 15.26 toks/s]
Processed prompts:  41%|████▏     | 1696/4096 [01:51<03:06, 12.86it/s, est. speed input: 15602.83 toks/s, output: 15.24 toks/s]
Processed prompts:  42%|████▏     | 1710/4096 [01:52<03:05, 12.84it/s, est. speed input: 15578.33 toks/s, output: 15.21 toks/s]
Processed prompts:  42%|████▏     | 1724/4096 [01:53<03:05, 12.82it/s, est. speed input: 15554.31 toks/s, output: 15.19 toks/s]
Processed prompts:  42%|████▏     | 1738/4096 [01:54<03:03, 12.82it/s, est. speed input: 15531.23 toks/s, output: 15.17 toks/s]
Processed prompts:  43%|████▎     | 1752/4096 [01:55<03:02, 12.83it/s, est. speed input: 15508.79 toks/s, output: 15.15 toks/s]
Processed prompts:  43%|████▎     | 1766/4096 [01:56<03:01, 12.83it/s, est. speed input: 15486.76 toks/s, output: 15.12 toks/s]
Processed prompts:  43%|████▎     | 1780/4096 [01:57<03:00, 12.83it/s, est. speed input: 15465.08 toks/s, output: 15.10 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:58<02:59, 12.83it/s, est. speed input: 15443.83 toks/s, output: 15.08 toks/s]
Processed prompts:  44%|████▍     | 1808/4096 [02:00<02:58, 12.84it/s, est. speed input: 15422.96 toks/s, output: 15.06 toks/s]
Processed prompts:  44%|████▍     | 1822/4096 [02:01<02:57, 12.84it/s, est. speed input: 15402.44 toks/s, output: 15.04 toks/s]
Processed prompts:  45%|████▍     | 1836/4096 [02:02<02:55, 12.84it/s, est. speed input: 15382.59 toks/s, output: 15.02 toks/s]
Processed prompts:  45%|████▌     | 1850/4096 [02:03<02:54, 12.86it/s, est. speed input: 15363.57 toks/s, output: 15.00 toks/s]
Processed prompts:  46%|████▌     | 1864/4096 [02:04<02:53, 12.87it/s, est. speed input: 15344.68 toks/s, output: 14.99 toks/s]
Processed prompts:  46%|████▌     | 1878/4096 [02:05<02:52, 12.88it/s, est. speed input: 15326.27 toks/s, output: 14.97 toks/s]
Processed prompts:  46%|████▌     | 1892/4096 [02:06<02:51, 12.89it/s, est. speed input: 15308.16 toks/s, output: 14.95 toks/s]
Processed prompts:  47%|████▋     | 1906/4096 [02:07<02:49, 12.89it/s, est. speed input: 15290.39 toks/s, output: 14.93 toks/s]
Processed prompts:  47%|████▋     | 1934/4096 [02:08<01:55, 18.72it/s, est. speed input: 15429.49 toks/s, output: 15.07 toks/s]
Processed prompts:  48%|████▊     | 1948/4096 [02:09<02:07, 16.84it/s, est. speed input: 15410.87 toks/s, output: 15.05 toks/s]
Processed prompts:  48%|████▊     | 1962/4096 [02:10<02:16, 15.59it/s, est. speed input: 15392.49 toks/s, output: 15.03 toks/s]
Processed prompts:  48%|████▊     | 1976/4096 [02:11<02:23, 14.75it/s, est. speed input: 15374.35 toks/s, output: 15.01 toks/s]
Processed prompts:  49%|████▊     | 1990/4096 [02:12<02:28, 14.17it/s, est. speed input: 15356.50 toks/s, output: 15.00 toks/s]
Processed prompts:  49%|████▉     | 2004/4096 [02:13<02:31, 13.78it/s, est. speed input: 15338.95 toks/s, output: 14.98 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [02:14<02:33, 13.51it/s, est. speed input: 15321.70 toks/s, output: 14.96 toks/s]
Processed prompts:  50%|████▉     | 2032/4096 [02:15<02:34, 13.32it/s, est. speed input: 15304.74 toks/s, output: 14.95 toks/s]
Processed prompts:  50%|████▉     | 2046/4096 [02:17<02:35, 13.19it/s, est. speed input: 15288.04 toks/s, output: 14.93 toks/s]
Processed prompts:  50%|█████     | 2060/4096 [02:18<02:35, 13.10it/s, est. speed input: 15271.53 toks/s, output: 14.91 toks/s]
Processed prompts:  51%|█████     | 2074/4096 [02:19<02:35, 13.03it/s, est. speed input: 15255.31 toks/s, output: 14.90 toks/s]
Processed prompts:  51%|█████     | 2088/4096 [02:20<02:34, 12.99it/s, est. speed input: 15239.31 toks/s, output: 14.88 toks/s]
Processed prompts:  51%|█████▏    | 2102/4096 [02:21<02:33, 12.96it/s, est. speed input: 15223.56 toks/s, output: 14.87 toks/s]
Processed prompts:  52%|█████▏    | 2116/4096 [02:22<02:33, 12.93it/s, est. speed input: 15208.06 toks/s, output: 14.85 toks/s]
Processed prompts:  52%|█████▏    | 2130/4096 [02:23<02:32, 12.92it/s, est. speed input: 15192.79 toks/s, output: 14.84 toks/s]
Processed prompts:  52%|█████▏    | 2144/4096 [02:24<02:31, 12.91it/s, est. speed input: 15177.76 toks/s, output: 14.82 toks/s]
Processed prompts:  53%|█████▎    | 2158/4096 [02:25<02:30, 12.90it/s, est. speed input: 15162.93 toks/s, output: 14.81 toks/s]
Processed prompts:  53%|█████▎    | 2172/4096 [02:26<02:29, 12.89it/s, est. speed input: 15148.33 toks/s, output: 14.79 toks/s]
Processed prompts:  53%|█████▎    | 2186/4096 [02:27<02:28, 12.89it/s, est. speed input: 15133.93 toks/s, output: 14.78 toks/s]
Processed prompts:  54%|█████▎    | 2200/4096 [02:28<02:27, 12.89it/s, est. speed input: 15119.75 toks/s, output: 14.77 toks/s]
Processed prompts:  54%|█████▍    | 2214/4096 [02:30<02:26, 12.88it/s, est. speed input: 15105.76 toks/s, output: 14.75 toks/s]
Processed prompts:  54%|█████▍    | 2228/4096 [02:31<02:24, 12.88it/s, est. speed input: 15092.01 toks/s, output: 14.74 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [02:32<02:23, 12.88it/s, est. speed input: 15078.42 toks/s, output: 14.73 toks/s]
Processed prompts:  55%|█████▌    | 2256/4096 [02:33<02:22, 12.88it/s, est. speed input: 15065.06 toks/s, output: 14.71 toks/s]
Processed prompts:  55%|█████▌    | 2270/4096 [02:34<02:21, 12.88it/s, est. speed input: 15051.88 toks/s, output: 14.70 toks/s]
Processed prompts:  56%|█████▌    | 2284/4096 [02:35<02:20, 12.88it/s, est. speed input: 15038.85 toks/s, output: 14.69 toks/s]
Processed prompts:  56%|█████▌    | 2298/4096 [02:36<02:19, 12.88it/s, est. speed input: 15025.98 toks/s, output: 14.67 toks/s]
Processed prompts:  56%|█████▋    | 2312/4096 [02:37<02:18, 12.88it/s, est. speed input: 15013.33 toks/s, output: 14.66 toks/s]
Processed prompts:  57%|█████▋    | 2326/4096 [02:38<02:17, 12.88it/s, est. speed input: 15000.84 toks/s, output: 14.65 toks/s]
Processed prompts:  57%|█████▋    | 2354/4096 [02:39<01:34, 18.48it/s, est. speed input: 15110.42 toks/s, output: 14.76 toks/s]
Processed prompts:  58%|█████▊    | 2368/4096 [02:40<01:43, 16.68it/s, est. speed input: 15097.39 toks/s, output: 14.74 toks/s]
Processed prompts:  58%|█████▊    | 2382/4096 [02:41<01:50, 15.48it/s, est. speed input: 15084.51 toks/s, output: 14.73 toks/s]
Processed prompts:  58%|█████▊    | 2396/4096 [02:42<01:55, 14.68it/s, est. speed input: 15071.82 toks/s, output: 14.72 toks/s]
Processed prompts:  59%|█████▉    | 2410/4096 [02:43<01:59, 14.12it/s, est. speed input: 15059.29 toks/s, output: 14.71 toks/s]
Processed prompts:  59%|█████▉    | 2424/4096 [02:44<02:01, 13.74it/s, est. speed input: 15046.94 toks/s, output: 14.69 toks/s]
Processed prompts:  60%|█████▉    | 2438/4096 [02:46<02:03, 13.48it/s, est. speed input: 15034.72 toks/s, output: 14.68 toks/s]
Processed prompts:  60%|█████▉    | 2452/4096 [02:47<02:03, 13.30it/s, est. speed input: 15022.68 toks/s, output: 14.67 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [02:48<02:03, 13.17it/s, est. speed input: 15010.85 toks/s, output: 14.66 toks/s]
Processed prompts:  61%|██████    | 2480/4096 [02:49<02:03, 13.08it/s, est. speed input: 14999.03 toks/s, output: 14.65 toks/s]
Processed prompts:  61%|██████    | 2494/4096 [02:50<02:03, 13.02it/s, est. speed input: 14987.45 toks/s, output: 14.64 toks/s]
Processed prompts:  61%|██████    | 2508/4096 [02:51<02:02, 12.97it/s, est. speed input: 14976.02 toks/s, output: 14.63 toks/s]
Processed prompts:  62%|██████▏   | 2522/4096 [02:52<02:01, 12.94it/s, est. speed input: 14964.71 toks/s, output: 14.61 toks/s]
Processed prompts:  62%|██████▏   | 2536/4096 [02:53<02:00, 12.92it/s, est. speed input: 14953.58 toks/s, output: 14.60 toks/s]
Processed prompts:  62%|██████▏   | 2550/4096 [02:54<01:59, 12.91it/s, est. speed input: 14942.57 toks/s, output: 14.59 toks/s]
Processed prompts:  63%|██████▎   | 2564/4096 [02:55<01:58, 12.90it/s, est. speed input: 14931.75 toks/s, output: 14.58 toks/s]
Processed prompts:  63%|██████▎   | 2578/4096 [02:56<01:57, 12.89it/s, est. speed input: 14921.00 toks/s, output: 14.57 toks/s]
Processed prompts:  63%|██████▎   | 2592/4096 [02:58<01:56, 12.89it/s, est. speed input: 14910.39 toks/s, output: 14.56 toks/s]
Processed prompts:  64%|██████▎   | 2606/4096 [02:59<01:55, 12.89it/s, est. speed input: 14900.02 toks/s, output: 14.55 toks/s]
Processed prompts:  64%|██████▍   | 2620/4096 [03:00<01:54, 12.89it/s, est. speed input: 14889.75 toks/s, output: 14.54 toks/s]
Processed prompts:  64%|██████▍   | 2634/4096 [03:01<01:53, 12.89it/s, est. speed input: 14879.59 toks/s, output: 14.53 toks/s]
Processed prompts:  65%|██████▍   | 2648/4096 [03:02<01:52, 12.89it/s, est. speed input: 14869.59 toks/s, output: 14.52 toks/s]
Processed prompts:  65%|██████▍   | 2662/4096 [03:03<01:51, 12.89it/s, est. speed input: 14859.69 toks/s, output: 14.51 toks/s]
Processed prompts:  65%|██████▌   | 2676/4096 [03:04<01:50, 12.89it/s, est. speed input: 14849.91 toks/s, output: 14.50 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [03:05<01:49, 12.89it/s, est. speed input: 14840.22 toks/s, output: 14.49 toks/s]
Processed prompts:  66%|██████▌   | 2704/4096 [03:06<01:48, 12.88it/s, est. speed input: 14830.60 toks/s, output: 14.48 toks/s]
Processed prompts:  66%|██████▋   | 2718/4096 [03:07<01:46, 12.88it/s, est. speed input: 14821.05 toks/s, output: 14.47 toks/s]
Processed prompts:  67%|██████▋   | 2732/4096 [03:08<01:45, 12.88it/s, est. speed input: 14811.61 toks/s, output: 14.46 toks/s]
Processed prompts:  67%|██████▋   | 2746/4096 [03:09<01:44, 12.88it/s, est. speed input: 14802.27 toks/s, output: 14.46 toks/s]
Processed prompts:  68%|██████▊   | 2774/4096 [03:10<01:11, 18.54it/s, est. speed input: 14895.50 toks/s, output: 14.55 toks/s]
Processed prompts:  68%|██████▊   | 2788/4096 [03:11<01:18, 16.72it/s, est. speed input: 14885.81 toks/s, output: 14.54 toks/s]
Processed prompts:  68%|██████▊   | 2802/4096 [03:12<01:23, 15.51it/s, est. speed input: 14876.21 toks/s, output: 14.53 toks/s]
Processed prompts:  69%|██████▉   | 2816/4096 [03:13<01:27, 14.69it/s, est. speed input: 14866.72 toks/s, output: 14.52 toks/s]
Processed prompts:  69%|██████▉   | 2830/4096 [03:15<01:29, 14.13it/s, est. speed input: 14857.23 toks/s, output: 14.51 toks/s]
Processed prompts:  69%|██████▉   | 2844/4096 [03:16<01:31, 13.74it/s, est. speed input: 14847.86 toks/s, output: 14.50 toks/s]
Processed prompts:  70%|██████▉   | 2858/4096 [03:17<01:31, 13.47it/s, est. speed input: 14838.56 toks/s, output: 14.49 toks/s]
Processed prompts:  70%|███████   | 2872/4096 [03:18<01:32, 13.29it/s, est. speed input: 14829.37 toks/s, output: 14.48 toks/s]
Processed prompts:  70%|███████   | 2886/4096 [03:19<01:31, 13.16it/s, est. speed input: 14820.29 toks/s, output: 14.47 toks/s]
Processed prompts:  71%|███████   | 2900/4096 [03:20<01:31, 13.07it/s, est. speed input: 14811.28 toks/s, output: 14.46 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [03:21<01:30, 13.00it/s, est. speed input: 14802.38 toks/s, output: 14.46 toks/s]
Processed prompts:  71%|███████▏  | 2928/4096 [03:22<01:30, 12.96it/s, est. speed input: 14793.64 toks/s, output: 14.45 toks/s]
Processed prompts:  72%|███████▏  | 2942/4096 [03:23<01:29, 12.93it/s, est. speed input: 14785.03 toks/s, output: 14.44 toks/s]
Processed prompts:  72%|███████▏  | 2956/4096 [03:24<01:28, 12.92it/s, est. speed input: 14776.53 toks/s, output: 14.43 toks/s]
Processed prompts:  73%|███████▎  | 2970/4096 [03:25<01:27, 12.90it/s, est. speed input: 14768.12 toks/s, output: 14.42 toks/s]
Processed prompts:  73%|███████▎  | 2984/4096 [03:27<01:26, 12.90it/s, est. speed input: 14759.81 toks/s, output: 14.41 toks/s]
Processed prompts:  73%|███████▎  | 2998/4096 [03:28<01:25, 12.89it/s, est. speed input: 14751.58 toks/s, output: 14.41 toks/s]
Processed prompts:  74%|███████▎  | 3012/4096 [03:29<01:24, 12.88it/s, est. speed input: 14743.40 toks/s, output: 14.40 toks/s]
Processed prompts:  74%|███████▍  | 3026/4096 [03:30<01:23, 12.88it/s, est. speed input: 14735.30 toks/s, output: 14.39 toks/s]
Processed prompts:  74%|███████▍  | 3040/4096 [03:31<01:21, 12.88it/s, est. speed input: 14727.33 toks/s, output: 14.38 toks/s]
Processed prompts:  75%|███████▍  | 3054/4096 [03:32<01:20, 12.88it/s, est. speed input: 14719.41 toks/s, output: 14.37 toks/s]
Processed prompts:  75%|███████▍  | 3068/4096 [03:33<01:19, 12.88it/s, est. speed input: 14711.58 toks/s, output: 14.37 toks/s]
Processed prompts:  75%|███████▌  | 3082/4096 [03:34<01:18, 12.87it/s, est. speed input: 14703.83 toks/s, output: 14.36 toks/s]
Processed prompts:  76%|███████▌  | 3096/4096 [03:35<01:17, 12.87it/s, est. speed input: 14696.16 toks/s, output: 14.35 toks/s]
Processed prompts:  76%|███████▌  | 3110/4096 [03:36<01:16, 12.87it/s, est. speed input: 14688.58 toks/s, output: 14.34 toks/s]
Processed prompts:  76%|███████▋  | 3124/4096 [03:37<01:15, 12.87it/s, est. speed input: 14681.07 toks/s, output: 14.34 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [03:38<01:14, 12.88it/s, est. speed input: 14673.65 toks/s, output: 14.33 toks/s]
Processed prompts:  77%|███████▋  | 3152/4096 [03:40<01:13, 12.87it/s, est. speed input: 14666.28 toks/s, output: 14.32 toks/s]
Processed prompts:  78%|███████▊  | 3180/4096 [03:40<00:49, 18.65it/s, est. speed input: 14748.57 toks/s, output: 14.40 toks/s]
Processed prompts:  78%|███████▊  | 3194/4096 [03:41<00:53, 16.78it/s, est. speed input: 14740.88 toks/s, output: 14.40 toks/s]
Processed prompts:  78%|███████▊  | 3208/4096 [03:42<00:57, 15.55it/s, est. speed input: 14733.36 toks/s, output: 14.39 toks/s]
Processed prompts:  79%|███████▊  | 3222/4096 [03:44<00:59, 14.72it/s, est. speed input: 14725.79 toks/s, output: 14.38 toks/s]
Processed prompts:  79%|███████▉  | 3236/4096 [03:45<01:00, 14.15it/s, est. speed input: 14718.36 toks/s, output: 14.37 toks/s]
Processed prompts:  79%|███████▉  | 3250/4096 [03:46<01:01, 13.76it/s, est. speed input: 14711.02 toks/s, output: 14.37 toks/s]
Processed prompts:  80%|███████▉  | 3264/4096 [03:47<01:01, 13.49it/s, est. speed input: 14703.64 toks/s, output: 14.36 toks/s]
Processed prompts:  80%|████████  | 3278/4096 [03:48<01:01, 13.30it/s, est. speed input: 14696.39 toks/s, output: 14.35 toks/s]
Processed prompts:  80%|████████  | 3292/4096 [03:49<01:01, 13.17it/s, est. speed input: 14689.22 toks/s, output: 14.34 toks/s]
Processed prompts:  81%|████████  | 3306/4096 [03:50<01:00, 13.08it/s, est. speed input: 14682.10 toks/s, output: 14.34 toks/s]
Processed prompts:  81%|████████  | 3320/4096 [03:51<00:59, 13.02it/s, est. speed input: 14675.05 toks/s, output: 14.33 toks/s]
Processed prompts:  81%|████████▏ | 3334/4096 [03:52<00:58, 12.98it/s, est. speed input: 14668.09 toks/s, output: 14.32 toks/s]
Processed prompts:  82%|████████▏ | 3348/4096 [03:53<00:57, 12.95it/s, est. speed input: 14661.19 toks/s, output: 14.32 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [03:54<00:56, 12.92it/s, est. speed input: 14654.32 toks/s, output: 14.31 toks/s]
Processed prompts:  82%|████████▏ | 3376/4096 [03:56<00:55, 12.91it/s, est. speed input: 14647.54 toks/s, output: 14.30 toks/s]
Processed prompts:  83%|████████▎ | 3390/4096 [03:57<00:54, 12.90it/s, est. speed input: 14640.82 toks/s, output: 14.30 toks/s]
Processed prompts:  83%|████████▎ | 3404/4096 [03:58<00:53, 12.89it/s, est. speed input: 14634.14 toks/s, output: 14.29 toks/s]
Processed prompts:  83%|████████▎ | 3418/4096 [03:59<00:52, 12.88it/s, est. speed input: 14627.54 toks/s, output: 14.28 toks/s]
Processed prompts:  84%|████████▍ | 3432/4096 [04:00<00:51, 12.88it/s, est. speed input: 14621.00 toks/s, output: 14.28 toks/s]
Processed prompts:  84%|████████▍ | 3446/4096 [04:01<00:50, 12.88it/s, est. speed input: 14614.51 toks/s, output: 14.27 toks/s]
Processed prompts:  84%|████████▍ | 3460/4096 [04:02<00:49, 12.88it/s, est. speed input: 14608.09 toks/s, output: 14.27 toks/s]
Processed prompts:  85%|████████▍ | 3474/4096 [04:03<00:48, 12.88it/s, est. speed input: 14601.74 toks/s, output: 14.26 toks/s]
Processed prompts:  85%|████████▌ | 3488/4096 [04:04<00:47, 12.88it/s, est. speed input: 14595.43 toks/s, output: 14.25 toks/s]
Processed prompts:  85%|████████▌ | 3502/4096 [04:05<00:46, 12.88it/s, est. speed input: 14589.19 toks/s, output: 14.25 toks/s]
Processed prompts:  86%|████████▌ | 3516/4096 [04:06<00:45, 12.88it/s, est. speed input: 14583.00 toks/s, output: 14.24 toks/s]
Processed prompts:  86%|████████▌ | 3530/4096 [04:07<00:43, 12.88it/s, est. speed input: 14576.87 toks/s, output: 14.24 toks/s]
Processed prompts:  87%|████████▋ | 3544/4096 [04:09<00:42, 12.87it/s, est. speed input: 14570.77 toks/s, output: 14.23 toks/s]
Processed prompts:  87%|████████▋ | 3558/4096 [04:10<00:41, 12.87it/s, est. speed input: 14564.74 toks/s, output: 14.22 toks/s]
Processed prompts:  87%|████████▋ | 3572/4096 [04:11<00:40, 12.87it/s, est. speed input: 14558.75 toks/s, output: 14.22 toks/s]
Processed prompts:  88%|████████▊ | 3600/4096 [04:11<00:26, 18.56it/s, est. speed input: 14630.34 toks/s, output: 14.29 toks/s]
Processed prompts:  88%|████████▊ | 3614/4096 [04:13<00:28, 16.73it/s, est. speed input: 14624.13 toks/s, output: 14.28 toks/s]
Processed prompts:  89%|████████▊ | 3628/4096 [04:14<00:30, 15.51it/s, est. speed input: 14617.95 toks/s, output: 14.28 toks/s]
Processed prompts:  89%|████████▉ | 3642/4096 [04:15<00:30, 14.69it/s, est. speed input: 14611.83 toks/s, output: 14.27 toks/s]
Processed prompts:  89%|████████▉ | 3656/4096 [04:16<00:31, 14.14it/s, est. speed input: 14605.78 toks/s, output: 14.26 toks/s]
Processed prompts:  90%|████████▉ | 3670/4096 [04:17<00:30, 13.75it/s, est. speed input: 14599.78 toks/s, output: 14.26 toks/s]
Processed prompts:  90%|████████▉ | 3684/4096 [04:18<00:30, 13.49it/s, est. speed input: 14593.83 toks/s, output: 14.25 toks/s]
Processed prompts:  90%|█████████ | 3698/4096 [04:19<00:29, 13.30it/s, est. speed input: 14587.92 toks/s, output: 14.25 toks/s]
Processed prompts:  91%|█████████ | 3712/4096 [04:20<00:29, 13.17it/s, est. speed input: 14582.05 toks/s, output: 14.24 toks/s]
Processed prompts:  91%|█████████ | 3726/4096 [04:21<00:28, 13.08it/s, est. speed input: 14576.25 toks/s, output: 14.23 toks/s]
Processed prompts:  91%|█████████▏| 3740/4096 [04:22<00:27, 13.02it/s, est. speed input: 14570.47 toks/s, output: 14.23 toks/s]
Processed prompts:  92%|█████████▏| 3754/4096 [04:23<00:26, 12.98it/s, est. speed input: 14564.76 toks/s, output: 14.22 toks/s]
Processed prompts:  92%|█████████▏| 3768/4096 [04:25<00:25, 12.94it/s, est. speed input: 14559.08 toks/s, output: 14.22 toks/s]
Processed prompts:  92%|█████████▏| 3782/4096 [04:26<00:24, 12.92it/s, est. speed input: 14553.45 toks/s, output: 14.21 toks/s]
Processed prompts:  93%|█████████▎| 3796/4096 [04:27<00:23, 12.91it/s, est. speed input: 14547.86 toks/s, output: 14.21 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [04:28<00:22, 12.90it/s, est. speed input: 14542.33 toks/s, output: 14.20 toks/s]
Processed prompts:  93%|█████████▎| 3824/4096 [04:29<00:21, 12.89it/s, est. speed input: 14536.85 toks/s, output: 14.20 toks/s]
Processed prompts:  94%|█████████▎| 3838/4096 [04:30<00:20, 12.89it/s, est. speed input: 14531.40 toks/s, output: 14.19 toks/s]
Processed prompts:  94%|█████████▍| 3852/4096 [04:31<00:18, 12.88it/s, est. speed input: 14526.01 toks/s, output: 14.19 toks/s]
Processed prompts:  94%|█████████▍| 3866/4096 [04:32<00:17, 12.88it/s, est. speed input: 14520.67 toks/s, output: 14.18 toks/s]
Processed prompts:  95%|█████████▍| 3880/4096 [04:33<00:16, 12.88it/s, est. speed input: 14515.37 toks/s, output: 14.18 toks/s]
Processed prompts:  95%|█████████▌| 3894/4096 [04:34<00:15, 12.88it/s, est. speed input: 14510.10 toks/s, output: 14.17 toks/s]
Processed prompts:  95%|█████████▌| 3908/4096 [04:35<00:14, 12.88it/s, est. speed input: 14504.89 toks/s, output: 14.16 toks/s]
Processed prompts:  96%|█████████▌| 3922/4096 [04:36<00:13, 12.88it/s, est. speed input: 14499.69 toks/s, output: 14.16 toks/s]
Processed prompts:  96%|█████████▌| 3936/4096 [04:38<00:12, 12.88it/s, est. speed input: 14494.55 toks/s, output: 14.15 toks/s]
Processed prompts:  96%|█████████▋| 3950/4096 [04:39<00:11, 12.87it/s, est. speed input: 14489.43 toks/s, output: 14.15 toks/s]
Processed prompts:  97%|█████████▋| 3964/4096 [04:40<00:10, 12.88it/s, est. speed input: 14484.37 toks/s, output: 14.14 toks/s]
Processed prompts:  97%|█████████▋| 3978/4096 [04:41<00:09, 12.88it/s, est. speed input: 14479.35 toks/s, output: 14.14 toks/s]
Processed prompts:  97%|█████████▋| 3992/4096 [04:42<00:08, 12.87it/s, est. speed input: 14474.34 toks/s, output: 14.14 toks/s]
Processed prompts:  98%|█████████▊| 4020/4096 [04:43<00:04, 18.56it/s, est. speed input: 14538.18 toks/s, output: 14.20 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [04:44<00:03, 16.72it/s, est. speed input: 14532.95 toks/s, output: 14.19 toks/s]
Processed prompts:  99%|█████████▉| 4048/4096 [04:45<00:03, 15.51it/s, est. speed input: 14527.82 toks/s, output: 14.19 toks/s]
Processed prompts:  99%|█████████▉| 4062/4096 [04:46<00:02, 14.69it/s, est. speed input: 14522.73 toks/s, output: 14.18 toks/s]
Processed prompts: 100%|█████████▉| 4076/4096 [04:47<00:01, 14.14it/s, est. speed input: 14517.71 toks/s, output: 14.18 toks/s]
Processed prompts: 100%|█████████▉| 4090/4096 [04:48<00:00, 16.22it/s, est. speed input: 14540.04 toks/s, output: 14.20 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [04:48<00:00, 16.22it/s, est. speed input: 14561.36 toks/s, output: 14.22 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [04:48<00:00, 14.22it/s, est. speed input: 14561.36 toks/s, output: 14.22 toks/s]
[rank0]:[W126 07:37:25.665891820 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 400.2s

测试结果:
  Requests/s:   12.86
  Tokens/s:     13180.18
  Total Reqs:   4096
  Elapsed:      318.54s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     13167.32

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:38:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:38:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=355821) WARNING 01-26 07:38:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=355821) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=355821) WARNING 01-26 07:39:03 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=355821) ERROR 01-26 07:40:06 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 07:38:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:38:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:38:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:38:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:38:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:38:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:38:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:38:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:38:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:38:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:38:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:38:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:38:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:38:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:38:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:38:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:38:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.01it/s]
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.01s/it]
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=355821) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.19it/s]
(EngineCore_DP0 pid=355821) 
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=355821) [2026-01-26 07:38:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=355821) [rank0]:W0126 07:39:16.771000 355821 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=355821) [rank0]:W0126 07:39:16.847000 355821 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=355821) [rank0]:W0126 07:39:17.968000 355821 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=355821) [rank0]:W0126 07:39:18.087000 355821 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=355821) Process EngineCore_DP0:
(EngineCore_DP0 pid=355821) Traceback (most recent call last):
(EngineCore_DP0 pid=355821)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=355821)     self.run()
(EngineCore_DP0 pid=355821)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=355821)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=355821)     raise e
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=355821)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=355821)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=355821)     super().__init__(
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=355821)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=355821)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=355821)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=355821)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=355821)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=355821)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=355821)     raise ValueError(
(EngineCore_DP0 pid=355821) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:40:08.397541340 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,9.1957,4717.3924,13.9196
1024,1024,1,128,128,9.6579,9899.3193,13.2534
2048,1024,2,256,128,12.9853,13309.8866,19.7147
4096,1024,4,512,128,13.1016,13429.1445,39.0792
8192,1024,8,1024,128,12.9805,13305.0627,78.8873
16384,1024,16,2048,128,12.8871,13209.2576,158.9188
32768,1024,32,4096,128,12.8587,13180.1780,318.5389
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:40:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:40:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=357482) WARNING 01-26 07:40:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=357482) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=357482) WARNING 01-26 07:40:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.44 requests/s, 4843.75 total tokens/s, 9.44 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:40:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:40:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:15,  5.04s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:09<00:09,  4.91s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:11<00:03,  3.23s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.82s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.96s/it]
(EngineCore_DP0 pid=357482) 
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=357482) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]
(EngineCore_DP0 pid=357482) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▎      | 43/128 [00:00<00:00, 426.42it/s]
Adding requests:  69%|██████▉   | 88/128 [00:00<00:00, 438.92it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 429.67it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.77it/s, est. speed input: 1419.95 toks/s, output: 2.77 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:26,  4.78it/s, est. speed input: 2209.18 toks/s, output: 4.31 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:19,  6.25it/s, est. speed input: 2718.16 toks/s, output: 5.31 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:17,  7.29it/s, est. speed input: 3068.63 toks/s, output: 5.99 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:15,  8.05it/s, est. speed input: 3331.60 toks/s, output: 6.51 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:14,  8.62it/s, est. speed input: 3535.93 toks/s, output: 6.91 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:13,  9.01it/s, est. speed input: 3696.74 toks/s, output: 7.22 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:01<00:12,  9.26it/s, est. speed input: 3825.11 toks/s, output: 7.47 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:12,  9.45it/s, est. speed input: 3931.90 toks/s, output: 7.68 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:12,  9.56it/s, est. speed input: 4019.90 toks/s, output: 7.85 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:12,  9.69it/s, est. speed input: 4099.93 toks/s, output: 8.01 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:11,  9.78it/s, est. speed input: 4169.12 toks/s, output: 8.14 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:11,  9.88it/s, est. speed input: 4282.45 toks/s, output: 8.36 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.88it/s, est. speed input: 4327.09 toks/s, output: 8.45 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:11,  9.92it/s, est. speed input: 4405.83 toks/s, output: 8.60 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:02<00:11,  9.83it/s, est. speed input: 4430.50 toks/s, output: 8.65 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:11,  9.85it/s, est. speed input: 4459.83 toks/s, output: 8.71 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:10,  9.95it/s, est. speed input: 4518.76 toks/s, output: 8.83 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.97it/s, est. speed input: 4566.15 toks/s, output: 8.92 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10, 10.00it/s, est. speed input: 4607.68 toks/s, output: 9.00 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10, 10.00it/s, est. speed input: 4625.06 toks/s, output: 9.03 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:03<00:09, 10.01it/s, est. speed input: 4658.30 toks/s, output: 9.10 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:09,  9.99it/s, est. speed input: 4671.39 toks/s, output: 9.12 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:09,  9.99it/s, est. speed input: 4684.73 toks/s, output: 9.15 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:09,  9.98it/s, est. speed input: 4697.37 toks/s, output: 9.17 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:09,  9.99it/s, est. speed input: 4709.39 toks/s, output: 9.20 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.99it/s, est. speed input: 4731.77 toks/s, output: 9.24 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09,  9.98it/s, est. speed input: 4751.07 toks/s, output: 9.28 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:03<00:09,  9.96it/s, est. speed input: 4758.88 toks/s, output: 9.29 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:09,  9.85it/s, est. speed input: 4761.64 toks/s, output: 9.30 toks/s]
Processed prompts:  30%|███       | 39/128 [00:04<00:09,  9.78it/s, est. speed input: 4764.91 toks/s, output: 9.31 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:09,  9.76it/s, est. speed input: 4769.82 toks/s, output: 9.32 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:08,  9.72it/s, est. speed input: 4773.44 toks/s, output: 9.32 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:04<00:01, 44.59it/s, est. speed input: 6413.77 toks/s, output: 12.53 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:02, 24.20it/s, est. speed input: 6295.61 toks/s, output: 12.30 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:05<00:03, 18.60it/s, est. speed input: 6217.40 toks/s, output: 12.14 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:05<00:03, 15.50it/s, est. speed input: 6152.21 toks/s, output: 12.02 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:05<00:04, 14.03it/s, est. speed input: 6110.16 toks/s, output: 11.93 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:05<00:04, 12.90it/s, est. speed input: 6072.22 toks/s, output: 11.86 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:06<00:04, 12.02it/s, est. speed input: 6035.68 toks/s, output: 11.79 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:06<00:04, 11.40it/s, est. speed input: 6003.27 toks/s, output: 11.73 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:06<00:04, 10.97it/s, est. speed input: 5974.37 toks/s, output: 11.67 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:06<00:04, 10.62it/s, est. speed input: 5944.93 toks/s, output: 11.61 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:07<00:04, 10.39it/s, est. speed input: 5918.37 toks/s, output: 11.56 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:07<00:04, 10.19it/s, est. speed input: 5891.73 toks/s, output: 11.51 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:07<00:04, 10.10it/s, est. speed input: 5868.92 toks/s, output: 11.46 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:07<00:04, 10.05it/s, est. speed input: 5848.03 toks/s, output: 11.42 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:07<00:03,  9.99it/s, est. speed input: 5827.48 toks/s, output: 11.38 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:08<00:03,  9.93it/s, est. speed input: 5806.40 toks/s, output: 11.34 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:08<00:03,  9.89it/s, est. speed input: 5796.04 toks/s, output: 11.32 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:08<00:03,  9.85it/s, est. speed input: 5785.45 toks/s, output: 11.30 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:08<00:03,  9.83it/s, est. speed input: 5775.68 toks/s, output: 11.28 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:08<00:03,  9.82it/s, est. speed input: 5766.36 toks/s, output: 11.26 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:08<00:03,  9.81it/s, est. speed input: 5757.47 toks/s, output: 11.25 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:08<00:03,  9.80it/s, est. speed input: 5748.48 toks/s, output: 11.23 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:08<00:03,  9.76it/s, est. speed input: 5739.06 toks/s, output: 11.21 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:08<00:03,  9.59it/s, est. speed input: 5726.17 toks/s, output: 11.18 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:08<00:02,  9.62it/s, est. speed input: 5717.41 toks/s, output: 11.17 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:09<00:02,  9.66it/s, est. speed input: 5709.29 toks/s, output: 11.15 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:09<00:02,  9.67it/s, est. speed input: 5700.83 toks/s, output: 11.13 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:09<00:02,  9.67it/s, est. speed input: 5692.59 toks/s, output: 11.12 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:09<00:02,  9.71it/s, est. speed input: 5685.16 toks/s, output: 11.10 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:09<00:02,  9.76it/s, est. speed input: 5678.50 toks/s, output: 11.09 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:09<00:02,  9.81it/s, est. speed input: 5672.24 toks/s, output: 11.08 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:09<00:02,  9.81it/s, est. speed input: 5665.35 toks/s, output: 11.07 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:09<00:02,  9.77it/s, est. speed input: 5657.79 toks/s, output: 11.05 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:09<00:01,  9.79it/s, est. speed input: 5651.41 toks/s, output: 11.04 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:09<00:01,  9.84it/s, est. speed input: 5645.87 toks/s, output: 11.03 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:10<00:01,  9.83it/s, est. speed input: 5639.62 toks/s, output: 11.01 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:10<00:01,  9.81it/s, est. speed input: 5633.14 toks/s, output: 11.00 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:10<00:01,  9.80it/s, est. speed input: 5626.88 toks/s, output: 10.99 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:10<00:01,  9.83it/s, est. speed input: 5621.44 toks/s, output: 10.98 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:10<00:01,  9.85it/s, est. speed input: 5616.18 toks/s, output: 10.97 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:10<00:01,  9.87it/s, est. speed input: 5611.01 toks/s, output: 10.96 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:10<00:01,  9.88it/s, est. speed input: 5605.93 toks/s, output: 10.95 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:10<00:01,  9.82it/s, est. speed input: 5599.68 toks/s, output: 10.94 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:10<00:00,  9.77it/s, est. speed input: 5593.36 toks/s, output: 10.92 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:10<00:00,  9.74it/s, est. speed input: 5587.46 toks/s, output: 10.91 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:11<00:00,  9.74it/s, est. speed input: 5581.80 toks/s, output: 10.90 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:11<00:00,  9.74it/s, est. speed input: 5576.36 toks/s, output: 10.89 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:11<00:00,  9.76it/s, est. speed input: 5571.43 toks/s, output: 10.88 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:11<00:00,  9.77it/s, est. speed input: 5566.38 toks/s, output: 10.87 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:11<00:00,  9.78it/s, est. speed input: 5561.55 toks/s, output: 10.86 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:11<00:00,  9.79it/s, est. speed input: 5556.82 toks/s, output: 10.85 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00,  9.78it/s, est. speed input: 5551.97 toks/s, output: 10.84 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.76it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.76it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 10.83it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
[rank0]:[W126 07:41:36.981997239 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 86.9s

测试结果:
  Requests/s:   9.44
  Tokens/s:     4843.75
  Total Reqs:   128
  Elapsed:      13.56s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     4834.31

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:41:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:41:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=358979) WARNING 01-26 07:41:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=358979) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=358979) WARNING 01-26 07:42:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.76 requests/s, 10001.06 total tokens/s, 9.76 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:41:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:41:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:41:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:41:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:41:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:41:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:10,  3.65s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:08<00:09,  4.51s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:10<00:03,  3.03s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.80s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.75s/it]
(EngineCore_DP0 pid=358979) 
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=358979) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.23it/s]
(EngineCore_DP0 pid=358979) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▋        | 21/128 [00:00<00:00, 209.32it/s]
Adding requests:  36%|███▌      | 46/128 [00:00<00:00, 230.61it/s]
Adding requests:  56%|█████▋    | 72/128 [00:00<00:00, 238.14it/s]
Adding requests:  75%|███████▌  | 96/128 [00:00<00:00, 237.33it/s]
Adding requests:  95%|█████████▌| 122/128 [00:00<00:00, 241.83it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 238.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:05, 20.97it/s, est. speed input: 21480.48 toks/s, output: 20.97 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 13.34it/s, est. speed input: 14566.22 toks/s, output: 14.22 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:09, 12.00it/s, est. speed input: 13303.46 toks/s, output: 12.99 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:10, 11.25it/s, est. speed input: 12598.36 toks/s, output: 12.30 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:10, 10.82it/s, est. speed input: 12164.15 toks/s, output: 11.88 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:10, 10.58it/s, est. speed input: 11880.89 toks/s, output: 11.60 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:10, 10.40it/s, est. speed input: 11664.33 toks/s, output: 11.39 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:10, 10.27it/s, est. speed input: 11494.97 toks/s, output: 11.23 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:10, 10.18it/s, est. speed input: 11358.84 toks/s, output: 11.09 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10, 10.13it/s, est. speed input: 11253.01 toks/s, output: 10.99 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10, 10.11it/s, est. speed input: 11171.38 toks/s, output: 10.91 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:10, 10.06it/s, est. speed input: 11091.94 toks/s, output: 10.83 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:09, 10.03it/s, est. speed input: 11025.93 toks/s, output: 10.77 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:09, 10.00it/s, est. speed input: 10965.58 toks/s, output: 10.71 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.97it/s, est. speed input: 10912.40 toks/s, output: 10.66 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.96it/s, est. speed input: 10887.87 toks/s, output: 10.63 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09, 10.01it/s, est. speed input: 10856.16 toks/s, output: 10.60 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:03<00:08, 10.04it/s, est. speed input: 10827.54 toks/s, output: 10.57 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:03<00:08, 10.03it/s, est. speed input: 10798.11 toks/s, output: 10.54 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:03<00:08, 10.02it/s, est. speed input: 10768.98 toks/s, output: 10.52 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:08, 10.05it/s, est. speed input: 10749.50 toks/s, output: 10.50 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:04<00:08, 10.07it/s, est. speed input: 10732.02 toks/s, output: 10.48 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:04<00:07, 10.03it/s, est. speed input: 10707.27 toks/s, output: 10.46 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:04<00:07,  9.93it/s, est. speed input: 10674.89 toks/s, output: 10.42 toks/s]
Processed prompts:  41%|████      | 52/128 [00:04<00:07,  9.96it/s, est. speed input: 10659.18 toks/s, output: 10.41 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:05<00:07,  9.91it/s, est. speed input: 10644.09 toks/s, output: 10.39 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:05<00:07,  9.92it/s, est. speed input: 10635.75 toks/s, output: 10.39 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:05<00:07,  9.97it/s, est. speed input: 10623.31 toks/s, output: 10.37 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:05<00:07, 10.00it/s, est. speed input: 10611.44 toks/s, output: 10.36 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:05<00:06,  9.98it/s, est. speed input: 10603.16 toks/s, output: 10.35 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:05<00:06,  9.97it/s, est. speed input: 10595.46 toks/s, output: 10.35 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:05<00:06,  9.98it/s, est. speed input: 10583.79 toks/s, output: 10.34 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:06<00:06,  9.97it/s, est. speed input: 10577.15 toks/s, output: 10.33 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:06<00:06, 10.02it/s, est. speed input: 10569.97 toks/s, output: 10.32 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:06<00:06, 10.07it/s, est. speed input: 10565.18 toks/s, output: 10.32 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:06<00:05, 10.10it/s, est. speed input: 10560.07 toks/s, output: 10.31 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:06<00:05, 10.09it/s, est. speed input: 10552.80 toks/s, output: 10.31 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:07<00:05, 10.10it/s, est. speed input: 10548.00 toks/s, output: 10.30 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:07<00:05, 10.05it/s, est. speed input: 10537.96 toks/s, output: 10.29 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:07<00:05, 10.09it/s, est. speed input: 10534.51 toks/s, output: 10.29 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:07<00:04, 10.11it/s, est. speed input: 10530.88 toks/s, output: 10.28 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:07<00:04, 10.09it/s, est. speed input: 10525.16 toks/s, output: 10.28 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:08<00:04, 10.07it/s, est. speed input: 10518.73 toks/s, output: 10.27 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:08<00:04, 10.04it/s, est. speed input: 10510.90 toks/s, output: 10.26 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:08<00:04, 10.04it/s, est. speed input: 10505.40 toks/s, output: 10.26 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:08<00:03, 10.03it/s, est. speed input: 10499.40 toks/s, output: 10.25 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:08<00:03, 10.03it/s, est. speed input: 10494.23 toks/s, output: 10.25 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:09<00:03, 10.03it/s, est. speed input: 10489.16 toks/s, output: 10.24 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:09<00:03,  9.89it/s, est. speed input: 10473.77 toks/s, output: 10.23 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:09<00:00, 32.15it/s, est. speed input: 12016.45 toks/s, output: 11.73 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:09<00:00, 21.72it/s, est. speed input: 11944.12 toks/s, output: 11.66 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:10<00:00, 17.79it/s, est. speed input: 11893.95 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:10<00:00, 15.26it/s, est. speed input: 11845.83 toks/s, output: 11.57 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:10<00:00, 14.01it/s, est. speed input: 11815.09 toks/s, output: 11.54 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:10<00:00, 13.01it/s, est. speed input: 11786.68 toks/s, output: 11.51 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00, 12.22it/s, est. speed input: 11758.95 toks/s, output: 11.48 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 12.22it/s, est. speed input: 11742.99 toks/s, output: 11.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 11.47it/s, est. speed input: 11742.99 toks/s, output: 11.47 toks/s]
[rank0]:[W126 07:43:03.855798979 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 87.5s

测试结果:
  Requests/s:   9.76
  Tokens/s:     10001.06
  Total Reqs:   128
  Elapsed:      13.12s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     9991.30

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:43:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:43:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=360442) WARNING 01-26 07:43:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=360442) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=360442) WARNING 01-26 07:43:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.78 requests/s, 11049.35 total tokens/s, 10.78 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 07:43:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:43:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.31s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.11it/s]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.05s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
(EngineCore_DP0 pid=360442) 
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=360442) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.09it/s]
(EngineCore_DP0 pid=360442) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.80it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 203.93it/s]
Adding requests:  19%|█▉        | 48/256 [00:00<00:00, 236.79it/s]
Adding requests:  29%|██▉       | 75/256 [00:00<00:00, 248.93it/s]
Adding requests:  39%|███▉      | 100/256 [00:00<00:00, 246.22it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 251.53it/s]
Adding requests:  60%|█████▉    | 153/256 [00:00<00:00, 246.64it/s]
Adding requests:  70%|██████▉   | 179/256 [00:00<00:00, 249.89it/s]
Adding requests:  80%|████████  | 205/256 [00:00<00:00, 251.45it/s]
Adding requests:  91%|█████████ | 232/256 [00:00<00:00, 254.47it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 246.22it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:04, 51.75it/s, est. speed input: 52997.98 toks/s, output: 51.75 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:12, 19.03it/s, est. speed input: 22111.25 toks/s, output: 21.59 toks/s]
Processed prompts:   7%|▋         | 19/256 [00:00<00:12, 18.31it/s, est. speed input: 21059.42 toks/s, output: 20.57 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:01<00:16, 13.85it/s, est. speed input: 17472.70 toks/s, output: 17.06 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:01<00:17, 13.17it/s, est. speed input: 16703.28 toks/s, output: 16.31 toks/s]
Processed prompts:  10%|█         | 26/256 [00:01<00:18, 12.61it/s, est. speed input: 16104.34 toks/s, output: 15.73 toks/s]
Processed prompts:  11%|█         | 28/256 [00:01<00:18, 12.16it/s, est. speed input: 15614.91 toks/s, output: 15.25 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:02<00:19, 11.83it/s, est. speed input: 15218.86 toks/s, output: 14.86 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:02<00:19, 11.59it/s, est. speed input: 14889.73 toks/s, output: 14.54 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:02<00:19, 11.41it/s, est. speed input: 14610.52 toks/s, output: 14.27 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:02<00:19, 11.29it/s, est. speed input: 14370.56 toks/s, output: 14.03 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:02<00:19, 11.18it/s, est. speed input: 14159.94 toks/s, output: 13.83 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:02<00:19, 11.12it/s, est. speed input: 13976.85 toks/s, output: 13.65 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:03<00:19, 11.06it/s, est. speed input: 13813.81 toks/s, output: 13.49 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:03<00:19, 11.04it/s, est. speed input: 13671.21 toks/s, output: 13.35 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:03<00:19, 11.01it/s, est. speed input: 13542.17 toks/s, output: 13.22 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:03<00:18, 10.99it/s, est. speed input: 13425.60 toks/s, output: 13.11 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:03<00:18, 10.97it/s, est. speed input: 13319.27 toks/s, output: 13.01 toks/s]
Processed prompts:  20%|██        | 52/256 [00:04<00:18, 10.96it/s, est. speed input: 13221.88 toks/s, output: 12.91 toks/s]
Processed prompts:  21%|██        | 54/256 [00:04<00:18, 10.96it/s, est. speed input: 13134.91 toks/s, output: 12.83 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:04<00:18, 10.95it/s, est. speed input: 13054.22 toks/s, output: 12.75 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:04<00:18, 10.96it/s, est. speed input: 12982.14 toks/s, output: 12.68 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:04<00:17, 10.97it/s, est. speed input: 12915.65 toks/s, output: 12.61 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:04<00:17, 10.97it/s, est. speed input: 12853.34 toks/s, output: 12.55 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:05<00:17, 10.96it/s, est. speed input: 12794.08 toks/s, output: 12.49 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:05<00:17, 10.96it/s, est. speed input: 12740.06 toks/s, output: 12.44 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:05<00:17, 10.95it/s, est. speed input: 12688.10 toks/s, output: 12.39 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:05<00:16, 10.95it/s, est. speed input: 12640.36 toks/s, output: 12.34 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:05<00:16, 10.95it/s, est. speed input: 12596.65 toks/s, output: 12.30 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:06<00:16, 10.94it/s, est. speed input: 12553.48 toks/s, output: 12.26 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:06<00:16, 10.94it/s, est. speed input: 12513.42 toks/s, output: 12.22 toks/s]
Processed prompts:  30%|███       | 78/256 [00:06<00:16, 10.93it/s, est. speed input: 12474.88 toks/s, output: 12.18 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:06<00:16, 10.93it/s, est. speed input: 12439.10 toks/s, output: 12.15 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:06<00:15, 10.93it/s, est. speed input: 12405.52 toks/s, output: 12.11 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:06<00:15, 10.92it/s, est. speed input: 12372.50 toks/s, output: 12.08 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:07<00:15, 10.92it/s, est. speed input: 12342.07 toks/s, output: 12.05 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:07<00:15, 10.92it/s, est. speed input: 12312.88 toks/s, output: 12.02 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:07<00:15, 10.92it/s, est. speed input: 12285.50 toks/s, output: 12.00 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:07<00:15, 10.92it/s, est. speed input: 12259.19 toks/s, output: 11.97 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:07<00:14, 10.93it/s, est. speed input: 12234.51 toks/s, output: 11.95 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:08<00:14, 10.91it/s, est. speed input: 12209.65 toks/s, output: 11.92 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:08<00:14, 10.92it/s, est. speed input: 12187.12 toks/s, output: 11.90 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:08<00:14, 10.93it/s, est. speed input: 12165.74 toks/s, output: 11.88 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:08<00:14, 10.93it/s, est. speed input: 12145.59 toks/s, output: 11.86 toks/s]
Processed prompts:  41%|████      | 104/256 [00:08<00:13, 10.94it/s, est. speed input: 12125.97 toks/s, output: 11.84 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:08<00:13, 10.93it/s, est. speed input: 12106.91 toks/s, output: 11.82 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:09<00:13, 10.93it/s, est. speed input: 12088.67 toks/s, output: 11.81 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:09<00:13, 10.93it/s, est. speed input: 12070.76 toks/s, output: 11.79 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:09<00:13, 10.92it/s, est. speed input: 12053.33 toks/s, output: 11.77 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:09<00:13, 10.92it/s, est. speed input: 12036.99 toks/s, output: 11.75 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:09<00:12, 10.92it/s, est. speed input: 12021.28 toks/s, output: 11.74 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:10<00:12, 10.91it/s, est. speed input: 12005.37 toks/s, output: 11.72 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:10<00:12, 10.91it/s, est. speed input: 11990.17 toks/s, output: 11.71 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:10<00:12, 10.90it/s, est. speed input: 11975.47 toks/s, output: 11.69 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:10<00:12, 10.90it/s, est. speed input: 11961.21 toks/s, output: 11.68 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:10<00:11, 10.90it/s, est. speed input: 11947.56 toks/s, output: 11.67 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:10<00:11, 10.90it/s, est. speed input: 11934.40 toks/s, output: 11.65 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:11<00:11, 10.90it/s, est. speed input: 11921.70 toks/s, output: 11.64 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:11<00:11, 10.91it/s, est. speed input: 11909.75 toks/s, output: 11.63 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:11<00:11, 10.91it/s, est. speed input: 11898.11 toks/s, output: 11.62 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:11<00:11, 10.90it/s, est. speed input: 11886.28 toks/s, output: 11.61 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:11<00:10, 10.91it/s, est. speed input: 11875.51 toks/s, output: 11.60 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:12<00:10, 10.90it/s, est. speed input: 11864.51 toks/s, output: 11.59 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:12<00:10, 10.90it/s, est. speed input: 11853.63 toks/s, output: 11.58 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:12<00:10, 10.89it/s, est. speed input: 11842.91 toks/s, output: 11.57 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:12<00:10, 10.88it/s, est. speed input: 11832.40 toks/s, output: 11.56 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:12<00:09, 10.88it/s, est. speed input: 11822.38 toks/s, output: 11.55 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:13<00:09, 10.87it/s, est. speed input: 11812.49 toks/s, output: 11.54 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:13<00:09, 10.86it/s, est. speed input: 11802.60 toks/s, output: 11.53 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:13<00:09, 10.86it/s, est. speed input: 11793.28 toks/s, output: 11.52 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:13<00:09, 10.87it/s, est. speed input: 11784.31 toks/s, output: 11.51 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:13<00:09, 10.86it/s, est. speed input: 11775.29 toks/s, output: 11.50 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:13<00:08, 10.86it/s, est. speed input: 11766.74 toks/s, output: 11.49 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:14<00:08, 10.87it/s, est. speed input: 11758.50 toks/s, output: 11.48 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:14<00:08, 10.86it/s, est. speed input: 11749.95 toks/s, output: 11.47 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:14<00:08, 10.85it/s, est. speed input: 11741.75 toks/s, output: 11.47 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:14<00:08, 10.86it/s, est. speed input: 11734.34 toks/s, output: 11.46 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:14<00:07, 10.87it/s, est. speed input: 11726.92 toks/s, output: 11.45 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:15<00:07, 10.87it/s, est. speed input: 11719.60 toks/s, output: 11.44 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:15<00:07, 10.86it/s, est. speed input: 11712.14 toks/s, output: 11.44 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:15<00:07, 10.85it/s, est. speed input: 11704.81 toks/s, output: 11.43 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:15<00:07, 10.85it/s, est. speed input: 11697.73 toks/s, output: 11.42 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:15<00:07, 10.85it/s, est. speed input: 11690.87 toks/s, output: 11.42 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:15<00:06, 10.85it/s, est. speed input: 11684.14 toks/s, output: 11.41 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:16<00:06, 10.85it/s, est. speed input: 11677.72 toks/s, output: 11.40 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:16<00:06, 10.84it/s, est. speed input: 11670.91 toks/s, output: 11.40 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:16<00:06, 10.84it/s, est. speed input: 11664.33 toks/s, output: 11.39 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:16<00:06, 10.83it/s, est. speed input: 11657.84 toks/s, output: 11.38 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:16<00:05, 10.83it/s, est. speed input: 11651.72 toks/s, output: 11.38 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:17<00:05, 10.83it/s, est. speed input: 11645.56 toks/s, output: 11.37 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:17<00:05, 10.83it/s, est. speed input: 11639.66 toks/s, output: 11.37 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:17<00:05, 10.84it/s, est. speed input: 11634.05 toks/s, output: 11.36 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:17<00:05, 10.84it/s, est. speed input: 11628.68 toks/s, output: 11.36 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:17<00:04, 10.84it/s, est. speed input: 11623.11 toks/s, output: 11.35 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:17<00:04, 10.84it/s, est. speed input: 11617.66 toks/s, output: 11.35 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:18<00:04, 10.85it/s, est. speed input: 11612.65 toks/s, output: 11.34 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:18<00:04, 10.84it/s, est. speed input: 11607.29 toks/s, output: 11.34 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:18<00:04, 10.84it/s, est. speed input: 11602.36 toks/s, output: 11.33 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:18<00:04, 10.84it/s, est. speed input: 11597.43 toks/s, output: 11.33 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:18<00:03, 10.84it/s, est. speed input: 11592.35 toks/s, output: 11.32 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:19<00:03, 10.82it/s, est. speed input: 11587.08 toks/s, output: 11.32 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:19<00:03, 10.82it/s, est. speed input: 11582.00 toks/s, output: 11.31 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:19<00:03, 10.81it/s, est. speed input: 11576.98 toks/s, output: 11.31 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:19<00:03, 10.81it/s, est. speed input: 11572.19 toks/s, output: 11.30 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:19<00:02, 10.81it/s, est. speed input: 11567.42 toks/s, output: 11.30 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:20<00:02, 10.81it/s, est. speed input: 11562.78 toks/s, output: 11.29 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:20<00:02, 10.81it/s, est. speed input: 11558.33 toks/s, output: 11.29 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:20<00:02, 10.81it/s, est. speed input: 11554.01 toks/s, output: 11.28 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:20<00:02, 10.81it/s, est. speed input: 11549.48 toks/s, output: 11.28 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:20<00:02, 10.81it/s, est. speed input: 11545.42 toks/s, output: 11.27 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:20<00:01, 10.82it/s, est. speed input: 11541.36 toks/s, output: 11.27 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:21<00:01, 10.82it/s, est. speed input: 11537.26 toks/s, output: 11.27 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:21<00:01, 10.81it/s, est. speed input: 11532.99 toks/s, output: 11.26 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:21<00:01, 10.82it/s, est. speed input: 11529.24 toks/s, output: 11.26 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:21<00:01, 10.81it/s, est. speed input: 11525.07 toks/s, output: 11.25 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:21<00:00, 10.80it/s, est. speed input: 11521.08 toks/s, output: 11.25 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:22<00:00, 10.80it/s, est. speed input: 11517.07 toks/s, output: 11.25 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:22<00:00, 10.80it/s, est. speed input: 11513.26 toks/s, output: 11.24 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:22<00:00, 10.80it/s, est. speed input: 11509.65 toks/s, output: 11.24 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:22<00:00, 10.82it/s, est. speed input: 11506.41 toks/s, output: 11.24 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 12.50it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 12.50it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 11.27it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
[rank0]:[W126 07:44:31.284669797 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 87.5s

测试结果:
  Requests/s:   10.78
  Tokens/s:     11049.35
  Total Reqs:   256
  Elapsed:      23.75s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     11038.57

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:44:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:44:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=361907) WARNING 01-26 07:44:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=361907) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=361907) WARNING 01-26 07:45:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.86 requests/s, 11130.08 total tokens/s, 10.86 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 07:44:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:44:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:44:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:44:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:44:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:44:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.24s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.26s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.16it/s]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.01s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.03s/it]
(EngineCore_DP0 pid=361907) 
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=361907) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  4.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]
(EngineCore_DP0 pid=361907) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  5.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.23it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 22/512 [00:00<00:02, 219.87it/s]
Adding requests:   9%|▉         | 47/512 [00:00<00:01, 234.95it/s]
Adding requests:  14%|█▍        | 74/512 [00:00<00:01, 246.69it/s]
Adding requests:  19%|█▉        | 99/512 [00:00<00:01, 245.79it/s]
Adding requests:  24%|██▍       | 125/512 [00:00<00:01, 250.30it/s]
Adding requests:  29%|██▉       | 151/512 [00:00<00:01, 249.64it/s]
Adding requests:  35%|███▍      | 177/512 [00:00<00:01, 249.80it/s]
Adding requests:  40%|███▉      | 204/512 [00:00<00:01, 253.10it/s]
Adding requests:  45%|████▌     | 232/512 [00:00<00:01, 259.79it/s]
Adding requests:  50%|█████     | 258/512 [00:01<00:00, 256.36it/s]
Adding requests:  55%|█████▌    | 284/512 [00:01<00:00, 257.38it/s]
Adding requests:  61%|██████    | 310/512 [00:01<00:00, 257.76it/s]
Adding requests:  66%|██████▌   | 338/512 [00:01<00:00, 263.11it/s]
Adding requests:  71%|███████▏  | 366/512 [00:01<00:00, 265.16it/s]
Adding requests:  77%|███████▋  | 393/512 [00:01<00:00, 262.57it/s]
Adding requests:  82%|████████▏ | 421/512 [00:01<00:00, 265.03it/s]
Adding requests:  88%|████████▊ | 448/512 [00:01<00:00, 260.72it/s]
Adding requests:  93%|█████████▎| 475/512 [00:01<00:00, 263.32it/s]
Adding requests:  98%|█████████▊| 503/512 [00:01<00:00, 266.96it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 258.08it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:05, 95.01it/s, est. speed input: 97301.82 toks/s, output: 95.01 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:00<00:18, 26.53it/s, est. speed input: 31554.41 toks/s, output: 30.81 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:01<00:22, 21.77it/s, est. speed input: 26636.27 toks/s, output: 26.01 toks/s]
Processed prompts:   7%|▋         | 37/512 [00:01<00:26, 18.05it/s, est. speed input: 23269.39 toks/s, output: 22.72 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:01<00:31, 14.81it/s, est. speed input: 20602.60 toks/s, output: 20.12 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:02<00:39, 11.83it/s, est. speed input: 18317.21 toks/s, output: 17.89 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:02<00:40, 11.60it/s, est. speed input: 17392.86 toks/s, output: 16.99 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:03<00:40, 11.45it/s, est. speed input: 16685.60 toks/s, output: 16.29 toks/s]
Processed prompts:  11%|█         | 54/512 [00:03<00:40, 11.34it/s, est. speed input: 16128.13 toks/s, output: 15.75 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:03<00:40, 11.27it/s, est. speed input: 15675.64 toks/s, output: 15.31 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:04<00:40, 11.22it/s, est. speed input: 15302.21 toks/s, output: 14.94 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:04<00:39, 11.18it/s, est. speed input: 14987.22 toks/s, output: 14.64 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:04<00:39, 11.15it/s, est. speed input: 14718.44 toks/s, output: 14.37 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:05<00:39, 11.13it/s, est. speed input: 14486.26 toks/s, output: 14.15 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:05<00:39, 11.12it/s, est. speed input: 14283.57 toks/s, output: 13.95 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:05<00:38, 11.11it/s, est. speed input: 14105.22 toks/s, output: 13.77 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:06<00:38, 11.10it/s, est. speed input: 13947.67 toks/s, output: 13.62 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:06<00:38, 11.09it/s, est. speed input: 13806.59 toks/s, output: 13.48 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:07<00:37, 11.08it/s, est. speed input: 13679.60 toks/s, output: 13.36 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:07<00:37, 11.08it/s, est. speed input: 13565.23 toks/s, output: 13.25 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:07<00:37, 11.08it/s, est. speed input: 13462.05 toks/s, output: 13.15 toks/s]
Processed prompts:  21%|██        | 106/512 [00:08<00:36, 11.03it/s, est. speed input: 13358.23 toks/s, output: 13.05 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:08<00:36, 10.98it/s, est. speed input: 13262.75 toks/s, output: 12.95 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:08<00:36, 10.96it/s, est. speed input: 13175.41 toks/s, output: 12.87 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:09<00:36, 10.93it/s, est. speed input: 13094.35 toks/s, output: 12.79 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:09<00:35, 10.92it/s, est. speed input: 13019.25 toks/s, output: 12.71 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:09<00:35, 10.90it/s, est. speed input: 12949.73 toks/s, output: 12.65 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:10<00:35, 10.89it/s, est. speed input: 12885.13 toks/s, output: 12.58 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:10<00:34, 10.89it/s, est. speed input: 12824.86 toks/s, output: 12.52 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:11<00:34, 10.88it/s, est. speed input: 12768.67 toks/s, output: 12.47 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:11<00:34, 10.88it/s, est. speed input: 12715.56 toks/s, output: 12.42 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:11<00:33, 10.87it/s, est. speed input: 12665.69 toks/s, output: 12.37 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:12<00:33, 10.87it/s, est. speed input: 12618.87 toks/s, output: 12.32 toks/s]
Processed prompts:  30%|███       | 154/512 [00:12<00:32, 10.86it/s, est. speed input: 12574.77 toks/s, output: 12.28 toks/s]
Processed prompts:  31%|███       | 158/512 [00:12<00:32, 10.86it/s, est. speed input: 12532.95 toks/s, output: 12.24 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:13<00:32, 10.85it/s, est. speed input: 12493.16 toks/s, output: 12.20 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:13<00:31, 10.85it/s, est. speed input: 12455.58 toks/s, output: 12.16 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:14<00:31, 10.85it/s, est. speed input: 12419.82 toks/s, output: 12.13 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:14<00:31, 10.84it/s, est. speed input: 12385.92 toks/s, output: 12.10 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:14<00:30, 10.84it/s, est. speed input: 12353.84 toks/s, output: 12.06 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:15<00:30, 10.84it/s, est. speed input: 12323.21 toks/s, output: 12.03 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:15<00:30, 10.84it/s, est. speed input: 12293.77 toks/s, output: 12.01 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:15<00:29, 10.84it/s, est. speed input: 12266.11 toks/s, output: 11.98 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:16<00:29, 10.85it/s, est. speed input: 12240.68 toks/s, output: 11.95 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:16<00:28, 10.86it/s, est. speed input: 12216.34 toks/s, output: 11.93 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:16<00:28, 10.87it/s, est. speed input: 12193.31 toks/s, output: 11.91 toks/s]
Processed prompts:  40%|████      | 206/512 [00:17<00:28, 10.88it/s, est. speed input: 12171.33 toks/s, output: 11.89 toks/s]
Processed prompts:  41%|████      | 210/512 [00:17<00:27, 10.88it/s, est. speed input: 12150.00 toks/s, output: 11.87 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:18<00:27, 10.88it/s, est. speed input: 12129.50 toks/s, output: 11.85 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:18<00:27, 10.88it/s, est. speed input: 12109.83 toks/s, output: 11.83 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:18<00:26, 10.88it/s, est. speed input: 12090.83 toks/s, output: 11.81 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:19<00:26, 10.88it/s, est. speed input: 12072.50 toks/s, output: 11.79 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:19<00:25, 10.88it/s, est. speed input: 12054.78 toks/s, output: 11.77 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:19<00:25, 10.88it/s, est. speed input: 12037.87 toks/s, output: 11.76 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:20<00:25, 10.88it/s, est. speed input: 12021.57 toks/s, output: 11.74 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:20<00:24, 10.87it/s, est. speed input: 12005.53 toks/s, output: 11.72 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:21<00:24, 10.87it/s, est. speed input: 11990.24 toks/s, output: 11.71 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:21<00:24, 10.87it/s, est. speed input: 11975.52 toks/s, output: 11.69 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:21<00:23, 10.87it/s, est. speed input: 11960.95 toks/s, output: 11.68 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:22<00:23, 10.86it/s, est. speed input: 11946.85 toks/s, output: 11.67 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:22<00:23, 10.86it/s, est. speed input: 11933.34 toks/s, output: 11.65 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:22<00:22, 10.86it/s, est. speed input: 11920.20 toks/s, output: 11.64 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:23<00:22, 10.86it/s, est. speed input: 11907.41 toks/s, output: 11.63 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:23<00:21, 10.86it/s, est. speed input: 11895.03 toks/s, output: 11.62 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:23<00:21, 10.86it/s, est. speed input: 11883.17 toks/s, output: 11.60 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:24<00:21, 10.87it/s, est. speed input: 11872.42 toks/s, output: 11.59 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:24<00:20, 10.88it/s, est. speed input: 11861.71 toks/s, output: 11.58 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:25<00:20, 10.89it/s, est. speed input: 11851.52 toks/s, output: 11.57 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:25<00:20, 10.89it/s, est. speed input: 11841.61 toks/s, output: 11.56 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:25<00:19, 10.89it/s, est. speed input: 11831.78 toks/s, output: 11.55 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:26<00:19, 10.89it/s, est. speed input: 11822.17 toks/s, output: 11.55 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:26<00:18, 10.89it/s, est. speed input: 11812.98 toks/s, output: 11.54 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:26<00:18, 10.90it/s, est. speed input: 11804.17 toks/s, output: 11.53 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:27<00:18, 10.90it/s, est. speed input: 11795.84 toks/s, output: 11.52 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:27<00:17, 10.90it/s, est. speed input: 11787.50 toks/s, output: 11.51 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:27<00:17, 10.91it/s, est. speed input: 11779.46 toks/s, output: 11.50 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:28<00:17, 10.91it/s, est. speed input: 11771.54 toks/s, output: 11.50 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:28<00:16, 10.91it/s, est. speed input: 11763.95 toks/s, output: 11.49 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:29<00:16, 10.91it/s, est. speed input: 11756.52 toks/s, output: 11.48 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:29<00:15, 10.91it/s, est. speed input: 11749.23 toks/s, output: 11.47 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:29<00:06, 23.81it/s, est. speed input: 12287.34 toks/s, output: 12.00 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:30<00:07, 19.96it/s, est. speed input: 12273.84 toks/s, output: 11.99 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:30<00:08, 17.25it/s, est. speed input: 12260.49 toks/s, output: 11.97 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:30<00:09, 15.36it/s, est. speed input: 12247.57 toks/s, output: 11.96 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:31<00:09, 14.02it/s, est. speed input: 12234.98 toks/s, output: 11.95 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:31<00:10, 13.09it/s, est. speed input: 12222.58 toks/s, output: 11.94 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:32<00:10, 12.43it/s, est. speed input: 12210.42 toks/s, output: 11.92 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:32<00:10, 11.97it/s, est. speed input: 12198.46 toks/s, output: 11.91 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:32<00:10, 11.64it/s, est. speed input: 12186.66 toks/s, output: 11.90 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:33<00:10, 11.42it/s, est. speed input: 12175.28 toks/s, output: 11.89 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:33<00:10, 11.27it/s, est. speed input: 12164.21 toks/s, output: 11.88 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:33<00:09, 11.15it/s, est. speed input: 12153.17 toks/s, output: 11.87 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:34<00:09, 11.08it/s, est. speed input: 12142.51 toks/s, output: 11.86 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:34<00:09, 11.02it/s, est. speed input: 12131.98 toks/s, output: 11.85 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:34<00:08, 10.98it/s, est. speed input: 12121.72 toks/s, output: 11.84 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:35<00:08, 10.95it/s, est. speed input: 12111.67 toks/s, output: 11.83 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:35<00:08, 10.93it/s, est. speed input: 12101.76 toks/s, output: 11.82 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:36<00:07, 10.92it/s, est. speed input: 12092.06 toks/s, output: 11.81 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:36<00:07, 10.91it/s, est. speed input: 12082.59 toks/s, output: 11.80 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:36<00:07, 10.90it/s, est. speed input: 12073.24 toks/s, output: 11.79 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:37<00:06, 10.90it/s, est. speed input: 12064.05 toks/s, output: 11.78 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:37<00:06, 10.89it/s, est. speed input: 12055.06 toks/s, output: 11.77 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:37<00:06, 10.89it/s, est. speed input: 12046.15 toks/s, output: 11.76 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:38<00:05, 10.89it/s, est. speed input: 12037.53 toks/s, output: 11.76 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:38<00:05, 10.89it/s, est. speed input: 12029.05 toks/s, output: 11.75 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:39<00:04, 10.89it/s, est. speed input: 12020.77 toks/s, output: 11.74 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:39<00:04, 10.88it/s, est. speed input: 12012.55 toks/s, output: 11.73 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:39<00:04, 10.89it/s, est. speed input: 12004.63 toks/s, output: 11.72 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:40<00:03, 10.89it/s, est. speed input: 11996.74 toks/s, output: 11.72 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:40<00:03, 10.89it/s, est. speed input: 11989.07 toks/s, output: 11.71 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:40<00:03, 10.89it/s, est. speed input: 11981.48 toks/s, output: 11.70 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:41<00:02, 10.88it/s, est. speed input: 11973.96 toks/s, output: 11.69 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:41<00:02, 10.89it/s, est. speed input: 11966.80 toks/s, output: 11.69 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:41<00:02, 10.89it/s, est. speed input: 11959.63 toks/s, output: 11.68 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:42<00:01, 10.88it/s, est. speed input: 11952.48 toks/s, output: 11.67 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:42<00:01, 10.88it/s, est. speed input: 11945.47 toks/s, output: 11.67 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:43<00:00, 10.88it/s, est. speed input: 11938.58 toks/s, output: 11.66 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:43<00:00, 10.89it/s, est. speed input: 11931.99 toks/s, output: 11.65 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:43<00:00, 11.68it/s, est. speed input: 11948.06 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:43<00:00, 11.68it/s, est. speed input: 11994.85 toks/s, output: 11.71 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:43<00:00, 11.71it/s, est. speed input: 11994.85 toks/s, output: 11.71 toks/s]
[rank0]:[W126 07:46:22.185431347 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 111.1s

测试结果:
  Requests/s:   10.86
  Tokens/s:     11130.08
  Total Reqs:   512
  Elapsed:      47.15s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     11119.22

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:46:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:46:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=363758) WARNING 01-26 07:46:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=363758) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363758) WARNING 01-26 07:47:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.63 requests/s, 10894.74 total tokens/s, 10.63 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 07:46:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:46:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:46:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:46:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:46:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:46:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.33s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.09it/s]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.05s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
(EngineCore_DP0 pid=363758) 
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=363758) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  4.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.13it/s]
(EngineCore_DP0 pid=363758) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:01,  2.42it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.34it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  4.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 218.43it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 236.18it/s]
Adding requests:   7%|▋         | 74/1024 [00:00<00:03, 245.83it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:03, 245.91it/s]
Adding requests:  12%|█▏        | 124/1024 [00:00<00:03, 246.76it/s]
Adding requests:  15%|█▍        | 149/1024 [00:00<00:03, 237.83it/s]
Adding requests:  17%|█▋        | 173/1024 [00:00<00:03, 237.17it/s]
Adding requests:  19%|█▉        | 199/1024 [00:00<00:03, 241.81it/s]
Adding requests:  22%|██▏       | 225/1024 [00:00<00:03, 245.28it/s]
Adding requests:  24%|██▍       | 250/1024 [00:01<00:03, 244.34it/s]
Adding requests:  27%|██▋       | 275/1024 [00:01<00:03, 245.08it/s]
Adding requests:  29%|██▉       | 301/1024 [00:01<00:02, 247.94it/s]
Adding requests:  32%|███▏      | 327/1024 [00:01<00:02, 251.09it/s]
Adding requests:  35%|███▍      | 356/1024 [00:01<00:02, 261.49it/s]
Adding requests:  38%|███▊      | 384/1024 [00:01<00:02, 265.41it/s]
Adding requests:  40%|████      | 413/1024 [00:01<00:02, 269.78it/s]
Adding requests:  43%|████▎     | 440/1024 [00:01<00:02, 264.44it/s]
Adding requests:  46%|████▌     | 467/1024 [00:01<00:02, 262.48it/s]
Adding requests:  49%|████▊     | 497/1024 [00:01<00:01, 270.36it/s]
Adding requests:  52%|█████▏    | 528/1024 [00:02<00:01, 279.36it/s]
Adding requests:  54%|█████▍    | 556/1024 [00:02<00:01, 269.62it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:02<00:01, 266.38it/s]
Adding requests:  60%|█████▉    | 611/1024 [00:02<00:01, 261.73it/s]
Adding requests:  62%|██████▏   | 638/1024 [00:02<00:01, 262.70it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:02<00:01, 259.18it/s]
Adding requests:  68%|██████▊   | 693/1024 [00:02<00:01, 264.63it/s]
Adding requests:  70%|███████   | 720/1024 [00:02<00:01, 259.67it/s]
Adding requests:  73%|███████▎  | 747/1024 [00:02<00:01, 257.76it/s]
Adding requests:  76%|███████▌  | 774/1024 [00:03<00:00, 258.92it/s]
Adding requests:  78%|███████▊  | 800/1024 [00:03<00:00, 257.81it/s]
Adding requests:  81%|████████  | 827/1024 [00:03<00:00, 260.23it/s]
Adding requests:  83%|████████▎ | 854/1024 [00:03<00:00, 258.64it/s]
Adding requests:  86%|████████▌ | 880/1024 [00:03<00:00, 258.64it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:03<00:00, 262.65it/s]
Adding requests:  91%|█████████▏| 935/1024 [00:03<00:00, 252.89it/s]
Adding requests:  94%|█████████▍| 961/1024 [00:03<00:00, 252.15it/s]
Adding requests:  96%|█████████▋| 987/1024 [00:03<00:00, 251.14it/s]
Adding requests:  99%|█████████▉| 1013/1024 [00:03<00:00, 244.82it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 255.11it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 34/1024 [00:00<00:19, 51.66it/s, est. speed input: 52897.63 toks/s, output: 51.66 toks/s]
Processed prompts:   4%|▍         | 42/1024 [00:01<00:36, 26.62it/s, est. speed input: 30892.76 toks/s, output: 30.17 toks/s]
Processed prompts:   5%|▍         | 50/1024 [00:02<00:50, 19.11it/s, est. speed input: 23932.28 toks/s, output: 23.37 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:02<01:01, 15.83it/s, est. speed input: 20666.72 toks/s, output: 20.18 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:03<01:08, 14.04it/s, est. speed input: 18727.78 toks/s, output: 18.29 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:04<00:46, 20.12it/s, est. speed input: 21074.06 toks/s, output: 20.58 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:05<00:54, 17.11it/s, est. speed input: 19642.23 toks/s, output: 19.18 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:05<01:01, 15.05it/s, est. speed input: 18529.61 toks/s, output: 18.10 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:06<01:06, 13.75it/s, est. speed input: 17702.26 toks/s, output: 17.29 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:07<01:10, 12.86it/s, est. speed input: 17039.39 toks/s, output: 16.64 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:08<01:13, 12.24it/s, est. speed input: 16496.95 toks/s, output: 16.11 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:08<01:14, 11.82it/s, est. speed input: 16045.46 toks/s, output: 15.67 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:09<01:16, 11.52it/s, est. speed input: 15662.44 toks/s, output: 15.30 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:10<01:16, 11.31it/s, est. speed input: 15333.74 toks/s, output: 14.97 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:11<01:17, 11.11it/s, est. speed input: 15032.06 toks/s, output: 14.68 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:11<01:17, 11.02it/s, est. speed input: 14784.05 toks/s, output: 14.44 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:12<01:17, 10.96it/s, est. speed input: 14564.56 toks/s, output: 14.22 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:13<01:16, 10.91it/s, est. speed input: 14369.37 toks/s, output: 14.03 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:13<01:16, 10.88it/s, est. speed input: 14194.83 toks/s, output: 13.86 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:14<01:15, 10.86it/s, est. speed input: 14037.29 toks/s, output: 13.71 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:15<01:15, 10.84it/s, est. speed input: 13894.82 toks/s, output: 13.57 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:16<01:14, 10.78it/s, est. speed input: 13755.16 toks/s, output: 13.43 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:16<01:13, 10.78it/s, est. speed input: 13637.53 toks/s, output: 13.32 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:17<01:13, 10.78it/s, est. speed input: 13529.06 toks/s, output: 13.21 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:18<01:12, 10.79it/s, est. speed input: 13429.16 toks/s, output: 13.11 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:19<01:11, 10.78it/s, est. speed input: 13336.90 toks/s, output: 13.02 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:19<01:11, 10.78it/s, est. speed input: 13251.36 toks/s, output: 12.94 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:20<01:10, 10.78it/s, est. speed input: 13171.89 toks/s, output: 12.86 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:21<01:09, 10.73it/s, est. speed input: 13090.60 toks/s, output: 12.78 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:22<01:09, 10.74it/s, est. speed input: 13021.98 toks/s, output: 12.72 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:22<01:08, 10.75it/s, est. speed input: 12957.35 toks/s, output: 12.65 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:23<01:07, 10.76it/s, est. speed input: 12896.93 toks/s, output: 12.59 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:24<01:06, 10.76it/s, est. speed input: 12840.17 toks/s, output: 12.54 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:25<01:05, 10.76it/s, est. speed input: 12786.67 toks/s, output: 12.49 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:25<01:05, 10.76it/s, est. speed input: 12735.91 toks/s, output: 12.44 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:26<01:04, 10.70it/s, est. speed input: 12681.42 toks/s, output: 12.38 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:27<01:03, 10.72it/s, est. speed input: 12636.46 toks/s, output: 12.34 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:28<01:03, 10.73it/s, est. speed input: 12593.45 toks/s, output: 12.30 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:28<01:02, 10.74it/s, est. speed input: 12552.76 toks/s, output: 12.26 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:29<01:01, 10.75it/s, est. speed input: 12514.33 toks/s, output: 12.22 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:30<01:00, 10.75it/s, est. speed input: 12477.80 toks/s, output: 12.19 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:31<01:00, 10.75it/s, est. speed input: 12442.80 toks/s, output: 12.15 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:31<00:59, 10.70it/s, est. speed input: 12404.65 toks/s, output: 12.11 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:32<00:58, 10.72it/s, est. speed input: 12373.41 toks/s, output: 12.08 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:33<00:57, 10.73it/s, est. speed input: 12343.13 toks/s, output: 12.05 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:34<00:57, 10.74it/s, est. speed input: 12314.01 toks/s, output: 12.03 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:34<00:56, 10.75it/s, est. speed input: 12286.47 toks/s, output: 12.00 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:35<00:34, 16.81it/s, est. speed input: 12700.08 toks/s, output: 12.40 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:36<00:38, 15.03it/s, est. speed input: 12666.07 toks/s, output: 12.37 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:37<00:41, 13.76it/s, est. speed input: 12632.66 toks/s, output: 12.34 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:37<00:43, 12.86it/s, est. speed input: 12600.81 toks/s, output: 12.31 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:38<00:44, 12.23it/s, est. speed input: 12569.91 toks/s, output: 12.28 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:39<00:45, 11.79it/s, est. speed input: 12540.46 toks/s, output: 12.25 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:40<00:46, 11.48it/s, est. speed input: 12511.91 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:40<00:46, 11.26it/s, est. speed input: 12484.45 toks/s, output: 12.19 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:41<00:47, 10.92it/s, est. speed input: 12445.43 toks/s, output: 12.15 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:42<00:46, 10.86it/s, est. speed input: 12419.55 toks/s, output: 12.13 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:43<00:46, 10.83it/s, est. speed input: 12395.03 toks/s, output: 12.10 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:43<00:45, 10.80it/s, est. speed input: 12371.58 toks/s, output: 12.08 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:44<00:45, 10.78it/s, est. speed input: 12348.27 toks/s, output: 12.06 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:45<00:44, 10.77it/s, est. speed input: 12326.18 toks/s, output: 12.04 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:46<00:43, 10.76it/s, est. speed input: 12304.46 toks/s, output: 12.02 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:46<00:43, 10.71it/s, est. speed input: 12280.92 toks/s, output: 11.99 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:47<00:42, 10.71it/s, est. speed input: 12260.66 toks/s, output: 11.97 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:48<00:41, 10.72it/s, est. speed input: 12241.10 toks/s, output: 11.95 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:49<00:40, 10.72it/s, est. speed input: 12222.14 toks/s, output: 11.94 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:49<00:40, 10.72it/s, est. speed input: 12203.60 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:50<00:39, 10.73it/s, est. speed input: 12185.66 toks/s, output: 11.90 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:51<00:38, 10.73it/s, est. speed input: 12168.26 toks/s, output: 11.88 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:52<00:37, 10.69it/s, est. speed input: 12149.04 toks/s, output: 11.86 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:52<00:37, 10.70it/s, est. speed input: 12132.51 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:53<00:36, 10.71it/s, est. speed input: 12116.78 toks/s, output: 11.83 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:54<00:35, 10.72it/s, est. speed input: 12101.24 toks/s, output: 11.82 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:55<00:34, 10.72it/s, est. speed input: 12085.94 toks/s, output: 11.80 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:55<00:34, 10.71it/s, est. speed input: 12070.85 toks/s, output: 11.79 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:56<00:33, 10.71it/s, est. speed input: 12056.16 toks/s, output: 11.77 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:57<00:33, 10.54it/s, est. speed input: 12033.74 toks/s, output: 11.75 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:58<00:32, 10.59it/s, est. speed input: 12019.87 toks/s, output: 11.74 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:58<00:31, 10.63it/s, est. speed input: 12006.75 toks/s, output: 11.73 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:59<00:30, 10.66it/s, est. speed input: 11993.91 toks/s, output: 11.71 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [01:00<00:29, 10.67it/s, est. speed input: 11981.15 toks/s, output: 11.70 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [01:01<00:29, 10.69it/s, est. speed input: 11968.82 toks/s, output: 11.69 toks/s]
Processed prompts:  71%|███████   | 722/1024 [01:01<00:28, 10.70it/s, est. speed input: 11956.92 toks/s, output: 11.68 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [01:02<00:27, 10.66it/s, est. speed input: 11943.26 toks/s, output: 11.66 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [01:03<00:26, 10.68it/s, est. speed input: 11931.93 toks/s, output: 11.65 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [01:04<00:25, 10.69it/s, est. speed input: 11920.94 toks/s, output: 11.64 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [01:04<00:25, 10.70it/s, est. speed input: 11910.09 toks/s, output: 11.63 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [01:05<00:24, 10.71it/s, est. speed input: 11899.39 toks/s, output: 11.62 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [01:06<00:14, 16.76it/s, est. speed input: 12125.95 toks/s, output: 11.84 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [01:07<00:15, 14.98it/s, est. speed input: 12113.28 toks/s, output: 11.83 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [01:07<00:16, 13.72it/s, est. speed input: 12100.99 toks/s, output: 11.82 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [01:08<00:16, 12.83it/s, est. speed input: 12088.89 toks/s, output: 11.81 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [01:09<00:16, 12.21it/s, est. speed input: 12077.02 toks/s, output: 11.79 toks/s]
Processed prompts:  81%|████████  | 826/1024 [01:10<00:16, 11.77it/s, est. speed input: 12065.46 toks/s, output: 11.78 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [01:10<00:16, 11.45it/s, est. speed input: 12054.07 toks/s, output: 11.77 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [01:11<00:16, 11.19it/s, est. speed input: 12041.09 toks/s, output: 11.76 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [01:12<00:15, 11.05it/s, est. speed input: 12030.14 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [01:13<00:15, 10.95it/s, est. speed input: 12019.45 toks/s, output: 11.74 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [01:13<00:14, 10.89it/s, est. speed input: 12009.06 toks/s, output: 11.73 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [01:14<00:13, 10.83it/s, est. speed input: 11998.52 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [01:15<00:13, 10.80it/s, est. speed input: 11988.33 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [01:16<00:12, 10.77it/s, est. speed input: 11978.31 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [01:16<00:11, 10.70it/s, est. speed input: 11966.74 toks/s, output: 11.69 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [01:17<00:11, 10.70it/s, est. speed input: 11956.87 toks/s, output: 11.68 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [01:18<00:10, 10.70it/s, est. speed input: 11947.51 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [01:19<00:09, 10.70it/s, est. speed input: 11938.20 toks/s, output: 11.66 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [01:19<00:08, 10.71it/s, est. speed input: 11929.12 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [01:20<00:08, 10.70it/s, est. speed input: 11920.10 toks/s, output: 11.64 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [01:21<00:07, 10.71it/s, est. speed input: 11911.31 toks/s, output: 11.63 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [01:22<00:06, 10.66it/s, est. speed input: 11901.13 toks/s, output: 11.62 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [01:22<00:05, 10.67it/s, est. speed input: 11892.44 toks/s, output: 11.61 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [01:23<00:05, 10.68it/s, est. speed input: 11884.05 toks/s, output: 11.61 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [01:24<00:04, 10.68it/s, est. speed input: 11875.84 toks/s, output: 11.60 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [01:25<00:03, 10.69it/s, est. speed input: 11867.66 toks/s, output: 11.59 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [01:25<00:02, 10.68it/s, est. speed input: 11859.54 toks/s, output: 11.58 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [01:26<00:02, 10.69it/s, est. speed input: 11851.65 toks/s, output: 11.57 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [01:27<00:01, 10.65it/s, est. speed input: 11842.57 toks/s, output: 11.57 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [01:27<00:00, 11.04it/s, est. speed input: 11846.57 toks/s, output: 11.57 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:27<00:00, 11.04it/s, est. speed input: 11916.35 toks/s, output: 11.64 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:27<00:00, 11.64it/s, est. speed input: 11916.35 toks/s, output: 11.64 toks/s]
[rank0]:[W126 07:49:05.368082117 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 163.0s

测试结果:
  Requests/s:   10.63
  Tokens/s:     10894.74
  Total Reqs:   1024
  Elapsed:      96.34s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     10884.11

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:49:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:49:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=366367) WARNING 01-26 07:49:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=366367) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=366367) WARNING 01-26 07:49:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.68 requests/s, 10948.65 total tokens/s, 10.68 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 07:49:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:49:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:49:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:49:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:49:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:49:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.28s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.30s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.12it/s]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.04s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.07s/it]
(EngineCore_DP0 pid=366367) 
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:12.900000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:12.979000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:14.157000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:14.275000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  4.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  4.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  5.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  5.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.97it/s]
(EngineCore_DP0 pid=366367) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:01,  3.59it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.53it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  4.15it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.39it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/2048 [00:00<00:09, 207.10it/s]
Adding requests:   2%|▏         | 47/2048 [00:00<00:08, 237.08it/s]
Adding requests:   4%|▎         | 73/2048 [00:00<00:08, 242.58it/s]
Adding requests:   5%|▍         | 98/2048 [00:00<00:08, 242.88it/s]
Adding requests:   6%|▌         | 124/2048 [00:00<00:07, 247.01it/s]
Adding requests:   7%|▋         | 150/2048 [00:00<00:07, 250.09it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:07, 250.49it/s]
Adding requests:  10%|▉         | 203/2048 [00:00<00:07, 253.93it/s]
Adding requests:  11%|█▏        | 231/2048 [00:00<00:07, 259.12it/s]
Adding requests:  13%|█▎        | 257/2048 [00:01<00:07, 255.68it/s]
Adding requests:  14%|█▍        | 284/2048 [00:01<00:06, 257.03it/s]
Adding requests:  15%|█▌        | 312/2048 [00:01<00:06, 262.04it/s]
Adding requests:  17%|█▋        | 340/2048 [00:01<00:06, 266.20it/s]
Adding requests:  18%|█▊        | 367/2048 [00:01<00:06, 266.95it/s]
Adding requests:  19%|█▉        | 395/2048 [00:01<00:06, 268.13it/s]
Adding requests:  21%|██        | 424/2048 [00:01<00:05, 271.45it/s]
Adding requests:  22%|██▏       | 452/2048 [00:01<00:05, 267.08it/s]
Adding requests:  23%|██▎       | 481/2048 [00:01<00:05, 273.25it/s]
Adding requests:  25%|██▍       | 510/2048 [00:01<00:05, 276.16it/s]
Adding requests:  26%|██▋       | 538/2048 [00:02<00:05, 276.57it/s]
Adding requests:  28%|██▊       | 566/2048 [00:02<00:05, 275.34it/s]
Adding requests:  29%|██▉       | 594/2048 [00:02<00:05, 261.40it/s]
Adding requests:  30%|███       | 621/2048 [00:02<00:05, 260.63it/s]
Adding requests:  32%|███▏      | 648/2048 [00:02<00:05, 257.08it/s]
Adding requests:  33%|███▎      | 674/2048 [00:02<00:05, 254.99it/s]
Adding requests:  34%|███▍      | 702/2048 [00:02<00:05, 261.14it/s]
Adding requests:  36%|███▌      | 729/2048 [00:02<00:05, 256.23it/s]
Adding requests:  37%|███▋      | 755/2048 [00:02<00:05, 256.56it/s]
Adding requests:  38%|███▊      | 782/2048 [00:03<00:04, 257.67it/s]
Adding requests:  39%|███▉      | 808/2048 [00:03<00:04, 256.39it/s]
Adding requests:  41%|████      | 835/2048 [00:03<00:04, 259.44it/s]
Adding requests:  42%|████▏     | 861/2048 [00:03<00:04, 252.35it/s]
Adding requests:  43%|████▎     | 888/2048 [00:03<00:04, 256.87it/s]
Adding requests:  45%|████▍     | 914/2048 [00:03<00:04, 254.00it/s]
Adding requests:  46%|████▌     | 940/2048 [00:03<00:04, 253.53it/s]
Adding requests:  47%|████▋     | 966/2048 [00:03<00:04, 252.08it/s]
Adding requests:  48%|████▊     | 992/2048 [00:03<00:04, 248.91it/s]
Adding requests:  50%|████▉     | 1017/2048 [00:03<00:04, 248.26it/s]
Adding requests:  51%|█████     | 1044/2048 [00:04<00:03, 252.57it/s]
Adding requests:  52%|█████▏    | 1070/2048 [00:04<00:03, 250.96it/s]
Adding requests:  54%|█████▎    | 1096/2048 [00:04<00:03, 248.33it/s]
Adding requests:  55%|█████▍    | 1124/2048 [00:04<00:03, 254.58it/s]
Adding requests:  56%|█████▌    | 1151/2048 [00:04<00:03, 257.40it/s]
Adding requests:  58%|█████▊    | 1178/2048 [00:04<00:03, 258.60it/s]
Adding requests:  59%|█████▉    | 1205/2048 [00:04<00:03, 261.02it/s]
Adding requests:  60%|██████    | 1233/2048 [00:04<00:03, 265.06it/s]
Adding requests:  62%|██████▏   | 1260/2048 [00:04<00:03, 261.06it/s]
Adding requests:  63%|██████▎   | 1287/2048 [00:04<00:02, 259.28it/s]
Adding requests:  64%|██████▍   | 1314/2048 [00:05<00:02, 261.30it/s]
Adding requests:  65%|██████▌   | 1341/2048 [00:05<00:02, 258.67it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:05<00:02, 263.35it/s]
Adding requests:  68%|██████▊   | 1396/2048 [00:05<00:02, 261.97it/s]
Adding requests:  69%|██████▉   | 1423/2048 [00:05<00:02, 261.97it/s]
Adding requests:  71%|███████   | 1450/2048 [00:05<00:02, 262.98it/s]
Adding requests:  72%|███████▏  | 1477/2048 [00:05<00:02, 264.88it/s]
Adding requests:  73%|███████▎  | 1505/2048 [00:05<00:02, 266.62it/s]
Adding requests:  75%|███████▍  | 1532/2048 [00:05<00:01, 262.98it/s]
Adding requests:  76%|███████▌  | 1559/2048 [00:06<00:01, 256.63it/s]
Adding requests:  77%|███████▋  | 1585/2048 [00:06<00:01, 253.61it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:06<00:01, 248.96it/s]
Adding requests:  80%|███████▉  | 1636/2048 [00:06<00:01, 241.29it/s]
Adding requests:  81%|████████  | 1661/2048 [00:06<00:01, 232.85it/s]
Adding requests:  82%|████████▏ | 1688/2048 [00:06<00:01, 240.93it/s]
Adding requests:  84%|████████▎ | 1715/2048 [00:06<00:01, 247.77it/s]
Adding requests:  85%|████████▍ | 1740/2048 [00:06<00:01, 246.34it/s]
Adding requests:  86%|████████▋ | 1769/2048 [00:06<00:01, 256.69it/s]
Adding requests:  88%|████████▊ | 1795/2048 [00:06<00:01, 252.21it/s]
Adding requests:  89%|████████▉ | 1821/2048 [00:07<00:00, 251.08it/s]
Adding requests:  90%|█████████ | 1847/2048 [00:07<00:00, 243.76it/s]
Adding requests:  91%|█████████▏| 1872/2048 [00:07<00:00, 222.60it/s]
Adding requests:  93%|█████████▎| 1896/2048 [00:07<00:00, 225.12it/s]
Adding requests:  94%|█████████▍| 1924/2048 [00:07<00:00, 239.41it/s]
Adding requests:  95%|█████████▌| 1952/2048 [00:07<00:00, 250.73it/s]
Adding requests:  97%|█████████▋| 1979/2048 [00:07<00:00, 254.65it/s]
Adding requests:  98%|█████████▊| 2005/2048 [00:07<00:00, 253.89it/s]
Adding requests:  99%|█████████▉| 2031/2048 [00:07<00:00, 250.90it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 254.80it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:00<00:19, 103.41it/s, est. speed input: 105900.81 toks/s, output: 103.42 toks/s]
Processed prompts:   5%|▍         | 93/2048 [00:01<00:36, 52.96it/s, est. speed input: 62266.05 toks/s, output: 60.81 toks/s]   
Processed prompts:   5%|▍         | 99/2048 [00:02<00:59, 32.83it/s, est. speed input: 44729.05 toks/s, output: 43.68 toks/s]
Processed prompts:   5%|▌         | 106/2048 [00:03<01:21, 23.70it/s, est. speed input: 36124.51 toks/s, output: 35.28 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:03<01:41, 19.09it/s, est. speed input: 31191.79 toks/s, output: 30.46 toks/s]
Processed prompts:   6%|▌         | 122/2048 [00:04<01:58, 16.30it/s, est. speed input: 27883.51 toks/s, output: 27.23 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:05<02:12, 14.51it/s, est. speed input: 25507.42 toks/s, output: 24.91 toks/s]
Processed prompts:   7%|▋         | 138/2048 [00:05<02:23, 13.34it/s, est. speed input: 23719.96 toks/s, output: 23.16 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:06<02:31, 12.56it/s, est. speed input: 22326.21 toks/s, output: 21.80 toks/s]
Processed prompts:   8%|▊         | 154/2048 [00:07<02:37, 12.02it/s, est. speed input: 21208.22 toks/s, output: 20.71 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:08<02:41, 11.65it/s, est. speed input: 20292.27 toks/s, output: 19.82 toks/s]
Processed prompts:   8%|▊         | 170/2048 [00:08<02:44, 11.40it/s, est. speed input: 19527.43 toks/s, output: 19.07 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:09<02:46, 11.22it/s, est. speed input: 18879.22 toks/s, output: 18.44 toks/s]
Processed prompts:   9%|▉         | 186/2048 [00:10<02:47, 11.10it/s, est. speed input: 18323.42 toks/s, output: 17.89 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:11<02:48, 11.01it/s, est. speed input: 17840.66 toks/s, output: 17.42 toks/s]
Processed prompts:  10%|▉         | 202/2048 [00:11<02:48, 10.94it/s, est. speed input: 17416.94 toks/s, output: 17.01 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:12<02:48, 10.89it/s, est. speed input: 17041.43 toks/s, output: 16.64 toks/s]
Processed prompts:  11%|█         | 218/2048 [00:13<02:48, 10.86it/s, est. speed input: 16707.95 toks/s, output: 16.32 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:14<02:48, 10.83it/s, est. speed input: 16409.23 toks/s, output: 16.02 toks/s]
Processed prompts:  11%|█▏        | 234/2048 [00:14<02:47, 10.81it/s, est. speed input: 16140.03 toks/s, output: 15.76 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:15<02:47, 10.80it/s, est. speed input: 15896.35 toks/s, output: 15.52 toks/s]
Processed prompts:  13%|█▎        | 266/2048 [00:16<01:45, 16.91it/s, est. speed input: 16626.46 toks/s, output: 16.24 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:17<01:57, 15.09it/s, est. speed input: 16382.94 toks/s, output: 16.00 toks/s]
Processed prompts:  14%|█▍        | 282/2048 [00:17<02:07, 13.80it/s, est. speed input: 16159.42 toks/s, output: 15.78 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:18<02:16, 12.89it/s, est. speed input: 15953.67 toks/s, output: 15.58 toks/s]
Processed prompts:  15%|█▍        | 298/2048 [00:19<02:22, 12.25it/s, est. speed input: 15763.99 toks/s, output: 15.39 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:20<02:27, 11.80it/s, est. speed input: 15587.16 toks/s, output: 15.22 toks/s]
Processed prompts:  15%|█▌        | 314/2048 [00:20<02:31, 11.48it/s, est. speed input: 15423.17 toks/s, output: 15.06 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:21<02:33, 11.23it/s, est. speed input: 15265.60 toks/s, output: 14.91 toks/s]
Processed prompts:  16%|█▌        | 330/2048 [00:22<02:35, 11.08it/s, est. speed input: 15122.96 toks/s, output: 14.77 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:23<02:35, 10.98it/s, est. speed input: 14989.60 toks/s, output: 14.64 toks/s]
Processed prompts:  17%|█▋        | 346/2048 [00:23<02:36, 10.90it/s, est. speed input: 14864.67 toks/s, output: 14.52 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:24<02:36, 10.86it/s, est. speed input: 14747.56 toks/s, output: 14.40 toks/s]
Processed prompts:  18%|█▊        | 362/2048 [00:25<02:35, 10.82it/s, est. speed input: 14636.97 toks/s, output: 14.29 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:26<02:35, 10.79it/s, est. speed input: 14532.90 toks/s, output: 14.19 toks/s]
Processed prompts:  18%|█▊        | 378/2048 [00:26<02:34, 10.78it/s, est. speed input: 14434.69 toks/s, output: 14.10 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:27<02:34, 10.76it/s, est. speed input: 14341.58 toks/s, output: 14.01 toks/s]
Processed prompts:  19%|█▉        | 394/2048 [00:28<02:33, 10.76it/s, est. speed input: 14254.00 toks/s, output: 13.92 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:29<02:32, 10.76it/s, est. speed input: 14171.11 toks/s, output: 13.84 toks/s]
Processed prompts:  20%|██        | 410/2048 [00:29<02:32, 10.76it/s, est. speed input: 14092.02 toks/s, output: 13.76 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:30<02:31, 10.75it/s, est. speed input: 14016.38 toks/s, output: 13.69 toks/s]
Processed prompts:  21%|██        | 426/2048 [00:31<02:30, 10.75it/s, est. speed input: 13944.62 toks/s, output: 13.62 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:32<02:30, 10.75it/s, est. speed input: 13876.41 toks/s, output: 13.55 toks/s]
Processed prompts:  22%|██▏       | 442/2048 [00:32<02:29, 10.74it/s, est. speed input: 13810.83 toks/s, output: 13.49 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:33<02:28, 10.73it/s, est. speed input: 13747.45 toks/s, output: 13.43 toks/s]
Processed prompts:  22%|██▏       | 458/2048 [00:34<02:28, 10.73it/s, est. speed input: 13686.84 toks/s, output: 13.37 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:35<02:27, 10.72it/s, est. speed input: 13628.82 toks/s, output: 13.31 toks/s]
Processed prompts:  23%|██▎       | 474/2048 [00:35<02:26, 10.72it/s, est. speed input: 13573.52 toks/s, output: 13.26 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:36<02:26, 10.71it/s, est. speed input: 13519.82 toks/s, output: 13.20 toks/s]
Processed prompts:  24%|██▍       | 490/2048 [00:37<02:25, 10.71it/s, est. speed input: 13468.56 toks/s, output: 13.15 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:38<02:24, 10.71it/s, est. speed input: 13419.14 toks/s, output: 13.10 toks/s]
Processed prompts:  25%|██▍       | 506/2048 [00:38<02:24, 10.71it/s, est. speed input: 13371.59 toks/s, output: 13.06 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:39<02:23, 10.71it/s, est. speed input: 13326.08 toks/s, output: 13.01 toks/s]
Processed prompts:  25%|██▌       | 522/2048 [00:40<02:22, 10.71it/s, est. speed input: 13282.20 toks/s, output: 12.97 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:40<02:21, 10.71it/s, est. speed input: 13239.91 toks/s, output: 12.93 toks/s]
Processed prompts:  26%|██▋       | 538/2048 [00:41<02:21, 10.70it/s, est. speed input: 13198.99 toks/s, output: 12.89 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:42<02:20, 10.71it/s, est. speed input: 13159.83 toks/s, output: 12.85 toks/s]
Processed prompts:  27%|██▋       | 554/2048 [00:43<02:19, 10.71it/s, est. speed input: 13121.79 toks/s, output: 12.81 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:43<02:18, 10.70it/s, est. speed input: 13085.00 toks/s, output: 12.78 toks/s]
Processed prompts:  28%|██▊       | 570/2048 [00:44<02:18, 10.71it/s, est. speed input: 13049.61 toks/s, output: 12.74 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:45<02:17, 10.71it/s, est. speed input: 13015.28 toks/s, output: 12.71 toks/s]
Processed prompts:  29%|██▊       | 586/2048 [00:46<02:16, 10.71it/s, est. speed input: 12982.30 toks/s, output: 12.68 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:47<01:25, 16.91it/s, est. speed input: 13289.68 toks/s, output: 12.98 toks/s]
Processed prompts:  30%|███       | 618/2048 [00:47<01:34, 15.07it/s, est. speed input: 13253.48 toks/s, output: 12.94 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:48<01:43, 13.77it/s, est. speed input: 13218.11 toks/s, output: 12.91 toks/s]
Processed prompts:  31%|███       | 634/2048 [00:49<01:50, 12.85it/s, est. speed input: 13183.68 toks/s, output: 12.87 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:49<01:55, 12.21it/s, est. speed input: 13150.48 toks/s, output: 12.84 toks/s]
Processed prompts:  32%|███▏      | 650/2048 [00:50<01:58, 11.76it/s, est. speed input: 13118.16 toks/s, output: 12.81 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:51<02:01, 11.44it/s, est. speed input: 13086.83 toks/s, output: 12.78 toks/s]
Processed prompts:  33%|███▎      | 666/2048 [00:52<02:03, 11.22it/s, est. speed input: 13056.34 toks/s, output: 12.75 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:52<02:04, 11.07it/s, est. speed input: 13026.95 toks/s, output: 12.72 toks/s]
Processed prompts:  33%|███▎      | 682/2048 [00:53<02:04, 10.96it/s, est. speed input: 12998.33 toks/s, output: 12.69 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:54<02:04, 10.88it/s, est. speed input: 12970.21 toks/s, output: 12.67 toks/s]
Processed prompts:  34%|███▍      | 698/2048 [00:55<02:04, 10.83it/s, est. speed input: 12943.02 toks/s, output: 12.64 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:55<02:04, 10.79it/s, est. speed input: 12916.42 toks/s, output: 12.61 toks/s]
Processed prompts:  35%|███▍      | 714/2048 [00:56<02:03, 10.76it/s, est. speed input: 12890.48 toks/s, output: 12.59 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:57<02:03, 10.74it/s, est. speed input: 12865.34 toks/s, output: 12.56 toks/s]
Processed prompts:  36%|███▌      | 730/2048 [00:58<02:02, 10.73it/s, est. speed input: 12840.96 toks/s, output: 12.54 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:58<02:02, 10.72it/s, est. speed input: 12817.06 toks/s, output: 12.52 toks/s]
Processed prompts:  36%|███▋      | 746/2048 [00:59<02:01, 10.72it/s, est. speed input: 12793.76 toks/s, output: 12.49 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [01:00<02:00, 10.71it/s, est. speed input: 12771.02 toks/s, output: 12.47 toks/s]
Processed prompts:  37%|███▋      | 762/2048 [01:01<02:00, 10.71it/s, est. speed input: 12748.85 toks/s, output: 12.45 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [01:01<01:59, 10.71it/s, est. speed input: 12727.44 toks/s, output: 12.43 toks/s]
Processed prompts:  38%|███▊      | 778/2048 [01:02<01:58, 10.70it/s, est. speed input: 12706.17 toks/s, output: 12.41 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [01:03<01:57, 10.70it/s, est. speed input: 12685.58 toks/s, output: 12.39 toks/s]
Processed prompts:  39%|███▉      | 794/2048 [01:04<01:57, 10.71it/s, est. speed input: 12665.59 toks/s, output: 12.37 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [01:04<01:56, 10.71it/s, est. speed input: 12645.98 toks/s, output: 12.35 toks/s]
Processed prompts:  40%|███▉      | 810/2048 [01:05<01:55, 10.70it/s, est. speed input: 12626.81 toks/s, output: 12.33 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [01:06<01:54, 10.71it/s, est. speed input: 12608.19 toks/s, output: 12.31 toks/s]
Processed prompts:  40%|████      | 826/2048 [01:07<01:54, 10.71it/s, est. speed input: 12589.86 toks/s, output: 12.29 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:07<01:53, 10.70it/s, est. speed input: 12571.91 toks/s, output: 12.28 toks/s]
Processed prompts:  41%|████      | 842/2048 [01:08<01:52, 10.70it/s, est. speed input: 12554.30 toks/s, output: 12.26 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:09<01:51, 10.70it/s, est. speed input: 12537.16 toks/s, output: 12.24 toks/s]
Processed prompts:  42%|████▏     | 858/2048 [01:10<01:51, 10.70it/s, est. speed input: 12520.33 toks/s, output: 12.23 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:10<01:50, 10.70it/s, est. speed input: 12503.82 toks/s, output: 12.21 toks/s]
Processed prompts:  43%|████▎     | 874/2048 [01:11<01:49, 10.70it/s, est. speed input: 12487.72 toks/s, output: 12.20 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [01:12<01:48, 10.70it/s, est. speed input: 12471.89 toks/s, output: 12.18 toks/s]
Processed prompts:  43%|████▎     | 890/2048 [01:13<01:48, 10.70it/s, est. speed input: 12456.54 toks/s, output: 12.16 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:13<01:47, 10.70it/s, est. speed input: 12441.26 toks/s, output: 12.15 toks/s]
Processed prompts:  44%|████▍     | 906/2048 [01:14<01:46, 10.70it/s, est. speed input: 12426.43 toks/s, output: 12.14 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:15<01:45, 10.70it/s, est. speed input: 12411.86 toks/s, output: 12.12 toks/s]
Processed prompts:  45%|████▌     | 922/2048 [01:16<01:45, 10.70it/s, est. speed input: 12397.46 toks/s, output: 12.11 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:16<01:44, 10.70it/s, est. speed input: 12383.53 toks/s, output: 12.09 toks/s]
Processed prompts:  46%|████▌     | 938/2048 [01:17<01:43, 10.70it/s, est. speed input: 12369.74 toks/s, output: 12.08 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:18<01:04, 16.78it/s, est. speed input: 12557.18 toks/s, output: 12.26 toks/s]
Processed prompts:  47%|████▋     | 970/2048 [01:19<01:11, 14.98it/s, est. speed input: 12542.09 toks/s, output: 12.25 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:19<01:18, 13.71it/s, est. speed input: 12527.32 toks/s, output: 12.23 toks/s]
Processed prompts:  48%|████▊     | 986/2048 [01:20<01:22, 12.82it/s, est. speed input: 12512.87 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:21<01:26, 12.19it/s, est. speed input: 12498.64 toks/s, output: 12.21 toks/s]
Processed prompts:  49%|████▉     | 1002/2048 [01:22<01:29, 11.75it/s, est. speed input: 12484.71 toks/s, output: 12.19 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:22<01:30, 11.43it/s, est. speed input: 12470.94 toks/s, output: 12.18 toks/s]
Processed prompts:  50%|████▉     | 1018/2048 [01:23<01:31, 11.21it/s, est. speed input: 12457.45 toks/s, output: 12.17 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:24<01:32, 11.06it/s, est. speed input: 12444.20 toks/s, output: 12.15 toks/s]
Processed prompts:  50%|█████     | 1034/2048 [01:25<01:32, 10.95it/s, est. speed input: 12431.13 toks/s, output: 12.14 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:25<01:32, 10.87it/s, est. speed input: 12418.17 toks/s, output: 12.13 toks/s]
Processed prompts:  51%|█████▏    | 1050/2048 [01:26<01:32, 10.82it/s, est. speed input: 12405.68 toks/s, output: 12.11 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:27<01:31, 10.79it/s, est. speed input: 12393.24 toks/s, output: 12.10 toks/s]
Processed prompts:  52%|█████▏    | 1066/2048 [01:28<01:31, 10.76it/s, est. speed input: 12380.98 toks/s, output: 12.09 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:28<01:30, 10.74it/s, est. speed input: 12368.93 toks/s, output: 12.08 toks/s]
Processed prompts:  53%|█████▎    | 1082/2048 [01:29<01:30, 10.72it/s, est. speed input: 12357.06 toks/s, output: 12.07 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:30<01:29, 10.72it/s, est. speed input: 12345.45 toks/s, output: 12.06 toks/s]
Processed prompts:  54%|█████▎    | 1098/2048 [01:31<01:28, 10.71it/s, est. speed input: 12334.11 toks/s, output: 12.05 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:31<01:27, 10.71it/s, est. speed input: 12322.86 toks/s, output: 12.03 toks/s]
Processed prompts:  54%|█████▍    | 1114/2048 [01:32<01:27, 10.70it/s, est. speed input: 12311.77 toks/s, output: 12.02 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:33<01:26, 10.70it/s, est. speed input: 12300.96 toks/s, output: 12.01 toks/s]
Processed prompts:  55%|█████▌    | 1130/2048 [01:34<01:25, 10.70it/s, est. speed input: 12290.37 toks/s, output: 12.00 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:34<01:25, 10.70it/s, est. speed input: 12279.82 toks/s, output: 11.99 toks/s]
Processed prompts:  56%|█████▌    | 1146/2048 [01:35<01:24, 10.70it/s, est. speed input: 12269.46 toks/s, output: 11.98 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:36<01:23, 10.70it/s, est. speed input: 12259.30 toks/s, output: 11.97 toks/s]
Processed prompts:  57%|█████▋    | 1162/2048 [01:37<01:22, 10.70it/s, est. speed input: 12249.36 toks/s, output: 11.96 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:37<01:22, 10.70it/s, est. speed input: 12239.42 toks/s, output: 11.95 toks/s]
Processed prompts:  58%|█████▊    | 1178/2048 [01:38<01:21, 10.70it/s, est. speed input: 12229.61 toks/s, output: 11.94 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:39<01:20, 10.69it/s, est. speed input: 12219.94 toks/s, output: 11.93 toks/s]
Processed prompts:  58%|█████▊    | 1194/2048 [01:40<01:19, 10.69it/s, est. speed input: 12210.40 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:40<01:19, 10.70it/s, est. speed input: 12201.17 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▉    | 1210/2048 [01:41<01:18, 10.70it/s, est. speed input: 12192.01 toks/s, output: 11.91 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [01:42<01:17, 10.70it/s, est. speed input: 12182.92 toks/s, output: 11.90 toks/s]
Processed prompts:  60%|█████▉    | 1226/2048 [01:43<01:16, 10.69it/s, est. speed input: 12173.95 toks/s, output: 11.89 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:43<01:16, 10.69it/s, est. speed input: 12165.10 toks/s, output: 11.88 toks/s]
Processed prompts:  61%|██████    | 1242/2048 [01:44<01:15, 10.69it/s, est. speed input: 12156.37 toks/s, output: 11.87 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:45<01:14, 10.69it/s, est. speed input: 12147.84 toks/s, output: 11.86 toks/s]
Processed prompts:  61%|██████▏   | 1258/2048 [01:46<01:13, 10.69it/s, est. speed input: 12139.34 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:46<01:13, 10.69it/s, est. speed input: 12131.04 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 1274/2048 [01:47<01:12, 10.69it/s, est. speed input: 12122.85 toks/s, output: 11.84 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:48<01:11, 10.70it/s, est. speed input: 12114.80 toks/s, output: 11.83 toks/s]
Processed prompts:  64%|██████▍   | 1306/2048 [01:49<00:44, 16.75it/s, est. speed input: 12250.92 toks/s, output: 11.96 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:49<00:49, 14.96it/s, est. speed input: 12242.05 toks/s, output: 11.96 toks/s]
Processed prompts:  65%|██████▍   | 1322/2048 [01:50<00:53, 13.69it/s, est. speed input: 12233.36 toks/s, output: 11.95 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:51<00:56, 12.80it/s, est. speed input: 12224.71 toks/s, output: 11.94 toks/s]
Processed prompts:  65%|██████▌   | 1338/2048 [01:52<00:58, 12.18it/s, est. speed input: 12216.34 toks/s, output: 11.93 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:52<00:59, 11.73it/s, est. speed input: 12207.92 toks/s, output: 11.92 toks/s]
Processed prompts:  66%|██████▌   | 1354/2048 [01:53<01:00, 11.43it/s, est. speed input: 12199.76 toks/s, output: 11.91 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:54<01:01, 11.20it/s, est. speed input: 12191.55 toks/s, output: 11.91 toks/s]
Processed prompts:  67%|██████▋   | 1370/2048 [01:55<01:01, 11.05it/s, est. speed input: 12183.51 toks/s, output: 11.90 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:55<01:01, 10.95it/s, est. speed input: 12175.63 toks/s, output: 11.89 toks/s]
Processed prompts:  68%|██████▊   | 1386/2048 [01:56<01:00, 10.87it/s, est. speed input: 12167.79 toks/s, output: 11.88 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:57<01:00, 10.82it/s, est. speed input: 12159.99 toks/s, output: 11.87 toks/s]
Processed prompts:  68%|██████▊   | 1402/2048 [01:58<00:59, 10.78it/s, est. speed input: 12152.31 toks/s, output: 11.87 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:58<00:59, 10.75it/s, est. speed input: 12144.74 toks/s, output: 11.86 toks/s]
Processed prompts:  69%|██████▉   | 1418/2048 [01:59<00:58, 10.74it/s, est. speed input: 12137.30 toks/s, output: 11.85 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [02:00<00:58, 10.72it/s, est. speed input: 12129.93 toks/s, output: 11.85 toks/s]
Processed prompts:  70%|███████   | 1434/2048 [02:01<00:57, 10.71it/s, est. speed input: 12122.63 toks/s, output: 11.84 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [02:01<00:56, 10.70it/s, est. speed input: 12115.32 toks/s, output: 11.83 toks/s]
Processed prompts:  71%|███████   | 1450/2048 [02:02<00:55, 10.70it/s, est. speed input: 12108.19 toks/s, output: 11.82 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [02:03<00:55, 10.70it/s, est. speed input: 12101.12 toks/s, output: 11.82 toks/s]
Processed prompts:  72%|███████▏  | 1466/2048 [02:04<00:54, 10.69it/s, est. speed input: 12094.11 toks/s, output: 11.81 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [02:04<00:53, 10.69it/s, est. speed input: 12087.26 toks/s, output: 11.80 toks/s]
Processed prompts:  72%|███████▏  | 1482/2048 [02:05<00:52, 10.69it/s, est. speed input: 12080.51 toks/s, output: 11.80 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [02:06<00:52, 10.69it/s, est. speed input: 12073.82 toks/s, output: 11.79 toks/s]
Processed prompts:  73%|███████▎  | 1498/2048 [02:07<00:51, 10.69it/s, est. speed input: 12067.15 toks/s, output: 11.78 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [02:07<00:50, 10.69it/s, est. speed input: 12060.56 toks/s, output: 11.78 toks/s]
Processed prompts:  74%|███████▍  | 1514/2048 [02:08<00:49, 10.69it/s, est. speed input: 12054.05 toks/s, output: 11.77 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [02:09<00:49, 10.69it/s, est. speed input: 12047.61 toks/s, output: 11.77 toks/s]
Processed prompts:  75%|███████▍  | 1530/2048 [02:10<00:48, 10.69it/s, est. speed input: 12041.25 toks/s, output: 11.76 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [02:10<00:47, 10.69it/s, est. speed input: 12034.94 toks/s, output: 11.75 toks/s]
Processed prompts:  75%|███████▌  | 1546/2048 [02:11<00:46, 10.69it/s, est. speed input: 12028.79 toks/s, output: 11.75 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [02:12<00:46, 10.69it/s, est. speed input: 12022.66 toks/s, output: 11.74 toks/s]
Processed prompts:  76%|███████▋  | 1562/2048 [02:13<00:45, 10.69it/s, est. speed input: 12016.60 toks/s, output: 11.73 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [02:13<00:44, 10.69it/s, est. speed input: 12010.60 toks/s, output: 11.73 toks/s]
Processed prompts:  77%|███████▋  | 1578/2048 [02:14<00:43, 10.69it/s, est. speed input: 12004.69 toks/s, output: 11.72 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:15<00:43, 10.69it/s, est. speed input: 11998.82 toks/s, output: 11.72 toks/s]
Processed prompts:  78%|███████▊  | 1594/2048 [02:16<00:42, 10.69it/s, est. speed input: 11993.06 toks/s, output: 11.71 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [02:16<00:41, 10.69it/s, est. speed input: 11987.32 toks/s, output: 11.71 toks/s]
Processed prompts:  79%|███████▊  | 1610/2048 [02:17<00:40, 10.69it/s, est. speed input: 11981.61 toks/s, output: 11.70 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [02:18<00:40, 10.69it/s, est. speed input: 11975.99 toks/s, output: 11.70 toks/s]
Processed prompts:  79%|███████▉  | 1626/2048 [02:19<00:39, 10.69it/s, est. speed input: 11970.49 toks/s, output: 11.69 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [02:19<00:38, 10.69it/s, est. speed input: 11965.00 toks/s, output: 11.68 toks/s]
Processed prompts:  81%|████████  | 1658/2048 [02:20<00:23, 16.79it/s, est. speed input: 12072.14 toks/s, output: 11.79 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [02:21<00:25, 14.99it/s, est. speed input: 12066.28 toks/s, output: 11.78 toks/s]
Processed prompts:  82%|████████▏ | 1674/2048 [02:22<00:27, 13.72it/s, est. speed input: 12060.51 toks/s, output: 11.78 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [02:22<00:28, 12.82it/s, est. speed input: 12054.81 toks/s, output: 11.77 toks/s]
Processed prompts:  83%|████████▎ | 1690/2048 [02:23<00:29, 12.19it/s, est. speed input: 12049.12 toks/s, output: 11.77 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [02:24<00:29, 11.75it/s, est. speed input: 12043.51 toks/s, output: 11.76 toks/s]
Processed prompts:  83%|████████▎ | 1706/2048 [02:25<00:29, 11.44it/s, est. speed input: 12037.99 toks/s, output: 11.76 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [02:25<00:29, 11.22it/s, est. speed input: 12032.47 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 1722/2048 [02:26<00:29, 11.06it/s, est. speed input: 12027.02 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [02:27<00:29, 10.96it/s, est. speed input: 12021.66 toks/s, output: 11.74 toks/s]
Processed prompts:  85%|████████▍ | 1738/2048 [02:28<00:28, 10.88it/s, est. speed input: 12016.35 toks/s, output: 11.73 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [02:28<00:27, 10.82it/s, est. speed input: 12010.92 toks/s, output: 11.73 toks/s]
Processed prompts:  86%|████████▌ | 1754/2048 [02:29<00:27, 10.78it/s, est. speed input: 12005.56 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [02:30<00:26, 10.76it/s, est. speed input: 12000.34 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▋ | 1770/2048 [02:31<00:25, 10.73it/s, est. speed input: 11995.06 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [02:31<00:25, 10.72it/s, est. speed input: 11989.90 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 1786/2048 [02:32<00:24, 10.71it/s, est. speed input: 11984.74 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:33<00:23, 10.70it/s, est. speed input: 11979.63 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 1802/2048 [02:34<00:22, 10.70it/s, est. speed input: 11974.62 toks/s, output: 11.69 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:34<00:22, 10.69it/s, est. speed input: 11969.61 toks/s, output: 11.69 toks/s]
Processed prompts:  89%|████████▉ | 1818/2048 [02:35<00:21, 10.70it/s, est. speed input: 11964.76 toks/s, output: 11.68 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:36<00:20, 10.69it/s, est. speed input: 11959.78 toks/s, output: 11.68 toks/s]
Processed prompts:  90%|████████▉ | 1834/2048 [02:37<00:20, 10.69it/s, est. speed input: 11954.93 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [02:37<00:19, 10.69it/s, est. speed input: 11950.13 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|█████████ | 1850/2048 [02:38<00:18, 10.68it/s, est. speed input: 11945.31 toks/s, output: 11.67 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:39<00:17, 10.68it/s, est. speed input: 11940.59 toks/s, output: 11.66 toks/s]
Processed prompts:  91%|█████████ | 1866/2048 [02:40<00:17, 10.68it/s, est. speed input: 11935.87 toks/s, output: 11.66 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:40<00:16, 10.68it/s, est. speed input: 11931.21 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 1882/2048 [02:41<00:15, 10.68it/s, est. speed input: 11926.61 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [02:42<00:14, 10.68it/s, est. speed input: 11921.99 toks/s, output: 11.64 toks/s]
Processed prompts:  93%|█████████▎| 1898/2048 [02:43<00:14, 10.68it/s, est. speed input: 11917.48 toks/s, output: 11.64 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [02:43<00:13, 10.68it/s, est. speed input: 11912.99 toks/s, output: 11.63 toks/s]
Processed prompts:  93%|█████████▎| 1914/2048 [02:44<00:12, 10.68it/s, est. speed input: 11908.55 toks/s, output: 11.63 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [02:45<00:11, 10.68it/s, est. speed input: 11904.19 toks/s, output: 11.63 toks/s]
Processed prompts:  94%|█████████▍| 1930/2048 [02:46<00:11, 10.68it/s, est. speed input: 11899.86 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:46<00:10, 10.69it/s, est. speed input: 11895.60 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▌| 1946/2048 [02:47<00:09, 10.69it/s, est. speed input: 11891.36 toks/s, output: 11.61 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:48<00:08, 10.69it/s, est. speed input: 11887.14 toks/s, output: 11.61 toks/s]
Processed prompts:  96%|█████████▌| 1962/2048 [02:49<00:08, 10.69it/s, est. speed input: 11883.00 toks/s, output: 11.60 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:49<00:07, 10.69it/s, est. speed input: 11878.83 toks/s, output: 11.60 toks/s]
Processed prompts:  97%|█████████▋| 1978/2048 [02:50<00:06, 10.69it/s, est. speed input: 11874.73 toks/s, output: 11.60 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:51<00:02, 16.78it/s, est. speed input: 11963.02 toks/s, output: 11.68 toks/s]
Processed prompts:  98%|█████████▊| 2010/2048 [02:52<00:02, 14.98it/s, est. speed input: 11958.54 toks/s, output: 11.68 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:52<00:02, 13.73it/s, est. speed input: 11954.49 toks/s, output: 11.67 toks/s]
Processed prompts:  99%|█████████▉| 2026/2048 [02:53<00:01, 12.84it/s, est. speed input: 11950.42 toks/s, output: 11.67 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:54<00:01, 12.22it/s, est. speed input: 11946.40 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|█████████▉| 2042/2048 [02:55<00:00, 12.19it/s, est. speed input: 11948.17 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:55<00:00, 12.19it/s, est. speed input: 11983.26 toks/s, output: 11.70 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:55<00:00, 11.70it/s, est. speed input: 11983.26 toks/s, output: 11.70 toks/s]
[rank0]:[W126 07:53:27.292546357 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 261.9s

测试结果:
  Requests/s:   10.68
  Tokens/s:     10948.65
  Total Reqs:   2048
  Elapsed:      191.73s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     10937.97

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:54:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:54:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=370469) WARNING 01-26 07:54:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=370469) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=370469) WARNING 01-26 07:54:38 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 07:54:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:54:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:54:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:54:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:54:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:54:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:05,  1.79s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.79s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:04<00:01,  1.21s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.43s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.47s/it]
(EngineCore_DP0 pid=370469) 
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:52.100000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:52.181000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:53.482000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:53.606000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) Process EngineCore_DP0:
(EngineCore_DP0 pid=370469) Traceback (most recent call last):
(EngineCore_DP0 pid=370469)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=370469)     self.run()
(EngineCore_DP0 pid=370469)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=370469)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=370469)     raise e
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370469)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370469)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370469)     super().__init__(
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370469)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370469)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=370469)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=370469)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=370469)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=370469)     raise ValueError(
(EngineCore_DP0 pid=370469) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:55:05.659475315 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:56:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:56:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=372495) WARNING 01-26 07:56:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=372495) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372495) WARNING 01-26 07:56:45 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 07:56:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:56:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.85it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.08it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.31it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.47it/s]
(EngineCore_DP0 pid=372495) 
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.077000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.153000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.519000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.644000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) Process EngineCore_DP0:
(EngineCore_DP0 pid=372495) Traceback (most recent call last):
(EngineCore_DP0 pid=372495)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=372495)     self.run()
(EngineCore_DP0 pid=372495)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=372495)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=372495)     raise e
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372495)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372495)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372495)     super().__init__(
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372495)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372495)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=372495)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=372495)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=372495)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=372495)     raise ValueError(
(EngineCore_DP0 pid=372495) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:58:13.983542617 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,9.4420,4843.7491,13.5564
1024,1024,1,128,128,9.7571,10001.0551,13.1186
2048,1024,2,256,128,10.7798,11049.3452,23.7480
4096,1024,4,512,128,10.8586,11130.0827,47.1515
8192,1024,8,1024,128,10.6290,10894.7351,96.3401
16384,1024,16,2048,128,10.6816,10948.6497,191.7314
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 6 成功, 2 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:58:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:58:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=374506) WARNING 01-26 07:58:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=374506) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=374506) WARNING 01-26 07:59:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.53 requests/s, 4888.64 total tokens/s, 9.53 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:58:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:58:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:58:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:58:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:58:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:58:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:58:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:58:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:58:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:58:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:58:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:58:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:58:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:58:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:58:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:58:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:58:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:16,  5.51s/it]
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:10<00:10,  5.25s/it]
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:11<00:03,  3.43s/it]
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  4.30s/it]
(EngineCore_DP0 pid=374506) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  4.37s/it]
(EngineCore_DP0 pid=374506) 
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=374506) [2026-01-26 07:58:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=374506) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.91it/s]
(EngineCore_DP0 pid=374506) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  33%|███▎      | 42/128 [00:00<00:00, 413.59it/s]
Adding requests:  69%|██████▉   | 88/128 [00:00<00:00, 437.81it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 438.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:27,  4.69it/s, est. speed input: 2401.64 toks/s, output: 4.69 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:18,  6.65it/s, est. speed input: 3203.07 toks/s, output: 6.26 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:16,  7.73it/s, est. speed input: 3623.52 toks/s, output: 7.08 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:14,  8.33it/s, est. speed input: 3866.97 toks/s, output: 7.55 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:14,  8.72it/s, est. speed input: 4031.51 toks/s, output: 7.87 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:13,  8.97it/s, est. speed input: 4150.72 toks/s, output: 8.11 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:13,  9.15it/s, est. speed input: 4241.80 toks/s, output: 8.28 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:12,  9.30it/s, est. speed input: 4318.18 toks/s, output: 8.43 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:12,  9.41it/s, est. speed input: 4378.90 toks/s, output: 8.55 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:12,  9.49it/s, est. speed input: 4430.32 toks/s, output: 8.65 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:12,  9.56it/s, est. speed input: 4475.47 toks/s, output: 8.74 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:12,  9.62it/s, est. speed input: 4514.54 toks/s, output: 8.82 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:11,  9.66it/s, est. speed input: 4548.01 toks/s, output: 8.88 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:11,  9.66it/s, est. speed input: 4574.27 toks/s, output: 8.93 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.64it/s, est. speed input: 4595.06 toks/s, output: 8.97 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:11,  9.69it/s, est. speed input: 4620.07 toks/s, output: 9.02 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:11,  9.79it/s, est. speed input: 4666.66 toks/s, output: 9.11 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:11,  9.79it/s, est. speed input: 4683.23 toks/s, output: 9.15 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:02<00:11,  9.81it/s, est. speed input: 4700.87 toks/s, output: 9.18 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:10,  9.82it/s, est. speed input: 4716.02 toks/s, output: 9.21 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:02<00:10,  9.84it/s, est. speed input: 4730.65 toks/s, output: 9.24 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.80it/s, est. speed input: 4740.16 toks/s, output: 9.26 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:10,  9.79it/s, est. speed input: 4750.59 toks/s, output: 9.28 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10,  9.79it/s, est. speed input: 4760.90 toks/s, output: 9.30 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10,  9.78it/s, est. speed input: 4769.52 toks/s, output: 9.32 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:10,  9.78it/s, est. speed input: 4777.57 toks/s, output: 9.33 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:02<00:10,  9.79it/s, est. speed input: 4785.97 toks/s, output: 9.35 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:10,  9.80it/s, est. speed input: 4794.14 toks/s, output: 9.36 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:10,  9.78it/s, est. speed input: 4800.27 toks/s, output: 9.38 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:09,  9.76it/s, est. speed input: 4805.37 toks/s, output: 9.39 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:09,  9.81it/s, est. speed input: 4813.90 toks/s, output: 9.40 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.84it/s, est. speed input: 4821.47 toks/s, output: 9.42 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.84it/s, est. speed input: 4827.63 toks/s, output: 9.43 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:03<00:09,  9.88it/s, est. speed input: 4835.11 toks/s, output: 9.44 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09,  9.92it/s, est. speed input: 4842.59 toks/s, output: 9.46 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:03<00:09,  9.93it/s, est. speed input: 4849.27 toks/s, output: 9.47 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:09,  9.90it/s, est. speed input: 4854.04 toks/s, output: 9.48 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:04<00:01, 45.01it/s, est. speed input: 6614.51 toks/s, output: 12.92 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:04<00:02, 24.41it/s, est. speed input: 6477.58 toks/s, output: 12.65 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:03, 18.80it/s, est. speed input: 6389.44 toks/s, output: 12.48 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:05<00:04, 15.64it/s, est. speed input: 6312.53 toks/s, output: 12.33 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:05<00:04, 14.16it/s, est. speed input: 6264.01 toks/s, output: 12.23 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:05<00:04, 13.02it/s, est. speed input: 6220.12 toks/s, output: 12.15 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:05<00:04, 12.20it/s, est. speed input: 6182.52 toks/s, output: 12.08 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:05<00:04, 11.61it/s, est. speed input: 6148.26 toks/s, output: 12.01 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:06<00:04, 11.11it/s, est. speed input: 6113.03 toks/s, output: 11.94 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:06<00:04, 10.79it/s, est. speed input: 6081.82 toks/s, output: 11.88 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:06<00:04, 10.53it/s, est. speed input: 6051.22 toks/s, output: 11.82 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:06<00:04, 10.32it/s, est. speed input: 6020.35 toks/s, output: 11.76 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:07<00:04, 10.20it/s, est. speed input: 5993.11 toks/s, output: 11.71 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:07<00:04, 10.08it/s, est. speed input: 5965.80 toks/s, output: 11.65 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:07<00:04,  9.90it/s, est. speed input: 5934.48 toks/s, output: 11.59 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:07<00:04,  9.88it/s, est. speed input: 5921.93 toks/s, output: 11.57 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:07<00:04,  9.87it/s, est. speed input: 5909.87 toks/s, output: 11.54 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:07<00:03,  9.86it/s, est. speed input: 5898.19 toks/s, output: 11.52 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:07<00:03,  9.74it/s, est. speed input: 5883.48 toks/s, output: 11.49 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:07<00:03,  9.71it/s, est. speed input: 5870.89 toks/s, output: 11.47 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:08<00:03,  9.69it/s, est. speed input: 5858.71 toks/s, output: 11.44 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:08<00:03,  9.66it/s, est. speed input: 5846.50 toks/s, output: 11.42 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:08<00:03,  9.73it/s, est. speed input: 5836.98 toks/s, output: 11.40 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:08<00:03,  9.79it/s, est. speed input: 5828.11 toks/s, output: 11.38 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:08<00:03,  9.84it/s, est. speed input: 5819.47 toks/s, output: 11.37 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:08<00:03,  9.84it/s, est. speed input: 5810.21 toks/s, output: 11.35 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:08<00:03,  9.84it/s, est. speed input: 5801.15 toks/s, output: 11.33 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:08<00:02,  9.91it/s, est. speed input: 5785.66 toks/s, output: 11.30 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:09<00:02,  9.96it/s, est. speed input: 5771.30 toks/s, output: 11.27 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:09<00:02,  9.94it/s, est. speed input: 5763.43 toks/s, output: 11.26 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:09<00:02,  9.94it/s, est. speed input: 5756.10 toks/s, output: 11.24 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:09<00:02,  9.95it/s, est. speed input: 5742.16 toks/s, output: 11.22 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:09<00:02,  9.93it/s, est. speed input: 5734.79 toks/s, output: 11.20 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:09<00:02,  9.89it/s, est. speed input: 5726.97 toks/s, output: 11.19 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:09<00:01,  9.89it/s, est. speed input: 5720.07 toks/s, output: 11.17 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:09<00:01,  9.91it/s, est. speed input: 5713.80 toks/s, output: 11.16 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:09<00:01,  9.90it/s, est. speed input: 5707.05 toks/s, output: 11.15 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:10<00:01,  9.91it/s, est. speed input: 5700.86 toks/s, output: 11.13 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:10<00:01,  9.89it/s, est. speed input: 5694.17 toks/s, output: 11.12 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:10<00:01,  9.89it/s, est. speed input: 5688.03 toks/s, output: 11.11 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:10<00:01,  9.91it/s, est. speed input: 5682.25 toks/s, output: 11.10 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:10<00:01,  9.92it/s, est. speed input: 5676.59 toks/s, output: 11.09 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:10<00:01,  9.93it/s, est. speed input: 5671.00 toks/s, output: 11.08 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:10<00:01,  9.91it/s, est. speed input: 5665.19 toks/s, output: 11.06 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:10<00:00,  9.87it/s, est. speed input: 5658.98 toks/s, output: 11.05 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:10<00:00,  9.85it/s, est. speed input: 5652.90 toks/s, output: 11.04 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:10<00:00,  9.87it/s, est. speed input: 5647.54 toks/s, output: 11.03 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:11<00:00,  9.85it/s, est. speed input: 5641.82 toks/s, output: 11.02 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:11<00:00,  9.83it/s, est. speed input: 5635.98 toks/s, output: 11.01 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:11<00:00,  9.81it/s, est. speed input: 5630.24 toks/s, output: 11.00 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:11<00:00,  9.75it/s, est. speed input: 5623.82 toks/s, output: 10.98 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:11<00:00,  9.71it/s, est. speed input: 5617.45 toks/s, output: 10.97 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00,  9.67it/s, est. speed input: 5611.01 toks/s, output: 10.96 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.65it/s, est. speed input: 5604.74 toks/s, output: 10.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.65it/s, est. speed input: 5604.74 toks/s, output: 10.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 10.95it/s, est. speed input: 5604.74 toks/s, output: 10.95 toks/s]
[rank0]:[W126 07:59:43.665580114 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 88.8s

测试结果:
  Requests/s:   9.53
  Tokens/s:     4888.64
  Total Reqs:   128
  Elapsed:      13.43s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     4879.11

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:59:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:59:56 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=376008) WARNING 01-26 08:00:05 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=376008) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=376008) WARNING 01-26 08:00:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.34 requests/s, 9574.02 total tokens/s, 9.34 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 07:59:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:59:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:59:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:59:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:59:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:59:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:59:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:59:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:59:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:00:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:00:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:00:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:00:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:00:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:00:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:00:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:00:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=376008) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=376008) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.15it/s]
(EngineCore_DP0 pid=376008) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.25it/s]
(EngineCore_DP0 pid=376008) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.04s/it]
(EngineCore_DP0 pid=376008) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.03it/s]
(EngineCore_DP0 pid=376008) 
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=376008) [2026-01-26 08:00:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=376008) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.95it/s]
(EngineCore_DP0 pid=376008) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  17%|█▋        | 22/128 [00:00<00:00, 215.95it/s]
Adding requests:  37%|███▋      | 47/128 [00:00<00:00, 230.56it/s]
Adding requests:  57%|█████▋    | 73/128 [00:00<00:00, 241.54it/s]
Adding requests:  77%|███████▋  | 99/128 [00:00<00:00, 245.47it/s]
Adding requests:  98%|█████████▊| 125/128 [00:00<00:00, 250.49it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 243.81it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:07, 17.42it/s, est. speed input: 17840.10 toks/s, output: 17.42 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.40it/s, est. speed input: 13396.75 toks/s, output: 13.08 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:10, 11.06it/s, est. speed input: 12124.30 toks/s, output: 11.84 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:11, 10.50it/s, est. speed input: 11546.06 toks/s, output: 11.28 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:11, 10.16it/s, est. speed input: 11185.34 toks/s, output: 10.92 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:11, 10.00it/s, est. speed input: 10970.70 toks/s, output: 10.71 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.84it/s, est. speed input: 10787.57 toks/s, output: 10.53 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:11,  9.77it/s, est. speed input: 10715.65 toks/s, output: 10.46 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:11,  9.72it/s, est. speed input: 10653.65 toks/s, output: 10.40 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:11,  9.64it/s, est. speed input: 10588.62 toks/s, output: 10.34 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:11,  9.63it/s, est. speed input: 10546.19 toks/s, output: 10.30 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:11,  9.52it/s, est. speed input: 10486.10 toks/s, output: 10.24 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:11,  9.53it/s, est. speed input: 10449.83 toks/s, output: 10.20 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:02<00:11,  9.54it/s, est. speed input: 10417.75 toks/s, output: 10.17 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.55it/s, est. speed input: 10390.08 toks/s, output: 10.15 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:02<00:10,  9.56it/s, est. speed input: 10363.78 toks/s, output: 10.12 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10,  9.58it/s, est. speed input: 10342.81 toks/s, output: 10.10 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10,  9.57it/s, est. speed input: 10319.83 toks/s, output: 10.08 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:10,  9.59it/s, est. speed input: 10302.49 toks/s, output: 10.06 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:02<00:10,  9.60it/s, est. speed input: 10286.28 toks/s, output: 10.05 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:10,  9.62it/s, est. speed input: 10272.66 toks/s, output: 10.03 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:02<00:10,  9.63it/s, est. speed input: 10259.29 toks/s, output: 10.02 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:10,  9.63it/s, est. speed input: 10245.23 toks/s, output: 10.01 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:09,  9.63it/s, est. speed input: 10233.29 toks/s, output: 9.99 toks/s] 
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.64it/s, est. speed input: 10222.22 toks/s, output: 9.98 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.59it/s, est. speed input: 10205.96 toks/s, output: 9.97 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:03<00:09,  9.60it/s, est. speed input: 10196.18 toks/s, output: 9.96 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09,  9.62it/s, est. speed input: 10187.67 toks/s, output: 9.95 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:03<00:09,  9.58it/s, est. speed input: 10174.31 toks/s, output: 9.94 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:03<00:09,  9.60it/s, est. speed input: 10165.93 toks/s, output: 9.93 toks/s]
Processed prompts:  30%|███       | 39/128 [00:03<00:09,  9.62it/s, est. speed input: 10159.21 toks/s, output: 9.92 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:09,  9.64it/s, est. speed input: 10152.78 toks/s, output: 9.91 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:09,  9.62it/s, est. speed input: 10144.02 toks/s, output: 9.91 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:04<00:08,  9.61it/s, est. speed input: 10136.31 toks/s, output: 9.90 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:04<00:08,  9.62it/s, est. speed input: 10130.29 toks/s, output: 9.89 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:08,  9.60it/s, est. speed input: 10121.93 toks/s, output: 9.88 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:04<00:08,  9.60it/s, est. speed input: 10114.91 toks/s, output: 9.88 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:04<00:08,  9.59it/s, est. speed input: 10107.64 toks/s, output: 9.87 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:04<00:08,  9.58it/s, est. speed input: 10100.78 toks/s, output: 9.86 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:04<00:08,  9.60it/s, est. speed input: 10095.89 toks/s, output: 9.86 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:04<00:08,  9.61it/s, est. speed input: 10091.14 toks/s, output: 9.85 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:05<00:08,  9.59it/s, est. speed input: 10084.89 toks/s, output: 9.85 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:05<00:08,  9.60it/s, est. speed input: 10080.18 toks/s, output: 9.84 toks/s]
Processed prompts:  41%|████      | 52/128 [00:05<00:07,  9.61it/s, est. speed input: 10076.16 toks/s, output: 9.84 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:05<00:07,  9.63it/s, est. speed input: 10072.47 toks/s, output: 9.84 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:05<00:07,  9.63it/s, est. speed input: 10068.62 toks/s, output: 9.83 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:05<00:07,  9.64it/s, est. speed input: 10065.19 toks/s, output: 9.83 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:05<00:07,  9.63it/s, est. speed input: 10061.47 toks/s, output: 9.83 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:05<00:07,  9.58it/s, est. speed input: 10054.33 toks/s, output: 9.82 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:05<00:07,  9.60it/s, est. speed input: 10051.52 toks/s, output: 9.82 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:06<00:07,  9.62it/s, est. speed input: 10048.96 toks/s, output: 9.81 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:06<00:07,  9.63it/s, est. speed input: 10046.35 toks/s, output: 9.81 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:06<00:06,  9.64it/s, est. speed input: 10043.68 toks/s, output: 9.81 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:06<00:06,  9.64it/s, est. speed input: 10040.86 toks/s, output: 9.81 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:06<00:06,  9.65it/s, est. speed input: 10038.39 toks/s, output: 9.80 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:06<00:06,  9.65it/s, est. speed input: 10035.84 toks/s, output: 9.80 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:06<00:06,  9.65it/s, est. speed input: 10033.51 toks/s, output: 9.80 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:06<00:06,  9.64it/s, est. speed input: 10030.51 toks/s, output: 9.80 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:06<00:06,  9.64it/s, est. speed input: 10028.28 toks/s, output: 9.79 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:06<00:06,  9.65it/s, est. speed input: 10026.22 toks/s, output: 9.79 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:07<00:06,  9.65it/s, est. speed input: 10024.34 toks/s, output: 9.79 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:07<00:06,  9.66it/s, est. speed input: 10022.74 toks/s, output: 9.79 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:07<00:05,  9.66it/s, est. speed input: 10020.79 toks/s, output: 9.79 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:07<00:05,  9.64it/s, est. speed input: 10018.18 toks/s, output: 9.78 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:07<00:05,  9.65it/s, est. speed input: 10016.61 toks/s, output: 9.78 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:07<00:05,  9.64it/s, est. speed input: 10014.41 toks/s, output: 9.78 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:07<00:05,  9.64it/s, est. speed input: 10012.30 toks/s, output: 9.78 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:07<00:05,  9.64it/s, est. speed input: 10010.61 toks/s, output: 9.78 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:07<00:05,  9.64it/s, est. speed input: 10008.67 toks/s, output: 9.77 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:07<00:05,  9.64it/s, est. speed input: 10006.93 toks/s, output: 9.77 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:08<00:05,  9.65it/s, est. speed input: 10005.49 toks/s, output: 9.77 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:08<00:04,  9.64it/s, est. speed input: 10003.52 toks/s, output: 9.77 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:08<00:04,  9.64it/s, est. speed input: 10001.98 toks/s, output: 9.77 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:08<00:04,  9.64it/s, est. speed input: 10000.09 toks/s, output: 9.77 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:08<00:04,  9.64it/s, est. speed input: 9998.54 toks/s, output: 9.76 toks/s] 
Processed prompts:  66%|██████▌   | 84/128 [00:08<00:04,  9.63it/s, est. speed input: 9996.85 toks/s, output: 9.76 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:08<00:04,  9.63it/s, est. speed input: 9995.19 toks/s, output: 9.76 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:08<00:04,  9.63it/s, est. speed input: 9993.74 toks/s, output: 9.76 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:08<00:04,  9.63it/s, est. speed input: 9992.11 toks/s, output: 9.76 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:09<00:04,  9.63it/s, est. speed input: 9990.62 toks/s, output: 9.76 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:09<00:04,  9.61it/s, est. speed input: 9988.49 toks/s, output: 9.75 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:09<00:03,  9.63it/s, est. speed input: 9987.31 toks/s, output: 9.75 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:09<00:03,  9.63it/s, est. speed input: 9986.14 toks/s, output: 9.75 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:09<00:03,  9.64it/s, est. speed input: 9984.94 toks/s, output: 9.75 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:09<00:03,  9.64it/s, est. speed input: 9983.90 toks/s, output: 9.75 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:09<00:03,  9.64it/s, est. speed input: 9982.65 toks/s, output: 9.75 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:09<00:03,  9.65it/s, est. speed input: 9981.65 toks/s, output: 9.75 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:09<00:03,  9.65it/s, est. speed input: 9980.55 toks/s, output: 9.75 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:09<00:03,  9.64it/s, est. speed input: 9979.27 toks/s, output: 9.75 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:10<00:03,  9.64it/s, est. speed input: 9978.28 toks/s, output: 9.74 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:10<00:03,  9.64it/s, est. speed input: 9977.23 toks/s, output: 9.74 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:10<00:02,  9.65it/s, est. speed input: 9976.29 toks/s, output: 9.74 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:10<00:02,  9.65it/s, est. speed input: 9975.37 toks/s, output: 9.74 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:10<00:02,  9.65it/s, est. speed input: 9974.59 toks/s, output: 9.74 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:10<00:02,  9.65it/s, est. speed input: 9973.57 toks/s, output: 9.74 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:10<00:02,  9.64it/s, est. speed input: 9972.33 toks/s, output: 9.74 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:10<00:02,  9.64it/s, est. speed input: 9971.31 toks/s, output: 9.74 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:10<00:02,  9.64it/s, est. speed input: 9970.31 toks/s, output: 9.74 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:10<00:02,  9.48it/s, est. speed input: 9964.25 toks/s, output: 9.73 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:11<00:02,  9.53it/s, est. speed input: 9963.32 toks/s, output: 9.73 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:11<00:01,  9.56it/s, est. speed input: 9962.48 toks/s, output: 9.73 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:11<00:01,  9.58it/s, est. speed input: 9961.55 toks/s, output: 9.73 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:11<00:01,  9.60it/s, est. speed input: 9960.60 toks/s, output: 9.73 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:11<00:01,  9.60it/s, est. speed input: 9959.62 toks/s, output: 9.73 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:11<00:01,  9.61it/s, est. speed input: 9958.67 toks/s, output: 9.73 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:11<00:01,  9.61it/s, est. speed input: 9957.64 toks/s, output: 9.72 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:11<00:01,  9.61it/s, est. speed input: 9956.66 toks/s, output: 9.72 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:11<00:01,  9.61it/s, est. speed input: 9955.71 toks/s, output: 9.72 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:12<00:01,  9.61it/s, est. speed input: 9954.75 toks/s, output: 9.72 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:12<00:01,  9.62it/s, est. speed input: 9953.96 toks/s, output: 9.72 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:12<00:00,  9.62it/s, est. speed input: 9953.06 toks/s, output: 9.72 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:12<00:00,  9.63it/s, est. speed input: 9952.42 toks/s, output: 9.72 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:12<00:00,  9.63it/s, est. speed input: 9951.69 toks/s, output: 9.72 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:12<00:00,  9.63it/s, est. speed input: 9950.84 toks/s, output: 9.72 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:12<00:00,  9.63it/s, est. speed input: 9950.09 toks/s, output: 9.72 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:12<00:00,  9.63it/s, est. speed input: 9949.41 toks/s, output: 9.72 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:12<00:00,  9.63it/s, est. speed input: 9948.73 toks/s, output: 9.72 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:12<00:00,  9.63it/s, est. speed input: 9948.01 toks/s, output: 9.71 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:13<00:00,  9.63it/s, est. speed input: 9947.35 toks/s, output: 9.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.64it/s, est. speed input: 9947.02 toks/s, output: 9.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.64it/s, est. speed input: 9947.02 toks/s, output: 9.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.71it/s, est. speed input: 9947.02 toks/s, output: 9.71 toks/s]
[rank0]:[W126 08:01:02.991664356 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 79.4s

测试结果:
  Requests/s:   9.34
  Tokens/s:     9574.02
  Total Reqs:   128
  Elapsed:      13.70s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     9564.68

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:01:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:01:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=377352) WARNING 01-26 08:01:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=377352) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=377352) WARNING 01-26 08:01:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.01 requests/s, 10257.64 total tokens/s, 10.01 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 08:01:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:01:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:01:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:01:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:01:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:01:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:01:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:01:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:01:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.44s/it]
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.43s/it]
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.04it/s]
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
(EngineCore_DP0 pid=377352) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.16s/it]
(EngineCore_DP0 pid=377352) 
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=377352) [2026-01-26 08:01:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=377352) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  2.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  3.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.61it/s]
(EngineCore_DP0 pid=377352) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.06it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 23/256 [00:00<00:01, 228.46it/s]
Adding requests:  19%|█▉        | 48/256 [00:00<00:00, 239.77it/s]
Adding requests:  29%|██▉       | 74/256 [00:00<00:00, 248.43it/s]
Adding requests:  39%|███▊      | 99/256 [00:00<00:00, 241.42it/s]
Adding requests:  48%|████▊     | 124/256 [00:00<00:00, 243.65it/s]
Adding requests:  58%|█████▊    | 149/256 [00:00<00:00, 245.48it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 249.36it/s]
Adding requests:  79%|███████▊  | 201/256 [00:00<00:00, 250.61it/s]
Adding requests:  89%|████████▊ | 227/256 [00:00<00:00, 253.36it/s]
Adding requests:  99%|█████████▉| 253/256 [00:01<00:00, 252.40it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 248.00it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:05, 42.74it/s, est. speed input: 43770.06 toks/s, output: 42.74 toks/s]
Processed prompts:   6%|▌         | 15/256 [00:00<00:11, 21.52it/s, est. speed input: 24463.31 toks/s, output: 23.89 toks/s]
Processed prompts:   7%|▋         | 18/256 [00:01<00:16, 14.54it/s, est. speed input: 18042.36 toks/s, output: 17.62 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:01<00:17, 13.38it/s, est. speed input: 16804.34 toks/s, output: 16.41 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:01<00:18, 12.49it/s, est. speed input: 15912.35 toks/s, output: 15.54 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:01<00:19, 11.83it/s, est. speed input: 15235.78 toks/s, output: 14.88 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:06, 33.93it/s, est. speed input: 23205.66 toks/s, output: 22.66 toks/s]
Processed prompts:  18%|█▊        | 45/256 [00:02<00:08, 24.00it/s, est. speed input: 21336.41 toks/s, output: 20.84 toks/s]
Processed prompts:  19%|█▉        | 49/256 [00:02<00:11, 18.46it/s, est. speed input: 19648.20 toks/s, output: 19.19 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:14, 14.51it/s, est. speed input: 18060.30 toks/s, output: 17.64 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:03<00:13, 14.65it/s, est. speed input: 17905.00 toks/s, output: 17.49 toks/s]
Processed prompts:  22%|██▏       | 57/256 [00:03<00:14, 13.63it/s, est. speed input: 17463.62 toks/s, output: 17.05 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:03<00:15, 12.78it/s, est. speed input: 17071.24 toks/s, output: 16.67 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:03<00:16, 12.10it/s, est. speed input: 16720.16 toks/s, output: 16.33 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:03<00:16, 11.57it/s, est. speed input: 16400.87 toks/s, output: 16.02 toks/s]
Processed prompts:  25%|██▌       | 65/256 [00:04<00:17, 11.16it/s, est. speed input: 16110.72 toks/s, output: 15.73 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:04<00:17, 10.86it/s, est. speed input: 15848.19 toks/s, output: 15.48 toks/s]
Processed prompts:  27%|██▋       | 69/256 [00:04<00:17, 10.65it/s, est. speed input: 15610.42 toks/s, output: 15.24 toks/s]
Processed prompts:  28%|██▊       | 71/256 [00:04<00:17, 10.49it/s, est. speed input: 15390.20 toks/s, output: 15.03 toks/s]
Processed prompts:  29%|██▊       | 73/256 [00:04<00:17, 10.38it/s, est. speed input: 15188.19 toks/s, output: 14.83 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:05<00:17, 10.30it/s, est. speed input: 15001.69 toks/s, output: 14.65 toks/s]
Processed prompts:  30%|███       | 77/256 [00:05<00:17, 10.25it/s, est. speed input: 14829.12 toks/s, output: 14.48 toks/s]
Processed prompts:  31%|███       | 79/256 [00:05<00:17, 10.21it/s, est. speed input: 14669.42 toks/s, output: 14.33 toks/s]
Processed prompts:  32%|███▏      | 81/256 [00:05<00:17, 10.19it/s, est. speed input: 14520.72 toks/s, output: 14.18 toks/s]
Processed prompts:  32%|███▏      | 83/256 [00:05<00:17, 10.16it/s, est. speed input: 14380.77 toks/s, output: 14.04 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:06<00:16, 10.14it/s, est. speed input: 14249.79 toks/s, output: 13.92 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:06<00:16, 10.13it/s, est. speed input: 14127.20 toks/s, output: 13.80 toks/s]
Processed prompts:  35%|███▍      | 89/256 [00:06<00:16, 10.12it/s, est. speed input: 14011.91 toks/s, output: 13.68 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:06<00:16, 10.12it/s, est. speed input: 13904.09 toks/s, output: 13.58 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:06<00:16, 10.12it/s, est. speed input: 13802.36 toks/s, output: 13.48 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:07<00:15, 10.12it/s, est. speed input: 13706.90 toks/s, output: 13.39 toks/s]
Processed prompts:  38%|███▊      | 97/256 [00:07<00:15, 10.12it/s, est. speed input: 13616.19 toks/s, output: 13.30 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:07<00:15, 10.12it/s, est. speed input: 13530.28 toks/s, output: 13.21 toks/s]
Processed prompts:  39%|███▉      | 101/256 [00:07<00:15, 10.11it/s, est. speed input: 13448.40 toks/s, output: 13.13 toks/s]
Processed prompts:  40%|████      | 103/256 [00:07<00:15, 10.12it/s, est. speed input: 13371.79 toks/s, output: 13.06 toks/s]
Processed prompts:  41%|████      | 105/256 [00:08<00:14, 10.12it/s, est. speed input: 13297.60 toks/s, output: 12.99 toks/s]
Processed prompts:  42%|████▏     | 107/256 [00:08<00:14, 10.11it/s, est. speed input: 13226.72 toks/s, output: 12.92 toks/s]
Processed prompts:  43%|████▎     | 109/256 [00:08<00:14, 10.10it/s, est. speed input: 13158.81 toks/s, output: 12.85 toks/s]
Processed prompts:  43%|████▎     | 111/256 [00:08<00:14, 10.10it/s, est. speed input: 13094.32 toks/s, output: 12.79 toks/s]
Processed prompts:  44%|████▍     | 113/256 [00:08<00:14, 10.09it/s, est. speed input: 13032.21 toks/s, output: 12.73 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:09<00:13, 10.09it/s, est. speed input: 12973.25 toks/s, output: 12.67 toks/s]
Processed prompts:  46%|████▌     | 117/256 [00:09<00:13, 10.09it/s, est. speed input: 12916.96 toks/s, output: 12.61 toks/s]
Processed prompts:  46%|████▋     | 119/256 [00:09<00:13, 10.08it/s, est. speed input: 12862.18 toks/s, output: 12.56 toks/s]
Processed prompts:  47%|████▋     | 121/256 [00:09<00:13, 10.08it/s, est. speed input: 12810.09 toks/s, output: 12.51 toks/s]
Processed prompts:  48%|████▊     | 123/256 [00:09<00:13, 10.09it/s, est. speed input: 12760.47 toks/s, output: 12.46 toks/s]
Processed prompts:  49%|████▉     | 125/256 [00:10<00:12, 10.08it/s, est. speed input: 12712.18 toks/s, output: 12.41 toks/s]
Processed prompts:  50%|████▉     | 127/256 [00:10<00:12, 10.09it/s, est. speed input: 12666.53 toks/s, output: 12.37 toks/s]
Processed prompts:  50%|█████     | 129/256 [00:10<00:12, 10.09it/s, est. speed input: 12622.59 toks/s, output: 12.33 toks/s]
Processed prompts:  51%|█████     | 131/256 [00:10<00:12, 10.09it/s, est. speed input: 12580.28 toks/s, output: 12.29 toks/s]
Processed prompts:  52%|█████▏    | 133/256 [00:10<00:12, 10.09it/s, est. speed input: 12539.10 toks/s, output: 12.25 toks/s]
Processed prompts:  53%|█████▎    | 135/256 [00:11<00:11, 10.09it/s, est. speed input: 12499.67 toks/s, output: 12.21 toks/s]
Processed prompts:  54%|█████▎    | 137/256 [00:11<00:11, 10.08it/s, est. speed input: 12460.80 toks/s, output: 12.17 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:11<00:11, 10.07it/s, est. speed input: 12423.24 toks/s, output: 12.13 toks/s]
Processed prompts:  55%|█████▌    | 141/256 [00:11<00:11, 10.07it/s, est. speed input: 12387.18 toks/s, output: 12.10 toks/s]
Processed prompts:  56%|█████▌    | 143/256 [00:11<00:11, 10.07it/s, est. speed input: 12351.99 toks/s, output: 12.06 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:12<00:11, 10.06it/s, est. speed input: 12318.10 toks/s, output: 12.03 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:12<00:10, 10.06it/s, est. speed input: 12284.99 toks/s, output: 12.00 toks/s]
Processed prompts:  58%|█████▊    | 149/256 [00:12<00:10, 10.05it/s, est. speed input: 12252.94 toks/s, output: 11.97 toks/s]
Processed prompts:  59%|█████▉    | 151/256 [00:12<00:10, 10.05it/s, est. speed input: 12222.02 toks/s, output: 11.94 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:12<00:10, 10.05it/s, est. speed input: 12191.85 toks/s, output: 11.91 toks/s]
Processed prompts:  61%|██████    | 155/256 [00:13<00:10, 10.05it/s, est. speed input: 12162.93 toks/s, output: 11.88 toks/s]
Processed prompts:  61%|██████▏   | 157/256 [00:13<00:09, 10.05it/s, est. speed input: 12134.80 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:13<00:09, 10.06it/s, est. speed input: 12108.39 toks/s, output: 11.82 toks/s]
Processed prompts:  63%|██████▎   | 161/256 [00:13<00:09, 10.07it/s, est. speed input: 12082.29 toks/s, output: 11.80 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:13<00:09, 10.07it/s, est. speed input: 12056.88 toks/s, output: 11.77 toks/s]
Processed prompts:  64%|██████▍   | 165/256 [00:14<00:09, 10.07it/s, est. speed input: 12032.41 toks/s, output: 11.75 toks/s]
Processed prompts:  65%|██████▌   | 167/256 [00:14<00:08, 10.07it/s, est. speed input: 12008.29 toks/s, output: 11.73 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:14<00:08, 10.06it/s, est. speed input: 11984.57 toks/s, output: 11.70 toks/s]
Processed prompts:  67%|██████▋   | 171/256 [00:14<00:08, 10.05it/s, est. speed input: 11961.35 toks/s, output: 11.68 toks/s]
Processed prompts:  68%|██████▊   | 173/256 [00:14<00:08, 10.05it/s, est. speed input: 11938.74 toks/s, output: 11.66 toks/s]
Processed prompts:  68%|██████▊   | 175/256 [00:15<00:08, 10.04it/s, est. speed input: 11916.63 toks/s, output: 11.64 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:15<00:07, 10.04it/s, est. speed input: 11895.01 toks/s, output: 11.62 toks/s]
Processed prompts:  70%|██████▉   | 179/256 [00:15<00:07, 10.04it/s, est. speed input: 11874.00 toks/s, output: 11.60 toks/s]
Processed prompts:  71%|███████   | 181/256 [00:15<00:07, 10.04it/s, est. speed input: 11853.99 toks/s, output: 11.58 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:15<00:07, 10.05it/s, est. speed input: 11834.45 toks/s, output: 11.56 toks/s]
Processed prompts:  72%|███████▏  | 185/256 [00:16<00:07, 10.04it/s, est. speed input: 11815.16 toks/s, output: 11.54 toks/s]
Processed prompts:  73%|███████▎  | 187/256 [00:16<00:06, 10.04it/s, est. speed input: 11796.22 toks/s, output: 11.52 toks/s]
Processed prompts:  74%|███████▍  | 189/256 [00:16<00:06, 10.04it/s, est. speed input: 11778.01 toks/s, output: 11.50 toks/s]
Processed prompts:  75%|███████▍  | 191/256 [00:16<00:06, 10.05it/s, est. speed input: 11760.31 toks/s, output: 11.48 toks/s]
Processed prompts:  75%|███████▌  | 193/256 [00:16<00:06, 10.05it/s, est. speed input: 11742.89 toks/s, output: 11.47 toks/s]
Processed prompts:  76%|███████▌  | 195/256 [00:17<00:06, 10.04it/s, est. speed input: 11725.46 toks/s, output: 11.45 toks/s]
Processed prompts:  77%|███████▋  | 197/256 [00:17<00:05, 10.03it/s, est. speed input: 11708.59 toks/s, output: 11.43 toks/s]
Processed prompts:  78%|███████▊  | 199/256 [00:17<00:05, 10.03it/s, est. speed input: 11692.03 toks/s, output: 11.42 toks/s]
Processed prompts:  79%|███████▊  | 201/256 [00:17<00:05, 10.03it/s, est. speed input: 11676.03 toks/s, output: 11.40 toks/s]
Processed prompts:  79%|███████▉  | 203/256 [00:17<00:05, 10.03it/s, est. speed input: 11660.12 toks/s, output: 11.39 toks/s]
Processed prompts:  80%|████████  | 205/256 [00:18<00:05, 10.02it/s, est. speed input: 11644.49 toks/s, output: 11.37 toks/s]
Processed prompts:  81%|████████  | 207/256 [00:18<00:04, 10.03it/s, est. speed input: 11629.57 toks/s, output: 11.36 toks/s]
Processed prompts:  82%|████████▏ | 209/256 [00:18<00:04, 10.03it/s, est. speed input: 11614.75 toks/s, output: 11.34 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:18<00:04, 10.02it/s, est. speed input: 11600.13 toks/s, output: 11.33 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:18<00:04, 10.02it/s, est. speed input: 11585.80 toks/s, output: 11.31 toks/s]
Processed prompts:  84%|████████▍ | 215/256 [00:19<00:04, 10.01it/s, est. speed input: 11571.69 toks/s, output: 11.30 toks/s]
Processed prompts:  85%|████████▍ | 217/256 [00:19<00:03, 10.01it/s, est. speed input: 11558.05 toks/s, output: 11.29 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:19<00:03, 10.02it/s, est. speed input: 11544.79 toks/s, output: 11.27 toks/s]
Processed prompts:  86%|████████▋ | 221/256 [00:19<00:03, 10.03it/s, est. speed input: 11531.98 toks/s, output: 11.26 toks/s]
Processed prompts:  87%|████████▋ | 223/256 [00:19<00:03, 10.03it/s, est. speed input: 11519.28 toks/s, output: 11.25 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:20<00:03, 10.02it/s, est. speed input: 11506.73 toks/s, output: 11.24 toks/s]
Processed prompts:  89%|████████▊ | 227/256 [00:20<00:02, 10.02it/s, est. speed input: 11494.47 toks/s, output: 11.23 toks/s]
Processed prompts:  89%|████████▉ | 229/256 [00:20<00:02, 10.03it/s, est. speed input: 11482.68 toks/s, output: 11.21 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:20<00:02, 10.03it/s, est. speed input: 11470.86 toks/s, output: 11.20 toks/s]
Processed prompts:  91%|█████████ | 233/256 [00:20<00:02, 10.02it/s, est. speed input: 11458.94 toks/s, output: 11.19 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:21<00:02, 10.02it/s, est. speed input: 11447.57 toks/s, output: 11.18 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:21<00:01, 10.01it/s, est. speed input: 11436.20 toks/s, output: 11.17 toks/s]
Processed prompts:  93%|█████████▎| 239/256 [00:21<00:01, 10.02it/s, est. speed input: 11425.37 toks/s, output: 11.16 toks/s]
Processed prompts:  94%|█████████▍| 241/256 [00:21<00:01, 10.02it/s, est. speed input: 11414.49 toks/s, output: 11.15 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:21<00:01, 10.01it/s, est. speed input: 11403.78 toks/s, output: 11.14 toks/s]
Processed prompts:  96%|█████████▌| 245/256 [00:22<00:01, 10.01it/s, est. speed input: 11393.31 toks/s, output: 11.13 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:22<00:00, 10.01it/s, est. speed input: 11383.14 toks/s, output: 11.12 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:22<00:00, 10.02it/s, est. speed input: 11373.24 toks/s, output: 11.11 toks/s]
Processed prompts:  98%|█████████▊| 251/256 [00:22<00:00, 10.02it/s, est. speed input: 11363.58 toks/s, output: 11.10 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:22<00:00, 10.02it/s, est. speed input: 11353.91 toks/s, output: 11.09 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:23<00:00, 10.02it/s, est. speed input: 11344.48 toks/s, output: 11.08 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:23<00:00, 10.02it/s, est. speed input: 11336.31 toks/s, output: 11.07 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:23<00:00, 11.07it/s, est. speed input: 11336.31 toks/s, output: 11.07 toks/s]
[rank0]:[W126 08:02:32.123128115 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 89.9s

测试结果:
  Requests/s:   10.01
  Tokens/s:     10257.64
  Total Reqs:   256
  Elapsed:      25.58s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     10247.63

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:02:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:02:46 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=378832) WARNING 01-26 08:02:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=378832) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=378832) WARNING 01-26 08:03:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.07 requests/s, 10324.46 total tokens/s, 10.07 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 08:02:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:02:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:02:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:02:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:02:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:02:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:02:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:02:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:02:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=378832) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.40s/it]
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.38s/it]
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.08it/s]
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
(EngineCore_DP0 pid=378832) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
(EngineCore_DP0 pid=378832) 
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=378832) [2026-01-26 08:03:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=378832) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  2.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.15it/s]
(EngineCore_DP0 pid=378832) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  4.63it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  3.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.22it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 22/512 [00:00<00:02, 217.07it/s]
Adding requests:   9%|▉         | 47/512 [00:00<00:01, 235.11it/s]
Adding requests:  14%|█▍        | 73/512 [00:00<00:01, 246.23it/s]
Adding requests:  19%|█▉        | 98/512 [00:00<00:01, 245.52it/s]
Adding requests:  24%|██▍       | 123/512 [00:00<00:01, 243.58it/s]
Adding requests:  29%|██▉       | 149/512 [00:00<00:01, 246.33it/s]
Adding requests:  34%|███▍      | 176/512 [00:00<00:01, 252.16it/s]
Adding requests:  39%|███▉      | 202/512 [00:00<00:01, 254.27it/s]
Adding requests:  45%|████▍     | 228/512 [00:00<00:01, 255.20it/s]
Adding requests:  50%|████▉     | 254/512 [00:01<00:01, 252.22it/s]
Adding requests:  55%|█████▍    | 280/512 [00:01<00:00, 252.72it/s]
Adding requests:  60%|█████▉    | 306/512 [00:01<00:00, 252.98it/s]
Adding requests:  65%|██████▌   | 334/512 [00:01<00:00, 260.90it/s]
Adding requests:  71%|███████   | 362/512 [00:01<00:00, 263.93it/s]
Adding requests:  76%|███████▌  | 389/512 [00:01<00:00, 265.52it/s]
Adding requests:  82%|████████▏ | 418/512 [00:01<00:00, 272.10it/s]
Adding requests:  87%|████████▋ | 446/512 [00:01<00:00, 265.61it/s]
Adding requests:  92%|█████████▏| 473/512 [00:01<00:00, 266.32it/s]
Adding requests:  98%|█████████▊| 502/512 [00:01<00:00, 271.40it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 258.46it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:10, 46.89it/s, est. speed input: 48021.28 toks/s, output: 46.89 toks/s]
Processed prompts:   4%|▍         | 23/512 [00:00<00:18, 26.69it/s, est. speed input: 30406.54 toks/s, output: 29.69 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:01<00:27, 17.99it/s, est. speed input: 22860.20 toks/s, output: 22.32 toks/s]
Processed prompts:   6%|▌         | 30/512 [00:01<00:32, 14.93it/s, est. speed input: 19757.76 toks/s, output: 19.29 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:01<00:36, 13.24it/s, est. speed input: 17897.43 toks/s, output: 17.48 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:02<00:38, 12.22it/s, est. speed input: 16663.83 toks/s, output: 16.27 toks/s]
Processed prompts:  11%|█         | 54/512 [00:02<00:16, 27.92it/s, est. speed input: 22506.33 toks/s, output: 21.98 toks/s]
Processed prompts:  12%|█▏        | 60/512 [00:02<00:19, 23.18it/s, est. speed input: 21573.28 toks/s, output: 21.07 toks/s]
Processed prompts:  12%|█▎        | 64/512 [00:03<00:24, 18.66it/s, est. speed input: 20234.92 toks/s, output: 19.76 toks/s]
Processed prompts:  13%|█▎        | 68/512 [00:03<00:28, 15.85it/s, est. speed input: 19182.52 toks/s, output: 18.73 toks/s]
Processed prompts:  14%|█▍        | 71/512 [00:04<00:33, 13.20it/s, est. speed input: 18079.00 toks/s, output: 17.66 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:04<00:38, 11.46it/s, est. speed input: 17172.01 toks/s, output: 16.77 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:04<00:39, 11.07it/s, est. speed input: 16624.45 toks/s, output: 16.23 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:05<00:39, 10.81it/s, est. speed input: 16160.32 toks/s, output: 15.78 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:05<00:40, 10.62it/s, est. speed input: 15759.63 toks/s, output: 15.39 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:05<00:40, 10.50it/s, est. speed input: 15411.76 toks/s, output: 15.05 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:06<00:40, 10.41it/s, est. speed input: 15106.52 toks/s, output: 14.75 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:06<00:40, 10.34it/s, est. speed input: 14836.06 toks/s, output: 14.49 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:07<00:39, 10.30it/s, est. speed input: 14596.19 toks/s, output: 14.25 toks/s]
Processed prompts:  21%|██        | 106/512 [00:07<00:39, 10.27it/s, est. speed input: 14380.53 toks/s, output: 14.04 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:07<00:39, 10.25it/s, est. speed input: 14185.13 toks/s, output: 13.85 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:08<00:38, 10.23it/s, est. speed input: 14008.85 toks/s, output: 13.68 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:08<00:38, 10.22it/s, est. speed input: 13848.06 toks/s, output: 13.52 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:09<00:38, 10.21it/s, est. speed input: 13700.63 toks/s, output: 13.38 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:09<00:37, 10.20it/s, est. speed input: 13565.20 toks/s, output: 13.25 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:09<00:37, 10.19it/s, est. speed input: 13439.98 toks/s, output: 13.12 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:10<00:37, 10.18it/s, est. speed input: 13324.39 toks/s, output: 13.01 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:10<00:36, 10.18it/s, est. speed input: 13217.32 toks/s, output: 12.91 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:11<00:36, 10.17it/s, est. speed input: 13117.37 toks/s, output: 12.81 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:11<00:35, 10.17it/s, est. speed input: 13024.39 toks/s, output: 12.72 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:11<00:35, 10.17it/s, est. speed input: 12937.23 toks/s, output: 12.63 toks/s]
Processed prompts:  30%|███       | 154/512 [00:12<00:35, 10.16it/s, est. speed input: 12855.90 toks/s, output: 12.55 toks/s]
Processed prompts:  31%|███       | 158/512 [00:12<00:34, 10.16it/s, est. speed input: 12779.32 toks/s, output: 12.48 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:13<00:34, 10.16it/s, est. speed input: 12707.32 toks/s, output: 12.41 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:13<00:34, 10.15it/s, est. speed input: 12639.43 toks/s, output: 12.34 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:13<00:33, 10.15it/s, est. speed input: 12574.95 toks/s, output: 12.28 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:14<00:33, 10.14it/s, est. speed input: 12513.99 toks/s, output: 12.22 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:14<00:32, 10.14it/s, est. speed input: 12456.45 toks/s, output: 12.16 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:15<00:32, 10.14it/s, est. speed input: 12402.00 toks/s, output: 12.11 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:15<00:32, 10.14it/s, est. speed input: 12350.14 toks/s, output: 12.06 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:15<00:31, 10.14it/s, est. speed input: 12300.87 toks/s, output: 12.01 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:16<00:31, 10.14it/s, est. speed input: 12253.94 toks/s, output: 11.97 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:16<00:30, 10.13it/s, est. speed input: 12209.04 toks/s, output: 11.92 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:17<00:30, 10.13it/s, est. speed input: 12166.20 toks/s, output: 11.88 toks/s]
Processed prompts:  40%|████      | 206/512 [00:17<00:30, 10.13it/s, est. speed input: 12125.57 toks/s, output: 11.84 toks/s]
Processed prompts:  41%|████      | 210/512 [00:17<00:29, 10.13it/s, est. speed input: 12086.41 toks/s, output: 11.80 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:18<00:29, 10.12it/s, est. speed input: 12048.94 toks/s, output: 11.77 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:18<00:29, 10.12it/s, est. speed input: 12012.98 toks/s, output: 11.73 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:18<00:28, 10.12it/s, est. speed input: 11978.33 toks/s, output: 11.70 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:19<00:28, 10.12it/s, est. speed input: 11945.13 toks/s, output: 11.67 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:19<00:27, 10.11it/s, est. speed input: 11913.28 toks/s, output: 11.63 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:20<00:27, 10.11it/s, est. speed input: 11882.48 toks/s, output: 11.60 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:20<00:27, 10.11it/s, est. speed input: 11853.14 toks/s, output: 11.58 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:20<00:26, 10.11it/s, est. speed input: 11824.71 toks/s, output: 11.55 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:21<00:26, 10.11it/s, est. speed input: 11797.23 toks/s, output: 11.52 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:21<00:25, 10.10it/s, est. speed input: 11770.64 toks/s, output: 11.49 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:22<00:25, 10.10it/s, est. speed input: 11744.97 toks/s, output: 11.47 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:22<00:25, 10.10it/s, est. speed input: 11720.24 toks/s, output: 11.45 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:22<00:24, 10.10it/s, est. speed input: 11696.39 toks/s, output: 11.42 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:23<00:24, 10.10it/s, est. speed input: 11673.27 toks/s, output: 11.40 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:23<00:23, 10.10it/s, est. speed input: 11650.89 toks/s, output: 11.38 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:24<00:23, 10.10it/s, est. speed input: 11629.31 toks/s, output: 11.36 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:24<00:23, 10.09it/s, est. speed input: 11608.39 toks/s, output: 11.34 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:24<00:22, 10.09it/s, est. speed input: 11588.04 toks/s, output: 11.32 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:25<00:22, 10.09it/s, est. speed input: 11568.42 toks/s, output: 11.30 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:25<00:22, 10.09it/s, est. speed input: 11549.30 toks/s, output: 11.28 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:26<00:21, 10.09it/s, est. speed input: 11530.97 toks/s, output: 11.26 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:26<00:21, 10.10it/s, est. speed input: 11513.31 toks/s, output: 11.24 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:26<00:20, 10.10it/s, est. speed input: 11496.25 toks/s, output: 11.23 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:27<00:20, 10.10it/s, est. speed input: 11479.62 toks/s, output: 11.21 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:27<00:19, 10.10it/s, est. speed input: 11463.47 toks/s, output: 11.19 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:28<00:19, 10.11it/s, est. speed input: 11447.79 toks/s, output: 11.18 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:28<00:19, 10.10it/s, est. speed input: 11432.48 toks/s, output: 11.16 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:28<00:18, 10.10it/s, est. speed input: 11417.49 toks/s, output: 11.15 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:29<00:18, 10.11it/s, est. speed input: 11403.20 toks/s, output: 11.14 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:29<00:18, 10.10it/s, est. speed input: 11388.98 toks/s, output: 11.12 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:30<00:17, 10.10it/s, est. speed input: 11375.30 toks/s, output: 11.11 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:30<00:17, 10.11it/s, est. speed input: 11361.97 toks/s, output: 11.10 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:30<00:16, 10.10it/s, est. speed input: 11348.79 toks/s, output: 11.08 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:31<00:16, 10.10it/s, est. speed input: 11336.20 toks/s, output: 11.07 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:31<00:16, 10.10it/s, est. speed input: 11323.85 toks/s, output: 11.06 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:32<00:15, 10.10it/s, est. speed input: 11311.73 toks/s, output: 11.05 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:32<00:15, 10.10it/s, est. speed input: 11299.91 toks/s, output: 11.04 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:32<00:14, 10.10it/s, est. speed input: 11288.30 toks/s, output: 11.02 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:33<00:14, 10.10it/s, est. speed input: 11277.03 toks/s, output: 11.01 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:33<00:14, 10.10it/s, est. speed input: 11266.10 toks/s, output: 11.00 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:33<00:05, 23.90it/s, est. speed input: 11705.91 toks/s, output: 11.43 toks/s]
Processed prompts:  76%|███████▋  | 391/512 [00:34<00:06, 19.98it/s, est. speed input: 11720.15 toks/s, output: 11.45 toks/s]
Processed prompts:  77%|███████▋  | 395/512 [00:34<00:07, 16.71it/s, est. speed input: 11704.62 toks/s, output: 11.43 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:34<00:08, 13.78it/s, est. speed input: 11660.15 toks/s, output: 11.39 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:35<00:08, 12.62it/s, est. speed input: 11645.45 toks/s, output: 11.37 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:35<00:08, 11.84it/s, est. speed input: 11631.06 toks/s, output: 11.36 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:36<00:09, 11.30it/s, est. speed input: 11616.78 toks/s, output: 11.34 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:36<00:08, 10.93it/s, est. speed input: 11602.97 toks/s, output: 11.33 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:36<00:08, 10.68it/s, est. speed input: 11589.51 toks/s, output: 11.32 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:37<00:08, 10.51it/s, est. speed input: 11576.37 toks/s, output: 11.31 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:37<00:08, 10.39it/s, est. speed input: 11563.48 toks/s, output: 11.29 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:38<00:07, 10.30it/s, est. speed input: 11550.85 toks/s, output: 11.28 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:38<00:07, 10.24it/s, est. speed input: 11538.49 toks/s, output: 11.27 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:38<00:07, 10.20it/s, est. speed input: 11526.25 toks/s, output: 11.26 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:39<00:06, 10.17it/s, est. speed input: 11514.23 toks/s, output: 11.24 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:39<00:06, 10.15it/s, est. speed input: 11502.49 toks/s, output: 11.23 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:40<00:06, 10.14it/s, est. speed input: 11491.31 toks/s, output: 11.22 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:40<00:05, 10.13it/s, est. speed input: 11480.13 toks/s, output: 11.21 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:40<00:05, 10.12it/s, est. speed input: 11468.96 toks/s, output: 11.20 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:41<00:04, 10.11it/s, est. speed input: 11458.10 toks/s, output: 11.19 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:41<00:04, 10.10it/s, est. speed input: 11447.31 toks/s, output: 11.18 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:42<00:04, 10.09it/s, est. speed input: 11436.64 toks/s, output: 11.17 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:42<00:03, 10.09it/s, est. speed input: 11426.26 toks/s, output: 11.16 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:42<00:03, 10.08it/s, est. speed input: 11415.92 toks/s, output: 11.15 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:43<00:02, 10.08it/s, est. speed input: 11405.82 toks/s, output: 11.14 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:43<00:02, 10.08it/s, est. speed input: 11396.03 toks/s, output: 11.13 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:44<00:02, 10.08it/s, est. speed input: 11386.45 toks/s, output: 11.12 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:44<00:01, 10.09it/s, est. speed input: 11377.05 toks/s, output: 11.11 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:44<00:01, 10.08it/s, est. speed input: 11367.65 toks/s, output: 11.10 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:45<00:00, 10.08it/s, est. speed input: 11358.39 toks/s, output: 11.09 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:45<00:00, 10.08it/s, est. speed input: 11349.44 toks/s, output: 11.08 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:45<00:00, 10.82it/s, est. speed input: 11362.95 toks/s, output: 11.10 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:45<00:00, 10.82it/s, est. speed input: 11407.45 toks/s, output: 11.14 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:45<00:00, 11.14it/s, est. speed input: 11407.45 toks/s, output: 11.14 toks/s]
[rank0]:[W126 08:04:27.969808880 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 115.1s

测试结果:
  Requests/s:   10.07
  Tokens/s:     10324.46
  Total Reqs:   512
  Elapsed:      50.83s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     10314.39

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:04:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:04:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=380708) WARNING 01-26 08:04:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=380708) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=380708) WARNING 01-26 08:05:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.06 requests/s, 10311.56 total tokens/s, 10.06 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 08:04:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:04:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:04:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:04:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:04:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:04:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:04:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:04:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:04:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:04:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:04:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:04:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:04:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:04:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:04:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:04:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:04:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=380708) [2026-01-26 08:04:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.40s/it]
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.38s/it]
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.07it/s]
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
(EngineCore_DP0 pid=380708) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
(EngineCore_DP0 pid=380708) 
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=380708) [2026-01-26 08:05:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=380708) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  5.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.78it/s]
(EngineCore_DP0 pid=380708) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:01,  2.31it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.08it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:01<00:00,  3.06it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  3.35it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 23/1024 [00:00<00:04, 226.10it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 238.34it/s]
Adding requests:   7%|▋         | 74/1024 [00:00<00:03, 248.05it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:03, 247.24it/s]
Adding requests:  12%|█▏        | 124/1024 [00:00<00:03, 246.29it/s]
Adding requests:  15%|█▍        | 149/1024 [00:00<00:03, 240.10it/s]
Adding requests:  17%|█▋        | 176/1024 [00:00<00:03, 247.18it/s]
Adding requests:  20%|█▉        | 203/1024 [00:00<00:03, 253.37it/s]
Adding requests:  22%|██▏       | 230/1024 [00:00<00:03, 257.41it/s]
Adding requests:  25%|██▌       | 256/1024 [00:01<00:03, 251.29it/s]
Adding requests:  28%|██▊       | 282/1024 [00:01<00:02, 252.23it/s]
Adding requests:  30%|███       | 309/1024 [00:01<00:02, 254.16it/s]
Adding requests:  33%|███▎      | 337/1024 [00:01<00:02, 260.52it/s]
Adding requests:  36%|███▌      | 364/1024 [00:01<00:02, 261.66it/s]
Adding requests:  38%|███▊      | 392/1024 [00:01<00:02, 264.75it/s]
Adding requests:  41%|████      | 420/1024 [00:01<00:02, 268.57it/s]
Adding requests:  44%|████▎     | 447/1024 [00:01<00:02, 258.99it/s]
Adding requests:  46%|████▋     | 476/1024 [00:01<00:02, 266.43it/s]
Adding requests:  49%|████▉     | 505/1024 [00:01<00:01, 271.85it/s]
Adding requests:  52%|█████▏    | 535/1024 [00:02<00:01, 277.65it/s]
Adding requests:  55%|█████▍    | 563/1024 [00:02<00:01, 275.09it/s]
Adding requests:  58%|█████▊    | 591/1024 [00:02<00:01, 266.13it/s]
Adding requests:  60%|██████    | 618/1024 [00:02<00:01, 264.74it/s]
Adding requests:  63%|██████▎   | 645/1024 [00:02<00:01, 255.19it/s]
Adding requests:  66%|██████▌   | 671/1024 [00:02<00:01, 249.84it/s]
Adding requests:  68%|██████▊   | 698/1024 [00:02<00:01, 254.31it/s]
Adding requests:  71%|███████   | 724/1024 [00:02<00:01, 253.93it/s]
Adding requests:  73%|███████▎  | 750/1024 [00:02<00:01, 249.21it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:03<00:00, 250.38it/s]
Adding requests:  78%|███████▊  | 802/1024 [00:03<00:00, 251.69it/s]
Adding requests:  81%|████████  | 828/1024 [00:03<00:00, 253.36it/s]
Adding requests:  83%|████████▎ | 854/1024 [00:03<00:00, 252.89it/s]
Adding requests:  86%|████████▌ | 880/1024 [00:03<00:00, 252.82it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:03<00:00, 258.03it/s]
Adding requests:  91%|█████████ | 934/1024 [00:03<00:00, 249.53it/s]
Adding requests:  94%|█████████▍| 960/1024 [00:03<00:00, 250.55it/s]
Adding requests:  96%|█████████▋| 986/1024 [00:03<00:00, 249.33it/s]
Adding requests:  99%|█████████▊| 1011/1024 [00:03<00:00, 247.56it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 254.99it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 38/1024 [00:00<00:09, 99.33it/s, est. speed input: 101726.42 toks/s, output: 99.34 toks/s]
Processed prompts:   5%|▍         | 48/1024 [00:01<00:28, 34.85it/s, est. speed input: 42195.39 toks/s, output: 41.21 toks/s] 
Processed prompts:   5%|▌         | 53/1024 [00:01<00:35, 27.19it/s, est. speed input: 34877.54 toks/s, output: 34.06 toks/s]
Processed prompts:   6%|▌         | 57/1024 [00:01<00:44, 21.57it/s, est. speed input: 29978.67 toks/s, output: 29.28 toks/s]
Processed prompts:   6%|▌         | 60/1024 [00:02<00:56, 17.10it/s, est. speed input: 26276.57 toks/s, output: 25.66 toks/s]
Processed prompts:   6%|▌         | 62/1024 [00:02<01:12, 13.32it/s, est. speed input: 23259.18 toks/s, output: 22.71 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:03<01:17, 12.36it/s, est. speed input: 21653.39 toks/s, output: 21.15 toks/s]
Processed prompts:   7%|▋         | 70/1024 [00:03<01:21, 11.70it/s, est. speed input: 20405.42 toks/s, output: 19.93 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:03<01:24, 11.25it/s, est. speed input: 19410.32 toks/s, output: 18.96 toks/s]
Processed prompts:   8%|▊         | 78/1024 [00:04<01:26, 10.94it/s, est. speed input: 18594.55 toks/s, output: 18.16 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:04<01:27, 10.72it/s, est. speed input: 17915.27 toks/s, output: 17.50 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:04<00:37, 24.60it/s, est. speed input: 20794.28 toks/s, output: 20.31 toks/s]
Processed prompts:  10%|█         | 103/1024 [00:05<00:44, 20.47it/s, est. speed input: 20213.45 toks/s, output: 19.74 toks/s]
Processed prompts:  10%|█         | 107/1024 [00:05<00:53, 17.05it/s, est. speed input: 19530.88 toks/s, output: 19.07 toks/s]
Processed prompts:  11%|█         | 110/1024 [00:06<01:05, 14.01it/s, est. speed input: 18764.14 toks/s, output: 18.32 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:06<01:11, 12.81it/s, est. speed input: 18253.22 toks/s, output: 17.83 toks/s]
Processed prompts:  12%|█▏        | 118/1024 [00:06<01:15, 11.99it/s, est. speed input: 17800.32 toks/s, output: 17.38 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:07<01:18, 11.43it/s, est. speed input: 17395.83 toks/s, output: 16.99 toks/s]
Processed prompts:  12%|█▏        | 126/1024 [00:07<01:21, 11.05it/s, est. speed input: 17034.36 toks/s, output: 16.64 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:07<01:22, 10.78it/s, est. speed input: 16707.91 toks/s, output: 16.32 toks/s]
Processed prompts:  13%|█▎        | 134/1024 [00:08<01:24, 10.59it/s, est. speed input: 16410.22 toks/s, output: 16.03 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:08<01:24, 10.46it/s, est. speed input: 16140.74 toks/s, output: 15.76 toks/s]
Processed prompts:  14%|█▍        | 142/1024 [00:09<01:25, 10.37it/s, est. speed input: 15893.65 toks/s, output: 15.52 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:09<01:25, 10.30it/s, est. speed input: 15666.17 toks/s, output: 15.30 toks/s]
Processed prompts:  15%|█▍        | 150/1024 [00:09<01:25, 10.26it/s, est. speed input: 15458.16 toks/s, output: 15.10 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:10<01:25, 10.23it/s, est. speed input: 15265.18 toks/s, output: 14.91 toks/s]
Processed prompts:  15%|█▌        | 158/1024 [00:10<01:24, 10.20it/s, est. speed input: 15085.46 toks/s, output: 14.73 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:11<01:24, 10.19it/s, est. speed input: 14919.70 toks/s, output: 14.57 toks/s]
Processed prompts:  16%|█▌        | 166/1024 [00:11<01:24, 10.17it/s, est. speed input: 14763.70 toks/s, output: 14.42 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:11<01:24, 10.16it/s, est. speed input: 14618.77 toks/s, output: 14.28 toks/s]
Processed prompts:  17%|█▋        | 174/1024 [00:12<01:23, 10.16it/s, est. speed input: 14483.30 toks/s, output: 14.14 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:12<01:23, 10.15it/s, est. speed input: 14356.05 toks/s, output: 14.02 toks/s]
Processed prompts:  18%|█▊        | 182/1024 [00:13<01:22, 10.15it/s, est. speed input: 14236.27 toks/s, output: 13.90 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:13<01:22, 10.14it/s, est. speed input: 14123.24 toks/s, output: 13.79 toks/s]
Processed prompts:  19%|█▊        | 190/1024 [00:13<01:22, 10.14it/s, est. speed input: 14016.57 toks/s, output: 13.69 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:14<01:21, 10.14it/s, est. speed input: 13916.43 toks/s, output: 13.59 toks/s]
Processed prompts:  19%|█▉        | 198/1024 [00:14<01:21, 10.14it/s, est. speed input: 13821.05 toks/s, output: 13.50 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:15<01:21, 10.14it/s, est. speed input: 13730.79 toks/s, output: 13.41 toks/s]
Processed prompts:  20%|██        | 206/1024 [00:15<01:20, 10.14it/s, est. speed input: 13645.29 toks/s, output: 13.33 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:15<01:20, 10.13it/s, est. speed input: 13563.70 toks/s, output: 13.25 toks/s]
Processed prompts:  21%|██        | 214/1024 [00:16<01:19, 10.14it/s, est. speed input: 13486.44 toks/s, output: 13.17 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:16<01:19, 10.13it/s, est. speed input: 13412.54 toks/s, output: 13.10 toks/s]
Processed prompts:  22%|██▏       | 222/1024 [00:17<01:19, 10.13it/s, est. speed input: 13342.34 toks/s, output: 13.03 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:17<01:18, 10.13it/s, est. speed input: 13274.95 toks/s, output: 12.96 toks/s]
Processed prompts:  22%|██▏       | 230/1024 [00:17<01:18, 10.13it/s, est. speed input: 13210.64 toks/s, output: 12.90 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:18<01:17, 10.13it/s, est. speed input: 13149.05 toks/s, output: 12.84 toks/s]
Processed prompts:  23%|██▎       | 238/1024 [00:18<01:17, 10.13it/s, est. speed input: 13090.25 toks/s, output: 12.78 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:19<01:17, 10.13it/s, est. speed input: 13033.66 toks/s, output: 12.73 toks/s]
Processed prompts:  24%|██▍       | 246/1024 [00:19<01:16, 10.13it/s, est. speed input: 12979.34 toks/s, output: 12.68 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:19<01:16, 10.13it/s, est. speed input: 12927.23 toks/s, output: 12.62 toks/s]
Processed prompts:  25%|██▍       | 254/1024 [00:20<01:16, 10.12it/s, est. speed input: 12877.09 toks/s, output: 12.58 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:20<01:15, 10.12it/s, est. speed input: 12828.91 toks/s, output: 12.53 toks/s]
Processed prompts:  26%|██▌       | 262/1024 [00:20<01:15, 10.12it/s, est. speed input: 12782.53 toks/s, output: 12.48 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:21<01:14, 10.12it/s, est. speed input: 12737.87 toks/s, output: 12.44 toks/s]
Processed prompts:  26%|██▋       | 270/1024 [00:21<01:14, 10.12it/s, est. speed input: 12694.65 toks/s, output: 12.40 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:22<01:14, 10.12it/s, est. speed input: 12653.11 toks/s, output: 12.36 toks/s]
Processed prompts:  27%|██▋       | 278/1024 [00:22<01:13, 10.12it/s, est. speed input: 12613.11 toks/s, output: 12.32 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:22<01:13, 10.12it/s, est. speed input: 12574.11 toks/s, output: 12.28 toks/s]
Processed prompts:  28%|██▊       | 286/1024 [00:23<01:12, 10.12it/s, est. speed input: 12536.56 toks/s, output: 12.24 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:23<01:12, 10.12it/s, est. speed input: 12500.24 toks/s, output: 12.21 toks/s]
Processed prompts:  29%|██▊       | 294/1024 [00:24<01:12, 10.11it/s, est. speed input: 12465.13 toks/s, output: 12.17 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:24<01:11, 10.11it/s, est. speed input: 12431.19 toks/s, output: 12.14 toks/s]
Processed prompts:  29%|██▉       | 302/1024 [00:24<01:11, 10.11it/s, est. speed input: 12398.22 toks/s, output: 12.11 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:25<01:11, 10.11it/s, est. speed input: 12366.19 toks/s, output: 12.08 toks/s]
Processed prompts:  30%|███       | 310/1024 [00:25<01:10, 10.11it/s, est. speed input: 12335.16 toks/s, output: 12.05 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:26<01:10, 10.11it/s, est. speed input: 12305.25 toks/s, output: 12.02 toks/s]
Processed prompts:  31%|███       | 318/1024 [00:26<01:09, 10.11it/s, est. speed input: 12276.09 toks/s, output: 11.99 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:26<01:09, 10.11it/s, est. speed input: 12247.61 toks/s, output: 11.96 toks/s]
Processed prompts:  32%|███▏      | 326/1024 [00:27<01:09, 10.11it/s, est. speed input: 12220.15 toks/s, output: 11.93 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:27<01:08, 10.10it/s, est. speed input: 12193.25 toks/s, output: 11.91 toks/s]
Processed prompts:  33%|███▎      | 334/1024 [00:28<01:08, 10.11it/s, est. speed input: 12167.43 toks/s, output: 11.88 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:28<01:07, 10.11it/s, est. speed input: 12142.26 toks/s, output: 11.86 toks/s]
Processed prompts:  33%|███▎      | 342/1024 [00:28<01:07, 10.11it/s, est. speed input: 12117.58 toks/s, output: 11.83 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:29<01:07, 10.11it/s, est. speed input: 12093.65 toks/s, output: 11.81 toks/s]
Processed prompts:  34%|███▍      | 350/1024 [00:29<01:06, 10.10it/s, est. speed input: 12070.35 toks/s, output: 11.79 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:30<01:06, 10.10it/s, est. speed input: 12047.71 toks/s, output: 11.77 toks/s]
Processed prompts:  35%|███▍      | 358/1024 [00:30<01:05, 10.11it/s, est. speed input: 12025.65 toks/s, output: 11.74 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:30<01:05, 10.11it/s, est. speed input: 12004.16 toks/s, output: 11.72 toks/s]
Processed prompts:  36%|███▌      | 366/1024 [00:31<01:05, 10.11it/s, est. speed input: 11983.17 toks/s, output: 11.70 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:31<01:04, 10.11it/s, est. speed input: 11962.78 toks/s, output: 11.68 toks/s]
Processed prompts:  37%|███▋      | 374/1024 [00:32<01:04, 10.11it/s, est. speed input: 11942.81 toks/s, output: 11.66 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:32<01:03, 10.10it/s, est. speed input: 11923.33 toks/s, output: 11.64 toks/s]
Processed prompts:  37%|███▋      | 382/1024 [00:32<01:03, 10.11it/s, est. speed input: 11904.41 toks/s, output: 11.63 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:33<01:03, 10.10it/s, est. speed input: 11885.71 toks/s, output: 11.61 toks/s]
Processed prompts:  38%|███▊      | 390/1024 [00:33<01:02, 10.10it/s, est. speed input: 11867.56 toks/s, output: 11.59 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:34<01:02, 10.10it/s, est. speed input: 11849.83 toks/s, output: 11.57 toks/s]
Processed prompts:  39%|███▉      | 398/1024 [00:34<01:01, 10.10it/s, est. speed input: 11832.52 toks/s, output: 11.56 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:34<01:01, 10.10it/s, est. speed input: 11815.55 toks/s, output: 11.54 toks/s]
Processed prompts:  40%|███▉      | 406/1024 [00:35<01:01, 10.10it/s, est. speed input: 11798.85 toks/s, output: 11.52 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:35<01:00, 10.09it/s, est. speed input: 11782.37 toks/s, output: 11.51 toks/s]
Processed prompts:  40%|████      | 414/1024 [00:36<01:00, 10.09it/s, est. speed input: 11766.48 toks/s, output: 11.49 toks/s]
Processed prompts:  42%|████▏     | 430/1024 [00:36<00:24, 24.02it/s, est. speed input: 12177.32 toks/s, output: 11.89 toks/s]
Processed prompts:  42%|████▏     | 435/1024 [00:36<00:29, 20.03it/s, est. speed input: 12185.15 toks/s, output: 11.90 toks/s]
Processed prompts:  43%|████▎     | 439/1024 [00:36<00:35, 16.71it/s, est. speed input: 12165.12 toks/s, output: 11.88 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:37<00:42, 13.76it/s, est. speed input: 12118.06 toks/s, output: 11.83 toks/s]
Processed prompts:  44%|████▎     | 446/1024 [00:37<00:45, 12.60it/s, est. speed input: 12099.12 toks/s, output: 11.82 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:38<00:48, 11.81it/s, est. speed input: 12080.47 toks/s, output: 11.80 toks/s]
Processed prompts:  44%|████▍     | 454/1024 [00:38<00:50, 11.28it/s, est. speed input: 12062.43 toks/s, output: 11.78 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:38<00:51, 10.91it/s, est. speed input: 12044.66 toks/s, output: 11.76 toks/s]
Processed prompts:  45%|████▌     | 462/1024 [00:39<00:52, 10.66it/s, est. speed input: 12027.21 toks/s, output: 11.75 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:39<00:53, 10.49it/s, est. speed input: 12010.29 toks/s, output: 11.73 toks/s]
Processed prompts:  46%|████▌     | 470/1024 [00:40<00:53, 10.36it/s, est. speed input: 11993.38 toks/s, output: 11.71 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:40<00:53, 10.28it/s, est. speed input: 11977.09 toks/s, output: 11.70 toks/s]
Processed prompts:  47%|████▋     | 478/1024 [00:40<00:53, 10.21it/s, est. speed input: 11960.91 toks/s, output: 11.68 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:41<00:53, 10.17it/s, est. speed input: 11945.04 toks/s, output: 11.67 toks/s]
Processed prompts:  47%|████▋     | 486/1024 [00:41<00:53, 10.14it/s, est. speed input: 11929.59 toks/s, output: 11.65 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:42<00:52, 10.12it/s, est. speed input: 11914.29 toks/s, output: 11.64 toks/s]
Processed prompts:  48%|████▊     | 494/1024 [00:42<00:52, 10.11it/s, est. speed input: 11899.32 toks/s, output: 11.62 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:42<00:52, 10.10it/s, est. speed input: 11884.68 toks/s, output: 11.61 toks/s]
Processed prompts:  49%|████▉     | 502/1024 [00:43<00:51, 10.09it/s, est. speed input: 11870.13 toks/s, output: 11.59 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:43<00:51, 10.08it/s, est. speed input: 11855.96 toks/s, output: 11.58 toks/s]
Processed prompts:  50%|████▉     | 510/1024 [00:44<00:51, 10.08it/s, est. speed input: 11842.03 toks/s, output: 11.56 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:44<00:50, 10.07it/s, est. speed input: 11828.29 toks/s, output: 11.55 toks/s]
Processed prompts:  51%|█████     | 518/1024 [00:44<00:50, 10.07it/s, est. speed input: 11814.94 toks/s, output: 11.54 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:45<00:49, 10.07it/s, est. speed input: 11801.67 toks/s, output: 11.53 toks/s]
Processed prompts:  51%|█████▏    | 526/1024 [00:45<00:49, 10.07it/s, est. speed input: 11788.66 toks/s, output: 11.51 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:46<00:49, 10.07it/s, est. speed input: 11775.87 toks/s, output: 11.50 toks/s]
Processed prompts:  52%|█████▏    | 534/1024 [00:46<00:48, 10.07it/s, est. speed input: 11763.32 toks/s, output: 11.49 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:46<00:48, 10.06it/s, est. speed input: 11750.91 toks/s, output: 11.48 toks/s]
Processed prompts:  53%|█████▎    | 542/1024 [00:47<00:47, 10.07it/s, est. speed input: 11738.82 toks/s, output: 11.46 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:47<00:47, 10.06it/s, est. speed input: 11726.82 toks/s, output: 11.45 toks/s]
Processed prompts:  54%|█████▎    | 550/1024 [00:48<00:47, 10.06it/s, est. speed input: 11715.10 toks/s, output: 11.44 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:48<00:46, 10.07it/s, est. speed input: 11703.58 toks/s, output: 11.43 toks/s]
Processed prompts:  54%|█████▍    | 558/1024 [00:48<00:46, 10.07it/s, est. speed input: 11692.30 toks/s, output: 11.42 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:49<00:45, 10.07it/s, est. speed input: 11681.11 toks/s, output: 11.41 toks/s]
Processed prompts:  55%|█████▌    | 566/1024 [00:49<00:45, 10.07it/s, est. speed input: 11670.11 toks/s, output: 11.40 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:50<00:45, 10.07it/s, est. speed input: 11659.32 toks/s, output: 11.39 toks/s]
Processed prompts:  56%|█████▌    | 574/1024 [00:50<00:44, 10.07it/s, est. speed input: 11648.68 toks/s, output: 11.38 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:50<00:44, 10.07it/s, est. speed input: 11638.21 toks/s, output: 11.37 toks/s]
Processed prompts:  57%|█████▋    | 582/1024 [00:51<00:43, 10.07it/s, est. speed input: 11627.88 toks/s, output: 11.36 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:51<00:43, 10.07it/s, est. speed input: 11617.71 toks/s, output: 11.35 toks/s]
Processed prompts:  58%|█████▊    | 590/1024 [00:52<00:43, 10.07it/s, est. speed input: 11607.77 toks/s, output: 11.34 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:52<00:42, 10.07it/s, est. speed input: 11597.92 toks/s, output: 11.33 toks/s]
Processed prompts:  58%|█████▊    | 598/1024 [00:52<00:42, 10.07it/s, est. speed input: 11588.27 toks/s, output: 11.32 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:53<00:41, 10.07it/s, est. speed input: 11578.66 toks/s, output: 11.31 toks/s]
Processed prompts:  59%|█████▉    | 606/1024 [00:53<00:41, 10.06it/s, est. speed input: 11569.17 toks/s, output: 11.30 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:54<00:41, 10.06it/s, est. speed input: 11559.90 toks/s, output: 11.29 toks/s]
Processed prompts:  60%|█████▉    | 614/1024 [00:54<00:40, 10.06it/s, est. speed input: 11550.73 toks/s, output: 11.28 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:54<00:40, 10.06it/s, est. speed input: 11541.67 toks/s, output: 11.27 toks/s]
Processed prompts:  61%|██████    | 622/1024 [00:55<00:39, 10.06it/s, est. speed input: 11532.78 toks/s, output: 11.26 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:55<00:39, 10.07it/s, est. speed input: 11524.06 toks/s, output: 11.25 toks/s]
Processed prompts:  62%|██████▏   | 630/1024 [00:56<00:39, 10.06it/s, est. speed input: 11515.40 toks/s, output: 11.25 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:56<00:38, 10.07it/s, est. speed input: 11506.91 toks/s, output: 11.24 toks/s]
Processed prompts:  62%|██████▏   | 638/1024 [00:56<00:38, 10.07it/s, est. speed input: 11498.53 toks/s, output: 11.23 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:57<00:37, 10.06it/s, est. speed input: 11490.15 toks/s, output: 11.22 toks/s]
Processed prompts:  63%|██████▎   | 646/1024 [00:57<00:37, 10.06it/s, est. speed input: 11481.93 toks/s, output: 11.21 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:58<00:37, 10.06it/s, est. speed input: 11473.95 toks/s, output: 11.21 toks/s]
Processed prompts:  64%|██████▍   | 654/1024 [00:58<00:36, 10.07it/s, est. speed input: 11466.06 toks/s, output: 11.20 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:58<00:36, 10.07it/s, est. speed input: 11458.24 toks/s, output: 11.19 toks/s]
Processed prompts:  65%|██████▍   | 662/1024 [00:59<00:35, 10.07it/s, est. speed input: 11450.54 toks/s, output: 11.18 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:59<00:35, 10.07it/s, est. speed input: 11442.93 toks/s, output: 11.17 toks/s]
Processed prompts:  65%|██████▌   | 670/1024 [00:59<00:35, 10.07it/s, est. speed input: 11435.41 toks/s, output: 11.17 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [01:00<00:34, 10.07it/s, est. speed input: 11428.00 toks/s, output: 11.16 toks/s]
Processed prompts:  66%|██████▌   | 678/1024 [01:00<00:34, 10.07it/s, est. speed input: 11420.64 toks/s, output: 11.15 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [01:01<00:33, 10.06it/s, est. speed input: 11413.37 toks/s, output: 11.15 toks/s]
Processed prompts:  67%|██████▋   | 686/1024 [01:01<00:33, 10.06it/s, est. speed input: 11406.23 toks/s, output: 11.14 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [01:01<00:33, 10.06it/s, est. speed input: 11399.14 toks/s, output: 11.13 toks/s]
Processed prompts:  68%|██████▊   | 694/1024 [01:02<00:32, 10.06it/s, est. speed input: 11392.20 toks/s, output: 11.13 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [01:02<00:32, 10.06it/s, est. speed input: 11385.32 toks/s, output: 11.12 toks/s]
Processed prompts:  69%|██████▊   | 702/1024 [01:03<00:32, 10.06it/s, est. speed input: 11378.43 toks/s, output: 11.11 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [01:03<00:31, 10.06it/s, est. speed input: 11371.74 toks/s, output: 11.11 toks/s]
Processed prompts:  69%|██████▉   | 710/1024 [01:03<00:31, 10.06it/s, est. speed input: 11365.10 toks/s, output: 11.10 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [01:04<00:30, 10.06it/s, est. speed input: 11358.61 toks/s, output: 11.09 toks/s]
Processed prompts:  70%|███████   | 718/1024 [01:04<00:30, 10.06it/s, est. speed input: 11352.15 toks/s, output: 11.09 toks/s]
Processed prompts:  71%|███████   | 722/1024 [01:05<00:30, 10.06it/s, est. speed input: 11345.74 toks/s, output: 11.08 toks/s]
Processed prompts:  71%|███████   | 726/1024 [01:05<00:29, 10.06it/s, est. speed input: 11339.42 toks/s, output: 11.07 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [01:05<00:29, 10.06it/s, est. speed input: 11333.19 toks/s, output: 11.07 toks/s]
Processed prompts:  72%|███████▏  | 734/1024 [01:06<00:28, 10.07it/s, est. speed input: 11327.08 toks/s, output: 11.06 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [01:06<00:28, 10.07it/s, est. speed input: 11321.01 toks/s, output: 11.06 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [01:06<00:11, 23.71it/s, est. speed input: 11542.00 toks/s, output: 11.27 toks/s]
Processed prompts:  74%|███████▍  | 759/1024 [01:07<00:13, 19.85it/s, est. speed input: 11549.92 toks/s, output: 11.28 toks/s]
Processed prompts:  75%|███████▍  | 763/1024 [01:07<00:15, 16.60it/s, est. speed input: 11542.61 toks/s, output: 11.27 toks/s]
Processed prompts:  75%|███████▍  | 766/1024 [01:08<00:18, 13.70it/s, est. speed input: 11520.42 toks/s, output: 11.25 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [01:08<00:20, 12.56it/s, est. speed input: 11513.41 toks/s, output: 11.24 toks/s]
Processed prompts:  76%|███████▌  | 774/1024 [01:08<00:21, 11.79it/s, est. speed input: 11506.48 toks/s, output: 11.24 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [01:09<00:21, 11.26it/s, est. speed input: 11499.65 toks/s, output: 11.23 toks/s]
Processed prompts:  76%|███████▋  | 782/1024 [01:09<00:22, 10.89it/s, est. speed input: 11492.81 toks/s, output: 11.22 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [01:10<00:22, 10.64it/s, est. speed input: 11486.07 toks/s, output: 11.22 toks/s]
Processed prompts:  77%|███████▋  | 790/1024 [01:10<00:22, 10.47it/s, est. speed input: 11479.44 toks/s, output: 11.21 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [01:10<00:22, 10.35it/s, est. speed input: 11472.86 toks/s, output: 11.20 toks/s]
Processed prompts:  78%|███████▊  | 798/1024 [01:11<00:22, 10.26it/s, est. speed input: 11466.35 toks/s, output: 11.20 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [01:11<00:21, 10.20it/s, est. speed input: 11459.89 toks/s, output: 11.19 toks/s]
Processed prompts:  79%|███████▊  | 806/1024 [01:12<00:21, 10.16it/s, est. speed input: 11453.50 toks/s, output: 11.19 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [01:12<00:21, 10.13it/s, est. speed input: 11447.19 toks/s, output: 11.18 toks/s]
Processed prompts:  79%|███████▉  | 814/1024 [01:12<00:20, 10.11it/s, est. speed input: 11441.00 toks/s, output: 11.17 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [01:13<00:20, 10.10it/s, est. speed input: 11434.86 toks/s, output: 11.17 toks/s]
Processed prompts:  80%|████████  | 822/1024 [01:13<00:20, 10.08it/s, est. speed input: 11428.70 toks/s, output: 11.16 toks/s]
Processed prompts:  81%|████████  | 826/1024 [01:14<00:19, 10.08it/s, est. speed input: 11422.64 toks/s, output: 11.15 toks/s]
Processed prompts:  81%|████████  | 830/1024 [01:14<00:19, 10.07it/s, est. speed input: 11416.67 toks/s, output: 11.15 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [01:14<00:18, 10.07it/s, est. speed input: 11410.76 toks/s, output: 11.14 toks/s]
Processed prompts:  82%|████████▏ | 838/1024 [01:15<00:18, 10.07it/s, est. speed input: 11404.87 toks/s, output: 11.14 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [01:15<00:18, 10.06it/s, est. speed input: 11399.05 toks/s, output: 11.13 toks/s]
Processed prompts:  83%|████████▎ | 846/1024 [01:16<00:17, 10.06it/s, est. speed input: 11393.35 toks/s, output: 11.13 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [01:16<00:17, 10.06it/s, est. speed input: 11387.61 toks/s, output: 11.12 toks/s]
Processed prompts:  83%|████████▎ | 854/1024 [01:16<00:16, 10.06it/s, est. speed input: 11381.98 toks/s, output: 11.12 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [01:17<00:16, 10.06it/s, est. speed input: 11376.46 toks/s, output: 11.11 toks/s]
Processed prompts:  84%|████████▍ | 862/1024 [01:17<00:16, 10.06it/s, est. speed input: 11370.89 toks/s, output: 11.10 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [01:18<00:15, 10.06it/s, est. speed input: 11365.48 toks/s, output: 11.10 toks/s]
Processed prompts:  85%|████████▍ | 870/1024 [01:18<00:15, 10.06it/s, est. speed input: 11360.07 toks/s, output: 11.09 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [01:18<00:14, 10.06it/s, est. speed input: 11354.76 toks/s, output: 11.09 toks/s]
Processed prompts:  86%|████████▌ | 878/1024 [01:19<00:14, 10.07it/s, est. speed input: 11349.58 toks/s, output: 11.08 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [01:19<00:14, 10.06it/s, est. speed input: 11344.30 toks/s, output: 11.08 toks/s]
Processed prompts:  87%|████████▋ | 886/1024 [01:20<00:13, 10.07it/s, est. speed input: 11339.19 toks/s, output: 11.07 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [01:20<00:13, 10.06it/s, est. speed input: 11334.03 toks/s, output: 11.07 toks/s]
Processed prompts:  87%|████████▋ | 894/1024 [01:20<00:12, 10.06it/s, est. speed input: 11328.94 toks/s, output: 11.06 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [01:21<00:12, 10.06it/s, est. speed input: 11323.91 toks/s, output: 11.06 toks/s]
Processed prompts:  88%|████████▊ | 902/1024 [01:21<00:12, 10.06it/s, est. speed input: 11318.93 toks/s, output: 11.05 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [01:21<00:11, 10.06it/s, est. speed input: 11314.00 toks/s, output: 11.05 toks/s]
Processed prompts:  89%|████████▉ | 910/1024 [01:22<00:11, 10.06it/s, est. speed input: 11309.11 toks/s, output: 11.04 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [01:22<00:10, 10.06it/s, est. speed input: 11304.30 toks/s, output: 11.04 toks/s]
Processed prompts:  90%|████████▉ | 918/1024 [01:23<00:10, 10.06it/s, est. speed input: 11299.51 toks/s, output: 11.03 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [01:23<00:10, 10.06it/s, est. speed input: 11294.77 toks/s, output: 11.03 toks/s]
Processed prompts:  90%|█████████ | 926/1024 [01:23<00:09, 10.06it/s, est. speed input: 11290.06 toks/s, output: 11.03 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [01:24<00:09, 10.06it/s, est. speed input: 11285.43 toks/s, output: 11.02 toks/s]
Processed prompts:  91%|█████████ | 934/1024 [01:24<00:08, 10.06it/s, est. speed input: 11280.86 toks/s, output: 11.02 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [01:25<00:08, 10.07it/s, est. speed input: 11276.35 toks/s, output: 11.01 toks/s]
Processed prompts:  92%|█████████▏| 942/1024 [01:25<00:08, 10.06it/s, est. speed input: 11271.80 toks/s, output: 11.01 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [01:25<00:07, 10.06it/s, est. speed input: 11267.28 toks/s, output: 11.00 toks/s]
Processed prompts:  93%|█████████▎| 950/1024 [01:26<00:07, 10.06it/s, est. speed input: 11262.84 toks/s, output: 11.00 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [01:26<00:06, 10.06it/s, est. speed input: 11258.46 toks/s, output: 10.99 toks/s]
Processed prompts:  94%|█████████▎| 958/1024 [01:27<00:06, 10.06it/s, est. speed input: 11254.08 toks/s, output: 10.99 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [01:27<00:06, 10.06it/s, est. speed input: 11249.76 toks/s, output: 10.99 toks/s]
Processed prompts:  94%|█████████▍| 966/1024 [01:27<00:05, 10.06it/s, est. speed input: 11245.50 toks/s, output: 10.98 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [01:28<00:05, 10.06it/s, est. speed input: 11241.24 toks/s, output: 10.98 toks/s]
Processed prompts:  95%|█████████▌| 974/1024 [01:28<00:04, 10.06it/s, est. speed input: 11237.09 toks/s, output: 10.97 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [01:29<00:04, 10.06it/s, est. speed input: 11232.95 toks/s, output: 10.97 toks/s]
Processed prompts:  96%|█████████▌| 982/1024 [01:29<00:04, 10.06it/s, est. speed input: 11228.81 toks/s, output: 10.97 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [01:29<00:03, 10.06it/s, est. speed input: 11224.70 toks/s, output: 10.96 toks/s]
Processed prompts:  97%|█████████▋| 990/1024 [01:30<00:03, 10.06it/s, est. speed input: 11220.66 toks/s, output: 10.96 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [01:30<00:02, 10.07it/s, est. speed input: 11216.71 toks/s, output: 10.95 toks/s]
Processed prompts:  97%|█████████▋| 998/1024 [01:31<00:02, 10.06it/s, est. speed input: 11212.70 toks/s, output: 10.95 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [01:31<00:02, 10.06it/s, est. speed input: 11208.71 toks/s, output: 10.95 toks/s]
Processed prompts:  98%|█████████▊| 1006/1024 [01:31<00:01, 10.06it/s, est. speed input: 11204.79 toks/s, output: 10.94 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [01:32<00:01, 10.06it/s, est. speed input: 11200.90 toks/s, output: 10.94 toks/s]
Processed prompts:  99%|█████████▉| 1014/1024 [01:32<00:00, 10.06it/s, est. speed input: 11197.11 toks/s, output: 10.93 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [01:33<00:00, 10.06it/s, est. speed input: 11193.28 toks/s, output: 10.93 toks/s]
Processed prompts: 100%|█████████▉| 1022/1024 [01:33<00:00, 10.80it/s, est. speed input: 11200.31 toks/s, output: 10.94 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:33<00:00, 10.80it/s, est. speed input: 11222.20 toks/s, output: 10.96 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:33<00:00, 10.96it/s, est. speed input: 11222.20 toks/s, output: 10.96 toks/s]
[rank0]:[W126 08:07:17.543185149 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 169.4s

测试结果:
  Requests/s:   10.06
  Tokens/s:     10311.56
  Total Reqs:   1024
  Elapsed:      101.79s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     10301.50

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:07:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:07:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=383407) WARNING 01-26 08:07:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=383407) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=383407) WARNING 01-26 08:08:11 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=383407) ERROR 01-26 08:08:32 [core.py:866] ValueError: To serve at least one request with the models's max seq len (1025), (0.19 GiB KV cache is needed, which is larger than the available KV cache memory (0.18 GiB). Based on the available memory, the estimated maximum model length is 960. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:07:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:07:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:07:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:07:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:07:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:07:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:07:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:07:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:07:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:07:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:07:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:07:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:07:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:07:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:07:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:07:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:07:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.40s/it]
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.38s/it]
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.08it/s]
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
(EngineCore_DP0 pid=383407) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
(EngineCore_DP0 pid=383407) 
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=383407) [2026-01-26 08:07:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=383407) [rank0]:W0126 08:08:23.861000 383407 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=383407) [rank0]:W0126 08:08:23.941000 383407 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=383407) [rank0]:W0126 08:08:25.598000 383407 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=383407) [rank0]:W0126 08:08:25.718000 383407 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=383407) Process EngineCore_DP0:
(EngineCore_DP0 pid=383407) Traceback (most recent call last):
(EngineCore_DP0 pid=383407)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=383407)     self.run()
(EngineCore_DP0 pid=383407)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=383407)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=383407)     raise e
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=383407)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=383407)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=383407)     super().__init__(
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=383407)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=383407)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=383407)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=383407)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=383407)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=383407)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=383407)     raise ValueError(
(EngineCore_DP0 pid=383407) ValueError: To serve at least one request with the models's max seq len (1025), (0.19 GiB KV cache is needed, which is larger than the available KV cache memory (0.18 GiB). Based on the available memory, the estimated maximum model length is 960. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:08:34.865543788 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:09:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:09:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=384906) WARNING 01-26 08:09:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=384906) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=384906) WARNING 01-26 08:09:54 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=384906) ERROR 01-26 08:11:36 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:09:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:09:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:09:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:09:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:09:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:09:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:09:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:09:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:09:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:09:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:09:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:09:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:09:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:09:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:09:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:09:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:09:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 08:09:32.012671433 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.46s/it]
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.41s/it]
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.06it/s]
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.11s/it]
(EngineCore_DP0 pid=384906) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
(EngineCore_DP0 pid=384906) 
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=384906) [2026-01-26 08:09:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=384906) [rank0]:W0126 08:10:06.483000 384906 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=384906) [rank0]:W0126 08:10:06.562000 384906 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=384906) [rank0]:W0126 08:10:08.672000 384906 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=384906) [rank0]:W0126 08:10:08.789000 384906 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=384906) Process EngineCore_DP0:
(EngineCore_DP0 pid=384906) Traceback (most recent call last):
(EngineCore_DP0 pid=384906)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=384906)     self.run()
(EngineCore_DP0 pid=384906)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=384906)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=384906)     raise e
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=384906)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=384906)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=384906)     super().__init__(
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=384906)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=384906)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=384906)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=384906)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=384906)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=384906)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=384906)     raise ValueError(
(EngineCore_DP0 pid=384906) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:11:37.727815867 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:12:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:12:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=388096) WARNING 01-26 08:12:59 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=388096) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=388096) WARNING 01-26 08:13:20 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=388096) ERROR 01-26 08:18:23 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:12:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:12:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:12:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:12:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:12:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:12:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:12:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=388096) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=388096) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.46s/it]
(EngineCore_DP0 pid=388096) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.93it/s]
(EngineCore_DP0 pid=388096) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.21it/s]
(EngineCore_DP0 pid=388096) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
(EngineCore_DP0 pid=388096) 
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=388096) [2026-01-26 08:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=388096) [rank0]:W0126 08:13:33.290000 388096 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=388096) [rank0]:W0126 08:13:33.369000 388096 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=388096) [rank0]:W0126 08:13:34.358000 388096 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=388096) [rank0]:W0126 08:13:34.478000 388096 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=388096) Process EngineCore_DP0:
(EngineCore_DP0 pid=388096) Traceback (most recent call last):
(EngineCore_DP0 pid=388096)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=388096)     self.run()
(EngineCore_DP0 pid=388096)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=388096)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=388096)     raise e
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388096)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388096)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388096)     super().__init__(
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388096)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388096)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=388096)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=388096)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=388096)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=388096)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=388096)     raise ValueError(
(EngineCore_DP0 pid=388096) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:18:24.615289427 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,9.5295,4888.6364,13.4320
1024,1024,1,128,128,9.3405,9574.0190,13.7038
2048,1024,2,256,128,10.0075,10257.6423,25.5809
4096,1024,4,512,128,10.0726,10324.4601,50.8307
8192,1024,8,1024,128,10.0601,10311.5564,101.7887
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 5 成功, 3 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:18:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:18:38 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=393227) WARNING 01-26 08:18:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=393227) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=393227) WARNING 01-26 08:19:19 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=393227) ERROR 01-26 08:19:39 [core.py:866] ValueError: To serve at least one request with the models's max seq len (513), (0.10 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 48. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:18:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:18:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:18:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:18:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:18:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:18:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:18:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:18:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:18:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:18:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:18:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:18:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:18:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:18:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=393227) [2026-01-26 08:18:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.92s/it]
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:11<00:11,  5.54s/it]
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:12<00:03,  3.60s/it]
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:18<00:00,  4.45s/it]
(EngineCore_DP0 pid=393227) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:18<00:00,  4.56s/it]
(EngineCore_DP0 pid=393227) 
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=393227) [2026-01-26 08:19:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=393227) Process EngineCore_DP0:
(EngineCore_DP0 pid=393227) Traceback (most recent call last):
(EngineCore_DP0 pid=393227)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=393227)     self.run()
(EngineCore_DP0 pid=393227)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=393227)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=393227)     raise e
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393227)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393227)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393227)     super().__init__(
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393227)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393227)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=393227)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=393227)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=393227)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=393227)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=393227)     raise ValueError(
(EngineCore_DP0 pid=393227) ValueError: To serve at least one request with the models's max seq len (513), (0.10 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 48. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:19:40.958264215 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:19:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:19:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=394516) WARNING 01-26 08:20:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=394516) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=394516) WARNING 01-26 08:20:36 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=394516) ERROR 01-26 08:20:55 [core.py:866] ValueError: To serve at least one request with the models's max seq len (1025), (0.19 GiB KV cache is needed, which is larger than the available KV cache memory (0.00 GiB).  Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:19:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:19:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:19:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:19:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:19:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:20:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:20:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:20:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:20:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:20:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:20:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:20:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:20:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:20:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.80s/it]
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:11<00:11,  5.60s/it]
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:12<00:03,  3.66s/it]
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  4.29s/it]
(EngineCore_DP0 pid=394516) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  4.47s/it]
(EngineCore_DP0 pid=394516) 
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=394516) [2026-01-26 08:20:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=394516) Process EngineCore_DP0:
(EngineCore_DP0 pid=394516) Traceback (most recent call last):
(EngineCore_DP0 pid=394516)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=394516)     self.run()
(EngineCore_DP0 pid=394516)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=394516)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=394516)     raise e
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=394516)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=394516)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=394516)     super().__init__(
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=394516)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=394516)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=394516)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=394516)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=394516)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=394516)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=394516)     raise ValueError(
(EngineCore_DP0 pid=394516) ValueError: To serve at least one request with the models's max seq len (1025), (0.19 GiB KV cache is needed, which is larger than the available KV cache memory (0.00 GiB).  Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:20:56.087011796 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:21:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:21:12 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=395779) WARNING 01-26 08:21:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=395779) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=395779) WARNING 01-26 08:21:41 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=395779) ERROR 01-26 08:22:00 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:21:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:21:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:21:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:21:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:21:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:21:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:21:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:21:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:21:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:21:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:21:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:21:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:21:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:21:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:21:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:21:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:21:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.55s/it]
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.54s/it]
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.04s/it]
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.22s/it]
(EngineCore_DP0 pid=395779) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.26s/it]
(EngineCore_DP0 pid=395779) 
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=395779) [2026-01-26 08:21:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=395779) Process EngineCore_DP0:
(EngineCore_DP0 pid=395779) Traceback (most recent call last):
(EngineCore_DP0 pid=395779)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=395779)     self.run()
(EngineCore_DP0 pid=395779)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=395779)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=395779)     raise e
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395779)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395779)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395779)     super().__init__(
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395779)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395779)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=395779)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=395779)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=395779)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=395779)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=395779)     raise ValueError(
(EngineCore_DP0 pid=395779) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:22:01.302881978 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:22:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:22:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=396943) WARNING 01-26 08:22:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=396943) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=396943) WARNING 01-26 08:22:48 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=396943) ERROR 01-26 08:23:15 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:22:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:22:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:22:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:22:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:22:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:22:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:22:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:22:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:22:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.55s/it]
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.54s/it]
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
(EngineCore_DP0 pid=396943) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.24s/it]
(EngineCore_DP0 pid=396943) 
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=396943) [2026-01-26 08:22:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=396943) Process EngineCore_DP0:
(EngineCore_DP0 pid=396943) Traceback (most recent call last):
(EngineCore_DP0 pid=396943)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=396943)     self.run()
(EngineCore_DP0 pid=396943)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=396943)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=396943)     raise e
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=396943)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=396943)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=396943)     super().__init__(
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=396943)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=396943)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=396943)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=396943)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=396943)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=396943)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=396943)     raise ValueError(
(EngineCore_DP0 pid=396943) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:23:17.342968887 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:23:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:23:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=398237) WARNING 01-26 08:23:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=398237) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=398237) WARNING 01-26 08:24:06 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=398237) ERROR 01-26 08:24:47 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:23:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:23:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:23:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:23:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:23:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:23:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:23:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:23:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:23:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:23:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:23:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:23:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:23:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:23:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:23:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:23:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:23:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.55s/it]
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.54s/it]
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.04s/it]
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.22s/it]
(EngineCore_DP0 pid=398237) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.26s/it]
(EngineCore_DP0 pid=398237) 
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=398237) [2026-01-26 08:23:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=398237) Process EngineCore_DP0:
(EngineCore_DP0 pid=398237) Traceback (most recent call last):
(EngineCore_DP0 pid=398237)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=398237)     self.run()
(EngineCore_DP0 pid=398237)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=398237)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=398237)     raise e
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398237)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398237)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398237)     super().__init__(
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398237)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398237)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=398237)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=398237)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=398237)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=398237)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=398237)     raise ValueError(
(EngineCore_DP0 pid=398237) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:24:48.091208966 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:25:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:25:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=399795) WARNING 01-26 08:25:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=399795) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=399795) WARNING 01-26 08:25:47 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=399795) ERROR 01-26 08:28:18 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:25:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:25:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:25:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:25:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:25:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:25:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:25:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:25:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:25:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:25:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:25:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:25:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:25:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:25:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:25:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:25:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:25:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=399795) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=399795) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.47s/it]
(EngineCore_DP0 pid=399795) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.82it/s]
(EngineCore_DP0 pid=399795) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.14it/s]
(EngineCore_DP0 pid=399795) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.17it/s]
(EngineCore_DP0 pid=399795) 
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=399795) [2026-01-26 08:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=399795) [rank0]:W0126 08:25:59.320000 399795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=399795) [rank0]:W0126 08:25:59.399000 399795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=399795) [rank0]:W0126 08:26:01.010000 399795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=399795) [rank0]:W0126 08:26:01.131000 399795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=399795) Process EngineCore_DP0:
(EngineCore_DP0 pid=399795) Traceback (most recent call last):
(EngineCore_DP0 pid=399795)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=399795)     self.run()
(EngineCore_DP0 pid=399795)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=399795)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=399795)     raise e
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=399795)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=399795)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=399795)     super().__init__(
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=399795)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=399795)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=399795)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=399795)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=399795)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=399795)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=399795)     raise ValueError(
(EngineCore_DP0 pid=399795) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:28:20.876909750 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:29:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:29:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=403198) WARNING 01-26 08:29:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=403198) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=403198) WARNING 01-26 08:29:36 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=403198) ERROR 01-26 08:34:06 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:29:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:29:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:29:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:29:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:29:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:29:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:29:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:29:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:29:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:29:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:29:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:29:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:29:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:29:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:29:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:29:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:29:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.52s/it]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.50s/it]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.22s/it]
(EngineCore_DP0 pid=403198) 
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-26 08:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=403198) [rank0]:W0126 08:29:48.745000 403198 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=403198) [rank0]:W0126 08:29:48.825000 403198 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=403198) [rank0]:W0126 08:29:50.673000 403198 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=403198) [rank0]:W0126 08:29:50.798000 403198 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=403198) Process EngineCore_DP0:
(EngineCore_DP0 pid=403198) Traceback (most recent call last):
(EngineCore_DP0 pid=403198)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=403198)     self.run()
(EngineCore_DP0 pid=403198)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=403198)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=403198)     raise e
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=403198)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=403198)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=403198)     super().__init__(
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=403198)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=403198)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=403198)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=403198)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=403198)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=403198)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=403198)     raise ValueError(
(EngineCore_DP0 pid=403198) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:34:07.054175155 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:35:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:35:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=408658) WARNING 01-26 08:35:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=408658) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=408658) WARNING 01-26 08:35:52 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=408658) ERROR 01-26 08:45:09 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 08:35:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:35:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:35:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:35:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:35:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:35:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:35:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:35:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:35:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:35:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:35:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 08:35:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 08:35:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:35:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:35:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:35:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:35:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.53s/it]
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.53s/it]
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.22s/it]
(EngineCore_DP0 pid=408658) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.25s/it]
(EngineCore_DP0 pid=408658) 
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=408658) [2026-01-26 08:35:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=408658) [rank0]:W0126 08:36:06.011000 408658 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=408658) [rank0]:W0126 08:36:06.094000 408658 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=408658) [rank0]:W0126 08:36:10.462000 408658 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=408658) [rank0]:W0126 08:36:10.584000 408658 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=408658) Process EngineCore_DP0:
(EngineCore_DP0 pid=408658) Traceback (most recent call last):
(EngineCore_DP0 pid=408658)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=408658)     self.run()
(EngineCore_DP0 pid=408658)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=408658)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=408658)     raise e
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=408658)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=408658)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=408658)     super().__init__(
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=408658)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=408658)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=408658)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=408658)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=408658)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=408658)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=408658)     raise ValueError(
(EngineCore_DP0 pid=408658) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 08:45:10.391616071 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败


============================================================
  Benchmark 完成!
============================================================


总计: 24 成功, 16 失败
============================================================
