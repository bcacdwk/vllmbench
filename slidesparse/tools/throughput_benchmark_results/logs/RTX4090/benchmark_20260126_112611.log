======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-26 11:26:11
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512

命令行参数:
  --model: qwen2.5-14b-fp8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: decode
  --M: 64,128,256,512
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX4090
  Compute Capability: cc89
  VRAM: 24.0 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/4] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:26:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:26:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=582070) WARNING 01-26 11:26:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=582070) WARNING 01-26 11:26:56 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.74 requests/s, 1560.56 total tokens/s, 1468.76 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384


─── STDERR ───
[2026-01-26 11:26:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:26:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:26:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:26:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:26:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:26:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:26:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:26:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:26:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:26:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:26:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:26:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:26:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:26:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:26:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:26:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:26:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=582070) [2026-01-26 11:26:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=582070) [2026-01-26 11:26:29] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=582070) [2026-01-26 11:26:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=582070) [2026-01-26 11:26:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=582070) [2026-01-26 11:26:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.93s/it]
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:07<00:07,  3.96s/it]
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:09<00:02,  2.73s/it]
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:13<00:00,  3.17s/it]
(EngineCore_DP0 pid=582070) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:13<00:00,  3.26s/it]
(EngineCore_DP0 pid=582070) 
(EngineCore_DP0 pid=582070) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:05,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:04,  3.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:02,  5.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  5.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:01<00:02,  5.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:02,  5.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  5.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:02<00:01,  5.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:01,  4.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:03<00:02,  2.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:03<00:03,  1.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:04<00:02,  2.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:04<00:01,  2.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:04<00:00,  3.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:04<00:00,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:04<00:00,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  3.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  3.69it/s]
(EngineCore_DP0 pid=582070) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  4.44it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:02,  4.01it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  2.82it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:01<00:02,  2.86it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:02,  2.83it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:02<00:01,  2.84it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:02<00:01,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:02<00:00,  3.69it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:02<00:00,  3.98it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:02<00:00,  4.28it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  4.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  3.63it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2439.32it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:07<07:37,  7.26s/it, est. speed input: 2.20 toks/s, output: 35.25 toks/s]
Processed prompts:   3%|▎         | 2/64 [00:07<03:09,  3.06s/it, est. speed input: 4.34 toks/s, output: 69.37 toks/s]
Processed prompts:  52%|█████▏    | 33/64 [00:07<00:03,  8.53it/s, est. speed input: 70.26 toks/s, output: 1124.16 toks/s]
Processed prompts:  73%|███████▎  | 47/64 [00:08<00:01,  9.27it/s, est. speed input: 85.31 toks/s, output: 1364.97 toks/s]
Processed prompts:  84%|████████▍ | 54/64 [00:10<00:01,  8.00it/s, est. speed input: 85.33 toks/s, output: 1365.22 toks/s]
Processed prompts:  92%|█████████▏| 59/64 [00:10<00:00,  8.28it/s, est. speed input: 88.78 toks/s, output: 1420.51 toks/s]
Processed prompts:  98%|█████████▊| 63/64 [00:11<00:00,  8.38it/s, est. speed input: 90.95 toks/s, output: 1455.27 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  8.38it/s, est. speed input: 92.03 toks/s, output: 1472.45 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.75it/s, est. speed input: 92.03 toks/s, output: 1472.45 toks/s]
[rank0]:[W126 11:27:40.096904734 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 91.8s

测试结果:
  Requests/s:   5.74
  Tokens/s:     1560.56
  Total Reqs:   64
  Elapsed:      11.15s

  [Decode 分析]
  Total Decode Tokens:  16384
  Decode Tokens/s:      1468.76

============================================================
[2/4] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:27:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:27:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=583537) WARNING 01-26 11:27:59 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=583537) WARNING 01-26 11:28:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.38 requests/s, 2279.11 total tokens/s, 2145.04 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 11:27:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:27:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:27:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:27:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:27:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:27:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:27:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:27:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:27:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:27:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:27:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:27:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:27:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:27:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:27:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:27:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:27:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=583537) [2026-01-26 11:27:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=583537) [2026-01-26 11:27:59] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=583537) [2026-01-26 11:27:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=583537) [2026-01-26 11:27:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=583537) [2026-01-26 11:27:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.02s/it]
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.20s/it]
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.06it/s]
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.01it/s]
(EngineCore_DP0 pid=583537) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.01s/it]
(EngineCore_DP0 pid=583537) 
(EngineCore_DP0 pid=583537) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:25,  1.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:14,  2.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:10,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:08,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:07,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:02<00:09,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:02<00:11,  2.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:03<00:15,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:03<00:11,  2.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:03<00:09,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:04<00:07,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:06,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:04<00:05,  3.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:04<00:05,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:05<00:05,  3.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:05<00:07,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:06<00:09,  1.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:06<00:07,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:07<00:05,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:07<00:04,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:07<00:04,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:07<00:03,  3.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:07<00:02,  4.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:08<00:03,  3.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:08<00:04,  2.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:09<00:04,  1.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:10<00:03,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:10<00:02,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:10<00:01,  3.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:10<00:01,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:10<00:01,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:11<00:00,  4.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:11<00:00,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:12<00:00,  2.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  2.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  2.76it/s]
(EngineCore_DP0 pid=583537) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:08,  2.00it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:05,  2.92it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:04,  3.61it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:01<00:03,  4.09it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:03,  4.39it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:01<00:02,  4.55it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:01<00:01,  8.46it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:02<00:01,  6.60it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:02<00:01,  6.18it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:02<00:01,  5.89it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:02<00:00,  5.66it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:02<00:00,  5.53it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:03<00:00,  5.35it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:03<00:00,  5.12it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:03<00:00,  4.65it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:04<00:00,  3.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:04<00:00,  4.65it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2534.68it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:08<18:23,  8.69s/it, est. speed input: 1.84 toks/s, output: 29.47 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:08<00:10,  7.59it/s, est. speed input: 86.40 toks/s, output: 1382.36 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:09<00:06,  9.49it/s, est. speed input: 104.59 toks/s, output: 1673.43 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:11<00:06,  8.31it/s, est. speed input: 102.66 toks/s, output: 1642.56 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:11<00:06,  8.29it/s, est. speed input: 104.44 toks/s, output: 1670.99 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:12<00:05,  8.32it/s, est. speed input: 105.66 toks/s, output: 1690.56 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:12<00:04,  8.99it/s, est. speed input: 108.21 toks/s, output: 1731.37 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:12<00:04,  8.66it/s, est. speed input: 108.45 toks/s, output: 1735.17 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:12<00:04,  9.33it/s, est. speed input: 110.06 toks/s, output: 1761.01 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:13<00:03, 10.74it/s, est. speed input: 112.67 toks/s, output: 1802.69 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:13<00:03,  9.89it/s, est. speed input: 113.05 toks/s, output: 1808.85 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:13<00:02, 11.34it/s, est. speed input: 115.33 toks/s, output: 1845.32 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:13<00:02, 13.18it/s, est. speed input: 117.78 toks/s, output: 1884.48 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:14<00:02, 11.84it/s, est. speed input: 118.50 toks/s, output: 1896.05 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:14<00:01, 13.43it/s, est. speed input: 120.66 toks/s, output: 1930.52 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:14<00:01, 14.90it/s, est. speed input: 122.77 toks/s, output: 1964.35 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:14<00:00, 17.80it/s, est. speed input: 125.96 toks/s, output: 2015.42 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:14<00:00, 14.99it/s, est. speed input: 126.80 toks/s, output: 2028.74 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:14<00:00, 15.34it/s, est. speed input: 127.94 toks/s, output: 2046.97 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:14<00:00, 17.54it/s, est. speed input: 130.15 toks/s, output: 2082.34 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:15<00:00, 20.61it/s, est. speed input: 133.21 toks/s, output: 2131.29 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:15<00:00, 20.61it/s, est. speed input: 134.52 toks/s, output: 2152.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:15<00:00,  8.41it/s, est. speed input: 134.52 toks/s, output: 2152.39 toks/s]
[rank0]:[W126 11:29:11.171744062 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 91.5s

测试结果:
  Requests/s:   8.38
  Tokens/s:     2279.11
  Total Reqs:   128
  Elapsed:      15.28s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      2145.04

============================================================
[3/4] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:29:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:29:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=585011) WARNING 01-26 11:29:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=585011) WARNING 01-26 11:29:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.32 requests/s, 2262.20 total tokens/s, 2129.13 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536


─── STDERR ───
[2026-01-26 11:29:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:29:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:29:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:29:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:29:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:29:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:29:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:29:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:29:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:29:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:29:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:29:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:29:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:29:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:29:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:29:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:29:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=585011) [2026-01-26 11:29:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=585011) [2026-01-26 11:29:32] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=585011) [2026-01-26 11:29:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=585011) [2026-01-26 11:29:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=585011) [2026-01-26 11:29:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.03s/it]
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.08s/it]
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.28it/s]
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.15it/s]
(EngineCore_DP0 pid=585011) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.12it/s]
(EngineCore_DP0 pid=585011) 
(EngineCore_DP0 pid=585011) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:07,  4.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:07,  4.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:07,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:14,  2.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:02<00:17,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:02<00:14,  2.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:02<00:11,  2.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:02<00:09,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:03<00:07,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:03<00:06,  3.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:03<00:06,  4.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:03<00:06,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:04<00:09,  2.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:05<00:11,  1.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:05<00:09,  2.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:05<00:07,  2.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:06<00:06,  3.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:06<00:05,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:06<00:04,  3.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:06<00:04,  3.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:07<00:04,  3.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:07<00:05,  2.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:08<00:06,  1.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:08<00:05,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:09<00:04,  2.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:09<00:03,  3.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:09<00:02,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:09<00:02,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:09<00:01,  4.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:10<00:01,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:10<00:01,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:11<00:02,  1.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:11<00:01,  2.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:12<00:00,  2.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:12<00:00,  3.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:12<00:00,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:12<00:00,  2.87it/s]
(EngineCore_DP0 pid=585011) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:12,  2.83it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:09,  3.58it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:09,  3.47it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:01<00:11,  2.70it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:11,  2.70it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:02<00:12,  2.27it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:02<00:10,  2.74it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:02<00:08,  3.18it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:07,  3.58it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:03<00:06,  3.91it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:03<00:05,  4.18it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:03<00:05,  4.40it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:03<00:04,  4.55it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:03<00:01,  9.22it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:04<00:02,  6.95it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:04<00:02,  6.45it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:04<00:02,  6.06it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:04<00:02,  5.63it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:05<00:02,  5.47it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:05<00:02,  5.27it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:05<00:02,  4.76it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:06<00:02,  3.33it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:06<00:02,  3.35it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:07<00:02,  2.63it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:07<00:02,  2.82it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:07<00:01,  3.22it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:07<00:01,  3.61it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:07<00:00,  3.95it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:08<00:00,  4.27it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:08<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:08<00:00,  4.57it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:08<00:00,  4.09it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2653.57it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:09<38:45,  9.12s/it, est. speed input: 1.75 toks/s, output: 28.07 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:09<00:44,  5.04it/s, est. speed input: 57.26 toks/s, output: 916.21 toks/s]
Processed prompts:  20%|██        | 52/256 [00:10<00:28,  7.14it/s, est. speed input: 78.90 toks/s, output: 1262.41 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:12<00:30,  6.31it/s, est. speed input: 78.54 toks/s, output: 1256.71 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:13<00:27,  6.65it/s, est. speed input: 82.03 toks/s, output: 1312.55 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:14<00:26,  6.80it/s, est. speed input: 83.87 toks/s, output: 1341.97 toks/s]
Processed prompts:  31%|███       | 79/256 [00:14<00:23,  7.44it/s, est. speed input: 86.66 toks/s, output: 1386.62 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:15<00:23,  7.27it/s, est. speed input: 87.17 toks/s, output: 1394.78 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:15<00:21,  8.03it/s, est. speed input: 89.24 toks/s, output: 1427.85 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:15<00:20,  8.32it/s, est. speed input: 90.23 toks/s, output: 1443.66 toks/s]
Processed prompts:  35%|███▍      | 89/256 [00:15<00:21,  7.60it/s, est. speed input: 90.11 toks/s, output: 1441.74 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:15<00:19,  8.26it/s, est. speed input: 91.24 toks/s, output: 1459.86 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:16<00:17,  9.12it/s, est. speed input: 92.45 toks/s, output: 1479.20 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:16<00:15, 10.11it/s, est. speed input: 93.69 toks/s, output: 1499.03 toks/s]
Processed prompts:  38%|███▊      | 97/256 [00:16<00:14, 11.23it/s, est. speed input: 94.96 toks/s, output: 1519.42 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:16<00:13, 11.72it/s, est. speed input: 96.04 toks/s, output: 1536.62 toks/s]
Processed prompts:  39%|███▉      | 101/256 [00:16<00:17,  9.08it/s, est. speed input: 95.94 toks/s, output: 1534.97 toks/s]
Processed prompts:  41%|████      | 104/256 [00:17<00:13, 10.98it/s, est. speed input: 97.76 toks/s, output: 1564.21 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:17<00:11, 13.06it/s, est. speed input: 100.20 toks/s, output: 1603.26 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:17<00:10, 13.91it/s, est. speed input: 101.40 toks/s, output: 1622.42 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:17<00:09, 14.68it/s, est. speed input: 102.58 toks/s, output: 1641.20 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:17<00:11, 12.14it/s, est. speed input: 103.38 toks/s, output: 1654.10 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:18<00:10, 12.72it/s, est. speed input: 104.82 toks/s, output: 1677.16 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:18<00:09, 13.78it/s, est. speed input: 105.97 toks/s, output: 1695.56 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:18<00:09, 14.76it/s, est. speed input: 107.10 toks/s, output: 1713.65 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:18<00:08, 15.61it/s, est. speed input: 108.22 toks/s, output: 1731.50 toks/s]
Processed prompts:  50%|████▉     | 127/256 [00:18<00:07, 17.23it/s, est. speed input: 109.98 toks/s, output: 1759.72 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:18<00:06, 20.12it/s, est. speed input: 111.97 toks/s, output: 1791.49 toks/s]
Processed prompts:  52%|█████▏    | 133/256 [00:19<00:10, 11.95it/s, est. speed input: 111.79 toks/s, output: 1788.60 toks/s]
Processed prompts:  53%|█████▎    | 135/256 [00:19<00:19,  6.27it/s, est. speed input: 108.87 toks/s, output: 1741.94 toks/s]
Processed prompts:  54%|█████▎    | 137/256 [00:20<00:23,  5.05it/s, est. speed input: 107.12 toks/s, output: 1713.97 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:20<00:25,  4.66it/s, est. speed input: 106.32 toks/s, output: 1701.11 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:21<00:26,  4.45it/s, est. speed input: 105.70 toks/s, output: 1691.25 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:21<00:26,  4.39it/s, est. speed input: 105.27 toks/s, output: 1684.31 toks/s]
Processed prompts:  55%|█████▌    | 141/256 [00:21<00:25,  4.48it/s, est. speed input: 104.99 toks/s, output: 1679.88 toks/s]
Processed prompts:  56%|█████▌    | 143/256 [00:21<00:20,  5.56it/s, est. speed input: 105.38 toks/s, output: 1686.05 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:21<00:17,  6.45it/s, est. speed input: 105.77 toks/s, output: 1692.35 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:22<00:14,  7.52it/s, est. speed input: 106.36 toks/s, output: 1701.74 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:22<00:10, 10.51it/s, est. speed input: 107.90 toks/s, output: 1726.40 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:22<00:11,  9.02it/s, est. speed input: 107.88 toks/s, output: 1726.11 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:22<00:12,  8.36it/s, est. speed input: 107.95 toks/s, output: 1727.24 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:22<00:10,  9.35it/s, est. speed input: 108.63 toks/s, output: 1738.01 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:23<00:09, 10.19it/s, est. speed input: 109.28 toks/s, output: 1748.55 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:23<00:08, 11.05it/s, est. speed input: 109.98 toks/s, output: 1759.68 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:23<00:06, 14.20it/s, est. speed input: 111.48 toks/s, output: 1783.74 toks/s]
Processed prompts:  64%|██████▍   | 165/256 [00:23<00:06, 13.35it/s, est. speed input: 112.02 toks/s, output: 1792.30 toks/s]
Processed prompts:  65%|██████▌   | 167/256 [00:23<00:06, 13.37it/s, est. speed input: 112.66 toks/s, output: 1802.61 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:23<00:07, 11.31it/s, est. speed input: 112.85 toks/s, output: 1805.53 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:24<00:00, 67.38it/s, est. speed input: 134.17 toks/s, output: 2146.64 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:26<00:03, 14.50it/s, est. speed input: 129.12 toks/s, output: 2065.88 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:27<00:03, 12.35it/s, est. speed input: 129.13 toks/s, output: 2066.04 toks/s]
Processed prompts:  87%|████████▋ | 223/256 [00:27<00:02, 12.51it/s, est. speed input: 130.27 toks/s, output: 2084.32 toks/s]
Processed prompts:  89%|████████▊ | 227/256 [00:27<00:02, 12.80it/s, est. speed input: 131.28 toks/s, output: 2100.46 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:27<00:01, 13.59it/s, est. speed input: 132.31 toks/s, output: 2116.93 toks/s]
Processed prompts:  91%|█████████ | 233/256 [00:27<00:01, 14.80it/s, est. speed input: 133.45 toks/s, output: 2135.19 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:28<00:01, 15.73it/s, est. speed input: 134.47 toks/s, output: 2151.51 toks/s]
Processed prompts:  93%|█████████▎| 239/256 [00:28<00:01, 14.44it/s, est. speed input: 134.90 toks/s, output: 2158.47 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:28<00:01, 12.55it/s, est. speed input: 135.00 toks/s, output: 2160.05 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:28<00:00, 12.13it/s, est. speed input: 135.23 toks/s, output: 2163.65 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:28<00:00, 15.67it/s, est. speed input: 136.89 toks/s, output: 2190.18 toks/s]
Processed prompts:  98%|█████████▊| 251/256 [00:29<00:00, 16.36it/s, est. speed input: 137.77 toks/s, output: 2204.37 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:29<00:00, 16.36it/s, est. speed input: 140.30 toks/s, output: 2244.79 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:29<00:00,  8.77it/s, est. speed input: 140.30 toks/s, output: 2244.79 toks/s]
[rank0]:[W126 11:31:01.508073710 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 109.4s

测试结果:
  Requests/s:   8.32
  Tokens/s:     2262.20
  Total Reqs:   256
  Elapsed:      30.78s

  [Decode 分析]
  Total Decode Tokens:  65536
  Decode Tokens/s:      2129.13

============================================================
[4/4] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:31:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:31:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=586743) WARNING 01-26 11:31:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=586743) WARNING 01-26 11:31:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 4.85 requests/s, 1319.67 total tokens/s, 1242.04 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072


─── STDERR ───
[2026-01-26 11:31:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:31:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:31:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:31:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:31:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:31:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:31:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:31:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:31:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:31:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:31:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:31:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:31:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:31:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:31:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:31:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:31:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=586743) [2026-01-26 11:31:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=586743) [2026-01-26 11:31:23] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=586743) [2026-01-26 11:31:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=586743) [2026-01-26 11:31:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=586743) [2026-01-26 11:31:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=586743) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=586743) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.00s/it]
(EngineCore_DP0 pid=586743) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.05s/it]
(EngineCore_DP0 pid=586743) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.32it/s]
(EngineCore_DP0 pid=586743) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=586743) 
(EngineCore_DP0 pid=586743) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:40,  1.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:01<00:38,  1.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:01<00:25,  1.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:01<00:18,  2.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:02<00:15,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:02<00:12,  3.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:02<00:11,  3.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:02<00:10,  4.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:03<00:12,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:03<00:16,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:04<00:20,  1.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:04<00:16,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:05<00:13,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:05<00:11,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:05<00:10,  3.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:05<00:09,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:05<00:08,  4.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:06<00:09,  3.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:06<00:12,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:07<00:15,  2.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:07<00:13,  2.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:08<00:10,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:08<00:09,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:08<00:07,  3.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:08<00:06,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:09<00:06,  4.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:09<00:06,  3.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:10<00:09,  2.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:10<00:11,  1.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:11<00:09,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:11<00:07,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:11<00:06,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:11<00:05,  3.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:11<00:04,  3.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:12<00:03,  4.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:12<00:03,  4.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:13<00:06,  2.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:13<00:06,  2.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:14<00:05,  2.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:14<00:04,  2.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:14<00:03,  3.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:14<00:02,  3.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:15<00:02,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:15<00:01,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:15<00:01,  3.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:16<00:02,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:17<00:02,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:17<00:01,  2.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:17<00:00,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:17<00:00,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:18<00:00,  3.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:18<00:00,  2.82it/s]
(EngineCore_DP0 pid=586743) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:17,  2.91it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:13,  3.60it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:13,  3.44it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:01<00:17,  2.75it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:01<00:15,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:02<00:18,  2.40it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:02<00:16,  2.65it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:02<00:13,  3.11it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:02<00:11,  3.52it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:03<00:10,  3.87it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:03<00:09,  4.14it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:03<00:08,  4.35it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:03<00:08,  4.53it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:04<00:08,  4.19it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:04<00:11,  3.20it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:04<00:10,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:05<00:13,  2.62it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:05<00:11,  2.81it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:05<00:09,  3.22it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:06<00:08,  3.59it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:06<00:07,  3.90it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:06<00:06,  4.15it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:06<00:06,  4.35it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:06<00:06,  4.47it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:07<00:06,  4.29it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:07<00:08,  3.09it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:08<00:08,  2.93it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:08<00:09,  2.51it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:08<00:07,  2.83it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:09<00:06,  3.26it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:09<00:05,  3.63it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:09<00:04,  3.95it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:09<00:04,  4.21it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:09<00:03,  4.43it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:10<00:03,  4.60it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:10<00:03,  4.16it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:10<00:04,  3.17it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:11<00:03,  3.32it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:11<00:00,  9.40it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:11<00:00,  7.60it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:12<00:00,  4.97it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:12<00:00,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:13<00:00,  3.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:13<00:00,  3.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:13<00:00,  3.80it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  54%|█████▎    | 275/512 [00:00<00:00, 2747.00it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2777.97it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:06<57:15,  6.72s/it, est. speed input: 2.38 toks/s, output: 38.08 toks/s]
Processed prompts:   4%|▍         | 20/512 [00:07<02:16,  3.59it/s, est. speed input: 42.68 toks/s, output: 682.86 toks/s]
Processed prompts:   4%|▍         | 22/512 [00:08<02:25,  3.36it/s, est. speed input: 42.13 toks/s, output: 674.03 toks/s]
Processed prompts:   5%|▍         | 24/512 [00:08<02:19,  3.50it/s, est. speed input: 43.63 toks/s, output: 698.00 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:09<02:13,  3.64it/s, est. speed input: 44.99 toks/s, output: 719.91 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:09<02:08,  3.77it/s, est. speed input: 46.17 toks/s, output: 738.71 toks/s]
Processed prompts:   6%|▌         | 30/512 [00:10<02:03,  3.90it/s, est. speed input: 47.26 toks/s, output: 756.22 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:10<01:48,  4.40it/s, est. speed input: 49.53 toks/s, output: 792.51 toks/s]
Processed prompts:   7%|▋         | 37/512 [00:11<01:29,  5.31it/s, est. speed input: 53.04 toks/s, output: 848.64 toks/s]
Processed prompts:   8%|▊         | 41/512 [00:11<01:18,  6.03it/s, est. speed input: 56.26 toks/s, output: 900.20 toks/s]
Processed prompts:   9%|▉         | 45/512 [00:11<00:56,  8.24it/s, est. speed input: 61.06 toks/s, output: 976.88 toks/s]
Processed prompts:   9%|▉         | 47/512 [00:12<01:04,  7.23it/s, est. speed input: 61.58 toks/s, output: 985.33 toks/s]
Processed prompts:  10%|▉         | 49/512 [00:12<01:18,  5.87it/s, est. speed input: 61.33 toks/s, output: 981.30 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:13<01:34,  4.87it/s, est. speed input: 60.53 toks/s, output: 968.52 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:13<01:53,  4.06it/s, est. speed input: 59.67 toks/s, output: 954.78 toks/s]
Processed prompts:  10%|█         | 52/512 [00:14<02:14,  3.42it/s, est. speed input: 58.73 toks/s, output: 939.69 toks/s]
Processed prompts:  10%|█         | 53/512 [00:14<02:27,  3.12it/s, est. speed input: 58.11 toks/s, output: 929.71 toks/s]
Processed prompts:  11%|█         | 54/512 [00:14<02:14,  3.40it/s, est. speed input: 58.37 toks/s, output: 933.95 toks/s]
Processed prompts:  11%|█         | 55/512 [00:15<02:33,  2.98it/s, est. speed input: 57.66 toks/s, output: 922.62 toks/s]
Processed prompts:  11%|█         | 57/512 [00:15<01:50,  4.13it/s, est. speed input: 58.91 toks/s, output: 942.57 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:15<01:45,  4.29it/s, est. speed input: 59.16 toks/s, output: 946.61 toks/s]
Processed prompts:  12%|█▏        | 60/512 [00:15<01:16,  5.94it/s, est. speed input: 60.67 toks/s, output: 970.72 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:15<00:57,  7.79it/s, est. speed input: 62.24 toks/s, output: 995.83 toks/s]
Processed prompts:  12%|█▎        | 64/512 [00:16<00:47,  9.38it/s, est. speed input: 63.73 toks/s, output: 1019.72 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:16<01:18,  5.66it/s, est. speed input: 63.20 toks/s, output: 1011.21 toks/s]
Processed prompts:  13%|█▎        | 68/512 [00:16<01:02,  7.06it/s, est. speed input: 64.60 toks/s, output: 1033.61 toks/s]
Processed prompts:  14%|█▍        | 72/512 [00:17<00:41, 10.54it/s, est. speed input: 67.70 toks/s, output: 1083.21 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:17<00:42, 10.29it/s, est. speed input: 68.74 toks/s, output: 1099.87 toks/s]
Processed prompts:  15%|█▍        | 76/512 [00:17<00:48,  8.93it/s, est. speed input: 69.37 toks/s, output: 1109.92 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:18<01:50,  3.93it/s, est. speed input: 66.43 toks/s, output: 1062.85 toks/s]
Processed prompts:  15%|█▌        | 79/512 [00:19<02:09,  3.34it/s, est. speed input: 65.44 toks/s, output: 1047.08 toks/s]
Processed prompts:  16%|█▌        | 80/512 [00:19<02:13,  3.25it/s, est. speed input: 65.11 toks/s, output: 1041.71 toks/s]
Processed prompts:  16%|█▌        | 81/512 [00:19<02:12,  3.24it/s, est. speed input: 64.90 toks/s, output: 1038.37 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:20<02:32,  2.82it/s, est. speed input: 64.07 toks/s, output: 1025.10 toks/s]
Processed prompts:  16%|█▌        | 83/512 [00:20<02:15,  3.16it/s, est. speed input: 64.22 toks/s, output: 1027.45 toks/s]
Processed prompts:  16%|█▋        | 84/512 [00:20<02:02,  3.48it/s, est. speed input: 64.35 toks/s, output: 1029.66 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:21<01:30,  4.71it/s, est. speed input: 65.18 toks/s, output: 1042.95 toks/s]
Processed prompts:  17%|█▋        | 87/512 [00:21<01:29,  4.73it/s, est. speed input: 65.30 toks/s, output: 1044.75 toks/s]
Processed prompts:  17%|█▋        | 88/512 [00:21<01:24,  5.03it/s, est. speed input: 65.55 toks/s, output: 1048.85 toks/s]
Processed prompts:  17%|█▋        | 89/512 [00:21<01:19,  5.31it/s, est. speed input: 65.81 toks/s, output: 1052.94 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:21<01:13,  5.76it/s, est. speed input: 66.14 toks/s, output: 1058.17 toks/s]
Processed prompts:  18%|█▊        | 92/512 [00:21<00:58,  7.24it/s, est. speed input: 67.03 toks/s, output: 1072.55 toks/s]
Processed prompts:  19%|█▊        | 95/512 [00:22<00:42,  9.72it/s, est. speed input: 68.61 toks/s, output: 1097.71 toks/s]
Processed prompts:  19%|█▉        | 96/512 [00:22<00:45,  9.18it/s, est. speed input: 68.91 toks/s, output: 1102.56 toks/s]
Processed prompts:  19%|█▉        | 97/512 [00:22<00:52,  7.84it/s, est. speed input: 69.02 toks/s, output: 1104.28 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:22<00:43,  9.42it/s, est. speed input: 70.00 toks/s, output: 1120.00 toks/s]
Processed prompts:  20%|█▉        | 100/512 [00:22<00:49,  8.40it/s, est. speed input: 70.19 toks/s, output: 1123.03 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:22<00:43,  9.43it/s, est. speed input: 71.07 toks/s, output: 1137.06 toks/s]
Processed prompts:  21%|██        | 105/512 [00:23<00:40, 10.11it/s, est. speed input: 72.31 toks/s, output: 1156.89 toks/s]
Processed prompts:  21%|██        | 107/512 [00:24<01:49,  3.71it/s, est. speed input: 69.66 toks/s, output: 1114.53 toks/s]
Processed prompts:  21%|██        | 108/512 [00:24<01:55,  3.51it/s, est. speed input: 69.30 toks/s, output: 1108.84 toks/s]
Processed prompts:  21%|██▏       | 109/512 [00:25<02:02,  3.28it/s, est. speed input: 68.88 toks/s, output: 1102.14 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:25<02:27,  2.72it/s, est. speed input: 67.94 toks/s, output: 1087.11 toks/s]
Processed prompts:  22%|██▏       | 111/512 [00:26<02:18,  2.89it/s, est. speed input: 67.83 toks/s, output: 1085.24 toks/s]
Processed prompts:  22%|██▏       | 112/512 [00:26<02:04,  3.22it/s, est. speed input: 67.91 toks/s, output: 1086.51 toks/s]
Processed prompts:  22%|██▏       | 113/512 [00:26<01:49,  3.63it/s, est. speed input: 68.05 toks/s, output: 1088.76 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:26<00:20, 18.93it/s, est. speed input: 76.02 toks/s, output: 1216.39 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:27<00:25, 14.78it/s, est. speed input: 76.74 toks/s, output: 1227.88 toks/s]
Processed prompts:  26%|██▌       | 133/512 [00:27<00:29, 12.72it/s, est. speed input: 77.52 toks/s, output: 1240.29 toks/s]
Processed prompts:  26%|██▋       | 135/512 [00:28<00:56,  6.71it/s, est. speed input: 76.05 toks/s, output: 1216.81 toks/s]
Processed prompts:  27%|██▋       | 137/512 [00:29<01:23,  4.51it/s, est. speed input: 74.50 toks/s, output: 1192.07 toks/s]
Processed prompts:  27%|██▋       | 139/512 [00:30<01:32,  4.02it/s, est. speed input: 73.88 toks/s, output: 1182.11 toks/s]
Processed prompts:  27%|██▋       | 140/512 [00:30<01:27,  4.24it/s, est. speed input: 74.03 toks/s, output: 1184.51 toks/s]
Processed prompts:  28%|██▊       | 141/512 [00:30<01:23,  4.42it/s, est. speed input: 74.12 toks/s, output: 1185.93 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:30<01:23,  4.45it/s, est. speed input: 74.12 toks/s, output: 1185.85 toks/s]
Processed prompts:  28%|██▊       | 143/512 [00:30<01:27,  4.21it/s, est. speed input: 73.95 toks/s, output: 1183.27 toks/s]
Processed prompts:  28%|██▊       | 144/512 [00:31<01:24,  4.36it/s, est. speed input: 73.98 toks/s, output: 1183.72 toks/s]
Processed prompts:  28%|██▊       | 145/512 [00:31<01:24,  4.36it/s, est. speed input: 73.95 toks/s, output: 1183.26 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:31<01:14,  4.89it/s, est. speed input: 74.15 toks/s, output: 1186.32 toks/s]
Processed prompts:  29%|██▊       | 147/512 [00:31<01:05,  5.59it/s, est. speed input: 74.39 toks/s, output: 1190.25 toks/s]
Processed prompts:  29%|██▉       | 148/512 [00:31<01:00,  6.00it/s, est. speed input: 74.58 toks/s, output: 1193.22 toks/s]
Processed prompts:  29%|██▉       | 149/512 [00:31<00:59,  6.08it/s, est. speed input: 74.71 toks/s, output: 1195.32 toks/s]
Processed prompts:  29%|██▉       | 151/512 [00:32<00:43,  8.23it/s, est. speed input: 75.38 toks/s, output: 1206.15 toks/s]
Processed prompts:  30%|██▉       | 152/512 [00:32<00:47,  7.59it/s, est. speed input: 75.50 toks/s, output: 1207.97 toks/s]
Processed prompts:  30%|███       | 155/512 [00:32<00:31, 11.21it/s, est. speed input: 76.64 toks/s, output: 1226.27 toks/s]
Processed prompts:  31%|███       | 159/512 [00:32<00:24, 14.17it/s, est. speed input: 78.12 toks/s, output: 1249.98 toks/s]
Processed prompts:  31%|███▏      | 161/512 [00:32<00:26, 13.19it/s, est. speed input: 78.67 toks/s, output: 1258.69 toks/s]
Processed prompts:  32%|███▏      | 163/512 [00:33<00:39,  8.74it/s, est. speed input: 78.60 toks/s, output: 1257.57 toks/s]
Processed prompts:  32%|███▏      | 165/512 [00:34<01:43,  3.34it/s, est. speed input: 76.00 toks/s, output: 1216.07 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:35<01:59,  2.90it/s, est. speed input: 75.22 toks/s, output: 1203.52 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:35<02:20,  2.45it/s, est. speed input: 74.26 toks/s, output: 1188.23 toks/s]
Processed prompts:  33%|███▎      | 168/512 [00:36<02:10,  2.65it/s, est. speed input: 74.15 toks/s, output: 1186.42 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:36<02:00,  2.84it/s, est. speed input: 74.05 toks/s, output: 1184.77 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:36<01:43,  3.30it/s, est. speed input: 74.16 toks/s, output: 1186.64 toks/s]
Processed prompts:  33%|███▎      | 171/512 [00:36<01:37,  3.51it/s, est. speed input: 74.13 toks/s, output: 1186.00 toks/s]
Processed prompts:  34%|███▎      | 172/512 [00:37<01:24,  4.03it/s, est. speed input: 74.26 toks/s, output: 1188.11 toks/s]
Processed prompts:  34%|███▍      | 173/512 [00:37<01:26,  3.92it/s, est. speed input: 74.14 toks/s, output: 1186.32 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:37<01:11,  4.70it/s, est. speed input: 74.36 toks/s, output: 1189.71 toks/s]
Processed prompts:  34%|███▍      | 175/512 [00:37<01:04,  5.24it/s, est. speed input: 74.51 toks/s, output: 1192.19 toks/s]
Processed prompts:  35%|███▍      | 177/512 [00:37<00:49,  6.82it/s, est. speed input: 74.99 toks/s, output: 1199.85 toks/s]
Processed prompts:  35%|███▍      | 179/512 [00:37<00:44,  7.43it/s, est. speed input: 75.38 toks/s, output: 1206.01 toks/s]
Processed prompts:  35%|███▌      | 180/512 [00:38<00:47,  7.00it/s, est. speed input: 75.46 toks/s, output: 1207.28 toks/s]
Processed prompts:  35%|███▌      | 181/512 [00:38<00:48,  6.77it/s, est. speed input: 75.55 toks/s, output: 1208.81 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:38<00:45,  7.18it/s, est. speed input: 75.74 toks/s, output: 1211.87 toks/s]
Processed prompts:  36%|███▌      | 183/512 [00:38<00:43,  7.54it/s, est. speed input: 75.93 toks/s, output: 1214.91 toks/s]
Processed prompts:  36%|███▌      | 184/512 [00:38<00:47,  6.95it/s, est. speed input: 76.01 toks/s, output: 1216.09 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:38<00:45,  7.25it/s, est. speed input: 76.18 toks/s, output: 1218.82 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:39<00:42,  7.70it/s, est. speed input: 76.53 toks/s, output: 1224.45 toks/s]
Processed prompts:  37%|███▋      | 189/512 [00:39<00:34,  9.32it/s, est. speed input: 77.06 toks/s, output: 1233.01 toks/s]
Processed prompts:  37%|███▋      | 191/512 [00:39<00:28, 11.12it/s, est. speed input: 77.65 toks/s, output: 1242.34 toks/s]
Processed prompts:  38%|███▊      | 193/512 [00:40<01:03,  5.04it/s, est. speed input: 76.86 toks/s, output: 1229.71 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:40<01:13,  4.31it/s, est. speed input: 76.55 toks/s, output: 1224.74 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:41<01:30,  3.50it/s, est. speed input: 76.04 toks/s, output: 1216.67 toks/s]
Processed prompts:  38%|███▊      | 196/512 [00:41<01:41,  3.12it/s, est. speed input: 75.63 toks/s, output: 1210.13 toks/s]
Processed prompts:  38%|███▊      | 197/512 [00:41<01:43,  3.04it/s, est. speed input: 75.37 toks/s, output: 1205.99 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:41<01:30,  3.48it/s, est. speed input: 75.45 toks/s, output: 1207.18 toks/s]
Processed prompts:  39%|███▉      | 199/512 [00:42<01:25,  3.65it/s, est. speed input: 75.40 toks/s, output: 1206.43 toks/s]
Processed prompts:  39%|███▉      | 200/512 [00:42<01:19,  3.93it/s, est. speed input: 75.41 toks/s, output: 1206.61 toks/s]
Processed prompts:  39%|███▉      | 201/512 [00:42<01:06,  4.68it/s, est. speed input: 75.59 toks/s, output: 1209.44 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:42<00:57,  5.43it/s, est. speed input: 75.77 toks/s, output: 1212.26 toks/s]
Processed prompts:  40%|███▉      | 203/512 [00:42<00:52,  5.86it/s, est. speed input: 75.90 toks/s, output: 1214.33 toks/s]
Processed prompts:  40%|███▉      | 204/512 [00:42<00:51,  5.93it/s, est. speed input: 75.98 toks/s, output: 1215.66 toks/s]
Processed prompts:  40%|████      | 205/512 [00:43<00:49,  6.15it/s, est. speed input: 76.09 toks/s, output: 1217.41 toks/s]
Processed prompts:  40%|████      | 206/512 [00:43<00:47,  6.42it/s, est. speed input: 76.21 toks/s, output: 1219.40 toks/s]
Processed prompts:  40%|████      | 207/512 [00:43<00:52,  5.77it/s, est. speed input: 76.20 toks/s, output: 1219.26 toks/s]
Processed prompts:  41%|████      | 208/512 [00:43<00:51,  5.87it/s, est. speed input: 76.29 toks/s, output: 1220.56 toks/s]
Processed prompts:  41%|████      | 209/512 [00:43<00:57,  5.27it/s, est. speed input: 76.24 toks/s, output: 1219.86 toks/s]
Processed prompts:  41%|████      | 210/512 [00:43<00:52,  5.73it/s, est. speed input: 76.36 toks/s, output: 1221.84 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:44<00:38,  7.70it/s, est. speed input: 76.82 toks/s, output: 1229.13 toks/s]
Processed prompts:  42%|████▏     | 213/512 [00:44<00:37,  7.93it/s, est. speed input: 76.98 toks/s, output: 1231.72 toks/s]
Processed prompts:  42%|████▏     | 215/512 [00:44<00:31,  9.44it/s, est. speed input: 77.43 toks/s, output: 1238.95 toks/s]
Processed prompts:  42%|████▏     | 216/512 [00:44<00:32,  9.18it/s, est. speed input: 77.59 toks/s, output: 1241.39 toks/s]
Processed prompts:  42%|████▏     | 217/512 [00:44<00:32,  8.94it/s, est. speed input: 77.74 toks/s, output: 1243.76 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:44<00:33,  8.86it/s, est. speed input: 77.89 toks/s, output: 1246.26 toks/s]
Processed prompts:  43%|████▎     | 219/512 [00:44<00:35,  8.20it/s, est. speed input: 77.99 toks/s, output: 1247.90 toks/s]
Processed prompts:  43%|████▎     | 220/512 [00:45<00:37,  7.79it/s, est. speed input: 78.10 toks/s, output: 1249.57 toks/s]
Processed prompts:  43%|████▎     | 221/512 [00:45<00:36,  7.95it/s, est. speed input: 78.25 toks/s, output: 1251.93 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:45<01:11,  4.04it/s, est. speed input: 77.66 toks/s, output: 1242.56 toks/s]
Processed prompts:  44%|████▎     | 223/512 [00:46<01:42,  2.83it/s, est. speed input: 76.98 toks/s, output: 1231.75 toks/s]
Processed prompts:  44%|████▍     | 224/512 [00:46<01:45,  2.73it/s, est. speed input: 76.67 toks/s, output: 1226.77 toks/s]
Processed prompts:  44%|████▍     | 225/512 [00:47<01:44,  2.75it/s, est. speed input: 76.43 toks/s, output: 1222.93 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:47<01:28,  3.22it/s, est. speed input: 76.47 toks/s, output: 1223.55 toks/s]
Processed prompts:  44%|████▍     | 227/512 [00:47<01:24,  3.38it/s, est. speed input: 76.39 toks/s, output: 1222.22 toks/s]
Processed prompts:  45%|████▍     | 228/512 [00:47<01:27,  3.25it/s, est. speed input: 76.19 toks/s, output: 1219.00 toks/s]
Processed prompts:  45%|████▍     | 229/512 [00:48<01:20,  3.51it/s, est. speed input: 76.15 toks/s, output: 1218.46 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:48<01:18,  3.60it/s, est. speed input: 76.07 toks/s, output: 1217.19 toks/s]
Processed prompts:  45%|████▌     | 231/512 [00:48<01:14,  3.78it/s, est. speed input: 76.04 toks/s, output: 1216.59 toks/s]
Processed prompts:  45%|████▌     | 232/512 [00:48<01:03,  4.42it/s, est. speed input: 76.15 toks/s, output: 1218.44 toks/s]
Processed prompts:  46%|████▌     | 233/512 [00:48<00:57,  4.83it/s, est. speed input: 76.23 toks/s, output: 1219.64 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:49<01:00,  4.63it/s, est. speed input: 76.19 toks/s, output: 1218.98 toks/s]
Processed prompts:  46%|████▌     | 235/512 [00:49<00:55,  5.00it/s, est. speed input: 76.26 toks/s, output: 1220.14 toks/s]
Processed prompts:  46%|████▌     | 236/512 [00:49<00:54,  5.08it/s, est. speed input: 76.29 toks/s, output: 1220.64 toks/s]
Processed prompts:  46%|████▋     | 237/512 [00:49<01:05,  4.22it/s, est. speed input: 76.10 toks/s, output: 1217.67 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:50<01:00,  4.51it/s, est. speed input: 76.14 toks/s, output: 1218.26 toks/s]
Processed prompts:  47%|████▋     | 239/512 [00:50<00:51,  5.29it/s, est. speed input: 76.29 toks/s, output: 1220.63 toks/s]
Processed prompts:  47%|████▋     | 240/512 [00:50<00:51,  5.30it/s, est. speed input: 76.32 toks/s, output: 1221.17 toks/s]
Processed prompts:  47%|████▋     | 241/512 [00:50<00:49,  5.45it/s, est. speed input: 76.38 toks/s, output: 1222.10 toks/s]
Processed prompts:  47%|████▋     | 243/512 [00:50<00:34,  7.78it/s, est. speed input: 76.82 toks/s, output: 1229.09 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:50<00:22, 11.91it/s, est. speed input: 77.59 toks/s, output: 1241.41 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:50<00:16, 15.79it/s, est. speed input: 78.59 toks/s, output: 1257.47 toks/s]
Processed prompts:  49%|████▉     | 252/512 [00:51<00:16, 16.00it/s, est. speed input: 79.03 toks/s, output: 1264.55 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:51<00:41,  6.15it/s, est. speed input: 78.33 toks/s, output: 1253.26 toks/s]
Processed prompts:  50%|█████     | 256/512 [00:53<01:23,  3.05it/s, est. speed input: 76.70 toks/s, output: 1227.27 toks/s]
Processed prompts:  50%|█████     | 257/512 [00:53<01:23,  3.04it/s, est. speed input: 76.53 toks/s, output: 1224.43 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:54<01:23,  3.05it/s, est. speed input: 76.36 toks/s, output: 1221.79 toks/s]
Processed prompts:  51%|█████     | 259/512 [00:54<01:22,  3.06it/s, est. speed input: 76.21 toks/s, output: 1219.30 toks/s]
Processed prompts:  51%|█████     | 260/512 [00:54<01:17,  3.25it/s, est. speed input: 76.16 toks/s, output: 1218.49 toks/s]
Processed prompts:  51%|█████     | 261/512 [00:54<01:19,  3.16it/s, est. speed input: 75.97 toks/s, output: 1215.59 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:55<01:18,  3.20it/s, est. speed input: 75.85 toks/s, output: 1213.56 toks/s]
Processed prompts:  51%|█████▏    | 263/512 [00:55<01:13,  3.40it/s, est. speed input: 75.80 toks/s, output: 1212.84 toks/s]
Processed prompts:  52%|█████▏    | 264/512 [00:55<01:05,  3.79it/s, est. speed input: 75.83 toks/s, output: 1213.35 toks/s]
Processed prompts:  52%|█████▏    | 265/512 [00:55<01:01,  4.03it/s, est. speed input: 75.84 toks/s, output: 1213.38 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:56<00:54,  4.48it/s, est. speed input: 75.90 toks/s, output: 1214.44 toks/s]
Processed prompts:  52%|█████▏    | 267/512 [00:56<00:49,  4.91it/s, est. speed input: 75.98 toks/s, output: 1215.62 toks/s]
Processed prompts:  52%|█████▏    | 268/512 [00:56<00:43,  5.58it/s, est. speed input: 76.10 toks/s, output: 1217.55 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:56<00:31,  7.76it/s, est. speed input: 76.48 toks/s, output: 1223.64 toks/s]
Processed prompts:  53%|█████▎    | 271/512 [00:56<00:30,  8.00it/s, est. speed input: 76.61 toks/s, output: 1225.72 toks/s]
Processed prompts:  53%|█████▎    | 272/512 [00:56<00:30,  7.81it/s, est. speed input: 76.70 toks/s, output: 1227.28 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:56<00:25,  9.26it/s, est. speed input: 77.05 toks/s, output: 1232.77 toks/s]
Processed prompts:  54%|█████▎    | 275/512 [00:57<00:27,  8.51it/s, est. speed input: 77.13 toks/s, output: 1234.05 toks/s]
Processed prompts:  54%|█████▍    | 277/512 [00:57<00:23,  9.86it/s, est. speed input: 77.48 toks/s, output: 1239.66 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:57<00:24,  9.37it/s, est. speed input: 77.59 toks/s, output: 1241.43 toks/s]
Processed prompts:  55%|█████▍    | 280/512 [00:57<00:25,  9.12it/s, est. speed input: 77.84 toks/s, output: 1245.40 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:57<00:20, 11.15it/s, est. speed input: 78.25 toks/s, output: 1251.95 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:58<00:20, 10.87it/s, est. speed input: 78.84 toks/s, output: 1261.46 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:58<00:42,  5.26it/s, est. speed input: 78.15 toks/s, output: 1250.35 toks/s]
Processed prompts:  56%|█████▋    | 289/512 [00:59<00:46,  4.85it/s, est. speed input: 78.03 toks/s, output: 1248.52 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:59<00:45,  4.84it/s, est. speed input: 78.03 toks/s, output: 1248.44 toks/s]
Processed prompts:  57%|█████▋    | 291/512 [00:59<00:44,  4.96it/s, est. speed input: 78.06 toks/s, output: 1248.94 toks/s]
Processed prompts:  57%|█████▋    | 292/512 [00:59<00:44,  4.99it/s, est. speed input: 78.07 toks/s, output: 1249.12 toks/s]
Processed prompts:  57%|█████▋    | 293/512 [00:59<00:41,  5.28it/s, est. speed input: 78.13 toks/s, output: 1250.14 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [01:00<00:37,  5.82it/s, est. speed input: 78.24 toks/s, output: 1251.86 toks/s]
Processed prompts:  58%|█████▊    | 297/512 [01:00<00:25,  8.55it/s, est. speed input: 78.77 toks/s, output: 1260.35 toks/s]
Processed prompts:  58%|█████▊    | 299/512 [01:00<00:28,  7.45it/s, est. speed input: 78.86 toks/s, output: 1261.78 toks/s]
Processed prompts:  59%|█████▊    | 300/512 [01:00<00:28,  7.40it/s, est. speed input: 78.94 toks/s, output: 1263.11 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [01:00<00:24,  8.71it/s, est. speed input: 79.27 toks/s, output: 1268.29 toks/s]
Processed prompts:  59%|█████▉    | 304/512 [01:01<00:19, 10.65it/s, est. speed input: 79.65 toks/s, output: 1274.48 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [01:01<00:17, 12.08it/s, est. speed input: 80.02 toks/s, output: 1280.36 toks/s]
Processed prompts:  60%|██████    | 308/512 [01:01<00:21,  9.48it/s, est. speed input: 80.14 toks/s, output: 1282.26 toks/s]
Processed prompts:  61%|██████    | 310/512 [01:01<00:21,  9.55it/s, est. speed input: 80.39 toks/s, output: 1286.27 toks/s]
Processed prompts:  61%|██████    | 312/512 [01:02<00:45,  4.39it/s, est. speed input: 79.61 toks/s, output: 1273.74 toks/s]
Processed prompts:  61%|██████    | 313/512 [01:03<00:56,  3.50it/s, est. speed input: 79.17 toks/s, output: 1266.70 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [01:03<01:01,  3.22it/s, est. speed input: 78.91 toks/s, output: 1262.62 toks/s]
Processed prompts:  62%|██████▏   | 315/512 [01:04<01:07,  2.94it/s, est. speed input: 78.62 toks/s, output: 1257.92 toks/s]
Processed prompts:  62%|██████▏   | 316/512 [01:04<01:01,  3.19it/s, est. speed input: 78.59 toks/s, output: 1257.44 toks/s]
Processed prompts:  62%|██████▏   | 317/512 [01:04<00:52,  3.74it/s, est. speed input: 78.67 toks/s, output: 1258.73 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [01:04<00:47,  4.08it/s, est. speed input: 78.69 toks/s, output: 1259.09 toks/s]
Processed prompts:  62%|██████▏   | 319/512 [01:04<00:41,  4.66it/s, est. speed input: 78.78 toks/s, output: 1260.41 toks/s]
Processed prompts:  62%|██████▎   | 320/512 [01:04<00:37,  5.13it/s, est. speed input: 78.85 toks/s, output: 1261.53 toks/s]
Processed prompts:  63%|██████▎   | 321/512 [01:05<00:39,  4.85it/s, est. speed input: 78.81 toks/s, output: 1260.93 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [01:05<00:37,  5.10it/s, est. speed input: 78.85 toks/s, output: 1261.54 toks/s]
Processed prompts:  63%|██████▎   | 323/512 [01:05<00:38,  4.92it/s, est. speed input: 78.83 toks/s, output: 1261.21 toks/s]
Processed prompts:  63%|██████▎   | 324/512 [01:05<00:38,  4.88it/s, est. speed input: 78.82 toks/s, output: 1261.08 toks/s]
Processed prompts:  63%|██████▎   | 325/512 [01:05<00:35,  5.20it/s, est. speed input: 78.87 toks/s, output: 1261.87 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [01:06<00:29,  6.20it/s, est. speed input: 79.05 toks/s, output: 1264.84 toks/s]
Processed prompts:  64%|██████▍   | 328/512 [01:06<00:35,  5.22it/s, est. speed input: 78.96 toks/s, output: 1263.29 toks/s]
Processed prompts:  64%|██████▍   | 329/512 [01:06<00:32,  5.62it/s, est. speed input: 79.03 toks/s, output: 1264.49 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [01:06<00:31,  5.75it/s, est. speed input: 79.08 toks/s, output: 1265.24 toks/s]
Processed prompts:  65%|██████▍   | 332/512 [01:06<00:23,  7.60it/s, est. speed input: 79.37 toks/s, output: 1269.98 toks/s]
Processed prompts:  65%|██████▌   | 335/512 [01:07<00:16, 10.61it/s, est. speed input: 79.90 toks/s, output: 1278.33 toks/s]
Processed prompts:  66%|██████▌   | 337/512 [01:07<00:14, 11.99it/s, est. speed input: 80.23 toks/s, output: 1283.68 toks/s]
Processed prompts:  66%|██████▌   | 339/512 [01:07<00:16, 10.36it/s, est. speed input: 80.41 toks/s, output: 1286.48 toks/s]
Processed prompts:  67%|██████▋   | 341/512 [01:08<00:30,  5.57it/s, est. speed input: 80.01 toks/s, output: 1280.15 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [01:08<00:39,  4.32it/s, est. speed input: 79.70 toks/s, output: 1275.13 toks/s]
Processed prompts:  67%|██████▋   | 343/512 [01:09<00:46,  3.64it/s, est. speed input: 79.42 toks/s, output: 1270.66 toks/s]
Processed prompts:  67%|██████▋   | 344/512 [01:09<00:48,  3.47it/s, est. speed input: 79.27 toks/s, output: 1268.27 toks/s]
Processed prompts:  67%|██████▋   | 345/512 [01:09<00:51,  3.25it/s, est. speed input: 79.08 toks/s, output: 1265.20 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [01:09<00:43,  3.80it/s, est. speed input: 79.15 toks/s, output: 1266.42 toks/s]
Processed prompts:  68%|██████▊   | 347/512 [01:10<00:53,  3.08it/s, est. speed input: 78.83 toks/s, output: 1261.22 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [01:10<00:52,  3.12it/s, est. speed input: 78.71 toks/s, output: 1259.33 toks/s]
Processed prompts:  68%|██████▊   | 349/512 [01:11<00:51,  3.17it/s, est. speed input: 78.60 toks/s, output: 1257.54 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [01:11<00:48,  3.35it/s, est. speed input: 78.54 toks/s, output: 1256.62 toks/s]
Processed prompts:  69%|██████▊   | 351/512 [01:11<00:41,  3.87it/s, est. speed input: 78.58 toks/s, output: 1257.35 toks/s]
Processed prompts:  69%|██████▉   | 352/512 [01:11<00:34,  4.65it/s, est. speed input: 78.69 toks/s, output: 1258.97 toks/s]
Processed prompts:  69%|██████▉   | 353/512 [01:11<00:30,  5.21it/s, est. speed input: 78.76 toks/s, output: 1260.15 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [01:11<00:28,  5.49it/s, est. speed input: 78.81 toks/s, output: 1260.92 toks/s]
Processed prompts:  69%|██████▉   | 355/512 [01:12<00:27,  5.72it/s, est. speed input: 78.86 toks/s, output: 1261.71 toks/s]
Processed prompts:  70%|██████▉   | 356/512 [01:12<00:28,  5.39it/s, est. speed input: 78.85 toks/s, output: 1261.58 toks/s]
Processed prompts:  70%|██████▉   | 357/512 [01:12<00:31,  4.99it/s, est. speed input: 78.81 toks/s, output: 1261.02 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [01:12<00:29,  5.22it/s, est. speed input: 78.85 toks/s, output: 1261.58 toks/s]
Processed prompts:  70%|███████   | 359/512 [01:12<00:25,  5.94it/s, est. speed input: 78.94 toks/s, output: 1263.11 toks/s]
Processed prompts:  70%|███████   | 360/512 [01:12<00:25,  5.99it/s, est. speed input: 78.99 toks/s, output: 1263.80 toks/s]
Processed prompts:  71%|███████   | 361/512 [01:13<00:22,  6.62it/s, est. speed input: 79.08 toks/s, output: 1265.33 toks/s]
Processed prompts:  71%|███████   | 362/512 [01:13<00:21,  7.01it/s, est. speed input: 79.17 toks/s, output: 1266.70 toks/s]
Processed prompts:  71%|███████   | 364/512 [01:13<00:18,  8.09it/s, est. speed input: 79.39 toks/s, output: 1270.17 toks/s]
Processed prompts:  71%|███████▏  | 365/512 [01:13<00:18,  7.82it/s, est. speed input: 79.45 toks/s, output: 1271.23 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [01:13<00:18,  7.88it/s, est. speed input: 79.53 toks/s, output: 1272.56 toks/s]
Processed prompts:  72%|███████▏  | 368/512 [01:13<00:15,  9.39it/s, est. speed input: 79.80 toks/s, output: 1276.77 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [01:13<00:13, 10.89it/s, est. speed input: 80.08 toks/s, output: 1281.35 toks/s]
Processed prompts:  73%|███████▎  | 373/512 [01:14<00:14,  9.88it/s, est. speed input: 80.37 toks/s, output: 1285.86 toks/s]
Processed prompts:  73%|███████▎  | 375/512 [01:15<00:37,  3.69it/s, est. speed input: 79.37 toks/s, output: 1269.90 toks/s]
Processed prompts:  73%|███████▎  | 376/512 [01:16<00:41,  3.25it/s, est. speed input: 79.08 toks/s, output: 1265.27 toks/s]
Processed prompts:  74%|███████▎  | 377/512 [01:16<00:42,  3.20it/s, est. speed input: 78.94 toks/s, output: 1263.11 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [01:16<00:40,  3.34it/s, est. speed input: 78.89 toks/s, output: 1262.25 toks/s]
Processed prompts:  74%|███████▍  | 379/512 [01:17<00:41,  3.20it/s, est. speed input: 78.74 toks/s, output: 1259.77 toks/s]
Processed prompts:  74%|███████▍  | 381/512 [01:17<00:35,  3.69it/s, est. speed input: 78.72 toks/s, output: 1259.55 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [01:17<00:34,  3.81it/s, est. speed input: 78.69 toks/s, output: 1259.07 toks/s]
Processed prompts:  75%|███████▍  | 383/512 [01:18<00:37,  3.44it/s, est. speed input: 78.51 toks/s, output: 1256.21 toks/s]
Processed prompts:  75%|███████▌  | 384/512 [01:18<00:31,  4.11it/s, est. speed input: 78.61 toks/s, output: 1257.76 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [01:18<00:22,  5.57it/s, est. speed input: 78.83 toks/s, output: 1261.31 toks/s]
Processed prompts:  76%|███████▌  | 387/512 [01:18<00:21,  5.82it/s, est. speed input: 78.89 toks/s, output: 1262.22 toks/s]
Processed prompts:  76%|███████▌  | 388/512 [01:18<00:21,  5.69it/s, est. speed input: 78.90 toks/s, output: 1262.46 toks/s]
Processed prompts:  76%|███████▌  | 389/512 [01:18<00:22,  5.40it/s, est. speed input: 78.90 toks/s, output: 1262.34 toks/s]
Processed prompts:  76%|███████▋  | 391/512 [01:19<00:17,  6.85it/s, est. speed input: 79.11 toks/s, output: 1265.80 toks/s]
Processed prompts:  77%|███████▋  | 393/512 [01:19<00:13,  8.94it/s, est. speed input: 79.40 toks/s, output: 1270.48 toks/s]
Processed prompts:  77%|███████▋  | 395/512 [01:19<00:11, 10.46it/s, est. speed input: 79.68 toks/s, output: 1274.83 toks/s]
Processed prompts:  78%|███████▊  | 397/512 [01:19<00:11, 10.11it/s, est. speed input: 79.87 toks/s, output: 1277.89 toks/s]
Processed prompts:  78%|███████▊  | 399/512 [01:19<00:10, 11.02it/s, est. speed input: 80.12 toks/s, output: 1281.94 toks/s]
Processed prompts:  78%|███████▊  | 401/512 [01:19<00:10, 10.15it/s, est. speed input: 80.29 toks/s, output: 1284.65 toks/s]
Processed prompts:  79%|███████▊  | 403/512 [01:20<00:12,  8.44it/s, est. speed input: 80.36 toks/s, output: 1285.83 toks/s]
Processed prompts:  79%|███████▉  | 404/512 [01:20<00:22,  4.88it/s, est. speed input: 79.97 toks/s, output: 1279.53 toks/s]
Processed prompts:  79%|███████▉  | 405/512 [01:21<00:42,  2.51it/s, est. speed input: 79.05 toks/s, output: 1264.86 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [01:22<00:47,  2.24it/s, est. speed input: 78.66 toks/s, output: 1258.61 toks/s]
Processed prompts:  79%|███████▉  | 407/512 [01:22<00:43,  2.42it/s, est. speed input: 78.56 toks/s, output: 1257.00 toks/s]
Processed prompts:  80%|███████▉  | 408/512 [01:23<00:38,  2.73it/s, est. speed input: 78.53 toks/s, output: 1256.55 toks/s]
Processed prompts:  80%|███████▉  | 409/512 [01:23<00:32,  3.16it/s, est. speed input: 78.56 toks/s, output: 1256.90 toks/s]
Processed prompts:  80%|████████  | 410/512 [01:23<00:29,  3.50it/s, est. speed input: 78.55 toks/s, output: 1256.86 toks/s]
Processed prompts:  80%|████████  | 411/512 [01:23<00:24,  4.19it/s, est. speed input: 78.63 toks/s, output: 1258.10 toks/s]
Processed prompts:  80%|████████  | 412/512 [01:23<00:21,  4.65it/s, est. speed input: 78.67 toks/s, output: 1258.79 toks/s]
Processed prompts:  81%|████████  | 413/512 [01:24<00:23,  4.20it/s, est. speed input: 78.59 toks/s, output: 1257.43 toks/s]
Processed prompts:  81%|████████  | 414/512 [01:24<00:22,  4.38it/s, est. speed input: 78.59 toks/s, output: 1257.42 toks/s]
Processed prompts:  81%|████████  | 415/512 [01:24<00:23,  4.11it/s, est. speed input: 78.52 toks/s, output: 1256.29 toks/s]
Processed prompts:  81%|████████▏ | 416/512 [01:24<00:21,  4.42it/s, est. speed input: 78.53 toks/s, output: 1256.56 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [01:24<00:16,  5.67it/s, est. speed input: 78.69 toks/s, output: 1259.11 toks/s]
Processed prompts:  82%|████████▏ | 420/512 [01:25<00:12,  7.20it/s, est. speed input: 78.92 toks/s, output: 1262.70 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [01:25<00:09,  9.27it/s, est. speed input: 79.20 toks/s, output: 1267.13 toks/s]
Processed prompts:  83%|████████▎ | 424/512 [01:25<00:07, 11.21it/s, est. speed input: 79.47 toks/s, output: 1271.56 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [01:25<00:07, 12.19it/s, est. speed input: 79.72 toks/s, output: 1275.54 toks/s]
Processed prompts:  84%|████████▎ | 428/512 [01:25<00:06, 13.22it/s, est. speed input: 79.98 toks/s, output: 1279.68 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [01:25<00:06, 13.60it/s, est. speed input: 80.22 toks/s, output: 1283.59 toks/s]
Processed prompts:  84%|████████▍ | 432/512 [01:26<00:11,  6.70it/s, est. speed input: 80.00 toks/s, output: 1280.04 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [01:27<00:20,  3.89it/s, est. speed input: 79.45 toks/s, output: 1271.22 toks/s]
Processed prompts:  85%|████████▍ | 435/512 [01:27<00:22,  3.50it/s, est. speed input: 79.25 toks/s, output: 1268.08 toks/s]
Processed prompts:  85%|████████▌ | 436/512 [01:28<00:24,  3.12it/s, est. speed input: 79.03 toks/s, output: 1264.44 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [01:28<00:10,  6.96it/s, est. speed input: 79.88 toks/s, output: 1278.14 toks/s]
Processed prompts:  87%|████████▋ | 444/512 [01:28<00:10,  6.72it/s, est. speed input: 79.95 toks/s, output: 1279.13 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [01:29<00:08,  7.41it/s, est. speed input: 80.14 toks/s, output: 1282.20 toks/s]
Processed prompts:  87%|████████▋ | 447/512 [01:29<00:09,  7.00it/s, est. speed input: 80.15 toks/s, output: 1282.38 toks/s]
Processed prompts:  88%|████████▊ | 448/512 [01:29<00:09,  6.84it/s, est. speed input: 80.18 toks/s, output: 1282.93 toks/s]
Processed prompts:  88%|████████▊ | 449/512 [01:29<00:09,  6.70it/s, est. speed input: 80.22 toks/s, output: 1283.47 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [01:29<00:08,  7.07it/s, est. speed input: 80.29 toks/s, output: 1284.68 toks/s]
Processed prompts:  88%|████████▊ | 453/512 [01:29<00:06,  9.58it/s, est. speed input: 80.65 toks/s, output: 1290.41 toks/s]
Processed prompts:  89%|████████▉ | 457/512 [01:30<00:04, 13.73it/s, est. speed input: 81.22 toks/s, output: 1299.55 toks/s]
Processed prompts:  90%|████████▉ | 460/512 [01:30<00:03, 16.01it/s, est. speed input: 81.64 toks/s, output: 1306.23 toks/s]
Processed prompts:  90%|█████████ | 462/512 [01:30<00:07,  6.98it/s, est. speed input: 81.29 toks/s, output: 1300.61 toks/s]
Processed prompts:  91%|█████████ | 464/512 [01:32<00:12,  3.87it/s, est. speed input: 80.60 toks/s, output: 1289.57 toks/s]
Processed prompts:  91%|█████████ | 465/512 [01:32<00:13,  3.41it/s, est. speed input: 80.35 toks/s, output: 1285.66 toks/s]
Processed prompts:  91%|█████████ | 466/512 [01:32<00:13,  3.31it/s, est. speed input: 80.23 toks/s, output: 1283.67 toks/s]
Processed prompts:  91%|█████████ | 467/512 [01:33<00:14,  3.05it/s, est. speed input: 80.03 toks/s, output: 1280.52 toks/s]
Processed prompts:  91%|█████████▏| 468/512 [01:33<00:13,  3.27it/s, est. speed input: 80.01 toks/s, output: 1280.11 toks/s]
Processed prompts:  92%|█████████▏| 469/512 [01:33<00:11,  3.63it/s, est. speed input: 80.02 toks/s, output: 1280.37 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [01:34<00:11,  3.79it/s, est. speed input: 80.00 toks/s, output: 1279.94 toks/s]
Processed prompts:  92%|█████████▏| 471/512 [01:34<00:10,  3.87it/s, est. speed input: 79.96 toks/s, output: 1279.33 toks/s]
Processed prompts:  92%|█████████▏| 472/512 [01:34<00:09,  4.11it/s, est. speed input: 79.96 toks/s, output: 1279.29 toks/s]
Processed prompts:  92%|█████████▏| 473/512 [01:34<00:09,  3.93it/s, est. speed input: 79.89 toks/s, output: 1278.18 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [01:34<00:08,  4.30it/s, est. speed input: 79.90 toks/s, output: 1278.47 toks/s]
Processed prompts:  93%|█████████▎| 475/512 [01:35<00:07,  4.91it/s, est. speed input: 79.96 toks/s, output: 1279.36 toks/s]
Processed prompts:  93%|█████████▎| 476/512 [01:35<00:06,  5.65it/s, est. speed input: 80.03 toks/s, output: 1280.52 toks/s]
Processed prompts:  93%|█████████▎| 477/512 [01:35<00:05,  6.33it/s, est. speed input: 80.11 toks/s, output: 1281.70 toks/s]
Processed prompts:  94%|█████████▎| 479/512 [01:35<00:04,  8.17it/s, est. speed input: 80.31 toks/s, output: 1284.90 toks/s]
Processed prompts:  94%|█████████▍| 481/512 [01:35<00:03,  9.14it/s, est. speed input: 80.49 toks/s, output: 1287.85 toks/s]
Processed prompts:  94%|█████████▍| 483/512 [01:35<00:02, 11.29it/s, est. speed input: 80.74 toks/s, output: 1291.81 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [01:35<00:01, 14.81it/s, est. speed input: 81.14 toks/s, output: 1298.19 toks/s]
Processed prompts:  96%|█████████▌| 489/512 [01:35<00:01, 17.58it/s, est. speed input: 81.54 toks/s, output: 1304.58 toks/s]
Processed prompts:  96%|█████████▌| 491/512 [01:36<00:01, 16.39it/s, est. speed input: 81.75 toks/s, output: 1307.94 toks/s]
Processed prompts:  96%|█████████▋| 493/512 [01:37<00:03,  5.20it/s, est. speed input: 81.17 toks/s, output: 1298.79 toks/s]
Processed prompts:  97%|█████████▋| 495/512 [01:38<00:05,  3.03it/s, est. speed input: 80.38 toks/s, output: 1286.11 toks/s]
Processed prompts:  97%|█████████▋| 496/512 [01:38<00:05,  3.06it/s, est. speed input: 80.29 toks/s, output: 1284.66 toks/s]
Processed prompts:  97%|█████████▋| 497/512 [01:39<00:04,  3.09it/s, est. speed input: 80.20 toks/s, output: 1283.24 toks/s]
Processed prompts:  97%|█████████▋| 499/512 [01:39<00:03,  3.87it/s, est. speed input: 80.30 toks/s, output: 1284.73 toks/s]
Processed prompts:  98%|█████████▊| 500/512 [01:39<00:02,  4.09it/s, est. speed input: 80.30 toks/s, output: 1284.86 toks/s]
Processed prompts:  98%|█████████▊| 501/512 [01:39<00:02,  4.12it/s, est. speed input: 80.27 toks/s, output: 1284.39 toks/s]
Processed prompts:  98%|█████████▊| 503/512 [01:40<00:01,  5.17it/s, est. speed input: 80.41 toks/s, output: 1286.50 toks/s]
Processed prompts:  98%|█████████▊| 504/512 [01:40<00:01,  5.65it/s, est. speed input: 80.47 toks/s, output: 1287.55 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [01:40<00:00,  7.13it/s, est. speed input: 80.66 toks/s, output: 1290.56 toks/s]
Processed prompts:  99%|█████████▉| 508/512 [01:40<00:00,  8.15it/s, est. speed input: 80.83 toks/s, output: 1293.32 toks/s]
Processed prompts:  99%|█████████▉| 509/512 [01:40<00:00,  7.98it/s, est. speed input: 80.88 toks/s, output: 1294.12 toks/s]
Processed prompts: 100%|█████████▉| 511/512 [01:40<00:00, 10.01it/s, est. speed input: 81.11 toks/s, output: 1297.76 toks/s]
Processed prompts: 100%|██████████| 512/512 [01:40<00:00, 10.01it/s, est. speed input: 81.16 toks/s, output: 1298.59 toks/s]
Processed prompts: 100%|██████████| 512/512 [01:40<00:00,  5.07it/s, est. speed input: 81.16 toks/s, output: 1298.59 toks/s]
[rank0]:[W126 11:34:14.604782759 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 193.3s

测试结果:
  Requests/s:   4.85
  Tokens/s:     1319.67
  Total Reqs:   512
  Elapsed:      105.53s

  [Decode 分析]
  Total Decode Tokens:  131072
  Decode Tokens/s:      1242.04


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt/Qwen2.5-14B-FP8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
64,16,64,64,256,256,5.7373,1560.5577,11.1550
128,16,128,128,256,256,8.3791,2279.1083,15.2762
256,16,256,256,256,256,8.3169,2262.1961,30.7807
512,16,512,512,256,256,4.8517,1319.6668,105.5297

------------------------------------------------------------

[INFO] 完成: 4 成功, 0 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_4) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/4] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:34:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:34:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=589647) WARNING 01-26 11:34:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=589647) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=589647) WARNING 01-26 11:35:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.57 requests/s, 2875.25 total tokens/s, 2706.11 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384


─── STDERR ───
[2026-01-26 11:34:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:34:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:34:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:34:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:34:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:34:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:34:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:34:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:34:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:34:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:34:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:34:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:34:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:34:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:34:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:34:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:34:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.89s/it]
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:07<00:07,  3.97s/it]
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:09<00:02,  2.73s/it]
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.13s/it]
(EngineCore_DP0 pid=589647) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.23s/it]
(EngineCore_DP0 pid=589647) 
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=589647) [2026-01-26 11:34:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=589647) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:06,  2.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:06,  2.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:09,  1.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:09,  1.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:07,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:06,  2.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:03<00:04,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:03<00:04,  2.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:03,  3.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:04<00:02,  3.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:04<00:03,  2.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:05<00:03,  2.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:05<00:02,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:05<00:01,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:06<00:01,  3.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:06<00:00,  3.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:06<00:00,  4.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:06<00:00,  4.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  4.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  2.76it/s]
(EngineCore_DP0 pid=589647) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  3.39it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:04,  2.01it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:01<00:02,  2.75it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  9.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  8.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.41it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2449.21it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:05<06:13,  5.93s/it, est. speed input: 2.70 toks/s, output: 43.20 toks/s]
Processed prompts:  97%|█████████▋| 62/64 [00:06<00:00, 14.52it/s, est. speed input: 164.60 toks/s, output: 2633.66 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:06<00:00, 14.52it/s, est. speed input: 169.91 toks/s, output: 2718.54 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:06<00:00, 10.62it/s, est. speed input: 169.91 toks/s, output: 2718.54 toks/s]
[rank0]:[W126 11:35:43.347303012 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 89.1s

测试结果:
  Requests/s:   10.57
  Tokens/s:     2875.25
  Total Reqs:   64
  Elapsed:      6.05s

  [Decode 分析]
  Total Decode Tokens:  16384
  Decode Tokens/s:      2706.11

============================================================
[2/4] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:35:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:35:56 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=591125) WARNING 01-26 11:36:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=591125) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591125) WARNING 01-26 11:36:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.71 requests/s, 4273.94 total tokens/s, 4022.54 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 11:35:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:35:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:35:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:35:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:35:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:35:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:35:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:35:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:35:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:36:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:36:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:36:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:36:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:36:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:36:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:36:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:36:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:36:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:02<00:07,  2.39s/it]
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:06<00:06,  3.30s/it]
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:07<00:02,  2.36s/it]
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:11<00:00,  2.91s/it]
(EngineCore_DP0 pid=591125) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:11<00:00,  2.83s/it]
(EngineCore_DP0 pid=591125) 
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=591125) [2026-01-26 11:36:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=591125) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:28,  1.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:27,  1.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:17,  1.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:02<00:12,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:02<00:09,  3.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:02<00:08,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:02<00:07,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:02<00:06,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:03<00:07,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:03<00:10,  2.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:04<00:13,  1.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:10,  2.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:05<00:08,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:05<00:06,  3.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:05<00:05,  3.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:05<00:04,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:05<00:04,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:06<00:04,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:06<00:06,  2.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:07<00:05,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:07<00:06,  2.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:08<00:04,  2.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:08<00:03,  3.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:08<00:03,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:08<00:02,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:08<00:02,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:09<00:01,  4.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:09<00:01,  3.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:10<00:02,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:11<00:02,  1.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:11<00:01,  2.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:11<00:01,  2.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:11<00:00,  3.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:11<00:00,  3.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  3.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  2.91it/s]
(EngineCore_DP0 pid=591125) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:03,  4.60it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:03,  5.05it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:03,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:01<00:05,  2.94it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:04,  3.14it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:01<00:04,  2.85it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:02<00:04,  2.62it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:02<00:03,  3.13it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:02<00:02,  3.62it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:02<00:02,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:03<00:01,  4.38it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:03<00:01,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:03<00:01,  4.85it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:03<00:01,  4.56it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:04<00:01,  2.89it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:04<00:00,  3.18it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:05<00:00,  2.78it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  4.77it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2593.62it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:07<15:33,  7.35s/it, est. speed input: 2.18 toks/s, output: 34.83 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:07<00:15,  6.16it/s, est. speed input: 70.24 toks/s, output: 1123.88 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:07<00:01, 22.95it/s, est. speed input: 205.57 toks/s, output: 3289.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 22.95it/s, est. speed input: 253.00 toks/s, output: 4047.97 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.81it/s, est. speed input: 253.00 toks/s, output: 4047.97 toks/s]
[rank0]:[W126 11:37:17.310119546 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 93.8s

测试结果:
  Requests/s:   15.71
  Tokens/s:     4273.94
  Total Reqs:   128
  Elapsed:      8.15s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      4022.54

============================================================
[3/4] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:37:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:37:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=592661) WARNING 01-26 11:37:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=592661) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=592661) WARNING 01-26 11:37:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.02 requests/s, 3814.48 total tokens/s, 3590.10 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536


─── STDERR ───
[2026-01-26 11:37:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:37:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:37:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:37:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:37:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:37:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:37:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:37:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:37:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:37:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:37:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:37:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:37:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:37:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:37:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:37:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:37:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.01s/it]
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.04s/it]
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.33it/s]
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.17it/s]
(EngineCore_DP0 pid=592661) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.15it/s]
(EngineCore_DP0 pid=592661) 
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=592661) [2026-01-26 11:37:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=592661) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:07,  5.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:06,  4.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:06,  4.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:08,  3.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:12,  2.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:02<00:16,  1.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:02<00:12,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:02<00:10,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:03<00:08,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:03<00:07,  3.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:03<00:06,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:03<00:05,  4.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:03<00:05,  4.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:04<00:08,  2.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:05<00:08,  2.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:05<00:09,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:05<00:07,  2.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:06<00:05,  3.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:06<00:04,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:06<00:04,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:06<00:03,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:06<00:03,  4.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:07<00:03,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:07<00:04,  2.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:08<00:05,  1.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:08<00:04,  2.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:09<00:03,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:09<00:02,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:09<00:01,  3.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:09<00:01,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:09<00:01,  4.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:10<00:00,  4.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:10<00:00,  3.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:11<00:00,  2.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:11<00:00,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:12<00:00,  2.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:12<00:00,  2.98it/s]
(EngineCore_DP0 pid=592661) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:12,  2.72it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:08,  3.81it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:07,  4.38it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:06,  4.67it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:06,  4.83it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:06,  4.40it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:02<00:10,  2.77it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:02<00:10,  2.69it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:10,  2.46it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:03<00:08,  2.81it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:03<00:07,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:03<00:06,  3.74it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:03<00:05,  4.11it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:03<00:04,  4.42it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:04<00:04,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:04<00:04,  4.75it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:04<00:04,  4.15it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:05<00:05,  2.84it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:05<00:05,  3.01it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:06<00:06,  2.38it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:06<00:05,  2.73it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:06<00:04,  3.20it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:06<00:03,  3.63it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:06<00:02,  4.01it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:07<00:02,  4.32it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:07<00:01,  4.58it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:07<00:01,  4.65it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:07<00:01,  4.30it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:08<00:01,  3.07it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:08<00:01,  3.04it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:09<00:01,  2.95it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:09<00:00,  3.12it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:09<00:00,  3.57it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:09<00:00,  3.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  4.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  3.55it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2644.65it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:07<33:36,  7.91s/it, est. speed input: 2.02 toks/s, output: 32.37 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:08<00:38,  5.80it/s, est. speed input: 65.91 toks/s, output: 1054.54 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:08<00:07, 21.58it/s, est. speed input: 192.70 toks/s, output: 3083.16 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:10<00:06, 19.09it/s, est. speed input: 205.26 toks/s, output: 3284.21 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:12<00:06, 16.14it/s, est. speed input: 200.14 toks/s, output: 3202.31 toks/s]
Processed prompts:  65%|██████▌   | 167/256 [00:13<00:05, 15.96it/s, est. speed input: 203.20 toks/s, output: 3251.16 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:13<00:04, 16.57it/s, est. speed input: 207.73 toks/s, output: 3323.71 toks/s]
Processed prompts:  72%|███████▏  | 185/256 [00:14<00:04, 17.12it/s, est. speed input: 211.20 toks/s, output: 3379.18 toks/s]
Processed prompts:  75%|███████▍  | 191/256 [00:14<00:03, 18.23it/s, est. speed input: 215.00 toks/s, output: 3439.96 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:14<00:03, 18.32it/s, est. speed input: 216.59 toks/s, output: 3465.41 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:14<00:03, 18.61it/s, est. speed input: 218.08 toks/s, output: 3489.24 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:14<00:02, 19.62it/s, est. speed input: 220.20 toks/s, output: 3523.25 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:14<00:02, 20.77it/s, est. speed input: 222.34 toks/s, output: 3557.40 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:15<00:01, 22.54it/s, est. speed input: 224.77 toks/s, output: 3596.28 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:15<00:01, 23.02it/s, est. speed input: 226.58 toks/s, output: 3625.27 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:15<00:01, 22.06it/s, est. speed input: 227.37 toks/s, output: 3637.85 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:15<00:01, 22.73it/s, est. speed input: 228.73 toks/s, output: 3659.63 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:15<00:01, 24.42it/s, est. speed input: 230.84 toks/s, output: 3693.42 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:15<00:01, 24.97it/s, est. speed input: 232.67 toks/s, output: 3722.74 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:15<00:00, 26.41it/s, est. speed input: 234.77 toks/s, output: 3756.33 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:16<00:00, 26.43it/s, est. speed input: 236.54 toks/s, output: 3784.70 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:16<00:00, 27.62it/s, est. speed input: 238.60 toks/s, output: 3817.59 toks/s]
Processed prompts:  96%|█████████▌| 245/256 [00:16<00:00, 27.56it/s, est. speed input: 239.94 toks/s, output: 3839.00 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:16<00:00, 28.91it/s, est. speed input: 242.02 toks/s, output: 3872.35 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:16<00:00, 28.88it/s, est. speed input: 243.40 toks/s, output: 3894.35 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:16<00:00, 29.00it/s, est. speed input: 244.78 toks/s, output: 3916.55 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:16<00:00, 29.00it/s, est. speed input: 245.50 toks/s, output: 3927.93 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:16<00:00, 15.34it/s, est. speed input: 245.50 toks/s, output: 3927.93 toks/s]
[rank0]:[W126 11:38:57.134669778 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 100.6s

测试结果:
  Requests/s:   14.02
  Tokens/s:     3814.48
  Total Reqs:   256
  Elapsed:      18.25s

  [Decode 分析]
  Total Decode Tokens:  65536
  Decode Tokens/s:      3590.10

============================================================
[4/4] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:39:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:39:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=594269) WARNING 01-26 11:39:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=594269) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=594269) WARNING 01-26 11:39:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 13.74 requests/s, 3737.70 total tokens/s, 3517.84 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072


─── STDERR ───
[2026-01-26 11:39:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:39:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:39:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:39:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:39:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:39:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:39:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:39:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:39:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:39:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:39:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:39:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:39:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:39:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:39:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:39:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:39:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.01s/it]
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.04s/it]
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.34it/s]
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.20it/s]
(EngineCore_DP0 pid=594269) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.17it/s]
(EngineCore_DP0 pid=594269) 
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 27525120 bytes
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 19660800 bytes
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 106168320 bytes
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=594269) [2026-01-26 11:39:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 53084160 bytes
(EngineCore_DP0 pid=594269) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:12,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:10,  4.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:10,  4.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:01<00:22,  2.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:01<00:19,  2.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:02<00:22,  1.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:02<00:17,  2.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:02<00:14,  2.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:03<00:12,  3.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:03<00:10,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:03<00:09,  4.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:03<00:09,  4.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:04<00:11,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:04<00:13,  2.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:05<00:18,  1.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:05<00:15,  2.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:06<00:12,  2.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:06<00:10,  3.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:06<00:09,  3.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:06<00:08,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:06<00:07,  4.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:07<00:07,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:07<00:11,  2.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:08<00:14,  1.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:09<00:11,  2.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:09<00:09,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:09<00:07,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:09<00:06,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:09<00:05,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:10<00:05,  4.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:10<00:05,  3.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:11<00:07,  2.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:11<00:08,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:12<00:07,  2.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:12<00:05,  2.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:12<00:04,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:12<00:03,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:12<00:03,  3.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:13<00:02,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:13<00:02,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:14<00:04,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:14<00:03,  2.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:14<00:00,  7.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:15<00:00,  6.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:15<00:00,  3.20it/s]
(EngineCore_DP0 pid=594269) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:36,  1.36it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:22,  2.22it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:01<00:15,  3.01it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:01<00:13,  3.60it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:01<00:11,  4.02it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:01<00:10,  4.37it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:01<00:09,  4.57it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:02<00:09,  4.76it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:02<00:10,  4.19it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:02<00:13,  3.13it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:03<00:12,  3.25it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:03<00:15,  2.48it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:04<00:13,  2.82it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:04<00:11,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:04<00:09,  3.73it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:04<00:08,  4.10it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:04<00:07,  4.37it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:05<00:07,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:05<00:06,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:05<00:07,  4.10it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:06<00:09,  3.15it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:06<00:09,  2.95it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:07<00:11,  2.43it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:07<00:09,  2.87it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:07<00:07,  3.34it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:07<00:06,  3.77it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:07<00:05,  4.12it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:07<00:05,  4.42it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:08<00:04,  4.65it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:08<00:04,  4.61it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:08<00:05,  3.99it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:09<00:06,  3.04it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:09<00:05,  3.19it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:10<00:06,  2.54it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:10<00:05,  3.01it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:10<00:04,  3.47it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:10<00:03,  3.87it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:10<00:03,  4.20it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:11<00:02,  4.48it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:11<00:02,  4.70it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:11<00:02,  4.87it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:11<00:01,  4.94it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:11<00:01,  4.51it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:12<00:02,  3.29it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:12<00:01,  3.35it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:13<00:01,  2.95it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:13<00:01,  2.90it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:13<00:00,  3.38it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:13<00:00,  3.82it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:13<00:00,  4.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:14<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:14<00:00,  3.60it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  53%|█████▎    | 273/512 [00:00<00:00, 2725.86it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2791.21it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:09<1:21:26,  9.56s/it, est. speed input: 1.67 toks/s, output: 26.77 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:09<00:48,  9.19it/s, est. speed input: 104.00 toks/s, output: 1663.99 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:11<00:37, 11.35it/s, est. speed input: 129.44 toks/s, output: 2071.11 toks/s]
Processed prompts:  21%|██        | 107/512 [00:11<00:29, 13.57it/s, est. speed input: 146.29 toks/s, output: 2340.67 toks/s]
Processed prompts:  23%|██▎       | 119/512 [00:12<00:31, 12.66it/s, est. speed input: 147.63 toks/s, output: 2362.15 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:13<00:28, 13.69it/s, est. speed input: 153.50 toks/s, output: 2456.06 toks/s]
Processed prompts:  26%|██▌       | 133/512 [00:13<00:28, 13.37it/s, est. speed input: 154.81 toks/s, output: 2476.93 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:13<00:26, 14.07it/s, est. speed input: 157.75 toks/s, output: 2524.05 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:14<00:25, 14.78it/s, est. speed input: 160.13 toks/s, output: 2562.15 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:14<00:27, 13.32it/s, est. speed input: 159.68 toks/s, output: 2554.89 toks/s]
Processed prompts:  29%|██▉       | 149/512 [00:14<00:25, 14.45it/s, est. speed input: 161.71 toks/s, output: 2587.30 toks/s]
Processed prompts:  30%|██▉       | 152/512 [00:14<00:22, 15.74it/s, est. speed input: 163.70 toks/s, output: 2619.12 toks/s]
Processed prompts:  30%|███       | 155/512 [00:14<00:20, 17.18it/s, est. speed input: 165.66 toks/s, output: 2650.51 toks/s]
Processed prompts:  31%|███       | 158/512 [00:15<00:19, 18.61it/s, est. speed input: 167.57 toks/s, output: 2681.06 toks/s]
Processed prompts:  31%|███▏      | 161/512 [00:15<00:25, 13.71it/s, est. speed input: 166.39 toks/s, output: 2662.16 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:15<00:22, 15.13it/s, est. speed input: 167.97 toks/s, output: 2687.53 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:15<00:20, 17.11it/s, est. speed input: 169.81 toks/s, output: 2716.94 toks/s]
Processed prompts:  33%|███▎      | 171/512 [00:15<00:16, 20.55it/s, est. speed input: 172.57 toks/s, output: 2761.17 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:15<00:15, 22.27it/s, est. speed input: 174.46 toks/s, output: 2791.35 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:16<00:21, 15.21it/s, est. speed input: 173.82 toks/s, output: 2781.14 toks/s]
Processed prompts:  35%|███▌      | 181/512 [00:16<00:19, 17.10it/s, est. speed input: 175.52 toks/s, output: 2808.29 toks/s]
Processed prompts:  36%|███▌      | 184/512 [00:16<00:17, 19.23it/s, est. speed input: 177.30 toks/s, output: 2836.82 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:16<00:16, 19.99it/s, est. speed input: 178.74 toks/s, output: 2859.81 toks/s]
Processed prompts:  37%|███▋      | 191/512 [00:16<00:13, 23.14it/s, est. speed input: 181.24 toks/s, output: 2899.84 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:16<00:12, 25.50it/s, est. speed input: 183.68 toks/s, output: 2938.82 toks/s]
Processed prompts:  39%|███▉      | 199/512 [00:17<00:12, 24.21it/s, est. speed input: 185.45 toks/s, output: 2967.17 toks/s]
Processed prompts:  40%|███▉      | 204/512 [00:17<00:16, 18.20it/s, est. speed input: 185.85 toks/s, output: 2973.63 toks/s]
Processed prompts:  40%|████      | 207/512 [00:17<00:16, 18.18it/s, est. speed input: 186.82 toks/s, output: 2989.19 toks/s]
Processed prompts:  41%|████      | 210/512 [00:17<00:15, 19.84it/s, est. speed input: 188.35 toks/s, output: 3013.66 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:17<00:13, 22.48it/s, est. speed input: 190.56 toks/s, output: 3049.03 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:18<00:12, 24.47it/s, est. speed input: 192.71 toks/s, output: 3083.28 toks/s]
Processed prompts:  44%|████▎     | 223/512 [00:18<00:10, 27.91it/s, est. speed input: 195.67 toks/s, output: 3130.68 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:18<00:10, 26.31it/s, est. speed input: 196.84 toks/s, output: 3149.48 toks/s]
Processed prompts:  45%|████▍     | 229/512 [00:18<00:14, 20.10it/s, est. speed input: 196.74 toks/s, output: 3147.89 toks/s]
Processed prompts:  45%|████▌     | 232/512 [00:19<00:24, 11.27it/s, est. speed input: 193.20 toks/s, output: 3091.23 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:19<00:32,  8.63it/s, est. speed input: 190.44 toks/s, output: 3047.01 toks/s]
Processed prompts:  46%|████▌     | 236/512 [00:20<00:36,  7.58it/s, est. speed input: 188.47 toks/s, output: 3015.57 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:20<00:45,  6.00it/s, est. speed input: 184.99 toks/s, output: 2959.86 toks/s]
Processed prompts:  47%|████▋     | 239/512 [00:20<00:43,  6.26it/s, est. speed input: 184.68 toks/s, output: 2954.90 toks/s]
Processed prompts:  47%|████▋     | 240/512 [00:20<00:43,  6.26it/s, est. speed input: 184.04 toks/s, output: 2944.58 toks/s]
Processed prompts:  47%|████▋     | 241/512 [00:21<00:44,  6.08it/s, est. speed input: 183.19 toks/s, output: 2931.04 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:21<00:42,  6.40it/s, est. speed input: 182.85 toks/s, output: 2925.54 toks/s]
Processed prompts:  47%|████▋     | 243/512 [00:21<00:38,  6.95it/s, est. speed input: 182.70 toks/s, output: 2923.12 toks/s]
Processed prompts:  48%|████▊     | 244/512 [00:21<00:35,  7.45it/s, est. speed input: 182.54 toks/s, output: 2920.62 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:21<00:28,  9.19it/s, est. speed input: 182.77 toks/s, output: 2924.30 toks/s]
Processed prompts:  48%|████▊     | 248/512 [00:21<00:26,  9.81it/s, est. speed input: 182.72 toks/s, output: 2923.47 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:21<00:23, 11.18it/s, est. speed input: 183.07 toks/s, output: 2929.19 toks/s]
Processed prompts:  49%|████▉     | 253/512 [00:22<00:18, 13.69it/s, est. speed input: 183.98 toks/s, output: 2943.67 toks/s]
Processed prompts:  50%|████▉     | 255/512 [00:22<00:18, 13.94it/s, est. speed input: 184.29 toks/s, output: 2948.57 toks/s]
Processed prompts:  50%|█████     | 257/512 [00:22<00:17, 14.31it/s, est. speed input: 184.64 toks/s, output: 2954.26 toks/s]
Processed prompts:  51%|█████     | 259/512 [00:22<00:17, 14.87it/s, est. speed input: 185.06 toks/s, output: 2961.03 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:22<00:14, 17.34it/s, est. speed input: 186.15 toks/s, output: 2978.37 toks/s]
Processed prompts:  52%|█████▏    | 267/512 [00:22<00:10, 24.27it/s, est. speed input: 188.72 toks/s, output: 3019.56 toks/s]
Processed prompts:  53%|█████▎    | 272/512 [00:22<00:08, 29.62it/s, est. speed input: 191.29 toks/s, output: 3060.63 toks/s]
Processed prompts:  54%|█████▍    | 276/512 [00:23<00:11, 19.79it/s, est. speed input: 191.19 toks/s, output: 3059.04 toks/s]
Processed prompts:  54%|█████▍    | 279/512 [00:23<00:12, 18.67it/s, est. speed input: 191.71 toks/s, output: 3067.43 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:23<00:12, 18.83it/s, est. speed input: 192.49 toks/s, output: 3079.81 toks/s]
Processed prompts:  56%|█████▌    | 285/512 [00:23<00:14, 16.13it/s, est. speed input: 192.44 toks/s, output: 3078.96 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:23<00:13, 16.69it/s, est. speed input: 193.12 toks/s, output: 3089.98 toks/s]
Processed prompts:  57%|█████▋    | 292/512 [00:23<00:10, 20.32it/s, est. speed input: 194.85 toks/s, output: 3117.59 toks/s]
Processed prompts:  58%|█████▊    | 297/512 [00:24<00:08, 25.24it/s, est. speed input: 197.19 toks/s, output: 3155.00 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:24<00:07, 29.16it/s, est. speed input: 199.49 toks/s, output: 3191.84 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:24<00:08, 25.19it/s, est. speed input: 200.38 toks/s, output: 3206.02 toks/s]
Processed prompts:  60%|██████    | 309/512 [00:24<00:08, 24.80it/s, est. speed input: 201.30 toks/s, output: 3220.72 toks/s]
Processed prompts:  61%|██████    | 312/512 [00:24<00:09, 20.57it/s, est. speed input: 201.45 toks/s, output: 3223.18 toks/s]
Processed prompts:  62%|██████▏   | 315/512 [00:25<00:11, 17.57it/s, est. speed input: 201.44 toks/s, output: 3222.96 toks/s]
Processed prompts:  62%|██████▏   | 319/512 [00:25<00:09, 19.46it/s, est. speed input: 202.68 toks/s, output: 3242.92 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:25<00:09, 19.70it/s, est. speed input: 203.40 toks/s, output: 3254.42 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:25<00:07, 24.28it/s, est. speed input: 205.51 toks/s, output: 3288.11 toks/s]
Processed prompts:  65%|██████▌   | 335/512 [00:25<00:05, 34.07it/s, est. speed input: 209.48 toks/s, output: 3351.76 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [00:25<00:03, 49.52it/s, est. speed input: 216.32 toks/s, output: 3461.10 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:26<00:09, 16.71it/s, est. speed input: 211.41 toks/s, output: 3382.63 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:27<00:13, 11.41it/s, est. speed input: 207.55 toks/s, output: 3320.79 toks/s]
Processed prompts:  71%|███████   | 361/512 [00:27<00:12, 11.81it/s, est. speed input: 207.69 toks/s, output: 3323.11 toks/s]
Processed prompts:  71%|███████   | 364/512 [00:28<00:12, 12.14it/s, est. speed input: 207.78 toks/s, output: 3324.52 toks/s]
Processed prompts:  72%|███████▏  | 367/512 [00:28<00:12, 11.21it/s, est. speed input: 206.98 toks/s, output: 3311.74 toks/s]
Processed prompts:  72%|███████▏  | 369/512 [00:28<00:13, 10.85it/s, est. speed input: 206.57 toks/s, output: 3305.05 toks/s]
Processed prompts:  72%|███████▏  | 371/512 [00:28<00:13, 10.69it/s, est. speed input: 206.26 toks/s, output: 3300.11 toks/s]
Processed prompts:  73%|███████▎  | 373/512 [00:28<00:12, 11.03it/s, est. speed input: 206.21 toks/s, output: 3299.38 toks/s]
Processed prompts:  73%|███████▎  | 375/512 [00:29<00:11, 11.67it/s, est. speed input: 206.32 toks/s, output: 3301.11 toks/s]
Processed prompts:  74%|███████▎  | 377/512 [00:29<00:11, 12.15it/s, est. speed input: 206.39 toks/s, output: 3302.31 toks/s]
Processed prompts:  74%|███████▍  | 379/512 [00:29<00:11, 11.37it/s, est. speed input: 206.03 toks/s, output: 3296.46 toks/s]
Processed prompts:  74%|███████▍  | 381/512 [00:29<00:12, 10.68it/s, est. speed input: 205.60 toks/s, output: 3289.62 toks/s]
Processed prompts:  75%|███████▍  | 383/512 [00:29<00:13,  9.60it/s, est. speed input: 204.87 toks/s, output: 3277.97 toks/s]
Processed prompts:  75%|███████▌  | 385/512 [00:30<00:12, 10.38it/s, est. speed input: 204.89 toks/s, output: 3278.23 toks/s]
Processed prompts:  76%|███████▌  | 387/512 [00:30<00:10, 11.51it/s, est. speed input: 205.08 toks/s, output: 3281.29 toks/s]
Processed prompts:  76%|███████▌  | 389/512 [00:30<00:11, 10.88it/s, est. speed input: 204.73 toks/s, output: 3275.65 toks/s]
Processed prompts:  77%|███████▋  | 392/512 [00:30<00:09, 13.18it/s, est. speed input: 205.29 toks/s, output: 3284.60 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:30<00:08, 13.53it/s, est. speed input: 205.41 toks/s, output: 3286.60 toks/s]
Processed prompts:  77%|███████▋  | 396/512 [00:30<00:09, 11.68it/s, est. speed input: 204.91 toks/s, output: 3278.48 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:31<00:09, 11.54it/s, est. speed input: 204.76 toks/s, output: 3276.10 toks/s]
Processed prompts:  78%|███████▊  | 400/512 [00:31<00:09, 11.51it/s, est. speed input: 204.63 toks/s, output: 3274.16 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:31<00:08, 12.92it/s, est. speed input: 204.95 toks/s, output: 3279.12 toks/s]
Processed prompts:  79%|███████▉  | 404/512 [00:31<00:07, 14.23it/s, est. speed input: 205.27 toks/s, output: 3284.32 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:31<00:06, 15.27it/s, est. speed input: 205.58 toks/s, output: 3289.26 toks/s]
Processed prompts:  80%|███████▉  | 409/512 [00:31<00:05, 17.31it/s, est. speed input: 206.21 toks/s, output: 3299.29 toks/s]
Processed prompts:  80%|████████  | 412/512 [00:31<00:05, 17.80it/s, est. speed input: 206.68 toks/s, output: 3306.83 toks/s]
Processed prompts:  81%|████████▏ | 417/512 [00:32<00:03, 24.30it/s, est. speed input: 208.42 toks/s, output: 3334.70 toks/s]
Processed prompts:  83%|████████▎ | 423/512 [00:32<00:02, 31.26it/s, est. speed input: 210.61 toks/s, output: 3369.82 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:32<00:02, 38.93it/s, est. speed input: 213.30 toks/s, output: 3412.87 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:32<00:01, 47.20it/s, est. speed input: 216.49 toks/s, output: 3463.76 toks/s]
Processed prompts:  87%|████████▋ | 444/512 [00:32<00:01, 48.68it/s, est. speed input: 218.68 toks/s, output: 3498.85 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:32<00:01, 50.27it/s, est. speed input: 220.88 toks/s, output: 3534.11 toks/s]
Processed prompts:  89%|████████▉ | 456/512 [00:32<00:01, 49.17it/s, est. speed input: 222.95 toks/s, output: 3567.21 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:32<00:00, 82.12it/s, est. speed input: 231.00 toks/s, output: 3696.07 toks/s]
Processed prompts:  96%|█████████▌| 491/512 [00:32<00:00, 89.72it/s, est. speed input: 238.08 toks/s, output: 3809.32 toks/s]
Processed prompts:  98%|█████████▊| 501/512 [00:34<00:00, 16.58it/s, est. speed input: 229.34 toks/s, output: 3669.38 toks/s]
Processed prompts:  99%|█████████▉| 508/512 [00:35<00:00, 16.44it/s, est. speed input: 229.65 toks/s, output: 3674.39 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:35<00:00, 16.44it/s, est. speed input: 230.24 toks/s, output: 3683.77 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:35<00:00, 14.39it/s, est. speed input: 230.24 toks/s, output: 3683.77 toks/s]
[rank0]:[W126 11:41:08.493290673 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 130.1s

测试结果:
  Requests/s:   13.74
  Tokens/s:     3737.70
  Total Reqs:   512
  Elapsed:      37.26s

  [Decode 分析]
  Total Decode Tokens:  131072
  Decode Tokens/s:      3517.84


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-14B-FP8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
64,16,64,64,256,256,10.5708,2875.2454,6.0544
128,16,128,128,256,256,15.7130,4273.9441,8.1461
256,16,256,256,256,256,14.0238,3814.4789,18.2547
512,16,512,512,256,256,13.7416,3737.7032,37.2592

------------------------------------------------------------

[INFO] 完成: 4 成功, 0 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/4] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:41:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:41:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=596302) WARNING 01-26 11:41:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=596302) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=596302) WARNING 01-26 11:42:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 6.17 requests/s, 1678.35 total tokens/s, 1579.62 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384


─── STDERR ───
[2026-01-26 11:41:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:41:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:41:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:41:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:41:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:41:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:41:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:41:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:41:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:41:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:41:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:41:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:41:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:41:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:41:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:41:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:41:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:15,  5.08s/it]
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:10<00:10,  5.00s/it]
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:11<00:03,  3.30s/it]
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  3.92s/it]
(EngineCore_DP0 pid=596302) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  4.04s/it]
(EngineCore_DP0 pid=596302) 
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=596302) [2026-01-26 11:41:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=596302) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:20,  1.15s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:02<00:17,  1.00s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:10,  1.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:06,  2.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:05,  2.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:03<00:03,  3.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:03<00:02,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:02,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:04<00:03,  2.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:04<00:03,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:05<00:03,  2.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:05<00:02,  2.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:05<00:01,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:05<00:01,  3.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:06<00:00,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:06<00:00,  4.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:06<00:00,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  2.82it/s]
(EngineCore_DP0 pid=596302) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:06,  1.65it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:03,  2.45it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:01<00:03,  2.42it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:01<00:02,  2.36it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:02,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:02<00:01,  3.48it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:02<00:01,  3.93it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:02<00:00,  4.31it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:02<00:00,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:02<00:00,  4.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  4.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  3.52it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2522.37it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:06<07:10,  6.84s/it, est. speed input: 2.34 toks/s, output: 37.42 toks/s]
Processed prompts:   3%|▎         | 2/64 [00:07<03:03,  2.96s/it, est. speed input: 4.52 toks/s, output: 72.25 toks/s]
Processed prompts:  52%|█████▏    | 33/64 [00:07<00:03,  8.81it/s, est. speed input: 73.15 toks/s, output: 1170.38 toks/s]
Processed prompts:  75%|███████▌  | 48/64 [00:07<00:01, 14.09it/s, est. speed input: 104.87 toks/s, output: 1677.96 toks/s]
Processed prompts:  95%|█████████▌| 61/64 [00:09<00:00,  8.72it/s, est. speed input: 97.99 toks/s, output: 1567.79 toks/s] 
Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  8.72it/s, est. speed input: 98.98 toks/s, output: 1583.74 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.19it/s, est. speed input: 98.98 toks/s, output: 1583.74 toks/s]
[rank0]:[W126 11:42:42.396850120 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 95.2s

测试结果:
  Requests/s:   6.17
  Tokens/s:     1678.35
  Total Reqs:   64
  Elapsed:      10.37s

  [Decode 分析]
  Total Decode Tokens:  16384
  Decode Tokens/s:      1579.62

============================================================
[2/4] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:42:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:42:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=597843) WARNING 01-26 11:43:02 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=597843) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=597843) WARNING 01-26 11:43:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.33 requests/s, 2538.85 total tokens/s, 2389.51 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 11:42:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:42:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:42:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:42:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:42:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:42:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:42:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:42:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:42:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:43:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:43:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:43:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:43:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:43:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:43:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:43:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:43:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:43:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.27s/it]
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.46s/it]
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.11s/it]
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
(EngineCore_DP0 pid=597843) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.22s/it]
(EngineCore_DP0 pid=597843) 
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=597843) [2026-01-26 11:43:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=597843) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:22,  1.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:12,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:09,  3.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:08,  3.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:07,  4.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:01<00:09,  3.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:02<00:11,  2.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:03<00:14,  1.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:03<00:11,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:03<00:09,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:03<00:07,  3.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:06,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:04<00:05,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:04<00:04,  4.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:04<00:04,  4.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:05<00:07,  2.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:06<00:08,  2.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:06<00:07,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:06<00:06,  2.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:07<00:04,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:07<00:04,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:07<00:03,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:07<00:02,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:07<00:02,  4.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:08<00:01,  5.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:08<00:01,  5.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:08<00:00,  5.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:08<00:00,  5.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:09<00:00,  5.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:09<00:00,  5.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:09<00:00,  5.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:09<00:00,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:09<00:00,  3.52it/s]
(EngineCore_DP0 pid=597843) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:12,  1.40it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:01<00:11,  1.52it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:01<00:07,  2.26it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:01<00:05,  2.93it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:04,  3.48it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:02<00:03,  3.93it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:02<00:02,  4.30it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:02<00:02,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:02<00:02,  4.78it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:02<00:01,  4.95it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:03<00:02,  2.70it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:03<00:02,  2.90it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:04<00:02,  2.72it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:04<00:01,  2.68it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:04<00:01,  3.16it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:05<00:00,  3.60it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:05<00:00,  4.02it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:05<00:00,  4.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:05<00:00,  4.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:05<00:00,  3.40it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2606.28it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:07<16:33,  7.82s/it, est. speed input: 2.05 toks/s, output: 32.72 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:08<00:09,  8.41it/s, est. speed input: 95.74 toks/s, output: 1531.91 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:08<00:05, 11.63it/s, est. speed input: 122.09 toks/s, output: 1953.46 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:10<00:05,  8.98it/s, est. speed input: 115.55 toks/s, output: 1848.78 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:11<00:04,  9.72it/s, est. speed input: 121.75 toks/s, output: 1947.93 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:11<00:03, 10.01it/s, est. speed input: 124.62 toks/s, output: 1993.99 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:11<00:02, 11.19it/s, est. speed input: 129.43 toks/s, output: 2070.88 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:12<00:02, 11.04it/s, est. speed input: 130.56 toks/s, output: 2088.95 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:12<00:02, 11.92it/s, est. speed input: 133.00 toks/s, output: 2128.06 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:12<00:01, 12.09it/s, est. speed input: 134.75 toks/s, output: 2155.98 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:12<00:01, 13.01it/s, est. speed input: 136.85 toks/s, output: 2189.63 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:12<00:01, 14.66it/s, est. speed input: 139.41 toks/s, output: 2230.48 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:13<00:00, 17.30it/s, est. speed input: 142.92 toks/s, output: 2286.69 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:13<00:00, 15.17it/s, est. speed input: 143.56 toks/s, output: 2296.90 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:13<00:00, 17.23it/s, est. speed input: 146.01 toks/s, output: 2336.14 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:13<00:00, 19.34it/s, est. speed input: 148.44 toks/s, output: 2375.06 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00, 19.34it/s, est. speed input: 149.90 toks/s, output: 2398.42 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:13<00:00,  9.37it/s, est. speed input: 149.90 toks/s, output: 2398.42 toks/s]
[rank0]:[W126 11:44:15.347859223 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 92.2s

测试结果:
  Requests/s:   9.33
  Tokens/s:     2538.85
  Total Reqs:   128
  Elapsed:      13.71s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      2389.51

============================================================
[3/4] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:44:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:44:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=599338) WARNING 01-26 11:44:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=599338) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=599338) WARNING 01-26 11:44:56 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.23 requests/s, 2511.17 total tokens/s, 2363.45 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536


─── STDERR ───
[2026-01-26 11:44:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:44:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:44:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:44:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:44:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:44:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:44:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:44:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:44:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:44:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:44:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:44:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:44:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:44:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:44:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:44:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:44:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.36s/it]
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.06it/s]
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
(EngineCore_DP0 pid=599338) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
(EngineCore_DP0 pid=599338) 
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=599338) [2026-01-26 11:44:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=599338) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:22,  1.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:12,  2.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:01<00:09,  3.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:08,  3.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:07,  4.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:07,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:02<00:12,  2.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:03<00:15,  1.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:03<00:13,  2.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:03<00:10,  2.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:04<00:08,  2.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:04<00:07,  3.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:04<00:06,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:04<00:05,  4.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:04<00:05,  4.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:05<00:08,  2.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:06<00:09,  1.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:06<00:07,  2.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:06<00:06,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:07<00:05,  3.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:07<00:04,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:07<00:03,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:07<00:03,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:07<00:02,  4.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:08<00:01,  5.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:08<00:01,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:08<00:01,  5.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:08<00:01,  5.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:09<00:00,  5.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:09<00:00,  5.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:09<00:00,  5.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:09<00:00,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:10<00:00,  2.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  1.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  3.14it/s]
(EngineCore_DP0 pid=599338) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:13,  2.56it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:08,  3.68it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:07,  4.28it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:06,  4.66it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:06,  4.85it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:06,  4.78it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:06,  4.08it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:02<00:08,  3.06it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:08,  3.19it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:03<00:10,  2.42it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:03<00:08,  2.80it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:03<00:07,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:03<00:05,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:03<00:05,  4.08it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:04<00:04,  4.38it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:04<00:04,  4.63it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:04<00:03,  4.57it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:04<00:04,  4.08it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:05<00:05,  3.16it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:05<00:05,  2.97it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:06<00:05,  2.54it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:06<00:04,  2.84it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:06<00:03,  3.28it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:06<00:02,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:07<00:02,  4.04it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:07<00:02,  4.35it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:07<00:01,  4.61it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:07<00:01,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:07<00:01,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:08<00:01,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:08<00:01,  3.39it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:08<00:00,  3.72it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:09<00:00,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:09<00:00,  3.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  3.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  3.60it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2739.44it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:08<35:28,  8.35s/it, est. speed input: 1.92 toks/s, output: 30.68 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:08<00:40,  5.49it/s, est. speed input: 62.44 toks/s, output: 999.01 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:08<00:24,  8.53it/s, est. speed input: 89.23 toks/s, output: 1427.66 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:11<00:27,  7.13it/s, est. speed input: 87.55 toks/s, output: 1400.78 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:11<00:25,  7.48it/s, est. speed input: 91.35 toks/s, output: 1461.64 toks/s]
Processed prompts:  29%|██▊       | 73/256 [00:12<00:24,  7.59it/s, est. speed input: 93.30 toks/s, output: 1492.80 toks/s]
Processed prompts:  30%|███       | 77/256 [00:13<00:23,  7.56it/s, est. speed input: 94.33 toks/s, output: 1509.20 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:13<00:21,  8.21it/s, est. speed input: 96.63 toks/s, output: 1546.00 toks/s]
Processed prompts:  32%|███▏      | 83/256 [00:13<00:21,  7.92it/s, est. speed input: 97.02 toks/s, output: 1552.29 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:13<00:20,  8.52it/s, est. speed input: 98.42 toks/s, output: 1574.79 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:13<00:18,  9.14it/s, est. speed input: 99.72 toks/s, output: 1595.55 toks/s]
Processed prompts:  35%|███▍      | 89/256 [00:14<00:16, 10.08it/s, est. speed input: 101.18 toks/s, output: 1618.93 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:14<00:14, 11.07it/s, est. speed input: 102.60 toks/s, output: 1641.67 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:14<00:18,  8.89it/s, est. speed input: 102.22 toks/s, output: 1635.44 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:14<00:15, 10.28it/s, est. speed input: 103.67 toks/s, output: 1658.66 toks/s]
Processed prompts:  38%|███▊      | 97/256 [00:14<00:13, 11.48it/s, est. speed input: 105.00 toks/s, output: 1680.02 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:14<00:13, 11.77it/s, est. speed input: 106.03 toks/s, output: 1696.46 toks/s]
Processed prompts:  39%|███▉      | 101/256 [00:15<00:12, 12.62it/s, est. speed input: 107.24 toks/s, output: 1715.89 toks/s]
Processed prompts:  40%|████      | 103/256 [00:15<00:10, 13.93it/s, est. speed input: 108.60 toks/s, output: 1737.57 toks/s]
Processed prompts:  41%|████      | 105/256 [00:15<00:13, 11.03it/s, est. speed input: 108.75 toks/s, output: 1739.98 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:15<00:12, 12.04it/s, est. speed input: 110.34 toks/s, output: 1765.37 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:15<00:09, 15.37it/s, est. speed input: 113.25 toks/s, output: 1812.02 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:15<00:08, 15.94it/s, est. speed input: 114.48 toks/s, output: 1831.63 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:16<00:02, 44.04it/s, est. speed input: 135.99 toks/s, output: 2175.84 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:17<00:07, 15.52it/s, est. speed input: 130.79 toks/s, output: 2092.63 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:17<00:09, 12.18it/s, est. speed input: 129.41 toks/s, output: 2070.55 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:18<00:09, 11.18it/s, est. speed input: 129.15 toks/s, output: 2066.34 toks/s]
Processed prompts:  58%|█████▊    | 149/256 [00:18<00:09, 10.89it/s, est. speed input: 129.41 toks/s, output: 2070.54 toks/s]
Processed prompts:  59%|█████▉    | 151/256 [00:18<00:09, 11.22it/s, est. speed input: 130.06 toks/s, output: 2080.98 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:18<00:09, 10.63it/s, est. speed input: 130.19 toks/s, output: 2083.06 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:18<00:08, 11.97it/s, est. speed input: 131.51 toks/s, output: 2104.10 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:19<00:08, 11.26it/s, est. speed input: 131.70 toks/s, output: 2107.22 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:19<00:08, 10.90it/s, est. speed input: 131.98 toks/s, output: 2111.69 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:19<00:08, 10.95it/s, est. speed input: 132.40 toks/s, output: 2118.40 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:19<00:07, 11.87it/s, est. speed input: 133.15 toks/s, output: 2130.45 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:19<00:07, 12.69it/s, est. speed input: 133.90 toks/s, output: 2142.38 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:19<00:06, 14.05it/s, est. speed input: 134.81 toks/s, output: 2156.90 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:20<00:06, 14.28it/s, est. speed input: 135.50 toks/s, output: 2167.96 toks/s]
Processed prompts:  68%|██████▊   | 173/256 [00:20<00:06, 13.78it/s, est. speed input: 136.33 toks/s, output: 2181.23 toks/s]
Processed prompts:  68%|██████▊   | 175/256 [00:20<00:06, 13.13it/s, est. speed input: 136.74 toks/s, output: 2187.91 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:20<00:05, 13.66it/s, est. speed input: 137.43 toks/s, output: 2198.87 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:20<00:05, 13.95it/s, est. speed input: 138.36 toks/s, output: 2213.83 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:20<00:04, 15.06it/s, est. speed input: 139.21 toks/s, output: 2227.42 toks/s]
Processed prompts:  72%|███████▏  | 185/256 [00:21<00:04, 17.26it/s, est. speed input: 140.65 toks/s, output: 2250.33 toks/s]
Processed prompts:  75%|███████▍  | 191/256 [00:21<00:02, 25.43it/s, est. speed input: 144.34 toks/s, output: 2309.37 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:21<00:01, 34.00it/s, est. speed input: 148.76 toks/s, output: 2380.09 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:21<00:01, 43.05it/s, est. speed input: 153.90 toks/s, output: 2462.44 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:22<00:03, 14.90it/s, est. speed input: 151.21 toks/s, output: 2419.39 toks/s]
Processed prompts:  84%|████████▍ | 215/256 [00:23<00:03, 10.41it/s, est. speed input: 149.07 toks/s, output: 2385.06 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:23<00:04,  8.57it/s, est. speed input: 147.37 toks/s, output: 2357.95 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:23<00:04,  8.15it/s, est. speed input: 146.82 toks/s, output: 2349.14 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:24<00:04,  8.35it/s, est. speed input: 146.84 toks/s, output: 2349.51 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:24<00:03,  8.94it/s, est. speed input: 147.16 toks/s, output: 2354.54 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:24<00:03,  9.08it/s, est. speed input: 147.21 toks/s, output: 2355.36 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:24<00:02, 10.30it/s, est. speed input: 147.82 toks/s, output: 2365.10 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:24<00:02, 11.86it/s, est. speed input: 148.67 toks/s, output: 2378.73 toks/s]
Processed prompts:  91%|█████████ | 233/256 [00:24<00:01, 12.49it/s, est. speed input: 149.15 toks/s, output: 2386.42 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:25<00:01, 13.57it/s, est. speed input: 149.76 toks/s, output: 2396.22 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:25<00:01, 13.37it/s, est. speed input: 150.11 toks/s, output: 2401.73 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:25<00:01, 15.07it/s, est. speed input: 151.08 toks/s, output: 2417.22 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:25<00:00, 16.44it/s, est. speed input: 152.06 toks/s, output: 2432.99 toks/s]
Processed prompts:  96%|█████████▌| 245/256 [00:25<00:00, 16.94it/s, est. speed input: 152.67 toks/s, output: 2442.76 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:25<00:00, 15.85it/s, est. speed input: 153.03 toks/s, output: 2448.50 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:25<00:00, 18.02it/s, est. speed input: 154.14 toks/s, output: 2466.22 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:26<00:00, 20.70it/s, est. speed input: 155.37 toks/s, output: 2485.95 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:26<00:00, 22.84it/s, est. speed input: 156.59 toks/s, output: 2505.51 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:26<00:00, 22.84it/s, est. speed input: 156.59 toks/s, output: 2505.51 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:26<00:00,  9.79it/s, est. speed input: 156.59 toks/s, output: 2505.51 toks/s]
[rank0]:[W126 11:46:06.307949403 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 111.2s

测试结果:
  Requests/s:   9.23
  Tokens/s:     2511.17
  Total Reqs:   256
  Elapsed:      27.73s

  [Decode 分析]
  Total Decode Tokens:  65536
  Decode Tokens/s:      2363.45

============================================================
[4/4] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:46:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:46:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=601092) WARNING 01-26 11:46:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=601092) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=601092) WARNING 01-26 11:46:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.66 requests/s, 1540.25 total tokens/s, 1449.65 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072


─── STDERR ───
[2026-01-26 11:46:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:46:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:46:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:46:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:46:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:46:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:46:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:46:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:46:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:46:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:46:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:46:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:46:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:46:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:46:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:46:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:46:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.27s/it]
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.29s/it]
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.12it/s]
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.04s/it]
(EngineCore_DP0 pid=601092) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.06s/it]
(EngineCore_DP0 pid=601092) 
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=601092) [2026-01-26 11:46:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=601092) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:01<01:01,  1.23s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:01<00:30,  1.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:01<00:20,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:01<00:15,  2.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:02<00:13,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:02<00:11,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:02<00:10,  4.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:02<00:11,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:03<00:17,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:04<00:21,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:04<00:18,  2.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:04<00:14,  2.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:04<00:12,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:05<00:10,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:05<00:09,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:05<00:08,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:05<00:09,  3.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:06<00:13,  2.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:07<00:16,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:07<00:14,  2.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:07<00:11,  2.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:08<00:09,  3.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:08<00:08,  3.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:08<00:07,  3.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:08<00:06,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:09<00:07,  3.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:09<00:09,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:10<00:12,  1.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:10<00:09,  2.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:11<00:07,  2.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:11<00:06,  3.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:11<00:05,  3.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:11<00:04,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:11<00:04,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:12<00:04,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:12<00:06,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:13<00:07,  1.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:13<00:05,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:14<00:04,  2.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:14<00:03,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:14<00:02,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:14<00:02,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:14<00:01,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:15<00:01,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:16<00:02,  2.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:16<00:02,  1.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:17<00:01,  2.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:17<00:01,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:17<00:00,  3.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:17<00:00,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:17<00:00,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:17<00:00,  2.85it/s]
(EngineCore_DP0 pid=601092) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:29,  1.67it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:01<00:29,  1.66it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:01<00:21,  2.20it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:04,  8.74it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:02<00:05,  7.26it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:02<00:08,  4.75it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:03<00:08,  4.45it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:03<00:10,  3.39it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:04<00:10,  3.40it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:04<00:09,  3.69it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:04<00:08,  3.97it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:04<00:07,  4.24it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:04<00:06,  4.48it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:04<00:06,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:05<00:06,  4.54it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:05<00:06,  4.07it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:06<00:08,  3.09it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:06<00:07,  3.32it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:06<00:09,  2.51it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:07<00:08,  2.84it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:07<00:07,  3.28it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:07<00:05,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:07<00:05,  4.08it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:07<00:04,  4.37it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:08<00:04,  4.58it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:08<00:03,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:08<00:04,  4.02it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:09<00:05,  3.12it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:09<00:04,  3.37it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:10<00:05,  2.49it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:10<00:04,  2.72it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:10<00:03,  3.17it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:10<00:03,  3.61it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:10<00:02,  4.00it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:11<00:02,  4.29it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:11<00:01,  4.53it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:11<00:01,  4.58it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:11<00:01,  4.27it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:12<00:01,  3.04it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:12<00:01,  3.14it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:13<00:01,  2.89it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:13<00:00,  3.08it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:13<00:00,  3.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:13<00:00,  3.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:13<00:00,  3.74it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  53%|█████▎    | 273/512 [00:00<00:00, 2724.81it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2760.30it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:06<52:33,  6.17s/it, est. speed input: 2.59 toks/s, output: 41.48 toks/s]
Processed prompts:   4%|▍         | 21/512 [00:06<01:58,  4.15it/s, est. speed input: 49.15 toks/s, output: 786.33 toks/s]
Processed prompts:   4%|▍         | 23/512 [00:07<01:56,  4.20it/s, est. speed input: 50.61 toks/s, output: 809.74 toks/s]
Processed prompts:   5%|▍         | 25/512 [00:07<01:52,  4.32it/s, est. speed input: 52.21 toks/s, output: 835.40 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:08<02:00,  4.02it/s, est. speed input: 51.53 toks/s, output: 824.54 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:08<01:56,  4.17it/s, est. speed input: 52.79 toks/s, output: 844.63 toks/s]
Processed prompts:   6%|▌         | 30/512 [00:08<01:51,  4.31it/s, est. speed input: 53.94 toks/s, output: 863.09 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:09<01:38,  4.86it/s, est. speed input: 56.42 toks/s, output: 902.69 toks/s]
Processed prompts:   7%|▋         | 36/512 [00:09<01:28,  5.36it/s, est. speed input: 58.79 toks/s, output: 940.63 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:10<01:13,  6.41it/s, est. speed input: 62.61 toks/s, output: 1001.69 toks/s]
Processed prompts:   9%|▊         | 44/512 [00:10<00:53,  8.80it/s, est. speed input: 67.91 toks/s, output: 1086.61 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:10<00:59,  7.84it/s, est. speed input: 68.58 toks/s, output: 1097.24 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:11<00:51,  8.97it/s, est. speed input: 73.00 toks/s, output: 1168.07 toks/s]
Processed prompts:  10%|█         | 53/512 [00:11<01:06,  6.93it/s, est. speed input: 72.23 toks/s, output: 1155.64 toks/s]
Processed prompts:  11%|█         | 54/512 [00:12<01:20,  5.71it/s, est. speed input: 71.17 toks/s, output: 1138.68 toks/s]
Processed prompts:  11%|█         | 55/512 [00:12<01:40,  4.53it/s, est. speed input: 69.70 toks/s, output: 1115.22 toks/s]
Processed prompts:  11%|█         | 56/512 [00:12<01:52,  4.04it/s, est. speed input: 68.93 toks/s, output: 1102.89 toks/s]
Processed prompts:  11%|█         | 57/512 [00:13<01:49,  4.17it/s, est. speed input: 69.05 toks/s, output: 1104.78 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:13<01:47,  4.23it/s, est. speed input: 69.08 toks/s, output: 1105.29 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:13<02:20,  3.23it/s, est. speed input: 67.56 toks/s, output: 1080.94 toks/s]
Processed prompts:  12%|█▏        | 61/512 [00:14<01:32,  4.89it/s, est. speed input: 69.34 toks/s, output: 1109.43 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:14<01:25,  5.25it/s, est. speed input: 69.77 toks/s, output: 1116.27 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:14<01:27,  5.15it/s, est. speed input: 69.89 toks/s, output: 1118.18 toks/s]
Processed prompts:  13%|█▎        | 65/512 [00:14<01:04,  6.90it/s, est. speed input: 71.37 toks/s, output: 1141.91 toks/s]
Processed prompts:  13%|█▎        | 68/512 [00:14<00:42, 10.50it/s, est. speed input: 74.07 toks/s, output: 1185.17 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:14<00:40, 10.95it/s, est. speed input: 75.41 toks/s, output: 1206.48 toks/s]
Processed prompts:  14%|█▍        | 72/512 [00:15<01:06,  6.57it/s, est. speed input: 74.64 toks/s, output: 1194.23 toks/s]
Processed prompts:  15%|█▌        | 79/512 [00:15<00:31, 13.72it/s, est. speed input: 81.12 toks/s, output: 1297.99 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:16<00:41, 10.37it/s, est. speed input: 81.68 toks/s, output: 1306.95 toks/s]
Processed prompts:  17%|█▋        | 85/512 [00:16<00:37, 11.52it/s, est. speed input: 83.71 toks/s, output: 1339.29 toks/s]
Processed prompts:  17%|█▋        | 87/512 [00:16<00:54,  7.84it/s, est. speed input: 82.81 toks/s, output: 1325.00 toks/s]
Processed prompts:  17%|█▋        | 89/512 [00:17<01:17,  5.43it/s, est. speed input: 81.12 toks/s, output: 1297.89 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:17<01:13,  5.70it/s, est. speed input: 81.46 toks/s, output: 1303.39 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:17<01:14,  5.62it/s, est. speed input: 81.49 toks/s, output: 1303.78 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:18<01:03,  6.59it/s, est. speed input: 82.38 toks/s, output: 1318.09 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:18<01:02,  6.64it/s, est. speed input: 82.60 toks/s, output: 1321.63 toks/s]
Processed prompts:  19%|█▉        | 96/512 [00:18<00:57,  7.24it/s, est. speed input: 83.31 toks/s, output: 1332.91 toks/s]
Processed prompts:  19%|█▉        | 97/512 [00:18<00:57,  7.17it/s, est. speed input: 83.52 toks/s, output: 1336.33 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:18<00:46,  8.85it/s, est. speed input: 84.63 toks/s, output: 1354.13 toks/s]
Processed prompts:  20%|█▉        | 101/512 [00:18<00:37, 10.86it/s, est. speed input: 85.87 toks/s, output: 1373.89 toks/s]
Processed prompts:  20%|██        | 103/512 [00:19<00:40, 10.11it/s, est. speed input: 86.53 toks/s, output: 1384.47 toks/s]
Processed prompts:  21%|██        | 105/512 [00:19<00:38, 10.50it/s, est. speed input: 87.41 toks/s, output: 1398.55 toks/s]
Processed prompts:  21%|██        | 107/512 [00:19<00:38, 10.51it/s, est. speed input: 88.20 toks/s, output: 1411.24 toks/s]
Processed prompts:  21%|██▏       | 109/512 [00:19<00:38, 10.60it/s, est. speed input: 89.00 toks/s, output: 1424.04 toks/s]
Processed prompts:  22%|██▏       | 112/512 [00:19<00:32, 12.13it/s, est. speed input: 90.56 toks/s, output: 1448.94 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:20<00:58,  6.79it/s, est. speed input: 89.31 toks/s, output: 1428.90 toks/s]
Processed prompts:  22%|██▏       | 115/512 [00:21<01:31,  4.35it/s, est. speed input: 87.31 toks/s, output: 1396.89 toks/s]
Processed prompts:  23%|██▎       | 116/512 [00:21<01:49,  3.61it/s, est. speed input: 86.11 toks/s, output: 1377.82 toks/s]
Processed prompts:  23%|██▎       | 117/512 [00:21<01:51,  3.55it/s, est. speed input: 85.66 toks/s, output: 1370.62 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:22<02:09,  3.05it/s, est. speed input: 84.55 toks/s, output: 1352.78 toks/s]
Processed prompts:  23%|██▎       | 119/512 [00:22<02:05,  3.12it/s, est. speed input: 84.14 toks/s, output: 1346.18 toks/s]
Processed prompts:  24%|██▎       | 121/512 [00:22<01:32,  4.23it/s, est. speed input: 84.66 toks/s, output: 1354.56 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:23<01:27,  4.47it/s, est. speed input: 84.69 toks/s, output: 1355.02 toks/s]
Processed prompts:  24%|██▍       | 123/512 [00:23<01:23,  4.68it/s, est. speed input: 84.71 toks/s, output: 1355.43 toks/s]
Processed prompts:  24%|██▍       | 124/512 [00:23<01:13,  5.28it/s, est. speed input: 84.96 toks/s, output: 1359.40 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:23<00:56,  6.89it/s, est. speed input: 85.70 toks/s, output: 1371.22 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:23<00:51,  7.43it/s, est. speed input: 86.02 toks/s, output: 1376.24 toks/s]
Processed prompts:  25%|██▌       | 128/512 [00:23<00:50,  7.59it/s, est. speed input: 86.24 toks/s, output: 1379.88 toks/s]
Processed prompts:  25%|██▌       | 129/512 [00:23<00:53,  7.18it/s, est. speed input: 86.33 toks/s, output: 1381.32 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:24<00:34, 11.09it/s, est. speed input: 87.83 toks/s, output: 1405.22 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:24<00:30, 12.60it/s, est. speed input: 88.73 toks/s, output: 1419.67 toks/s]
Processed prompts:  27%|██▋       | 136/512 [00:24<00:31, 12.06it/s, est. speed input: 89.39 toks/s, output: 1430.17 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:24<00:34, 10.72it/s, est. speed input: 89.85 toks/s, output: 1437.55 toks/s]
Processed prompts:  27%|██▋       | 140/512 [00:24<00:33, 11.14it/s, est. speed input: 90.54 toks/s, output: 1448.70 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:24<00:29, 12.42it/s, est. speed input: 91.40 toks/s, output: 1462.34 toks/s]
Processed prompts:  28%|██▊       | 144/512 [00:25<01:02,  5.88it/s, est. speed input: 89.98 toks/s, output: 1439.64 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:26<01:40,  3.64it/s, est. speed input: 87.71 toks/s, output: 1403.34 toks/s]
Processed prompts:  29%|██▊       | 147/512 [00:27<01:48,  3.38it/s, est. speed input: 87.02 toks/s, output: 1392.27 toks/s]
Processed prompts:  29%|██▉       | 148/512 [00:27<01:51,  3.27it/s, est. speed input: 86.51 toks/s, output: 1384.17 toks/s]
Processed prompts:  29%|██▉       | 149/512 [00:27<01:47,  3.38it/s, est. speed input: 86.27 toks/s, output: 1380.25 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:27<01:35,  3.77it/s, est. speed input: 86.32 toks/s, output: 1381.07 toks/s]
Processed prompts:  29%|██▉       | 151/512 [00:27<01:26,  4.19it/s, est. speed input: 86.39 toks/s, output: 1382.26 toks/s]
Processed prompts:  30%|██▉       | 152/512 [00:28<01:21,  4.43it/s, est. speed input: 86.37 toks/s, output: 1381.98 toks/s]
Processed prompts:  30%|██▉       | 153/512 [00:28<01:12,  4.92it/s, est. speed input: 86.50 toks/s, output: 1383.96 toks/s]
Processed prompts:  30%|███       | 154/512 [00:28<01:08,  5.23it/s, est. speed input: 86.57 toks/s, output: 1385.12 toks/s]
Processed prompts:  30%|███       | 155/512 [00:28<01:05,  5.46it/s, est. speed input: 86.64 toks/s, output: 1386.18 toks/s]
Processed prompts:  30%|███       | 156/512 [00:28<01:05,  5.46it/s, est. speed input: 86.64 toks/s, output: 1386.25 toks/s]
Processed prompts:  31%|███       | 157/512 [00:28<01:01,  5.81it/s, est. speed input: 86.76 toks/s, output: 1388.10 toks/s]
Processed prompts:  31%|███       | 158/512 [00:29<01:03,  5.62it/s, est. speed input: 86.73 toks/s, output: 1387.75 toks/s]
Processed prompts:  31%|███▏      | 160/512 [00:29<00:49,  7.08it/s, est. speed input: 87.25 toks/s, output: 1395.95 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:29<00:39,  8.89it/s, est. speed input: 87.93 toks/s, output: 1406.84 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:29<00:33, 10.33it/s, est. speed input: 88.60 toks/s, output: 1417.56 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:29<00:25, 13.62it/s, est. speed input: 89.82 toks/s, output: 1437.20 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:29<00:23, 14.67it/s, est. speed input: 90.56 toks/s, output: 1449.01 toks/s]
Processed prompts:  33%|███▎      | 171/512 [00:29<00:22, 15.00it/s, est. speed input: 91.25 toks/s, output: 1459.98 toks/s]
Processed prompts:  34%|███▍      | 173/512 [00:30<00:23, 14.39it/s, est. speed input: 91.85 toks/s, output: 1469.58 toks/s]
Processed prompts:  34%|███▍      | 175/512 [00:30<00:48,  6.88it/s, est. speed input: 90.95 toks/s, output: 1455.25 toks/s]
Processed prompts:  35%|███▍      | 177/512 [00:32<01:37,  3.43it/s, est. speed input: 88.35 toks/s, output: 1413.52 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:32<01:43,  3.22it/s, est. speed input: 87.76 toks/s, output: 1404.11 toks/s]
Processed prompts:  35%|███▍      | 179/512 [00:32<01:33,  3.55it/s, est. speed input: 87.79 toks/s, output: 1404.64 toks/s]
Processed prompts:  35%|███▌      | 180/512 [00:32<01:33,  3.57it/s, est. speed input: 87.54 toks/s, output: 1400.69 toks/s]
Processed prompts:  35%|███▌      | 181/512 [00:33<01:31,  3.63it/s, est. speed input: 87.34 toks/s, output: 1397.48 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:33<01:37,  3.40it/s, est. speed input: 86.91 toks/s, output: 1390.56 toks/s]
Processed prompts:  36%|███▌      | 183/512 [00:33<01:31,  3.59it/s, est. speed input: 86.78 toks/s, output: 1388.44 toks/s]
Processed prompts:  36%|███▌      | 184/512 [00:33<01:20,  4.07it/s, est. speed input: 86.84 toks/s, output: 1389.41 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:34<01:12,  4.51it/s, est. speed input: 86.90 toks/s, output: 1390.38 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:34<00:54,  5.96it/s, est. speed input: 87.32 toks/s, output: 1397.10 toks/s]
Processed prompts:  37%|███▋      | 188/512 [00:34<00:52,  6.14it/s, est. speed input: 87.41 toks/s, output: 1398.54 toks/s]
Processed prompts:  37%|███▋      | 189/512 [00:34<00:54,  5.96it/s, est. speed input: 87.41 toks/s, output: 1398.58 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:34<00:52,  6.18it/s, est. speed input: 87.51 toks/s, output: 1400.08 toks/s]
Processed prompts:  38%|███▊      | 192/512 [00:34<00:37,  8.58it/s, est. speed input: 88.14 toks/s, output: 1410.17 toks/s]
Processed prompts:  38%|███▊      | 193/512 [00:34<00:37,  8.43it/s, est. speed input: 88.28 toks/s, output: 1412.42 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:35<00:32,  9.86it/s, est. speed input: 88.81 toks/s, output: 1420.88 toks/s]
Processed prompts:  38%|███▊      | 197/512 [00:35<00:29, 10.65it/s, est. speed input: 89.31 toks/s, output: 1428.89 toks/s]
Processed prompts:  39%|███▉      | 199/512 [00:35<00:29, 10.48it/s, est. speed input: 89.71 toks/s, output: 1435.40 toks/s]
Processed prompts:  39%|███▉      | 201/512 [00:35<00:27, 11.49it/s, est. speed input: 90.26 toks/s, output: 1444.13 toks/s]
Processed prompts:  40%|███▉      | 203/512 [00:35<00:29, 10.46it/s, est. speed input: 90.58 toks/s, output: 1449.24 toks/s]
Processed prompts:  40%|████      | 206/512 [00:35<00:21, 14.02it/s, est. speed input: 91.64 toks/s, output: 1466.26 toks/s]
Processed prompts:  41%|████      | 208/512 [00:37<01:05,  4.65it/s, est. speed input: 89.61 toks/s, output: 1433.72 toks/s]
Processed prompts:  41%|████      | 210/512 [00:38<01:26,  3.47it/s, est. speed input: 88.23 toks/s, output: 1411.70 toks/s]
Processed prompts:  41%|████      | 211/512 [00:38<01:23,  3.63it/s, est. speed input: 88.15 toks/s, output: 1410.45 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:38<01:19,  3.79it/s, est. speed input: 88.08 toks/s, output: 1409.23 toks/s]
Processed prompts:  42%|████▏     | 213/512 [00:38<01:15,  3.95it/s, est. speed input: 88.00 toks/s, output: 1408.06 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:38<01:09,  4.28it/s, est. speed input: 88.03 toks/s, output: 1408.47 toks/s]
Processed prompts:  42%|████▏     | 215/512 [00:39<01:07,  4.37it/s, est. speed input: 87.95 toks/s, output: 1407.28 toks/s]
Processed prompts:  42%|████▏     | 216/512 [00:39<01:09,  4.24it/s, est. speed input: 87.79 toks/s, output: 1404.64 toks/s]
Processed prompts:  42%|████▏     | 217/512 [00:39<01:00,  4.88it/s, est. speed input: 87.92 toks/s, output: 1406.75 toks/s]
Processed prompts:  43%|████▎     | 219/512 [00:39<00:45,  6.48it/s, est. speed input: 88.33 toks/s, output: 1413.28 toks/s]
Processed prompts:  43%|████▎     | 221/512 [00:39<00:41,  7.06it/s, est. speed input: 88.59 toks/s, output: 1417.50 toks/s]
Processed prompts:  44%|████▎     | 223/512 [00:40<00:38,  7.57it/s, est. speed input: 88.88 toks/s, output: 1422.14 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:40<00:27, 10.40it/s, est. speed input: 89.75 toks/s, output: 1436.03 toks/s]
Processed prompts:  45%|████▍     | 228/512 [00:40<00:25, 11.35it/s, est. speed input: 90.24 toks/s, output: 1443.83 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:40<00:25, 11.11it/s, est. speed input: 90.61 toks/s, output: 1449.70 toks/s]
Processed prompts:  45%|████▌     | 232/512 [00:40<00:26, 10.69it/s, est. speed input: 90.94 toks/s, output: 1455.00 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:40<00:25, 11.03it/s, est. speed input: 91.35 toks/s, output: 1461.53 toks/s]
Processed prompts:  46%|████▋     | 237/512 [00:41<00:24, 11.45it/s, est. speed input: 91.97 toks/s, output: 1471.44 toks/s]
Processed prompts:  47%|████▋     | 239/512 [00:42<01:08,  3.98it/s, est. speed input: 89.72 toks/s, output: 1435.50 toks/s]
Processed prompts:  47%|████▋     | 240/512 [00:43<01:18,  3.45it/s, est. speed input: 89.07 toks/s, output: 1425.14 toks/s]
Processed prompts:  47%|████▋     | 241/512 [00:43<01:20,  3.37it/s, est. speed input: 88.77 toks/s, output: 1420.36 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:43<01:17,  3.47it/s, est. speed input: 88.62 toks/s, output: 1417.92 toks/s]
Processed prompts:  47%|████▋     | 243/512 [00:43<01:08,  3.93it/s, est. speed input: 88.69 toks/s, output: 1419.08 toks/s]
Processed prompts:  48%|████▊     | 244/512 [00:44<01:08,  3.90it/s, est. speed input: 88.53 toks/s, output: 1416.47 toks/s]
Processed prompts:  48%|████▊     | 245/512 [00:44<01:03,  4.18it/s, est. speed input: 88.51 toks/s, output: 1416.12 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:44<00:55,  4.82it/s, est. speed input: 88.62 toks/s, output: 1417.98 toks/s]
Processed prompts:  48%|████▊     | 247/512 [00:44<00:53,  5.00it/s, est. speed input: 88.62 toks/s, output: 1417.96 toks/s]
Processed prompts:  48%|████▊     | 248/512 [00:44<00:49,  5.29it/s, est. speed input: 88.66 toks/s, output: 1418.58 toks/s]
Processed prompts:  49%|████▊     | 249/512 [00:44<00:46,  5.68it/s, est. speed input: 88.73 toks/s, output: 1419.72 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:45<00:42,  6.22it/s, est. speed input: 88.84 toks/s, output: 1421.49 toks/s]
Processed prompts:  49%|████▉     | 252/512 [00:45<00:39,  6.64it/s, est. speed input: 89.01 toks/s, output: 1424.10 toks/s]
Processed prompts:  49%|████▉     | 253/512 [00:45<00:42,  6.11it/s, est. speed input: 88.96 toks/s, output: 1423.34 toks/s]
Processed prompts:  50%|████▉     | 255/512 [00:45<00:37,  6.78it/s, est. speed input: 89.17 toks/s, output: 1426.79 toks/s]
Processed prompts:  50%|█████     | 257/512 [00:45<00:29,  8.58it/s, est. speed input: 89.62 toks/s, output: 1433.97 toks/s]
Processed prompts:  51%|█████     | 259/512 [00:46<00:24, 10.15it/s, est. speed input: 90.07 toks/s, output: 1441.07 toks/s]
Processed prompts:  51%|█████     | 261/512 [00:46<00:22, 11.21it/s, est. speed input: 90.49 toks/s, output: 1447.78 toks/s]
Processed prompts:  51%|█████▏    | 263/512 [00:46<00:19, 12.54it/s, est. speed input: 90.94 toks/s, output: 1455.11 toks/s]
Processed prompts:  52%|█████▏    | 265/512 [00:46<00:19, 12.97it/s, est. speed input: 91.35 toks/s, output: 1461.66 toks/s]
Processed prompts:  52%|█████▏    | 268/512 [00:46<00:16, 14.82it/s, est. speed input: 92.07 toks/s, output: 1473.15 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:47<00:49,  4.90it/s, est. speed input: 90.58 toks/s, output: 1449.26 toks/s]
Processed prompts:  54%|█████▎    | 275/512 [00:47<00:29,  8.11it/s, est. speed input: 91.85 toks/s, output: 1469.68 toks/s]
Processed prompts:  54%|█████▍    | 277/512 [00:48<00:28,  8.28it/s, est. speed input: 92.09 toks/s, output: 1473.50 toks/s]
Processed prompts:  54%|█████▍    | 279/512 [00:48<00:35,  6.49it/s, est. speed input: 91.77 toks/s, output: 1468.27 toks/s]
Processed prompts:  55%|█████▍    | 281/512 [00:49<00:37,  6.23it/s, est. speed input: 91.75 toks/s, output: 1467.99 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:49<00:36,  6.30it/s, est. speed input: 91.80 toks/s, output: 1468.77 toks/s]
Processed prompts:  55%|█████▌    | 283/512 [00:49<00:37,  6.14it/s, est. speed input: 91.78 toks/s, output: 1468.54 toks/s]
Processed prompts:  55%|█████▌    | 284/512 [00:49<00:37,  6.09it/s, est. speed input: 91.79 toks/s, output: 1468.69 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:49<00:29,  7.54it/s, est. speed input: 92.15 toks/s, output: 1474.33 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:49<00:24,  9.21it/s, est. speed input: 92.56 toks/s, output: 1480.88 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:50<00:24,  8.96it/s, est. speed input: 92.76 toks/s, output: 1484.14 toks/s]
Processed prompts:  57%|█████▋    | 292/512 [00:50<00:20, 10.58it/s, est. speed input: 93.18 toks/s, output: 1490.91 toks/s]
Processed prompts:  58%|█████▊    | 295/512 [00:50<00:16, 13.02it/s, est. speed input: 93.85 toks/s, output: 1501.64 toks/s]
Processed prompts:  58%|█████▊    | 297/512 [00:50<00:14, 14.42it/s, est. speed input: 94.30 toks/s, output: 1508.82 toks/s]
Processed prompts:  58%|█████▊    | 299/512 [00:50<00:15, 14.14it/s, est. speed input: 94.66 toks/s, output: 1514.52 toks/s]
Processed prompts:  59%|█████▉    | 301/512 [00:50<00:20, 10.15it/s, est. speed input: 94.67 toks/s, output: 1514.65 toks/s]
Processed prompts:  59%|█████▉    | 303/512 [00:51<00:45,  4.62it/s, est. speed input: 93.45 toks/s, output: 1495.28 toks/s]
Processed prompts:  59%|█████▉    | 304/512 [00:52<00:58,  3.59it/s, est. speed input: 92.73 toks/s, output: 1483.66 toks/s]
Processed prompts:  60%|█████▉    | 305/512 [00:53<01:13,  2.81it/s, est. speed input: 91.87 toks/s, output: 1469.86 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:53<01:08,  2.99it/s, est. speed input: 91.72 toks/s, output: 1467.52 toks/s]
Processed prompts:  60%|█████▉    | 307/512 [00:53<01:05,  3.11it/s, est. speed input: 91.54 toks/s, output: 1464.59 toks/s]
Processed prompts:  60%|██████    | 308/512 [00:53<01:01,  3.32it/s, est. speed input: 91.43 toks/s, output: 1462.82 toks/s]
Processed prompts:  60%|██████    | 309/512 [00:54<01:02,  3.25it/s, est. speed input: 91.17 toks/s, output: 1458.73 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:54<00:50,  3.99it/s, est. speed input: 91.30 toks/s, output: 1460.75 toks/s]
Processed prompts:  61%|██████    | 311/512 [00:54<00:45,  4.42it/s, est. speed input: 91.31 toks/s, output: 1461.01 toks/s]
Processed prompts:  61%|██████    | 313/512 [00:54<00:37,  5.33it/s, est. speed input: 91.43 toks/s, output: 1462.92 toks/s]
Processed prompts:  62%|██████▏   | 315/512 [00:54<00:27,  7.12it/s, est. speed input: 91.79 toks/s, output: 1468.70 toks/s]
Processed prompts:  62%|██████▏   | 317/512 [00:55<00:23,  8.15it/s, est. speed input: 92.07 toks/s, output: 1473.15 toks/s]
Processed prompts:  62%|██████▏   | 319/512 [00:55<00:21,  9.08it/s, est. speed input: 92.37 toks/s, output: 1477.85 toks/s]
Processed prompts:  63%|██████▎   | 321/512 [00:55<00:17, 10.94it/s, est. speed input: 92.77 toks/s, output: 1484.29 toks/s]
Processed prompts:  63%|██████▎   | 323/512 [00:55<00:17, 10.50it/s, est. speed input: 93.00 toks/s, output: 1487.97 toks/s]
Processed prompts:  63%|██████▎   | 325/512 [00:55<00:17, 10.62it/s, est. speed input: 93.27 toks/s, output: 1492.25 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:55<00:16, 11.01it/s, est. speed input: 93.56 toks/s, output: 1496.96 toks/s]
Processed prompts:  64%|██████▍   | 329/512 [00:56<00:15, 11.95it/s, est. speed input: 93.91 toks/s, output: 1502.50 toks/s]
Processed prompts:  65%|██████▍   | 332/512 [00:56<00:13, 12.99it/s, est. speed input: 94.42 toks/s, output: 1510.80 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:57<00:45,  3.94it/s, est. speed input: 92.61 toks/s, output: 1481.84 toks/s]
Processed prompts:  65%|██████▌   | 335/512 [00:58<00:46,  3.82it/s, est. speed input: 92.41 toks/s, output: 1478.52 toks/s]
Processed prompts:  66%|██████▌   | 336/512 [00:58<00:45,  3.89it/s, est. speed input: 92.31 toks/s, output: 1476.88 toks/s]
Processed prompts:  66%|██████▌   | 337/512 [00:58<00:48,  3.63it/s, est. speed input: 92.04 toks/s, output: 1472.59 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:58<00:45,  3.83it/s, est. speed input: 91.98 toks/s, output: 1471.60 toks/s]
Processed prompts:  66%|██████▌   | 339/512 [00:58<00:40,  4.31it/s, est. speed input: 92.02 toks/s, output: 1472.33 toks/s]
Processed prompts:  66%|██████▋   | 340/512 [00:59<00:37,  4.55it/s, est. speed input: 92.00 toks/s, output: 1472.06 toks/s]
Processed prompts:  67%|██████▋   | 341/512 [00:59<00:33,  5.17it/s, est. speed input: 92.08 toks/s, output: 1473.32 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:59<00:30,  5.57it/s, est. speed input: 92.13 toks/s, output: 1474.04 toks/s]
Processed prompts:  67%|██████▋   | 343/512 [00:59<00:27,  6.10it/s, est. speed input: 92.20 toks/s, output: 1475.24 toks/s]
Processed prompts:  67%|██████▋   | 344/512 [00:59<00:30,  5.47it/s, est. speed input: 92.12 toks/s, output: 1473.86 toks/s]
Processed prompts:  67%|██████▋   | 345/512 [00:59<00:29,  5.60it/s, est. speed input: 92.12 toks/s, output: 1473.99 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [01:00<00:25,  6.42it/s, est. speed input: 92.24 toks/s, output: 1475.78 toks/s]
Processed prompts:  68%|██████▊   | 347/512 [01:00<00:24,  6.63it/s, est. speed input: 92.29 toks/s, output: 1476.62 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [01:00<00:24,  6.79it/s, est. speed input: 92.34 toks/s, output: 1477.46 toks/s]
Processed prompts:  68%|██████▊   | 349/512 [01:00<00:24,  6.79it/s, est. speed input: 92.38 toks/s, output: 1478.09 toks/s]
Processed prompts:  69%|██████▊   | 351/512 [01:00<00:17,  9.19it/s, est. speed input: 92.71 toks/s, output: 1483.44 toks/s]
Processed prompts:  69%|██████▉   | 353/512 [01:00<00:16,  9.39it/s, est. speed input: 92.93 toks/s, output: 1486.84 toks/s]
Processed prompts:  69%|██████▉   | 355/512 [01:01<00:17,  8.97it/s, est. speed input: 93.09 toks/s, output: 1489.37 toks/s]
Processed prompts:  70%|██████▉   | 357/512 [01:01<00:15,  9.86it/s, est. speed input: 93.36 toks/s, output: 1493.75 toks/s]
Processed prompts:  70%|███████   | 359/512 [01:01<00:13, 11.62it/s, est. speed input: 93.72 toks/s, output: 1499.44 toks/s]
Processed prompts:  71%|███████   | 362/512 [01:01<00:10, 13.73it/s, est. speed input: 94.25 toks/s, output: 1507.99 toks/s]
Processed prompts:  71%|███████   | 364/512 [01:02<00:19,  7.46it/s, est. speed input: 93.88 toks/s, output: 1502.14 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [01:03<00:39,  3.67it/s, est. speed input: 92.56 toks/s, output: 1481.02 toks/s]
Processed prompts:  72%|███████▏  | 367/512 [01:03<00:42,  3.45it/s, est. speed input: 92.27 toks/s, output: 1476.32 toks/s]
Processed prompts:  72%|███████▏  | 368/512 [01:03<00:40,  3.58it/s, est. speed input: 92.18 toks/s, output: 1474.85 toks/s]
Processed prompts:  72%|███████▏  | 369/512 [01:04<00:36,  3.94it/s, est. speed input: 92.20 toks/s, output: 1475.12 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [01:04<00:37,  3.79it/s, est. speed input: 92.02 toks/s, output: 1472.31 toks/s]
Processed prompts:  72%|███████▏  | 371/512 [01:04<00:35,  3.98it/s, est. speed input: 91.96 toks/s, output: 1471.41 toks/s]
Processed prompts:  73%|███████▎  | 372/512 [01:04<00:37,  3.77it/s, est. speed input: 91.78 toks/s, output: 1468.46 toks/s]
Processed prompts:  73%|███████▎  | 373/512 [01:05<00:33,  4.19it/s, est. speed input: 91.79 toks/s, output: 1468.60 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [01:05<00:30,  4.57it/s, est. speed input: 91.80 toks/s, output: 1468.73 toks/s]
Processed prompts:  73%|███████▎  | 375/512 [01:05<00:27,  5.04it/s, est. speed input: 91.83 toks/s, output: 1469.30 toks/s]
Processed prompts:  73%|███████▎  | 376/512 [01:05<00:23,  5.67it/s, est. speed input: 91.90 toks/s, output: 1470.47 toks/s]
Processed prompts:  74%|███████▎  | 377/512 [01:05<00:23,  5.83it/s, est. speed input: 91.92 toks/s, output: 1470.79 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [01:05<00:22,  5.85it/s, est. speed input: 91.93 toks/s, output: 1470.90 toks/s]
Processed prompts:  74%|███████▍  | 379/512 [01:05<00:21,  6.10it/s, est. speed input: 91.97 toks/s, output: 1471.49 toks/s]
Processed prompts:  74%|███████▍  | 380/512 [01:06<00:19,  6.89it/s, est. speed input: 92.07 toks/s, output: 1473.11 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [01:06<00:13,  9.73it/s, est. speed input: 92.41 toks/s, output: 1478.50 toks/s]
Processed prompts:  75%|███████▌  | 384/512 [01:06<00:11, 10.87it/s, est. speed input: 92.68 toks/s, output: 1482.85 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [01:06<00:11, 11.33it/s, est. speed input: 92.93 toks/s, output: 1486.91 toks/s]
Processed prompts:  76%|███████▌  | 389/512 [01:06<00:09, 13.23it/s, est. speed input: 93.40 toks/s, output: 1494.47 toks/s]
Processed prompts:  76%|███████▋  | 391/512 [01:06<00:08, 14.35it/s, est. speed input: 93.73 toks/s, output: 1499.65 toks/s]
Processed prompts:  77%|███████▋  | 393/512 [01:06<00:08, 13.23it/s, est. speed input: 93.96 toks/s, output: 1503.29 toks/s]
Processed prompts:  77%|███████▋  | 396/512 [01:07<00:11,  9.80it/s, est. speed input: 94.07 toks/s, output: 1505.06 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [01:09<00:34,  3.30it/s, est. speed input: 92.22 toks/s, output: 1475.52 toks/s]
Processed prompts:  78%|███████▊  | 399/512 [01:09<00:35,  3.18it/s, est. speed input: 91.96 toks/s, output: 1471.29 toks/s]
Processed prompts:  78%|███████▊  | 400/512 [01:09<00:32,  3.43it/s, est. speed input: 91.93 toks/s, output: 1470.88 toks/s]
Processed prompts:  78%|███████▊  | 401/512 [01:09<00:32,  3.41it/s, est. speed input: 91.76 toks/s, output: 1468.23 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [01:10<00:31,  3.51it/s, est. speed input: 91.66 toks/s, output: 1466.50 toks/s]
Processed prompts:  79%|███████▊  | 403/512 [01:10<00:31,  3.41it/s, est. speed input: 91.47 toks/s, output: 1463.49 toks/s]
Processed prompts:  79%|███████▉  | 404/512 [01:10<00:29,  3.61it/s, est. speed input: 91.40 toks/s, output: 1462.32 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [01:10<00:22,  4.78it/s, est. speed input: 91.54 toks/s, output: 1464.66 toks/s]
Processed prompts:  79%|███████▉  | 407/512 [01:11<00:21,  4.81it/s, est. speed input: 91.50 toks/s, output: 1464.05 toks/s]
Processed prompts:  80%|███████▉  | 409/512 [01:11<00:15,  6.68it/s, est. speed input: 91.79 toks/s, output: 1468.66 toks/s]
Processed prompts:  80%|████████  | 411/512 [01:11<00:12,  7.89it/s, est. speed input: 92.02 toks/s, output: 1472.27 toks/s]
Processed prompts:  81%|████████  | 413/512 [01:11<00:10,  9.37it/s, est. speed input: 92.29 toks/s, output: 1476.61 toks/s]
Processed prompts:  81%|████████  | 415/512 [01:11<00:08, 10.78it/s, est. speed input: 92.57 toks/s, output: 1481.11 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [01:11<00:06, 14.30it/s, est. speed input: 93.09 toks/s, output: 1489.48 toks/s]
Processed prompts:  82%|████████▏ | 420/512 [01:12<00:06, 13.64it/s, est. speed input: 93.32 toks/s, output: 1493.20 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [01:12<00:07, 12.59it/s, est. speed input: 93.52 toks/s, output: 1496.37 toks/s]
Processed prompts:  83%|████████▎ | 424/512 [01:12<00:06, 12.98it/s, est. speed input: 93.78 toks/s, output: 1500.51 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [01:12<00:06, 13.14it/s, est. speed input: 94.03 toks/s, output: 1504.52 toks/s]
Processed prompts:  84%|████████▎ | 428/512 [01:14<00:26,  3.19it/s, est. speed input: 92.24 toks/s, output: 1475.76 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [01:14<00:25,  3.19it/s, est. speed input: 91.89 toks/s, output: 1470.25 toks/s]
Processed prompts:  84%|████████▍ | 431/512 [01:15<00:23,  3.47it/s, est. speed input: 91.90 toks/s, output: 1470.36 toks/s]
Processed prompts:  84%|████████▍ | 432/512 [01:15<00:20,  3.87it/s, est. speed input: 91.94 toks/s, output: 1471.07 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [01:15<00:17,  4.46it/s, est. speed input: 91.96 toks/s, output: 1471.43 toks/s]
Processed prompts:  85%|████████▍ | 435/512 [01:15<00:16,  4.53it/s, est. speed input: 91.92 toks/s, output: 1470.79 toks/s]
Processed prompts:  85%|████████▌ | 436/512 [01:15<00:15,  5.04it/s, est. speed input: 91.99 toks/s, output: 1471.76 toks/s]
Processed prompts:  85%|████████▌ | 437/512 [01:15<00:13,  5.72it/s, est. speed input: 92.07 toks/s, output: 1473.16 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [01:16<00:12,  5.78it/s, est. speed input: 92.08 toks/s, output: 1473.27 toks/s]
Processed prompts:  86%|████████▌ | 439/512 [01:16<00:11,  6.50it/s, est. speed input: 92.17 toks/s, output: 1474.66 toks/s]
Processed prompts:  86%|████████▌ | 440/512 [01:16<00:10,  7.19it/s, est. speed input: 92.25 toks/s, output: 1476.07 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [01:16<00:08,  8.31it/s, est. speed input: 92.44 toks/s, output: 1479.03 toks/s]
Processed prompts:  87%|████████▋ | 443/512 [01:16<00:08,  7.91it/s, est. speed input: 92.47 toks/s, output: 1479.55 toks/s]
Processed prompts:  87%|████████▋ | 445/512 [01:16<00:08,  8.37it/s, est. speed input: 92.63 toks/s, output: 1482.01 toks/s]
Processed prompts:  87%|████████▋ | 447/512 [01:17<00:07,  8.99it/s, est. speed input: 92.81 toks/s, output: 1484.91 toks/s]
Processed prompts:  88%|████████▊ | 449/512 [01:17<00:06,  9.33it/s, est. speed input: 92.98 toks/s, output: 1487.71 toks/s]
Processed prompts:  88%|████████▊ | 452/512 [01:17<00:04, 12.44it/s, est. speed input: 93.44 toks/s, output: 1495.10 toks/s]
Processed prompts:  89%|████████▉ | 456/512 [01:17<00:05, 10.59it/s, est. speed input: 93.73 toks/s, output: 1499.66 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [01:18<00:09,  5.57it/s, est. speed input: 93.07 toks/s, output: 1489.19 toks/s]
Processed prompts:  90%|█████████ | 463/512 [01:18<00:05,  9.02it/s, est. speed input: 93.90 toks/s, output: 1502.43 toks/s]
Processed prompts:  91%|█████████ | 465/512 [01:19<00:06,  7.32it/s, est. speed input: 93.75 toks/s, output: 1500.04 toks/s]
Processed prompts:  91%|█████████ | 467/512 [01:19<00:06,  7.21it/s, est. speed input: 93.81 toks/s, output: 1500.99 toks/s]
Processed prompts:  92%|█████████▏| 469/512 [01:19<00:05,  8.08it/s, est. speed input: 94.03 toks/s, output: 1504.46 toks/s]
Processed prompts:  92%|█████████▏| 471/512 [01:20<00:05,  7.96it/s, est. speed input: 94.12 toks/s, output: 1505.93 toks/s]
Processed prompts:  92%|█████████▏| 473/512 [01:20<00:05,  7.15it/s, est. speed input: 94.10 toks/s, output: 1505.64 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [01:20<00:05,  7.49it/s, est. speed input: 94.18 toks/s, output: 1506.92 toks/s]
Processed prompts:  93%|█████████▎| 475/512 [01:20<00:04,  7.84it/s, est. speed input: 94.26 toks/s, output: 1508.19 toks/s]
Processed prompts:  93%|█████████▎| 476/512 [01:20<00:04,  7.68it/s, est. speed input: 94.30 toks/s, output: 1508.75 toks/s]
Processed prompts:  93%|█████████▎| 477/512 [01:20<00:04,  7.73it/s, est. speed input: 94.35 toks/s, output: 1509.56 toks/s]
Processed prompts:  94%|█████████▎| 479/512 [01:21<00:03,  8.95it/s, est. speed input: 94.54 toks/s, output: 1512.70 toks/s]
Processed prompts:  94%|█████████▍| 481/512 [01:21<00:03, 10.05it/s, est. speed input: 94.76 toks/s, output: 1516.09 toks/s]
Processed prompts:  94%|█████████▍| 483/512 [01:21<00:02, 10.88it/s, est. speed input: 94.97 toks/s, output: 1519.51 toks/s]
Processed prompts:  95%|█████████▍| 485/512 [01:21<00:02, 11.99it/s, est. speed input: 95.21 toks/s, output: 1523.32 toks/s]
Processed prompts:  95%|█████████▌| 488/512 [01:21<00:01, 15.62it/s, est. speed input: 95.67 toks/s, output: 1530.70 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [01:22<00:03,  6.66it/s, est. speed input: 95.20 toks/s, output: 1523.18 toks/s]
Processed prompts:  96%|█████████▌| 492/512 [01:23<00:05,  3.87it/s, est. speed input: 94.38 toks/s, output: 1510.09 toks/s]
Processed prompts:  96%|█████████▋| 493/512 [01:23<00:04,  3.86it/s, est. speed input: 94.27 toks/s, output: 1508.39 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [01:23<00:04,  4.11it/s, est. speed input: 94.27 toks/s, output: 1508.27 toks/s]
Processed prompts:  97%|█████████▋| 495/512 [01:24<00:04,  4.20it/s, est. speed input: 94.21 toks/s, output: 1507.36 toks/s]
Processed prompts:  97%|█████████▋| 496/512 [01:24<00:03,  4.58it/s, est. speed input: 94.23 toks/s, output: 1507.63 toks/s]
Processed prompts:  97%|█████████▋| 497/512 [01:24<00:03,  4.97it/s, est. speed input: 94.25 toks/s, output: 1507.95 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [01:24<00:02,  5.32it/s, est. speed input: 94.27 toks/s, output: 1508.28 toks/s]
Processed prompts:  98%|█████████▊| 500/512 [01:24<00:02,  6.00it/s, est. speed input: 94.34 toks/s, output: 1509.39 toks/s]
Processed prompts:  98%|█████████▊| 501/512 [01:24<00:01,  6.36it/s, est. speed input: 94.38 toks/s, output: 1510.15 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [01:25<00:01,  6.03it/s, est. speed input: 94.36 toks/s, output: 1509.76 toks/s]
Processed prompts:  98%|█████████▊| 503/512 [01:25<00:01,  6.66it/s, est. speed input: 94.43 toks/s, output: 1510.88 toks/s]
Processed prompts:  98%|█████████▊| 504/512 [01:25<00:01,  6.92it/s, est. speed input: 94.47 toks/s, output: 1511.58 toks/s]
Processed prompts:  99%|█████████▊| 505/512 [01:25<00:00,  7.47it/s, est. speed input: 94.54 toks/s, output: 1512.70 toks/s]
Processed prompts:  99%|█████████▉| 508/512 [01:25<00:00, 11.01it/s, est. speed input: 94.92 toks/s, output: 1518.74 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [01:25<00:00, 12.38it/s, est. speed input: 95.16 toks/s, output: 1522.53 toks/s]
Processed prompts: 100%|██████████| 512/512 [01:25<00:00, 12.38it/s, est. speed input: 95.44 toks/s, output: 1527.04 toks/s]
Processed prompts: 100%|██████████| 512/512 [01:25<00:00,  5.96it/s, est. speed input: 95.44 toks/s, output: 1527.04 toks/s]
[rank0]:[W126 11:49:09.025430154 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 182.9s

测试结果:
  Requests/s:   5.66
  Tokens/s:     1540.25
  Total Reqs:   512
  Elapsed:      90.42s

  [Decode 分析]
  Total Decode Tokens:  131072
  Decode Tokens/s:      1449.65


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-14B-FP8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
64,16,64,64,256,256,6.1704,1678.3459,10.3721
128,16,128,128,256,256,9.3340,2538.8538,13.7133
256,16,256,256,256,256,9.2322,2511.1679,27.7289
512,16,512,512,256,256,5.6627,1540.2510,90.4164

------------------------------------------------------------

[INFO] 完成: 4 成功, 0 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/4] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:49:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:49:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=603836) WARNING 01-26 11:49:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=603836) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=603836) WARNING 01-26 11:50:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 3.34 requests/s, 909.31 total tokens/s, 855.82 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384


─── STDERR ───
[2026-01-26 11:49:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:49:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:49:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:49:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:49:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:49:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:49:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:49:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:49:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:49:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:49:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:49:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:49:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:49:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:49:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:49:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:49:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:04<00:12,  4.15s/it]
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:09<00:09,  4.76s/it]
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:10<00:03,  3.19s/it]
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  4.13s/it]
(EngineCore_DP0 pid=603836) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  4.06s/it]
(EngineCore_DP0 pid=603836) 
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=603836) [2026-01-26 11:49:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=603836) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:08,  2.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:06,  2.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:04,  3.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:03,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:03,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:05,  2.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:03<00:06,  1.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:03<00:04,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:03,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:03<00:02,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:03<00:02,  3.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:04<00:01,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:04<00:01,  4.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:04<00:01,  4.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:05<00:01,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:05<00:01,  2.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:06<00:00,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:06<00:00,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  2.85it/s]
(EngineCore_DP0 pid=603836) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  4.75it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  5.08it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:01,  5.18it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:01,  5.18it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:01,  4.79it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:01<00:01,  2.67it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:01,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:02<00:01,  2.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.85it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2443.41it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:07<07:23,  7.03s/it, est. speed input: 2.27 toks/s, output: 36.40 toks/s]
Processed prompts:  28%|██▊       | 18/64 [00:07<00:13,  3.50it/s, est. speed input: 40.18 toks/s, output: 642.90 toks/s]
Processed prompts:  41%|████      | 26/64 [00:11<00:15,  2.53it/s, est. speed input: 35.62 toks/s, output: 569.94 toks/s]
Processed prompts:  48%|████▊     | 31/64 [00:13<00:12,  2.74it/s, est. speed input: 37.93 toks/s, output: 606.93 toks/s]
Processed prompts:  53%|█████▎    | 34/64 [00:13<00:10,  2.92it/s, est. speed input: 39.39 toks/s, output: 630.31 toks/s]
Processed prompts:  56%|█████▋    | 36/64 [00:14<00:09,  2.92it/s, est. speed input: 39.76 toks/s, output: 636.11 toks/s]
Processed prompts:  59%|█████▉    | 38/64 [00:14<00:07,  3.37it/s, est. speed input: 41.50 toks/s, output: 663.98 toks/s]
Processed prompts:  64%|██████▍   | 41/64 [00:15<00:05,  3.98it/s, est. speed input: 43.63 toks/s, output: 698.12 toks/s]
Processed prompts:  72%|███████▏  | 46/64 [00:15<00:03,  5.38it/s, est. speed input: 47.60 toks/s, output: 761.58 toks/s]
Processed prompts:  75%|███████▌  | 48/64 [00:15<00:02,  6.06it/s, est. speed input: 49.22 toks/s, output: 787.49 toks/s]
Processed prompts:  78%|███████▊  | 50/64 [00:16<00:03,  4.17it/s, est. speed input: 48.02 toks/s, output: 768.39 toks/s]
Processed prompts:  80%|███████▉  | 51/64 [00:17<00:03,  3.63it/s, est. speed input: 47.52 toks/s, output: 760.37 toks/s]
Processed prompts:  81%|████████▏ | 52/64 [00:17<00:03,  3.67it/s, est. speed input: 47.74 toks/s, output: 763.85 toks/s]
Processed prompts:  83%|████████▎ | 53/64 [00:17<00:02,  3.96it/s, est. speed input: 48.20 toks/s, output: 771.26 toks/s]
Processed prompts:  84%|████████▍ | 54/64 [00:17<00:02,  3.67it/s, est. speed input: 48.16 toks/s, output: 770.52 toks/s]
Processed prompts:  86%|████████▌ | 55/64 [00:18<00:02,  3.88it/s, est. speed input: 48.49 toks/s, output: 775.82 toks/s]
Processed prompts:  89%|████████▉ | 57/64 [00:18<00:01,  5.09it/s, est. speed input: 49.69 toks/s, output: 795.06 toks/s]
Processed prompts:  91%|█████████ | 58/64 [00:18<00:01,  5.46it/s, est. speed input: 50.19 toks/s, output: 803.05 toks/s]
Processed prompts:  94%|█████████▍| 60/64 [00:18<00:00,  6.78it/s, est. speed input: 51.42 toks/s, output: 822.69 toks/s]
Processed prompts:  95%|█████████▌| 61/64 [00:18<00:00,  6.68it/s, est. speed input: 51.84 toks/s, output: 829.41 toks/s]
Processed prompts:  97%|█████████▋| 62/64 [00:18<00:00,  6.85it/s, est. speed input: 52.32 toks/s, output: 837.04 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  8.45it/s, est. speed input: 53.57 toks/s, output: 857.07 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  8.45it/s, est. speed input: 53.57 toks/s, output: 857.07 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.35it/s, est. speed input: 53.57 toks/s, output: 857.07 toks/s]
[rank0]:[W126 11:50:55.900807565 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 106.3s

测试结果:
  Requests/s:   3.34
  Tokens/s:     909.31
  Total Reqs:   64
  Elapsed:      19.14s

  [Decode 分析]
  Total Decode Tokens:  16384
  Decode Tokens/s:      855.82

============================================================
[2/4] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:51:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:51:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=605537) WARNING 01-26 11:51:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=605537) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=605537) WARNING 01-26 11:52:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 6.44 requests/s, 1751.41 total tokens/s, 1648.38 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 11:51:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:51:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:51:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:51:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:51:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:51:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:51:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:51:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:51:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:51:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:51:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:51:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:51:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:51:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:51:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:51:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:51:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 11:51:24.349447071 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.76s/it]
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:09<00:09,  4.63s/it]
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:10<00:03,  3.14s/it]
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  4.14s/it]
(EngineCore_DP0 pid=605537) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:16<00:00,  4.16s/it]
(EngineCore_DP0 pid=605537) 
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=605537) [2026-01-26 11:51:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=605537) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:32,  1.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:27,  1.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:17,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:02<00:12,  2.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:02<00:09,  3.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:02<00:08,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:02<00:07,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:02<00:06,  4.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:03<00:06,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:03<00:10,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:04<00:12,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:10,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:05<00:08,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:05<00:06,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:05<00:05,  3.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:05<00:04,  3.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:05<00:04,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:06<00:04,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:07<00:06,  2.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:07<00:07,  2.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:08<00:06,  2.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:08<00:05,  2.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:08<00:03,  3.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:08<00:03,  3.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:08<00:02,  3.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:09<00:02,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:09<00:01,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:10<00:02,  2.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:10<00:02,  2.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:11<00:02,  2.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:11<00:01,  2.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:11<00:01,  2.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:11<00:00,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:11<00:00,  3.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  4.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:12<00:00,  2.87it/s]
(EngineCore_DP0 pid=605537) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:04,  3.81it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:05,  3.39it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:01<00:06,  2.58it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:01<00:04,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:05,  2.62it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:02<00:05,  2.56it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:02<00:03,  3.07it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:02<00:03,  3.55it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:02<00:02,  3.99it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:02<00:02,  4.33it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:03<00:01,  4.61it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:03<00:01,  4.78it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:03<00:01,  4.32it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:04<00:01,  2.93it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:04<00:01,  3.07it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:05<00:01,  2.49it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:05<00:00,  2.97it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:05<00:00,  3.44it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:05<00:00,  3.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:05<00:00,  3.38it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2600.33it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:06<13:23,  6.33s/it, est. speed input: 2.53 toks/s, output: 40.45 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:06<00:28,  3.88it/s, est. speed input: 44.54 toks/s, output: 712.65 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:06<00:12,  7.49it/s, est. speed input: 76.21 toks/s, output: 1219.41 toks/s]
Processed prompts:  30%|███       | 39/128 [00:08<00:14,  6.13it/s, est. speed input: 73.63 toks/s, output: 1178.01 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:09<00:15,  5.59it/s, est. speed input: 72.67 toks/s, output: 1162.74 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:09<00:13,  6.17it/s, est. speed input: 75.88 toks/s, output: 1214.13 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:10<00:14,  5.63it/s, est. speed input: 74.92 toks/s, output: 1198.70 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:10<00:12,  6.37it/s, est. speed input: 77.27 toks/s, output: 1236.38 toks/s]
Processed prompts:  41%|████      | 52/128 [00:10<00:12,  5.93it/s, est. speed input: 77.11 toks/s, output: 1233.70 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:10<00:10,  6.80it/s, est. speed input: 79.09 toks/s, output: 1265.44 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:11<00:11,  6.22it/s, est. speed input: 79.04 toks/s, output: 1264.70 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:11<00:09,  7.51it/s, est. speed input: 81.14 toks/s, output: 1298.28 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:11<00:08,  8.03it/s, est. speed input: 82.50 toks/s, output: 1319.93 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:12<00:11,  5.94it/s, est. speed input: 81.26 toks/s, output: 1300.13 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:12<00:08,  7.39it/s, est. speed input: 83.20 toks/s, output: 1331.16 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:12<00:07,  8.30it/s, est. speed input: 84.65 toks/s, output: 1354.36 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:12<00:06,  9.95it/s, est. speed input: 86.50 toks/s, output: 1383.97 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:12<00:07,  8.07it/s, est. speed input: 86.56 toks/s, output: 1384.88 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:13<00:05, 10.59it/s, est. speed input: 89.28 toks/s, output: 1428.53 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:13<00:03, 14.96it/s, est. speed input: 93.34 toks/s, output: 1493.43 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:13<00:03, 12.43it/s, est. speed input: 94.60 toks/s, output: 1513.63 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:13<00:02, 15.16it/s, est. speed input: 97.43 toks/s, output: 1558.80 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:13<00:02, 18.85it/s, est. speed input: 101.20 toks/s, output: 1619.18 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:14<00:04,  8.49it/s, est. speed input: 98.64 toks/s, output: 1578.25 toks/s] 
Processed prompts:  72%|███████▏  | 92/128 [00:15<00:06,  5.78it/s, est. speed input: 95.88 toks/s, output: 1534.11 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:16<00:07,  4.74it/s, est. speed input: 93.85 toks/s, output: 1501.60 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:16<00:05,  5.45it/s, est. speed input: 94.66 toks/s, output: 1514.52 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:16<00:04,  6.07it/s, est. speed input: 95.32 toks/s, output: 1525.08 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:16<00:04,  6.18it/s, est. speed input: 95.43 toks/s, output: 1526.95 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:16<00:03,  7.44it/s, est. speed input: 96.51 toks/s, output: 1544.15 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:16<00:02,  8.94it/s, est. speed input: 97.71 toks/s, output: 1563.30 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:16<00:02, 10.35it/s, est. speed input: 98.88 toks/s, output: 1582.00 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:17<00:02, 10.25it/s, est. speed input: 99.59 toks/s, output: 1593.45 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:17<00:01, 10.26it/s, est. speed input: 100.32 toks/s, output: 1605.07 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:17<00:01, 10.01it/s, est. speed input: 101.26 toks/s, output: 1620.23 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:17<00:00, 16.25it/s, est. speed input: 105.71 toks/s, output: 1691.36 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:18<00:00, 15.73it/s, est. speed input: 107.15 toks/s, output: 1714.47 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:18<00:00, 16.07it/s, est. speed input: 108.24 toks/s, output: 1731.87 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:18<00:00, 17.53it/s, est. speed input: 110.06 toks/s, output: 1760.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:18<00:00, 17.53it/s, est. speed input: 111.40 toks/s, output: 1782.34 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:18<00:00,  6.96it/s, est. speed input: 111.40 toks/s, output: 1782.34 toks/s]
[rank0]:[W126 11:52:56.285920375 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 120.1s

测试结果:
  Requests/s:   6.44
  Tokens/s:     1751.41
  Total Reqs:   128
  Elapsed:      19.88s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      1648.38

============================================================
[3/4] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:53:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:53:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=607394) WARNING 01-26 11:53:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=607394) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=607394) WARNING 01-26 11:53:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 4.67 requests/s, 1270.05 total tokens/s, 1195.34 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536


─── STDERR ───
[2026-01-26 11:53:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:53:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:53:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:53:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:53:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:53:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:53:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:53:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:53:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:53:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:53:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:53:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:53:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:53:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:53:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:53:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:53:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 11:53:26.977675743 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.45s/it]
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.45s/it]
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.00it/s]
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
(EngineCore_DP0 pid=607394) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
(EngineCore_DP0 pid=607394) 
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=607394) [2026-01-26 11:53:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=607394) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:10,  3.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:08,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:07,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:06,  4.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:06,  4.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:08,  3.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:02<00:11,  2.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:03<00:15,  1.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:03<00:11,  2.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:03<00:09,  2.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:03<00:07,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:03<00:06,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:04<00:05,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:04<00:03,  5.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:04<00:03,  5.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:05<00:03,  5.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:05<00:03,  5.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:05<00:02,  5.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:05<00:02,  5.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:05<00:02,  5.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:06<00:02,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:06<00:04,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:07<00:05,  1.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:08<00:03,  2.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:08<00:02,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:08<00:02,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:08<00:01,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:08<00:01,  3.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:09<00:00,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:09<00:00,  4.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:10<00:00,  2.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:10<00:00,  2.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  2.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  3.26it/s]
(EngineCore_DP0 pid=607394) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:11,  3.02it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:08,  4.03it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:07,  4.48it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:06,  4.74it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:06,  4.82it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:05,  4.92it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:06,  4.38it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:02<00:08,  3.12it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:08,  3.24it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:03<00:10,  2.41it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:03<00:08,  2.76it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:03<00:07,  3.23it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:03<00:06,  3.65it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:03<00:05,  4.02it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:04<00:04,  4.25it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:04<00:04,  4.46it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:04<00:03,  4.67it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:04<00:03,  4.33it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:05<00:05,  3.18it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:05<00:05,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:05<00:04,  2.99it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:06<00:04,  2.67it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:06<00:03,  3.15it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:06<00:03,  3.59it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:06<00:02,  3.97it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:07<00:02,  4.30it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:07<00:01,  4.57it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:07<00:01,  4.63it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:07<00:01,  4.29it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:08<00:01,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:08<00:01,  3.15it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:09<00:01,  2.83it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:09<00:00,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:09<00:00,  3.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  3.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:09<00:00,  3.59it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2704.90it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:06<28:50,  6.79s/it, est. speed input: 2.36 toks/s, output: 37.73 toks/s]
Processed prompts:   7%|▋         | 19/256 [00:07<01:06,  3.55it/s, est. speed input: 41.63 toks/s, output: 666.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:08<01:08,  3.44it/s, est. speed input: 42.45 toks/s, output: 679.17 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:08<01:05,  3.55it/s, est. speed input: 43.86 toks/s, output: 701.72 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:09<01:07,  3.41it/s, est. speed input: 43.67 toks/s, output: 698.73 toks/s]
Processed prompts:  11%|█         | 27/256 [00:09<01:04,  3.58it/s, est. speed input: 44.92 toks/s, output: 718.74 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:09<00:51,  4.39it/s, est. speed input: 47.64 toks/s, output: 762.18 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:10<00:56,  3.97it/s, est. speed input: 47.37 toks/s, output: 757.86 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:10<00:55,  4.04it/s, est. speed input: 48.26 toks/s, output: 772.18 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:10<00:43,  5.15it/s, est. speed input: 50.64 toks/s, output: 810.27 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:11<00:44,  4.91it/s, est. speed input: 51.45 toks/s, output: 823.24 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:11<00:35,  6.07it/s, est. speed input: 54.85 toks/s, output: 877.56 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:11<00:24,  8.67it/s, est. speed input: 59.51 toks/s, output: 952.24 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:12<00:17, 11.46it/s, est. speed input: 65.82 toks/s, output: 1053.16 toks/s]
Processed prompts:  20%|██        | 52/256 [00:12<00:28,  7.14it/s, est. speed input: 64.41 toks/s, output: 1030.63 toks/s]
Processed prompts:  21%|██        | 54/256 [00:13<00:34,  5.78it/s, est. speed input: 63.90 toks/s, output: 1022.46 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:13<00:36,  5.45it/s, est. speed input: 63.89 toks/s, output: 1022.19 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:13<00:37,  5.35it/s, est. speed input: 64.09 toks/s, output: 1025.45 toks/s]
Processed prompts:  22%|██▏       | 57/256 [00:14<00:36,  5.52it/s, est. speed input: 64.52 toks/s, output: 1032.33 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:14<00:33,  5.85it/s, est. speed input: 65.05 toks/s, output: 1040.74 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:14<00:21,  8.93it/s, est. speed input: 67.77 toks/s, output: 1084.35 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:14<00:25,  7.45it/s, est. speed input: 68.25 toks/s, output: 1092.02 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:15<00:33,  5.81it/s, est. speed input: 67.75 toks/s, output: 1084.00 toks/s]
Processed prompts:  25%|██▌       | 65/256 [00:15<00:30,  6.28it/s, est. speed input: 68.32 toks/s, output: 1093.08 toks/s]
Processed prompts:  27%|██▋       | 69/256 [00:15<00:17, 10.54it/s, est. speed input: 71.77 toks/s, output: 1148.31 toks/s]
Processed prompts:  28%|██▊       | 71/256 [00:15<00:18, 10.08it/s, est. speed input: 72.80 toks/s, output: 1164.87 toks/s]
Processed prompts:  29%|██▊       | 73/256 [00:15<00:19,  9.28it/s, est. speed input: 73.63 toks/s, output: 1178.14 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:16<00:23,  7.80it/s, est. speed input: 74.38 toks/s, output: 1190.15 toks/s]
Processed prompts:  30%|███       | 77/256 [00:17<00:40,  4.46it/s, est. speed input: 72.03 toks/s, output: 1152.48 toks/s]
Processed prompts:  30%|███       | 78/256 [00:17<00:55,  3.23it/s, est. speed input: 70.10 toks/s, output: 1121.58 toks/s]
Processed prompts:  31%|███       | 79/256 [00:18<00:58,  3.04it/s, est. speed input: 69.42 toks/s, output: 1110.66 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:18<01:04,  2.74it/s, est. speed input: 68.45 toks/s, output: 1095.19 toks/s]
Processed prompts:  32%|███▏      | 81/256 [00:18<00:53,  3.30it/s, est. speed input: 68.90 toks/s, output: 1102.42 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:18<00:46,  3.77it/s, est. speed input: 69.18 toks/s, output: 1106.88 toks/s]
Processed prompts:  32%|███▏      | 83/256 [00:19<00:43,  3.94it/s, est. speed input: 69.21 toks/s, output: 1107.30 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:19<00:39,  4.40it/s, est. speed input: 69.47 toks/s, output: 1111.53 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:19<00:36,  4.66it/s, est. speed input: 69.64 toks/s, output: 1114.22 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:19<00:31,  5.31it/s, est. speed input: 70.16 toks/s, output: 1122.53 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:20<00:33,  5.04it/s, est. speed input: 70.15 toks/s, output: 1122.39 toks/s]
Processed prompts:  35%|███▍      | 89/256 [00:20<00:32,  5.16it/s, est. speed input: 70.31 toks/s, output: 1125.03 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:20<00:36,  4.53it/s, est. speed input: 70.09 toks/s, output: 1121.43 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:20<00:34,  4.75it/s, est. speed input: 70.24 toks/s, output: 1123.82 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:20<00:35,  4.63it/s, est. speed input: 70.23 toks/s, output: 1123.67 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:21<00:31,  5.21it/s, est. speed input: 70.55 toks/s, output: 1128.74 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:21<00:21,  7.64it/s, est. speed input: 71.68 toks/s, output: 1146.86 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:21<00:14, 11.22it/s, est. speed input: 73.46 toks/s, output: 1175.44 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:21<00:09, 16.94it/s, est. speed input: 76.08 toks/s, output: 1217.27 toks/s]
Processed prompts:  41%|████      | 105/256 [00:22<00:16,  8.91it/s, est. speed input: 76.03 toks/s, output: 1216.54 toks/s]
Processed prompts:  42%|████▏     | 107/256 [00:23<00:36,  4.06it/s, est. speed input: 73.12 toks/s, output: 1169.98 toks/s]
Processed prompts:  43%|████▎     | 109/256 [00:23<00:36,  4.01it/s, est. speed input: 72.88 toks/s, output: 1166.14 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:24<00:34,  4.19it/s, est. speed input: 73.00 toks/s, output: 1167.92 toks/s]
Processed prompts:  43%|████▎     | 111/256 [00:24<00:37,  3.91it/s, est. speed input: 72.66 toks/s, output: 1162.50 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:24<00:44,  3.27it/s, est. speed input: 71.84 toks/s, output: 1149.51 toks/s]
Processed prompts:  44%|████▍     | 113/256 [00:25<00:48,  2.97it/s, est. speed input: 71.23 toks/s, output: 1139.66 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:25<00:49,  2.85it/s, est. speed input: 70.76 toks/s, output: 1132.10 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:25<00:42,  3.33it/s, est. speed input: 70.95 toks/s, output: 1135.19 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:26<00:39,  3.55it/s, est. speed input: 70.93 toks/s, output: 1134.92 toks/s]
Processed prompts:  46%|████▌     | 117/256 [00:26<00:36,  3.85it/s, est. speed input: 71.00 toks/s, output: 1135.93 toks/s]
Processed prompts:  46%|████▋     | 119/256 [00:26<00:27,  5.06it/s, est. speed input: 71.56 toks/s, output: 1144.94 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:26<00:23,  5.67it/s, est. speed input: 71.86 toks/s, output: 1149.83 toks/s]
Processed prompts:  47%|████▋     | 121/256 [00:26<00:21,  6.30it/s, est. speed input: 72.17 toks/s, output: 1154.75 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:26<00:20,  6.69it/s, est. speed input: 72.43 toks/s, output: 1158.94 toks/s]
Processed prompts:  48%|████▊     | 123/256 [00:27<00:19,  6.89it/s, est. speed input: 72.67 toks/s, output: 1162.66 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:27<00:12, 10.01it/s, est. speed input: 73.93 toks/s, output: 1182.93 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:27<00:12, 10.22it/s, est. speed input: 74.59 toks/s, output: 1193.49 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:27<00:12, 10.04it/s, est. speed input: 75.19 toks/s, output: 1203.10 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:27<00:08, 14.18it/s, est. speed input: 77.07 toks/s, output: 1233.08 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:28<00:14,  8.53it/s, est. speed input: 76.82 toks/s, output: 1229.18 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:29<00:33,  3.48it/s, est. speed input: 74.02 toks/s, output: 1184.40 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:30<00:39,  2.93it/s, est. speed input: 73.03 toks/s, output: 1168.55 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:31<00:45,  2.55it/s, est. speed input: 72.10 toks/s, output: 1153.64 toks/s]
Processed prompts:  55%|█████▌    | 141/256 [00:31<00:44,  2.61it/s, est. speed input: 71.81 toks/s, output: 1148.94 toks/s]
Processed prompts:  56%|█████▌    | 143/256 [00:31<00:32,  3.46it/s, est. speed input: 72.22 toks/s, output: 1155.57 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:31<00:29,  3.75it/s, est. speed input: 72.31 toks/s, output: 1156.99 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:31<00:25,  4.35it/s, est. speed input: 72.56 toks/s, output: 1161.01 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:32<00:20,  5.37it/s, est. speed input: 73.02 toks/s, output: 1168.24 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:32<00:20,  5.26it/s, est. speed input: 73.05 toks/s, output: 1168.78 toks/s]
Processed prompts:  58%|█████▊    | 149/256 [00:32<00:18,  5.67it/s, est. speed input: 73.24 toks/s, output: 1171.86 toks/s]
Processed prompts:  59%|█████▉    | 151/256 [00:32<00:14,  7.45it/s, est. speed input: 73.89 toks/s, output: 1182.30 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:32<00:13,  7.77it/s, est. speed input: 74.13 toks/s, output: 1186.14 toks/s]
Processed prompts:  61%|██████    | 155/256 [00:32<00:09, 10.92it/s, est. speed input: 75.23 toks/s, output: 1203.71 toks/s]
Processed prompts:  61%|██████▏   | 157/256 [00:33<00:08, 11.58it/s, est. speed input: 75.86 toks/s, output: 1213.70 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:33<00:07, 12.65it/s, est. speed input: 76.53 toks/s, output: 1224.51 toks/s]
Processed prompts:  63%|██████▎   | 161/256 [00:33<00:08, 11.61it/s, est. speed input: 77.02 toks/s, output: 1232.35 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:34<00:15,  5.86it/s, est. speed input: 76.33 toks/s, output: 1221.24 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:34<00:20,  4.44it/s, est. speed input: 75.74 toks/s, output: 1211.87 toks/s]
Processed prompts:  64%|██████▍   | 165/256 [00:35<00:26,  3.37it/s, est. speed input: 74.96 toks/s, output: 1199.34 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:35<00:27,  3.22it/s, est. speed input: 74.66 toks/s, output: 1194.53 toks/s]
Processed prompts:  65%|██████▌   | 167/256 [00:35<00:26,  3.37it/s, est. speed input: 74.57 toks/s, output: 1193.11 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:36<00:27,  3.17it/s, est. speed input: 74.25 toks/s, output: 1188.04 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:36<00:25,  3.42it/s, est. speed input: 74.22 toks/s, output: 1187.57 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:36<00:24,  3.55it/s, est. speed input: 74.15 toks/s, output: 1186.33 toks/s]
Processed prompts:  67%|██████▋   | 171/256 [00:36<00:23,  3.56it/s, est. speed input: 74.02 toks/s, output: 1184.30 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:37<00:24,  3.49it/s, est. speed input: 73.85 toks/s, output: 1181.63 toks/s]
Processed prompts:  68%|██████▊   | 173/256 [00:37<00:20,  4.02it/s, est. speed input: 73.97 toks/s, output: 1183.50 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:37<00:18,  4.37it/s, est. speed input: 74.04 toks/s, output: 1184.61 toks/s]
Processed prompts:  68%|██████▊   | 175/256 [00:37<00:16,  4.83it/s, est. speed input: 74.16 toks/s, output: 1186.52 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:37<00:15,  5.28it/s, est. speed input: 74.29 toks/s, output: 1188.64 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:38<00:13,  6.05it/s, est. speed input: 74.50 toks/s, output: 1191.98 toks/s]
Processed prompts:  70%|██████▉   | 179/256 [00:38<00:10,  7.15it/s, est. speed input: 74.91 toks/s, output: 1198.53 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:38<00:10,  7.57it/s, est. speed input: 75.11 toks/s, output: 1201.81 toks/s]
Processed prompts:  71%|███████   | 181/256 [00:38<00:09,  7.91it/s, est. speed input: 75.31 toks/s, output: 1205.02 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:38<00:07,  9.61it/s, est. speed input: 75.85 toks/s, output: 1213.66 toks/s]
Processed prompts:  72%|███████▏  | 185/256 [00:38<00:06, 10.77it/s, est. speed input: 76.39 toks/s, output: 1222.21 toks/s]
Processed prompts:  73%|███████▎  | 187/256 [00:38<00:06, 10.37it/s, est. speed input: 76.81 toks/s, output: 1228.89 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:39<00:05, 12.34it/s, est. speed input: 77.67 toks/s, output: 1242.80 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:39<00:04, 13.07it/s, est. speed input: 78.23 toks/s, output: 1251.69 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:41<00:19,  3.15it/s, est. speed input: 75.59 toks/s, output: 1209.49 toks/s]
Processed prompts:  76%|███████▌  | 195/256 [00:41<00:23,  2.64it/s, est. speed input: 74.76 toks/s, output: 1196.10 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:41<00:21,  2.82it/s, est. speed input: 74.68 toks/s, output: 1194.94 toks/s]
Processed prompts:  77%|███████▋  | 197/256 [00:42<00:19,  2.97it/s, est. speed input: 74.57 toks/s, output: 1193.15 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:42<00:17,  3.34it/s, est. speed input: 74.64 toks/s, output: 1194.16 toks/s]
Processed prompts:  78%|███████▊  | 199/256 [00:42<00:17,  3.26it/s, est. speed input: 74.44 toks/s, output: 1190.96 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:42<00:14,  3.75it/s, est. speed input: 74.53 toks/s, output: 1192.55 toks/s]
Processed prompts:  79%|███████▊  | 201/256 [00:43<00:13,  4.23it/s, est. speed input: 74.64 toks/s, output: 1194.17 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:43<00:01, 21.17it/s, est. speed input: 79.21 toks/s, output: 1267.44 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:43<00:02, 18.33it/s, est. speed input: 80.14 toks/s, output: 1282.29 toks/s]
Processed prompts:  86%|████████▋ | 221/256 [00:44<00:03,  9.76it/s, est. speed input: 79.77 toks/s, output: 1276.31 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:45<00:06,  5.27it/s, est. speed input: 78.40 toks/s, output: 1254.39 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:46<00:05,  5.09it/s, est. speed input: 78.32 toks/s, output: 1253.13 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:46<00:05,  4.85it/s, est. speed input: 78.19 toks/s, output: 1251.11 toks/s]
Processed prompts:  89%|████████▉ | 229/256 [00:46<00:05,  4.86it/s, est. speed input: 78.20 toks/s, output: 1251.19 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:47<00:05,  4.96it/s, est. speed input: 78.24 toks/s, output: 1251.87 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:47<00:04,  5.06it/s, est. speed input: 78.28 toks/s, output: 1252.47 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:47<00:04,  5.33it/s, est. speed input: 78.37 toks/s, output: 1253.96 toks/s]
Processed prompts:  91%|█████████ | 233/256 [00:47<00:03,  5.92it/s, est. speed input: 78.53 toks/s, output: 1256.52 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:47<00:02,  7.38it/s, est. speed input: 78.93 toks/s, output: 1262.82 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:47<00:02,  8.50it/s, est. speed input: 79.31 toks/s, output: 1268.99 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:47<00:02,  8.47it/s, est. speed input: 79.45 toks/s, output: 1271.16 toks/s]
Processed prompts:  93%|█████████▎| 239/256 [00:48<00:02,  7.42it/s, est. speed input: 79.46 toks/s, output: 1271.41 toks/s]
Processed prompts:  94%|█████████▍| 241/256 [00:48<00:01,  9.53it/s, est. speed input: 79.93 toks/s, output: 1278.92 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:48<00:01,  9.51it/s, est. speed input: 80.24 toks/s, output: 1283.92 toks/s]
Processed prompts:  96%|█████████▌| 245/256 [00:48<00:01,  9.22it/s, est. speed input: 80.52 toks/s, output: 1288.38 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:48<00:01,  8.75it/s, est. speed input: 80.62 toks/s, output: 1289.97 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:49<00:00,  8.78it/s, est. speed input: 81.04 toks/s, output: 1296.66 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:49<00:01,  4.50it/s, est. speed input: 80.19 toks/s, output: 1283.03 toks/s]
Processed prompts:  98%|█████████▊| 251/256 [00:50<00:01,  3.49it/s, est. speed input: 79.65 toks/s, output: 1274.35 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:50<00:01,  3.14it/s, est. speed input: 79.29 toks/s, output: 1268.69 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:51<00:00,  3.26it/s, est. speed input: 79.19 toks/s, output: 1267.01 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:51<00:00,  3.44it/s, est. speed input: 79.12 toks/s, output: 1265.91 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:51<00:00,  3.68it/s, est. speed input: 79.09 toks/s, output: 1265.50 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:51<00:00,  3.99it/s, est. speed input: 79.10 toks/s, output: 1265.67 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:51<00:00,  3.99it/s, est. speed input: 79.10 toks/s, output: 1265.67 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:51<00:00,  4.94it/s, est. speed input: 79.10 toks/s, output: 1265.67 toks/s]
[rank0]:[W126 11:55:23.691640245 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 147.3s

测试结果:
  Requests/s:   4.67
  Tokens/s:     1270.05
  Total Reqs:   256
  Elapsed:      54.83s

  [Decode 分析]
  Total Decode Tokens:  65536
  Decode Tokens/s:      1195.34

============================================================
[4/4] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:55:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:55:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=609645) WARNING 01-26 11:55:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=609645) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=609645) WARNING 01-26 11:56:16 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=609645) ERROR 01-26 11:56:37 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 11:55:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:55:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:55:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:55:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:55:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:55:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:55:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 11:55:53.054610915 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=609645) [2026-01-26 11:55:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.45s/it]
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.47s/it]
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.17s/it]
(EngineCore_DP0 pid=609645) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
(EngineCore_DP0 pid=609645) 
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41287680 bytes
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29491200 bytes
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 159252480 bytes
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=609645) [2026-01-26 11:56:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 79626240 bytes
(EngineCore_DP0 pid=609645) Process EngineCore_DP0:
(EngineCore_DP0 pid=609645) Traceback (most recent call last):
(EngineCore_DP0 pid=609645)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=609645)     self.run()
(EngineCore_DP0 pid=609645)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=609645)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=609645)     raise e
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=609645)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=609645)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=609645)     super().__init__(
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=609645)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=609645)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=609645)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=609645)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=609645)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=609645)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=609645)     raise ValueError(
(EngineCore_DP0 pid=609645) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 11:56:39.497442936 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-14B-FP8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
64,16,64,64,256,256,3.3430,909.3056,19.1443
128,16,128,128,256,256,6.4390,1751.4073,19.8789
256,16,256,256,256,256,4.6693,1270.0490,54.8262
512,16,512,512,256,256,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 3 成功, 1 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/4] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:56:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:56:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=610892) WARNING 01-26 11:57:00 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=610892) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=610892) WARNING 01-26 11:57:36 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=610892) ERROR 01-26 11:57:56 [core.py:866] ValueError: To serve at least one request with the models's max seq len (272), (0.05 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 64. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 11:56:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:56:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:56:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:56:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:56:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:56:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:56:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:56:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:56:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:56:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:56:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:56:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:56:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:56:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:01] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.87s/it]
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:11<00:11,  5.59s/it]
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:12<00:03,  3.66s/it]
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  3.94s/it]
(EngineCore_DP0 pid=610892) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:17<00:00,  4.25s/it]
(EngineCore_DP0 pid=610892) 
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=610892) [2026-01-26 11:57:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=610892) Process EngineCore_DP0:
(EngineCore_DP0 pid=610892) Traceback (most recent call last):
(EngineCore_DP0 pid=610892)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=610892)     self.run()
(EngineCore_DP0 pid=610892)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=610892)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=610892)     raise e
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=610892)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=610892)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=610892)     super().__init__(
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=610892)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=610892)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=610892)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=610892)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=610892)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=610892)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=610892)     raise ValueError(
(EngineCore_DP0 pid=610892) ValueError: To serve at least one request with the models's max seq len (272), (0.05 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 64. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 11:57:58.895381761 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=64 (exit code: 1)

============================================================
[2/4] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:58:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:58:12 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=612183) WARNING 01-26 11:58:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=612183) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=612183) WARNING 01-26 11:58:45 [backends.py:609] Failed to read file <frozen os>
Throughput: 3.27 requests/s, 890.50 total tokens/s, 838.12 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 11:58:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:58:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:58:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:58:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:58:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:58:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:58:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:58:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:58:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:58:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:58:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 11:58:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 11:58:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:58:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:58:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:58:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:58:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.54s/it]
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.72s/it]
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:04<00:01,  1.28s/it]
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.39s/it]
(EngineCore_DP0 pid=612183) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.43s/it]
(EngineCore_DP0 pid=612183) 
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=612183) [2026-01-26 11:58:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=612183) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:01<00:37,  1.10s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:23,  1.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:15,  2.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:11,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:02<00:09,  3.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:02<00:10,  2.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:03<00:12,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:04<00:15,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:04<00:12,  2.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:04<00:09,  2.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:04<00:07,  3.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:06,  3.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:05<00:05,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:05<00:05,  4.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:05<00:05,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:06<00:07,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:07<00:10,  1.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:07<00:08,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:07<00:06,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:08<00:05,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:08<00:04,  3.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:08<00:03,  3.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:08<00:03,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:09<00:04,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:10<00:06,  1.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:10<00:04,  2.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:10<00:03,  2.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:11<00:02,  2.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:11<00:01,  3.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:11<00:01,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:11<00:00,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:12<00:00,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:12<00:00,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:13<00:00,  1.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:14<00:00,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:14<00:00,  2.48it/s]
(EngineCore_DP0 pid=612183) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:04,  4.13it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:03,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:03,  4.77it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:03,  4.95it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:03,  4.60it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:01<00:04,  2.97it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:01<00:04,  2.98it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:02<00:03,  2.85it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:02<00:03,  2.59it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:03<00:02,  3.08it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:03<00:02,  3.50it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:03<00:01,  3.90it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:03<00:01,  4.25it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:03<00:01,  4.49it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:03<00:00,  4.71it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:04<00:00,  4.22it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:04<00:00,  3.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:04<00:00,  4.74it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2581.59it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:07<15:40,  7.40s/it, est. speed input: 2.16 toks/s, output: 34.58 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:08<00:45,  2.51it/s, est. speed input: 29.69 toks/s, output: 475.06 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:08<00:44,  2.48it/s, est. speed input: 30.42 toks/s, output: 486.75 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:09<00:45,  2.41it/s, est. speed input: 30.44 toks/s, output: 487.11 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:09<00:45,  2.39it/s, est. speed input: 30.73 toks/s, output: 491.68 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:10<00:39,  2.71it/s, est. speed input: 32.43 toks/s, output: 518.85 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:10<00:40,  2.59it/s, est. speed input: 32.47 toks/s, output: 519.50 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:10<00:35,  2.95it/s, est. speed input: 33.54 toks/s, output: 536.59 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:11<00:32,  3.18it/s, est. speed input: 34.74 toks/s, output: 555.85 toks/s]
Processed prompts:  20%|██        | 26/128 [00:11<00:27,  3.66it/s, est. speed input: 35.80 toks/s, output: 572.84 toks/s]
Processed prompts:  21%|██        | 27/128 [00:12<00:30,  3.30it/s, est. speed input: 35.92 toks/s, output: 574.67 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:12<00:16,  5.79it/s, est. speed input: 39.56 toks/s, output: 632.89 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:12<00:17,  5.41it/s, est. speed input: 40.78 toks/s, output: 652.41 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:13<00:17,  5.40it/s, est. speed input: 42.70 toks/s, output: 683.27 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:13<00:17,  5.38it/s, est. speed input: 43.30 toks/s, output: 692.81 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:13<00:22,  4.04it/s, est. speed input: 42.84 toks/s, output: 685.46 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:14<00:36,  2.45it/s, est. speed input: 41.00 toks/s, output: 655.99 toks/s]
Processed prompts:  30%|███       | 39/128 [00:15<00:40,  2.17it/s, est. speed input: 40.36 toks/s, output: 645.74 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:15<00:38,  2.30it/s, est. speed input: 40.45 toks/s, output: 647.24 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:16<00:37,  2.34it/s, est. speed input: 40.44 toks/s, output: 646.97 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:16<00:23,  3.61it/s, est. speed input: 42.01 toks/s, output: 672.18 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:16<00:22,  3.75it/s, est. speed input: 42.38 toks/s, output: 678.16 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:16<00:19,  4.28it/s, est. speed input: 43.00 toks/s, output: 687.98 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:16<00:19,  4.26it/s, est. speed input: 43.34 toks/s, output: 693.45 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:17<00:17,  4.66it/s, est. speed input: 43.86 toks/s, output: 701.81 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:17<00:14,  5.39it/s, est. speed input: 44.51 toks/s, output: 712.17 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:17<00:19,  4.13it/s, est. speed input: 44.45 toks/s, output: 711.18 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:17<00:12,  6.35it/s, est. speed input: 45.98 toks/s, output: 735.72 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:18<00:07,  9.22it/s, est. speed input: 48.81 toks/s, output: 781.03 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:19<00:18,  3.80it/s, est. speed input: 47.20 toks/s, output: 755.22 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:20<00:25,  2.76it/s, est. speed input: 46.01 toks/s, output: 736.20 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:20<00:24,  2.80it/s, est. speed input: 46.04 toks/s, output: 736.71 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:20<00:22,  3.04it/s, est. speed input: 46.30 toks/s, output: 740.81 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:21<00:28,  2.32it/s, est. speed input: 45.42 toks/s, output: 726.72 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:21<00:26,  2.46it/s, est. speed input: 45.45 toks/s, output: 727.24 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:22<00:25,  2.58it/s, est. speed input: 45.49 toks/s, output: 727.79 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:22<00:23,  2.69it/s, est. speed input: 45.53 toks/s, output: 728.43 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:22<00:20,  3.00it/s, est. speed input: 45.76 toks/s, output: 732.23 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:23<00:20,  3.07it/s, est. speed input: 45.85 toks/s, output: 733.58 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:23<00:18,  3.27it/s, est. speed input: 46.03 toks/s, output: 736.48 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:23<00:12,  4.86it/s, est. speed input: 47.06 toks/s, output: 752.90 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:23<00:11,  4.99it/s, est. speed input: 47.37 toks/s, output: 757.91 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:23<00:10,  5.29it/s, est. speed input: 47.73 toks/s, output: 763.66 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:23<00:07,  7.42it/s, est. speed input: 48.82 toks/s, output: 781.14 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:24<00:05,  8.91it/s, est. speed input: 49.85 toks/s, output: 797.53 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:24<00:04, 10.16it/s, est. speed input: 51.77 toks/s, output: 828.27 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:26<00:18,  2.52it/s, est. speed input: 48.32 toks/s, output: 773.12 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:27<00:20,  2.20it/s, est. speed input: 47.58 toks/s, output: 761.28 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:27<00:20,  2.24it/s, est. speed input: 47.45 toks/s, output: 759.27 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:28<00:18,  2.34it/s, est. speed input: 47.42 toks/s, output: 758.74 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:28<00:16,  2.58it/s, est. speed input: 47.56 toks/s, output: 760.91 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:28<00:11,  3.44it/s, est. speed input: 48.19 toks/s, output: 770.96 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:29<00:10,  3.83it/s, est. speed input: 48.48 toks/s, output: 775.60 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:29<00:07,  5.29it/s, est. speed input: 49.32 toks/s, output: 789.19 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:29<00:06,  5.29it/s, est. speed input: 49.55 toks/s, output: 792.80 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:29<00:06,  5.86it/s, est. speed input: 49.91 toks/s, output: 798.49 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:29<00:06,  5.56it/s, est. speed input: 50.10 toks/s, output: 801.55 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:29<00:05,  5.69it/s, est. speed input: 50.36 toks/s, output: 805.72 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:30<00:01, 14.41it/s, est. speed input: 53.33 toks/s, output: 853.26 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:31<00:05,  5.06it/s, est. speed input: 52.35 toks/s, output: 837.63 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:31<00:04,  4.82it/s, est. speed input: 52.58 toks/s, output: 841.35 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:32<00:04,  4.45it/s, est. speed input: 52.69 toks/s, output: 843.11 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:32<00:04,  4.51it/s, est. speed input: 52.85 toks/s, output: 845.66 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:32<00:04,  4.54it/s, est. speed input: 53.00 toks/s, output: 847.95 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:32<00:04,  4.70it/s, est. speed input: 53.19 toks/s, output: 850.97 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:33<00:03,  4.63it/s, est. speed input: 53.30 toks/s, output: 852.86 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:33<00:03,  5.17it/s, est. speed input: 53.59 toks/s, output: 857.38 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:33<00:03,  4.99it/s, est. speed input: 53.71 toks/s, output: 859.39 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:33<00:02,  5.59it/s, est. speed input: 53.99 toks/s, output: 863.92 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:33<00:01,  7.54it/s, est. speed input: 54.71 toks/s, output: 875.37 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:33<00:01,  8.41it/s, est. speed input: 55.34 toks/s, output: 885.49 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:33<00:01,  8.40it/s, est. speed input: 55.62 toks/s, output: 889.92 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:34<00:01,  8.39it/s, est. speed input: 55.89 toks/s, output: 894.31 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:34<00:01,  4.72it/s, est. speed input: 55.57 toks/s, output: 889.10 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:35<00:02,  2.91it/s, est. speed input: 54.91 toks/s, output: 878.51 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:35<00:02,  2.35it/s, est. speed input: 54.37 toks/s, output: 869.97 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:36<00:02,  2.22it/s, est. speed input: 54.04 toks/s, output: 864.59 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:36<00:01,  2.40it/s, est. speed input: 53.99 toks/s, output: 863.76 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:37<00:01,  2.65it/s, est. speed input: 54.01 toks/s, output: 864.11 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:37<00:00,  3.25it/s, est. speed input: 54.23 toks/s, output: 867.72 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:37<00:00,  3.34it/s, est. speed input: 54.26 toks/s, output: 868.12 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:37<00:00,  3.98it/s, est. speed input: 54.48 toks/s, output: 871.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:37<00:00,  3.98it/s, est. speed input: 54.48 toks/s, output: 871.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:37<00:00,  3.41it/s, est. speed input: 54.48 toks/s, output: 871.76 toks/s]
[rank0]:[W126 12:00:01.321236166 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 122.1s

测试结果:
  Requests/s:   3.27
  Tokens/s:     890.50
  Total Reqs:   128
  Elapsed:      39.10s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      838.12

============================================================
[3/4] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:00:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:00:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=614177) WARNING 01-26 12:00:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=614177) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=614177) WARNING 01-26 12:00:48 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=614177) ERROR 01-26 12:01:06 [core.py:866] ValueError: To serve at least one request with the models's max seq len (272), (0.05 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 64. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 12:00:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:00:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:00:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:00:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:00:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:00:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:00:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:00:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:00:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:05,  1.94s/it]
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.89s/it]
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:04<00:01,  1.26s/it]
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.50s/it]
(EngineCore_DP0 pid=614177) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.54s/it]
(EngineCore_DP0 pid=614177) 
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=614177) [2026-01-26 12:00:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=614177) Process EngineCore_DP0:
(EngineCore_DP0 pid=614177) Traceback (most recent call last):
(EngineCore_DP0 pid=614177)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=614177)     self.run()
(EngineCore_DP0 pid=614177)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=614177)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=614177)     raise e
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=614177)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=614177)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=614177)     super().__init__(
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=614177)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=614177)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=614177)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=614177)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=614177)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=614177)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=614177)     raise ValueError(
(EngineCore_DP0 pid=614177) ValueError: To serve at least one request with the models's max seq len (272), (0.05 GiB KV cache is needed, which is larger than the available KV cache memory (0.01 GiB). Based on the available memory, the estimated maximum model length is 64. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 12:01:07.230184542 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=256 (exit code: 1)

============================================================
[4/4] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:01:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:01:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=615315) WARNING 01-26 12:01:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=615315) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615315) WARNING 01-26 12:01:53 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=615315) ERROR 01-26 12:02:15 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 12:01:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:01:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:01:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:01:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:01:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:01:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:01:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:01:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:01:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:01:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:01:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 12:01:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 12:01:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:01:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:01:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:01:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:01:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.51s/it]
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.51s/it]
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.23s/it]
(EngineCore_DP0 pid=615315) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.26s/it]
(EngineCore_DP0 pid=615315) 
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44040192 bytes
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 169869312 bytes
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=615315) [2026-01-26 12:01:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 85032960 bytes
(EngineCore_DP0 pid=615315) Process EngineCore_DP0:
(EngineCore_DP0 pid=615315) Traceback (most recent call last):
(EngineCore_DP0 pid=615315)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=615315)     self.run()
(EngineCore_DP0 pid=615315)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=615315)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=615315)     raise e
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=615315)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=615315)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=615315)     super().__init__(
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=615315)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=615315)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=615315)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=615315)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=615315)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=615315)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=615315)     raise ValueError(
(EngineCore_DP0 pid=615315) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 12:02:17.731610566 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-14B-FP8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
64,16,64,64,256,256,-1.0000,-1.0000,-1.0000
128,16,128,128,256,256,3.2739,890.5042,39.0970
256,16,256,256,256,256,-1.0000,-1.0000,-1.0000
512,16,512,512,256,256,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 1 成功, 3 失败


============================================================
  Benchmark 完成!
============================================================


总计: 16 成功, 4 失败
============================================================
