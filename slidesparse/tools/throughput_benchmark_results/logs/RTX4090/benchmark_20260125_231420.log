======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-25 23:14:20
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-7b-int8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX4090
  Compute Capability: cc89
  VRAM: 24.0 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-7B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:14:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:14:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=526010) WARNING 01-25 23:14:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=526010) WARNING 01-25 23:15:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 13.76 requests/s, 7058.37 total tokens/s, 13.76 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:14:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:14:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:14:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:14:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:14:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:14:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:14:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:14:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:14:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:14:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:14:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:14:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:14:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:14:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:14:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:14:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:14:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=526010) [2026-01-25 23:14:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=526010) [2026-01-25 23:14:45] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=526010) [2026-01-25 23:14:45] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=526010) [2026-01-25 23:14:45] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=526010) [2026-01-25 23:14:45] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=526010) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=526010) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.14s/it]
(EngineCore_DP0 pid=526010) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.77s/it]
(EngineCore_DP0 pid=526010) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.67s/it]
(EngineCore_DP0 pid=526010) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=526010) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]
(EngineCore_DP0 pid=526010) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [-1:59:59<00:00, -96.89it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:59,  2.13it/s, est. speed input: 1089.61 toks/s, output: 2.13 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:21,  5.80it/s, est. speed input: 2533.13 toks/s, output: 4.95 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:14,  8.44it/s, est. speed input: 3453.04 toks/s, output: 6.74 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:11, 10.33it/s, est. speed input: 4090.28 toks/s, output: 7.99 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:10, 11.61it/s, est. speed input: 4549.01 toks/s, output: 8.88 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:09, 12.42it/s, est. speed input: 4883.71 toks/s, output: 9.54 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:08, 13.01it/s, est. speed input: 5150.44 toks/s, output: 10.06 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:08, 13.34it/s, est. speed input: 5354.21 toks/s, output: 10.46 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:08, 13.43it/s, est. speed input: 5505.76 toks/s, output: 10.75 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:07, 13.71it/s, est. speed input: 5655.24 toks/s, output: 11.05 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:07, 13.92it/s, est. speed input: 5783.93 toks/s, output: 11.30 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:07, 14.31it/s, est. speed input: 5917.96 toks/s, output: 11.56 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:07, 14.60it/s, est. speed input: 6036.64 toks/s, output: 11.79 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:06, 14.89it/s, est. speed input: 6147.95 toks/s, output: 12.01 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:06, 15.08it/s, est. speed input: 6246.13 toks/s, output: 12.20 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:06, 15.17it/s, est. speed input: 6330.50 toks/s, output: 12.36 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 15.33it/s, est. speed input: 6413.02 toks/s, output: 12.53 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:05, 15.53it/s, est. speed input: 6494.06 toks/s, output: 12.68 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 15.64it/s, est. speed input: 6565.87 toks/s, output: 12.82 toks/s]
Processed prompts:  30%|███       | 39/128 [00:03<00:05, 15.74it/s, est. speed input: 6633.21 toks/s, output: 12.96 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:03<00:05, 15.74it/s, est. speed input: 6690.88 toks/s, output: 13.07 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:03<00:05, 15.74it/s, est. speed input: 6743.90 toks/s, output: 13.17 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:03<00:05, 15.65it/s, est. speed input: 6788.69 toks/s, output: 13.26 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 15.61it/s, est. speed input: 6830.84 toks/s, output: 13.34 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 15.65it/s, est. speed input: 6873.71 toks/s, output: 13.43 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 15.71it/s, est. speed input: 6915.31 toks/s, output: 13.51 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.74it/s, est. speed input: 6953.62 toks/s, output: 13.58 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:04<00:04, 15.76it/s, est. speed input: 6989.15 toks/s, output: 13.65 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:04<00:04, 15.66it/s, est. speed input: 7017.69 toks/s, output: 13.71 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:04<00:04, 15.63it/s, est. speed input: 7046.09 toks/s, output: 13.76 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:04, 15.62it/s, est. speed input: 7073.33 toks/s, output: 13.82 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 15.55it/s, est. speed input: 7096.50 toks/s, output: 13.86 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:04, 15.34it/s, est. speed input: 7111.34 toks/s, output: 13.89 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:04, 15.20it/s, est. speed input: 7125.33 toks/s, output: 13.92 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 15.11it/s, est. speed input: 7139.32 toks/s, output: 13.94 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:05<00:03, 15.02it/s, est. speed input: 7151.17 toks/s, output: 13.97 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:05<00:03, 14.94it/s, est. speed input: 7161.43 toks/s, output: 13.99 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:05<00:03, 14.84it/s, est. speed input: 7169.87 toks/s, output: 14.00 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:05<00:03, 14.74it/s, est. speed input: 7176.45 toks/s, output: 14.02 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:03, 14.77it/s, est. speed input: 7186.37 toks/s, output: 14.04 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:03, 14.80it/s, est. speed input: 7196.25 toks/s, output: 14.06 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:03, 14.76it/s, est. speed input: 7203.42 toks/s, output: 14.07 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:06<00:02, 14.72it/s, est. speed input: 7210.12 toks/s, output: 14.08 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:06<00:02, 14.69it/s, est. speed input: 7216.05 toks/s, output: 14.09 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:06<00:02, 14.70it/s, est. speed input: 7222.93 toks/s, output: 14.11 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:06<00:02, 14.70it/s, est. speed input: 7229.31 toks/s, output: 14.12 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:06<00:02, 14.73it/s, est. speed input: 7236.56 toks/s, output: 14.13 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:02, 14.81it/s, est. speed input: 7245.50 toks/s, output: 14.15 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:02, 14.89it/s, est. speed input: 7254.64 toks/s, output: 14.17 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 14.97it/s, est. speed input: 7264.26 toks/s, output: 14.19 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:07<00:01, 14.96it/s, est. speed input: 7271.40 toks/s, output: 14.20 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:07<00:01, 14.97it/s, est. speed input: 7279.02 toks/s, output: 14.22 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:07<00:01, 14.83it/s, est. speed input: 7281.68 toks/s, output: 14.22 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:07<00:01, 14.63it/s, est. speed input: 7281.26 toks/s, output: 14.22 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:07<00:01, 14.46it/s, est. speed input: 7280.04 toks/s, output: 14.22 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:01, 14.45it/s, est. speed input: 7281.92 toks/s, output: 14.22 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:01, 14.41it/s, est. speed input: 7282.82 toks/s, output: 14.22 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:08<00:00, 14.39it/s, est. speed input: 7283.92 toks/s, output: 14.23 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:08<00:00, 14.38it/s, est. speed input: 7284.86 toks/s, output: 14.23 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:08<00:00, 14.32it/s, est. speed input: 7284.54 toks/s, output: 14.23 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:08<00:00, 14.33it/s, est. speed input: 7285.62 toks/s, output: 14.23 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:08<00:00, 14.30it/s, est. speed input: 7285.64 toks/s, output: 14.23 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:08<00:00, 14.28it/s, est. speed input: 7285.56 toks/s, output: 14.23 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 14.30it/s, est. speed input: 7286.54 toks/s, output: 14.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 14.30it/s, est. speed input: 7288.50 toks/s, output: 14.24 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 14.23it/s, est. speed input: 7288.50 toks/s, output: 14.24 toks/s]
[rank0]:[W125 23:15:33.491008314 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 75.8s

测试结果:
  Requests/s:   13.76
  Tokens/s:     7058.37
  Total Reqs:   128
  Elapsed:      9.30s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     7044.61

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:15:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:15:47 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=527449) WARNING 01-25 23:15:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=527449) WARNING 01-25 23:16:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.42 requests/s, 14783.47 total tokens/s, 14.42 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:15:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:15:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:15:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:15:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:15:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:15:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:15:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:15:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:15:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:15:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:15:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:15:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:15:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:15:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:15:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:15:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:15:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=527449) [2026-01-25 23:15:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=527449) [2026-01-25 23:15:55] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=527449) [2026-01-25 23:15:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=527449) [2026-01-25 23:15:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=527449) [2026-01-25 23:15:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=527449) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=527449) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=527449) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07s/it]
(EngineCore_DP0 pid=527449) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]
(EngineCore_DP0 pid=527449) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=527449) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.50it/s]
(EngineCore_DP0 pid=527449) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▋        | 21/128 [00:00<00:00, 201.98it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 215.97it/s]
Adding requests:  55%|█████▍    | 70/128 [00:00<00:00, 233.49it/s]
Adding requests:  73%|███████▎  | 94/128 [00:00<00:00, 233.67it/s]
Adding requests:  92%|█████████▏| 118/128 [00:00<00:00, 235.36it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 230.11it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:04, 30.52it/s, est. speed input: 31254.14 toks/s, output: 30.52 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 18.85it/s, est. speed input: 20473.14 toks/s, output: 19.99 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:06, 17.09it/s, est. speed input: 18725.42 toks/s, output: 18.29 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 16.30it/s, est. speed input: 17998.29 toks/s, output: 17.58 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:07, 15.80it/s, est. speed input: 17528.05 toks/s, output: 17.12 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:07, 15.42it/s, est. speed input: 17167.59 toks/s, output: 16.76 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:07, 14.89it/s, est. speed input: 16778.29 toks/s, output: 16.38 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:07, 14.71it/s, est. speed input: 16548.53 toks/s, output: 16.16 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:07, 14.66it/s, est. speed input: 16387.17 toks/s, output: 16.00 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:07, 14.63it/s, est. speed input: 16257.76 toks/s, output: 15.88 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 14.60it/s, est. speed input: 16146.39 toks/s, output: 15.77 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:06, 14.57it/s, est. speed input: 16049.32 toks/s, output: 15.67 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:06, 14.55it/s, est. speed input: 15968.04 toks/s, output: 15.59 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 14.45it/s, est. speed input: 15874.30 toks/s, output: 15.50 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:06, 14.44it/s, est. speed input: 15806.85 toks/s, output: 15.44 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:06, 14.48it/s, est. speed input: 15755.85 toks/s, output: 15.39 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:06, 14.48it/s, est. speed input: 15704.94 toks/s, output: 15.34 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:06, 14.49it/s, est. speed input: 15661.38 toks/s, output: 15.29 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 14.49it/s, est. speed input: 15621.43 toks/s, output: 15.26 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 14.65it/s, est. speed input: 15611.29 toks/s, output: 15.25 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 14.72it/s, est. speed input: 15595.38 toks/s, output: 15.23 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 14.80it/s, est. speed input: 15585.54 toks/s, output: 15.22 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:05, 15.11it/s, est. speed input: 15610.39 toks/s, output: 15.24 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.47it/s, est. speed input: 15651.98 toks/s, output: 15.29 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 15.74it/s, est. speed input: 15691.03 toks/s, output: 15.32 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 15.89it/s, est. speed input: 15722.91 toks/s, output: 15.35 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 16.02it/s, est. speed input: 15755.01 toks/s, output: 15.39 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 16.19it/s, est. speed input: 15792.89 toks/s, output: 15.42 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 16.21it/s, est. speed input: 15818.24 toks/s, output: 15.45 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 16.06it/s, est. speed input: 15827.29 toks/s, output: 15.46 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 15.94it/s, est. speed input: 15832.71 toks/s, output: 15.46 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 15.90it/s, est. speed input: 15842.96 toks/s, output: 15.47 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 15.74it/s, est. speed input: 15839.90 toks/s, output: 15.47 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 15.78it/s, est. speed input: 15851.25 toks/s, output: 15.48 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 15.77it/s, est. speed input: 15858.13 toks/s, output: 15.49 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 15.75it/s, est. speed input: 15864.17 toks/s, output: 15.49 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:03, 15.81it/s, est. speed input: 15875.68 toks/s, output: 15.50 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 15.77it/s, est. speed input: 15879.80 toks/s, output: 15.51 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 15.74it/s, est. speed input: 15883.97 toks/s, output: 15.51 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 15.72it/s, est. speed input: 15888.09 toks/s, output: 15.52 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 15.72it/s, est. speed input: 15893.00 toks/s, output: 15.52 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 15.76it/s, est. speed input: 15900.58 toks/s, output: 15.53 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 15.72it/s, est. speed input: 15902.26 toks/s, output: 15.53 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 15.76it/s, est. speed input: 15909.26 toks/s, output: 15.54 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:02, 15.70it/s, est. speed input: 15910.25 toks/s, output: 15.54 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:02, 15.38it/s, est. speed input: 15891.37 toks/s, output: 15.52 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 15.19it/s, est. speed input: 15874.55 toks/s, output: 15.50 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 15.21it/s, est. speed input: 15869.84 toks/s, output: 15.50 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 15.22it/s, est. speed input: 15864.79 toks/s, output: 15.49 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 15.26it/s, est. speed input: 15861.86 toks/s, output: 15.49 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 15.13it/s, est. speed input: 15848.78 toks/s, output: 15.48 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:07<00:01, 15.12it/s, est. speed input: 15841.65 toks/s, output: 15.47 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:01, 15.17it/s, est. speed input: 15838.30 toks/s, output: 15.47 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:00, 15.12it/s, est. speed input: 15829.38 toks/s, output: 15.46 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 15.01it/s, est. speed input: 15816.15 toks/s, output: 15.45 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 14.97it/s, est. speed input: 15806.35 toks/s, output: 15.44 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 14.98it/s, est. speed input: 15798.33 toks/s, output: 15.43 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 14.94it/s, est. speed input: 15788.35 toks/s, output: 15.42 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 14.94it/s, est. speed input: 15780.20 toks/s, output: 15.41 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:08<00:00, 14.98it/s, est. speed input: 15774.36 toks/s, output: 15.40 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 14.98it/s, est. speed input: 15767.52 toks/s, output: 15.40 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 14.98it/s, est. speed input: 15760.32 toks/s, output: 15.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.39it/s, est. speed input: 15760.32 toks/s, output: 15.39 toks/s]
[rank0]:[W125 23:16:36.685477750 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 63.2s

测试结果:
  Requests/s:   14.42
  Tokens/s:     14783.47
  Total Reqs:   128
  Elapsed:      8.87s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     14769.05

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:16:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:16:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=528626) WARNING 01-25 23:16:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=528626) WARNING 01-25 23:17:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.80 requests/s, 19271.53 total tokens/s, 18.80 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 23:16:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:16:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:16:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:16:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:16:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:16:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:16:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:16:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:16:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:16:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:16:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:16:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:16:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:16:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:16:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:16:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:16:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=528626) [2026-01-25 23:16:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=528626) [2026-01-25 23:16:58] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=528626) [2026-01-25 23:16:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=528626) [2026-01-25 23:16:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=528626) [2026-01-25 23:16:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=528626) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=528626) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=528626) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.03s/it]
(EngineCore_DP0 pid=528626) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=528626) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=528626) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [-1:59:59<00:00, -2.43it/s]
(EngineCore_DP0 pid=528626) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.83it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 24/256 [00:00<00:00, 232.85it/s]
Adding requests:  19%|█▉        | 49/256 [00:00<00:00, 237.29it/s]
Adding requests:  30%|██▉       | 76/256 [00:00<00:00, 250.37it/s]
Adding requests:  40%|███▉      | 102/256 [00:00<00:00, 252.04it/s]
Adding requests:  50%|█████     | 128/256 [00:00<00:00, 254.03it/s]
Adding requests:  60%|██████    | 154/256 [00:00<00:00, 254.44it/s]
Adding requests:  70%|███████   | 180/256 [00:00<00:00, 255.75it/s]
Adding requests:  80%|████████  | 206/256 [00:00<00:00, 251.30it/s]
Adding requests:  91%|█████████ | 232/256 [00:00<00:00, 247.65it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 247.61it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:02, 97.08it/s, est. speed input: 99437.57 toks/s, output: 97.09 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:08, 28.90it/s, est. speed input: 33084.68 toks/s, output: 32.31 toks/s]
Processed prompts:  10%|█         | 26/256 [00:00<00:09, 24.80it/s, est. speed input: 28658.15 toks/s, output: 27.99 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:01<00:09, 23.17it/s, est. speed input: 27016.16 toks/s, output: 26.38 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:01<00:09, 24.18it/s, est. speed input: 27241.82 toks/s, output: 26.60 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:10, 21.00it/s, est. speed input: 25474.93 toks/s, output: 24.88 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:01<00:09, 22.51it/s, est. speed input: 25748.82 toks/s, output: 25.15 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:01<00:10, 19.68it/s, est. speed input: 24462.56 toks/s, output: 23.89 toks/s]
Processed prompts:  18%|█▊        | 45/256 [00:01<00:09, 21.55it/s, est. speed input: 24751.48 toks/s, output: 24.17 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:02<00:10, 18.96it/s, est. speed input: 23753.66 toks/s, output: 23.20 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:02<00:09, 21.04it/s, est. speed input: 24038.18 toks/s, output: 23.47 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:10, 18.61it/s, est. speed input: 23239.83 toks/s, output: 22.69 toks/s]
Processed prompts:  22%|██▏       | 57/256 [00:02<00:09, 20.80it/s, est. speed input: 23510.34 toks/s, output: 22.96 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:10, 18.41it/s, est. speed input: 22837.58 toks/s, output: 22.30 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:02<00:09, 20.62it/s, est. speed input: 23087.18 toks/s, output: 22.55 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:03<00:10, 18.28it/s, est. speed input: 22509.81 toks/s, output: 21.98 toks/s]
Processed prompts:  27%|██▋       | 69/256 [00:03<00:09, 20.52it/s, est. speed input: 22743.87 toks/s, output: 22.21 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:10, 18.27it/s, est. speed input: 22253.73 toks/s, output: 21.73 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:03<00:08, 20.57it/s, est. speed input: 22482.96 toks/s, output: 21.96 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 18.29it/s, est. speed input: 22048.83 toks/s, output: 21.53 toks/s]
Processed prompts:  32%|███▏      | 81/256 [00:03<00:08, 20.58it/s, est. speed input: 22263.04 toks/s, output: 21.74 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:09, 18.25it/s, est. speed input: 21868.34 toks/s, output: 21.36 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:04<00:08, 20.51it/s, est. speed input: 22066.10 toks/s, output: 21.55 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:04<00:09, 18.24it/s, est. speed input: 21713.28 toks/s, output: 21.20 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:04<00:07, 20.48it/s, est. speed input: 21898.36 toks/s, output: 21.39 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 18.22it/s, est. speed input: 21576.90 toks/s, output: 21.07 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:04<00:07, 20.50it/s, est. speed input: 21756.32 toks/s, output: 21.25 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:08, 18.24it/s, est. speed input: 21463.54 toks/s, output: 20.96 toks/s]
Processed prompts:  41%|████      | 105/256 [00:04<00:07, 20.50it/s, est. speed input: 21631.98 toks/s, output: 21.12 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:05<00:08, 18.37it/s, est. speed input: 21377.30 toks/s, output: 20.88 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:07, 19.22it/s, est. speed input: 21378.30 toks/s, output: 20.88 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:05<00:07, 19.76it/s, est. speed input: 21379.35 toks/s, output: 20.88 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:06, 20.12it/s, est. speed input: 21379.72 toks/s, output: 20.88 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:06, 20.34it/s, est. speed input: 21378.43 toks/s, output: 20.88 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:06<00:06, 20.51it/s, est. speed input: 21378.52 toks/s, output: 20.88 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:06<00:06, 20.63it/s, est. speed input: 21379.15 toks/s, output: 20.88 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:05, 20.72it/s, est. speed input: 21380.86 toks/s, output: 20.88 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:06<00:05, 20.78it/s, est. speed input: 21382.27 toks/s, output: 20.88 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:05, 20.84it/s, est. speed input: 21384.49 toks/s, output: 20.88 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:07<00:05, 20.88it/s, est. speed input: 21386.96 toks/s, output: 20.89 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:07<00:04, 20.89it/s, est. speed input: 21387.74 toks/s, output: 20.89 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:04, 20.88it/s, est. speed input: 21386.83 toks/s, output: 20.89 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:07<00:04, 20.89it/s, est. speed input: 21387.53 toks/s, output: 20.89 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:07<00:04, 22.48it/s, est. speed input: 21502.69 toks/s, output: 21.00 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:07<00:04, 19.66it/s, est. speed input: 21327.86 toks/s, output: 20.83 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:08<00:04, 21.51it/s, est. speed input: 21433.96 toks/s, output: 20.93 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:08<00:04, 18.91it/s, est. speed input: 21265.68 toks/s, output: 20.77 toks/s]
Processed prompts:  68%|██████▊   | 175/256 [00:08<00:03, 20.98it/s, est. speed input: 21369.34 toks/s, output: 20.87 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:08<00:04, 18.55it/s, est. speed input: 21210.09 toks/s, output: 20.71 toks/s]
Processed prompts:  71%|███████   | 181/256 [00:08<00:03, 20.72it/s, est. speed input: 21310.17 toks/s, output: 20.81 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:08<00:03, 18.35it/s, est. speed input: 21156.83 toks/s, output: 20.66 toks/s]
Processed prompts:  73%|███████▎  | 187/256 [00:09<00:03, 20.56it/s, est. speed input: 21252.97 toks/s, output: 20.75 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:09<00:03, 18.25it/s, est. speed input: 21106.62 toks/s, output: 20.61 toks/s]
Processed prompts:  75%|███████▌  | 193/256 [00:09<00:03, 20.49it/s, est. speed input: 21200.56 toks/s, output: 20.70 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:09<00:03, 18.23it/s, est. speed input: 21061.71 toks/s, output: 20.57 toks/s]
Processed prompts:  78%|███████▊  | 199/256 [00:09<00:02, 20.50it/s, est. speed input: 21153.92 toks/s, output: 20.66 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:09<00:02, 19.48it/s, est. speed input: 21096.50 toks/s, output: 20.60 toks/s]
Processed prompts:  80%|████████  | 205/256 [00:09<00:02, 21.61it/s, est. speed input: 21186.55 toks/s, output: 20.69 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:10<00:02, 18.82it/s, est. speed input: 21055.85 toks/s, output: 20.56 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:10<00:02, 21.00it/s, est. speed input: 21141.58 toks/s, output: 20.65 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:10<00:02, 18.50it/s, est. speed input: 21015.83 toks/s, output: 20.52 toks/s]
Processed prompts:  85%|████████▍ | 217/256 [00:10<00:01, 20.73it/s, est. speed input: 21100.30 toks/s, output: 20.61 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:10<00:01, 18.30it/s, est. speed input: 20975.88 toks/s, output: 20.48 toks/s]
Processed prompts:  87%|████████▋ | 223/256 [00:10<00:01, 20.56it/s, est. speed input: 21058.30 toks/s, output: 20.56 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:11<00:01, 18.25it/s, est. speed input: 20940.94 toks/s, output: 20.45 toks/s]
Processed prompts:  89%|████████▉ | 229/256 [00:11<00:01, 20.52it/s, est. speed input: 21021.36 toks/s, output: 20.53 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:11<00:01, 18.18it/s, est. speed input: 20905.56 toks/s, output: 20.42 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:11<00:01, 20.46it/s, est. speed input: 20984.18 toks/s, output: 20.49 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:11<00:00, 18.16it/s, est. speed input: 20872.34 toks/s, output: 20.38 toks/s]
Processed prompts:  94%|█████████▍| 241/256 [00:11<00:00, 20.42it/s, est. speed input: 20948.41 toks/s, output: 20.46 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:11<00:00, 18.12it/s, est. speed input: 20839.43 toks/s, output: 20.35 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:12<00:00, 20.36it/s, est. speed input: 20912.88 toks/s, output: 20.42 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:12<00:00, 18.09it/s, est. speed input: 20807.37 toks/s, output: 20.32 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:12<00:00, 20.37it/s, est. speed input: 20880.51 toks/s, output: 20.39 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 19.36it/s, est. speed input: 20837.77 toks/s, output: 20.35 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 19.36it/s, est. speed input: 20837.77 toks/s, output: 20.35 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.35it/s, est. speed input: 20837.77 toks/s, output: 20.35 toks/s]
[rank0]:[W125 23:17:43.079429291 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 66.7s

测试结果:
  Requests/s:   18.80
  Tokens/s:     19271.53
  Total Reqs:   256
  Elapsed:      13.62s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     19252.73

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:17:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:18:00 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=529902) WARNING 01-25 23:18:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=529902) WARNING 01-25 23:18:18 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.82 requests/s, 20320.52 total tokens/s, 19.82 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 23:17:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:17:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:17:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:17:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:17:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:17:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:17:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:17:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:17:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:18:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:18:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:18:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:18:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:18:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:18:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:18:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:18:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:18:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=529902) [2026-01-25 23:18:07] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=529902) [2026-01-25 23:18:07] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=529902) [2026-01-25 23:18:07] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=529902) [2026-01-25 23:18:07] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=529902) [2026-01-25 23:18:07] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=529902) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=529902) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.31it/s]
(EngineCore_DP0 pid=529902) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=529902) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.08it/s]
(EngineCore_DP0 pid=529902) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=529902) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.32it/s]
(EngineCore_DP0 pid=529902) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  5.48it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  5.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.73it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 21/512 [00:00<00:02, 202.30it/s]
Adding requests:   9%|▉         | 45/512 [00:00<00:02, 219.88it/s]
Adding requests:  14%|█▎        | 70/512 [00:00<00:01, 230.59it/s]
Adding requests:  18%|█▊        | 94/512 [00:00<00:01, 227.90it/s]
Adding requests:  23%|██▎       | 118/512 [00:00<00:01, 227.41it/s]
Adding requests:  28%|██▊       | 141/512 [00:00<00:01, 224.89it/s]
Adding requests:  32%|███▏      | 164/512 [00:00<00:01, 224.87it/s]
Adding requests:  37%|███▋      | 189/512 [00:00<00:01, 230.64it/s]
Adding requests:  42%|████▏     | 214/512 [00:00<00:01, 234.18it/s]
Adding requests:  47%|████▋     | 239/512 [00:01<00:01, 235.96it/s]
Adding requests:  51%|█████▏    | 263/512 [00:01<00:01, 235.73it/s]
Adding requests:  56%|█████▌    | 287/512 [00:01<00:00, 234.59it/s]
Adding requests:  61%|██████    | 312/512 [00:01<00:00, 237.93it/s]
Adding requests:  66%|██████▌   | 338/512 [00:01<00:00, 241.73it/s]
Adding requests:  71%|███████   | 363/512 [00:01<00:00, 243.78it/s]
Adding requests:  76%|███████▌  | 388/512 [00:01<00:00, 243.13it/s]
Adding requests:  81%|████████  | 415/512 [00:01<00:00, 248.24it/s]
Adding requests:  86%|████████▌ | 440/512 [00:01<00:00, 245.35it/s]
Adding requests:  91%|█████████ | 465/512 [00:01<00:00, 241.20it/s]
Adding requests:  96%|█████████▋| 493/512 [00:02<00:00, 250.16it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 237.74it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:00<00:02, 234.89it/s, est. speed input: 240577.88 toks/s, output: 234.91 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:01<00:11, 37.79it/s, est. speed input: 45756.73 toks/s, output: 44.68 toks/s]   
Processed prompts:  14%|█▍        | 73/512 [00:01<00:12, 34.69it/s, est. speed input: 41794.49 toks/s, output: 40.81 toks/s]
Processed prompts:  16%|█▌        | 81/512 [00:02<00:13, 30.80it/s, est. speed input: 38282.25 toks/s, output: 37.38 toks/s]
Processed prompts:  17%|█▋        | 87/512 [00:02<00:16, 26.46it/s, est. speed input: 35015.10 toks/s, output: 34.19 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:02<00:16, 25.54it/s, est. speed input: 34089.71 toks/s, output: 33.29 toks/s]
Processed prompts:  19%|█▊        | 95/512 [00:02<00:16, 24.68it/s, est. speed input: 33286.93 toks/s, output: 32.51 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:18, 22.75it/s, est. speed input: 32253.98 toks/s, output: 31.50 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:18, 22.36it/s, est. speed input: 31644.69 toks/s, output: 30.90 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:18, 22.06it/s, est. speed input: 31104.96 toks/s, output: 30.38 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:18, 21.83it/s, est. speed input: 30622.87 toks/s, output: 29.90 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:03<00:18, 21.30it/s, est. speed input: 30099.67 toks/s, output: 29.39 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:18, 20.78it/s, est. speed input: 29593.42 toks/s, output: 28.90 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:19, 20.42it/s, est. speed input: 29138.80 toks/s, output: 28.46 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:19, 20.17it/s, est. speed input: 28723.81 toks/s, output: 28.05 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:19, 20.00it/s, est. speed input: 28348.38 toks/s, output: 27.68 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:19, 19.86it/s, est. speed input: 27999.32 toks/s, output: 27.34 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:18, 19.77it/s, est. speed input: 27679.32 toks/s, output: 27.03 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:18, 19.69it/s, est. speed input: 27381.94 toks/s, output: 26.74 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:18, 19.65it/s, est. speed input: 27108.97 toks/s, output: 26.47 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:18, 19.61it/s, est. speed input: 26853.85 toks/s, output: 26.22 toks/s]
Processed prompts:  30%|███       | 154/512 [00:05<00:18, 19.59it/s, est. speed input: 26616.98 toks/s, output: 25.99 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:18, 19.56it/s, est. speed input: 26395.09 toks/s, output: 25.78 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:17, 19.55it/s, est. speed input: 26186.93 toks/s, output: 25.57 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:17, 19.54it/s, est. speed input: 25992.51 toks/s, output: 25.38 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:17, 19.53it/s, est. speed input: 25810.20 toks/s, output: 25.21 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:06<00:17, 19.52it/s, est. speed input: 25637.69 toks/s, output: 25.04 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:17, 19.53it/s, est. speed input: 25476.37 toks/s, output: 24.88 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:16, 19.54it/s, est. speed input: 25325.51 toks/s, output: 24.73 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:07<00:16, 19.56it/s, est. speed input: 25183.61 toks/s, output: 24.59 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:16, 19.57it/s, est. speed input: 25049.25 toks/s, output: 24.46 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:07<00:16, 19.55it/s, est. speed input: 24918.24 toks/s, output: 24.33 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:16, 19.53it/s, est. speed input: 24793.81 toks/s, output: 24.21 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:14, 20.95it/s, est. speed input: 24813.56 toks/s, output: 24.23 toks/s]
Processed prompts:  40%|████      | 206/512 [00:08<00:14, 20.50it/s, est. speed input: 24698.02 toks/s, output: 24.12 toks/s]
Processed prompts:  41%|████      | 210/512 [00:08<00:14, 20.20it/s, est. speed input: 24587.86 toks/s, output: 24.01 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:14, 19.98it/s, est. speed input: 24481.69 toks/s, output: 23.91 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:14, 19.83it/s, est. speed input: 24380.28 toks/s, output: 23.81 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:14, 19.73it/s, est. speed input: 24283.31 toks/s, output: 23.71 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:09<00:14, 20.00it/s, est. speed input: 24220.24 toks/s, output: 23.65 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:09<00:13, 20.32it/s, est. speed input: 24169.61 toks/s, output: 23.60 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:13, 20.56it/s, est. speed input: 24121.37 toks/s, output: 23.56 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:13, 20.74it/s, est. speed input: 24076.18 toks/s, output: 23.51 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:12, 20.85it/s, est. speed input: 24031.11 toks/s, output: 23.47 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:10<00:12, 20.95it/s, est. speed input: 23988.60 toks/s, output: 23.43 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:10<00:12, 21.03it/s, est. speed input: 23948.67 toks/s, output: 23.39 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:10<00:12, 21.05it/s, est. speed input: 23908.14 toks/s, output: 23.35 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:12, 21.07it/s, est. speed input: 23868.74 toks/s, output: 23.31 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:11, 21.07it/s, est. speed input: 23829.90 toks/s, output: 23.27 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:11<00:11, 21.08it/s, est. speed input: 23793.47 toks/s, output: 23.24 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:11<00:11, 21.09it/s, est. speed input: 23757.72 toks/s, output: 23.20 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:11<00:11, 21.00it/s, est. speed input: 23718.04 toks/s, output: 23.16 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:12<00:11, 20.52it/s, est. speed input: 23653.54 toks/s, output: 23.10 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:11, 20.20it/s, est. speed input: 23591.77 toks/s, output: 23.04 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:12<00:11, 19.97it/s, est. speed input: 23531.31 toks/s, output: 22.98 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:12<00:11, 19.82it/s, est. speed input: 23472.92 toks/s, output: 22.92 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:12<00:11, 19.72it/s, est. speed input: 23416.81 toks/s, output: 22.87 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:13<00:10, 19.64it/s, est. speed input: 23362.09 toks/s, output: 22.81 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:10, 19.60it/s, est. speed input: 23309.54 toks/s, output: 22.76 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:13<00:10, 19.57it/s, est. speed input: 23258.87 toks/s, output: 22.71 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:13<00:10, 19.55it/s, est. speed input: 23209.68 toks/s, output: 22.67 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:13<00:10, 19.54it/s, est. speed input: 23162.06 toks/s, output: 22.62 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:14<00:09, 19.52it/s, est. speed input: 23114.87 toks/s, output: 22.57 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:09, 19.50it/s, est. speed input: 23069.06 toks/s, output: 22.53 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:14<00:09, 19.49it/s, est. speed input: 23024.56 toks/s, output: 22.48 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:14<00:09, 19.46it/s, est. speed input: 22980.26 toks/s, output: 22.44 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:14<00:09, 19.46it/s, est. speed input: 22937.94 toks/s, output: 22.40 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:15<00:08, 19.44it/s, est. speed input: 22896.22 toks/s, output: 22.36 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:15<00:08, 19.45it/s, est. speed input: 22856.39 toks/s, output: 22.32 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:15<00:08, 19.44it/s, est. speed input: 22817.21 toks/s, output: 22.28 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:15<00:08, 19.44it/s, est. speed input: 22779.10 toks/s, output: 22.25 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:15<00:08, 19.45it/s, est. speed input: 22742.27 toks/s, output: 22.21 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:16<00:07, 19.44it/s, est. speed input: 22706.04 toks/s, output: 22.17 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:16<00:07, 19.43it/s, est. speed input: 22670.33 toks/s, output: 22.14 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:16<00:07, 19.42it/s, est. speed input: 22635.27 toks/s, output: 22.10 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:16<00:07, 19.43it/s, est. speed input: 22602.14 toks/s, output: 22.07 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:16<00:07, 19.49it/s, est. speed input: 22571.97 toks/s, output: 22.04 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:17<00:06, 19.93it/s, est. speed input: 22560.74 toks/s, output: 22.03 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:17<00:06, 20.26it/s, est. speed input: 22550.07 toks/s, output: 22.02 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:17<00:06, 20.49it/s, est. speed input: 22539.33 toks/s, output: 22.01 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:17<00:05, 20.65it/s, est. speed input: 22528.65 toks/s, output: 22.00 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:17<00:05, 20.79it/s, est. speed input: 22518.91 toks/s, output: 21.99 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:18<00:05, 20.86it/s, est. speed input: 22508.77 toks/s, output: 21.98 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:18<00:05, 20.93it/s, est. speed input: 22499.35 toks/s, output: 21.97 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:18<00:05, 20.98it/s, est. speed input: 22489.94 toks/s, output: 21.96 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:18<00:04, 21.00it/s, est. speed input: 22480.53 toks/s, output: 21.95 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:18<00:04, 21.02it/s, est. speed input: 22471.39 toks/s, output: 21.94 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:19<00:04, 21.04it/s, est. speed input: 22462.54 toks/s, output: 21.94 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:19<00:04, 21.03it/s, est. speed input: 22453.28 toks/s, output: 21.93 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:19<00:04, 21.05it/s, est. speed input: 22444.99 toks/s, output: 21.92 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:19<00:03, 21.07it/s, est. speed input: 22437.05 toks/s, output: 21.91 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:19<00:03, 21.07it/s, est. speed input: 22428.78 toks/s, output: 21.90 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:20<00:03, 20.59it/s, est. speed input: 22404.32 toks/s, output: 21.88 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:20<00:03, 20.25it/s, est. speed input: 22379.53 toks/s, output: 21.85 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:20<00:03, 20.00it/s, est. speed input: 22354.55 toks/s, output: 21.83 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:20<00:03, 19.83it/s, est. speed input: 22330.20 toks/s, output: 21.81 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:20<00:02, 19.71it/s, est. speed input: 22306.12 toks/s, output: 21.78 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:21<00:02, 19.63it/s, est. speed input: 22282.62 toks/s, output: 21.76 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:21<00:02, 19.57it/s, est. speed input: 22259.69 toks/s, output: 21.74 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:21<00:02, 19.53it/s, est. speed input: 22237.06 toks/s, output: 21.72 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:21<00:02, 19.50it/s, est. speed input: 22214.80 toks/s, output: 21.69 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:21<00:01, 19.49it/s, est. speed input: 22193.25 toks/s, output: 21.67 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 19.49it/s, est. speed input: 23889.12 toks/s, output: 23.33 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 23.33it/s, est. speed input: 23889.12 toks/s, output: 23.33 toks/s]
[rank0]:[W125 23:19:01.439275812 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 78.8s

测试结果:
  Requests/s:   19.82
  Tokens/s:     20320.52
  Total Reqs:   512
  Elapsed:      25.83s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     20300.69

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:19:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:19:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=531298) WARNING 01-25 23:19:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=531298) WARNING 01-25 23:19:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.17 requests/s, 20669.33 total tokens/s, 20.17 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 23:19:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:19:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:19:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:19:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:19:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:19:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:19:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=531298) [2026-01-25 23:19:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=531298) [2026-01-25 23:19:32] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=531298) [2026-01-25 23:19:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=531298) [2026-01-25 23:19:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=531298) [2026-01-25 23:19:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=531298) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=531298) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  6.89it/s]
(EngineCore_DP0 pid=531298) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  6.88it/s]
(EngineCore_DP0 pid=531298) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=531298) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  5.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  5.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]
(EngineCore_DP0 pid=531298) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  4.42it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  2.77it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  3.44it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  2.58it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 217.55it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 239.52it/s]
Adding requests:   7%|▋         | 76/1024 [00:00<00:03, 253.09it/s]
Adding requests:  10%|▉         | 102/1024 [00:00<00:03, 255.06it/s]
Adding requests:  12%|█▎        | 128/1024 [00:00<00:03, 254.67it/s]
Adding requests:  15%|█▌        | 154/1024 [00:00<00:03, 253.01it/s]
Adding requests:  18%|█▊        | 181/1024 [00:00<00:03, 257.07it/s]
Adding requests:  20%|██        | 208/1024 [00:00<00:03, 258.90it/s]
Adding requests:  23%|██▎       | 235/1024 [00:00<00:03, 260.83it/s]
Adding requests:  26%|██▌       | 262/1024 [00:01<00:02, 256.23it/s]
Adding requests:  28%|██▊       | 288/1024 [00:01<00:02, 256.61it/s]
Adding requests:  31%|███       | 316/1024 [00:01<00:02, 262.92it/s]
Adding requests:  33%|███▎      | 343/1024 [00:01<00:02, 261.52it/s]
Adding requests:  36%|███▌      | 370/1024 [00:01<00:02, 263.35it/s]
Adding requests:  39%|███▉      | 397/1024 [00:01<00:02, 263.71it/s]
Adding requests:  42%|████▏     | 426/1024 [00:01<00:02, 270.20it/s]
Adding requests:  44%|████▍     | 454/1024 [00:01<00:02, 269.79it/s]
Adding requests:  47%|████▋     | 483/1024 [00:01<00:01, 273.30it/s]
Adding requests:  50%|█████     | 513/1024 [00:01<00:01, 279.36it/s]
Adding requests:  53%|█████▎    | 543/1024 [00:02<00:01, 283.76it/s]
Adding requests:  56%|█████▌    | 572/1024 [00:02<00:01, 280.51it/s]
Adding requests:  59%|█████▊    | 601/1024 [00:02<00:01, 266.00it/s]
Adding requests:  61%|██████▏   | 628/1024 [00:02<00:01, 256.50it/s]
Adding requests:  64%|██████▍   | 654/1024 [00:02<00:01, 248.23it/s]
Adding requests:  66%|██████▋   | 679/1024 [00:02<00:01, 243.43it/s]
Adding requests:  69%|██████▉   | 705/1024 [00:02<00:01, 246.12it/s]
Adding requests:  71%|███████▏  | 730/1024 [00:02<00:01, 239.15it/s]
Adding requests:  74%|███████▎  | 755/1024 [00:02<00:01, 238.93it/s]
Adding requests:  76%|███████▌  | 780/1024 [00:03<00:01, 240.87it/s]
Adding requests:  79%|███████▊  | 805/1024 [00:03<00:00, 240.98it/s]
Adding requests:  81%|████████  | 831/1024 [00:03<00:00, 245.86it/s]
Adding requests:  84%|████████▎ | 856/1024 [00:03<00:00, 245.68it/s]
Adding requests:  86%|████████▌ | 881/1024 [00:03<00:00, 244.26it/s]
Adding requests:  88%|████████▊ | 906/1024 [00:03<00:00, 245.25it/s]
Adding requests:  91%|█████████ | 931/1024 [00:03<00:00, 235.01it/s]
Adding requests:  93%|█████████▎| 957/1024 [00:03<00:00, 238.75it/s]
Adding requests:  96%|█████████▌| 981/1024 [00:03<00:00, 237.06it/s]
Adding requests:  98%|█████████▊| 1005/1024 [00:03<00:00, 233.81it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 252.25it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:00<00:06, 155.70it/s, est. speed input: 159449.14 toks/s, output: 155.71 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:01<00:15, 59.66it/s, est. speed input: 72057.35 toks/s, output: 70.36 toks/s]   
Processed prompts:  10%|▉         | 98/1024 [00:01<00:19, 46.35it/s, est. speed input: 59731.79 toks/s, output: 58.33 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:02<00:24, 37.80it/s, est. speed input: 52151.81 toks/s, output: 50.93 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:02<00:28, 32.12it/s, est. speed input: 47000.37 toks/s, output: 45.90 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:02<00:31, 28.31it/s, est. speed input: 43289.80 toks/s, output: 42.27 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:34, 25.72it/s, est. speed input: 40490.61 toks/s, output: 39.54 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:03<00:37, 23.94it/s, est. speed input: 38297.81 toks/s, output: 37.40 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:04<00:37, 23.13it/s, est. speed input: 36750.71 toks/s, output: 35.89 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:38, 22.68it/s, est. speed input: 35524.51 toks/s, output: 34.69 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:04<00:38, 22.36it/s, est. speed input: 34490.35 toks/s, output: 33.68 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:05<00:38, 22.12it/s, est. speed input: 33599.46 toks/s, output: 32.81 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:38, 21.96it/s, est. speed input: 32830.64 toks/s, output: 32.06 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:05<00:38, 21.83it/s, est. speed input: 32155.00 toks/s, output: 31.40 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:06<00:38, 21.58it/s, est. speed input: 31512.87 toks/s, output: 30.77 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:37, 21.74it/s, est. speed input: 31032.46 toks/s, output: 30.31 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:07<00:38, 21.15it/s, est. speed input: 30425.14 toks/s, output: 29.71 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:38, 20.76it/s, est. speed input: 29883.29 toks/s, output: 29.18 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:38, 20.50it/s, est. speed input: 29397.99 toks/s, output: 28.71 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:08<00:38, 20.31it/s, est. speed input: 28959.43 toks/s, output: 28.28 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:38, 20.18it/s, est. speed input: 28559.81 toks/s, output: 27.89 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:09<00:38, 20.08it/s, est. speed input: 28194.73 toks/s, output: 27.53 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:09<00:38, 20.03it/s, est. speed input: 27863.36 toks/s, output: 27.21 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:37, 19.97it/s, est. speed input: 27555.59 toks/s, output: 26.91 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:10<00:37, 19.95it/s, est. speed input: 27274.82 toks/s, output: 26.64 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:10<00:37, 19.92it/s, est. speed input: 27012.97 toks/s, output: 26.38 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:11<00:36, 19.90it/s, est. speed input: 26769.99 toks/s, output: 26.14 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:11<00:36, 19.89it/s, est. speed input: 26545.01 toks/s, output: 25.92 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:35, 20.13it/s, est. speed input: 26371.88 toks/s, output: 25.75 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:12<00:34, 20.52it/s, est. speed input: 26239.58 toks/s, output: 25.62 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:12<00:33, 20.81it/s, est. speed input: 26114.90 toks/s, output: 25.50 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:33, 21.01it/s, est. speed input: 25998.21 toks/s, output: 25.39 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:13<00:32, 21.15it/s, est. speed input: 25886.65 toks/s, output: 25.28 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:13<00:31, 21.25it/s, est. speed input: 25781.42 toks/s, output: 25.18 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:14<00:31, 21.33it/s, est. speed input: 25682.28 toks/s, output: 25.08 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:14<00:31, 21.00it/s, est. speed input: 25548.14 toks/s, output: 24.95 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:14<00:31, 20.63it/s, est. speed input: 25406.38 toks/s, output: 24.81 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:15<00:31, 20.38it/s, est. speed input: 25271.11 toks/s, output: 24.68 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:15<00:31, 20.20it/s, est. speed input: 25142.68 toks/s, output: 24.55 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:16<00:31, 20.08it/s, est. speed input: 25021.19 toks/s, output: 24.43 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:16<00:31, 20.00it/s, est. speed input: 24905.62 toks/s, output: 24.32 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:16<00:30, 19.94it/s, est. speed input: 24794.78 toks/s, output: 24.21 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:17<00:30, 19.90it/s, est. speed input: 24689.71 toks/s, output: 24.11 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:17<00:30, 19.87it/s, est. speed input: 24589.25 toks/s, output: 24.01 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:18<00:29, 19.84it/s, est. speed input: 24492.24 toks/s, output: 23.92 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:18<00:29, 19.82it/s, est. speed input: 24399.56 toks/s, output: 23.83 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:18<00:28, 19.81it/s, est. speed input: 24311.50 toks/s, output: 23.74 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:19<00:28, 19.80it/s, est. speed input: 24226.76 toks/s, output: 23.66 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:19<00:27, 20.22it/s, est. speed input: 24179.74 toks/s, output: 23.61 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:20<00:26, 20.57it/s, est. speed input: 24138.35 toks/s, output: 23.57 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:20<00:26, 20.82it/s, est. speed input: 24098.56 toks/s, output: 23.53 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:20<00:25, 21.01it/s, est. speed input: 24060.34 toks/s, output: 23.50 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:21<00:24, 21.13it/s, est. speed input: 24022.95 toks/s, output: 23.46 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:21<00:24, 21.21it/s, est. speed input: 23986.29 toks/s, output: 23.42 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:21<00:23, 21.27it/s, est. speed input: 23951.22 toks/s, output: 23.39 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:22<00:23, 21.16it/s, est. speed input: 23907.61 toks/s, output: 23.35 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:22<00:23, 20.72it/s, est. speed input: 23842.20 toks/s, output: 23.28 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:23<00:23, 20.42it/s, est. speed input: 23779.44 toks/s, output: 23.22 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:23<00:23, 20.23it/s, est. speed input: 23719.02 toks/s, output: 23.16 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:23<00:23, 20.08it/s, est. speed input: 23659.87 toks/s, output: 23.11 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:24<00:23, 19.97it/s, est. speed input: 23602.35 toks/s, output: 23.05 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:24<00:22, 19.91it/s, est. speed input: 23547.25 toks/s, output: 23.00 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:25<00:22, 19.86it/s, est. speed input: 23494.07 toks/s, output: 22.94 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:25<00:22, 19.83it/s, est. speed input: 23442.52 toks/s, output: 22.89 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:26<00:21, 19.81it/s, est. speed input: 23392.48 toks/s, output: 22.84 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:26<00:21, 19.80it/s, est. speed input: 23344.21 toks/s, output: 22.80 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:26<00:20, 19.79it/s, est. speed input: 23297.35 toks/s, output: 22.75 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:27<00:20, 19.78it/s, est. speed input: 23251.86 toks/s, output: 22.71 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:27<00:20, 19.88it/s, est. speed input: 23213.85 toks/s, output: 22.67 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:27<00:19, 20.32it/s, est. speed input: 23196.69 toks/s, output: 22.65 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:28<00:06, 52.17it/s, est. speed input: 24480.04 toks/s, output: 23.91 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:28<00:08, 42.28it/s, est. speed input: 24447.02 toks/s, output: 23.87 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:28<00:09, 35.71it/s, est. speed input: 24414.48 toks/s, output: 23.84 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:29<00:10, 31.27it/s, est. speed input: 24382.71 toks/s, output: 23.81 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:29<00:11, 28.25it/s, est. speed input: 24352.06 toks/s, output: 23.78 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:30<00:11, 26.15it/s, est. speed input: 24321.49 toks/s, output: 23.75 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:30<00:12, 24.43it/s, est. speed input: 24280.71 toks/s, output: 23.71 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:30<00:12, 22.95it/s, est. speed input: 24227.45 toks/s, output: 23.66 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:31<00:13, 21.95it/s, est. speed input: 24175.66 toks/s, output: 23.61 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:31<00:13, 21.28it/s, est. speed input: 24125.40 toks/s, output: 23.56 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:32<00:12, 20.81it/s, est. speed input: 24076.01 toks/s, output: 23.51 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:32<00:12, 20.48it/s, est. speed input: 24027.57 toks/s, output: 23.46 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:32<00:12, 20.26it/s, est. speed input: 23981.02 toks/s, output: 23.42 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:33<00:12, 20.10it/s, est. speed input: 23935.05 toks/s, output: 23.37 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:33<00:11, 20.62it/s, est. speed input: 23919.37 toks/s, output: 23.36 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:34<00:11, 20.35it/s, est. speed input: 23875.22 toks/s, output: 23.32 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:34<00:11, 20.16it/s, est. speed input: 23832.16 toks/s, output: 23.27 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:34<00:10, 20.04it/s, est. speed input: 23790.18 toks/s, output: 23.23 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:35<00:10, 19.96it/s, est. speed input: 23749.78 toks/s, output: 23.19 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:35<00:09, 19.91it/s, est. speed input: 23710.42 toks/s, output: 23.15 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:36<00:09, 19.95it/s, est. speed input: 23674.91 toks/s, output: 23.12 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:36<00:08, 20.36it/s, est. speed input: 23656.96 toks/s, output: 23.10 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:36<00:08, 20.67it/s, est. speed input: 23639.45 toks/s, output: 23.09 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:37<00:07, 20.88it/s, est. speed input: 23622.11 toks/s, output: 23.07 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:37<00:07, 21.04it/s, est. speed input: 23605.25 toks/s, output: 23.05 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:37<00:07, 21.14it/s, est. speed input: 23588.52 toks/s, output: 23.04 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:38<00:06, 21.18it/s, est. speed input: 23570.74 toks/s, output: 23.02 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:38<00:06, 20.74it/s, est. speed input: 23535.92 toks/s, output: 22.98 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:39<00:06, 20.43it/s, est. speed input: 23501.49 toks/s, output: 22.95 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:39<00:05, 20.22it/s, est. speed input: 23468.13 toks/s, output: 22.92 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:39<00:05, 20.08it/s, est. speed input: 23435.17 toks/s, output: 22.89 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:40<00:05, 19.97it/s, est. speed input: 23402.63 toks/s, output: 22.85 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:40<00:04, 19.91it/s, est. speed input: 23371.10 toks/s, output: 22.82 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:41<00:04, 19.86it/s, est. speed input: 23340.24 toks/s, output: 22.79 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:41<00:03, 19.83it/s, est. speed input: 23309.90 toks/s, output: 22.76 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:41<00:03, 19.81it/s, est. speed input: 23280.11 toks/s, output: 22.73 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:42<00:03, 19.79it/s, est. speed input: 23251.00 toks/s, output: 22.71 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:42<00:02, 19.78it/s, est. speed input: 23222.29 toks/s, output: 22.68 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:43<00:02, 19.76it/s, est. speed input: 23193.96 toks/s, output: 22.65 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:43<00:01, 19.75it/s, est. speed input: 23166.16 toks/s, output: 22.62 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:43<00:01, 19.96it/s, est. speed input: 23146.25 toks/s, output: 22.60 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:44<00:01, 20.36it/s, est. speed input: 23135.73 toks/s, output: 22.59 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:44<00:00, 20.66it/s, est. speed input: 23125.29 toks/s, output: 22.58 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:45<00:00, 21.57it/s, est. speed input: 23136.26 toks/s, output: 22.59 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:45<00:00, 21.57it/s, est. speed input: 23272.50 toks/s, output: 22.73 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:45<00:00, 22.73it/s, est. speed input: 23272.50 toks/s, output: 22.73 toks/s]
[rank0]:[W125 23:20:51.823833221 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 109.6s

测试结果:
  Requests/s:   20.17
  Tokens/s:     20669.33
  Total Reqs:   1024
  Elapsed:      50.78s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     20649.16

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:21:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:21:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=533233) WARNING 01-25 23:21:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=533233) WARNING 01-25 23:21:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.45 requests/s, 20962.24 total tokens/s, 20.45 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 23:21:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:21:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:21:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:21:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:21:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:21:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:21:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:21:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:21:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:21:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:21:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:21:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:21:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:21:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:21:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:21:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:21:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=533233) [2026-01-25 23:21:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=533233) [2026-01-25 23:21:27] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=533233) [2026-01-25 23:21:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=533233) [2026-01-25 23:21:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=533233) [2026-01-25 23:21:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=533233) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=533233) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.31it/s]
(EngineCore_DP0 pid=533233) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.06it/s]
(EngineCore_DP0 pid=533233) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.09it/s]
(EngineCore_DP0 pid=533233) 
(EngineCore_DP0 pid=533233) [rank0]:W0125 23:21:47.005000 533233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=533233) [rank0]:W0125 23:21:47.940000 533233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=533233) [rank0]:W0125 23:21:50.334000 533233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=533233) [rank0]:W0125 23:21:50.528000 533233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=533233) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:02,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  5.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  6.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  6.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  6.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.84it/s]
(EngineCore_DP0 pid=533233) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  6.38it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  6.99it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  7.37it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  7.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  6.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  6.60it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/2048 [00:00<00:08, 239.58it/s]
Adding requests:   2%|▏         | 50/2048 [00:00<00:08, 247.52it/s]
Adding requests:   4%|▍         | 77/2048 [00:00<00:07, 255.89it/s]
Adding requests:   5%|▌         | 103/2048 [00:00<00:07, 253.34it/s]
Adding requests:   6%|▋         | 130/2048 [00:00<00:07, 256.12it/s]
Adding requests:   8%|▊         | 157/2048 [00:00<00:07, 259.54it/s]
Adding requests:   9%|▉         | 185/2048 [00:00<00:07, 263.01it/s]
Adding requests:  10%|█         | 212/2048 [00:00<00:06, 264.54it/s]
Adding requests:  12%|█▏        | 239/2048 [00:00<00:06, 259.07it/s]
Adding requests:  13%|█▎        | 265/2048 [00:01<00:06, 258.25it/s]
Adding requests:  14%|█▍        | 292/2048 [00:01<00:06, 260.19it/s]
Adding requests:  16%|█▌        | 320/2048 [00:01<00:06, 264.54it/s]
Adding requests:  17%|█▋        | 347/2048 [00:01<00:06, 264.84it/s]
Adding requests:  18%|█▊        | 375/2048 [00:01<00:06, 267.78it/s]
Adding requests:  20%|█▉        | 404/2048 [00:01<00:06, 272.56it/s]
Adding requests:  21%|██        | 432/2048 [00:01<00:06, 266.75it/s]
Adding requests:  22%|██▏       | 459/2048 [00:01<00:06, 264.55it/s]
Adding requests:  24%|██▍       | 488/2048 [00:01<00:05, 270.94it/s]
Adding requests:  25%|██▌       | 516/2048 [00:01<00:05, 271.17it/s]
Adding requests:  27%|██▋       | 545/2048 [00:02<00:05, 275.03it/s]
Adding requests:  28%|██▊       | 573/2048 [00:02<00:05, 273.50it/s]
Adding requests:  29%|██▉       | 601/2048 [00:02<00:05, 263.34it/s]
Adding requests:  31%|███       | 628/2048 [00:02<00:05, 262.67it/s]
Adding requests:  32%|███▏      | 655/2048 [00:02<00:05, 249.56it/s]
Adding requests:  33%|███▎      | 681/2048 [00:02<00:05, 244.77it/s]
Adding requests:  34%|███▍      | 706/2048 [00:02<00:05, 244.29it/s]
Adding requests:  36%|███▌      | 731/2048 [00:02<00:05, 241.88it/s]
Adding requests:  37%|███▋      | 756/2048 [00:02<00:05, 237.47it/s]
Adding requests:  38%|███▊      | 782/2048 [00:03<00:05, 242.69it/s]
Adding requests:  39%|███▉      | 807/2048 [00:03<00:05, 243.38it/s]
Adding requests:  41%|████      | 835/2048 [00:03<00:04, 252.53it/s]
Adding requests:  42%|████▏     | 861/2048 [00:03<00:04, 252.02it/s]
Adding requests:  43%|████▎     | 887/2048 [00:03<00:04, 253.09it/s]
Adding requests:  45%|████▍     | 913/2048 [00:03<00:04, 250.40it/s]
Adding requests:  46%|████▌     | 939/2048 [00:03<00:04, 240.38it/s]
Adding requests:  47%|████▋     | 964/2048 [00:03<00:04, 239.28it/s]
Adding requests:  48%|████▊     | 989/2048 [00:03<00:04, 240.49it/s]
Adding requests:  50%|████▉     | 1014/2048 [00:03<00:04, 236.48it/s]
Adding requests:  51%|█████     | 1039/2048 [00:04<00:04, 238.40it/s]
Adding requests:  52%|█████▏    | 1063/2048 [00:04<00:04, 228.77it/s]
Adding requests:  73%|███████▎  | 1502/2048 [00:04<00:00, 1398.40it/s]
Adding requests:  80%|████████  | 1648/2048 [00:04<00:00, 574.41it/s] 
Adding requests:  86%|████████▌ | 1758/2048 [00:05<00:00, 435.84it/s]
Adding requests:  90%|████████▉ | 1842/2048 [00:05<00:00, 373.33it/s]
Adding requests:  93%|█████████▎| 1908/2048 [00:05<00:00, 339.75it/s]
Adding requests:  96%|█████████▌| 1962/2048 [00:06<00:00, 314.49it/s]
Adding requests:  98%|█████████▊| 2007/2048 [00:06<00:00, 296.75it/s]
Adding requests: 100%|█████████▉| 2046/2048 [00:06<00:00, 280.44it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 311.23it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:00<00:07, 253.22it/s, est. speed input: 259312.69 toks/s, output: 253.23 toks/s]
Processed prompts:   9%|▉         | 188/2048 [00:01<00:16, 116.10it/s, est. speed input: 138234.50 toks/s, output: 134.99 toks/s]
Processed prompts:  10%|▉         | 201/2048 [00:02<00:26, 70.14it/s, est. speed input: 96690.31 toks/s, output: 94.42 toks/s]   
Processed prompts:  10%|█         | 210/2048 [00:02<00:39, 46.99it/s, est. speed input: 75081.55 toks/s, output: 73.32 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:03<00:48, 37.78it/s, est. speed input: 64265.79 toks/s, output: 62.76 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:04<00:57, 31.59it/s, est. speed input: 56504.87 toks/s, output: 55.18 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:05<01:04, 27.64it/s, est. speed input: 50955.31 toks/s, output: 49.76 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:05<01:10, 25.13it/s, est. speed input: 46881.96 toks/s, output: 45.78 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:06<01:14, 23.49it/s, est. speed input: 43764.18 toks/s, output: 42.74 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:07<01:17, 22.39it/s, est. speed input: 41303.75 toks/s, output: 40.34 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:08<01:19, 21.64it/s, est. speed input: 39310.71 toks/s, output: 38.39 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:09<01:20, 21.12it/s, est. speed input: 37663.19 toks/s, output: 36.78 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:09<01:21, 20.77it/s, est. speed input: 36282.90 toks/s, output: 35.43 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:10<01:19, 21.01it/s, est. speed input: 35306.90 toks/s, output: 34.48 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:11<01:18, 21.18it/s, est. speed input: 34454.54 toks/s, output: 33.65 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:12<01:18, 21.01it/s, est. speed input: 33609.83 toks/s, output: 32.82 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:13<01:18, 20.67it/s, est. speed input: 32795.96 toks/s, output: 32.03 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:13<01:18, 20.44it/s, est. speed input: 32075.99 toks/s, output: 31.32 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:14<01:18, 20.27it/s, est. speed input: 31433.63 toks/s, output: 30.70 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:15<01:18, 20.16it/s, est. speed input: 30859.05 toks/s, output: 30.14 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:16<01:17, 20.08it/s, est. speed input: 30341.03 toks/s, output: 29.63 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:17<01:17, 20.02it/s, est. speed input: 29871.27 toks/s, output: 29.17 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:17<01:15, 20.34it/s, est. speed input: 29520.47 toks/s, output: 28.83 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:18<01:13, 20.69it/s, est. speed input: 29223.32 toks/s, output: 28.54 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:19<01:11, 20.94it/s, est. speed input: 28948.21 toks/s, output: 28.27 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:20<01:10, 20.99it/s, est. speed input: 28671.50 toks/s, output: 28.00 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:20<01:11, 20.66it/s, est. speed input: 28353.77 toks/s, output: 27.69 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:21<01:11, 20.42it/s, est. speed input: 28057.07 toks/s, output: 27.40 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:22<01:10, 20.27it/s, est. speed input: 27783.33 toks/s, output: 27.13 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:23<01:10, 20.17it/s, est. speed input: 27529.73 toks/s, output: 26.88 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:24<01:09, 20.09it/s, est. speed input: 27290.83 toks/s, output: 26.65 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:24<01:08, 20.15it/s, est. speed input: 27085.17 toks/s, output: 26.45 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:25<01:06, 20.56it/s, est. speed input: 26940.36 toks/s, output: 26.31 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:26<01:05, 20.85it/s, est. speed input: 26803.78 toks/s, output: 26.18 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:27<01:03, 21.06it/s, est. speed input: 26674.79 toks/s, output: 26.05 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:27<01:02, 21.21it/s, est. speed input: 26552.70 toks/s, output: 25.93 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:28<00:37, 34.48it/s, est. speed input: 27609.02 toks/s, output: 26.96 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:29<00:41, 30.33it/s, est. speed input: 27447.60 toks/s, output: 26.80 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:30<00:46, 27.04it/s, est. speed input: 27259.19 toks/s, output: 26.62 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:30<00:49, 24.83it/s, est. speed input: 27081.00 toks/s, output: 26.45 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:31<00:52, 23.33it/s, est. speed input: 26911.99 toks/s, output: 26.28 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:32<00:53, 22.29it/s, est. speed input: 26751.70 toks/s, output: 26.12 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:33<00:53, 21.94it/s, est. speed input: 26634.31 toks/s, output: 26.01 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:34<00:53, 21.84it/s, est. speed input: 26535.99 toks/s, output: 25.91 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:34<00:52, 21.78it/s, est. speed input: 26442.30 toks/s, output: 25.82 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:35<00:52, 21.73it/s, est. speed input: 26352.91 toks/s, output: 25.74 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:36<00:52, 21.45it/s, est. speed input: 26245.60 toks/s, output: 25.63 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:37<00:52, 20.98it/s, est. speed input: 26119.90 toks/s, output: 25.51 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:37<00:52, 20.65it/s, est. speed input: 25998.67 toks/s, output: 25.39 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:38<00:52, 20.43it/s, est. speed input: 25882.60 toks/s, output: 25.28 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:39<00:51, 20.28it/s, est. speed input: 25771.74 toks/s, output: 25.17 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:40<00:51, 20.18it/s, est. speed input: 25665.11 toks/s, output: 25.06 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:41<00:50, 20.11it/s, est. speed input: 25562.50 toks/s, output: 24.96 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:41<00:50, 20.06it/s, est. speed input: 25464.16 toks/s, output: 24.87 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:42<00:48, 20.27it/s, est. speed input: 25388.73 toks/s, output: 24.79 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:43<00:47, 20.65it/s, est. speed input: 25333.04 toks/s, output: 24.74 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:44<00:46, 20.79it/s, est. speed input: 25269.72 toks/s, output: 24.68 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:44<00:45, 20.53it/s, est. speed input: 25183.10 toks/s, output: 24.59 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:45<00:45, 20.34it/s, est. speed input: 25098.99 toks/s, output: 24.51 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:46<00:45, 20.22it/s, est. speed input: 25018.40 toks/s, output: 24.43 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:47<00:44, 20.13it/s, est. speed input: 24940.48 toks/s, output: 24.36 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:48<00:43, 20.07it/s, est. speed input: 24864.78 toks/s, output: 24.28 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:48<00:43, 20.03it/s, est. speed input: 24791.81 toks/s, output: 24.21 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:49<00:41, 20.31it/s, est. speed input: 24741.68 toks/s, output: 24.16 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:50<00:40, 20.68it/s, est. speed input: 24703.08 toks/s, output: 24.12 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:51<00:38, 20.95it/s, est. speed input: 24665.69 toks/s, output: 24.09 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:51<00:37, 21.14it/s, est. speed input: 24629.30 toks/s, output: 24.05 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:52<00:37, 20.76it/s, est. speed input: 24565.24 toks/s, output: 23.99 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:53<00:37, 20.51it/s, est. speed input: 24503.34 toks/s, output: 23.93 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:54<00:36, 20.34it/s, est. speed input: 24443.14 toks/s, output: 23.87 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:55<00:36, 20.22it/s, est. speed input: 24384.54 toks/s, output: 23.81 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:55<00:35, 20.13it/s, est. speed input: 24327.76 toks/s, output: 23.76 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:56<00:34, 20.29it/s, est. speed input: 24284.67 toks/s, output: 23.72 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:57<00:33, 20.67it/s, est. speed input: 24256.83 toks/s, output: 23.69 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:58<00:32, 20.93it/s, est. speed input: 24229.31 toks/s, output: 23.66 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:58<00:30, 21.13it/s, est. speed input: 24202.85 toks/s, output: 23.64 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:59<00:16, 37.51it/s, est. speed input: 24822.43 toks/s, output: 24.24 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:00<00:18, 32.20it/s, est. speed input: 24781.50 toks/s, output: 24.20 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:01<00:20, 28.17it/s, est. speed input: 24723.63 toks/s, output: 24.14 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:01<00:21, 25.55it/s, est. speed input: 24667.97 toks/s, output: 24.09 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:02<00:22, 23.79it/s, est. speed input: 24613.47 toks/s, output: 24.04 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:03<00:23, 22.60it/s, est. speed input: 24560.38 toks/s, output: 23.98 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:04<00:23, 21.78it/s, est. speed input: 24508.46 toks/s, output: 23.93 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:05<00:23, 21.22it/s, est. speed input: 24457.81 toks/s, output: 23.88 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:05<00:22, 20.83it/s, est. speed input: 24408.36 toks/s, output: 23.84 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:06<00:21, 21.01it/s, est. speed input: 24381.09 toks/s, output: 23.81 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:07<00:21, 21.18it/s, est. speed input: 24356.08 toks/s, output: 23.79 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:08<00:19, 21.60it/s, est. speed input: 24344.32 toks/s, output: 23.77 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:08<00:19, 21.07it/s, est. speed input: 24298.40 toks/s, output: 23.73 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:09<00:19, 20.72it/s, est. speed input: 24253.40 toks/s, output: 23.68 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:10<00:18, 20.47it/s, est. speed input: 24209.53 toks/s, output: 23.64 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:11<00:18, 20.30it/s, est. speed input: 24166.57 toks/s, output: 23.60 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:12<00:17, 20.19it/s, est. speed input: 24124.69 toks/s, output: 23.56 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:12<00:16, 20.10it/s, est. speed input: 24083.46 toks/s, output: 23.52 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:13<00:15, 20.07it/s, est. speed input: 24044.30 toks/s, output: 23.48 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:14<00:14, 20.50it/s, est. speed input: 24025.03 toks/s, output: 23.46 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:15<00:13, 20.82it/s, est. speed input: 24006.02 toks/s, output: 23.44 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:15<00:12, 21.04it/s, est. speed input: 23987.46 toks/s, output: 23.43 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:16<00:12, 20.83it/s, est. speed input: 23955.24 toks/s, output: 23.39 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:17<00:11, 20.55it/s, est. speed input: 23918.29 toks/s, output: 23.36 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:18<00:10, 20.36it/s, est. speed input: 23882.19 toks/s, output: 23.32 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:19<00:10, 20.22it/s, est. speed input: 23846.75 toks/s, output: 23.29 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:19<00:09, 20.13it/s, est. speed input: 23812.04 toks/s, output: 23.25 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:20<00:08, 20.07it/s, est. speed input: 23778.09 toks/s, output: 23.22 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:21<00:07, 20.25it/s, est. speed input: 23753.49 toks/s, output: 23.20 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:22<00:06, 20.64it/s, est. speed input: 23738.73 toks/s, output: 23.18 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:22<00:06, 20.91it/s, est. speed input: 23724.05 toks/s, output: 23.17 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:23<00:05, 21.11it/s, est. speed input: 23709.77 toks/s, output: 23.15 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:24<00:04, 21.04it/s, est. speed input: 23688.58 toks/s, output: 23.13 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:25<00:03, 20.69it/s, est. speed input: 23657.57 toks/s, output: 23.10 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:26<00:03, 20.45it/s, est. speed input: 23626.97 toks/s, output: 23.07 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:26<00:02, 20.29it/s, est. speed input: 23597.18 toks/s, output: 23.04 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:27<00:01, 20.18it/s, est. speed input: 23567.90 toks/s, output: 23.02 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:28<00:00, 20.45it/s, est. speed input: 23551.12 toks/s, output: 23.00 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:28<00:00, 20.45it/s, est. speed input: 23713.12 toks/s, output: 23.16 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:28<00:00, 23.16it/s, est. speed input: 23713.12 toks/s, output: 23.16 toks/s]
[rank0]:[W125 23:23:37.728075135 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 164.5s

测试结果:
  Requests/s:   20.45
  Tokens/s:     20962.24
  Total Reqs:   2048
  Elapsed:      100.14s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     20941.79

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:24:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:24:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=536187) WARNING 01-25 23:24:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=536187) WARNING 01-25 23:24:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.51 requests/s, 21021.36 total tokens/s, 20.51 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 23:24:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:24:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:24:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:24:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:24:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:24:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:24:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:24:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:24:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:24:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:24:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:24:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:24:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:24:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:24:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:24:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:24:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=536187) [2026-01-25 23:24:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=536187) [2026-01-25 23:24:29] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=536187) [2026-01-25 23:24:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=536187) [2026-01-25 23:24:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=536187) [2026-01-25 23:24:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=536187) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=536187) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=536187) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=536187) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=536187) 
(EngineCore_DP0 pid=536187) [rank0]:W0125 23:24:48.510000 536187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=536187) [rank0]:W0125 23:24:49.109000 536187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=536187) [rank0]:W0125 23:24:51.001000 536187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=536187) [rank0]:W0125 23:24:51.194000 536187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=536187) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  7.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  7.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  7.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  5.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  3.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  5.47it/s]
(EngineCore_DP0 pid=536187) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:02,  2.19it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:01,  3.49it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  4.73it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  5.58it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  6.29it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  6.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  7.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  5.63it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/4096 [00:00<00:19, 204.29it/s]
Adding requests:   1%|          | 44/4096 [00:00<00:18, 214.38it/s]
Adding requests:   2%|▏         | 70/4096 [00:00<00:17, 228.88it/s]
Adding requests:   2%|▏         | 93/4096 [00:00<00:17, 225.43it/s]
Adding requests:   3%|▎         | 116/4096 [00:00<00:17, 226.10it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:17, 226.93it/s]
Adding requests:   4%|▍         | 163/4096 [00:00<00:17, 228.72it/s]
Adding requests:   5%|▍         | 187/4096 [00:00<00:17, 229.47it/s]
Adding requests:   5%|▌         | 211/4096 [00:00<00:16, 231.17it/s]
Adding requests:   6%|▌         | 236/4096 [00:01<00:16, 235.46it/s]
Adding requests:   6%|▋         | 260/4096 [00:01<00:16, 235.75it/s]
Adding requests:   7%|▋         | 285/4096 [00:01<00:16, 237.48it/s]
Adding requests:   8%|▊         | 311/4096 [00:01<00:15, 243.15it/s]
Adding requests:   8%|▊         | 337/4096 [00:01<00:15, 246.68it/s]
Adding requests:   9%|▉         | 363/4096 [00:01<00:14, 249.44it/s]
Adding requests:   9%|▉         | 388/4096 [00:01<00:14, 249.30it/s]
Adding requests:  10%|█         | 415/4096 [00:01<00:14, 253.08it/s]
Adding requests:  11%|█         | 441/4096 [00:01<00:14, 249.62it/s]
Adding requests:  11%|█▏        | 467/4096 [00:01<00:14, 250.56it/s]
Adding requests:  12%|█▏        | 493/4096 [00:02<00:14, 252.84it/s]
Adding requests:  13%|█▎        | 519/4096 [00:02<00:14, 251.23it/s]
Adding requests:  13%|█▎        | 545/4096 [00:02<00:14, 252.14it/s]
Adding requests:  14%|█▍        | 571/4096 [00:02<00:13, 253.24it/s]
Adding requests:  15%|█▍        | 597/4096 [00:02<00:14, 244.20it/s]
Adding requests:  15%|█▌        | 622/4096 [00:02<00:14, 243.88it/s]
Adding requests:  16%|█▌        | 647/4096 [00:02<00:14, 245.09it/s]
Adding requests:  16%|█▋        | 673/4096 [00:02<00:13, 246.80it/s]
Adding requests:  17%|█▋        | 700/4096 [00:02<00:13, 252.36it/s]
Adding requests:  18%|█▊        | 726/4096 [00:02<00:13, 250.85it/s]
Adding requests:  18%|█▊        | 752/4096 [00:03<00:13, 251.53it/s]
Adding requests:  19%|█▉        | 778/4096 [00:03<00:13, 253.95it/s]
Adding requests:  20%|█▉        | 804/4096 [00:03<00:12, 254.38it/s]
Adding requests:  20%|██        | 832/4096 [00:03<00:12, 259.90it/s]
Adding requests:  21%|██        | 859/4096 [00:03<00:12, 261.75it/s]
Adding requests:  22%|██▏       | 887/4096 [00:03<00:12, 264.80it/s]
Adding requests:  22%|██▏       | 914/4096 [00:03<00:12, 259.77it/s]
Adding requests:  23%|██▎       | 940/4096 [00:03<00:12, 257.67it/s]
Adding requests:  24%|██▎       | 966/4096 [00:03<00:12, 258.05it/s]
Adding requests:  24%|██▍       | 992/4096 [00:04<00:12, 255.62it/s]
Adding requests:  25%|██▍       | 1018/4096 [00:04<00:12, 252.95it/s]
Adding requests:  26%|██▌       | 1045/4096 [00:04<00:11, 255.51it/s]
Adding requests:  26%|██▌       | 1072/4096 [00:04<00:11, 259.48it/s]
Adding requests:  27%|██▋       | 1098/4096 [00:04<00:11, 258.48it/s]
Adding requests:  27%|██▋       | 1126/4096 [00:04<00:11, 264.30it/s]
Adding requests:  28%|██▊       | 1153/4096 [00:04<00:11, 263.76it/s]
Adding requests:  29%|██▉       | 1181/4096 [00:04<00:10, 268.44it/s]
Adding requests:  29%|██▉       | 1208/4096 [00:04<00:11, 259.06it/s]
Adding requests:  30%|███       | 1235/4096 [00:04<00:10, 261.47it/s]
Adding requests:  31%|███       | 1262/4096 [00:05<00:10, 262.85it/s]
Adding requests:  31%|███▏      | 1289/4096 [00:05<00:10, 259.13it/s]
Adding requests:  32%|███▏      | 1315/4096 [00:05<00:10, 258.53it/s]
Adding requests:  33%|███▎      | 1341/4096 [00:05<00:10, 258.04it/s]
Adding requests:  33%|███▎      | 1369/4096 [00:05<00:10, 261.00it/s]
Adding requests:  34%|███▍      | 1396/4096 [00:05<00:10, 260.62it/s]
Adding requests:  35%|███▍      | 1423/4096 [00:05<00:10, 256.79it/s]
Adding requests:  35%|███▌      | 1449/4096 [00:05<00:10, 252.07it/s]
Adding requests:  36%|███▌      | 1475/4096 [00:05<00:10, 253.24it/s]
Adding requests:  37%|███▋      | 1501/4096 [00:05<00:10, 252.71it/s]
Adding requests:  37%|███▋      | 1527/4096 [00:06<00:10, 250.89it/s]
Adding requests:  38%|███▊      | 1553/4096 [00:06<00:10, 244.24it/s]
Adding requests:  39%|███▊      | 1578/4096 [00:06<00:10, 235.81it/s]
Adding requests:  39%|███▉      | 1602/4096 [00:06<00:10, 235.90it/s]
Adding requests:  40%|███▉      | 1626/4096 [00:06<00:10, 231.33it/s]
Adding requests:  40%|████      | 1650/4096 [00:06<00:10, 230.59it/s]
Adding requests:  41%|████      | 1674/4096 [00:06<00:10, 227.66it/s]
Adding requests:  41%|████▏     | 1698/4096 [00:06<00:10, 229.17it/s]
Adding requests:  42%|████▏     | 1723/4096 [00:06<00:10, 233.20it/s]
Adding requests:  43%|████▎     | 1747/4096 [00:07<00:10, 231.01it/s]
Adding requests:  43%|████▎     | 1774/4096 [00:07<00:09, 240.12it/s]
Adding requests:  44%|████▍     | 1799/4096 [00:07<00:09, 238.53it/s]
Adding requests:  55%|█████▍    | 2236/4096 [00:07<00:01, 1424.86it/s]
Adding requests:  58%|█████▊    | 2381/4096 [00:07<00:02, 594.38it/s] 
Adding requests:  61%|██████    | 2490/4096 [00:08<00:03, 435.33it/s]
Adding requests:  63%|██████▎   | 2574/4096 [00:08<00:04, 367.57it/s]
Adding requests:  64%|██████▍   | 2640/4096 [00:09<00:04, 336.31it/s]
Adding requests:  66%|██████▌   | 2694/4096 [00:09<00:04, 315.93it/s]
Adding requests:  67%|██████▋   | 2739/4096 [00:09<00:04, 300.75it/s]
Adding requests:  68%|██████▊   | 2778/4096 [00:09<00:04, 290.56it/s]
Adding requests:  69%|██████▊   | 2813/4096 [00:09<00:04, 285.21it/s]
Adding requests:  69%|██████▉   | 2846/4096 [00:09<00:04, 276.87it/s]
Adding requests:  70%|███████   | 2876/4096 [00:09<00:04, 268.47it/s]
Adding requests:  71%|███████   | 2905/4096 [00:10<00:04, 262.26it/s]
Adding requests:  72%|███████▏  | 2933/4096 [00:10<00:04, 258.35it/s]
Adding requests:  72%|███████▏  | 2960/4096 [00:10<00:04, 259.62it/s]
Adding requests:  73%|███████▎  | 2987/4096 [00:10<00:04, 253.80it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:10<00:04, 257.97it/s]
Adding requests:  74%|███████▍  | 3043/4096 [00:10<00:04, 260.86it/s]
Adding requests:  75%|███████▍  | 3071/4096 [00:10<00:03, 263.77it/s]
Adding requests:  76%|███████▌  | 3098/4096 [00:10<00:03, 265.27it/s]
Adding requests:  76%|███████▋  | 3126/4096 [00:10<00:03, 268.41it/s]
Adding requests:  77%|███████▋  | 3153/4096 [00:11<00:03, 266.27it/s]
Adding requests:  78%|███████▊  | 3180/4096 [00:11<00:03, 261.35it/s]
Adding requests:  78%|███████▊  | 3207/4096 [00:11<00:03, 260.11it/s]
Adding requests:  79%|███████▉  | 3235/4096 [00:11<00:03, 263.61it/s]
Adding requests:  80%|███████▉  | 3262/4096 [00:11<00:03, 260.53it/s]
Adding requests:  80%|████████  | 3289/4096 [00:11<00:03, 244.93it/s]
Adding requests:  81%|████████  | 3314/4096 [00:11<00:03, 243.01it/s]
Adding requests:  82%|████████▏ | 3340/4096 [00:11<00:03, 245.86it/s]
Adding requests:  82%|████████▏ | 3367/4096 [00:11<00:02, 250.73it/s]
Adding requests:  83%|████████▎ | 3396/4096 [00:12<00:02, 259.22it/s]
Adding requests:  84%|████████▎ | 3423/4096 [00:12<00:02, 261.81it/s]
Adding requests:  84%|████████▍ | 3451/4096 [00:12<00:02, 267.08it/s]
Adding requests:  85%|████████▍ | 3479/4096 [00:12<00:02, 270.20it/s]
Adding requests:  86%|████████▌ | 3507/4096 [00:12<00:02, 270.21it/s]
Adding requests:  86%|████████▋ | 3537/4096 [00:12<00:02, 278.66it/s]
Adding requests:  87%|████████▋ | 3566/4096 [00:12<00:01, 279.96it/s]
Adding requests:  88%|████████▊ | 3595/4096 [00:12<00:01, 272.40it/s]
Adding requests:  88%|████████▊ | 3623/4096 [00:12<00:01, 271.50it/s]
Adding requests:  89%|████████▉ | 3651/4096 [00:12<00:01, 268.26it/s]
Adding requests:  90%|████████▉ | 3678/4096 [00:13<00:01, 258.03it/s]
Adding requests:  90%|█████████ | 3705/4096 [00:13<00:01, 259.41it/s]
Adding requests:  91%|█████████ | 3732/4096 [00:13<00:01, 260.53it/s]
Adding requests:  92%|█████████▏| 3759/4096 [00:13<00:01, 254.17it/s]
Adding requests:  92%|█████████▏| 3785/4096 [00:13<00:01, 240.63it/s]
Adding requests:  93%|█████████▎| 3810/4096 [00:13<00:01, 235.56it/s]
Adding requests:  94%|█████████▎| 3834/4096 [00:13<00:01, 236.74it/s]
Adding requests:  94%|█████████▍| 3859/4096 [00:13<00:00, 239.99it/s]
Adding requests:  95%|█████████▍| 3884/4096 [00:13<00:00, 240.97it/s]
Adding requests:  95%|█████████▌| 3909/4096 [00:14<00:00, 237.61it/s]
Adding requests:  96%|█████████▌| 3933/4096 [00:14<00:00, 233.36it/s]
Adding requests:  97%|█████████▋| 3958/4096 [00:14<00:00, 236.44it/s]
Adding requests:  97%|█████████▋| 3982/4096 [00:14<00:00, 234.75it/s]
Adding requests:  98%|█████████▊| 4006/4096 [00:14<00:00, 235.33it/s]
Adding requests:  98%|█████████▊| 4030/4096 [00:14<00:00, 222.32it/s]
Adding requests:  99%|█████████▉| 4054/4096 [00:14<00:00, 225.75it/s]
Adding requests: 100%|█████████▉| 4078/4096 [00:14<00:00, 226.98it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 275.70it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:01<00:14, 267.13it/s, est. speed input: 273549.70 toks/s, output: 267.13 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:02<00:35, 105.78it/s, est. speed input: 129697.53 toks/s, output: 126.66 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:04<00:57, 64.39it/s, est. speed input: 90106.98 toks/s, output: 87.99 toks/s]   
Processed prompts:  10%|█         | 418/4096 [00:05<01:18, 46.98it/s, est. speed input: 72265.27 toks/s, output: 70.57 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:07<01:36, 37.70it/s, est. speed input: 61989.74 toks/s, output: 60.54 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:09<01:54, 31.49it/s, est. speed input: 54663.48 toks/s, output: 53.38 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:10<02:09, 27.66it/s, est. speed input: 49530.30 toks/s, output: 48.37 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:12<02:20, 25.18it/s, est. speed input: 45732.34 toks/s, output: 44.66 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:13<02:25, 24.10it/s, est. speed input: 43176.78 toks/s, output: 42.16 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:15<02:29, 23.29it/s, est. speed input: 41086.87 toks/s, output: 40.12 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:16<02:35, 22.25it/s, est. speed input: 39126.34 toks/s, output: 38.21 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:18<02:38, 21.56it/s, est. speed input: 37507.82 toks/s, output: 36.63 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:19<02:39, 21.26it/s, est. speed input: 36223.96 toks/s, output: 35.37 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:21<02:37, 21.38it/s, est. speed input: 35259.26 toks/s, output: 34.43 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:22<02:33, 21.64it/s, est. speed input: 34476.91 toks/s, output: 33.67 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:24<01:57, 27.74it/s, est. speed input: 34989.38 toks/s, output: 34.17 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:26<02:07, 25.33it/s, est. speed input: 34098.84 toks/s, output: 33.30 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:27<02:14, 23.69it/s, est. speed input: 33311.42 toks/s, output: 32.53 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:29<02:17, 23.09it/s, est. speed input: 32743.14 toks/s, output: 31.98 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:30<02:18, 22.69it/s, est. speed input: 32235.09 toks/s, output: 31.48 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:32<02:20, 22.04it/s, est. speed input: 31693.27 toks/s, output: 30.95 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:33<02:23, 21.42it/s, est. speed input: 31163.40 toks/s, output: 30.43 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:35<02:24, 20.98it/s, est. speed input: 30680.03 toks/s, output: 29.96 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:36<02:25, 20.70it/s, est. speed input: 30240.54 toks/s, output: 29.53 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:38<02:23, 20.76it/s, est. speed input: 29889.21 toks/s, output: 29.19 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:39<02:21, 20.78it/s, est. speed input: 29560.07 toks/s, output: 28.87 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:41<02:21, 20.56it/s, est. speed input: 29213.60 toks/s, output: 28.53 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:43<02:21, 20.40it/s, est. speed input: 28892.02 toks/s, output: 28.21 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:44<02:19, 20.43it/s, est. speed input: 28617.06 toks/s, output: 27.95 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:46<02:15, 20.80it/s, est. speed input: 28413.51 toks/s, output: 27.75 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:47<02:13, 20.89it/s, est. speed input: 28196.87 toks/s, output: 27.54 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:49<02:13, 20.63it/s, est. speed input: 27948.18 toks/s, output: 27.29 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:50<02:12, 20.45it/s, est. speed input: 27715.12 toks/s, output: 27.07 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:52<02:11, 20.50it/s, est. speed input: 27520.68 toks/s, output: 26.88 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:53<02:07, 20.85it/s, est. speed input: 27376.14 toks/s, output: 26.73 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [00:55<01:29, 28.98it/s, est. speed input: 27967.03 toks/s, output: 27.31 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:56<01:37, 26.13it/s, est. speed input: 27760.71 toks/s, output: 27.11 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:58<01:44, 24.21it/s, est. speed input: 27563.03 toks/s, output: 26.92 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [00:59<01:47, 23.10it/s, est. speed input: 27394.43 toks/s, output: 26.75 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [01:01<01:49, 22.41it/s, est. speed input: 27241.86 toks/s, output: 26.60 toks/s]
Processed prompts:  41%|████      | 1666/4096 [01:02<01:49, 22.21it/s, est. speed input: 27124.61 toks/s, output: 26.49 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [01:04<01:50, 21.66it/s, est. speed input: 26974.01 toks/s, output: 26.34 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [01:06<01:51, 21.16it/s, est. speed input: 26817.81 toks/s, output: 26.19 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [01:07<01:52, 20.81it/s, est. speed input: 26669.06 toks/s, output: 26.04 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:09<01:51, 20.72it/s, est. speed input: 26540.97 toks/s, output: 25.92 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [01:10<01:48, 21.00it/s, est. speed input: 26450.82 toks/s, output: 25.83 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [01:12<01:47, 20.91it/s, est. speed input: 26338.28 toks/s, output: 25.72 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:13<01:46, 20.63it/s, est. speed input: 26211.09 toks/s, output: 25.60 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:15<01:46, 20.44it/s, est. speed input: 26090.13 toks/s, output: 25.48 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:17<01:44, 20.43it/s, est. speed input: 25983.97 toks/s, output: 25.37 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:18<01:41, 20.79it/s, est. speed input: 25913.13 toks/s, output: 25.31 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:20<01:39, 20.83it/s, est. speed input: 25827.47 toks/s, output: 25.22 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:21<01:39, 20.58it/s, est. speed input: 25723.06 toks/s, output: 25.12 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:23<01:38, 20.40it/s, est. speed input: 25622.40 toks/s, output: 25.02 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:24<01:37, 20.28it/s, est. speed input: 25525.54 toks/s, output: 24.93 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:26<01:10, 27.22it/s, est. speed input: 25867.41 toks/s, output: 25.26 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:27<01:14, 25.47it/s, est. speed input: 25798.03 toks/s, output: 25.19 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:29<01:17, 23.77it/s, est. speed input: 25703.14 toks/s, output: 25.10 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:30<01:20, 22.62it/s, est. speed input: 25611.47 toks/s, output: 25.01 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:32<01:22, 21.82it/s, est. speed input: 25523.06 toks/s, output: 24.92 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:34<01:21, 21.59it/s, est. speed input: 25458.30 toks/s, output: 24.86 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:35<01:19, 21.58it/s, est. speed input: 25405.73 toks/s, output: 24.81 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:37<01:20, 21.09it/s, est. speed input: 25324.24 toks/s, output: 24.73 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:38<01:20, 20.75it/s, est. speed input: 25245.51 toks/s, output: 24.65 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:40<01:19, 20.52it/s, est. speed input: 25169.68 toks/s, output: 24.58 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:41<01:17, 20.67it/s, est. speed input: 25115.40 toks/s, output: 24.53 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [01:43<01:14, 20.96it/s, est. speed input: 25073.68 toks/s, output: 24.49 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [01:44<01:14, 20.70it/s, est. speed input: 25006.00 toks/s, output: 24.42 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [01:46<01:13, 20.50it/s, est. speed input: 24938.77 toks/s, output: 24.35 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [01:48<01:12, 20.34it/s, est. speed input: 24872.56 toks/s, output: 24.29 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [01:49<01:10, 20.53it/s, est. speed input: 24825.41 toks/s, output: 24.24 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [01:51<01:07, 20.87it/s, est. speed input: 24790.70 toks/s, output: 24.21 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [01:52<01:06, 20.72it/s, est. speed input: 24736.05 toks/s, output: 24.16 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [01:54<01:05, 20.50it/s, est. speed input: 24676.72 toks/s, output: 24.10 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [01:55<00:47, 27.07it/s, est. speed input: 24927.44 toks/s, output: 24.34 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [01:57<00:49, 25.05it/s, est. speed input: 24873.84 toks/s, output: 24.29 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [01:58<00:50, 24.07it/s, est. speed input: 24840.49 toks/s, output: 24.26 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [02:00<00:51, 23.02it/s, est. speed input: 24792.55 toks/s, output: 24.21 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [02:01<00:52, 22.09it/s, est. speed input: 24735.98 toks/s, output: 24.16 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [02:03<00:52, 21.45it/s, est. speed input: 24680.92 toks/s, output: 24.10 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [02:05<00:51, 21.01it/s, est. speed input: 24627.10 toks/s, output: 24.05 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [02:06<00:49, 21.12it/s, est. speed input: 24595.23 toks/s, output: 24.02 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [02:08<00:48, 21.09it/s, est. speed input: 24558.70 toks/s, output: 23.98 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [02:09<00:47, 20.76it/s, est. speed input: 24508.71 toks/s, output: 23.93 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [02:11<00:46, 20.53it/s, est. speed input: 24459.73 toks/s, output: 23.89 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [02:12<00:45, 20.37it/s, est. speed input: 24411.94 toks/s, output: 23.84 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [02:14<00:43, 20.72it/s, est. speed input: 24386.36 toks/s, output: 23.81 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [02:15<00:41, 20.89it/s, est. speed input: 24357.83 toks/s, output: 23.79 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [02:17<00:40, 20.62it/s, est. speed input: 24313.12 toks/s, output: 23.74 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [02:19<00:39, 20.42it/s, est. speed input: 24268.72 toks/s, output: 23.70 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [02:20<00:37, 20.32it/s, est. speed input: 24226.59 toks/s, output: 23.66 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [02:22<00:35, 20.71it/s, est. speed input: 24205.49 toks/s, output: 23.64 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [02:23<00:33, 20.97it/s, est. speed input: 24184.09 toks/s, output: 23.62 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [02:25<00:32, 20.67it/s, est. speed input: 24143.58 toks/s, output: 23.58 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:26<00:22, 27.21it/s, est. speed input: 24345.95 toks/s, output: 23.78 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:28<00:22, 24.98it/s, est. speed input: 24304.39 toks/s, output: 23.73 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:29<00:22, 23.77it/s, est. speed input: 24274.67 toks/s, output: 23.71 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:31<00:22, 23.16it/s, est. speed input: 24254.40 toks/s, output: 23.69 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:32<00:21, 22.28it/s, est. speed input: 24218.52 toks/s, output: 23.65 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:34<00:20, 21.58it/s, est. speed input: 24180.01 toks/s, output: 23.61 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:36<00:19, 21.27it/s, est. speed input: 24148.70 toks/s, output: 23.58 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [02:37<00:18, 20.92it/s, est. speed input: 24112.97 toks/s, output: 23.55 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [02:39<00:16, 21.14it/s, est. speed input: 24095.17 toks/s, output: 23.53 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [02:40<00:15, 20.96it/s, est. speed input: 24065.60 toks/s, output: 23.50 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [02:42<00:13, 20.67it/s, est. speed input: 24030.36 toks/s, output: 23.47 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [02:43<00:12, 20.47it/s, est. speed input: 23996.00 toks/s, output: 23.43 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [02:45<00:10, 20.47it/s, est. speed input: 23967.22 toks/s, output: 23.41 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [02:46<00:09, 20.97it/s, est. speed input: 23957.07 toks/s, output: 23.40 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [02:48<00:07, 20.93it/s, est. speed input: 23933.18 toks/s, output: 23.37 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [02:50<00:06, 20.65it/s, est. speed input: 23900.98 toks/s, output: 23.34 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [02:51<00:04, 20.46it/s, est. speed input: 23869.32 toks/s, output: 23.31 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [02:53<00:03, 20.61it/s, est. speed input: 23848.28 toks/s, output: 23.29 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [02:54<00:01, 21.11it/s, est. speed input: 23840.76 toks/s, output: 23.28 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:54<00:00, 21.11it/s, est. speed input: 24016.57 toks/s, output: 23.45 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:54<00:00, 23.45it/s, est. speed input: 24016.57 toks/s, output: 23.45 toks/s]
[rank0]:[W125 23:28:13.327253976 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 276.1s

测试结果:
  Requests/s:   20.51
  Tokens/s:     21021.36
  Total Reqs:   4096
  Elapsed:      199.72s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     21000.85

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:29:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:29:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=540794) WARNING 01-25 23:29:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=540794) WARNING 01-25 23:29:47 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     def forward(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     raise e
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/tmp/torchinductor_root/7x/c7x3tr3gdlrrlz4jpedcnjezo7odyiwhisohz45bwwio6lnbddt4.py", line 1090, in call
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     triton_poi_fused_mul_quant_only_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_only_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=540794) ERROR 01-25 23:30:00 [core.py:866] 


─── STDERR ───
[2026-01-25 23:29:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:29:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:29:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:29:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:29:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:29:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:29:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:29:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:29:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:29:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:29:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:29:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:29:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:29:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:29:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:29:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:29:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:35] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=540794) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=540794) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.23it/s]
(EngineCore_DP0 pid=540794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01s/it]
(EngineCore_DP0 pid=540794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.02it/s]
(EngineCore_DP0 pid=540794) 
(EngineCore_DP0 pid=540794) [rank0]:W0125 23:29:55.583000 540794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=540794) [rank0]:W0125 23:29:56.036000 540794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=540794) [rank0]:W0125 23:29:57.969000 540794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=540794) [rank0]:W0125 23:29:58.156000 540794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=540794) [2026-01-25 23:29:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=540794) Process EngineCore_DP0:
(EngineCore_DP0 pid=540794) Traceback (most recent call last):
(EngineCore_DP0 pid=540794)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=540794)     self.run()
(EngineCore_DP0 pid=540794)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=540794)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=540794)     raise e
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=540794)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=540794)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=540794)     super().__init__(
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=540794)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=540794)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=540794)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=540794)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=540794)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=540794)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=540794)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=540794)     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=540794)     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=540794)     self.model_runner.profile_run()
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=540794)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=540794)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=540794)     return func(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=540794)     outputs = self.model(
(EngineCore_DP0 pid=540794)               ^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=540794)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=540794)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=540794)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=540794)     hidden_states = self.model(
(EngineCore_DP0 pid=540794)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=540794)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=540794)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=540794)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=540794)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=540794)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=540794)     def forward(
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=540794)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=540794)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=540794)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=540794)     raise e
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=540794)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=540794)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=540794)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=540794)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=540794)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=540794)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=540794)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=540794)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=540794)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=540794)     return compiled_fn(full_args)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=540794)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=540794)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=540794)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=540794)                             ^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=540794)     outs = compiled_fn(args)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=540794)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=540794)     return self.current_callable(inputs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=540794)     out = model(new_inputs)
(EngineCore_DP0 pid=540794)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/tmp/torchinductor_root/7x/c7x3tr3gdlrrlz4jpedcnjezo7odyiwhisohz45bwwio6lnbddt4.py", line 1090, in call
(EngineCore_DP0 pid=540794)     triton_poi_fused_mul_quant_only_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_only_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=540794)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=540794)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=540794)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=540794)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=540794)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=540794)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=540794)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=540794)     torch.cuda.synchronize()
(EngineCore_DP0 pid=540794)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=540794)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=540794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=540794) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=540794) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=540794) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=540794) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=540794) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=540794) 
[rank0]:[W125 23:30:01.566146795 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,13.7590,7058.3719,9.3030
1024,1024,1,128,128,14.4229,14783.4739,8.8748
2048,1024,2,256,128,18.8015,19271.5292,13.6159
4096,1024,4,512,128,19.8249,20320.5198,25.8261
8192,1024,8,1024,128,20.1652,20669.3279,50.7806
16384,1024,16,2048,128,20.4510,20962.2434,100.1420
32768,1024,32,4096,128,20.5086,21021.3590,199.7207
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:30:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:30:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=541693) WARNING 01-25 23:30:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=541693) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=541693) WARNING 01-25 23:30:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.62 requests/s, 7499.63 total tokens/s, 14.62 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:30:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:30:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:30:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:30:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:30:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:30:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:30:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:30:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:30:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:30:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:30:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:30:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:30:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:30:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:30:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:30:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:30:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=541693) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=541693) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.20s/it]
(EngineCore_DP0 pid=541693) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.85s/it]
(EngineCore_DP0 pid=541693) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.75s/it]
(EngineCore_DP0 pid=541693) 
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=541693) [2026-01-25 23:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=541693) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]
(EngineCore_DP0 pid=541693) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.32it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  31%|███▏      | 40/128 [00:00<00:00, 397.32it/s]
Adding requests:  66%|██████▌   | 84/128 [00:00<00:00, 417.70it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 427.04it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 422.21it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:48,  2.63it/s, est. speed input: 1347.20 toks/s, output: 2.63 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:18,  6.80it/s, est. speed input: 3005.16 toks/s, output: 5.87 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:12,  9.54it/s, est. speed input: 3993.53 toks/s, output: 7.80 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:10, 11.34it/s, est. speed input: 4642.26 toks/s, output: 9.07 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:09, 12.56it/s, est. speed input: 5104.06 toks/s, output: 9.97 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:08, 13.43it/s, est. speed input: 5453.56 toks/s, output: 10.65 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:08, 14.04it/s, est. speed input: 5726.66 toks/s, output: 11.18 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 14.43it/s, est. speed input: 5940.58 toks/s, output: 11.60 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:07, 14.64it/s, est. speed input: 6107.41 toks/s, output: 11.93 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:07, 14.77it/s, est. speed input: 6245.14 toks/s, output: 12.20 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:07, 14.94it/s, est. speed input: 6368.52 toks/s, output: 12.44 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 15.02it/s, est. speed input: 6470.74 toks/s, output: 12.64 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 15.14it/s, est. speed input: 6565.98 toks/s, output: 12.82 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:06, 15.20it/s, est. speed input: 6646.95 toks/s, output: 12.98 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:06, 15.25it/s, est. speed input: 6718.79 toks/s, output: 13.12 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:06, 15.26it/s, est. speed input: 6780.80 toks/s, output: 13.24 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 15.15it/s, est. speed input: 6826.67 toks/s, output: 13.33 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:06, 15.10it/s, est. speed input: 6869.57 toks/s, output: 13.42 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:06, 15.12it/s, est. speed input: 6912.82 toks/s, output: 13.50 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 15.17it/s, est. speed input: 6954.54 toks/s, output: 13.58 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 15.30it/s, est. speed input: 6998.97 toks/s, output: 13.67 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:03<00:05, 15.41it/s, est. speed input: 7041.06 toks/s, output: 13.75 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:03<00:05, 15.53it/s, est. speed input: 7082.01 toks/s, output: 13.83 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 15.60it/s, est. speed input: 7119.16 toks/s, output: 13.90 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 15.62it/s, est. speed input: 7152.07 toks/s, output: 13.97 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 15.57it/s, est. speed input: 7179.32 toks/s, output: 14.02 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.55it/s, est. speed input: 7205.27 toks/s, output: 14.07 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 15.42it/s, est. speed input: 7223.67 toks/s, output: 14.11 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:04<00:04, 15.38it/s, est. speed input: 7243.24 toks/s, output: 14.15 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:04<00:04, 15.32it/s, est. speed input: 7259.78 toks/s, output: 14.18 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:04, 15.29it/s, est. speed input: 7276.17 toks/s, output: 14.21 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 15.38it/s, est. speed input: 7296.58 toks/s, output: 14.25 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:04, 15.70it/s, est. speed input: 7327.24 toks/s, output: 14.31 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 15.96it/s, est. speed input: 7357.75 toks/s, output: 14.37 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 16.10it/s, est. speed input: 7384.64 toks/s, output: 14.42 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 16.16it/s, est. speed input: 7408.57 toks/s, output: 14.47 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:05<00:03, 16.19it/s, est. speed input: 7431.16 toks/s, output: 14.51 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:05<00:03, 16.37it/s, est. speed input: 7458.09 toks/s, output: 14.57 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:05<00:03, 16.41it/s, est. speed input: 7480.84 toks/s, output: 14.61 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:02, 16.43it/s, est. speed input: 7502.67 toks/s, output: 14.65 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 16.46it/s, est. speed input: 7523.68 toks/s, output: 14.69 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 16.50it/s, est. speed input: 7544.40 toks/s, output: 14.74 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 16.50it/s, est. speed input: 7563.43 toks/s, output: 14.77 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 16.54it/s, est. speed input: 7582.91 toks/s, output: 14.81 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 16.54it/s, est. speed input: 7600.87 toks/s, output: 14.85 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:06<00:02, 16.63it/s, est. speed input: 7620.65 toks/s, output: 14.88 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:06<00:02, 16.71it/s, est. speed input: 7640.37 toks/s, output: 14.92 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:01, 16.71it/s, est. speed input: 7657.62 toks/s, output: 14.96 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:01, 16.75it/s, est. speed input: 7675.26 toks/s, output: 14.99 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 16.65it/s, est. speed input: 7688.89 toks/s, output: 15.02 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 16.71it/s, est. speed input: 7705.51 toks/s, output: 15.05 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 16.80it/s, est. speed input: 7722.77 toks/s, output: 15.08 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 16.74it/s, est. speed input: 7736.29 toks/s, output: 15.11 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:07<00:01, 16.26it/s, est. speed input: 7737.47 toks/s, output: 15.11 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:07<00:01, 15.96it/s, est. speed input: 7739.38 toks/s, output: 15.12 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:01, 15.80it/s, est. speed input: 7742.14 toks/s, output: 15.12 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:00, 15.66it/s, est. speed input: 7744.09 toks/s, output: 15.13 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 15.56it/s, est. speed input: 7746.09 toks/s, output: 15.13 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 15.52it/s, est. speed input: 7748.61 toks/s, output: 15.13 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 15.47it/s, est. speed input: 7750.36 toks/s, output: 15.14 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 15.39it/s, est. speed input: 7750.91 toks/s, output: 15.14 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:08<00:00, 15.37it/s, est. speed input: 7752.44 toks/s, output: 15.14 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:08<00:00, 15.34it/s, est. speed input: 7753.56 toks/s, output: 15.14 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 15.30it/s, est. speed input: 7754.11 toks/s, output: 15.14 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.30it/s, est. speed input: 7755.14 toks/s, output: 15.15 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.15it/s, est. speed input: 7755.14 toks/s, output: 15.15 toks/s]
[rank0]:[W125 23:31:13.972217075 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 70.2s

测试结果:
  Requests/s:   14.62
  Tokens/s:     7499.63
  Total Reqs:   128
  Elapsed:      8.76s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     7485.01

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:31:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:31:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=543037) WARNING 01-25 23:31:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=543037) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=543037) WARNING 01-25 23:31:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.86 requests/s, 15228.69 total tokens/s, 14.86 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:31:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:31:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:31:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:31:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:31:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:31:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:31:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:31:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:31:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:31:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:31:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:31:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:31:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:31:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:31:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:31:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:31:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=543037) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=543037) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.34it/s]
(EngineCore_DP0 pid=543037) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]
(EngineCore_DP0 pid=543037) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=543037) 
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=543037) [2026-01-25 23:31:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=543037) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.47it/s]
(EngineCore_DP0 pid=543037) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 23/128 [00:00<00:00, 225.17it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 233.58it/s]
Adding requests:  58%|█████▊    | 74/128 [00:00<00:00, 242.28it/s]
Adding requests:  77%|███████▋  | 99/128 [00:00<00:00, 238.74it/s]
Adding requests:  98%|█████████▊| 126/128 [00:00<00:00, 247.62it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 242.49it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:20,  6.10it/s, est. speed input: 6251.48 toks/s, output: 6.10 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:10, 11.49it/s, est. speed input: 10815.71 toks/s, output: 10.56 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:08, 13.83it/s, est. speed input: 12771.94 toks/s, output: 12.47 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:08, 14.86it/s, est. speed input: 13735.49 toks/s, output: 13.41 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:07, 15.62it/s, est. speed input: 14423.65 toks/s, output: 14.09 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 16.01it/s, est. speed input: 14856.45 toks/s, output: 14.51 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 16.15it/s, est. speed input: 15130.86 toks/s, output: 14.78 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 15.99it/s, est. speed input: 15247.30 toks/s, output: 14.89 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:07, 15.82it/s, est. speed input: 15313.35 toks/s, output: 14.95 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 15.64it/s, est. speed input: 15344.68 toks/s, output: 14.98 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 15.52it/s, est. speed input: 15371.70 toks/s, output: 15.01 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 15.47it/s, est. speed input: 15402.25 toks/s, output: 15.04 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 15.44it/s, est. speed input: 15427.27 toks/s, output: 15.07 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 15.46it/s, est. speed input: 15460.00 toks/s, output: 15.10 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:06, 15.46it/s, est. speed input: 15484.34 toks/s, output: 15.12 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:06, 15.47it/s, est. speed input: 15509.22 toks/s, output: 15.15 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 15.51it/s, est. speed input: 15537.20 toks/s, output: 15.17 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:06, 15.45it/s, est. speed input: 15544.77 toks/s, output: 15.18 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 15.42it/s, est. speed input: 15554.48 toks/s, output: 15.19 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 15.43it/s, est. speed input: 15567.85 toks/s, output: 15.20 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 15.36it/s, est. speed input: 15567.00 toks/s, output: 15.20 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 15.38it/s, est. speed input: 15578.31 toks/s, output: 15.21 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 15.37it/s, est. speed input: 15583.61 toks/s, output: 15.22 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 15.49it/s, est. speed input: 15607.96 toks/s, output: 15.24 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 15.65it/s, est. speed input: 15639.76 toks/s, output: 15.27 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 15.71it/s, est. speed input: 15662.16 toks/s, output: 15.29 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.72it/s, est. speed input: 15678.49 toks/s, output: 15.31 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 15.73it/s, est. speed input: 15695.23 toks/s, output: 15.33 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 15.82it/s, est. speed input: 15718.95 toks/s, output: 15.35 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 15.88it/s, est. speed input: 15741.39 toks/s, output: 15.37 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 15.90it/s, est. speed input: 15759.98 toks/s, output: 15.39 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 15.86it/s, est. speed input: 15772.43 toks/s, output: 15.40 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 15.93it/s, est. speed input: 15792.72 toks/s, output: 15.42 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 15.99it/s, est. speed input: 15813.41 toks/s, output: 15.44 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 15.82it/s, est. speed input: 15813.38 toks/s, output: 15.44 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 15.79it/s, est. speed input: 15821.38 toks/s, output: 15.45 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 15.73it/s, est. speed input: 15824.88 toks/s, output: 15.45 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 15.77it/s, est. speed input: 15836.33 toks/s, output: 15.47 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 15.80it/s, est. speed input: 15846.70 toks/s, output: 15.48 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:03, 15.76it/s, est. speed input: 15851.84 toks/s, output: 15.48 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 15.80it/s, est. speed input: 15861.67 toks/s, output: 15.49 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 15.80it/s, est. speed input: 15869.26 toks/s, output: 15.50 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 15.74it/s, est. speed input: 15871.82 toks/s, output: 15.50 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 15.69it/s, est. speed input: 15873.71 toks/s, output: 15.50 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 15.70it/s, est. speed input: 15878.47 toks/s, output: 15.51 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 15.68it/s, est. speed input: 15881.24 toks/s, output: 15.51 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 15.64it/s, est. speed input: 15882.56 toks/s, output: 15.51 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:02, 15.68it/s, est. speed input: 15888.04 toks/s, output: 15.52 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:01, 15.70it/s, est. speed input: 15892.82 toks/s, output: 15.52 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 16.04it/s, est. speed input: 15918.73 toks/s, output: 15.55 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 16.30it/s, est. speed input: 15945.08 toks/s, output: 15.57 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 16.58it/s, est. speed input: 15975.71 toks/s, output: 15.60 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 16.74it/s, est. speed input: 16002.59 toks/s, output: 15.63 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 16.75it/s, est. speed input: 16022.84 toks/s, output: 15.65 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 16.79it/s, est. speed input: 16044.82 toks/s, output: 15.67 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:01, 16.89it/s, est. speed input: 16069.28 toks/s, output: 15.69 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:00, 16.95it/s, est. speed input: 16092.83 toks/s, output: 15.72 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 17.00it/s, est. speed input: 16115.63 toks/s, output: 15.74 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 17.00it/s, est. speed input: 16136.16 toks/s, output: 15.76 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 16.82it/s, est. speed input: 16146.97 toks/s, output: 15.77 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 16.74it/s, est. speed input: 16159.54 toks/s, output: 15.78 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 16.74it/s, est. speed input: 16174.95 toks/s, output: 15.80 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 16.73it/s, est. speed input: 16189.15 toks/s, output: 15.81 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 16.74it/s, est. speed input: 16203.38 toks/s, output: 15.82 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 16.74it/s, est. speed input: 16210.06 toks/s, output: 15.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.83it/s, est. speed input: 16210.06 toks/s, output: 15.83 toks/s]
[rank0]:[W125 23:32:15.423915378 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 62.3s

测试结果:
  Requests/s:   14.86
  Tokens/s:     15228.69
  Total Reqs:   128
  Elapsed:      8.62s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     15213.83

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:32:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:32:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=544223) WARNING 01-25 23:32:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=544223) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=544223) WARNING 01-25 23:32:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.24 requests/s, 26898.72 total tokens/s, 26.24 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 23:32:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:32:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:32:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:32:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:32:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:32:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:32:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:32:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:32:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:32:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:32:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:32:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:32:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:32:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:32:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:32:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:32:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=544223) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=544223) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.35it/s]
(EngineCore_DP0 pid=544223) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.03it/s]
(EngineCore_DP0 pid=544223) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.06it/s]
(EngineCore_DP0 pid=544223) 
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=544223) [2026-01-25 23:32:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=544223) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.07it/s]
(EngineCore_DP0 pid=544223) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.20it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 205.20it/s]
Adding requests:  18%|█▊        | 45/256 [00:00<00:00, 224.18it/s]
Adding requests:  28%|██▊       | 71/256 [00:00<00:00, 237.44it/s]
Adding requests:  37%|███▋      | 95/256 [00:00<00:00, 236.57it/s]
Adding requests:  47%|████▋     | 120/256 [00:00<00:00, 240.23it/s]
Adding requests:  57%|█████▋    | 145/256 [00:00<00:00, 240.40it/s]
Adding requests:  67%|██████▋   | 171/256 [00:00<00:00, 244.18it/s]
Adding requests:  77%|███████▋  | 198/256 [00:00<00:00, 251.07it/s]
Adding requests:  88%|████████▊ | 224/256 [00:00<00:00, 252.36it/s]
Adding requests:  98%|█████████▊| 250/256 [00:01<00:00, 250.67it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 243.52it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 173.38it/s, est. speed input: 177584.76 toks/s, output: 173.39 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:00<00:05, 42.41it/s, est. speed input: 49315.72 toks/s, output: 48.16 toks/s]   
Processed prompts:  18%|█▊        | 47/256 [00:01<00:05, 37.98it/s, est. speed input: 44244.89 toks/s, output: 43.21 toks/s]
Processed prompts:  21%|██        | 54/256 [00:01<00:06, 32.95it/s, est. speed input: 39821.65 toks/s, output: 38.89 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:01<00:05, 33.06it/s, est. speed input: 39290.90 toks/s, output: 38.37 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:01<00:06, 29.90it/s, est. speed input: 37206.18 toks/s, output: 36.33 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:01<00:06, 29.32it/s, est. speed input: 36487.96 toks/s, output: 35.63 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:06, 29.25it/s, est. speed input: 36031.20 toks/s, output: 35.19 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:02<00:06, 29.20it/s, est. speed input: 35633.39 toks/s, output: 34.80 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:02<00:06, 29.14it/s, est. speed input: 35278.94 toks/s, output: 34.45 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:02<00:05, 29.07it/s, est. speed input: 34957.31 toks/s, output: 34.14 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:02<00:05, 29.06it/s, est. speed input: 34679.64 toks/s, output: 33.87 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:02<00:05, 29.07it/s, est. speed input: 34433.81 toks/s, output: 33.63 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:02<00:05, 29.08it/s, est. speed input: 34213.00 toks/s, output: 33.41 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:03<00:05, 29.10it/s, est. speed input: 34013.37 toks/s, output: 33.22 toks/s]
Processed prompts:  41%|████      | 104/256 [00:03<00:05, 29.10it/s, est. speed input: 33830.10 toks/s, output: 33.04 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:03<00:05, 29.03it/s, est. speed input: 33650.28 toks/s, output: 32.86 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:03<00:04, 29.06it/s, est. speed input: 33496.27 toks/s, output: 32.71 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:03<00:04, 29.10it/s, est. speed input: 33357.70 toks/s, output: 32.58 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:03<00:04, 29.05it/s, est. speed input: 33218.89 toks/s, output: 32.44 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:03<00:04, 29.04it/s, est. speed input: 33092.66 toks/s, output: 32.32 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:03<00:04, 29.01it/s, est. speed input: 32973.03 toks/s, output: 32.20 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:04<00:04, 29.03it/s, est. speed input: 32865.28 toks/s, output: 32.09 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:04<00:04, 29.02it/s, est. speed input: 32763.05 toks/s, output: 31.99 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:04<00:03, 29.02it/s, est. speed input: 32666.96 toks/s, output: 31.90 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:04<00:03, 28.49it/s, est. speed input: 32515.70 toks/s, output: 31.75 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:04<00:03, 27.93it/s, est. speed input: 32350.98 toks/s, output: 31.59 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:04<00:03, 27.55it/s, est. speed input: 32194.83 toks/s, output: 31.44 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:04<00:03, 27.27it/s, est. speed input: 32047.42 toks/s, output: 31.30 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:05<00:03, 27.13it/s, est. speed input: 31913.15 toks/s, output: 31.17 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:05<00:03, 26.82it/s, est. speed input: 31764.32 toks/s, output: 31.02 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:05<00:03, 26.80it/s, est. speed input: 31643.76 toks/s, output: 30.90 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:05<00:03, 26.76it/s, est. speed input: 31527.60 toks/s, output: 30.79 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:05<00:02, 26.80it/s, est. speed input: 31423.73 toks/s, output: 30.69 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:05<00:02, 26.80it/s, est. speed input: 31323.07 toks/s, output: 30.59 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:06<00:02, 26.81it/s, est. speed input: 31228.15 toks/s, output: 30.50 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:06<00:02, 26.82it/s, est. speed input: 31138.20 toks/s, output: 30.41 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:06<00:02, 26.82it/s, est. speed input: 31051.37 toks/s, output: 30.32 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:06<00:02, 26.81it/s, est. speed input: 30968.13 toks/s, output: 30.24 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:06<00:02, 26.76it/s, est. speed input: 30884.47 toks/s, output: 30.16 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:06<00:01, 27.36it/s, est. speed input: 30857.78 toks/s, output: 30.13 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:06<00:01, 27.14it/s, est. speed input: 30779.72 toks/s, output: 30.06 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:07<00:01, 27.03it/s, est. speed input: 30708.69 toks/s, output: 29.99 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:07<00:01, 26.96it/s, est. speed input: 30641.57 toks/s, output: 29.92 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:07<00:01, 26.86it/s, est. speed input: 30572.86 toks/s, output: 29.86 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:07<00:01, 26.83it/s, est. speed input: 30509.78 toks/s, output: 29.79 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:07<00:01, 26.76it/s, est. speed input: 30445.65 toks/s, output: 29.73 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:07<00:00, 26.78it/s, est. speed input: 30388.57 toks/s, output: 29.68 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:07<00:00, 26.77it/s, est. speed input: 30332.31 toks/s, output: 29.62 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:08<00:00, 26.75it/s, est. speed input: 30277.51 toks/s, output: 29.57 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:08<00:00, 26.73it/s, est. speed input: 30223.46 toks/s, output: 29.52 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:08<00:00, 26.73it/s, est. speed input: 30173.14 toks/s, output: 29.47 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:08<00:00, 26.74it/s, est. speed input: 30124.84 toks/s, output: 29.42 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 27.49it/s, est. speed input: 30124.83 toks/s, output: 29.42 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 27.49it/s, est. speed input: 30124.83 toks/s, output: 29.42 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 29.42it/s, est. speed input: 30124.83 toks/s, output: 29.42 toks/s]
[rank0]:[W125 23:33:16.995239057 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 60.6s

测试结果:
  Requests/s:   26.24
  Tokens/s:     26898.72
  Total Reqs:   256
  Elapsed:      9.76s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     26872.48

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:33:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:33:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=545397) WARNING 01-25 23:33:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=545397) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=545397) WARNING 01-25 23:33:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.48 requests/s, 28165.67 total tokens/s, 27.48 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 23:33:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:33:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:33:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:33:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:33:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:33:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:33:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:33:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:33:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:33:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:33:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:33:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:33:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:33:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:33:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:33:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:33:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=545397) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=545397) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.28it/s]
(EngineCore_DP0 pid=545397) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=545397) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=545397) 
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=545397) [2026-01-25 23:33:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=545397) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  7.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  6.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  2.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.69it/s]
(EngineCore_DP0 pid=545397) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  4.82it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  3.11it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.38it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.43it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 22/512 [00:00<00:02, 214.81it/s]
Adding requests:   9%|▉         | 47/512 [00:00<00:01, 234.38it/s]
Adding requests:  14%|█▍        | 72/512 [00:00<00:01, 239.21it/s]
Adding requests:  19%|█▉        | 96/512 [00:00<00:01, 235.50it/s]
Adding requests:  24%|██▎       | 121/512 [00:00<00:01, 240.21it/s]
Adding requests:  29%|██▊       | 146/512 [00:00<00:01, 239.55it/s]
Adding requests:  34%|███▎      | 172/512 [00:00<00:01, 245.24it/s]
Adding requests:  39%|███▉      | 199/512 [00:00<00:01, 250.19it/s]
Adding requests:  44%|████▍     | 225/512 [00:00<00:01, 245.95it/s]
Adding requests:  49%|████▉     | 250/512 [00:01<00:01, 244.73it/s]
Adding requests:  54%|█████▎    | 275/512 [00:01<00:00, 243.90it/s]
Adding requests:  59%|█████▉    | 301/512 [00:01<00:00, 246.47it/s]
Adding requests:  64%|██████▎   | 326/512 [00:01<00:00, 247.32it/s]
Adding requests:  69%|██████▉   | 353/512 [00:01<00:00, 251.18it/s]
Adding requests:  74%|███████▍  | 379/512 [00:01<00:00, 250.83it/s]
Adding requests:  79%|███████▉  | 407/512 [00:01<00:00, 256.13it/s]
Adding requests:  85%|████████▍ | 433/512 [00:01<00:00, 256.98it/s]
Adding requests:  90%|████████▉ | 459/512 [00:01<00:00, 254.07it/s]
Adding requests:  95%|█████████▌| 487/512 [00:01<00:00, 260.82it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 249.89it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:00<00:02, 213.77it/s, est. speed input: 218935.24 toks/s, output: 213.78 toks/s]
Processed prompts:  12%|█▎        | 64/512 [00:00<00:06, 64.03it/s, est. speed input: 76061.23 toks/s, output: 74.28 toks/s]   
Processed prompts:  15%|█▍        | 75/512 [00:01<00:08, 48.85it/s, est. speed input: 60881.51 toks/s, output: 59.45 toks/s]
Processed prompts:  16%|█▌        | 83/512 [00:01<00:09, 43.52it/s, est. speed input: 55632.91 toks/s, output: 54.33 toks/s]
Processed prompts:  17%|█▋        | 89/512 [00:01<00:09, 43.78it/s, est. speed input: 54874.44 toks/s, output: 53.59 toks/s]
Processed prompts:  19%|█▊        | 95/512 [00:01<00:11, 36.85it/s, est. speed input: 50464.82 toks/s, output: 49.28 toks/s]
Processed prompts:  20%|█▉        | 100/512 [00:02<00:11, 36.98it/s, est. speed input: 49685.67 toks/s, output: 48.52 toks/s]
Processed prompts:  21%|██        | 105/512 [00:02<00:10, 37.08it/s, est. speed input: 48996.80 toks/s, output: 47.85 toks/s]
Processed prompts:  21%|██▏       | 109/512 [00:02<00:11, 35.43it/s, est. speed input: 47947.09 toks/s, output: 46.82 toks/s]
Processed prompts:  22%|██▏       | 113/512 [00:02<00:11, 34.07it/s, est. speed input: 47012.20 toks/s, output: 45.91 toks/s]
Processed prompts:  23%|██▎       | 117/512 [00:02<00:12, 32.83it/s, est. speed input: 46127.82 toks/s, output: 45.05 toks/s]
Processed prompts:  24%|██▎       | 121/512 [00:02<00:12, 31.38it/s, est. speed input: 45200.25 toks/s, output: 44.14 toks/s]
Processed prompts:  24%|██▍       | 125/512 [00:02<00:12, 30.33it/s, est. speed input: 44363.72 toks/s, output: 43.32 toks/s]
Processed prompts:  25%|██▌       | 129/512 [00:03<00:12, 29.57it/s, est. speed input: 43604.94 toks/s, output: 42.58 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:03<00:14, 27.01it/s, est. speed input: 42598.75 toks/s, output: 41.60 toks/s]
Processed prompts:  26%|██▋       | 135/512 [00:03<00:14, 25.17it/s, est. speed input: 41674.38 toks/s, output: 40.70 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:15, 23.85it/s, est. speed input: 40821.53 toks/s, output: 39.86 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:03<00:14, 25.00it/s, est. speed input: 40321.56 toks/s, output: 39.38 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:03<00:14, 25.82it/s, est. speed input: 39864.63 toks/s, output: 38.93 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:03<00:13, 26.36it/s, est. speed input: 39434.57 toks/s, output: 38.51 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:13, 26.75it/s, est. speed input: 39036.93 toks/s, output: 38.12 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:13, 27.03it/s, est. speed input: 38667.50 toks/s, output: 37.76 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:12, 27.25it/s, est. speed input: 38326.00 toks/s, output: 37.43 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:04<00:12, 27.35it/s, est. speed input: 38000.36 toks/s, output: 37.11 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:04<00:12, 27.43it/s, est. speed input: 37694.88 toks/s, output: 36.81 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:04<00:12, 27.52it/s, est. speed input: 37412.97 toks/s, output: 36.54 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:04<00:12, 27.54it/s, est. speed input: 37142.62 toks/s, output: 36.27 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:11, 27.59it/s, est. speed input: 36891.85 toks/s, output: 36.03 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:11, 27.64it/s, est. speed input: 36657.08 toks/s, output: 35.80 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:05<00:11, 27.66it/s, est. speed input: 36433.22 toks/s, output: 35.58 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:05<00:11, 27.68it/s, est. speed input: 36221.28 toks/s, output: 35.37 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:05<00:11, 27.67it/s, est. speed input: 36017.89 toks/s, output: 35.17 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:05<00:10, 29.12it/s, est. speed input: 35975.09 toks/s, output: 35.13 toks/s]
Processed prompts:  40%|████      | 206/512 [00:05<00:10, 28.68it/s, est. speed input: 35789.30 toks/s, output: 34.95 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:10, 28.36it/s, est. speed input: 35609.25 toks/s, output: 34.77 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:10, 28.13it/s, est. speed input: 35437.48 toks/s, output: 34.61 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:06<00:10, 28.00it/s, est. speed input: 35275.72 toks/s, output: 34.45 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:10, 27.93it/s, est. speed input: 35123.28 toks/s, output: 34.30 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:06<00:10, 27.88it/s, est. speed input: 34977.52 toks/s, output: 34.16 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:06<00:10, 27.83it/s, est. speed input: 34836.70 toks/s, output: 34.02 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:06<00:10, 27.78it/s, est. speed input: 34700.40 toks/s, output: 33.89 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:09, 27.72it/s, est. speed input: 34567.51 toks/s, output: 33.76 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:07<00:09, 27.69it/s, est. speed input: 34441.16 toks/s, output: 33.63 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:07<00:09, 28.19it/s, est. speed input: 34361.16 toks/s, output: 33.56 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:07<00:09, 28.70it/s, est. speed input: 34295.31 toks/s, output: 33.49 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:07<00:08, 29.09it/s, est. speed input: 34233.28 toks/s, output: 33.43 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:07<00:08, 29.34it/s, est. speed input: 34171.45 toks/s, output: 33.37 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:07<00:08, 29.52it/s, est. speed input: 34112.33 toks/s, output: 33.31 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:07<00:08, 29.65it/s, est. speed input: 34054.80 toks/s, output: 33.26 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:08<00:08, 29.71it/s, est. speed input: 33997.59 toks/s, output: 33.20 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:08<00:07, 29.79it/s, est. speed input: 33943.96 toks/s, output: 33.15 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:08<00:07, 29.83it/s, est. speed input: 33891.80 toks/s, output: 33.10 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:08<00:07, 29.85it/s, est. speed input: 33840.00 toks/s, output: 33.05 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:08<00:07, 29.87it/s, est. speed input: 33790.61 toks/s, output: 33.00 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:08<00:07, 29.89it/s, est. speed input: 33742.77 toks/s, output: 32.95 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:08<00:07, 29.89it/s, est. speed input: 33696.24 toks/s, output: 32.91 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:09<00:07, 29.94it/s, est. speed input: 33653.41 toks/s, output: 32.86 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:09<00:07, 29.94it/s, est. speed input: 33609.66 toks/s, output: 32.82 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:09<00:06, 29.97it/s, est. speed input: 33569.14 toks/s, output: 32.78 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:09<00:06, 29.99it/s, est. speed input: 33529.44 toks/s, output: 32.74 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:09<00:06, 30.01it/s, est. speed input: 33491.61 toks/s, output: 32.71 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:09<00:06, 30.02it/s, est. speed input: 33454.42 toks/s, output: 32.67 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:09<00:06, 30.03it/s, est. speed input: 33418.10 toks/s, output: 32.63 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:09<00:06, 30.04it/s, est. speed input: 33383.22 toks/s, output: 32.60 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:10<00:06, 30.03it/s, est. speed input: 33348.11 toks/s, output: 32.57 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:10<00:05, 29.95it/s, est. speed input: 33310.80 toks/s, output: 32.53 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:10<00:05, 29.93it/s, est. speed input: 33275.75 toks/s, output: 32.50 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:10<00:05, 29.90it/s, est. speed input: 33241.05 toks/s, output: 32.46 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:10<00:05, 29.70it/s, est. speed input: 33198.75 toks/s, output: 32.42 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:10<00:05, 29.03it/s, est. speed input: 33132.10 toks/s, output: 32.36 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:10<00:05, 28.60it/s, est. speed input: 33068.48 toks/s, output: 32.29 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:11<00:05, 28.27it/s, est. speed input: 33004.69 toks/s, output: 32.23 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:11<00:05, 28.08it/s, est. speed input: 32944.25 toks/s, output: 32.17 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:11<00:05, 27.94it/s, est. speed input: 32884.88 toks/s, output: 32.11 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:11<00:05, 27.85it/s, est. speed input: 32827.48 toks/s, output: 32.06 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:11<00:04, 27.75it/s, est. speed input: 32769.65 toks/s, output: 32.00 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:11<00:04, 27.71it/s, est. speed input: 32714.72 toks/s, output: 31.95 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:12<00:00, 112.46it/s, est. speed input: 36570.49 toks/s, output: 35.71 toks/s]
Processed prompts:  86%|████████▌ | 440/512 [00:12<00:00, 78.79it/s, est. speed input: 36540.58 toks/s, output: 35.68 toks/s] 
Processed prompts:  88%|████████▊ | 448/512 [00:12<00:01, 59.26it/s, est. speed input: 36350.01 toks/s, output: 35.50 toks/s]
Processed prompts:  89%|████████▉ | 455/512 [00:12<00:01, 46.83it/s, est. speed input: 36086.95 toks/s, output: 35.24 toks/s]
Processed prompts:  90%|█████████ | 461/512 [00:13<00:01, 45.73it/s, est. speed input: 36156.35 toks/s, output: 35.31 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:13<00:01, 35.31it/s, est. speed input: 35753.10 toks/s, output: 34.92 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:13<00:01, 33.72it/s, est. speed input: 35672.43 toks/s, output: 34.84 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:13<00:01, 32.30it/s, est. speed input: 35592.28 toks/s, output: 34.76 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:13<00:01, 31.13it/s, est. speed input: 35514.52 toks/s, output: 34.68 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:13<00:00, 30.24it/s, est. speed input: 35440.12 toks/s, output: 34.61 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:14<00:00, 29.55it/s, est. speed input: 35367.37 toks/s, output: 34.54 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:14<00:00, 29.02it/s, est. speed input: 35295.40 toks/s, output: 34.47 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:14<00:00, 28.63it/s, est. speed input: 35225.09 toks/s, output: 34.40 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:14<00:00, 28.33it/s, est. speed input: 35155.44 toks/s, output: 34.33 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:14<00:00, 28.14it/s, est. speed input: 35088.15 toks/s, output: 34.27 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:14<00:00, 27.97it/s, est. speed input: 35020.80 toks/s, output: 34.20 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:14<00:00, 29.85it/s, est. speed input: 35031.72 toks/s, output: 34.21 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:14<00:00, 29.85it/s, est. speed input: 35168.59 toks/s, output: 34.34 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:14<00:00, 34.34it/s, est. speed input: 35168.59 toks/s, output: 34.34 toks/s]
[rank0]:[W125 23:34:29.422348494 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 72.4s

测试结果:
  Requests/s:   27.48
  Tokens/s:     28165.67
  Total Reqs:   512
  Elapsed:      18.63s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     28138.19

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:34:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:34:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=546741) WARNING 01-25 23:34:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=546741) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=546741) WARNING 01-25 23:35:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.92 requests/s, 28615.90 total tokens/s, 27.92 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 23:34:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:34:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:34:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:34:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:34:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:34:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:34:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:34:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:34:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:34:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:34:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:34:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:34:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:34:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:34:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:34:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:34:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=546741) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=546741) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.27it/s]
(EngineCore_DP0 pid=546741) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.04s/it]
(EngineCore_DP0 pid=546741) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.00s/it]
(EngineCore_DP0 pid=546741) 
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=546741) [2026-01-25 23:34:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=546741) [2026-01-25 23:35:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=546741) [2026-01-25 23:35:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=546741) [2026-01-25 23:35:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=546741) [2026-01-25 23:35:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=546741) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 157.18it/s]
(EngineCore_DP0 pid=546741) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.87it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.74it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  9.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.07it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 21/1024 [00:00<00:04, 202.14it/s]
Adding requests:   4%|▍         | 45/1024 [00:00<00:04, 219.94it/s]
Adding requests:   7%|▋         | 70/1024 [00:00<00:04, 231.59it/s]
Adding requests:   9%|▉         | 94/1024 [00:00<00:04, 226.68it/s]
Adding requests:  11%|█▏        | 117/1024 [00:00<00:04, 226.62it/s]
Adding requests:  14%|█▍        | 141/1024 [00:00<00:03, 228.78it/s]
Adding requests:  16%|█▌        | 164/1024 [00:00<00:03, 226.50it/s]
Adding requests:  18%|█▊        | 187/1024 [00:00<00:03, 225.28it/s]
Adding requests:  21%|██        | 211/1024 [00:00<00:03, 228.07it/s]
Adding requests:  23%|██▎       | 236/1024 [00:01<00:03, 233.21it/s]
Adding requests:  25%|██▌       | 260/1024 [00:01<00:03, 232.65it/s]
Adding requests:  28%|██▊       | 286/1024 [00:01<00:03, 239.95it/s]
Adding requests:  31%|███       | 313/1024 [00:01<00:02, 247.48it/s]
Adding requests:  33%|███▎      | 339/1024 [00:01<00:02, 248.18it/s]
Adding requests:  36%|███▌      | 366/1024 [00:01<00:02, 251.33it/s]
Adding requests:  38%|███▊      | 392/1024 [00:01<00:02, 252.66it/s]
Adding requests:  41%|████      | 419/1024 [00:01<00:02, 256.50it/s]
Adding requests:  43%|████▎     | 445/1024 [00:01<00:02, 247.99it/s]
Adding requests:  46%|████▌     | 472/1024 [00:01<00:02, 252.12it/s]
Adding requests:  49%|████▊     | 498/1024 [00:02<00:02, 253.28it/s]
Adding requests:  51%|█████▏    | 525/1024 [00:02<00:01, 258.06it/s]
Adding requests:  54%|█████▍    | 551/1024 [00:02<00:01, 251.80it/s]
Adding requests:  56%|█████▋    | 577/1024 [00:02<00:01, 252.44it/s]
Adding requests:  59%|█████▉    | 603/1024 [00:02<00:01, 245.23it/s]
Adding requests:  61%|██████▏   | 628/1024 [00:02<00:01, 239.92it/s]
Adding requests:  64%|██████▍   | 653/1024 [00:02<00:01, 234.72it/s]
Adding requests:  66%|██████▌   | 677/1024 [00:02<00:01, 233.80it/s]
Adding requests:  69%|██████▊   | 702/1024 [00:02<00:01, 235.68it/s]
Adding requests:  71%|███████   | 726/1024 [00:03<00:01, 233.69it/s]
Adding requests:  73%|███████▎  | 750/1024 [00:03<00:01, 230.10it/s]
Adding requests:  76%|███████▌  | 775/1024 [00:03<00:01, 233.64it/s]
Adding requests:  78%|███████▊  | 800/1024 [00:03<00:00, 237.26it/s]
Adding requests:  80%|████████  | 824/1024 [00:03<00:00, 236.54it/s]
Adding requests:  83%|████████▎ | 850/1024 [00:03<00:00, 241.09it/s]
Adding requests:  85%|████████▌ | 875/1024 [00:03<00:00, 242.64it/s]
Adding requests:  88%|████████▊ | 900/1024 [00:03<00:00, 242.60it/s]
Adding requests:  90%|█████████ | 925/1024 [00:03<00:00, 236.68it/s]
Adding requests:  93%|█████████▎| 949/1024 [00:03<00:00, 237.18it/s]
Adding requests:  95%|█████████▌| 974/1024 [00:04<00:00, 240.61it/s]
Adding requests:  98%|█████████▊| 999/1024 [00:04<00:00, 240.01it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 241.53it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 239.67it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:00<00:02, 442.09it/s, est. speed input: 452761.75 toks/s, output: 442.11 toks/s]
Processed prompts:  14%|█▍        | 143/1024 [00:01<00:11, 75.57it/s, est. speed input: 93287.35 toks/s, output: 91.10 toks/s]  
Processed prompts:  16%|█▌        | 164/1024 [00:02<00:15, 54.34it/s, est. speed input: 70944.69 toks/s, output: 69.28 toks/s]
Processed prompts:  17%|█▋        | 177/1024 [00:02<00:15, 53.42it/s, est. speed input: 68838.88 toks/s, output: 67.23 toks/s]
Processed prompts:  18%|█▊        | 187/1024 [00:03<00:19, 41.85it/s, est. speed input: 60333.84 toks/s, output: 58.92 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:03<00:21, 38.32it/s, est. speed input: 57383.32 toks/s, output: 56.04 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:03<00:22, 36.76it/s, est. speed input: 55575.40 toks/s, output: 54.27 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:04<00:23, 34.54it/s, est. speed input: 53622.09 toks/s, output: 52.36 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:04<00:24, 32.77it/s, est. speed input: 51930.54 toks/s, output: 50.71 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:04<00:25, 31.41it/s, est. speed input: 50450.84 toks/s, output: 49.27 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:04<00:25, 30.40it/s, est. speed input: 49151.17 toks/s, output: 48.00 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:05<00:26, 29.64it/s, est. speed input: 47993.27 toks/s, output: 46.87 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:05<00:26, 29.09it/s, est. speed input: 46957.40 toks/s, output: 45.86 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:05<00:26, 28.70it/s, est. speed input: 46026.81 toks/s, output: 44.95 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:06<00:26, 28.42it/s, est. speed input: 45185.43 toks/s, output: 44.13 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:06<00:26, 28.22it/s, est. speed input: 44419.46 toks/s, output: 43.38 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:06<00:26, 28.09it/s, est. speed input: 43722.23 toks/s, output: 42.70 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:06<00:26, 27.99it/s, est. speed input: 43082.97 toks/s, output: 42.07 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:07<00:26, 27.92it/s, est. speed input: 42493.31 toks/s, output: 41.50 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:07<00:25, 27.85it/s, est. speed input: 41947.54 toks/s, output: 40.96 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:07<00:25, 27.81it/s, est. speed input: 41441.97 toks/s, output: 40.47 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:08<00:25, 27.78it/s, est. speed input: 40973.06 toks/s, output: 40.01 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:08<00:25, 27.75it/s, est. speed input: 40536.18 toks/s, output: 39.59 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:08<00:24, 27.94it/s, est. speed input: 40160.90 toks/s, output: 39.22 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:08<00:23, 28.52it/s, est. speed input: 39876.90 toks/s, output: 38.94 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:09<00:23, 28.95it/s, est. speed input: 39610.16 toks/s, output: 38.68 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:09<00:22, 29.26it/s, est. speed input: 39358.70 toks/s, output: 38.44 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:09<00:22, 29.47it/s, est. speed input: 39120.09 toks/s, output: 38.20 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:09<00:21, 29.63it/s, est. speed input: 38895.85 toks/s, output: 37.98 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:10<00:21, 29.75it/s, est. speed input: 38682.75 toks/s, output: 37.78 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:10<00:21, 29.83it/s, est. speed input: 38480.65 toks/s, output: 37.58 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:10<00:20, 29.88it/s, est. speed input: 38287.89 toks/s, output: 37.39 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:11<00:20, 29.91it/s, est. speed input: 38104.27 toks/s, output: 37.21 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:11<00:20, 29.41it/s, est. speed input: 37876.47 toks/s, output: 36.99 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:11<00:20, 28.87it/s, est. speed input: 37638.88 toks/s, output: 36.76 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:11<00:20, 28.49it/s, est. speed input: 37411.65 toks/s, output: 36.53 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:12<00:20, 28.24it/s, est. speed input: 37195.43 toks/s, output: 36.32 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:12<00:20, 28.06it/s, est. speed input: 36989.65 toks/s, output: 36.12 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:12<00:20, 27.95it/s, est. speed input: 36793.64 toks/s, output: 35.93 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:13<00:20, 27.85it/s, est. speed input: 36605.22 toks/s, output: 35.75 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:13<00:19, 27.79it/s, est. speed input: 36425.24 toks/s, output: 35.57 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:13<00:19, 27.75it/s, est. speed input: 36253.03 toks/s, output: 35.40 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:13<00:19, 27.72it/s, est. speed input: 36087.52 toks/s, output: 35.24 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:14<00:18, 27.71it/s, est. speed input: 35930.22 toks/s, output: 35.09 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:14<00:18, 27.69it/s, est. speed input: 35777.64 toks/s, output: 34.94 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:14<00:18, 27.68it/s, est. speed input: 35631.63 toks/s, output: 34.80 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:15<00:18, 27.67it/s, est. speed input: 35490.90 toks/s, output: 34.66 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:15<00:17, 27.66it/s, est. speed input: 35355.25 toks/s, output: 34.53 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:15<00:17, 27.66it/s, est. speed input: 35225.13 toks/s, output: 34.40 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:15<00:17, 27.66it/s, est. speed input: 35099.85 toks/s, output: 34.28 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:16<00:16, 27.65it/s, est. speed input: 34978.68 toks/s, output: 34.16 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:16<00:16, 27.80it/s, est. speed input: 34872.68 toks/s, output: 34.06 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:16<00:15, 28.41it/s, est. speed input: 34805.58 toks/s, output: 33.99 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:17<00:15, 28.85it/s, est. speed input: 34740.20 toks/s, output: 33.93 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:17<00:15, 29.16it/s, est. speed input: 34676.49 toks/s, output: 33.86 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:17<00:14, 29.39it/s, est. speed input: 34615.41 toks/s, output: 33.80 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:17<00:14, 29.55it/s, est. speed input: 34556.02 toks/s, output: 33.75 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:18<00:13, 29.65it/s, est. speed input: 34497.62 toks/s, output: 33.69 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:18<00:13, 29.73it/s, est. speed input: 34441.50 toks/s, output: 33.63 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:18<00:13, 29.79it/s, est. speed input: 34387.23 toks/s, output: 33.58 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:18<00:13, 29.83it/s, est. speed input: 34334.17 toks/s, output: 33.53 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:19<00:12, 29.69it/s, est. speed input: 34273.77 toks/s, output: 33.47 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:19<00:12, 29.03it/s, est. speed input: 34184.20 toks/s, output: 33.38 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:19<00:12, 28.60it/s, est. speed input: 34098.19 toks/s, output: 33.30 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:20<00:12, 28.28it/s, est. speed input: 34012.88 toks/s, output: 33.22 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:20<00:12, 28.08it/s, est. speed input: 33931.50 toks/s, output: 33.14 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:20<00:12, 27.94it/s, est. speed input: 33851.95 toks/s, output: 33.06 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:20<00:12, 27.83it/s, est. speed input: 33774.37 toks/s, output: 32.98 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:21<00:11, 27.76it/s, est. speed input: 33698.82 toks/s, output: 32.91 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:21<00:11, 27.71it/s, est. speed input: 33625.50 toks/s, output: 32.84 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:21<00:11, 27.68it/s, est. speed input: 33554.10 toks/s, output: 32.77 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:22<00:10, 27.66it/s, est. speed input: 33485.00 toks/s, output: 32.70 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:22<00:10, 27.63it/s, est. speed input: 33416.45 toks/s, output: 32.63 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:22<00:10, 27.62it/s, est. speed input: 33350.44 toks/s, output: 32.57 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:22<00:10, 27.60it/s, est. speed input: 33285.69 toks/s, output: 32.51 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:23<00:09, 27.59it/s, est. speed input: 33222.62 toks/s, output: 32.44 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:23<00:09, 27.58it/s, est. speed input: 33160.74 toks/s, output: 32.38 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:23<00:09, 27.58it/s, est. speed input: 33100.67 toks/s, output: 32.32 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:24<00:08, 27.58it/s, est. speed input: 33042.17 toks/s, output: 32.27 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:24<00:08, 28.48it/s, est. speed input: 33026.47 toks/s, output: 32.25 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:24<00:02, 83.97it/s, est. speed input: 35043.36 toks/s, output: 34.22 toks/s]
Processed prompts:  83%|████████▎ | 852/1024 [00:24<00:02, 69.93it/s, est. speed input: 35077.49 toks/s, output: 34.26 toks/s]
Processed prompts:  84%|████████▍ | 860/1024 [00:25<00:02, 57.86it/s, est. speed input: 35028.94 toks/s, output: 34.21 toks/s]
Processed prompts:  85%|████████▍ | 867/1024 [00:25<00:03, 48.33it/s, est. speed input: 34941.83 toks/s, output: 34.12 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:25<00:03, 41.65it/s, est. speed input: 34855.93 toks/s, output: 34.04 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:25<00:03, 38.09it/s, est. speed input: 34811.21 toks/s, output: 34.00 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:26<00:03, 35.61it/s, est. speed input: 34767.60 toks/s, output: 33.95 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:26<00:03, 33.87it/s, est. speed input: 34724.57 toks/s, output: 33.91 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:26<00:03, 32.66it/s, est. speed input: 34682.72 toks/s, output: 33.87 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:27<00:03, 31.82it/s, est. speed input: 34642.00 toks/s, output: 33.83 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:27<00:03, 30.80it/s, est. speed input: 34586.25 toks/s, output: 33.78 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:27<00:03, 29.78it/s, est. speed input: 34519.30 toks/s, output: 33.71 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:27<00:02, 29.08it/s, est. speed input: 34453.23 toks/s, output: 33.65 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:28<00:02, 28.61it/s, est. speed input: 34388.65 toks/s, output: 33.58 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:28<00:02, 28.28it/s, est. speed input: 34325.49 toks/s, output: 33.52 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:28<00:02, 28.05it/s, est. speed input: 34263.53 toks/s, output: 33.46 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:29<00:01, 27.90it/s, est. speed input: 34202.80 toks/s, output: 33.40 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:29<00:01, 27.78it/s, est. speed input: 34143.11 toks/s, output: 33.34 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:29<00:01, 27.71it/s, est. speed input: 34084.86 toks/s, output: 33.29 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:29<00:01, 27.66it/s, est. speed input: 34027.73 toks/s, output: 33.23 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:30<00:00, 27.62it/s, est. speed input: 33971.65 toks/s, output: 33.18 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:30<00:00, 27.60it/s, est. speed input: 33916.92 toks/s, output: 33.12 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:30<00:00, 28.57it/s, est. speed input: 33899.76 toks/s, output: 33.11 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:30<00:00, 28.57it/s, est. speed input: 34099.23 toks/s, output: 33.30 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:30<00:00, 33.30it/s, est. speed input: 34099.23 toks/s, output: 33.30 toks/s]
[rank0]:[W125 23:36:05.125753381 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 96.1s

测试结果:
  Requests/s:   27.92
  Tokens/s:     28615.90
  Total Reqs:   1024
  Elapsed:      36.68s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     28587.99

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:36:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:36:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=548436) WARNING 01-25 23:36:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=548436) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=548436) WARNING 01-25 23:36:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.19 requests/s, 28898.67 total tokens/s, 28.19 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 23:36:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:36:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:36:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:36:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:36:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:36:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:36:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:36:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:36:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:36:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:36:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:36:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:36:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:36:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:36:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:36:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:36:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=548436) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=548436) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.26it/s]
(EngineCore_DP0 pid=548436) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.03s/it]
(EngineCore_DP0 pid=548436) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=548436) 
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=548436) [2026-01-25 23:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=548436) [rank0]:W0125 23:37:02.568000 548436 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=548436) [rank0]:W0125 23:37:02.689000 548436 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=548436) [rank0]:W0125 23:37:04.396000 548436 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=548436) [rank0]:W0125 23:37:04.572000 548436 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=548436) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  7.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  3.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.61it/s]
(EngineCore_DP0 pid=548436) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.48it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.37it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 20/2048 [00:00<00:10, 198.68it/s]
Adding requests:   2%|▏         | 44/2048 [00:00<00:09, 219.15it/s]
Adding requests:   3%|▎         | 68/2048 [00:00<00:08, 225.69it/s]
Adding requests:   4%|▍         | 91/2048 [00:00<00:08, 218.75it/s]
Adding requests:   6%|▌         | 113/2048 [00:00<00:08, 217.60it/s]
Adding requests:   7%|▋         | 136/2048 [00:00<00:08, 219.68it/s]
Adding requests:   8%|▊         | 160/2048 [00:00<00:08, 224.90it/s]
Adding requests:   9%|▉         | 185/2048 [00:00<00:08, 231.93it/s]
Adding requests:  10%|█         | 210/2048 [00:00<00:07, 235.41it/s]
Adding requests:  11%|█▏        | 235/2048 [00:01<00:07, 238.43it/s]
Adding requests:  13%|█▎        | 259/2048 [00:01<00:07, 238.26it/s]
Adding requests:  14%|█▍        | 284/2048 [00:01<00:07, 240.10it/s]
Adding requests:  15%|█▌        | 310/2048 [00:01<00:07, 244.60it/s]
Adding requests:  16%|█▋        | 337/2048 [00:01<00:06, 249.42it/s]
Adding requests:  18%|█▊        | 363/2048 [00:01<00:06, 251.07it/s]
Adding requests:  19%|█▉        | 389/2048 [00:01<00:06, 250.39it/s]
Adding requests:  20%|██        | 417/2048 [00:01<00:06, 256.64it/s]
Adding requests:  22%|██▏       | 443/2048 [00:01<00:06, 246.15it/s]
Adding requests:  23%|██▎       | 468/2048 [00:01<00:06, 243.80it/s]
Adding requests:  24%|██▍       | 495/2048 [00:02<00:06, 248.04it/s]
Adding requests:  25%|██▌       | 522/2048 [00:02<00:06, 253.87it/s]
Adding requests:  27%|██▋       | 548/2048 [00:02<00:05, 250.02it/s]
Adding requests:  28%|██▊       | 574/2048 [00:02<00:05, 250.10it/s]
Adding requests:  29%|██▉       | 600/2048 [00:02<00:06, 240.13it/s]
Adding requests:  31%|███       | 625/2048 [00:02<00:06, 235.14it/s]
Adding requests:  32%|███▏      | 649/2048 [00:02<00:06, 230.74it/s]
Adding requests:  33%|███▎      | 673/2048 [00:02<00:06, 227.44it/s]
Adding requests:  34%|███▍      | 698/2048 [00:02<00:05, 231.10it/s]
Adding requests:  35%|███▌      | 722/2048 [00:03<00:05, 229.63it/s]
Adding requests:  36%|███▋      | 745/2048 [00:03<00:05, 225.78it/s]
Adding requests:  38%|███▊      | 768/2048 [00:03<00:05, 222.74it/s]
Adding requests:  39%|███▉      | 794/2048 [00:03<00:05, 231.58it/s]
Adding requests:  40%|████      | 820/2048 [00:03<00:05, 238.54it/s]
Adding requests:  41%|████▏     | 847/2048 [00:03<00:04, 247.66it/s]
Adding requests:  43%|████▎     | 874/2048 [00:03<00:04, 250.97it/s]
Adding requests:  44%|████▍     | 900/2048 [00:03<00:04, 252.33it/s]
Adding requests:  45%|████▌     | 926/2048 [00:03<00:04, 247.03it/s]
Adding requests:  46%|████▋     | 951/2048 [00:03<00:04, 246.27it/s]
Adding requests:  48%|████▊     | 978/2048 [00:04<00:04, 250.85it/s]
Adding requests:  49%|████▉     | 1004/2048 [00:04<00:04, 250.76it/s]
Adding requests:  50%|█████     | 1031/2048 [00:04<00:03, 255.29it/s]
Adding requests:  52%|█████▏    | 1057/2048 [00:04<00:03, 255.99it/s]
Adding requests:  53%|█████▎    | 1083/2048 [00:04<00:03, 255.38it/s]
Adding requests:  54%|█████▍    | 1109/2048 [00:04<00:03, 256.52it/s]
Adding requests:  56%|█████▌    | 1139/2048 [00:04<00:03, 267.06it/s]
Adding requests:  57%|█████▋    | 1166/2048 [00:04<00:03, 260.14it/s]
Adding requests:  58%|█████▊    | 1193/2048 [00:04<00:03, 260.92it/s]
Adding requests:  60%|█████▉    | 1222/2048 [00:05<00:03, 265.76it/s]
Adding requests:  61%|██████    | 1249/2048 [00:05<00:03, 255.54it/s]
Adding requests:  62%|██████▏   | 1275/2048 [00:05<00:03, 251.04it/s]
Adding requests:  64%|██████▎   | 1301/2048 [00:05<00:02, 249.20it/s]
Adding requests:  65%|██████▍   | 1327/2048 [00:05<00:02, 252.03it/s]
Adding requests:  66%|██████▌   | 1354/2048 [00:05<00:02, 256.27it/s]
Adding requests:  67%|██████▋   | 1380/2048 [00:05<00:02, 256.79it/s]
Adding requests:  69%|██████▊   | 1407/2048 [00:05<00:02, 257.49it/s]
Adding requests:  70%|██████▉   | 1433/2048 [00:05<00:02, 255.47it/s]
Adding requests:  71%|███████   | 1459/2048 [00:05<00:02, 252.45it/s]
Adding requests:  73%|███████▎  | 1485/2048 [00:06<00:02, 250.06it/s]
Adding requests:  74%|███████▍  | 1511/2048 [00:06<00:02, 251.46it/s]
Adding requests:  75%|███████▌  | 1537/2048 [00:06<00:02, 240.30it/s]
Adding requests:  76%|███████▋  | 1562/2048 [00:06<00:02, 235.92it/s]
Adding requests:  77%|███████▋  | 1586/2048 [00:06<00:01, 232.80it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:06<00:01, 234.54it/s]
Adding requests:  80%|███████▉  | 1635/2048 [00:06<00:01, 228.66it/s]
Adding requests:  81%|████████  | 1658/2048 [00:06<00:01, 225.19it/s]
Adding requests:  82%|████████▏ | 1681/2048 [00:06<00:01, 225.11it/s]
Adding requests:  83%|████████▎ | 1706/2048 [00:07<00:01, 230.61it/s]
Adding requests:  85%|████████▍ | 1732/2048 [00:07<00:01, 236.08it/s]
Adding requests:  86%|████████▌ | 1758/2048 [00:07<00:01, 240.76it/s]
Adding requests:  87%|████████▋ | 1784/2048 [00:07<00:01, 244.84it/s]
Adding requests:  88%|████████▊ | 1809/2048 [00:07<00:00, 243.46it/s]
Adding requests:  90%|████████▉ | 1834/2048 [00:07<00:00, 244.06it/s]
Adding requests:  91%|█████████ | 1859/2048 [00:07<00:00, 245.76it/s]
Adding requests:  92%|█████████▏| 1885/2048 [00:07<00:00, 249.30it/s]
Adding requests:  93%|█████████▎| 1910/2048 [00:07<00:00, 238.59it/s]
Adding requests:  95%|█████████▍| 1936/2048 [00:07<00:00, 242.89it/s]
Adding requests:  96%|█████████▌| 1961/2048 [00:08<00:00, 241.84it/s]
Adding requests:  97%|█████████▋| 1986/2048 [00:08<00:00, 237.70it/s]
Adding requests:  98%|█████████▊| 2010/2048 [00:08<00:00, 230.72it/s]
Adding requests:  99%|█████████▉| 2034/2048 [00:08<00:00, 229.31it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 242.31it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:00<00:01, 1372.81it/s, est. speed input: 1406060.99 toks/s, output: 1372.90 toks/s]
Processed prompts:  17%|█▋        | 348/2048 [00:04<00:26, 63.29it/s, est. speed input: 78332.95 toks/s, output: 76.50 toks/s]      
Processed prompts:  20%|█▉        | 407/2048 [00:06<00:34, 47.97it/s, est. speed input: 61421.65 toks/s, output: 59.98 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:07<00:29, 54.34it/s, est. speed input: 64231.36 toks/s, output: 62.73 toks/s]
Processed prompts:  24%|██▍       | 490/2048 [00:08<00:29, 52.33it/s, est. speed input: 62668.45 toks/s, output: 61.20 toks/s]
Processed prompts:  25%|██▍       | 507/2048 [00:08<00:32, 48.13it/s, est. speed input: 60484.00 toks/s, output: 59.07 toks/s]
Processed prompts:  25%|██▌       | 519/2048 [00:09<00:36, 42.46it/s, est. speed input: 58015.89 toks/s, output: 56.66 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:09<00:40, 37.11it/s, est. speed input: 55735.11 toks/s, output: 54.43 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:10<00:42, 34.95it/s, est. speed input: 54261.08 toks/s, output: 52.99 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:10<00:44, 33.73it/s, est. speed input: 53102.27 toks/s, output: 51.86 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:11<00:44, 32.76it/s, est. speed input: 52053.57 toks/s, output: 50.83 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:11<00:45, 32.01it/s, est. speed input: 51097.33 toks/s, output: 49.90 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:12<00:45, 31.45it/s, est. speed input: 50223.48 toks/s, output: 49.05 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:12<00:45, 31.04it/s, est. speed input: 49421.14 toks/s, output: 48.26 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:13<00:45, 30.60it/s, est. speed input: 48652.70 toks/s, output: 47.51 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:14<00:46, 29.70it/s, est. speed input: 47820.35 toks/s, output: 46.70 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:14<00:47, 29.09it/s, est. speed input: 47053.70 toks/s, output: 45.95 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:15<00:47, 28.66it/s, est. speed input: 46344.85 toks/s, output: 45.26 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:15<00:47, 28.37it/s, est. speed input: 45687.59 toks/s, output: 44.62 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:16<00:47, 28.16it/s, est. speed input: 45076.60 toks/s, output: 44.02 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:16<00:46, 28.02it/s, est. speed input: 44507.14 toks/s, output: 43.46 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:17<00:46, 27.91it/s, est. speed input: 43974.34 toks/s, output: 42.94 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:18<00:45, 27.84it/s, est. speed input: 43475.58 toks/s, output: 42.46 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:18<00:44, 28.23it/s, est. speed input: 43077.35 toks/s, output: 42.07 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:19<00:44, 28.05it/s, est. speed input: 42633.62 toks/s, output: 41.63 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:19<00:43, 27.97it/s, est. speed input: 42221.27 toks/s, output: 41.23 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:20<00:42, 28.53it/s, est. speed input: 41918.07 toks/s, output: 40.94 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:20<00:41, 28.94it/s, est. speed input: 41630.62 toks/s, output: 40.65 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:21<00:40, 29.23it/s, est. speed input: 41357.11 toks/s, output: 40.39 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:22<00:40, 28.77it/s, est. speed input: 41018.25 toks/s, output: 40.06 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:22<00:40, 28.43it/s, est. speed input: 40692.64 toks/s, output: 39.74 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:23<00:40, 28.18it/s, est. speed input: 40383.19 toks/s, output: 39.44 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:23<00:39, 28.02it/s, est. speed input: 40088.58 toks/s, output: 39.15 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:24<00:39, 27.90it/s, est. speed input: 39807.73 toks/s, output: 38.87 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:24<00:39, 27.82it/s, est. speed input: 39540.23 toks/s, output: 38.61 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:25<00:38, 27.76it/s, est. speed input: 39284.67 toks/s, output: 38.36 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:26<00:38, 27.72it/s, est. speed input: 39040.87 toks/s, output: 38.13 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:26<00:37, 27.70it/s, est. speed input: 38807.43 toks/s, output: 37.90 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:27<00:36, 28.28it/s, est. speed input: 38642.38 toks/s, output: 37.74 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:27<00:34, 28.77it/s, est. speed input: 38489.25 toks/s, output: 37.59 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:28<00:34, 29.11it/s, est. speed input: 38341.39 toks/s, output: 37.44 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:28<00:33, 29.37it/s, est. speed input: 38199.55 toks/s, output: 37.30 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:29<00:32, 29.54it/s, est. speed input: 38062.66 toks/s, output: 37.17 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:29<00:32, 29.20it/s, est. speed input: 37894.15 toks/s, output: 37.01 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:30<00:32, 28.70it/s, est. speed input: 37710.41 toks/s, output: 36.83 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:31<00:32, 28.38it/s, est. speed input: 37535.45 toks/s, output: 36.66 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:31<00:31, 28.15it/s, est. speed input: 37366.19 toks/s, output: 36.49 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:32<00:31, 28.00it/s, est. speed input: 37203.62 toks/s, output: 36.33 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:32<00:30, 27.88it/s, est. speed input: 37046.10 toks/s, output: 36.18 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:33<00:30, 27.81it/s, est. speed input: 36894.54 toks/s, output: 36.03 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:33<00:29, 27.76it/s, est. speed input: 36747.98 toks/s, output: 35.89 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:34<00:29, 27.82it/s, est. speed input: 36613.48 toks/s, output: 35.75 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:35<00:28, 28.43it/s, est. speed input: 36522.92 toks/s, output: 35.67 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:35<00:27, 28.87it/s, est. speed input: 36435.29 toks/s, output: 35.58 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:36<00:26, 29.19it/s, est. speed input: 36350.05 toks/s, output: 35.50 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:36<00:25, 29.41it/s, est. speed input: 36267.01 toks/s, output: 35.42 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:37<00:24, 29.58it/s, est. speed input: 36187.10 toks/s, output: 35.34 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:37<00:12, 54.12it/s, est. speed input: 37336.76 toks/s, output: 36.46 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:38<00:14, 46.04it/s, est. speed input: 37201.78 toks/s, output: 36.33 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:38<00:15, 40.46it/s, est. speed input: 37070.66 toks/s, output: 36.20 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:39<00:16, 36.60it/s, est. speed input: 36943.45 toks/s, output: 36.08 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:40<00:17, 33.91it/s, est. speed input: 36819.87 toks/s, output: 35.96 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:40<00:18, 32.04it/s, est. speed input: 36699.69 toks/s, output: 35.84 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:41<00:18, 30.73it/s, est. speed input: 36583.02 toks/s, output: 35.73 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:41<00:18, 29.83it/s, est. speed input: 36470.16 toks/s, output: 35.62 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:42<00:18, 29.83it/s, est. speed input: 36394.89 toks/s, output: 35.54 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:42<00:17, 29.86it/s, est. speed input: 36323.49 toks/s, output: 35.47 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:43<00:17, 29.89it/s, est. speed input: 36254.08 toks/s, output: 35.40 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:43<00:16, 29.91it/s, est. speed input: 36186.18 toks/s, output: 35.34 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:44<00:15, 29.91it/s, est. speed input: 36119.73 toks/s, output: 35.27 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:45<00:15, 29.93it/s, est. speed input: 36055.19 toks/s, output: 35.21 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:45<00:14, 29.88it/s, est. speed input: 35989.67 toks/s, output: 35.15 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:46<00:14, 29.67it/s, est. speed input: 35917.01 toks/s, output: 35.08 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:46<00:14, 29.04it/s, est. speed input: 35822.83 toks/s, output: 34.98 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:47<00:13, 28.60it/s, est. speed input: 35730.82 toks/s, output: 34.89 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:47<00:13, 28.31it/s, est. speed input: 35641.09 toks/s, output: 34.81 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:48<00:13, 28.11it/s, est. speed input: 35553.41 toks/s, output: 34.72 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:49<00:12, 27.97it/s, est. speed input: 35467.94 toks/s, output: 34.64 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:49<00:11, 27.86it/s, est. speed input: 35384.14 toks/s, output: 34.55 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:50<00:11, 27.80it/s, est. speed input: 35302.77 toks/s, output: 34.48 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:50<00:10, 27.75it/s, est. speed input: 35222.97 toks/s, output: 34.40 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:51<00:10, 27.72it/s, est. speed input: 35144.78 toks/s, output: 34.32 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:51<00:09, 27.69it/s, est. speed input: 35068.52 toks/s, output: 34.25 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:52<00:08, 28.31it/s, est. speed input: 35022.81 toks/s, output: 34.20 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:52<00:08, 28.78it/s, est. speed input: 34978.83 toks/s, output: 34.16 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:53<00:07, 29.12it/s, est. speed input: 34935.52 toks/s, output: 34.12 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:54<00:07, 28.73it/s, est. speed input: 34867.52 toks/s, output: 34.05 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:54<00:06, 28.39it/s, est. speed input: 34798.07 toks/s, output: 33.98 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:55<00:06, 28.16it/s, est. speed input: 34730.05 toks/s, output: 33.92 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:55<00:05, 28.01it/s, est. speed input: 34663.58 toks/s, output: 33.85 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:56<00:05, 27.89it/s, est. speed input: 34598.19 toks/s, output: 33.79 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:56<00:04, 27.82it/s, est. speed input: 34534.24 toks/s, output: 33.72 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:57<00:03, 27.77it/s, est. speed input: 34471.72 toks/s, output: 33.66 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:58<00:03, 27.73it/s, est. speed input: 34410.28 toks/s, output: 33.60 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:58<00:02, 27.71it/s, est. speed input: 34350.26 toks/s, output: 33.55 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:59<00:02, 28.17it/s, est. speed input: 34310.19 toks/s, output: 33.51 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:59<00:01, 28.68it/s, est. speed input: 34277.69 toks/s, output: 33.47 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:00<00:01, 29.06it/s, est. speed input: 34246.01 toks/s, output: 33.44 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:00<00:00, 29.89it/s, est. speed input: 34234.01 toks/s, output: 33.43 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:00<00:00, 29.89it/s, est. speed input: 34469.44 toks/s, output: 33.66 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:00<00:00, 33.66it/s, est. speed input: 34469.44 toks/s, output: 33.66 toks/s]
[rank0]:[W125 23:38:25.094908445 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 140.6s

测试结果:
  Requests/s:   28.19
  Tokens/s:     28898.67
  Total Reqs:   2048
  Elapsed:      72.64s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     28870.48

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:39:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:39:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=550896) WARNING 01-25 23:39:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=550896) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=550896) WARNING 01-25 23:39:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.41 requests/s, 8621.35 total tokens/s, 8.41 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 23:39:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:39:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:39:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:39:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:39:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:39:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:39:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:39:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:39:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:39:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:39:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:39:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:39:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:39:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:39:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:39:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:39:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=550896) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=550896) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=550896) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.05s/it]
(EngineCore_DP0 pid=550896) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.01s/it]
(EngineCore_DP0 pid=550896) 
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=550896) [2026-01-25 23:39:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=550896) [rank0]:W0125 23:39:36.222000 550896 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=550896) [rank0]:W0125 23:39:36.330000 550896 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=550896) [rank0]:W0125 23:39:38.008000 550896 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=550896) [rank0]:W0125 23:39:38.183000 550896 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=550896) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  5.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  6.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  7.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  7.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  7.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  7.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  8.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  8.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  8.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.40it/s]
(EngineCore_DP0 pid=550896) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.48it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  5.36it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:01,  3.19it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:01<00:00,  3.61it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:01<00:00,  4.19it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  3.36it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  3.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  3.69it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/4096 [00:00<00:19, 206.65it/s]
Adding requests:   1%|          | 45/4096 [00:00<00:17, 225.30it/s]
Adding requests:   2%|▏         | 71/4096 [00:00<00:17, 236.00it/s]
Adding requests:   2%|▏         | 95/4096 [00:00<00:17, 231.60it/s]
Adding requests:   3%|▎         | 119/4096 [00:00<00:17, 228.32it/s]
Adding requests:   3%|▎         | 143/4096 [00:00<00:17, 229.62it/s]
Adding requests:   4%|▍         | 169/4096 [00:00<00:16, 238.45it/s]
Adding requests:   5%|▍         | 197/4096 [00:00<00:15, 247.06it/s]
Adding requests:   5%|▌         | 222/4096 [00:00<00:15, 246.79it/s]
Adding requests:   6%|▌         | 247/4096 [00:01<00:15, 246.97it/s]
Adding requests:   7%|▋         | 272/4096 [00:01<00:15, 247.47it/s]
Adding requests:   7%|▋         | 299/4096 [00:01<00:14, 253.75it/s]
Adding requests:   8%|▊         | 325/4096 [00:01<00:14, 254.23it/s]
Adding requests:   9%|▊         | 352/4096 [00:01<00:14, 257.51it/s]
Adding requests:   9%|▉         | 379/4096 [00:01<00:14, 260.51it/s]
Adding requests:  10%|▉         | 406/4096 [00:01<00:14, 254.94it/s]
Adding requests:  11%|█         | 432/4096 [00:01<00:14, 248.79it/s]
Adding requests:  11%|█         | 458/4096 [00:01<00:14, 251.59it/s]
Adding requests:  12%|█▏        | 484/4096 [00:01<00:14, 245.25it/s]
Adding requests:  13%|█▎        | 514/4096 [00:02<00:13, 258.03it/s]
Adding requests:  13%|█▎        | 540/4096 [00:02<00:13, 257.59it/s]
Adding requests:  14%|█▍        | 568/4096 [00:02<00:13, 261.29it/s]
Adding requests:  15%|█▍        | 595/4096 [00:02<00:13, 258.88it/s]
Adding requests:  15%|█▌        | 621/4096 [00:02<00:13, 249.72it/s]
Adding requests:  16%|█▌        | 647/4096 [00:02<00:13, 248.86it/s]
Adding requests:  16%|█▋        | 672/4096 [00:02<00:14, 231.46it/s]
Adding requests:  17%|█▋        | 700/4096 [00:02<00:13, 243.03it/s]
Adding requests:  18%|█▊        | 725/4096 [00:02<00:14, 232.56it/s]
Adding requests:  18%|█▊        | 749/4096 [00:03<00:14, 231.21it/s]
Adding requests:  19%|█▉        | 775/4096 [00:03<00:14, 236.78it/s]
Adding requests:  20%|█▉        | 799/4096 [00:03<00:14, 227.21it/s]
Adding requests:  20%|██        | 823/4096 [00:03<00:14, 230.39it/s]
Adding requests:  21%|██        | 847/4096 [00:03<00:14, 227.25it/s]
Adding requests:  21%|██▏       | 871/4096 [00:03<00:13, 230.59it/s]
Adding requests:  22%|██▏       | 896/4096 [00:03<00:13, 233.50it/s]
Adding requests:  22%|██▏       | 920/4096 [00:03<00:14, 216.50it/s]
Adding requests:  23%|██▎       | 944/4096 [00:03<00:14, 221.04it/s]
Adding requests:  24%|██▎       | 967/4096 [00:04<00:14, 215.61it/s]
Adding requests:  24%|██▍       | 989/4096 [00:04<00:14, 211.31it/s]
Adding requests:  25%|██▍       | 1012/4096 [00:04<00:14, 215.91it/s]
Adding requests:  25%|██▌       | 1034/4096 [00:04<00:14, 210.18it/s]
Adding requests:  26%|██▌       | 1058/4096 [00:04<00:13, 217.37it/s]
Adding requests:  26%|██▋       | 1081/4096 [00:04<00:13, 219.18it/s]
Adding requests:  27%|██▋       | 1103/4096 [00:04<00:14, 212.38it/s]
Adding requests:  28%|██▊       | 1128/4096 [00:04<00:13, 221.33it/s]
Adding requests:  28%|██▊       | 1151/4096 [00:04<00:13, 211.59it/s]
Adding requests:  29%|██▊       | 1174/4096 [00:05<00:13, 216.41it/s]
Adding requests:  29%|██▉       | 1197/4096 [00:05<00:13, 217.83it/s]
Adding requests:  30%|██▉       | 1219/4096 [00:05<00:13, 209.47it/s]
Adding requests:  30%|███       | 1243/4096 [00:05<00:13, 216.41it/s]
Adding requests:  31%|███       | 1265/4096 [00:05<00:13, 217.22it/s]
Adding requests:  31%|███▏      | 1287/4096 [00:05<00:13, 215.79it/s]
Adding requests:  32%|███▏      | 1312/4096 [00:05<00:12, 223.81it/s]
Adding requests:  33%|███▎      | 1335/4096 [00:05<00:12, 217.53it/s]
Adding requests:  33%|███▎      | 1360/4096 [00:05<00:12, 226.00it/s]
Adding requests:  34%|███▍      | 1384/4096 [00:05<00:11, 226.36it/s]
Adding requests:  34%|███▍      | 1407/4096 [00:06<00:12, 214.02it/s]
Adding requests:  35%|███▍      | 1432/4096 [00:06<00:11, 223.44it/s]
Adding requests:  36%|███▌      | 1455/4096 [00:06<00:12, 219.73it/s]
Adding requests:  36%|███▌      | 1478/4096 [00:06<00:11, 221.93it/s]
Adding requests:  37%|███▋      | 1503/4096 [00:06<00:11, 228.67it/s]
Adding requests:  37%|███▋      | 1526/4096 [00:06<00:11, 220.44it/s]
Adding requests:  38%|███▊      | 1551/4096 [00:06<00:11, 226.70it/s]
Adding requests:  38%|███▊      | 1574/4096 [00:06<00:11, 220.47it/s]
Adding requests:  39%|███▉      | 1597/4096 [00:06<00:11, 215.45it/s]
Adding requests:  40%|███▉      | 1621/4096 [00:07<00:11, 219.53it/s]
Adding requests:  40%|████      | 1644/4096 [00:07<00:11, 206.55it/s]
Adding requests:  41%|████      | 1666/4096 [00:07<00:11, 209.58it/s]
Adding requests:  41%|████▏     | 1690/4096 [00:07<00:11, 216.96it/s]
Adding requests:  42%|████▏     | 1712/4096 [00:07<00:11, 215.83it/s]
Adding requests:  42%|████▏     | 1736/4096 [00:07<00:10, 221.78it/s]
Adding requests:  43%|████▎     | 1759/4096 [00:07<00:10, 219.60it/s]
Adding requests:  44%|████▎     | 1783/4096 [00:07<00:10, 224.31it/s]
Adding requests:  44%|████▍     | 1807/4096 [00:07<00:10, 226.35it/s]
Adding requests:  45%|████▍     | 1830/4096 [00:08<00:10, 214.88it/s]
Adding requests:  45%|████▌     | 1853/4096 [00:08<00:10, 218.22it/s]
Adding requests:  46%|████▌     | 1878/4096 [00:08<00:09, 227.01it/s]
Adding requests:  46%|████▋     | 1902/4096 [00:08<00:09, 229.97it/s]
Adding requests:  47%|████▋     | 1932/4096 [00:08<00:08, 249.51it/s]
Adding requests:  48%|████▊     | 1958/4096 [00:08<00:08, 246.19it/s]
Adding requests:  48%|████▊     | 1985/4096 [00:08<00:08, 250.68it/s]
Adding requests:  49%|████▉     | 2011/4096 [00:08<00:08, 244.16it/s]
Adding requests:  50%|████▉     | 2036/4096 [00:08<00:08, 241.92it/s]
Adding requests:  50%|█████     | 2062/4096 [00:08<00:08, 244.37it/s]
Adding requests:  51%|█████     | 2087/4096 [00:09<00:08, 228.08it/s]
Adding requests:  52%|█████▏    | 2113/4096 [00:09<00:08, 236.62it/s]
Adding requests:  52%|█████▏    | 2137/4096 [00:09<00:08, 223.89it/s]
Adding requests:  53%|█████▎    | 2162/4096 [00:09<00:08, 230.38it/s]
Adding requests:  53%|█████▎    | 2186/4096 [00:09<00:08, 229.30it/s]
Adding requests:  54%|█████▍    | 2210/4096 [00:09<00:08, 226.28it/s]
Adding requests:  55%|█████▍    | 2237/4096 [00:09<00:07, 237.37it/s]
Adding requests:  55%|█████▌    | 2261/4096 [00:09<00:08, 228.57it/s]
Adding requests:  56%|█████▌    | 2289/4096 [00:09<00:07, 240.98it/s]
Adding requests:  56%|█████▋    | 2314/4096 [00:10<00:07, 235.44it/s]
Adding requests:  57%|█████▋    | 2340/4096 [00:10<00:07, 241.49it/s]
Adding requests:  58%|█████▊    | 2365/4096 [00:10<00:07, 238.96it/s]
Adding requests:  58%|█████▊    | 2389/4096 [00:10<00:07, 235.77it/s]
Adding requests:  59%|█████▉    | 2416/4096 [00:10<00:06, 245.24it/s]
Adding requests:  60%|█████▉    | 2441/4096 [00:10<00:07, 226.02it/s]
Adding requests:  60%|██████    | 2466/4096 [00:10<00:07, 231.01it/s]
Adding requests:  61%|██████    | 2492/4096 [00:10<00:06, 235.50it/s]
Adding requests:  61%|██████▏   | 2516/4096 [00:10<00:06, 235.43it/s]
Adding requests:  62%|██████▏   | 2544/4096 [00:10<00:06, 247.08it/s]
Adding requests:  63%|██████▎   | 2569/4096 [00:11<00:06, 243.49it/s]
Adding requests:  63%|██████▎   | 2598/4096 [00:11<00:05, 254.84it/s]
Adding requests:  64%|██████▍   | 2624/4096 [00:11<00:06, 235.37it/s]
Adding requests:  65%|██████▍   | 2648/4096 [00:11<00:06, 233.26it/s]
Adding requests:  65%|██████▌   | 2673/4096 [00:11<00:06, 236.07it/s]
Adding requests:  66%|██████▌   | 2697/4096 [00:11<00:06, 225.87it/s]
Adding requests:  66%|██████▋   | 2722/4096 [00:11<00:05, 230.56it/s]
Adding requests:  67%|██████▋   | 2746/4096 [00:11<00:05, 229.47it/s]
Adding requests:  68%|██████▊   | 2770/4096 [00:11<00:05, 231.11it/s]
Adding requests:  68%|██████▊   | 2794/4096 [00:12<00:05, 233.55it/s]
Adding requests:  69%|██████▉   | 2818/4096 [00:12<00:05, 224.20it/s]
Adding requests:  69%|██████▉   | 2842/4096 [00:12<00:05, 228.09it/s]
Adding requests:  70%|██████▉   | 2865/4096 [00:12<00:05, 226.56it/s]
Adding requests:  71%|███████   | 2888/4096 [00:12<00:05, 218.96it/s]
Adding requests:  71%|███████   | 2912/4096 [00:12<00:05, 224.88it/s]
Adding requests:  72%|███████▏  | 2935/4096 [00:12<00:05, 221.66it/s]
Adding requests:  72%|███████▏  | 2958/4096 [00:12<00:05, 223.59it/s]
Adding requests:  73%|███████▎  | 2983/4096 [00:12<00:04, 229.19it/s]
Adding requests:  73%|███████▎  | 3006/4096 [00:13<00:04, 222.82it/s]
Adding requests:  74%|███████▍  | 3030/4096 [00:13<00:04, 226.68it/s]
Adding requests:  75%|███████▍  | 3055/4096 [00:13<00:04, 233.13it/s]
Adding requests:  75%|███████▌  | 3079/4096 [00:13<00:04, 221.20it/s]
Adding requests:  76%|███████▌  | 3103/4096 [00:13<00:04, 225.86it/s]
Adding requests:  76%|███████▋  | 3126/4096 [00:13<00:04, 225.33it/s]
Adding requests:  77%|███████▋  | 3149/4096 [00:13<00:04, 222.41it/s]
Adding requests:  77%|███████▋  | 3173/4096 [00:13<00:04, 224.89it/s]
Adding requests:  78%|███████▊  | 3196/4096 [00:13<00:04, 214.55it/s]
Adding requests:  79%|███████▊  | 3221/4096 [00:13<00:03, 222.79it/s]
Adding requests:  79%|███████▉  | 3244/4096 [00:14<00:03, 222.09it/s]
Adding requests:  80%|███████▉  | 3267/4096 [00:14<00:03, 212.91it/s]
Adding requests:  80%|████████  | 3289/4096 [00:14<00:03, 212.89it/s]
Adding requests:  91%|█████████ | 3708/4096 [00:14<00:00, 1324.60it/s]
Adding requests:  94%|█████████▍| 3844/4096 [00:15<00:00, 509.32it/s] 
Adding requests:  96%|█████████▋| 3945/4096 [00:15<00:00, 381.04it/s]
Adding requests:  98%|█████████▊| 4022/4096 [00:15<00:00, 331.16it/s]
Adding requests: 100%|█████████▉| 4083/4096 [00:16<00:00, 303.50it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 251.96it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:02<01:16, 51.80it/s, est. speed input: 53039.08 toks/s, output: 51.80 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:06<02:59, 21.87it/s, est. speed input: 26017.78 toks/s, output: 25.41 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:10<04:15, 15.29it/s, est. speed input: 19543.37 toks/s, output: 19.09 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:14<05:11, 12.41it/s, est. speed input: 16530.23 toks/s, output: 16.14 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:17<05:50, 10.95it/s, est. speed input: 14853.80 toks/s, output: 14.51 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:21<06:17, 10.08it/s, est. speed input: 13759.22 toks/s, output: 13.44 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:25<06:34,  9.56it/s, est. speed input: 13011.16 toks/s, output: 12.71 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:27<05:50, 10.67it/s, est. speed input: 13178.44 toks/s, output: 12.87 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:31<06:18,  9.79it/s, est. speed input: 12583.11 toks/s, output: 12.29 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:35<06:29,  9.44it/s, est. speed input: 12196.98 toks/s, output: 11.91 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:38<06:43,  9.03it/s, est. speed input: 11816.43 toks/s, output: 11.54 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:42<06:47,  8.86it/s, est. speed input: 11541.09 toks/s, output: 11.27 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:46<06:52,  8.67it/s, est. speed input: 11285.40 toks/s, output: 11.02 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:50<06:50,  8.65it/s, est. speed input: 11100.09 toks/s, output: 10.84 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:54<06:51,  8.55it/s, est. speed input: 10918.56 toks/s, output: 10.66 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:57<06:48,  8.54it/s, est. speed input: 10775.74 toks/s, output: 10.52 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:00<05:51,  9.82it/s, est. speed input: 10940.59 toks/s, output: 10.68 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:03<06:08,  9.28it/s, est. speed input: 10788.56 toks/s, output: 10.54 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:07<06:11,  9.13it/s, est. speed input: 10693.03 toks/s, output: 10.44 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:11<06:20,  8.83it/s, est. speed input: 10566.48 toks/s, output: 10.32 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [01:15<06:15,  8.87it/s, est. speed input: 10500.72 toks/s, output: 10.25 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [01:18<06:20,  8.66it/s, est. speed input: 10397.78 toks/s, output: 10.15 toks/s]
Processed prompts:  20%|██        | 834/4096 [01:22<06:17,  8.64it/s, est. speed input: 10325.55 toks/s, output: 10.08 toks/s]
Processed prompts:  21%|██        | 866/4096 [01:26<06:18,  8.53it/s, est. speed input: 10243.46 toks/s, output: 10.00 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [01:30<06:14,  8.54it/s, est. speed input: 10182.62 toks/s, output: 9.94 toks/s] 
Processed prompts:  23%|██▎       | 930/4096 [01:32<05:17,  9.97it/s, est. speed input: 10322.22 toks/s, output: 10.08 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [01:36<05:34,  9.36it/s, est. speed input: 10243.48 toks/s, output: 10.00 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [01:39<05:39,  9.14it/s, est. speed input: 10193.02 toks/s, output: 9.95 toks/s] 
Processed prompts:  25%|██▌       | 1026/4096 [01:43<05:47,  8.83it/s, est. speed input: 10124.90 toks/s, output: 9.89 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [01:47<05:45,  8.78it/s, est. speed input: 10082.01 toks/s, output: 9.85 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [01:51<05:49,  8.60it/s, est. speed input: 10022.46 toks/s, output: 9.79 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [01:55<05:45,  8.61it/s, est. speed input: 9984.70 toks/s, output: 9.75 toks/s] 
Processed prompts:  28%|██▊       | 1154/4096 [01:58<05:46,  8.50it/s, est. speed input: 9934.24 toks/s, output: 9.70 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [02:01<04:56,  9.80it/s, est. speed input: 10033.30 toks/s, output: 9.80 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [02:04<05:05,  9.42it/s, est. speed input: 9997.48 toks/s, output: 9.76 toks/s] 
Processed prompts:  31%|███       | 1250/4096 [02:08<05:15,  9.01it/s, est. speed input: 9948.64 toks/s, output: 9.72 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [02:12<05:16,  8.89it/s, est. speed input: 9916.89 toks/s, output: 9.68 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [02:16<05:21,  8.67it/s, est. speed input: 9872.96 toks/s, output: 9.64 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [02:19<05:17,  8.67it/s, est. speed input: 9846.57 toks/s, output: 9.62 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [02:23<05:19,  8.52it/s, est. speed input: 9806.86 toks/s, output: 9.58 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [02:27<05:13,  8.57it/s, est. speed input: 9784.64 toks/s, output: 9.56 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [02:31<05:13,  8.45it/s, est. speed input: 9748.51 toks/s, output: 9.52 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [02:33<04:32,  9.62it/s, est. speed input: 9818.91 toks/s, output: 9.59 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [02:37<04:39,  9.26it/s, est. speed input: 9792.79 toks/s, output: 9.56 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [02:41<04:46,  8.91it/s, est. speed input: 9758.81 toks/s, output: 9.53 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [02:45<04:46,  8.82it/s, est. speed input: 9737.20 toks/s, output: 9.51 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [02:48<04:44,  8.77it/s, est. speed input: 9718.00 toks/s, output: 9.49 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [02:52<04:41,  8.73it/s, est. speed input: 9699.79 toks/s, output: 9.47 toks/s]
Processed prompts:  41%|████      | 1666/4096 [02:56<04:43,  8.56it/s, est. speed input: 9670.73 toks/s, output: 9.44 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [03:00<04:38,  8.63it/s, est. speed input: 9656.83 toks/s, output: 9.43 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [03:02<04:01,  9.81it/s, est. speed input: 9719.44 toks/s, output: 9.49 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [03:06<04:10,  9.33it/s, est. speed input: 9695.77 toks/s, output: 9.47 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [03:09<04:14,  9.06it/s, est. speed input: 9675.49 toks/s, output: 9.45 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [03:13<04:18,  8.79it/s, est. speed input: 9650.22 toks/s, output: 9.42 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [03:17<04:16,  8.71it/s, est. speed input: 9633.01 toks/s, output: 9.41 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [03:21<04:17,  8.57it/s, est. speed input: 9610.42 toks/s, output: 9.39 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [03:25<04:13,  8.59it/s, est. speed input: 9596.61 toks/s, output: 9.37 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [03:28<04:11,  8.51it/s, est. speed input: 9576.73 toks/s, output: 9.35 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [03:32<04:06,  8.57it/s, est. speed input: 9565.37 toks/s, output: 9.34 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [03:34<03:33,  9.72it/s, est. speed input: 9617.31 toks/s, output: 9.39 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [03:38<03:39,  9.31it/s, est. speed input: 9601.16 toks/s, output: 9.38 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [03:42<03:43,  9.02it/s, est. speed input: 9583.94 toks/s, output: 9.36 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [03:46<03:45,  8.77it/s, est. speed input: 9564.48 toks/s, output: 9.34 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [03:50<03:44,  8.68it/s, est. speed input: 9549.68 toks/s, output: 9.33 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [03:53<03:39,  8.72it/s, est. speed input: 9541.73 toks/s, output: 9.32 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [03:57<03:37,  8.68it/s, est. speed input: 9529.92 toks/s, output: 9.31 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [04:01<03:36,  8.55it/s, est. speed input: 9512.90 toks/s, output: 9.29 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [04:03<03:03,  9.93it/s, est. speed input: 9569.02 toks/s, output: 9.34 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [04:07<03:11,  9.35it/s, est. speed input: 9551.06 toks/s, output: 9.33 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [04:10<03:12,  9.13it/s, est. speed input: 9540.78 toks/s, output: 9.32 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [04:14<03:14,  8.89it/s, est. speed input: 9526.27 toks/s, output: 9.30 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [04:18<03:15,  8.68it/s, est. speed input: 9509.57 toks/s, output: 9.29 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [04:22<03:13,  8.60it/s, est. speed input: 9496.92 toks/s, output: 9.27 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [04:26<03:11,  8.53it/s, est. speed input: 9483.52 toks/s, output: 9.26 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [04:30<03:07,  8.52it/s, est. speed input: 9472.78 toks/s, output: 9.25 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [04:33<03:04,  8.47it/s, est. speed input: 9459.78 toks/s, output: 9.24 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [04:35<02:34,  9.96it/s, est. speed input: 9513.54 toks/s, output: 9.29 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [04:39<02:40,  9.37it/s, est. speed input: 9498.59 toks/s, output: 9.28 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [04:43<02:41,  9.10it/s, est. speed input: 9488.60 toks/s, output: 9.27 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [04:47<02:42,  8.85it/s, est. speed input: 9475.46 toks/s, output: 9.25 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [04:51<02:41,  8.73it/s, est. speed input: 9464.85 toks/s, output: 9.24 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [04:54<02:39,  8.62it/s, est. speed input: 9453.41 toks/s, output: 9.23 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [04:58<02:36,  8.56it/s, est. speed input: 9442.76 toks/s, output: 9.22 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [05:02<02:33,  8.53it/s, est. speed input: 9432.96 toks/s, output: 9.21 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [05:04<02:11,  9.75it/s, est. speed input: 9472.98 toks/s, output: 9.25 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [05:08<02:11,  9.47it/s, est. speed input: 9468.25 toks/s, output: 9.25 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [05:12<02:14,  9.04it/s, est. speed input: 9454.69 toks/s, output: 9.23 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [05:15<02:12,  8.91it/s, est. speed input: 9447.06 toks/s, output: 9.23 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [05:19<02:12,  8.70it/s, est. speed input: 9434.87 toks/s, output: 9.21 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [05:23<02:09,  8.65it/s, est. speed input: 9426.78 toks/s, output: 9.21 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [05:27<02:07,  8.54it/s, est. speed input: 9416.08 toks/s, output: 9.20 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [05:31<02:03,  8.53it/s, est. speed input: 9407.92 toks/s, output: 9.19 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [05:34<02:00,  8.49it/s, est. speed input: 9398.63 toks/s, output: 9.18 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [05:37<01:43,  9.60it/s, est. speed input: 9431.41 toks/s, output: 9.21 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [05:40<01:43,  9.29it/s, est. speed input: 9424.94 toks/s, output: 9.20 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [05:44<01:43,  8.93it/s, est. speed input: 9413.16 toks/s, output: 9.19 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [05:48<01:41,  8.84it/s, est. speed input: 9407.02 toks/s, output: 9.19 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [05:52<01:39,  8.63it/s, est. speed input: 9395.70 toks/s, output: 9.18 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [05:56<01:36,  8.64it/s, est. speed input: 9390.09 toks/s, output: 9.17 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [06:00<01:33,  8.50it/s, est. speed input: 9379.48 toks/s, output: 9.16 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [06:03<01:29,  8.55it/s, est. speed input: 9374.29 toks/s, output: 9.15 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [06:07<01:26,  8.47it/s, est. speed input: 9364.96 toks/s, output: 9.15 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [06:09<01:12,  9.67it/s, est. speed input: 9397.46 toks/s, output: 9.18 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [06:13<01:11,  9.32it/s, est. speed input: 9391.60 toks/s, output: 9.17 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [06:17<01:11,  8.95it/s, est. speed input: 9381.19 toks/s, output: 9.16 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [06:21<01:08,  8.85it/s, est. speed input: 9375.78 toks/s, output: 9.16 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [06:25<01:06,  8.64it/s, est. speed input: 9365.74 toks/s, output: 9.15 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [06:28<01:02,  8.66it/s, est. speed input: 9361.50 toks/s, output: 9.14 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [06:32<00:59,  8.54it/s, est. speed input: 9352.66 toks/s, output: 9.13 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [06:36<00:55,  8.61it/s, est. speed input: 9349.20 toks/s, output: 9.13 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [06:38<00:45,  9.77it/s, est. speed input: 9378.75 toks/s, output: 9.16 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [06:42<00:44,  9.40it/s, est. speed input: 9373.99 toks/s, output: 9.15 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [06:45<00:41,  9.14it/s, est. speed input: 9368.69 toks/s, output: 9.15 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [06:49<00:39,  8.84it/s, est. speed input: 9359.33 toks/s, output: 9.14 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [06:53<00:36,  8.76it/s, est. speed input: 9354.31 toks/s, output: 9.14 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [06:57<00:33,  8.60it/s, est. speed input: 9345.80 toks/s, output: 9.13 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [07:01<00:29,  8.65it/s, est. speed input: 9342.60 toks/s, output: 9.12 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [07:05<00:26,  8.51it/s, est. speed input: 9333.80 toks/s, output: 9.12 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [07:08<00:21,  8.71it/s, est. speed input: 9334.86 toks/s, output: 9.12 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [07:10<00:15,  9.88it/s, est. speed input: 9362.75 toks/s, output: 9.14 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [07:14<00:13,  9.39it/s, est. speed input: 9356.23 toks/s, output: 9.14 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [07:18<00:10,  9.13it/s, est. speed input: 9351.29 toks/s, output: 9.13 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [07:22<00:07,  8.83it/s, est. speed input: 9342.76 toks/s, output: 9.12 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [07:25<00:03,  8.88it/s, est. speed input: 9341.95 toks/s, output: 9.12 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [07:25<00:00,  8.88it/s, est. speed input: 9410.86 toks/s, output: 9.19 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [07:25<00:00,  9.19it/s, est. speed input: 9410.86 toks/s, output: 9.19 toks/s]
[rank0]:[W125 23:47:33.174528428 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 548.7s

测试结果:
  Requests/s:   8.41
  Tokens/s:     8621.35
  Total Reqs:   4096
  Elapsed:      486.98s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     8612.94

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:48:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:48:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=559149) WARNING 01-25 23:48:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=559149) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=559149) WARNING 01-25 23:49:10 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     def forward(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     raise e
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/tmp/torchinductor_root/kp/ckpniwar6bwhyukpv5i62ryj47uysbdhjhadgl4x6iqsrkxzxjji.py", line 1090, in call
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=559149) ERROR 01-25 23:49:21 [core.py:866] 


─── STDERR ───
[2026-01-25 23:48:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:48:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:48:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:48:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:48:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:48:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:48:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:48:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:48:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:48:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:48:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:48:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:48:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:48:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:48:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:48:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:48:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=559149) [2026-01-25 23:48:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=559149) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=559149) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=559149) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.03it/s]
(EngineCore_DP0 pid=559149) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.07it/s]
(EngineCore_DP0 pid=559149) 
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=559149) [2026-01-25 23:49:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=559149) [rank0]:W0125 23:49:19.225000 559149 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=559149) [rank0]:W0125 23:49:19.347000 559149 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=559149) [rank0]:W0125 23:49:19.907000 559149 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=559149) [rank0]:W0125 23:49:20.088000 559149 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=559149) Process EngineCore_DP0:
(EngineCore_DP0 pid=559149) Traceback (most recent call last):
(EngineCore_DP0 pid=559149)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=559149)     self.run()
(EngineCore_DP0 pid=559149)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=559149)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=559149)     raise e
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=559149)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=559149)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=559149)     super().__init__(
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=559149)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=559149)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=559149)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=559149)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=559149)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=559149)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=559149)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=559149)     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=559149)     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=559149)     self.model_runner.profile_run()
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=559149)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=559149)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=559149)     return func(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=559149)     outputs = self.model(
(EngineCore_DP0 pid=559149)               ^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=559149)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=559149)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=559149)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=559149)     hidden_states = self.model(
(EngineCore_DP0 pid=559149)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=559149)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=559149)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=559149)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=559149)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=559149)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=559149)     def forward(
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=559149)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=559149)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=559149)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=559149)     raise e
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=559149)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=559149)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=559149)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=559149)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=559149)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=559149)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=559149)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=559149)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=559149)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=559149)     return compiled_fn(full_args)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=559149)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=559149)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=559149)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=559149)                             ^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=559149)     outs = compiled_fn(args)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=559149)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=559149)     return self.current_callable(inputs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=559149)     out = model(new_inputs)
(EngineCore_DP0 pid=559149)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/tmp/torchinductor_root/kp/ckpniwar6bwhyukpv5i62ryj47uysbdhjhadgl4x6iqsrkxzxjji.py", line 1090, in call
(EngineCore_DP0 pid=559149)     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=559149)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=559149)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=559149)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=559149)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=559149)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=559149)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=559149)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=559149)     torch.cuda.synchronize()
(EngineCore_DP0 pid=559149)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=559149)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=559149)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=559149) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=559149) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=559149) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=559149) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=559149) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=559149) 
[rank0]:[W125 23:49:22.379183748 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,14.6192,7499.6333,8.7556
1024,1024,1,128,128,14.8573,15228.6875,8.6153
2048,1024,2,256,128,26.2427,26898.7201,9.7551
4096,1024,4,512,128,27.4787,28165.6693,18.6326
8192,1024,8,1024,128,27.9180,28615.9040,36.6789
16384,1024,16,2048,128,28.1938,28898.6701,72.6400
32768,1024,32,4096,128,8.4111,8621.3473,486.9773
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:49:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:49:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=560056) WARNING 01-25 23:49:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=560056) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=560056) WARNING 01-25 23:50:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.74 requests/s, 7559.33 total tokens/s, 14.74 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:49:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:49:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:49:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:49:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:49:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:49:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:49:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:49:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:49:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:49:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:49:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:49:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:49:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:49:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:49:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:49:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:49:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=560056) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=560056) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.72s/it]
(EngineCore_DP0 pid=560056) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.79s/it]
(EngineCore_DP0 pid=560056) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.78s/it]
(EngineCore_DP0 pid=560056) 
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=560056) [2026-01-25 23:49:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=560056) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, -25.61it/s]
(EngineCore_DP0 pid=560056) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  30%|███       | 39/128 [00:00<00:00, 389.38it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 410.54it/s]
Adding requests:  98%|█████████▊| 125/128 [00:00<00:00, 417.87it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 412.78it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:52,  2.41it/s, est. speed input: 1232.05 toks/s, output: 2.41 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:36,  3.43it/s, est. speed input: 1652.00 toks/s, output: 3.23 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:18,  6.70it/s, est. speed input: 2733.43 toks/s, output: 5.34 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:13,  9.00it/s, est. speed input: 3465.06 toks/s, output: 6.77 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:01<00:11, 10.80it/s, est. speed input: 4027.92 toks/s, output: 7.87 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:09, 12.06it/s, est. speed input: 4455.97 toks/s, output: 8.70 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:08, 13.06it/s, est. speed input: 4808.18 toks/s, output: 9.39 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:08, 13.94it/s, est. speed input: 5114.04 toks/s, output: 9.99 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:07, 14.51it/s, est. speed input: 5363.36 toks/s, output: 10.48 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:07, 15.25it/s, est. speed input: 5606.46 toks/s, output: 10.95 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 15.82it/s, est. speed input: 5819.34 toks/s, output: 11.37 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 16.30it/s, est. speed input: 6011.04 toks/s, output: 11.74 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 16.68it/s, est. speed input: 6182.37 toks/s, output: 12.07 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:06, 16.90it/s, est. speed input: 6332.21 toks/s, output: 12.37 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:02<00:05, 16.95it/s, est. speed input: 6459.50 toks/s, output: 12.62 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:02<00:05, 16.92it/s, est. speed input: 6569.64 toks/s, output: 12.83 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:02<00:05, 16.87it/s, est. speed input: 6666.80 toks/s, output: 13.02 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:02<00:05, 16.90it/s, est. speed input: 6759.22 toks/s, output: 13.20 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 16.90it/s, est. speed input: 6842.31 toks/s, output: 13.36 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 16.84it/s, est. speed input: 6915.15 toks/s, output: 13.51 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 16.85it/s, est. speed input: 6984.86 toks/s, output: 13.64 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:03<00:05, 16.81it/s, est. speed input: 7046.57 toks/s, output: 13.76 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:03<00:04, 16.84it/s, est. speed input: 7106.58 toks/s, output: 13.88 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:03<00:04, 16.75it/s, est. speed input: 7156.84 toks/s, output: 13.98 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:03<00:04, 16.70it/s, est. speed input: 7204.16 toks/s, output: 14.07 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:04, 16.74it/s, est. speed input: 7251.75 toks/s, output: 14.16 toks/s]
Processed prompts:  41%|████      | 52/128 [00:03<00:04, 16.75it/s, est. speed input: 7295.10 toks/s, output: 14.25 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 16.71it/s, est. speed input: 7334.19 toks/s, output: 14.32 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 16.69it/s, est. speed input: 7370.95 toks/s, output: 14.40 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:04<00:04, 16.71it/s, est. speed input: 7406.63 toks/s, output: 14.47 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:04<00:04, 16.77it/s, est. speed input: 7442.63 toks/s, output: 14.54 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:04<00:03, 16.81it/s, est. speed input: 7476.58 toks/s, output: 14.60 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:04<00:03, 16.72it/s, est. speed input: 7503.60 toks/s, output: 14.66 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:04<00:03, 16.72it/s, est. speed input: 7531.60 toks/s, output: 14.71 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:04<00:03, 16.72it/s, est. speed input: 7558.53 toks/s, output: 14.76 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 16.77it/s, est. speed input: 7585.92 toks/s, output: 14.82 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 16.80it/s, est. speed input: 7611.61 toks/s, output: 14.87 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 16.79it/s, est. speed input: 7635.09 toks/s, output: 14.91 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:05<00:03, 16.79it/s, est. speed input: 7657.64 toks/s, output: 14.96 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:05<00:02, 16.68it/s, est. speed input: 7675.24 toks/s, output: 14.99 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:05<00:02, 16.33it/s, est. speed input: 7682.32 toks/s, output: 15.00 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:05<00:02, 16.07it/s, est. speed input: 7688.41 toks/s, output: 15.02 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:05<00:02, 15.90it/s, est. speed input: 7694.08 toks/s, output: 15.03 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:05<00:02, 15.80it/s, est. speed input: 7700.44 toks/s, output: 15.04 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 15.72it/s, est. speed input: 7706.12 toks/s, output: 15.05 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 15.68it/s, est. speed input: 7712.05 toks/s, output: 15.06 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:06<00:02, 15.43it/s, est. speed input: 7709.99 toks/s, output: 15.06 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:06<00:02, 15.48it/s, est. speed input: 7715.73 toks/s, output: 15.07 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:06<00:02, 15.60it/s, est. speed input: 7724.06 toks/s, output: 15.09 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:06<00:01, 15.63it/s, est. speed input: 7730.00 toks/s, output: 15.10 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:06<00:01, 15.73it/s, est. speed input: 7738.60 toks/s, output: 15.11 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:06<00:01, 15.75it/s, est. speed input: 7745.22 toks/s, output: 15.13 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:06<00:01, 15.80it/s, est. speed input: 7752.45 toks/s, output: 15.14 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 15.76it/s, est. speed input: 7757.39 toks/s, output: 15.15 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:07<00:01, 15.78it/s, est. speed input: 7763.52 toks/s, output: 15.16 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:07<00:01, 15.79it/s, est. speed input: 7769.43 toks/s, output: 15.17 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:07<00:01, 15.86it/s, est. speed input: 7776.79 toks/s, output: 15.19 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:07<00:00, 15.93it/s, est. speed input: 7784.59 toks/s, output: 15.20 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:07<00:00, 15.94it/s, est. speed input: 7791.01 toks/s, output: 15.22 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:07<00:00, 15.97it/s, est. speed input: 7797.84 toks/s, output: 15.23 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:07<00:00, 15.98it/s, est. speed input: 7803.93 toks/s, output: 15.24 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 16.00it/s, est. speed input: 7810.39 toks/s, output: 15.25 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:08<00:00, 16.05it/s, est. speed input: 7817.51 toks/s, output: 15.27 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:08<00:00, 16.01it/s, est. speed input: 7822.56 toks/s, output: 15.28 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.91it/s, est. speed input: 7825.63 toks/s, output: 15.28 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.91it/s, est. speed input: 7825.63 toks/s, output: 15.28 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.28it/s, est. speed input: 7825.63 toks/s, output: 15.28 toks/s]
[rank0]:[W125 23:50:32.162603311 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 67.9s

测试结果:
  Requests/s:   14.74
  Tokens/s:     7559.33
  Total Reqs:   128
  Elapsed:      8.69s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     7544.59

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:50:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:50:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=561295) WARNING 01-25 23:50:52 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=561295) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=561295) WARNING 01-25 23:51:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.81 requests/s, 15179.97 total tokens/s, 14.81 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 23:50:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:50:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:50:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:50:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:50:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:50:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:50:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:50:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:50:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:50:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:50:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:50:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:50:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:50:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:50:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:50:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:50:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=561295) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=561295) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
(EngineCore_DP0 pid=561295) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.48s/it]
(EngineCore_DP0 pid=561295) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.43s/it]
(EngineCore_DP0 pid=561295) 
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=561295) [2026-01-25 23:50:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=561295) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.90it/s]
(EngineCore_DP0 pid=561295) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▋        | 21/128 [00:00<00:00, 206.03it/s]
Adding requests:  35%|███▌      | 45/128 [00:00<00:00, 221.15it/s]
Adding requests:  55%|█████▍    | 70/128 [00:00<00:00, 228.09it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 223.80it/s]
Adding requests:  91%|█████████ | 116/128 [00:00<00:00, 224.95it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 224.22it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:07, 17.18it/s, est. speed input: 17599.46 toks/s, output: 17.18 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 15.51it/s, est. speed input: 16164.69 toks/s, output: 15.78 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:07, 15.50it/s, est. speed input: 16080.72 toks/s, output: 15.70 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:07, 15.55it/s, est. speed input: 16062.49 toks/s, output: 15.69 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 15.14it/s, est. speed input: 15809.24 toks/s, output: 15.44 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 15.22it/s, est. speed input: 15801.60 toks/s, output: 15.43 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:07, 15.22it/s, est. speed input: 15770.63 toks/s, output: 15.40 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:07, 15.27it/s, est. speed input: 15770.89 toks/s, output: 15.40 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:07, 15.41it/s, est. speed input: 15805.90 toks/s, output: 15.44 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 15.46it/s, est. speed input: 15818.23 toks/s, output: 15.45 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 15.49it/s, est. speed input: 15828.77 toks/s, output: 15.46 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 15.56it/s, est. speed input: 15849.40 toks/s, output: 15.48 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 15.43it/s, est. speed input: 15823.80 toks/s, output: 15.45 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:06, 15.42it/s, est. speed input: 15818.60 toks/s, output: 15.45 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:06, 15.34it/s, est. speed input: 15801.02 toks/s, output: 15.43 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 15.42it/s, est. speed input: 15810.06 toks/s, output: 15.44 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:06, 15.45it/s, est. speed input: 15815.42 toks/s, output: 15.44 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 15.49it/s, est. speed input: 15823.38 toks/s, output: 15.45 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 15.50it/s, est. speed input: 15826.83 toks/s, output: 15.46 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 15.54it/s, est. speed input: 15835.87 toks/s, output: 15.46 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 15.48it/s, est. speed input: 15830.00 toks/s, output: 15.46 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 15.41it/s, est. speed input: 15820.25 toks/s, output: 15.45 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 15.34it/s, est. speed input: 15808.59 toks/s, output: 15.44 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 15.37it/s, est. speed input: 15808.59 toks/s, output: 15.44 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:05, 15.36it/s, est. speed input: 15804.50 toks/s, output: 15.43 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.36it/s, est. speed input: 15801.12 toks/s, output: 15.43 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 15.35it/s, est. speed input: 15797.90 toks/s, output: 15.43 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 15.35it/s, est. speed input: 15794.82 toks/s, output: 15.42 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 15.51it/s, est. speed input: 15810.78 toks/s, output: 15.44 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 15.81it/s, est. speed input: 15845.60 toks/s, output: 15.47 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 16.03it/s, est. speed input: 15879.14 toks/s, output: 15.51 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 16.27it/s, est. speed input: 15917.96 toks/s, output: 15.54 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 16.48it/s, est. speed input: 15959.00 toks/s, output: 15.58 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 16.60it/s, est. speed input: 15994.34 toks/s, output: 15.62 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 16.72it/s, est. speed input: 16031.37 toks/s, output: 15.66 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 16.84it/s, est. speed input: 16068.86 toks/s, output: 15.69 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 16.91it/s, est. speed input: 16103.49 toks/s, output: 15.73 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 16.86it/s, est. speed input: 16128.92 toks/s, output: 15.75 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:02, 16.86it/s, est. speed input: 16156.22 toks/s, output: 15.78 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 16.47it/s, est. speed input: 16152.94 toks/s, output: 15.77 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 16.58it/s, est. speed input: 16176.85 toks/s, output: 15.80 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 16.69it/s, est. speed input: 16202.63 toks/s, output: 15.82 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 16.74it/s, est. speed input: 16225.61 toks/s, output: 15.85 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 16.39it/s, est. speed input: 16220.82 toks/s, output: 15.84 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 16.32it/s, est. speed input: 16227.46 toks/s, output: 15.85 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 16.51it/s, est. speed input: 16250.78 toks/s, output: 15.87 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 16.60it/s, est. speed input: 16270.13 toks/s, output: 15.89 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:01, 16.65it/s, est. speed input: 16287.90 toks/s, output: 15.91 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 16.68it/s, est. speed input: 16304.35 toks/s, output: 15.92 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 16.73it/s, est. speed input: 16321.92 toks/s, output: 15.94 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 16.52it/s, est. speed input: 16324.26 toks/s, output: 15.94 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 16.23it/s, est. speed input: 16317.16 toks/s, output: 15.93 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 15.99it/s, est. speed input: 16307.91 toks/s, output: 15.93 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 15.83it/s, est. speed input: 16298.68 toks/s, output: 15.92 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:01, 15.51it/s, est. speed input: 16276.75 toks/s, output: 15.90 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:00, 15.51it/s, est. speed input: 16269.86 toks/s, output: 15.89 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 15.49it/s, est. speed input: 16261.70 toks/s, output: 15.88 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 15.57it/s, est. speed input: 16259.73 toks/s, output: 15.88 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 15.68it/s, est. speed input: 16260.93 toks/s, output: 15.88 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 15.77it/s, est. speed input: 16262.62 toks/s, output: 15.88 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 15.76it/s, est. speed input: 16260.20 toks/s, output: 15.88 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 15.62it/s, est. speed input: 16250.43 toks/s, output: 15.87 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 15.55it/s, est. speed input: 16242.29 toks/s, output: 15.86 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.55it/s, est. speed input: 16241.10 toks/s, output: 15.86 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.86it/s, est. speed input: 16241.10 toks/s, output: 15.86 toks/s]
[rank0]:[W125 23:51:35.219573407 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 62.9s

测试结果:
  Requests/s:   14.81
  Tokens/s:     15179.97
  Total Reqs:   128
  Elapsed:      8.64s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     15165.16

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:51:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:51:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=562442) WARNING 01-25 23:51:56 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=562442) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=562442) WARNING 01-25 23:52:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.35 requests/s, 22912.70 total tokens/s, 22.35 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 23:51:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:51:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:51:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:51:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:51:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:51:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:51:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:51:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:51:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:51:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:51:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:51:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:51:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:51:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:51:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:51:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:51:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=562442) [2026-01-25 23:51:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=562442) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=562442) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.01s/it]
(EngineCore_DP0 pid=562442) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.35s/it]
(EngineCore_DP0 pid=562442) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.30s/it]
(EngineCore_DP0 pid=562442) 
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=562442) [2026-01-25 23:52:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=562442) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  2.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:01<00:00,  2.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:01<00:00,  2.30it/s]
(EngineCore_DP0 pid=562442) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  6.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  6.46it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 200.95it/s]
Adding requests:  18%|█▊        | 45/256 [00:00<00:00, 220.19it/s]
Adding requests:  28%|██▊       | 71/256 [00:00<00:00, 234.49it/s]
Adding requests:  37%|███▋      | 95/256 [00:00<00:00, 233.26it/s]
Adding requests:  46%|████▋     | 119/256 [00:00<00:00, 231.26it/s]
Adding requests:  56%|█████▌    | 143/256 [00:00<00:00, 232.06it/s]
Adding requests:  65%|██████▌   | 167/256 [00:00<00:00, 232.62it/s]
Adding requests:  75%|███████▌  | 192/256 [00:00<00:00, 237.15it/s]
Adding requests:  84%|████████▍ | 216/256 [00:00<00:00, 235.45it/s]
Adding requests:  94%|█████████▍| 240/256 [00:01<00:00, 234.51it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 231.64it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 18/256 [00:00<00:01, 127.39it/s, est. speed input: 130474.51 toks/s, output: 127.40 toks/s]
Processed prompts:  12%|█▏        | 31/256 [00:00<00:05, 41.09it/s, est. speed input: 47705.15 toks/s, output: 46.59 toks/s]   
Processed prompts:  15%|█▍        | 38/256 [00:01<00:06, 31.75it/s, est. speed input: 38365.01 toks/s, output: 37.46 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:01<00:06, 31.01it/s, est. speed input: 37049.10 toks/s, output: 36.18 toks/s]
Processed prompts:  18%|█▊        | 47/256 [00:01<00:07, 28.87it/s, est. speed input: 35271.54 toks/s, output: 34.44 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:01<00:07, 27.27it/s, est. speed input: 33925.28 toks/s, output: 33.13 toks/s]
Processed prompts:  21%|██        | 54/256 [00:01<00:08, 24.47it/s, est. speed input: 32256.50 toks/s, output: 31.50 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:01<00:08, 24.01it/s, est. speed input: 31437.10 toks/s, output: 30.70 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:02<00:08, 23.69it/s, est. speed input: 30760.34 toks/s, output: 30.04 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:08, 23.46it/s, est. speed input: 30189.75 toks/s, output: 29.48 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:02<00:07, 23.26it/s, est. speed input: 29689.75 toks/s, output: 28.99 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:02<00:07, 23.11it/s, est. speed input: 29256.88 toks/s, output: 28.57 toks/s]
Processed prompts:  30%|███       | 78/256 [00:02<00:07, 22.98it/s, est. speed input: 28871.80 toks/s, output: 28.19 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:02<00:07, 22.93it/s, est. speed input: 28543.60 toks/s, output: 27.87 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:03<00:07, 22.92it/s, est. speed input: 28257.14 toks/s, output: 27.59 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:07, 22.90it/s, est. speed input: 27998.20 toks/s, output: 27.34 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:03<00:07, 22.89it/s, est. speed input: 27766.75 toks/s, output: 27.12 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:06, 22.88it/s, est. speed input: 27558.25 toks/s, output: 26.91 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:03<00:06, 22.89it/s, est. speed input: 27370.93 toks/s, output: 26.73 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:03<00:06, 22.91it/s, est. speed input: 27201.19 toks/s, output: 26.56 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:04<00:06, 22.90it/s, est. speed input: 27043.57 toks/s, output: 26.41 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:04<00:06, 22.90it/s, est. speed input: 26898.75 toks/s, output: 26.27 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:04<00:06, 22.87it/s, est. speed input: 26761.24 toks/s, output: 26.13 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:04<00:05, 22.84it/s, est. speed input: 26631.86 toks/s, output: 26.01 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:04<00:05, 23.36it/s, est. speed input: 26586.55 toks/s, output: 25.96 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:05<00:05, 23.76it/s, est. speed input: 26546.15 toks/s, output: 25.92 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:05<00:05, 24.05it/s, est. speed input: 26509.38 toks/s, output: 25.89 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:05<00:04, 24.27it/s, est. speed input: 26475.11 toks/s, output: 25.85 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:05<00:04, 24.44it/s, est. speed input: 26444.63 toks/s, output: 25.82 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:05<00:04, 24.50it/s, est. speed input: 26410.45 toks/s, output: 25.79 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:05<00:04, 24.56it/s, est. speed input: 26379.35 toks/s, output: 25.76 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:05<00:04, 24.61it/s, est. speed input: 26350.64 toks/s, output: 25.73 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:06<00:03, 24.65it/s, est. speed input: 26324.27 toks/s, output: 25.71 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:06<00:03, 24.68it/s, est. speed input: 26298.64 toks/s, output: 25.68 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:06<00:03, 24.67it/s, est. speed input: 26272.36 toks/s, output: 25.66 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:06<00:03, 24.69it/s, est. speed input: 26249.74 toks/s, output: 25.63 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:06<00:03, 24.68it/s, est. speed input: 26225.65 toks/s, output: 25.61 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:06<00:03, 24.35it/s, est. speed input: 26175.56 toks/s, output: 25.56 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:07<00:03, 23.90it/s, est. speed input: 26109.12 toks/s, output: 25.50 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:07<00:02, 23.60it/s, est. speed input: 26046.26 toks/s, output: 25.44 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:07<00:02, 23.37it/s, est. speed input: 25984.70 toks/s, output: 25.38 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:07<00:02, 23.18it/s, est. speed input: 25922.50 toks/s, output: 25.31 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:07<00:02, 23.06it/s, est. speed input: 25865.07 toks/s, output: 25.26 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:08<00:02, 23.55it/s, est. speed input: 25854.87 toks/s, output: 25.25 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:08<00:02, 23.32it/s, est. speed input: 25800.97 toks/s, output: 25.20 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:08<00:01, 23.16it/s, est. speed input: 25749.19 toks/s, output: 25.15 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:08<00:01, 23.05it/s, est. speed input: 25700.10 toks/s, output: 25.10 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:08<00:01, 22.98it/s, est. speed input: 25652.67 toks/s, output: 25.05 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:08<00:01, 22.90it/s, est. speed input: 25605.44 toks/s, output: 25.01 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:09<00:01, 22.85it/s, est. speed input: 25560.25 toks/s, output: 24.96 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:09<00:01, 22.83it/s, est. speed input: 25517.98 toks/s, output: 24.92 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:09<00:00, 22.82it/s, est. speed input: 25477.32 toks/s, output: 24.88 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:09<00:00, 22.81it/s, est. speed input: 25438.28 toks/s, output: 24.84 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:09<00:00, 22.77it/s, est. speed input: 25398.20 toks/s, output: 24.80 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:09<00:00, 22.80it/s, est. speed input: 25363.11 toks/s, output: 24.77 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:10<00:00, 22.81it/s, est. speed input: 25328.98 toks/s, output: 24.74 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:10<00:00, 22.84it/s, est. speed input: 25297.01 toks/s, output: 24.70 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 22.84it/s, est. speed input: 25339.52 toks/s, output: 24.75 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 24.75it/s, est. speed input: 25339.52 toks/s, output: 24.75 toks/s]
[rank0]:[W125 23:52:41.632613067 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 65.8s

测试结果:
  Requests/s:   22.35
  Tokens/s:     22912.70
  Total Reqs:   256
  Elapsed:      11.45s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     22890.34

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:52:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:52:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=563632) WARNING 01-25 23:53:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=563632) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=563632) WARNING 01-25 23:53:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.02 requests/s, 24624.04 total tokens/s, 24.02 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 23:52:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:52:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:52:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:52:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:52:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:52:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:52:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:52:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:52:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:53:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:53:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:53:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:53:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:53:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:53:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:53:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:53:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:53:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=563632) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=563632) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.01it/s]
(EngineCore_DP0 pid=563632) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.27s/it]
(EngineCore_DP0 pid=563632) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.23s/it]
(EngineCore_DP0 pid=563632) 
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=563632) [2026-01-25 23:53:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=563632) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.72it/s]
(EngineCore_DP0 pid=563632) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  6.90it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  7.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.03it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 21/512 [00:00<00:02, 199.98it/s]
Adding requests:   8%|▊         | 43/512 [00:00<00:02, 210.82it/s]
Adding requests:  13%|█▎        | 69/512 [00:00<00:01, 230.95it/s]
Adding requests:  18%|█▊        | 93/512 [00:00<00:01, 229.24it/s]
Adding requests:  23%|██▎       | 118/512 [00:00<00:01, 234.91it/s]
Adding requests:  28%|██▊       | 143/512 [00:00<00:01, 238.52it/s]
Adding requests:  33%|███▎      | 169/512 [00:00<00:01, 243.78it/s]
Adding requests:  38%|███▊      | 195/512 [00:00<00:01, 248.50it/s]
Adding requests:  43%|████▎     | 222/512 [00:00<00:01, 253.37it/s]
Adding requests:  48%|████▊     | 248/512 [00:01<00:01, 250.26it/s]
Adding requests:  54%|█████▎    | 274/512 [00:01<00:00, 247.83it/s]
Adding requests:  59%|█████▊    | 300/512 [00:01<00:00, 250.58it/s]
Adding requests:  64%|██████▎   | 326/512 [00:01<00:00, 246.06it/s]
Adding requests:  69%|██████▉   | 353/512 [00:01<00:00, 251.83it/s]
Adding requests:  74%|███████▍  | 379/512 [00:01<00:00, 252.93it/s]
Adding requests:  79%|███████▉  | 406/512 [00:01<00:00, 256.54it/s]
Adding requests:  84%|████████▍ | 432/512 [00:01<00:00, 252.40it/s]
Adding requests:  89%|████████▉ | 458/512 [00:01<00:00, 249.39it/s]
Adding requests:  95%|█████████▍| 485/512 [00:01<00:00, 253.89it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 256.45it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 247.16it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:00<00:02, 224.51it/s, est. speed input: 229927.85 toks/s, output: 224.51 toks/s]
Processed prompts:  13%|█▎        | 69/512 [00:01<00:07, 55.61it/s, est. speed input: 67034.74 toks/s, output: 65.46 toks/s]   
Processed prompts:  16%|█▌        | 80/512 [00:01<00:10, 41.85it/s, est. speed input: 53008.12 toks/s, output: 51.77 toks/s]
Processed prompts:  17%|█▋        | 87/512 [00:01<00:11, 36.50it/s, est. speed input: 47923.01 toks/s, output: 46.80 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:02<00:11, 36.80it/s, est. speed input: 47251.32 toks/s, output: 46.14 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:02<00:13, 30.17it/s, est. speed input: 43100.64 toks/s, output: 42.09 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:02<00:13, 29.30it/s, est. speed input: 42027.70 toks/s, output: 41.04 toks/s]
Processed prompts:  21%|██        | 106/512 [00:02<00:14, 28.50it/s, est. speed input: 41081.93 toks/s, output: 40.12 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:02<00:14, 27.82it/s, est. speed input: 40246.26 toks/s, output: 39.30 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:02<00:14, 27.26it/s, est. speed input: 39500.19 toks/s, output: 38.57 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:15, 26.26it/s, est. speed input: 38671.74 toks/s, output: 37.76 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:03<00:15, 25.49it/s, est. speed input: 37921.44 toks/s, output: 37.03 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:03<00:15, 24.93it/s, est. speed input: 37244.45 toks/s, output: 36.37 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:03<00:15, 24.52it/s, est. speed input: 36629.72 toks/s, output: 35.77 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:03<00:15, 24.25it/s, est. speed input: 36074.76 toks/s, output: 35.23 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:15, 24.03it/s, est. speed input: 35560.52 toks/s, output: 34.73 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:15, 23.89it/s, est. speed input: 35091.24 toks/s, output: 34.27 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:04<00:15, 23.78it/s, est. speed input: 34658.02 toks/s, output: 33.85 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:04<00:15, 23.71it/s, est. speed input: 34258.21 toks/s, output: 33.46 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:15, 23.65it/s, est. speed input: 33886.53 toks/s, output: 33.09 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:14, 23.61it/s, est. speed input: 33540.95 toks/s, output: 32.75 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:14, 23.62it/s, est. speed input: 33224.52 toks/s, output: 32.45 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:14, 23.62it/s, est. speed input: 32927.50 toks/s, output: 32.16 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:05<00:14, 23.60it/s, est. speed input: 32647.76 toks/s, output: 31.88 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:05<00:14, 23.59it/s, est. speed input: 32384.76 toks/s, output: 31.63 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:05<00:14, 23.58it/s, est. speed input: 32137.61 toks/s, output: 31.38 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:14, 23.56it/s, est. speed input: 31903.25 toks/s, output: 31.16 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:06<00:13, 23.55it/s, est. speed input: 31682.11 toks/s, output: 30.94 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:06<00:13, 23.55it/s, est. speed input: 31473.59 toks/s, output: 30.74 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:06<00:13, 23.55it/s, est. speed input: 31277.49 toks/s, output: 30.54 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:06<00:13, 23.55it/s, est. speed input: 31090.50 toks/s, output: 30.36 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:06<00:12, 24.92it/s, est. speed input: 31058.11 toks/s, output: 30.33 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:12, 24.50it/s, est. speed input: 30886.23 toks/s, output: 30.16 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:12, 24.20it/s, est. speed input: 30721.27 toks/s, output: 30.00 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:07<00:12, 23.97it/s, est. speed input: 30561.85 toks/s, output: 29.85 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:07<00:12, 23.84it/s, est. speed input: 30412.31 toks/s, output: 29.70 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:07<00:12, 23.73it/s, est. speed input: 30268.23 toks/s, output: 29.56 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:12, 23.67it/s, est. speed input: 30130.93 toks/s, output: 29.42 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:11, 23.62it/s, est. speed input: 30000.06 toks/s, output: 29.30 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:08<00:11, 23.58it/s, est. speed input: 29873.95 toks/s, output: 29.17 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:08<00:11, 23.57it/s, est. speed input: 29753.80 toks/s, output: 29.06 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:11, 23.77it/s, est. speed input: 29656.83 toks/s, output: 28.96 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:08<00:10, 24.27it/s, est. speed input: 29592.39 toks/s, output: 28.90 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:08<00:10, 24.62it/s, est. speed input: 29528.43 toks/s, output: 28.84 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:10, 24.87it/s, est. speed input: 29467.16 toks/s, output: 28.78 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:10, 25.05it/s, est. speed input: 29408.39 toks/s, output: 28.72 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:09<00:09, 25.18it/s, est. speed input: 29351.34 toks/s, output: 28.66 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:09<00:09, 25.25it/s, est. speed input: 29295.17 toks/s, output: 28.61 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:09<00:09, 25.33it/s, est. speed input: 29242.77 toks/s, output: 28.56 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:09<00:09, 25.37it/s, est. speed input: 29190.88 toks/s, output: 28.51 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:09, 25.41it/s, est. speed input: 29141.47 toks/s, output: 28.46 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:09, 25.41it/s, est. speed input: 29091.97 toks/s, output: 28.41 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:10<00:08, 25.40it/s, est. speed input: 29043.51 toks/s, output: 28.36 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:08, 25.40it/s, est. speed input: 28996.96 toks/s, output: 28.32 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:10<00:08, 25.40it/s, est. speed input: 28951.64 toks/s, output: 28.27 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:10<00:08, 25.42it/s, est. speed input: 28908.73 toks/s, output: 28.23 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:08, 25.41it/s, est. speed input: 28866.21 toks/s, output: 28.19 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:08, 25.43it/s, est. speed input: 28825.79 toks/s, output: 28.15 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:11<00:07, 25.39it/s, est. speed input: 28784.16 toks/s, output: 28.11 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:11<00:07, 24.80it/s, est. speed input: 28712.82 toks/s, output: 28.04 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:11<00:07, 24.43it/s, est. speed input: 28644.95 toks/s, output: 27.97 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:07, 24.17it/s, est. speed input: 28578.92 toks/s, output: 27.91 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:07, 23.97it/s, est. speed input: 28513.84 toks/s, output: 27.85 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:07, 23.81it/s, est. speed input: 28449.04 toks/s, output: 27.78 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:12<00:07, 23.71it/s, est. speed input: 28386.61 toks/s, output: 27.72 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:12<00:07, 23.62it/s, est. speed input: 28324.99 toks/s, output: 27.66 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:12<00:07, 23.58it/s, est. speed input: 28266.40 toks/s, output: 27.60 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:07, 23.55it/s, est. speed input: 28208.74 toks/s, output: 27.55 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:06, 23.48it/s, est. speed input: 28150.82 toks/s, output: 27.49 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:12<00:06, 23.48it/s, est. speed input: 28096.42 toks/s, output: 27.44 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:13<00:06, 23.48it/s, est. speed input: 28043.58 toks/s, output: 27.39 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:13<00:06, 23.46it/s, est. speed input: 27991.12 toks/s, output: 27.34 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:13<00:06, 23.46it/s, est. speed input: 27940.59 toks/s, output: 27.29 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:06, 23.47it/s, est. speed input: 27891.90 toks/s, output: 27.24 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:05, 23.46it/s, est. speed input: 27843.89 toks/s, output: 27.19 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:13<00:05, 23.47it/s, est. speed input: 27797.35 toks/s, output: 27.15 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:14<00:05, 23.47it/s, est. speed input: 27751.89 toks/s, output: 27.10 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:14<00:05, 23.44it/s, est. speed input: 27706.13 toks/s, output: 27.06 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:14<00:05, 23.47it/s, est. speed input: 27663.76 toks/s, output: 27.02 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:05, 23.48it/s, est. speed input: 27621.84 toks/s, output: 26.97 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:04, 23.47it/s, est. speed input: 27580.29 toks/s, output: 26.93 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:14<00:04, 23.48it/s, est. speed input: 27540.02 toks/s, output: 26.89 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:15<00:04, 23.49it/s, est. speed input: 27501.00 toks/s, output: 26.86 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:15<00:04, 23.47it/s, est. speed input: 27461.80 toks/s, output: 26.82 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:04, 23.45it/s, est. speed input: 27423.31 toks/s, output: 26.78 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:04, 23.44it/s, est. speed input: 27385.62 toks/s, output: 26.74 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:15<00:03, 23.44it/s, est. speed input: 27349.24 toks/s, output: 26.71 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:15<00:03, 23.59it/s, est. speed input: 27319.48 toks/s, output: 26.68 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:16<00:03, 24.10it/s, est. speed input: 27306.64 toks/s, output: 26.67 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:16<00:03, 24.47it/s, est. speed input: 27293.85 toks/s, output: 26.65 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:02, 24.75it/s, est. speed input: 27281.71 toks/s, output: 26.64 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:16<00:02, 24.94it/s, est. speed input: 27269.57 toks/s, output: 26.63 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:16<00:02, 25.06it/s, est. speed input: 27257.23 toks/s, output: 26.62 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:16<00:02, 25.15it/s, est. speed input: 27245.32 toks/s, output: 26.61 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:17<00:02, 25.23it/s, est. speed input: 27233.88 toks/s, output: 26.60 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:17<00:02, 25.27it/s, est. speed input: 27222.31 toks/s, output: 26.58 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:17<00:01, 25.31it/s, est. speed input: 27211.46 toks/s, output: 26.57 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:17<00:01, 25.35it/s, est. speed input: 27200.98 toks/s, output: 26.56 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:17<00:01, 25.37it/s, est. speed input: 27190.65 toks/s, output: 26.55 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:17<00:01, 25.39it/s, est. speed input: 27180.69 toks/s, output: 26.54 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:18<00:01, 25.40it/s, est. speed input: 27170.61 toks/s, output: 26.53 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:18<00:01, 25.42it/s, est. speed input: 27161.12 toks/s, output: 26.52 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:18<00:01, 25.41it/s, est. speed input: 27151.08 toks/s, output: 26.51 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:18<00:00, 25.39it/s, est. speed input: 27140.79 toks/s, output: 26.50 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:18<00:00, 25.40it/s, est. speed input: 27131.42 toks/s, output: 26.50 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:17<00:00, 25.40it/s, est. speed input: 29857.06 toks/s, output: 29.16 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:17<00:00, 29.16it/s, est. speed input: 29857.06 toks/s, output: 29.16 toks/s]
[rank0]:[W125 23:53:56.201798387 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 75.5s

测试结果:
  Requests/s:   24.02
  Tokens/s:     24624.04
  Total Reqs:   512
  Elapsed:      21.31s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     24600.02

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:54:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:54:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=564989) WARNING 01-25 23:54:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=564989) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=564989) WARNING 01-25 23:54:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.09 requests/s, 24695.67 total tokens/s, 24.09 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 23:54:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:54:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:54:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:54:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:54:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:54:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:54:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:54:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:54:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:54:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:54:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:54:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:54:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:54:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:54:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:54:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:54:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=564989) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=564989) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.06it/s]
(EngineCore_DP0 pid=564989) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.25s/it]
(EngineCore_DP0 pid=564989) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
(EngineCore_DP0 pid=564989) 
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=564989) [2026-01-25 23:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=564989) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:02,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  4.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  5.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  5.02it/s]
(EngineCore_DP0 pid=564989) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.48it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  7.61it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  6.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  6.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  6.70it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 21/1024 [00:00<00:04, 203.65it/s]
Adding requests:  42%|████▏     | 433/1024 [00:00<00:00, 2454.62it/s]
Adding requests:  66%|██████▋   | 680/1024 [00:01<00:00, 514.52it/s] 
Adding requests:  81%|████████  | 827/1024 [00:01<00:00, 412.05it/s]
Adding requests:  91%|█████████ | 927/1024 [00:02<00:00, 371.98it/s]
Adding requests:  98%|█████████▊| 1001/1024 [00:02<00:00, 349.39it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 424.83it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:00<00:01, 475.23it/s, est. speed input: 486714.32 toks/s, output: 475.25 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:02<00:16, 52.73it/s, est. speed input: 65361.03 toks/s, output: 63.83 toks/s]  
Processed prompts:  16%|█▌        | 159/1024 [00:02<00:18, 45.96it/s, est. speed input: 57414.05 toks/s, output: 56.07 toks/s]
Processed prompts:  17%|█▋        | 172/1024 [00:03<00:22, 37.71it/s, est. speed input: 50183.80 toks/s, output: 49.01 toks/s]
Processed prompts:  18%|█▊        | 181/1024 [00:03<00:23, 35.71it/s, est. speed input: 48181.23 toks/s, output: 47.05 toks/s]
Processed prompts:  18%|█▊        | 188/1024 [00:04<00:25, 32.64it/s, est. speed input: 46010.94 toks/s, output: 44.93 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:04<00:28, 29.26it/s, est. speed input: 43935.53 toks/s, output: 42.91 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:04<00:28, 28.58it/s, est. speed input: 42857.46 toks/s, output: 41.85 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:29, 27.29it/s, est. speed input: 41644.45 toks/s, output: 40.67 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:05<00:30, 26.32it/s, est. speed input: 40580.15 toks/s, output: 39.63 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:05<00:31, 25.58it/s, est. speed input: 39637.54 toks/s, output: 38.71 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:31, 25.04it/s, est. speed input: 38798.37 toks/s, output: 37.89 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:06<00:31, 24.93it/s, est. speed input: 38120.83 toks/s, output: 37.23 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:06<00:30, 25.14it/s, est. speed input: 37579.74 toks/s, output: 36.70 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:30, 25.28it/s, est. speed input: 37084.21 toks/s, output: 36.21 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:07<00:29, 25.40it/s, est. speed input: 36632.46 toks/s, output: 35.77 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:07<00:29, 25.48it/s, est. speed input: 36216.53 toks/s, output: 35.37 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:29, 25.54it/s, est. speed input: 35832.60 toks/s, output: 34.99 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:28, 25.57it/s, est. speed input: 35476.04 toks/s, output: 34.64 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:28, 25.59it/s, est. speed input: 35145.30 toks/s, output: 34.32 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:28, 25.24it/s, est. speed input: 34777.23 toks/s, output: 33.96 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:28, 24.75it/s, est. speed input: 34396.83 toks/s, output: 33.59 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:28, 24.42it/s, est. speed input: 34042.91 toks/s, output: 33.24 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:10<00:28, 24.18it/s, est. speed input: 33711.32 toks/s, output: 32.92 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:10<00:28, 24.02it/s, est. speed input: 33401.63 toks/s, output: 32.62 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:10<00:28, 23.91it/s, est. speed input: 33111.81 toks/s, output: 32.34 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:28, 23.84it/s, est. speed input: 32839.50 toks/s, output: 32.07 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:11<00:27, 23.78it/s, est. speed input: 32583.15 toks/s, output: 31.82 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:11<00:27, 23.74it/s, est. speed input: 32341.44 toks/s, output: 31.58 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:12<00:27, 23.71it/s, est. speed input: 32113.62 toks/s, output: 31.36 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:12<00:26, 23.69it/s, est. speed input: 31897.73 toks/s, output: 31.15 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:12<00:26, 23.67it/s, est. speed input: 31692.73 toks/s, output: 30.95 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:13<00:26, 23.66it/s, est. speed input: 31498.72 toks/s, output: 30.76 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:13<00:25, 23.65it/s, est. speed input: 31313.66 toks/s, output: 30.58 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:13<00:25, 23.64it/s, est. speed input: 31138.01 toks/s, output: 30.41 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:14<00:25, 23.63it/s, est. speed input: 30970.29 toks/s, output: 30.24 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:14<00:24, 23.98it/s, est. speed input: 30846.85 toks/s, output: 30.12 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:14<00:23, 24.43it/s, est. speed input: 30747.59 toks/s, output: 30.03 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:15<00:23, 24.76it/s, est. speed input: 30652.42 toks/s, output: 29.93 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:15<00:22, 25.00it/s, est. speed input: 30561.32 toks/s, output: 29.84 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:15<00:22, 25.17it/s, est. speed input: 30473.78 toks/s, output: 29.76 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:15<00:21, 25.28it/s, est. speed input: 30389.40 toks/s, output: 29.68 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:16<00:21, 25.36it/s, est. speed input: 30308.27 toks/s, output: 29.60 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:16<00:21, 25.42it/s, est. speed input: 30230.32 toks/s, output: 29.52 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:16<00:20, 25.36it/s, est. speed input: 30147.71 toks/s, output: 29.44 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:17<00:20, 24.80it/s, est. speed input: 30029.86 toks/s, output: 29.33 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:17<00:20, 24.41it/s, est. speed input: 29915.80 toks/s, output: 29.21 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:17<00:20, 24.15it/s, est. speed input: 29805.90 toks/s, output: 29.11 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:18<00:20, 23.96it/s, est. speed input: 29699.55 toks/s, output: 29.00 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:18<00:20, 23.84it/s, est. speed input: 29597.90 toks/s, output: 28.90 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:18<00:20, 23.76it/s, est. speed input: 29500.15 toks/s, output: 28.81 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:19<00:19, 23.69it/s, est. speed input: 29404.64 toks/s, output: 28.72 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:19<00:19, 23.64it/s, est. speed input: 29312.51 toks/s, output: 28.63 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:19<00:19, 23.60it/s, est. speed input: 29223.62 toks/s, output: 28.54 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:20<00:18, 23.58it/s, est. speed input: 29137.43 toks/s, output: 28.45 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:20<00:18, 23.56it/s, est. speed input: 29054.31 toks/s, output: 28.37 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:20<00:18, 23.55it/s, est. speed input: 28973.82 toks/s, output: 28.29 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:21<00:17, 23.54it/s, est. speed input: 28895.76 toks/s, output: 28.22 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:21<00:17, 23.54it/s, est. speed input: 28820.60 toks/s, output: 28.15 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:22<00:17, 23.54it/s, est. speed input: 28747.76 toks/s, output: 28.07 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:22<00:16, 24.00it/s, est. speed input: 28704.98 toks/s, output: 28.03 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:22<00:15, 24.42it/s, est. speed input: 28668.62 toks/s, output: 28.00 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:22<00:15, 24.73it/s, est. speed input: 28633.51 toks/s, output: 27.96 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:23<00:14, 24.95it/s, est. speed input: 28599.10 toks/s, output: 27.93 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:23<00:14, 25.10it/s, est. speed input: 28565.34 toks/s, output: 27.90 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:23<00:14, 25.21it/s, est. speed input: 28532.65 toks/s, output: 27.86 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:24<00:13, 25.29it/s, est. speed input: 28501.06 toks/s, output: 27.83 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:24<00:13, 25.35it/s, est. speed input: 28470.44 toks/s, output: 27.80 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:24<00:13, 25.38it/s, est. speed input: 28440.09 toks/s, output: 27.77 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:25<00:13, 24.87it/s, est. speed input: 28384.91 toks/s, output: 27.72 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:25<00:13, 24.44it/s, est. speed input: 28327.39 toks/s, output: 27.66 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:25<00:12, 24.15it/s, est. speed input: 28271.11 toks/s, output: 27.61 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:26<00:12, 23.96it/s, est. speed input: 28216.64 toks/s, output: 27.56 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:26<00:12, 23.82it/s, est. speed input: 28163.45 toks/s, output: 27.50 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:26<00:12, 23.73it/s, est. speed input: 28111.76 toks/s, output: 27.45 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:27<00:11, 23.66it/s, est. speed input: 28061.45 toks/s, output: 27.40 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:27<00:11, 23.62it/s, est. speed input: 28012.33 toks/s, output: 27.36 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:27<00:11, 23.59it/s, est. speed input: 27964.43 toks/s, output: 27.31 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:28<00:10, 23.58it/s, est. speed input: 27918.23 toks/s, output: 27.26 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:28<00:10, 23.57it/s, est. speed input: 27872.95 toks/s, output: 27.22 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:28<00:03, 59.85it/s, est. speed input: 29263.13 toks/s, output: 28.58 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:29<00:03, 48.82it/s, est. speed input: 29202.91 toks/s, output: 28.52 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:29<00:04, 41.16it/s, est. speed input: 29144.06 toks/s, output: 28.46 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:29<00:04, 35.85it/s, est. speed input: 29086.91 toks/s, output: 28.41 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:30<00:05, 32.39it/s, est. speed input: 29039.11 toks/s, output: 28.36 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:30<00:05, 30.41it/s, est. speed input: 29008.94 toks/s, output: 28.33 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:30<00:05, 28.99it/s, est. speed input: 28979.38 toks/s, output: 28.30 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:31<00:05, 27.96it/s, est. speed input: 28950.22 toks/s, output: 28.27 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:31<00:04, 27.23it/s, est. speed input: 28921.74 toks/s, output: 28.24 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:31<00:04, 26.71it/s, est. speed input: 28893.93 toks/s, output: 28.22 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:32<00:04, 26.35it/s, est. speed input: 28866.56 toks/s, output: 28.19 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:32<00:04, 26.09it/s, est. speed input: 28839.94 toks/s, output: 28.16 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:32<00:03, 25.91it/s, est. speed input: 28813.75 toks/s, output: 28.14 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:33<00:03, 25.47it/s, est. speed input: 28776.55 toks/s, output: 28.10 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:33<00:03, 24.86it/s, est. speed input: 28728.86 toks/s, output: 28.06 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:33<00:03, 24.45it/s, est. speed input: 28682.39 toks/s, output: 28.01 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:34<00:02, 24.17it/s, est. speed input: 28636.57 toks/s, output: 27.97 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:34<00:02, 23.97it/s, est. speed input: 28591.58 toks/s, output: 27.92 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:34<00:02, 23.83it/s, est. speed input: 28547.50 toks/s, output: 27.88 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:35<00:01, 23.74it/s, est. speed input: 28504.29 toks/s, output: 27.84 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:35<00:01, 23.68it/s, est. speed input: 28462.15 toks/s, output: 27.80 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:35<00:01, 23.64it/s, est. speed input: 28420.74 toks/s, output: 27.75 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:36<00:00, 23.60it/s, est. speed input: 28379.96 toks/s, output: 27.71 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:36<00:00, 23.58it/s, est. speed input: 28340.12 toks/s, output: 27.68 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:36<00:00, 24.45it/s, est. speed input: 28332.37 toks/s, output: 27.67 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 24.45it/s, est. speed input: 28499.12 toks/s, output: 27.83 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 27.83it/s, est. speed input: 28499.12 toks/s, output: 27.83 toks/s]
[rank0]:[W125 23:55:38.054947131 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 102.3s

测试结果:
  Requests/s:   24.09
  Tokens/s:     24695.67
  Total Reqs:   1024
  Elapsed:      42.50s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     24671.58

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:56:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:56:05 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=566785) WARNING 01-25 23:56:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=566785) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=566785) WARNING 01-25 23:56:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.10 requests/s, 24697.62 total tokens/s, 24.10 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 23:56:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:56:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:56:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:56:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:56:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:56:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:56:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:56:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:56:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:56:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:56:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:56:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:56:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:56:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:56:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:56:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:56:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=566785) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=566785) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.02s/it]
(EngineCore_DP0 pid=566785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.35s/it]
(EngineCore_DP0 pid=566785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.30s/it]
(EngineCore_DP0 pid=566785) 
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=566785) [2026-01-25 23:56:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=566785) [rank0]:W0125 23:56:35.710000 566785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=566785) [rank0]:W0125 23:56:35.827000 566785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=566785) [rank0]:W0125 23:56:37.468000 566785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=566785) [rank0]:W0125 23:56:37.638000 566785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=566785) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  7.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.61it/s]
(EngineCore_DP0 pid=566785) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:01,  3.63it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.06it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  3.60it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:01<00:00,  4.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  3.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  3.55it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/2048 [00:00<00:09, 207.35it/s]
Adding requests:   2%|▏         | 46/2048 [00:00<00:08, 230.76it/s]
Adding requests:   3%|▎         | 71/2048 [00:00<00:08, 236.67it/s]
Adding requests:   5%|▍         | 95/2048 [00:00<00:08, 236.26it/s]
Adding requests:   6%|▌         | 119/2048 [00:00<00:08, 235.60it/s]
Adding requests:   7%|▋         | 144/2048 [00:00<00:08, 237.43it/s]
Adding requests:   8%|▊         | 170/2048 [00:00<00:07, 241.59it/s]
Adding requests:  10%|▉         | 197/2048 [00:00<00:07, 247.74it/s]
Adding requests:  11%|█         | 222/2048 [00:00<00:07, 247.33it/s]
Adding requests:  12%|█▏        | 247/2048 [00:01<00:07, 244.88it/s]
Adding requests:  13%|█▎        | 272/2048 [00:01<00:07, 242.16it/s]
Adding requests:  15%|█▍        | 298/2048 [00:01<00:07, 245.19it/s]
Adding requests:  16%|█▌        | 324/2048 [00:01<00:06, 246.78it/s]
Adding requests:  17%|█▋        | 350/2048 [00:01<00:06, 249.64it/s]
Adding requests:  18%|█▊        | 376/2048 [00:01<00:06, 250.84it/s]
Adding requests:  20%|█▉        | 402/2048 [00:01<00:06, 249.98it/s]
Adding requests:  21%|██        | 428/2048 [00:01<00:06, 252.64it/s]
Adding requests:  22%|██▏       | 454/2048 [00:01<00:06, 250.30it/s]
Adding requests:  23%|██▎       | 481/2048 [00:01<00:06, 254.77it/s]
Adding requests:  25%|██▍       | 509/2048 [00:02<00:05, 261.24it/s]
Adding requests:  26%|██▋       | 538/2048 [00:02<00:05, 266.37it/s]
Adding requests:  28%|██▊       | 566/2048 [00:02<00:05, 266.96it/s]
Adding requests:  29%|██▉       | 593/2048 [00:02<00:05, 258.46it/s]
Adding requests:  30%|███       | 619/2048 [00:02<00:05, 256.15it/s]
Adding requests:  31%|███▏      | 645/2048 [00:02<00:05, 251.47it/s]
Adding requests:  33%|███▎      | 671/2048 [00:02<00:05, 248.89it/s]
Adding requests:  34%|███▍      | 698/2048 [00:02<00:05, 252.89it/s]
Adding requests:  35%|███▌      | 724/2048 [00:02<00:05, 250.16it/s]
Adding requests:  37%|███▋      | 750/2048 [00:03<00:05, 244.63it/s]
Adding requests:  38%|███▊      | 775/2048 [00:03<00:05, 244.58it/s]
Adding requests:  39%|███▉      | 801/2048 [00:03<00:05, 246.65it/s]
Adding requests:  40%|████      | 827/2048 [00:03<00:04, 249.22it/s]
Adding requests:  42%|████▏     | 853/2048 [00:03<00:04, 249.82it/s]
Adding requests:  43%|████▎     | 878/2048 [00:03<00:04, 249.09it/s]
Adding requests:  44%|████▍     | 905/2048 [00:03<00:04, 252.37it/s]
Adding requests:  45%|████▌     | 931/2048 [00:03<00:04, 241.79it/s]
Adding requests:  47%|████▋     | 956/2048 [00:03<00:04, 236.25it/s]
Adding requests:  48%|████▊     | 980/2048 [00:03<00:04, 236.47it/s]
Adding requests:  49%|████▉     | 1004/2048 [00:04<00:04, 233.78it/s]
Adding requests:  50%|█████     | 1029/2048 [00:04<00:04, 237.90it/s]
Adding requests:  51%|█████▏    | 1053/2048 [00:04<00:04, 234.76it/s]
Adding requests:  53%|█████▎    | 1078/2048 [00:04<00:04, 236.96it/s]
Adding requests:  54%|█████▍    | 1102/2048 [00:04<00:03, 236.61it/s]
Adding requests:  55%|█████▌    | 1129/2048 [00:04<00:03, 246.24it/s]
Adding requests:  56%|█████▋    | 1154/2048 [00:04<00:03, 245.69it/s]
Adding requests:  58%|█████▊    | 1182/2048 [00:04<00:03, 253.09it/s]
Adding requests:  59%|█████▉    | 1210/2048 [00:04<00:03, 259.91it/s]
Adding requests:  60%|██████    | 1237/2048 [00:04<00:03, 259.28it/s]
Adding requests:  62%|██████▏   | 1263/2048 [00:05<00:03, 258.88it/s]
Adding requests:  63%|██████▎   | 1289/2048 [00:05<00:02, 258.38it/s]
Adding requests:  64%|██████▍   | 1318/2048 [00:05<00:02, 265.15it/s]
Adding requests:  66%|██████▌   | 1346/2048 [00:05<00:02, 268.64it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:05<00:02, 271.46it/s]
Adding requests:  68%|██████▊   | 1402/2048 [00:05<00:02, 267.91it/s]
Adding requests:  70%|██████▉   | 1429/2048 [00:05<00:02, 267.17it/s]
Adding requests:  71%|███████   | 1457/2048 [00:05<00:02, 268.93it/s]
Adding requests:  73%|███████▎  | 1486/2048 [00:05<00:02, 274.39it/s]
Adding requests:  74%|███████▍  | 1515/2048 [00:06<00:01, 277.00it/s]
Adding requests:  75%|███████▌  | 1543/2048 [00:06<00:01, 270.62it/s]
Adding requests:  77%|███████▋  | 1571/2048 [00:06<00:01, 260.47it/s]
Adding requests:  78%|███████▊  | 1598/2048 [00:06<00:01, 260.12it/s]
Adding requests:  79%|███████▉  | 1625/2048 [00:06<00:01, 257.06it/s]
Adding requests:  81%|████████  | 1651/2048 [00:06<00:01, 256.42it/s]
Adding requests:  82%|████████▏ | 1677/2048 [00:06<00:01, 252.11it/s]
Adding requests:  83%|████████▎ | 1704/2048 [00:06<00:01, 256.51it/s]
Adding requests:  85%|████████▍ | 1731/2048 [00:06<00:01, 259.05it/s]
Adding requests:  86%|████████▌ | 1758/2048 [00:06<00:01, 261.85it/s]
Adding requests:  87%|████████▋ | 1786/2048 [00:07<00:00, 265.63it/s]
Adding requests:  89%|████████▊ | 1813/2048 [00:07<00:00, 263.70it/s]
Adding requests:  90%|████████▉ | 1840/2048 [00:07<00:00, 264.19it/s]
Adding requests:  91%|█████████ | 1867/2048 [00:07<00:00, 256.67it/s]
Adding requests:  92%|█████████▏| 1893/2048 [00:07<00:00, 255.51it/s]
Adding requests:  94%|█████████▎| 1919/2048 [00:07<00:00, 254.41it/s]
Adding requests:  95%|█████████▍| 1945/2048 [00:07<00:00, 251.37it/s]
Adding requests:  96%|█████████▌| 1971/2048 [00:07<00:00, 247.57it/s]
Adding requests:  97%|█████████▋| 1996/2048 [00:07<00:00, 243.03it/s]
Adding requests:  99%|█████████▊| 2021/2048 [00:08<00:00, 236.42it/s]
Adding requests: 100%|█████████▉| 2046/2048 [00:08<00:00, 238.18it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 251.59it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:00<00:05, 327.01it/s, est. speed input: 334872.93 toks/s, output: 327.01 toks/s]
Processed prompts:  10%|█         | 211/2048 [00:01<00:20, 91.05it/s, est. speed input: 114067.14 toks/s, output: 111.39 toks/s] 
Processed prompts:  11%|█         | 226/2048 [00:02<00:27, 66.42it/s, est. speed input: 90072.02 toks/s, output: 87.96 toks/s]  
Processed prompts:  12%|█▏        | 242/2048 [00:03<00:34, 51.97it/s, est. speed input: 76376.72 toks/s, output: 74.59 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:03<00:41, 42.75it/s, est. speed input: 67395.33 toks/s, output: 65.82 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:04<00:47, 37.38it/s, est. speed input: 61578.74 toks/s, output: 60.14 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:05<00:51, 33.87it/s, est. speed input: 57325.68 toks/s, output: 55.98 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:05<00:55, 31.40it/s, est. speed input: 53982.13 toks/s, output: 52.72 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:06<00:58, 29.67it/s, est. speed input: 51289.37 toks/s, output: 50.09 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:06<00:30, 55.23it/s, est. speed input: 57204.96 toks/s, output: 55.86 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:07<00:37, 44.74it/s, est. speed input: 54503.46 toks/s, output: 53.23 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:07<00:43, 37.62it/s, est. speed input: 52015.34 toks/s, output: 50.80 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:08<00:49, 33.05it/s, est. speed input: 49867.76 toks/s, output: 48.70 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:09<00:53, 30.20it/s, est. speed input: 48066.89 toks/s, output: 46.94 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:09<00:56, 28.30it/s, est. speed input: 46507.15 toks/s, output: 45.42 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:10<00:58, 27.01it/s, est. speed input: 45141.09 toks/s, output: 44.08 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:11<00:59, 26.13it/s, est. speed input: 43935.79 toks/s, output: 42.91 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:11<01:00, 25.52it/s, est. speed input: 42865.27 toks/s, output: 41.86 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:12<01:01, 25.10it/s, est. speed input: 41907.44 toks/s, output: 40.93 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:13<01:00, 24.93it/s, est. speed input: 41076.84 toks/s, output: 40.11 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:13<00:59, 25.11it/s, est. speed input: 40401.50 toks/s, output: 39.45 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:14<00:58, 25.23it/s, est. speed input: 39783.12 toks/s, output: 38.85 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:15<00:58, 25.32it/s, est. speed input: 39216.94 toks/s, output: 38.30 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:15<00:58, 24.88it/s, est. speed input: 38592.02 toks/s, output: 37.69 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:16<00:58, 24.46it/s, est. speed input: 37991.80 toks/s, output: 37.10 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:17<00:58, 24.17it/s, est. speed input: 37439.75 toks/s, output: 36.56 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:17<00:58, 23.98it/s, est. speed input: 36930.03 toks/s, output: 36.06 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:18<00:58, 23.84it/s, est. speed input: 36457.45 toks/s, output: 35.60 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:19<00:57, 23.75it/s, est. speed input: 36020.05 toks/s, output: 35.18 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:19<00:57, 23.69it/s, est. speed input: 35612.35 toks/s, output: 34.78 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:20<00:56, 23.65it/s, est. speed input: 35231.42 toks/s, output: 34.41 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:21<00:56, 23.61it/s, est. speed input: 34874.62 toks/s, output: 34.06 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:21<00:54, 23.91it/s, est. speed input: 34587.59 toks/s, output: 33.78 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:22<00:53, 24.36it/s, est. speed input: 34350.68 toks/s, output: 33.55 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:23<00:51, 24.70it/s, est. speed input: 34128.41 toks/s, output: 33.33 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:23<00:50, 24.89it/s, est. speed input: 33910.42 toks/s, output: 33.12 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:24<00:50, 24.47it/s, est. speed input: 33637.72 toks/s, output: 32.85 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:25<00:50, 24.18it/s, est. speed input: 33379.60 toks/s, output: 32.60 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:25<00:50, 23.99it/s, est. speed input: 33135.68 toks/s, output: 32.36 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:26<00:50, 23.86it/s, est. speed input: 32903.92 toks/s, output: 32.13 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:27<00:49, 23.77it/s, est. speed input: 32683.92 toks/s, output: 31.92 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:27<00:49, 23.70it/s, est. speed input: 32474.54 toks/s, output: 31.71 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:28<00:48, 23.65it/s, est. speed input: 32274.50 toks/s, output: 31.52 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:29<00:47, 23.99it/s, est. speed input: 32123.10 toks/s, output: 31.37 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:29<00:45, 24.43it/s, est. speed input: 31996.52 toks/s, output: 31.25 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:30<00:44, 24.74it/s, est. speed input: 31875.38 toks/s, output: 31.13 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:31<00:43, 24.97it/s, est. speed input: 31758.95 toks/s, output: 31.01 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:31<00:43, 24.79it/s, est. speed input: 31618.03 toks/s, output: 30.88 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:32<00:43, 24.40it/s, est. speed input: 31460.17 toks/s, output: 30.72 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:33<00:43, 24.13it/s, est. speed input: 31308.83 toks/s, output: 30.58 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:33<00:42, 23.95it/s, est. speed input: 31163.47 toks/s, output: 30.43 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:34<00:42, 23.83it/s, est. speed input: 31024.22 toks/s, output: 30.30 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:35<00:41, 23.74it/s, est. speed input: 30890.19 toks/s, output: 30.17 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:35<00:41, 23.68it/s, est. speed input: 30760.86 toks/s, output: 30.04 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:36<00:40, 23.72it/s, est. speed input: 30643.60 toks/s, output: 29.93 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:37<00:38, 24.23it/s, est. speed input: 30566.66 toks/s, output: 29.85 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:37<00:37, 24.60it/s, est. speed input: 30492.52 toks/s, output: 29.78 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:37<00:18, 47.70it/s, est. speed input: 31569.97 toks/s, output: 30.83 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:38<00:21, 40.29it/s, est. speed input: 31481.31 toks/s, output: 30.74 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:39<00:23, 35.52it/s, est. speed input: 31395.62 toks/s, output: 30.66 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:39<00:26, 31.68it/s, est. speed input: 31278.83 toks/s, output: 30.55 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:40<00:28, 29.04it/s, est. speed input: 31158.39 toks/s, output: 30.43 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:41<00:29, 27.30it/s, est. speed input: 31042.27 toks/s, output: 30.31 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:41<00:29, 26.13it/s, est. speed input: 30929.71 toks/s, output: 30.20 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:42<00:30, 25.33it/s, est. speed input: 30820.66 toks/s, output: 30.10 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:43<00:30, 24.79it/s, est. speed input: 30715.19 toks/s, output: 30.00 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:43<00:30, 24.41it/s, est. speed input: 30612.88 toks/s, output: 29.90 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:44<00:29, 24.14it/s, est. speed input: 30513.56 toks/s, output: 29.80 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:45<00:28, 24.48it/s, est. speed input: 30449.80 toks/s, output: 29.74 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:45<00:27, 24.77it/s, est. speed input: 30390.25 toks/s, output: 29.68 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:46<00:26, 24.98it/s, est. speed input: 30332.33 toks/s, output: 29.62 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:47<00:26, 25.13it/s, est. speed input: 30276.12 toks/s, output: 29.57 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:47<00:25, 24.86it/s, est. speed input: 30200.94 toks/s, output: 29.49 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:48<00:25, 24.45it/s, est. speed input: 30115.26 toks/s, output: 29.41 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:49<00:25, 24.17it/s, est. speed input: 30032.13 toks/s, output: 29.33 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:49<00:24, 23.97it/s, est. speed input: 29951.14 toks/s, output: 29.25 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:50<00:24, 23.84it/s, est. speed input: 29872.51 toks/s, output: 29.17 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:51<00:23, 23.75it/s, est. speed input: 29795.85 toks/s, output: 29.10 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:51<00:22, 23.69it/s, est. speed input: 29721.29 toks/s, output: 29.02 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:52<00:22, 23.64it/s, est. speed input: 29648.37 toks/s, output: 28.95 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:53<00:21, 23.93it/s, est. speed input: 29594.69 toks/s, output: 28.90 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:53<00:20, 24.38it/s, est. speed input: 29554.02 toks/s, output: 28.86 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:54<00:19, 24.71it/s, est. speed input: 29514.51 toks/s, output: 28.82 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:55<00:18, 24.94it/s, est. speed input: 29475.88 toks/s, output: 28.79 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:55<00:17, 24.80it/s, est. speed input: 29424.30 toks/s, output: 28.73 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:56<00:17, 24.82it/s, est. speed input: 29379.02 toks/s, output: 28.69 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:57<00:16, 24.42it/s, est. speed input: 29316.15 toks/s, output: 28.63 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:57<00:16, 24.15it/s, est. speed input: 29254.92 toks/s, output: 28.57 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:58<00:15, 23.97it/s, est. speed input: 29195.12 toks/s, output: 28.51 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:59<00:15, 23.84it/s, est. speed input: 29136.61 toks/s, output: 28.45 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:59<00:14, 23.75it/s, est. speed input: 29079.49 toks/s, output: 28.40 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:00<00:14, 23.68it/s, est. speed input: 29023.51 toks/s, output: 28.34 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:01<00:13, 24.04it/s, est. speed input: 28986.65 toks/s, output: 28.31 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:01<00:12, 24.46it/s, est. speed input: 28957.56 toks/s, output: 28.28 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:02<00:11, 24.77it/s, est. speed input: 28929.14 toks/s, output: 28.25 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:02<00:10, 24.99it/s, est. speed input: 28901.12 toks/s, output: 28.22 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:03<00:10, 24.96it/s, est. speed input: 28866.63 toks/s, output: 28.19 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:04<00:09, 24.52it/s, est. speed input: 28816.65 toks/s, output: 28.14 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:04<00:09, 24.22it/s, est. speed input: 28767.41 toks/s, output: 28.09 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:05<00:08, 24.02it/s, est. speed input: 28719.42 toks/s, output: 28.05 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:06<00:07, 23.87it/s, est. speed input: 28672.19 toks/s, output: 28.00 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:07<00:07, 23.78it/s, est. speed input: 28626.16 toks/s, output: 27.96 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:07<00:06, 23.71it/s, est. speed input: 28580.99 toks/s, output: 27.91 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:08<00:06, 23.66it/s, est. speed input: 28536.63 toks/s, output: 27.87 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:08<00:02, 43.08it/s, est. speed input: 29083.81 toks/s, output: 28.40 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:09<00:02, 37.61it/s, est. speed input: 29057.15 toks/s, output: 28.38 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:10<00:01, 33.88it/s, est. speed input: 29030.72 toks/s, output: 28.35 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:10<00:01, 31.33it/s, est. speed input: 29005.10 toks/s, output: 28.33 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:11<00:01, 29.57it/s, est. speed input: 28979.93 toks/s, output: 28.30 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:11<00:00, 28.41it/s, est. speed input: 28957.12 toks/s, output: 28.28 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:11<00:00, 28.41it/s, est. speed input: 29156.28 toks/s, output: 28.47 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:11<00:00, 28.47it/s, est. speed input: 29156.28 toks/s, output: 28.47 toks/s]
[rank0]:[W125 23:58:08.621179372 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 149.3s

测试结果:
  Requests/s:   24.10
  Tokens/s:     24697.62
  Total Reqs:   2048
  Elapsed:      85.00s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     24673.53

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:58:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 23:58:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=569305) WARNING 01-25 23:58:59 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=569305) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=569305) WARNING 01-25 23:59:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 6.31 requests/s, 6463.27 total tokens/s, 6.31 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 23:58:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:58:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:58:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:58:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:58:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:58:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:58:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:58:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:58:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:58:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:58:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:58:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:58:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:58:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:58:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:58:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:58:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:00] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=569305) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=569305) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.10it/s]
(EngineCore_DP0 pid=569305) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
(EngineCore_DP0 pid=569305) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.16s/it]
(EngineCore_DP0 pid=569305) 
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=569305) [2026-01-25 23:59:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=569305) [rank0]:W0125 23:59:21.536000 569305 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=569305) [rank0]:W0125 23:59:21.655000 569305 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=569305) [rank0]:W0125 23:59:23.732000 569305 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=569305) [rank0]:W0125 23:59:23.930000 569305 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=569305) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:06,  1.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  2.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:01<00:04,  1.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:02,  2.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:01<00:01,  3.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:02<00:01,  4.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:02<00:00,  5.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:02<00:00,  5.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:02<00:00,  6.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  6.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.10it/s]
(EngineCore_DP0 pid=569305) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.48it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  7.37it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  6.75it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  6.58it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  6.55it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  4.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  5.37it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/4096 [00:00<00:19, 208.58it/s]
Adding requests:   1%|          | 47/4096 [00:00<00:16, 238.41it/s]
Adding requests:   2%|▏         | 74/4096 [00:00<00:16, 250.43it/s]
Adding requests:   2%|▏         | 100/4096 [00:00<00:15, 251.23it/s]
Adding requests:   3%|▎         | 126/4096 [00:00<00:15, 252.65it/s]
Adding requests:   4%|▎         | 152/4096 [00:00<00:15, 250.98it/s]
Adding requests:   4%|▍         | 179/4096 [00:00<00:15, 255.40it/s]
Adding requests:   5%|▌         | 206/4096 [00:00<00:15, 259.02it/s]
Adding requests:   6%|▌         | 232/4096 [00:00<00:15, 256.56it/s]
Adding requests:   6%|▋         | 258/4096 [00:01<00:15, 249.26it/s]
Adding requests:  16%|█▌        | 663/4096 [00:01<00:02, 1358.65it/s]
Adding requests:  20%|█▉        | 801/4096 [00:01<00:06, 540.67it/s] 
Adding requests:  22%|██▏       | 904/4096 [00:02<00:07, 407.94it/s]
Adding requests:  24%|██▍       | 983/4096 [00:02<00:08, 346.70it/s]
Adding requests:  26%|██▌       | 1045/4096 [00:02<00:09, 310.58it/s]
Adding requests:  27%|██▋       | 1095/4096 [00:03<00:10, 292.81it/s]
Adding requests:  28%|██▊       | 1137/4096 [00:03<00:10, 270.50it/s]
Adding requests:  29%|██▊       | 1173/4096 [00:03<00:11, 264.07it/s]
Adding requests:  29%|██▉       | 1205/4096 [00:03<00:11, 252.21it/s]
Adding requests:  30%|███       | 1234/4096 [00:03<00:11, 250.58it/s]
Adding requests:  31%|███       | 1262/4096 [00:03<00:11, 248.80it/s]
Adding requests:  31%|███▏      | 1289/4096 [00:03<00:12, 233.74it/s]
Adding requests:  32%|███▏      | 1314/4096 [00:04<00:11, 233.76it/s]
Adding requests:  33%|███▎      | 1339/4096 [00:04<00:11, 236.00it/s]
Adding requests:  33%|███▎      | 1364/4096 [00:04<00:11, 231.69it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:04<00:11, 226.65it/s]
Adding requests:  34%|███▍      | 1412/4096 [00:04<00:11, 228.89it/s]
Adding requests:  35%|███▌      | 1438/4096 [00:04<00:11, 236.30it/s]
Adding requests:  36%|███▌      | 1462/4096 [00:04<00:11, 224.45it/s]
Adding requests:  36%|███▋      | 1488/4096 [00:04<00:11, 233.17it/s]
Adding requests:  37%|███▋      | 1514/4096 [00:04<00:10, 240.47it/s]
Adding requests:  38%|███▊      | 1539/4096 [00:05<00:11, 229.02it/s]
Adding requests:  38%|███▊      | 1563/4096 [00:05<00:11, 221.22it/s]
Adding requests:  39%|███▊      | 1587/4096 [00:05<00:11, 224.46it/s]
Adding requests:  39%|███▉      | 1611/4096 [00:05<00:11, 225.19it/s]
Adding requests:  40%|███▉      | 1634/4096 [00:05<00:11, 208.23it/s]
Adding requests:  40%|████      | 1657/4096 [00:05<00:11, 212.75it/s]
Adding requests:  41%|████      | 1683/4096 [00:05<00:10, 224.95it/s]
Adding requests:  42%|████▏     | 1706/4096 [00:05<00:10, 221.45it/s]
Adding requests:  42%|████▏     | 1732/4096 [00:05<00:10, 230.37it/s]
Adding requests:  43%|████▎     | 1760/4096 [00:06<00:09, 241.81it/s]
Adding requests:  44%|████▎     | 1785/4096 [00:06<00:09, 240.95it/s]
Adding requests:  44%|████▍     | 1810/4096 [00:06<00:09, 230.92it/s]
Adding requests:  45%|████▍     | 1836/4096 [00:06<00:09, 236.68it/s]
Adding requests:  45%|████▌     | 1860/4096 [00:06<00:09, 237.02it/s]
Adding requests:  46%|████▌     | 1884/4096 [00:06<00:09, 234.44it/s]
Adding requests:  47%|████▋     | 1911/4096 [00:06<00:08, 243.29it/s]
Adding requests:  47%|████▋     | 1938/4096 [00:06<00:08, 249.06it/s]
Adding requests:  48%|████▊     | 1963/4096 [00:06<00:08, 239.56it/s]
Adding requests:  49%|████▊     | 1990/4096 [00:06<00:08, 247.55it/s]
Adding requests:  49%|████▉     | 2016/4096 [00:07<00:08, 247.34it/s]
Adding requests:  50%|████▉     | 2041/4096 [00:07<00:08, 229.62it/s]
Adding requests:  50%|█████     | 2066/4096 [00:07<00:08, 235.07it/s]
Adding requests:  51%|█████     | 2093/4096 [00:07<00:08, 243.93it/s]
Adding requests:  52%|█████▏    | 2118/4096 [00:07<00:08, 240.83it/s]
Adding requests:  52%|█████▏    | 2143/4096 [00:07<00:08, 243.12it/s]
Adding requests:  53%|█████▎    | 2169/4096 [00:07<00:07, 247.31it/s]
Adding requests:  54%|█████▎    | 2194/4096 [00:07<00:07, 245.99it/s]
Adding requests:  54%|█████▍    | 2219/4096 [00:07<00:07, 241.41it/s]
Adding requests:  55%|█████▍    | 2244/4096 [00:08<00:07, 243.23it/s]
Adding requests:  55%|█████▌    | 2271/4096 [00:08<00:07, 250.78it/s]
Adding requests:  56%|█████▌    | 2297/4096 [00:08<00:07, 239.06it/s]
Adding requests:  57%|█████▋    | 2324/4096 [00:08<00:07, 247.01it/s]
Adding requests:  57%|█████▋    | 2349/4096 [00:08<00:07, 244.54it/s]
Adding requests:  58%|█████▊    | 2374/4096 [00:08<00:07, 233.69it/s]
Adding requests:  59%|█████▊    | 2402/4096 [00:08<00:06, 246.51it/s]
Adding requests:  59%|█████▉    | 2430/4096 [00:08<00:06, 253.83it/s]
Adding requests:  60%|█████▉    | 2456/4096 [00:08<00:06, 235.18it/s]
Adding requests:  61%|██████    | 2480/4096 [00:09<00:06, 233.00it/s]
Adding requests:  61%|██████    | 2505/4096 [00:09<00:06, 236.12it/s]
Adding requests:  62%|██████▏   | 2529/4096 [00:09<00:06, 233.06it/s]
Adding requests:  62%|██████▏   | 2553/4096 [00:09<00:06, 231.07it/s]
Adding requests:  63%|██████▎   | 2580/4096 [00:09<00:06, 240.92it/s]
Adding requests:  64%|██████▎   | 2606/4096 [00:09<00:06, 244.50it/s]
Adding requests:  64%|██████▍   | 2631/4096 [00:09<00:06, 224.21it/s]
Adding requests:  65%|██████▍   | 2655/4096 [00:09<00:06, 226.73it/s]
Adding requests:  65%|██████▌   | 2680/4096 [00:09<00:06, 231.93it/s]
Adding requests:  66%|██████▌   | 2704/4096 [00:09<00:06, 222.31it/s]
Adding requests:  67%|██████▋   | 2727/4096 [00:10<00:06, 218.53it/s]
Adding requests:  67%|██████▋   | 2752/4096 [00:10<00:05, 227.04it/s]
Adding requests:  68%|██████▊   | 2777/4096 [00:10<00:05, 231.03it/s]
Adding requests:  68%|██████▊   | 2801/4096 [00:10<00:05, 228.84it/s]
Adding requests:  69%|██████▉   | 2825/4096 [00:10<00:05, 230.72it/s]
Adding requests:  70%|██████▉   | 2852/4096 [00:10<00:05, 239.23it/s]
Adding requests:  70%|███████   | 2876/4096 [00:10<00:05, 238.81it/s]
Adding requests:  71%|███████   | 2900/4096 [00:10<00:05, 231.46it/s]
Adding requests:  71%|███████▏  | 2925/4096 [00:10<00:04, 236.62it/s]
Adding requests:  72%|███████▏  | 2953/4096 [00:11<00:04, 248.15it/s]
Adding requests:  73%|███████▎  | 2978/4096 [00:11<00:04, 236.02it/s]
Adding requests:  73%|███████▎  | 3002/4096 [00:11<00:04, 235.47it/s]
Adding requests:  74%|███████▍  | 3028/4096 [00:11<00:04, 239.89it/s]
Adding requests:  75%|███████▍  | 3053/4096 [00:11<00:04, 237.04it/s]
Adding requests:  75%|███████▌  | 3077/4096 [00:11<00:04, 228.09it/s]
Adding requests:  76%|███████▌  | 3103/4096 [00:11<00:04, 235.73it/s]
Adding requests:  76%|███████▋  | 3130/4096 [00:11<00:03, 244.99it/s]
Adding requests:  77%|███████▋  | 3155/4096 [00:11<00:04, 227.33it/s]
Adding requests:  78%|███████▊  | 3179/4096 [00:12<00:04, 229.24it/s]
Adding requests:  78%|███████▊  | 3205/4096 [00:12<00:03, 236.33it/s]
Adding requests:  79%|███████▉  | 3229/4096 [00:12<00:03, 234.51it/s]
Adding requests:  79%|███████▉  | 3253/4096 [00:12<00:03, 230.34it/s]
Adding requests:  80%|████████  | 3277/4096 [00:12<00:03, 227.17it/s]
Adding requests:  81%|████████  | 3300/4096 [00:12<00:03, 222.71it/s]
Adding requests:  81%|████████  | 3323/4096 [00:12<00:03, 210.80it/s]
Adding requests:  82%|████████▏ | 3348/4096 [00:12<00:03, 219.09it/s]
Adding requests:  82%|████████▏ | 3374/4096 [00:12<00:03, 229.87it/s]
Adding requests:  83%|████████▎ | 3398/4096 [00:12<00:03, 220.30it/s]
Adding requests:  84%|████████▎ | 3421/4096 [00:13<00:03, 220.09it/s]
Adding requests:  84%|████████▍ | 3447/4096 [00:13<00:02, 231.00it/s]
Adding requests:  85%|████████▍ | 3471/4096 [00:13<00:02, 232.53it/s]
Adding requests:  85%|████████▌ | 3495/4096 [00:13<00:02, 216.26it/s]
Adding requests:  86%|████████▌ | 3523/4096 [00:13<00:02, 232.65it/s]
Adding requests:  87%|████████▋ | 3552/4096 [00:13<00:02, 247.99it/s]
Adding requests:  87%|████████▋ | 3578/4096 [00:13<00:02, 233.90it/s]
Adding requests:  88%|████████▊ | 3604/4096 [00:13<00:02, 238.98it/s]
Adding requests:  89%|████████▊ | 3632/4096 [00:13<00:01, 248.94it/s]
Adding requests:  89%|████████▉ | 3658/4096 [00:14<00:01, 240.75it/s]
Adding requests:  90%|████████▉ | 3683/4096 [00:14<00:01, 232.90it/s]
Adding requests:  91%|█████████ | 3710/4096 [00:14<00:01, 241.09it/s]
Adding requests:  91%|█████████ | 3735/4096 [00:14<00:01, 228.21it/s]
Adding requests:  92%|█████████▏| 3759/4096 [00:14<00:01, 215.62it/s]
Adding requests:  92%|█████████▏| 3782/4096 [00:14<00:01, 218.30it/s]
Adding requests:  93%|█████████▎| 3805/4096 [00:14<00:01, 217.51it/s]
Adding requests:  93%|█████████▎| 3827/4096 [00:14<00:01, 209.90it/s]
Adding requests:  94%|█████████▍| 3850/4096 [00:14<00:01, 213.89it/s]
Adding requests:  95%|█████████▍| 3877/4096 [00:15<00:00, 228.63it/s]
Adding requests:  95%|█████████▌| 3901/4096 [00:15<00:00, 225.53it/s]
Adding requests:  96%|█████████▌| 3924/4096 [00:15<00:00, 226.18it/s]
Adding requests:  96%|█████████▋| 3951/4096 [00:15<00:00, 237.27it/s]
Adding requests:  97%|█████████▋| 3976/4096 [00:15<00:00, 239.08it/s]
Adding requests:  98%|█████████▊| 4000/4096 [00:15<00:00, 228.76it/s]
Adding requests:  98%|█████████▊| 4027/4096 [00:15<00:00, 237.96it/s]
Adding requests:  99%|█████████▉| 4053/4096 [00:15<00:00, 243.80it/s]
Adding requests: 100%|█████████▉| 4078/4096 [00:15<00:00, 231.42it/s]
Adding requests: 100%|██████████| 4096/4096 [00:15<00:00, 256.06it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:04<03:02, 21.85it/s, est. speed input: 22379.40 toks/s, output: 21.85 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:09<05:19, 12.41it/s, est. speed input: 14086.80 toks/s, output: 13.76 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:14<06:54,  9.48it/s, est. speed input: 11377.10 toks/s, output: 11.11 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:17<06:43,  9.68it/s, est. speed input: 11203.27 toks/s, output: 10.94 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:22<07:48,  8.26it/s, est. speed input: 10108.21 toks/s, output: 9.87 toks/s] 
Processed prompts:   6%|▋         | 258/4096 [00:27<08:26,  7.57it/s, est. speed input: 9461.19 toks/s, output: 9.24 toks/s] 
Processed prompts:   7%|▋         | 290/4096 [00:32<08:51,  7.17it/s, est. speed input: 9014.70 toks/s, output: 8.80 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:38<09:12,  6.83it/s, est. speed input: 8647.31 toks/s, output: 8.44 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:43<09:18,  6.70it/s, est. speed input: 8406.97 toks/s, output: 8.21 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:46<08:26,  7.32it/s, est. speed input: 8492.62 toks/s, output: 8.29 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:51<08:43,  7.03it/s, est. speed input: 8307.29 toks/s, output: 8.11 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:56<08:56,  6.79it/s, est. speed input: 8140.81 toks/s, output: 7.95 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:01<09:07,  6.61it/s, est. speed input: 7992.28 toks/s, output: 7.80 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:06<09:07,  6.55it/s, est. speed input: 7885.23 toks/s, output: 7.70 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:11<09:10,  6.45it/s, est. speed input: 7779.47 toks/s, output: 7.60 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:16<09:08,  6.41it/s, est. speed input: 7692.12 toks/s, output: 7.51 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:20<08:15,  7.04it/s, est. speed input: 7763.81 toks/s, output: 7.58 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:25<08:29,  6.78it/s, est. speed input: 7682.21 toks/s, output: 7.50 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:30<08:34,  6.65it/s, est. speed input: 7617.75 toks/s, output: 7.44 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:35<08:40,  6.51it/s, est. speed input: 7549.64 toks/s, output: 7.37 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:40<08:40,  6.45it/s, est. speed input: 7495.98 toks/s, output: 7.32 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [01:45<08:29,  6.53it/s, est. speed input: 7468.25 toks/s, output: 7.29 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [01:49<07:41,  7.14it/s, est. speed input: 7528.25 toks/s, output: 7.35 toks/s]
Processed prompts:  20%|██        | 834/4096 [01:54<07:52,  6.91it/s, est. speed input: 7486.87 toks/s, output: 7.31 toks/s]
Processed prompts:  21%|██        | 866/4096 [01:59<08:05,  6.66it/s, est. speed input: 7434.27 toks/s, output: 7.26 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:04<08:07,  6.56it/s, est. speed input: 7396.28 toks/s, output: 7.22 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:09<08:07,  6.50it/s, est. speed input: 7361.63 toks/s, output: 7.19 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:14<08:09,  6.40it/s, est. speed input: 7321.95 toks/s, output: 7.15 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:17<07:14,  7.14it/s, est. speed input: 7386.04 toks/s, output: 7.21 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:23<07:30,  6.81it/s, est. speed input: 7346.16 toks/s, output: 7.17 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [02:27<07:34,  6.69it/s, est. speed input: 7320.52 toks/s, output: 7.15 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [02:33<07:38,  6.55it/s, est. speed input: 7289.74 toks/s, output: 7.12 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [02:38<07:41,  6.45it/s, est. speed input: 7259.70 toks/s, output: 7.09 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [02:43<07:36,  6.44it/s, est. speed input: 7238.89 toks/s, output: 7.07 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [02:48<07:33,  6.41it/s, est. speed input: 7216.68 toks/s, output: 7.05 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [02:51<06:47,  7.07it/s, est. speed input: 7262.62 toks/s, output: 7.09 toks/s]
Processed prompts:  31%|███       | 1250/4096 [02:56<06:56,  6.83it/s, est. speed input: 7240.67 toks/s, output: 7.07 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:01<07:03,  6.65it/s, est. speed input: 7217.27 toks/s, output: 7.05 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:06<07:05,  6.54it/s, est. speed input: 7196.55 toks/s, output: 7.03 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:12<07:06,  6.45it/s, est. speed input: 7175.11 toks/s, output: 7.01 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:17<07:03,  6.41it/s, est. speed input: 7157.50 toks/s, output: 6.99 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [03:20<06:13,  7.18it/s, est. speed input: 7206.38 toks/s, output: 7.04 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [03:25<06:24,  6.90it/s, est. speed input: 7188.11 toks/s, output: 7.02 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [03:30<06:28,  6.74it/s, est. speed input: 7173.25 toks/s, output: 7.01 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [03:35<06:35,  6.55it/s, est. speed input: 7151.98 toks/s, output: 6.98 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [03:40<06:33,  6.51it/s, est. speed input: 7138.40 toks/s, output: 6.97 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [03:45<06:30,  6.46it/s, est. speed input: 7124.41 toks/s, output: 6.96 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [03:50<06:26,  6.46it/s, est. speed input: 7113.49 toks/s, output: 6.95 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [03:53<05:41,  7.21it/s, est. speed input: 7155.08 toks/s, output: 6.99 toks/s]
Processed prompts:  41%|████      | 1666/4096 [03:59<05:53,  6.86it/s, est. speed input: 7137.07 toks/s, output: 6.97 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:04<05:57,  6.71it/s, est. speed input: 7124.81 toks/s, output: 6.96 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [04:09<05:59,  6.58it/s, est. speed input: 7110.67 toks/s, output: 6.94 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [04:14<06:00,  6.48it/s, est. speed input: 7096.47 toks/s, output: 6.93 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [04:19<05:56,  6.46it/s, est. speed input: 7086.54 toks/s, output: 6.92 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [04:22<05:23,  7.02it/s, est. speed input: 7113.02 toks/s, output: 6.95 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [04:27<05:28,  6.82it/s, est. speed input: 7102.65 toks/s, output: 6.94 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [04:33<05:32,  6.63it/s, est. speed input: 7088.99 toks/s, output: 6.92 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [04:38<05:33,  6.53it/s, est. speed input: 7077.10 toks/s, output: 6.91 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [04:43<05:30,  6.49it/s, est. speed input: 7067.90 toks/s, output: 6.90 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [04:48<05:29,  6.40it/s, est. speed input: 7054.99 toks/s, output: 6.89 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [04:53<05:25,  6.39it/s, est. speed input: 7045.88 toks/s, output: 6.88 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [04:56<04:50,  7.05it/s, est. speed input: 7074.45 toks/s, output: 6.91 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [05:01<04:55,  6.81it/s, est. speed input: 7064.42 toks/s, output: 6.90 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [05:06<04:57,  6.67it/s, est. speed input: 7055.44 toks/s, output: 6.89 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [05:12<04:59,  6.50it/s, est. speed input: 7042.57 toks/s, output: 6.88 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [05:16<04:52,  6.56it/s, est. speed input: 7039.73 toks/s, output: 6.87 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [05:21<04:49,  6.50it/s, est. speed input: 7031.80 toks/s, output: 6.87 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [05:25<04:19,  7.13it/s, est. speed input: 7057.52 toks/s, output: 6.89 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [05:30<04:24,  6.89it/s, est. speed input: 7049.75 toks/s, output: 6.88 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [05:35<04:28,  6.66it/s, est. speed input: 7038.55 toks/s, output: 6.87 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [05:40<04:27,  6.56it/s, est. speed input: 7030.48 toks/s, output: 6.87 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [05:45<04:26,  6.48it/s, est. speed input: 7021.99 toks/s, output: 6.86 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [05:50<04:24,  6.41it/s, est. speed input: 7013.05 toks/s, output: 6.85 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [05:54<03:52,  7.15it/s, est. speed input: 7040.58 toks/s, output: 6.88 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [05:59<03:59,  6.81it/s, est. speed input: 7029.61 toks/s, output: 6.86 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [06:04<03:58,  6.70it/s, est. speed input: 7024.02 toks/s, output: 6.86 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [06:09<03:59,  6.53it/s, est. speed input: 7013.92 toks/s, output: 6.85 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [06:14<03:57,  6.46it/s, est. speed input: 7006.16 toks/s, output: 6.84 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [06:19<03:52,  6.46it/s, est. speed input: 7000.94 toks/s, output: 6.84 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [06:24<03:50,  6.38it/s, est. speed input: 6992.53 toks/s, output: 6.83 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [06:27<03:20,  7.18it/s, est. speed input: 7020.21 toks/s, output: 6.86 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [06:32<03:25,  6.85it/s, est. speed input: 7011.22 toks/s, output: 6.85 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [06:37<03:25,  6.70it/s, est. speed input: 7004.84 toks/s, output: 6.84 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [06:42<03:23,  6.60it/s, est. speed input: 6999.15 toks/s, output: 6.84 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [06:48<03:22,  6.46it/s, est. speed input: 6990.21 toks/s, output: 6.83 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [06:53<03:18,  6.45it/s, est. speed input: 6985.21 toks/s, output: 6.82 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [06:56<02:55,  7.11it/s, est. speed input: 7006.53 toks/s, output: 6.84 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [07:01<02:56,  6.88it/s, est. speed input: 7001.17 toks/s, output: 6.84 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [07:06<02:56,  6.71it/s, est. speed input: 6994.96 toks/s, output: 6.83 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [07:11<02:55,  6.54it/s, est. speed input: 6987.13 toks/s, output: 6.82 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [07:16<02:52,  6.50it/s, est. speed input: 6982.19 toks/s, output: 6.82 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [07:21<02:48,  6.43it/s, est. speed input: 6975.92 toks/s, output: 6.81 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [07:26<02:45,  6.38it/s, est. speed input: 6969.60 toks/s, output: 6.81 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [07:30<02:25,  7.03it/s, est. speed input: 6988.47 toks/s, output: 6.82 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [07:35<02:26,  6.76it/s, est. speed input: 6981.44 toks/s, output: 6.82 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [07:40<02:24,  6.64it/s, est. speed input: 6976.41 toks/s, output: 6.81 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [07:45<02:22,  6.52it/s, est. speed input: 6970.00 toks/s, output: 6.81 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [07:50<02:18,  6.45it/s, est. speed input: 6964.36 toks/s, output: 6.80 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [07:55<02:13,  6.45it/s, est. speed input: 6960.62 toks/s, output: 6.80 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [07:59<01:57,  7.06it/s, est. speed input: 6977.85 toks/s, output: 6.81 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [08:04<01:56,  6.85it/s, est. speed input: 6973.56 toks/s, output: 6.81 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [08:09<01:55,  6.63it/s, est. speed input: 6966.45 toks/s, output: 6.80 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [08:14<01:52,  6.54it/s, est. speed input: 6961.50 toks/s, output: 6.80 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [08:19<01:48,  6.50it/s, est. speed input: 6957.55 toks/s, output: 6.79 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [08:24<01:44,  6.41it/s, est. speed input: 6951.40 toks/s, output: 6.79 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [08:27<01:29,  7.12it/s, est. speed input: 6970.47 toks/s, output: 6.81 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [08:33<01:28,  6.82it/s, est. speed input: 6964.10 toks/s, output: 6.80 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [08:38<01:25,  6.68it/s, est. speed input: 6959.86 toks/s, output: 6.80 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [08:43<01:22,  6.56it/s, est. speed input: 6954.99 toks/s, output: 6.79 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [08:48<01:19,  6.44it/s, est. speed input: 6948.70 toks/s, output: 6.79 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [08:53<01:14,  6.44it/s, est. speed input: 6945.57 toks/s, output: 6.78 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [08:58<01:09,  6.41it/s, est. speed input: 6941.25 toks/s, output: 6.78 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [09:01<00:57,  7.16it/s, est. speed input: 6960.08 toks/s, output: 6.80 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [09:06<00:55,  6.92it/s, est. speed input: 6956.51 toks/s, output: 6.79 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [09:11<00:52,  6.70it/s, est. speed input: 6951.11 toks/s, output: 6.79 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [09:16<00:48,  6.57it/s, est. speed input: 6946.59 toks/s, output: 6.78 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [09:22<00:44,  6.47it/s, est. speed input: 6941.62 toks/s, output: 6.78 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [09:27<00:39,  6.42it/s, est. speed input: 6937.22 toks/s, output: 6.77 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [09:30<00:30,  7.18it/s, est. speed input: 6955.43 toks/s, output: 6.79 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [09:35<00:27,  6.98it/s, est. speed input: 6953.36 toks/s, output: 6.79 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [09:40<00:23,  6.80it/s, est. speed input: 6950.02 toks/s, output: 6.79 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [09:45<00:19,  6.59it/s, est. speed input: 6944.13 toks/s, output: 6.78 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [09:50<00:14,  6.53it/s, est. speed input: 6940.81 toks/s, output: 6.78 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [09:55<00:09,  6.48it/s, est. speed input: 6937.15 toks/s, output: 6.77 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [10:00<00:04,  6.48it/s, est. speed input: 6934.72 toks/s, output: 6.77 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [10:00<00:00,  6.48it/s, est. speed input: 6985.88 toks/s, output: 6.82 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [10:00<00:00,  6.82it/s, est. speed input: 6985.88 toks/s, output: 6.82 toks/s]
[rank0]:[W126 00:09:52.876813236 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 703.1s

测试结果:
  Requests/s:   6.31
  Tokens/s:     6463.27
  Total Reqs:   4096
  Elapsed:      649.58s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     6456.97

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:11:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:11:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=579617) WARNING 01-26 00:11:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=579617) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=579617) WARNING 01-26 00:11:27 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     def forward(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     raise e
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/tmp/torchinductor_root/ax/caxhtv4z7pvejo2kecicfp7dovq5qwcbf7pbrxlmuivaiaz6ety5.py", line 1093, in call
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) ERROR 01-26 00:11:40 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-26 00:11:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:11:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:11:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:11:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:11:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:11:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:11:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:11:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:11:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:11:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:11:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:11:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=579617) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=579617) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=579617) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.35s/it]
(EngineCore_DP0 pid=579617) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.29s/it]
(EngineCore_DP0 pid=579617) 
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=579617) [2026-01-26 00:11:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=579617) [rank0]:W0126 00:11:36.292000 579617 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=579617) [rank0]:W0126 00:11:36.413000 579617 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=579617) [rank0]:W0126 00:11:38.763000 579617 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=579617) [rank0]:W0126 00:11:38.945000 579617 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=579617) Process EngineCore_DP0:
(EngineCore_DP0 pid=579617) Traceback (most recent call last):
(EngineCore_DP0 pid=579617)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=579617)     self.run()
(EngineCore_DP0 pid=579617)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=579617)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=579617)     raise e
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579617)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579617)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579617)     super().__init__(
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=579617)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=579617)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=579617)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=579617)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=579617)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=579617)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=579617)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=579617)     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=579617)     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=579617)     self.model_runner.profile_run()
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=579617)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=579617)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=579617)     return func(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=579617)     outputs = self.model(
(EngineCore_DP0 pid=579617)               ^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=579617)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=579617)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=579617)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=579617)     hidden_states = self.model(
(EngineCore_DP0 pid=579617)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=579617)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=579617)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=579617)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=579617)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=579617)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=579617)     def forward(
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=579617)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=579617)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=579617)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=579617)     raise e
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=579617)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=579617)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=579617)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=579617)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=579617)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=579617)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=579617)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=579617)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=579617)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=579617)     return compiled_fn(full_args)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=579617)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=579617)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=579617)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=579617)                             ^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=579617)     outs = compiled_fn(args)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=579617)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=579617)     return self.current_callable(inputs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=579617)     out = model(new_inputs)
(EngineCore_DP0 pid=579617)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/tmp/torchinductor_root/ax/caxhtv4z7pvejo2kecicfp7dovq5qwcbf7pbrxlmuivaiaz6ety5.py", line 1093, in call
(EngineCore_DP0 pid=579617)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=579617)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=579617)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=579617)     return fn(input, L)
(EngineCore_DP0 pid=579617)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=579617)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=579617)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=579617)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=579617)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=579617)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=579617)     self._init_handles()
(EngineCore_DP0 pid=579617)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=579617)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=579617)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579617) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 00:11:41.428888115 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,14.7355,7559.3287,8.6865
1024,1024,1,128,128,14.8097,15179.9686,8.6430
2048,1024,2,256,128,22.3539,22912.6967,11.4522
4096,1024,4,512,128,24.0235,24624.0430,21.3125
8192,1024,8,1024,128,24.0933,24695.6723,42.5014
16384,1024,16,2048,128,24.0952,24697.6208,84.9960
32768,1024,32,4096,128,6.3056,6463.2728,649.5780
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:11:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:11:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=580462) WARNING 01-26 00:12:02 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=580462) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=580462) WARNING 01-26 00:12:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.99 requests/s, 7688.64 total tokens/s, 14.99 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 00:11:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:11:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:11:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:11:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:11:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:11:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:11:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:11:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:12:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:12:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:12:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:12:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:12:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:12:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:12:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:12:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:12:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=580462) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=580462) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.07s/it]
(EngineCore_DP0 pid=580462) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.93s/it]
(EngineCore_DP0 pid=580462) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.80s/it]
(EngineCore_DP0 pid=580462) 
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=580462) [2026-01-26 00:12:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=580462) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]
(EngineCore_DP0 pid=580462) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 438.24it/s]
Adding requests:  70%|██████▉   | 89/128 [00:00<00:00, 442.14it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 445.40it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:42,  2.98it/s, est. speed input: 1526.71 toks/s, output: 2.98 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:25,  4.93it/s, est. speed input: 2300.66 toks/s, output: 4.49 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:14,  8.76it/s, est. speed input: 3604.07 toks/s, output: 7.04 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:10, 11.43it/s, est. speed input: 4493.03 toks/s, output: 8.78 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:09, 13.20it/s, est. speed input: 5117.88 toks/s, output: 10.00 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:08, 14.21it/s, est. speed input: 5549.97 toks/s, output: 10.84 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:07, 15.02it/s, est. speed input: 5902.30 toks/s, output: 11.53 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:07, 15.67it/s, est. speed input: 6192.72 toks/s, output: 12.09 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:06, 16.02it/s, est. speed input: 6418.68 toks/s, output: 12.54 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:06, 16.34it/s, est. speed input: 6614.07 toks/s, output: 12.92 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 16.54it/s, est. speed input: 6777.20 toks/s, output: 13.24 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 16.68it/s, est. speed input: 6916.68 toks/s, output: 13.51 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 16.49it/s, est. speed input: 7009.75 toks/s, output: 13.69 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:06, 16.27it/s, est. speed input: 7082.08 toks/s, output: 13.83 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:02<00:06, 16.17it/s, est. speed input: 7149.89 toks/s, output: 13.96 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:02<00:06, 16.03it/s, est. speed input: 7203.06 toks/s, output: 14.07 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:02<00:06, 15.99it/s, est. speed input: 7255.32 toks/s, output: 14.17 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:02<00:05, 15.95it/s, est. speed input: 7300.97 toks/s, output: 14.26 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 15.96it/s, est. speed input: 7344.75 toks/s, output: 14.35 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 15.90it/s, est. speed input: 7380.17 toks/s, output: 14.41 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 15.84it/s, est. speed input: 7410.21 toks/s, output: 14.47 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 15.78it/s, est. speed input: 7436.54 toks/s, output: 14.52 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:03<00:05, 15.77it/s, est. speed input: 7462.92 toks/s, output: 14.58 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:03<00:05, 15.72it/s, est. speed input: 7484.12 toks/s, output: 14.62 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:03<00:05, 15.74it/s, est. speed input: 7507.45 toks/s, output: 14.66 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:04, 15.68it/s, est. speed input: 7524.28 toks/s, output: 14.70 toks/s]
Processed prompts:  41%|████      | 52/128 [00:03<00:04, 15.70it/s, est. speed input: 7543.95 toks/s, output: 14.73 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 15.68it/s, est. speed input: 7559.77 toks/s, output: 14.77 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 15.63it/s, est. speed input: 7572.97 toks/s, output: 14.79 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 15.61it/s, est. speed input: 7586.05 toks/s, output: 14.82 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:04<00:04, 15.58it/s, est. speed input: 7597.39 toks/s, output: 14.84 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:04<00:04, 15.58it/s, est. speed input: 7609.10 toks/s, output: 14.86 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:04<00:04, 15.59it/s, est. speed input: 7620.48 toks/s, output: 14.88 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:04<00:03, 15.53it/s, est. speed input: 7628.07 toks/s, output: 14.90 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:04<00:03, 15.53it/s, est. speed input: 7637.12 toks/s, output: 14.92 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 15.52it/s, est. speed input: 7645.39 toks/s, output: 14.93 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 15.54it/s, est. speed input: 7654.32 toks/s, output: 14.95 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 15.54it/s, est. speed input: 7662.25 toks/s, output: 14.97 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:05<00:03, 15.58it/s, est. speed input: 7671.24 toks/s, output: 14.98 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:05<00:03, 15.62it/s, est. speed input: 7680.47 toks/s, output: 15.00 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:05<00:03, 15.74it/s, est. speed input: 7692.76 toks/s, output: 15.02 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:05<00:02, 15.74it/s, est. speed input: 7701.16 toks/s, output: 15.04 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:05<00:02, 15.83it/s, est. speed input: 7712.77 toks/s, output: 15.06 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:05<00:02, 15.88it/s, est. speed input: 7723.18 toks/s, output: 15.08 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 15.90it/s, est. speed input: 7732.71 toks/s, output: 15.10 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 15.94it/s, est. speed input: 7742.77 toks/s, output: 15.12 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:06<00:02, 15.97it/s, est. speed input: 7752.44 toks/s, output: 15.14 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:06<00:02, 15.89it/s, est. speed input: 7758.20 toks/s, output: 15.15 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:06<00:02, 15.76it/s, est. speed input: 7761.59 toks/s, output: 15.16 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:06<00:01, 15.80it/s, est. speed input: 7768.86 toks/s, output: 15.17 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:06<00:01, 15.81it/s, est. speed input: 7775.38 toks/s, output: 15.19 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:06<00:01, 15.81it/s, est. speed input: 7781.43 toks/s, output: 15.20 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:06<00:01, 15.83it/s, est. speed input: 7787.68 toks/s, output: 15.21 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 15.77it/s, est. speed input: 7791.78 toks/s, output: 15.22 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:07<00:01, 16.14it/s, est. speed input: 7807.53 toks/s, output: 15.25 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:07<00:01, 16.46it/s, est. speed input: 7823.93 toks/s, output: 15.28 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:07<00:00, 16.61it/s, est. speed input: 7838.01 toks/s, output: 15.31 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:07<00:00, 16.77it/s, est. speed input: 7852.75 toks/s, output: 15.34 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:07<00:00, 16.87it/s, est. speed input: 7866.82 toks/s, output: 15.36 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:07<00:00, 16.92it/s, est. speed input: 7880.05 toks/s, output: 15.39 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:07<00:00, 17.00it/s, est. speed input: 7893.85 toks/s, output: 15.42 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 17.03it/s, est. speed input: 7906.51 toks/s, output: 15.44 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:08<00:00, 17.02it/s, est. speed input: 7918.21 toks/s, output: 15.47 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:08<00:00, 17.00it/s, est. speed input: 7929.17 toks/s, output: 15.49 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 17.10it/s, est. speed input: 7942.43 toks/s, output: 15.51 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 17.10it/s, est. speed input: 7942.43 toks/s, output: 15.51 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.51it/s, est. speed input: 7942.43 toks/s, output: 15.51 toks/s]
[rank0]:[W126 00:12:53.983933240 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 70.0s

测试结果:
  Requests/s:   14.99
  Tokens/s:     7688.64
  Total Reqs:   128
  Elapsed:      8.54s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     7673.65

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:13:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:13:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=581750) WARNING 01-26 00:13:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=581750) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=581750) WARNING 01-26 00:13:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.95 requests/s, 15327.72 total tokens/s, 14.95 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 00:13:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:13:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:13:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:13:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:13:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:13:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:13:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:13:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:13:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:13:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:13:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:13:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:13:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:13:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:13:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:13:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:13:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=581750) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=581750) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.82s/it]
(EngineCore_DP0 pid=581750) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.22s/it]
(EngineCore_DP0 pid=581750) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.01s/it]
(EngineCore_DP0 pid=581750) 
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=581750) [2026-01-26 00:13:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=581750) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.07it/s]
(EngineCore_DP0 pid=581750) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 233.91it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 233.64it/s]
Adding requests:  58%|█████▊    | 74/128 [00:00<00:00, 243.12it/s]
Adding requests:  77%|███████▋  | 99/128 [00:00<00:00, 242.24it/s]
Adding requests:  97%|█████████▋| 124/128 [00:00<00:00, 239.49it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 239.29it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:08, 15.52it/s, est. speed input: 15899.57 toks/s, output: 15.52 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:07, 16.04it/s, est. speed input: 16346.71 toks/s, output: 15.96 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:07, 16.24it/s, est. speed input: 16523.30 toks/s, output: 16.14 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:07, 16.33it/s, est. speed input: 16607.64 toks/s, output: 16.22 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:07, 16.40it/s, est. speed input: 16671.00 toks/s, output: 16.28 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:07, 16.53it/s, est. speed input: 16755.92 toks/s, output: 16.36 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 16.60it/s, est. speed input: 16808.47 toks/s, output: 16.41 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 16.69it/s, est. speed input: 16869.23 toks/s, output: 16.47 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:06, 16.74it/s, est. speed input: 16908.72 toks/s, output: 16.51 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 16.80it/s, est. speed input: 16952.37 toks/s, output: 16.55 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 16.90it/s, est. speed input: 17003.66 toks/s, output: 16.60 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 16.94it/s, est. speed input: 17039.57 toks/s, output: 16.64 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:06, 16.97it/s, est. speed input: 17069.75 toks/s, output: 16.67 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 16.99it/s, est. speed input: 17096.83 toks/s, output: 16.70 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 16.98it/s, est. speed input: 17114.93 toks/s, output: 16.71 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 16.99it/s, est. speed input: 17132.45 toks/s, output: 16.73 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:02<00:05, 16.97it/s, est. speed input: 17144.68 toks/s, output: 16.74 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 16.98it/s, est. speed input: 17159.24 toks/s, output: 16.76 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 16.74it/s, est. speed input: 17127.69 toks/s, output: 16.73 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 16.43it/s, est. speed input: 17074.90 toks/s, output: 16.67 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 16.10it/s, est. speed input: 17007.19 toks/s, output: 16.61 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:05, 15.97it/s, est. speed input: 16961.49 toks/s, output: 16.56 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:05, 15.80it/s, est. speed input: 16906.08 toks/s, output: 16.51 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:05, 15.64it/s, est. speed input: 16850.56 toks/s, output: 16.46 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:04, 15.63it/s, est. speed input: 16812.96 toks/s, output: 16.42 toks/s]
Processed prompts:  41%|████      | 52/128 [00:03<00:04, 15.62it/s, est. speed input: 16779.82 toks/s, output: 16.39 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 15.60it/s, est. speed input: 16746.02 toks/s, output: 16.35 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 15.64it/s, est. speed input: 16723.19 toks/s, output: 16.33 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 15.66it/s, est. speed input: 16699.87 toks/s, output: 16.31 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:04, 15.74it/s, est. speed input: 16687.05 toks/s, output: 16.30 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:04, 15.71it/s, est. speed input: 16664.09 toks/s, output: 16.27 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:04, 15.56it/s, est. speed input: 16628.00 toks/s, output: 16.24 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:04<00:03, 15.53it/s, est. speed input: 16602.52 toks/s, output: 16.21 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:04<00:03, 15.58it/s, est. speed input: 16587.06 toks/s, output: 16.20 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 15.61it/s, est. speed input: 16571.74 toks/s, output: 16.18 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:00, 73.89it/s, est. speed input: 22617.35 toks/s, output: 22.09 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 40.20it/s, est. speed input: 22045.29 toks/s, output: 21.53 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 30.17it/s, est. speed input: 21640.75 toks/s, output: 21.13 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 25.28it/s, est. speed input: 21316.93 toks/s, output: 20.82 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 22.64it/s, est. speed input: 21090.08 toks/s, output: 20.60 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 21.09it/s, est. speed input: 20936.41 toks/s, output: 20.45 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 19.82it/s, est. speed input: 20795.09 toks/s, output: 20.31 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.82it/s, est. speed input: 20748.34 toks/s, output: 20.26 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 20.26it/s, est. speed input: 20748.34 toks/s, output: 20.26 toks/s]
[rank0]:[W126 00:14:02.830062250 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 70.0s

测试结果:
  Requests/s:   14.95
  Tokens/s:     15327.72
  Total Reqs:   128
  Elapsed:      8.56s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     15312.76

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:14:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:14:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=583014) WARNING 01-26 00:14:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=583014) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=583014) WARNING 01-26 00:14:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.75 requests/s, 22290.54 total tokens/s, 21.75 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 00:14:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:14:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:14:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:14:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:14:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:14:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:14:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:14:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:14:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:14:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:14:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:14:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:14:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:14:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:14:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:14:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:14:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=583014) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=583014) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=583014) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.24it/s]
(EngineCore_DP0 pid=583014) 
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=583014) [2026-01-26 00:14:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=583014) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:01,  1.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  2.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:01<00:00,  2.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]
(EngineCore_DP0 pid=583014) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.60it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▊         | 22/256 [00:00<00:01, 215.12it/s]
Adding requests:  19%|█▉        | 48/256 [00:00<00:00, 240.18it/s]
Adding requests:  29%|██▉       | 75/256 [00:00<00:00, 251.00it/s]
Adding requests:  39%|███▉      | 101/256 [00:00<00:00, 248.21it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 248.40it/s]
Adding requests:  59%|█████▉    | 152/256 [00:00<00:00, 248.41it/s]
Adding requests:  70%|██████▉   | 178/256 [00:00<00:00, 250.24it/s]
Adding requests:  80%|███████▉  | 204/256 [00:00<00:00, 251.86it/s]
Adding requests:  90%|█████████ | 231/256 [00:00<00:00, 256.47it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 248.52it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:00<00:00, 478.61it/s, est. speed input: 490219.12 toks/s, output: 478.65 toks/s]
Processed prompts:  41%|████      | 104/256 [00:02<00:03, 38.87it/s, est. speed input: 46739.37 toks/s, output: 45.64 toks/s]  
Processed prompts:  49%|████▉     | 126/256 [00:03<00:04, 32.26it/s, est. speed input: 39308.05 toks/s, output: 38.39 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:03<00:03, 30.28it/s, est. speed input: 37166.09 toks/s, output: 36.29 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:04<00:03, 27.98it/s, est. speed input: 35358.75 toks/s, output: 34.53 toks/s]
Processed prompts:  61%|██████    | 155/256 [00:04<00:03, 27.59it/s, est. speed input: 34801.98 toks/s, output: 33.99 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:04<00:03, 25.90it/s, est. speed input: 33898.73 toks/s, output: 33.10 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:05<00:03, 25.30it/s, est. speed input: 33477.83 toks/s, output: 32.69 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:05<00:03, 24.71it/s, est. speed input: 33091.37 toks/s, output: 32.32 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:05<00:03, 24.17it/s, est. speed input: 32735.06 toks/s, output: 31.97 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:05<00:03, 23.70it/s, est. speed input: 32402.13 toks/s, output: 31.64 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:05<00:03, 23.25it/s, est. speed input: 32083.06 toks/s, output: 31.33 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:05<00:03, 22.92it/s, est. speed input: 31787.76 toks/s, output: 31.04 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:06<00:03, 22.61it/s, est. speed input: 31502.01 toks/s, output: 30.76 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:06<00:02, 22.60it/s, est. speed input: 31266.48 toks/s, output: 30.53 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:06<00:02, 22.74it/s, est. speed input: 31062.84 toks/s, output: 30.33 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:06<00:02, 22.85it/s, est. speed input: 30869.93 toks/s, output: 30.15 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:06<00:02, 23.71it/s, est. speed input: 30776.99 toks/s, output: 30.06 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:06<00:02, 23.52it/s, est. speed input: 30599.38 toks/s, output: 29.88 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:07<00:01, 23.36it/s, est. speed input: 30427.20 toks/s, output: 29.71 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:07<00:01, 23.27it/s, est. speed input: 30265.25 toks/s, output: 29.56 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:07<00:01, 23.21it/s, est. speed input: 30111.81 toks/s, output: 29.41 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:07<00:01, 23.12it/s, est. speed input: 29959.47 toks/s, output: 29.26 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:07<00:01, 23.10it/s, est. speed input: 29818.60 toks/s, output: 29.12 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:08<00:01, 23.10it/s, est. speed input: 29685.72 toks/s, output: 28.99 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:08<00:00, 23.09it/s, est. speed input: 29556.55 toks/s, output: 28.86 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:08<00:00, 23.10it/s, est. speed input: 29435.36 toks/s, output: 28.75 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:08<00:00, 23.13it/s, est. speed input: 29320.11 toks/s, output: 28.63 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:08<00:00, 22.71it/s, est. speed input: 29172.34 toks/s, output: 28.49 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:08<00:00, 22.24it/s, est. speed input: 29014.27 toks/s, output: 28.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 23.01it/s, est. speed input: 28955.04 toks/s, output: 28.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 23.01it/s, est. speed input: 28955.04 toks/s, output: 28.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 28.28it/s, est. speed input: 28955.04 toks/s, output: 28.28 toks/s]
[rank0]:[W126 00:15:11.823855724 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 69.0s

测试结果:
  Requests/s:   21.75
  Tokens/s:     22290.54
  Total Reqs:   256
  Elapsed:      11.77s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     22268.80

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:15:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:15:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=584455) WARNING 01-26 00:15:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=584455) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=584455) WARNING 01-26 00:15:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.12 requests/s, 22673.40 total tokens/s, 22.12 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 00:15:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:15:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:15:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:15:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:15:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:15:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:15:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:15:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:15:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:15:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:15:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:15:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:15:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:15:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:15:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:15:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:15:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=584455) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=584455) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.09s/it]
(EngineCore_DP0 pid=584455) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.42s/it]
(EngineCore_DP0 pid=584455) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.37s/it]
(EngineCore_DP0 pid=584455) 
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=584455) [2026-01-26 00:15:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=584455) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  2.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:01<00:00,  3.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]
(EngineCore_DP0 pid=584455) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.75it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  9.05it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.84it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 21/512 [00:00<00:02, 203.99it/s]
Adding requests:   9%|▉         | 45/512 [00:00<00:02, 223.22it/s]
Adding requests:  14%|█▎        | 70/512 [00:00<00:01, 232.32it/s]
Adding requests:  18%|█▊        | 94/512 [00:00<00:01, 225.80it/s]
Adding requests:  23%|██▎       | 118/512 [00:00<00:01, 227.29it/s]
Adding requests:  28%|██▊       | 142/512 [00:00<00:01, 231.15it/s]
Adding requests:  33%|███▎      | 167/512 [00:00<00:01, 234.29it/s]
Adding requests:  38%|███▊      | 192/512 [00:00<00:01, 239.16it/s]
Adding requests:  42%|████▏     | 216/512 [00:00<00:01, 237.34it/s]
Adding requests:  47%|████▋     | 241/512 [00:01<00:01, 240.61it/s]
Adding requests:  52%|█████▏    | 266/512 [00:01<00:01, 238.78it/s]
Adding requests:  57%|█████▋    | 290/512 [00:01<00:00, 237.21it/s]
Adding requests:  62%|██████▏   | 317/512 [00:01<00:00, 245.23it/s]
Adding requests:  67%|██████▋   | 342/512 [00:01<00:00, 245.78it/s]
Adding requests:  72%|███████▏  | 368/512 [00:01<00:00, 248.61it/s]
Adding requests:  77%|███████▋  | 394/512 [00:01<00:00, 250.95it/s]
Adding requests:  82%|████████▏ | 421/512 [00:01<00:00, 256.02it/s]
Adding requests:  87%|████████▋ | 447/512 [00:01<00:00, 251.33it/s]
Adding requests:  93%|█████████▎| 474/512 [00:01<00:00, 255.43it/s]
Adding requests:  98%|█████████▊| 501/512 [00:02<00:00, 259.01it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 243.72it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:00<00:03, 143.09it/s, est. speed input: 146547.08 toks/s, output: 143.10 toks/s]
Processed prompts:  10%|▉         | 49/512 [00:00<00:08, 54.79it/s, est. speed input: 64375.06 toks/s, output: 62.87 toks/s]   
Processed prompts:  11%|█         | 57/512 [00:01<00:11, 41.08it/s, est. speed input: 51216.81 toks/s, output: 50.02 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:01<00:14, 31.90it/s, est. speed input: 43006.53 toks/s, output: 42.00 toks/s]
Processed prompts:  13%|█▎        | 67/512 [00:01<00:14, 29.83it/s, est. speed input: 40819.43 toks/s, output: 39.86 toks/s]
Processed prompts:  14%|█▍        | 71/512 [00:01<00:15, 28.06it/s, est. speed input: 39065.98 toks/s, output: 38.15 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:17, 25.58it/s, est. speed input: 37310.04 toks/s, output: 36.44 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:17, 25.18it/s, est. speed input: 36342.72 toks/s, output: 35.49 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:17, 24.86it/s, est. speed input: 35510.66 toks/s, output: 34.68 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:02<00:17, 24.63it/s, est. speed input: 34792.89 toks/s, output: 33.98 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:17, 24.50it/s, est. speed input: 34174.04 toks/s, output: 33.37 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:02<00:17, 24.38it/s, est. speed input: 33622.00 toks/s, output: 32.83 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:17, 24.27it/s, est. speed input: 33124.66 toks/s, output: 32.35 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:16, 24.22it/s, est. speed input: 32685.77 toks/s, output: 31.92 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:16, 24.17it/s, est. speed input: 32288.01 toks/s, output: 31.53 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:16, 24.11it/s, est. speed input: 31921.16 toks/s, output: 31.17 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:03<00:16, 24.08it/s, est. speed input: 31590.45 toks/s, output: 30.85 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:16, 24.06it/s, est. speed input: 31287.64 toks/s, output: 30.55 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:16, 24.03it/s, est. speed input: 31008.48 toks/s, output: 30.28 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:16, 24.03it/s, est. speed input: 30753.90 toks/s, output: 30.03 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:15, 23.91it/s, est. speed input: 30500.60 toks/s, output: 29.79 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:16, 23.36it/s, est. speed input: 30191.20 toks/s, output: 29.48 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:04<00:16, 22.98it/s, est. speed input: 29903.17 toks/s, output: 29.20 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:16, 22.72it/s, est. speed input: 29635.88 toks/s, output: 28.94 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:16, 22.55it/s, est. speed input: 29389.51 toks/s, output: 28.70 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:16, 22.42it/s, est. speed input: 29159.24 toks/s, output: 28.48 toks/s]
Processed prompts:  30%|███       | 154/512 [00:05<00:16, 22.33it/s, est. speed input: 28943.60 toks/s, output: 28.27 toks/s]
Processed prompts:  31%|███       | 158/512 [00:05<00:15, 22.28it/s, est. speed input: 28742.95 toks/s, output: 28.07 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:05<00:15, 22.24it/s, est. speed input: 28554.63 toks/s, output: 27.89 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:15, 22.23it/s, est. speed input: 28379.47 toks/s, output: 27.71 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:15, 22.22it/s, est. speed input: 28214.33 toks/s, output: 27.55 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:06<00:15, 22.20it/s, est. speed input: 28057.10 toks/s, output: 27.40 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:06<00:15, 22.18it/s, est. speed input: 27908.01 toks/s, output: 27.25 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:06<00:14, 22.16it/s, est. speed input: 27766.64 toks/s, output: 27.12 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:06<00:14, 22.14it/s, est. speed input: 27631.31 toks/s, output: 26.98 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:14, 22.14it/s, est. speed input: 27504.55 toks/s, output: 26.86 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:07<00:14, 22.13it/s, est. speed input: 27383.57 toks/s, output: 26.74 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:07<00:14, 22.13it/s, est. speed input: 27268.57 toks/s, output: 26.63 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:07<00:13, 23.41it/s, est. speed input: 27277.52 toks/s, output: 26.64 toks/s]
Processed prompts:  40%|████      | 206/512 [00:07<00:13, 23.02it/s, est. speed input: 27170.73 toks/s, output: 26.53 toks/s]
Processed prompts:  41%|████      | 210/512 [00:07<00:13, 22.75it/s, est. speed input: 27068.13 toks/s, output: 26.43 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:13, 22.56it/s, est. speed input: 26970.04 toks/s, output: 26.34 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:08<00:13, 22.44it/s, est. speed input: 26877.18 toks/s, output: 26.25 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:08<00:12, 22.33it/s, est. speed input: 26786.47 toks/s, output: 26.16 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:08<00:12, 22.26it/s, est. speed input: 26699.03 toks/s, output: 26.07 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:08<00:12, 22.20it/s, est. speed input: 26615.00 toks/s, output: 25.99 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:12, 22.20it/s, est. speed input: 26537.92 toks/s, output: 25.92 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:09<00:12, 22.20it/s, est. speed input: 26463.23 toks/s, output: 25.84 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:09<00:12, 22.21it/s, est. speed input: 26392.27 toks/s, output: 25.77 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:09<00:11, 22.20it/s, est. speed input: 26322.84 toks/s, output: 25.71 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:09<00:11, 22.17it/s, est. speed input: 26254.12 toks/s, output: 25.64 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:09<00:11, 22.66it/s, est. speed input: 26224.02 toks/s, output: 25.61 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:10<00:11, 23.03it/s, est. speed input: 26195.90 toks/s, output: 25.58 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:10<00:10, 23.30it/s, est. speed input: 26168.39 toks/s, output: 25.56 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:10<00:10, 23.50it/s, est. speed input: 26142.66 toks/s, output: 25.53 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:10<00:10, 23.61it/s, est. speed input: 26116.08 toks/s, output: 25.50 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:10<00:10, 23.71it/s, est. speed input: 26091.01 toks/s, output: 25.48 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:10<00:09, 23.78it/s, est. speed input: 26066.90 toks/s, output: 25.46 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:11<00:09, 23.83it/s, est. speed input: 26043.55 toks/s, output: 25.43 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:11<00:09, 23.87it/s, est. speed input: 26021.13 toks/s, output: 25.41 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:11<00:09, 23.88it/s, est. speed input: 25998.82 toks/s, output: 25.39 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:11<00:09, 23.90it/s, est. speed input: 25977.22 toks/s, output: 25.37 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:11<00:08, 23.91it/s, est. speed input: 25956.34 toks/s, output: 25.35 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:11<00:08, 23.92it/s, est. speed input: 25936.51 toks/s, output: 25.33 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:12<00:08, 23.93it/s, est. speed input: 25916.66 toks/s, output: 25.31 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:12<00:08, 23.94it/s, est. speed input: 25898.11 toks/s, output: 25.29 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:12<00:08, 23.76it/s, est. speed input: 25870.45 toks/s, output: 25.26 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:12<00:08, 23.23it/s, est. speed input: 25824.00 toks/s, output: 25.22 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:12<00:08, 22.88it/s, est. speed input: 25778.47 toks/s, output: 25.17 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:12<00:08, 22.62it/s, est. speed input: 25733.83 toks/s, output: 25.13 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:13<00:08, 22.46it/s, est. speed input: 25690.80 toks/s, output: 25.09 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:13<00:07, 22.35it/s, est. speed input: 25649.19 toks/s, output: 25.05 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:13<00:07, 22.26it/s, est. speed input: 25608.03 toks/s, output: 25.01 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:13<00:07, 22.21it/s, est. speed input: 25568.64 toks/s, output: 24.97 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:13<00:07, 22.16it/s, est. speed input: 25529.60 toks/s, output: 24.93 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:14<00:07, 22.13it/s, est. speed input: 25491.80 toks/s, output: 24.89 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:14<00:07, 22.12it/s, est. speed input: 25455.33 toks/s, output: 24.86 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:14<00:06, 22.11it/s, est. speed input: 25419.74 toks/s, output: 24.82 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:14<00:06, 22.10it/s, est. speed input: 25384.75 toks/s, output: 24.79 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:14<00:06, 22.09it/s, est. speed input: 25350.53 toks/s, output: 24.76 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:14<00:06, 22.09it/s, est. speed input: 25317.46 toks/s, output: 24.72 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:15<00:06, 22.09it/s, est. speed input: 25285.04 toks/s, output: 24.69 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:15<00:06, 22.09it/s, est. speed input: 25253.60 toks/s, output: 24.66 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:15<00:05, 22.09it/s, est. speed input: 25222.71 toks/s, output: 24.63 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:15<00:05, 22.08it/s, est. speed input: 25192.40 toks/s, output: 24.60 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:15<00:05, 22.09it/s, est. speed input: 25163.29 toks/s, output: 24.57 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:16<00:05, 22.10it/s, est. speed input: 25134.99 toks/s, output: 24.55 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:16<00:05, 22.08it/s, est. speed input: 25106.23 toks/s, output: 24.52 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:16<00:04, 22.07it/s, est. speed input: 25078.49 toks/s, output: 24.49 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:16<00:04, 22.08it/s, est. speed input: 25051.52 toks/s, output: 24.46 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:16<00:04, 22.06it/s, est. speed input: 25024.63 toks/s, output: 24.44 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:16<00:04, 22.05it/s, est. speed input: 24998.21 toks/s, output: 24.41 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:17<00:04, 22.05it/s, est. speed input: 24972.53 toks/s, output: 24.39 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:17<00:04, 22.05it/s, est. speed input: 24947.32 toks/s, output: 24.36 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:17<00:03, 22.05it/s, est. speed input: 24922.84 toks/s, output: 24.34 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:17<00:03, 22.32it/s, est. speed input: 24909.05 toks/s, output: 24.33 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:17<00:03, 22.76it/s, est. speed input: 24904.53 toks/s, output: 24.32 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:18<00:03, 23.08it/s, est. speed input: 24900.15 toks/s, output: 24.32 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:18<00:03, 23.30it/s, est. speed input: 24895.53 toks/s, output: 24.31 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:18<00:02, 23.46it/s, est. speed input: 24891.05 toks/s, output: 24.31 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:18<00:02, 23.59it/s, est. speed input: 24887.34 toks/s, output: 24.30 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:18<00:02, 23.68it/s, est. speed input: 24883.66 toks/s, output: 24.30 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:18<00:02, 23.73it/s, est. speed input: 24879.43 toks/s, output: 24.30 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:19<00:02, 23.77it/s, est. speed input: 24875.65 toks/s, output: 24.29 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:19<00:01, 23.81it/s, est. speed input: 24872.03 toks/s, output: 24.29 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:19<00:01, 23.80it/s, est. speed input: 24867.57 toks/s, output: 24.28 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:19<00:01, 23.82it/s, est. speed input: 24863.80 toks/s, output: 24.28 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:19<00:01, 23.82it/s, est. speed input: 24859.69 toks/s, output: 24.28 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:19<00:01, 23.83it/s, est. speed input: 24856.07 toks/s, output: 24.27 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:20<00:01, 23.83it/s, est. speed input: 24852.34 toks/s, output: 24.27 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:20<00:00, 23.82it/s, est. speed input: 24848.22 toks/s, output: 24.27 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:20<00:00, 23.82it/s, est. speed input: 24844.51 toks/s, output: 24.26 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:20<00:00, 23.35it/s, est. speed input: 24827.24 toks/s, output: 24.25 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:20<00:00, 22.93it/s, est. speed input: 24807.03 toks/s, output: 24.23 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:20<00:00, 22.65it/s, est. speed input: 24787.54 toks/s, output: 24.21 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:21<00:00, 24.16it/s, est. speed input: 24817.37 toks/s, output: 24.24 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 24.16it/s, est. speed input: 24914.43 toks/s, output: 24.33 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 24.33it/s, est. speed input: 24914.43 toks/s, output: 24.33 toks/s]
[rank0]:[W126 00:16:32.709532046 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 78.4s

测试结果:
  Requests/s:   22.12
  Tokens/s:     22673.40
  Total Reqs:   512
  Elapsed:      23.15s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     22651.28

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:16:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:16:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=586298) WARNING 01-26 00:16:59 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=586298) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=586298) WARNING 01-26 00:17:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.74 requests/s, 23310.75 total tokens/s, 22.74 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 00:16:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:16:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:16:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:16:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:16:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:16:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:16:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:16:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:16:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:16:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:16:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:16:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:16:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:16:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:16:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:16:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:16:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:00] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=586298) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=586298) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.04it/s]
(EngineCore_DP0 pid=586298) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.33s/it]
(EngineCore_DP0 pid=586298) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.28s/it]
(EngineCore_DP0 pid=586298) 
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=586298) [2026-01-26 00:17:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=586298) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:03,  1.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:01<00:01,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:01<00:01,  1.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  2.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  2.56it/s]
(EngineCore_DP0 pid=586298) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  5.53it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.91it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  7.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  7.19it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 217.85it/s]
Adding requests:   5%|▍         | 47/1024 [00:00<00:04, 235.15it/s]
Adding requests:   7%|▋         | 73/1024 [00:00<00:03, 241.99it/s]
Adding requests:  10%|▉         | 98/1024 [00:00<00:03, 239.09it/s]
Adding requests:  12%|█▏        | 122/1024 [00:00<00:03, 238.37it/s]
Adding requests:  14%|█▍        | 146/1024 [00:00<00:03, 233.32it/s]
Adding requests:  17%|█▋        | 171/1024 [00:00<00:03, 237.99it/s]
Adding requests:  19%|█▉        | 199/1024 [00:00<00:03, 249.19it/s]
Adding requests:  22%|██▏       | 226/1024 [00:00<00:03, 254.09it/s]
Adding requests:  25%|██▍       | 252/1024 [00:01<00:03, 251.18it/s]
Adding requests:  27%|██▋       | 278/1024 [00:01<00:02, 251.53it/s]
Adding requests:  30%|██▉       | 304/1024 [00:01<00:02, 248.28it/s]
Adding requests:  32%|███▏      | 329/1024 [00:01<00:02, 242.06it/s]
Adding requests:  35%|███▍      | 354/1024 [00:01<00:02, 240.39it/s]
Adding requests:  37%|███▋      | 379/1024 [00:01<00:02, 237.31it/s]
Adding requests:  39%|███▉      | 404/1024 [00:01<00:02, 240.81it/s]
Adding requests:  42%|████▏     | 429/1024 [00:01<00:02, 241.09it/s]
Adding requests:  44%|████▍     | 454/1024 [00:01<00:02, 234.09it/s]
Adding requests:  47%|████▋     | 479/1024 [00:01<00:02, 237.93it/s]
Adding requests:  88%|████████▊ | 900/1024 [00:02<00:00, 1370.14it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 391.72it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:00<00:02, 364.33it/s, est. speed input: 373126.43 toks/s, output: 364.35 toks/s]
Processed prompts:  12%|█▏        | 119/1024 [00:01<00:15, 59.67it/s, est. speed input: 73866.72 toks/s, output: 72.14 toks/s]  
Processed prompts:  13%|█▎        | 136/1024 [00:02<00:19, 45.63it/s, est. speed input: 58933.83 toks/s, output: 57.55 toks/s]
Processed prompts:  14%|█▍        | 147/1024 [00:03<00:25, 34.78it/s, est. speed input: 48926.78 toks/s, output: 47.78 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:03<00:27, 31.70it/s, est. speed input: 45939.88 toks/s, output: 44.86 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:03<00:28, 30.13it/s, est. speed input: 44097.12 toks/s, output: 43.06 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:04<00:29, 28.77it/s, est. speed input: 42547.33 toks/s, output: 41.55 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:04<00:30, 27.66it/s, est. speed input: 41234.96 toks/s, output: 40.27 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:04<00:31, 26.77it/s, est. speed input: 40098.83 toks/s, output: 39.16 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:05<00:31, 26.09it/s, est. speed input: 39109.42 toks/s, output: 38.19 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:05<00:31, 26.06it/s, est. speed input: 38393.98 toks/s, output: 37.49 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:31, 25.54it/s, est. speed input: 37612.47 toks/s, output: 36.73 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:06<00:32, 25.17it/s, est. speed input: 36918.43 toks/s, output: 36.05 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:06<00:32, 24.90it/s, est. speed input: 36293.89 toks/s, output: 35.44 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:32, 24.28it/s, est. speed input: 35626.47 toks/s, output: 34.79 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:07<00:33, 23.69it/s, est. speed input: 34984.47 toks/s, output: 34.16 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:07<00:33, 23.29it/s, est. speed input: 34406.27 toks/s, output: 33.60 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:33, 23.02it/s, est. speed input: 33879.86 toks/s, output: 33.09 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:08<00:33, 22.83it/s, est. speed input: 33399.88 toks/s, output: 32.62 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:08<00:33, 22.70it/s, est. speed input: 32960.83 toks/s, output: 32.19 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:32, 22.59it/s, est. speed input: 32553.35 toks/s, output: 31.79 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:09<00:32, 22.52it/s, est. speed input: 32179.48 toks/s, output: 31.43 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:09<00:32, 22.47it/s, est. speed input: 31833.35 toks/s, output: 31.09 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:31, 22.45it/s, est. speed input: 31513.23 toks/s, output: 30.77 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:10<00:31, 22.42it/s, est. speed input: 31214.02 toks/s, output: 30.48 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:10<00:31, 22.40it/s, est. speed input: 30933.71 toks/s, output: 30.21 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:11<00:31, 22.38it/s, est. speed input: 30671.18 toks/s, output: 29.95 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:11<00:30, 22.36it/s, est. speed input: 30425.04 toks/s, output: 29.71 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:11<00:30, 22.35it/s, est. speed input: 30193.99 toks/s, output: 29.49 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:12<00:29, 22.34it/s, est. speed input: 29976.03 toks/s, output: 29.27 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:12<00:29, 22.32it/s, est. speed input: 29769.98 toks/s, output: 29.07 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:12<00:28, 22.62it/s, est. speed input: 29612.99 toks/s, output: 28.92 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:13<00:28, 23.06it/s, est. speed input: 29489.98 toks/s, output: 28.80 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:13<00:27, 23.38it/s, est. speed input: 29373.38 toks/s, output: 28.68 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:13<00:26, 23.61it/s, est. speed input: 29262.06 toks/s, output: 28.58 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:14<00:26, 23.76it/s, est. speed input: 29155.20 toks/s, output: 28.47 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:14<00:25, 23.87it/s, est. speed input: 29053.35 toks/s, output: 28.37 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:14<00:25, 23.45it/s, est. speed input: 28909.52 toks/s, output: 28.23 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:15<00:25, 23.09it/s, est. speed input: 28765.65 toks/s, output: 28.09 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:15<00:25, 22.83it/s, est. speed input: 28627.31 toks/s, output: 27.96 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:15<00:25, 22.66it/s, est. speed input: 28495.21 toks/s, output: 27.83 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:16<00:25, 22.54it/s, est. speed input: 28369.60 toks/s, output: 27.70 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:16<00:25, 22.46it/s, est. speed input: 28249.20 toks/s, output: 27.59 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:16<00:24, 22.40it/s, est. speed input: 28133.30 toks/s, output: 27.47 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:17<00:24, 22.35it/s, est. speed input: 28022.39 toks/s, output: 27.37 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:17<00:24, 22.32it/s, est. speed input: 27915.75 toks/s, output: 27.26 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:18<00:23, 22.29it/s, est. speed input: 27812.95 toks/s, output: 27.16 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:18<00:23, 22.27it/s, est. speed input: 27714.05 toks/s, output: 27.06 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:18<00:23, 22.26it/s, est. speed input: 27619.40 toks/s, output: 26.97 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:19<00:22, 22.25it/s, est. speed input: 27528.04 toks/s, output: 26.88 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:19<00:22, 22.28it/s, est. speed input: 27442.58 toks/s, output: 26.80 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:19<00:21, 22.79it/s, est. speed input: 27396.04 toks/s, output: 26.75 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:20<00:20, 23.16it/s, est. speed input: 27350.67 toks/s, output: 26.71 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:20<00:20, 23.43it/s, est. speed input: 27307.18 toks/s, output: 26.67 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:20<00:19, 23.62it/s, est. speed input: 27264.97 toks/s, output: 26.63 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:21<00:19, 23.75it/s, est. speed input: 27223.55 toks/s, output: 26.59 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:21<00:19, 23.85it/s, est. speed input: 27183.84 toks/s, output: 26.55 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:21<00:18, 23.92it/s, est. speed input: 27145.21 toks/s, output: 26.51 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:22<00:18, 23.96it/s, est. speed input: 27107.64 toks/s, output: 26.47 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:22<00:17, 23.99it/s, est. speed input: 27071.23 toks/s, output: 26.44 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:22<00:17, 23.52it/s, est. speed input: 27008.01 toks/s, output: 26.37 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:23<00:17, 23.11it/s, est. speed input: 26941.72 toks/s, output: 26.31 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:23<00:17, 22.83it/s, est. speed input: 26877.37 toks/s, output: 26.25 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:23<00:17, 22.64it/s, est. speed input: 26815.31 toks/s, output: 26.19 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:24<00:17, 22.51it/s, est. speed input: 26755.01 toks/s, output: 26.13 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:24<00:17, 22.42it/s, est. speed input: 26695.97 toks/s, output: 26.07 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:24<00:16, 22.35it/s, est. speed input: 26638.95 toks/s, output: 26.01 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:25<00:16, 22.31it/s, est. speed input: 26583.50 toks/s, output: 25.96 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:25<00:16, 22.27it/s, est. speed input: 26529.43 toks/s, output: 25.91 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:26<00:15, 22.26it/s, est. speed input: 26477.54 toks/s, output: 25.86 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:26<00:15, 22.24it/s, est. speed input: 26426.43 toks/s, output: 25.81 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:26<00:15, 22.23it/s, est. speed input: 26376.97 toks/s, output: 25.76 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:27<00:14, 22.24it/s, est. speed input: 26329.19 toks/s, output: 25.71 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:27<00:14, 22.44it/s, est. speed input: 26293.12 toks/s, output: 25.68 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:27<00:13, 22.91it/s, est. speed input: 26273.43 toks/s, output: 25.66 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:28<00:12, 23.25it/s, est. speed input: 26254.43 toks/s, output: 25.64 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:28<00:12, 23.48it/s, est. speed input: 26235.55 toks/s, output: 25.62 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:28<00:12, 23.66it/s, est. speed input: 26217.45 toks/s, output: 25.60 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:29<00:11, 23.79it/s, est. speed input: 26199.73 toks/s, output: 25.59 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:29<00:11, 23.86it/s, est. speed input: 26181.94 toks/s, output: 25.57 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:29<00:10, 23.92it/s, est. speed input: 26164.66 toks/s, output: 25.55 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:30<00:10, 23.97it/s, est. speed input: 26147.98 toks/s, output: 25.54 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:30<00:03, 62.44it/s, est. speed input: 27514.44 toks/s, output: 26.87 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:30<00:03, 49.97it/s, est. speed input: 27470.83 toks/s, output: 26.83 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:31<00:04, 41.36it/s, est. speed input: 27422.78 toks/s, output: 26.78 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:31<00:05, 35.57it/s, est. speed input: 27376.00 toks/s, output: 26.73 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:31<00:05, 31.61it/s, est. speed input: 27330.08 toks/s, output: 26.69 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:32<00:05, 28.88it/s, est. speed input: 27284.92 toks/s, output: 26.65 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:32<00:05, 27.01it/s, est. speed input: 27241.43 toks/s, output: 26.60 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:32<00:05, 25.70it/s, est. speed input: 27198.30 toks/s, output: 26.56 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:33<00:05, 24.80it/s, est. speed input: 27156.54 toks/s, output: 26.52 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:33<00:05, 24.16it/s, est. speed input: 27115.41 toks/s, output: 26.48 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:33<00:05, 23.72it/s, est. speed input: 27075.09 toks/s, output: 26.44 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:34<00:05, 23.41it/s, est. speed input: 27035.60 toks/s, output: 26.40 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:34<00:04, 23.19it/s, est. speed input: 26996.89 toks/s, output: 26.36 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:35<00:04, 23.04it/s, est. speed input: 26958.85 toks/s, output: 26.33 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:35<00:04, 22.93it/s, est. speed input: 26921.64 toks/s, output: 26.29 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:35<00:03, 22.86it/s, est. speed input: 26885.37 toks/s, output: 26.26 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:36<00:03, 22.81it/s, est. speed input: 26849.77 toks/s, output: 26.22 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:36<00:03, 23.04it/s, est. speed input: 26824.70 toks/s, output: 26.20 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:36<00:02, 23.34it/s, est. speed input: 26804.93 toks/s, output: 26.18 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:37<00:02, 23.55it/s, est. speed input: 26785.63 toks/s, output: 26.16 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:37<00:01, 23.70it/s, est. speed input: 26766.47 toks/s, output: 26.14 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:37<00:01, 23.81it/s, est. speed input: 26747.78 toks/s, output: 26.12 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:38<00:01, 23.89it/s, est. speed input: 26729.51 toks/s, output: 26.10 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:38<00:00, 23.95it/s, est. speed input: 26711.72 toks/s, output: 26.09 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:38<00:00, 23.69it/s, est. speed input: 26684.34 toks/s, output: 26.06 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:39<00:00, 24.11it/s, est. speed input: 26676.88 toks/s, output: 26.05 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 24.11it/s, est. speed input: 26833.92 toks/s, output: 26.20 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 26.20it/s, est. speed input: 26833.92 toks/s, output: 26.20 toks/s]
[rank0]:[W126 00:18:16.750577827 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 106.0s

测试结果:
  Requests/s:   22.74
  Tokens/s:     23310.75
  Total Reqs:   1024
  Elapsed:      45.03s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     23288.01

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:18:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:18:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=588311) WARNING 01-26 00:18:52 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=588311) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=588311) WARNING 01-26 00:19:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 13.37 requests/s, 13702.22 total tokens/s, 13.37 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 00:18:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:18:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:18:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:18:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:18:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:18:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:18:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:18:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:18:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:18:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:18:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:18:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:18:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:18:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:18:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:18:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:18:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=588311) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=588311) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.01s/it]
(EngineCore_DP0 pid=588311) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.35s/it]
(EngineCore_DP0 pid=588311) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.30s/it]
(EngineCore_DP0 pid=588311) 
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=588311) [2026-01-26 00:18:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=588311) [rank0]:W0126 00:19:15.123000 588311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=588311) [rank0]:W0126 00:19:15.242000 588311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=588311) [rank0]:W0126 00:19:17.132000 588311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=588311) [rank0]:W0126 00:19:17.329000 588311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=588311) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  7.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  7.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  7.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  5.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  2.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  2.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.76it/s]
(EngineCore_DP0 pid=588311) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:01,  2.87it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.00it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  4.28it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  5.40it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  6.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.96it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/2048 [00:00<00:08, 229.49it/s]
Adding requests:   2%|▏         | 48/2048 [00:00<00:08, 239.41it/s]
Adding requests:   4%|▎         | 74/2048 [00:00<00:08, 245.86it/s]
Adding requests:   5%|▍         | 99/2048 [00:00<00:07, 246.84it/s]
Adding requests:   6%|▌         | 125/2048 [00:00<00:07, 250.87it/s]
Adding requests:   7%|▋         | 151/2048 [00:00<00:07, 245.58it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:07, 246.09it/s]
Adding requests:  10%|▉         | 201/2048 [00:00<00:07, 244.50it/s]
Adding requests:  11%|█         | 227/2048 [00:00<00:07, 246.38it/s]
Adding requests:  12%|█▏        | 252/2048 [00:01<00:07, 240.49it/s]
Adding requests:  14%|█▎        | 277/2048 [00:01<00:07, 238.24it/s]
Adding requests:  15%|█▍        | 301/2048 [00:01<00:07, 236.25it/s]
Adding requests:  16%|█▌        | 325/2048 [00:01<00:07, 237.08it/s]
Adding requests:  17%|█▋        | 350/2048 [00:01<00:07, 238.69it/s]
Adding requests:  18%|█▊        | 375/2048 [00:01<00:07, 238.48it/s]
Adding requests:  20%|█▉        | 400/2048 [00:01<00:06, 241.56it/s]
Adding requests:  21%|██        | 425/2048 [00:01<00:06, 243.72it/s]
Adding requests:  22%|██▏       | 450/2048 [00:01<00:06, 236.28it/s]
Adding requests:  23%|██▎       | 474/2048 [00:01<00:06, 234.09it/s]
Adding requests:  24%|██▍       | 499/2048 [00:02<00:06, 236.36it/s]
Adding requests:  26%|██▌       | 525/2048 [00:02<00:06, 242.55it/s]
Adding requests:  27%|██▋       | 550/2048 [00:02<00:06, 235.49it/s]
Adding requests:  28%|██▊       | 574/2048 [00:02<00:06, 235.91it/s]
Adding requests:  29%|██▉       | 598/2048 [00:02<00:06, 225.98it/s]
Adding requests:  30%|███       | 621/2048 [00:02<00:06, 226.44it/s]
Adding requests:  31%|███▏      | 644/2048 [00:02<00:06, 225.28it/s]
Adding requests:  33%|███▎      | 667/2048 [00:02<00:06, 223.36it/s]
Adding requests:  34%|███▎      | 691/2048 [00:02<00:05, 227.16it/s]
Adding requests:  35%|███▍      | 714/2048 [00:03<00:06, 221.13it/s]
Adding requests:  36%|███▌      | 737/2048 [00:03<00:06, 211.97it/s]
Adding requests:  37%|███▋      | 759/2048 [00:03<00:06, 211.08it/s]
Adding requests:  38%|███▊      | 782/2048 [00:03<00:05, 214.44it/s]
Adding requests:  39%|███▉      | 804/2048 [00:03<00:05, 214.81it/s]
Adding requests:  40%|████      | 828/2048 [00:03<00:05, 219.51it/s]
Adding requests:  42%|████▏     | 850/2048 [00:03<00:05, 212.59it/s]
Adding requests:  43%|████▎     | 873/2048 [00:03<00:05, 217.45it/s]
Adding requests:  44%|████▍     | 897/2048 [00:03<00:05, 222.16it/s]
Adding requests:  45%|████▍     | 920/2048 [00:03<00:05, 214.27it/s]
Adding requests:  46%|████▌     | 942/2048 [00:04<00:05, 214.05it/s]
Adding requests:  47%|████▋     | 964/2048 [00:04<00:05, 215.57it/s]
Adding requests:  48%|████▊     | 986/2048 [00:04<00:04, 214.02it/s]
Adding requests:  49%|████▉     | 1008/2048 [00:04<00:04, 210.86it/s]
Adding requests:  50%|█████     | 1032/2048 [00:04<00:04, 217.54it/s]
Adding requests:  51%|█████▏    | 1054/2048 [00:04<00:04, 218.13it/s]
Adding requests:  53%|█████▎    | 1077/2048 [00:04<00:04, 221.49it/s]
Adding requests:  54%|█████▎    | 1100/2048 [00:04<00:04, 221.94it/s]
Adding requests:  55%|█████▍    | 1125/2048 [00:04<00:04, 228.24it/s]
Adding requests:  56%|█████▌    | 1149/2048 [00:05<00:03, 230.01it/s]
Adding requests:  57%|█████▋    | 1173/2048 [00:05<00:03, 232.38it/s]
Adding requests:  58%|█████▊    | 1197/2048 [00:05<00:03, 226.49it/s]
Adding requests:  60%|█████▉    | 1221/2048 [00:05<00:03, 229.49it/s]
Adding requests:  61%|██████    | 1244/2048 [00:05<00:03, 224.02it/s]
Adding requests:  62%|██████▏   | 1267/2048 [00:05<00:03, 223.92it/s]
Adding requests:  63%|██████▎   | 1290/2048 [00:05<00:03, 220.82it/s]
Adding requests:  64%|██████▍   | 1315/2048 [00:05<00:03, 227.49it/s]
Adding requests:  65%|██████▌   | 1340/2048 [00:05<00:03, 232.42it/s]
Adding requests:  67%|██████▋   | 1366/2048 [00:05<00:02, 240.03it/s]
Adding requests:  68%|██████▊   | 1391/2048 [00:06<00:02, 238.34it/s]
Adding requests:  69%|██████▉   | 1415/2048 [00:06<00:02, 234.77it/s]
Adding requests:  70%|███████   | 1441/2048 [00:06<00:02, 240.50it/s]
Adding requests:  72%|███████▏  | 1466/2048 [00:06<00:02, 242.65it/s]
Adding requests:  73%|███████▎  | 1491/2048 [00:06<00:02, 244.30it/s]
Adding requests:  74%|███████▍  | 1516/2048 [00:06<00:02, 243.32it/s]
Adding requests:  75%|███████▌  | 1541/2048 [00:06<00:02, 243.16it/s]
Adding requests:  76%|███████▋  | 1566/2048 [00:06<00:02, 235.08it/s]
Adding requests:  78%|███████▊  | 1591/2048 [00:06<00:01, 236.68it/s]
Adding requests:  79%|███████▉  | 1615/2048 [00:07<00:01, 235.04it/s]
Adding requests:  80%|████████  | 1639/2048 [00:07<00:01, 227.42it/s]
Adding requests:  81%|████████  | 1662/2048 [00:07<00:01, 225.55it/s]
Adding requests:  82%|████████▏ | 1687/2048 [00:07<00:01, 230.43it/s]
Adding requests:  84%|████████▎ | 1712/2048 [00:07<00:01, 233.59it/s]
Adding requests:  85%|████████▍ | 1736/2048 [00:07<00:01, 235.41it/s]
Adding requests:  86%|████████▌ | 1764/2048 [00:07<00:01, 247.27it/s]
Adding requests:  87%|████████▋ | 1790/2048 [00:07<00:01, 250.59it/s]
Adding requests:  89%|████████▊ | 1816/2048 [00:07<00:00, 249.74it/s]
Adding requests:  90%|████████▉ | 1842/2048 [00:07<00:00, 251.99it/s]
Adding requests:  91%|█████████ | 1868/2048 [00:08<00:00, 253.91it/s]
Adding requests:  92%|█████████▏| 1894/2048 [00:08<00:00, 253.07it/s]
Adding requests:  94%|█████████▍| 1920/2048 [00:08<00:00, 248.25it/s]
Adding requests:  95%|█████████▌| 1946/2048 [00:08<00:00, 248.16it/s]
Adding requests:  96%|█████████▌| 1971/2048 [00:08<00:00, 247.01it/s]
Adding requests:  97%|█████████▋| 1996/2048 [00:08<00:00, 235.96it/s]
Adding requests:  99%|█████████▊| 2020/2048 [00:08<00:00, 224.64it/s]
Adding requests: 100%|█████████▉| 2043/2048 [00:08<00:00, 215.14it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 231.57it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:00<00:09, 211.66it/s, est. speed input: 216753.44 toks/s, output: 211.66 toks/s]
Processed prompts:   6%|▌         | 120/2048 [00:01<00:32, 58.50it/s, est. speed input: 72808.96 toks/s, output: 71.10 toks/s]  
Processed prompts:   6%|▋         | 130/2048 [00:02<01:00, 31.80it/s, est. speed input: 45713.35 toks/s, output: 44.64 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:03<00:53, 35.12it/s, est. speed input: 45195.54 toks/s, output: 44.14 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:04<01:12, 25.76it/s, est. speed input: 37231.00 toks/s, output: 36.36 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:06<01:26, 21.55it/s, est. speed input: 32926.99 toks/s, output: 32.16 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:07<01:36, 19.05it/s, est. speed input: 30017.65 toks/s, output: 29.31 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:08<01:45, 17.20it/s, est. speed input: 27731.19 toks/s, output: 27.08 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:09<01:54, 15.82it/s, est. speed input: 25893.23 toks/s, output: 25.29 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:10<01:59, 14.93it/s, est. speed input: 24471.37 toks/s, output: 23.90 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:12<02:03, 14.34it/s, est. speed input: 23340.60 toks/s, output: 22.79 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:13<02:06, 13.94it/s, est. speed input: 22418.28 toks/s, output: 21.89 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:14<02:04, 13.94it/s, est. speed input: 21767.20 toks/s, output: 21.26 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:15<02:03, 13.97it/s, est. speed input: 21227.06 toks/s, output: 20.73 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:16<02:04, 13.74it/s, est. speed input: 20670.11 toks/s, output: 20.19 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:17<02:05, 13.53it/s, est. speed input: 20172.45 toks/s, output: 19.70 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:19<02:05, 13.38it/s, est. speed input: 19737.72 toks/s, output: 19.28 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:20<02:05, 13.28it/s, est. speed input: 19354.44 toks/s, output: 18.90 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:21<02:03, 13.35it/s, est. speed input: 19052.14 toks/s, output: 18.61 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:22<02:00, 13.57it/s, est. speed input: 18824.05 toks/s, output: 18.38 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:23<01:57, 13.70it/s, est. speed input: 18608.90 toks/s, output: 18.17 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:25<01:58, 13.49it/s, est. speed input: 18351.88 toks/s, output: 17.92 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:26<01:58, 13.35it/s, est. speed input: 18118.63 toks/s, output: 17.69 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:27<01:58, 13.26it/s, est. speed input: 17906.29 toks/s, output: 17.49 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:28<01:57, 13.24it/s, est. speed input: 17722.48 toks/s, output: 17.31 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:29<01:53, 13.49it/s, est. speed input: 17598.69 toks/s, output: 17.19 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:31<01:50, 13.68it/s, est. speed input: 17484.04 toks/s, output: 17.07 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:32<01:49, 13.69it/s, est. speed input: 17359.41 toks/s, output: 16.95 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:33<01:50, 13.48it/s, est. speed input: 17211.71 toks/s, output: 16.81 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:34<01:14, 19.50it/s, est. speed input: 17773.25 toks/s, output: 17.36 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:35<01:22, 17.36it/s, est. speed input: 17620.20 toks/s, output: 17.21 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:36<01:29, 15.97it/s, est. speed input: 17476.30 toks/s, output: 17.07 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:37<01:31, 15.35it/s, est. speed input: 17377.51 toks/s, output: 16.97 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:38<01:32, 14.98it/s, est. speed input: 17292.38 toks/s, output: 16.89 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:40<01:33, 14.63it/s, est. speed input: 17201.98 toks/s, output: 16.80 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:41<01:36, 14.13it/s, est. speed input: 17087.10 toks/s, output: 16.69 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:42<01:37, 13.78it/s, est. speed input: 16978.78 toks/s, output: 16.58 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:43<01:37, 13.55it/s, est. speed input: 16876.55 toks/s, output: 16.48 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:45<01:37, 13.39it/s, est. speed input: 16780.00 toks/s, output: 16.39 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:46<01:36, 13.38it/s, est. speed input: 16699.53 toks/s, output: 16.31 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:47<01:34, 13.59it/s, est. speed input: 16645.72 toks/s, output: 16.26 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:48<01:28, 14.32it/s, est. speed input: 16648.20 toks/s, output: 16.26 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:49<01:29, 13.90it/s, est. speed input: 16565.91 toks/s, output: 16.18 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:50<01:30, 13.63it/s, est. speed input: 16487.68 toks/s, output: 16.10 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:52<01:30, 13.44it/s, est. speed input: 16413.19 toks/s, output: 16.03 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:53<01:29, 13.41it/s, est. speed input: 16351.56 toks/s, output: 15.97 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:54<01:26, 13.61it/s, est. speed input: 16311.76 toks/s, output: 15.93 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:55<01:24, 13.76it/s, est. speed input: 16273.59 toks/s, output: 15.89 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:56<01:24, 13.64it/s, est. speed input: 16218.76 toks/s, output: 15.84 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:57<01:24, 13.44it/s, est. speed input: 16157.51 toks/s, output: 15.78 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:59<01:23, 13.31it/s, est. speed input: 16098.74 toks/s, output: 15.72 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:00<01:23, 13.22it/s, est. speed input: 16042.43 toks/s, output: 15.67 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:01<01:21, 13.33it/s, est. speed input: 16001.49 toks/s, output: 15.63 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:02<01:18, 13.55it/s, est. speed input: 15973.19 toks/s, output: 15.60 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:03<01:16, 13.71it/s, est. speed input: 15945.95 toks/s, output: 15.57 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:05<01:16, 13.51it/s, est. speed input: 15897.69 toks/s, output: 15.53 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:05<00:51, 19.50it/s, est. speed input: 16203.92 toks/s, output: 15.82 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:07<00:57, 17.36it/s, est. speed input: 16151.36 toks/s, output: 15.77 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:08<01:01, 15.97it/s, est. speed input: 16100.55 toks/s, output: 15.72 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:09<01:02, 15.36it/s, est. speed input: 16070.25 toks/s, output: 15.69 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:10<01:02, 14.98it/s, est. speed input: 16044.02 toks/s, output: 15.67 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:11<01:02, 14.72it/s, est. speed input: 16018.69 toks/s, output: 15.64 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:12<01:03, 14.24it/s, est. speed input: 15976.68 toks/s, output: 15.60 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:14<01:04, 13.86it/s, est. speed input: 15932.75 toks/s, output: 15.56 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:15<01:04, 13.60it/s, est. speed input: 15890.29 toks/s, output: 15.52 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:16<01:04, 13.42it/s, est. speed input: 15849.13 toks/s, output: 15.48 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:17<01:03, 13.30it/s, est. speed input: 15809.28 toks/s, output: 15.44 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [01:19<01:01, 13.41it/s, est. speed input: 15783.02 toks/s, output: 15.41 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:20<01:00, 13.55it/s, est. speed input: 15760.41 toks/s, output: 15.39 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:21<00:59, 13.38it/s, est. speed input: 15723.65 toks/s, output: 15.36 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:22<00:58, 13.27it/s, est. speed input: 15687.93 toks/s, output: 15.32 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:23<00:58, 13.19it/s, est. speed input: 15653.33 toks/s, output: 15.29 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [01:25<00:57, 13.14it/s, est. speed input: 15619.69 toks/s, output: 15.25 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:26<00:54, 13.37it/s, est. speed input: 15602.04 toks/s, output: 15.24 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:27<00:52, 13.58it/s, est. speed input: 15586.83 toks/s, output: 15.22 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:28<00:51, 13.58it/s, est. speed input: 15564.66 toks/s, output: 15.20 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:29<00:51, 13.41it/s, est. speed input: 15533.98 toks/s, output: 15.17 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:31<00:50, 13.29it/s, est. speed input: 15504.17 toks/s, output: 15.14 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:32<00:49, 13.20it/s, est. speed input: 15475.15 toks/s, output: 15.11 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:33<00:48, 13.26it/s, est. speed input: 15452.40 toks/s, output: 15.09 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:34<00:46, 13.50it/s, est. speed input: 15440.37 toks/s, output: 15.08 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:35<00:44, 13.68it/s, est. speed input: 15428.52 toks/s, output: 15.07 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:36<00:27, 20.83it/s, est. speed input: 15672.81 toks/s, output: 15.31 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:37<00:30, 18.26it/s, est. speed input: 15647.40 toks/s, output: 15.28 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:38<00:32, 16.64it/s, est. speed input: 15622.60 toks/s, output: 15.26 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:39<00:33, 15.57it/s, est. speed input: 15598.46 toks/s, output: 15.23 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:41<00:34, 14.86it/s, est. speed input: 15574.74 toks/s, output: 15.21 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:42<00:34, 14.48it/s, est. speed input: 15555.89 toks/s, output: 15.19 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:43<00:33, 14.37it/s, est. speed input: 15543.61 toks/s, output: 15.18 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:44<00:32, 14.14it/s, est. speed input: 15525.56 toks/s, output: 15.16 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:45<00:32, 13.78it/s, est. speed input: 15499.97 toks/s, output: 15.14 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:46<00:30, 14.31it/s, est. speed input: 15505.93 toks/s, output: 15.14 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:48<00:29, 13.90it/s, est. speed input: 15481.07 toks/s, output: 15.12 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:49<00:29, 13.62it/s, est. speed input: 15456.79 toks/s, output: 15.09 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:50<00:28, 13.47it/s, est. speed input: 15434.76 toks/s, output: 15.07 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:51<00:26, 13.65it/s, est. speed input: 15424.56 toks/s, output: 15.06 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:52<00:25, 13.59it/s, est. speed input: 15406.99 toks/s, output: 15.05 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:54<00:24, 13.41it/s, est. speed input: 15384.54 toks/s, output: 15.02 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:55<00:23, 13.29it/s, est. speed input: 15362.66 toks/s, output: 15.00 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:56<00:22, 13.20it/s, est. speed input: 15341.11 toks/s, output: 14.98 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:57<00:21, 13.21it/s, est. speed input: 15322.67 toks/s, output: 14.96 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:58<00:20, 13.47it/s, est. speed input: 15314.21 toks/s, output: 14.96 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:00<00:18, 13.65it/s, est. speed input: 15305.94 toks/s, output: 14.95 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:01<00:17, 13.49it/s, est. speed input: 15287.36 toks/s, output: 14.93 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:02<00:16, 13.34it/s, est. speed input: 15267.64 toks/s, output: 14.91 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [02:03<00:15, 13.24it/s, est. speed input: 15248.36 toks/s, output: 14.89 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:04<00:14, 13.17it/s, est. speed input: 15229.41 toks/s, output: 14.87 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:06<00:13, 13.36it/s, est. speed input: 15219.45 toks/s, output: 14.86 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [02:06<00:07, 20.13it/s, est. speed input: 15400.07 toks/s, output: 15.04 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [02:07<00:06, 18.20it/s, est. speed input: 15391.51 toks/s, output: 15.03 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:09<00:06, 16.60it/s, est. speed input: 15375.03 toks/s, output: 15.01 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:10<00:06, 15.44it/s, est. speed input: 15355.64 toks/s, output: 15.00 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:11<00:05, 14.67it/s, est. speed input: 15336.60 toks/s, output: 14.98 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [02:12<00:04, 14.16it/s, est. speed input: 15318.02 toks/s, output: 14.96 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:13<00:03, 13.91it/s, est. speed input: 15303.26 toks/s, output: 14.94 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:15<00:02, 13.97it/s, est. speed input: 15295.99 toks/s, output: 14.94 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:16<00:00, 14.80it/s, est. speed input: 15312.31 toks/s, output: 14.95 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:16<00:00, 14.80it/s, est. speed input: 15417.65 toks/s, output: 15.06 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:16<00:00, 15.06it/s, est. speed input: 15417.65 toks/s, output: 15.06 toks/s]
[rank0]:[W126 00:21:52.689812036 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 216.6s

测试结果:
  Requests/s:   13.37
  Tokens/s:     13702.22
  Total Reqs:   2048
  Elapsed:      153.20s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     13688.85

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:22:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:22:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=591795) WARNING 01-26 00:22:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=591795) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591795) WARNING 01-26 00:22:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.56 requests/s, 5694.31 total tokens/s, 5.56 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 00:22:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:22:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:22:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:22:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:22:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:22:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:22:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:22:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:22:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:22:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:22:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:22:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:22:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:22:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:22:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:22:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:22:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=591795) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=591795) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.07s/it]
(EngineCore_DP0 pid=591795) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.33s/it]
(EngineCore_DP0 pid=591795) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.29s/it]
(EngineCore_DP0 pid=591795) 
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=591795) [2026-01-26 00:22:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=591795) [rank0]:W0126 00:23:07.007000 591795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=591795) [rank0]:W0126 00:23:07.124000 591795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=591795) [rank0]:W0126 00:23:09.221000 591795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=591795) [rank0]:W0126 00:23:09.410000 591795 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=591795) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 35.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00, 11.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:00<00:00, 10.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 11.18it/s]
(EngineCore_DP0 pid=591795) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.36it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.03it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  6.98it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  7.43it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  6.12it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  3.60it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.38it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  5.07it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/4096 [00:00<00:17, 229.60it/s]
Adding requests:   1%|          | 48/4096 [00:00<00:17, 235.25it/s]
Adding requests:   2%|▏         | 73/4096 [00:00<00:16, 241.25it/s]
Adding requests:   2%|▏         | 98/4096 [00:00<00:16, 239.01it/s]
Adding requests:   3%|▎         | 123/4096 [00:00<00:16, 242.72it/s]
Adding requests:   4%|▎         | 148/4096 [00:00<00:16, 243.75it/s]
Adding requests:   4%|▍         | 175/4096 [00:00<00:15, 250.46it/s]
Adding requests:   5%|▍         | 202/4096 [00:00<00:15, 255.69it/s]
Adding requests:   6%|▌         | 229/4096 [00:00<00:14, 259.11it/s]
Adding requests:   6%|▌         | 255/4096 [00:01<00:15, 255.89it/s]
Adding requests:   7%|▋         | 282/4096 [00:01<00:14, 256.68it/s]
Adding requests:   8%|▊         | 308/4096 [00:01<00:14, 256.81it/s]
Adding requests:   8%|▊         | 334/4096 [00:01<00:14, 256.47it/s]
Adding requests:   9%|▉         | 360/4096 [00:01<00:15, 234.73it/s]
Adding requests:   9%|▉         | 384/4096 [00:01<00:16, 229.95it/s]
Adding requests:  10%|▉         | 409/4096 [00:01<00:15, 235.48it/s]
Adding requests:  11%|█         | 433/4096 [00:01<00:15, 235.14it/s]
Adding requests:  11%|█         | 457/4096 [00:01<00:17, 213.31it/s]
Adding requests:  12%|█▏        | 482/4096 [00:02<00:16, 221.23it/s]
Adding requests:  12%|█▏        | 507/4096 [00:02<00:15, 228.65it/s]
Adding requests:  13%|█▎        | 533/4096 [00:02<00:15, 234.23it/s]
Adding requests:  14%|█▎        | 557/4096 [00:02<00:15, 221.50it/s]
Adding requests:  14%|█▍        | 581/4096 [00:02<00:15, 225.40it/s]
Adding requests:  15%|█▍        | 604/4096 [00:02<00:15, 226.42it/s]
Adding requests:  15%|█▌        | 628/4096 [00:02<00:15, 229.67it/s]
Adding requests:  16%|█▌        | 652/4096 [00:02<00:16, 214.96it/s]
Adding requests:  17%|█▋        | 677/4096 [00:02<00:15, 223.67it/s]
Adding requests:  17%|█▋        | 702/4096 [00:02<00:14, 230.56it/s]
Adding requests:  18%|█▊        | 726/4096 [00:03<00:14, 224.97it/s]
Adding requests:  18%|█▊        | 749/4096 [00:03<00:15, 214.91it/s]
Adding requests:  19%|█▉        | 772/4096 [00:03<00:15, 218.56it/s]
Adding requests:  19%|█▉        | 796/4096 [00:03<00:14, 222.49it/s]
Adding requests:  20%|█▉        | 819/4096 [00:03<00:15, 216.69it/s]
Adding requests:  21%|██        | 841/4096 [00:03<00:15, 212.72it/s]
Adding requests:  21%|██        | 865/4096 [00:03<00:14, 219.86it/s]
Adding requests:  22%|██▏       | 890/4096 [00:03<00:14, 227.78it/s]
Adding requests:  22%|██▏       | 913/4096 [00:03<00:14, 221.66it/s]
Adding requests:  23%|██▎       | 936/4096 [00:04<00:15, 208.95it/s]
Adding requests:  23%|██▎       | 961/4096 [00:04<00:14, 219.54it/s]
Adding requests:  24%|██▍       | 985/4096 [00:04<00:13, 222.96it/s]
Adding requests:  25%|██▍       | 1008/4096 [00:04<00:14, 209.85it/s]
Adding requests:  25%|██▌       | 1030/4096 [00:04<00:14, 207.16it/s]
Adding requests:  26%|██▌       | 1053/4096 [00:04<00:14, 213.24it/s]
Adding requests:  26%|██▋       | 1077/4096 [00:04<00:13, 219.36it/s]
Adding requests:  27%|██▋       | 1100/4096 [00:04<00:14, 208.58it/s]
Adding requests:  27%|██▋       | 1122/4096 [00:04<00:14, 202.80it/s]
Adding requests:  28%|██▊       | 1147/4096 [00:05<00:13, 213.67it/s]
Adding requests:  29%|██▊       | 1169/4096 [00:05<00:13, 214.94it/s]
Adding requests:  29%|██▉       | 1191/4096 [00:05<00:13, 208.87it/s]
Adding requests:  30%|██▉       | 1214/4096 [00:05<00:13, 213.85it/s]
Adding requests:  30%|███       | 1238/4096 [00:05<00:12, 221.16it/s]
Adding requests:  31%|███       | 1262/4096 [00:05<00:12, 223.71it/s]
Adding requests:  31%|███▏      | 1285/4096 [00:05<00:13, 208.85it/s]
Adding requests:  32%|███▏      | 1307/4096 [00:05<00:13, 210.93it/s]
Adding requests:  32%|███▏      | 1330/4096 [00:05<00:12, 215.82it/s]
Adding requests:  33%|███▎      | 1354/4096 [00:06<00:12, 221.04it/s]
Adding requests:  34%|███▎      | 1377/4096 [00:06<00:12, 210.98it/s]
Adding requests:  34%|███▍      | 1400/4096 [00:06<00:12, 214.70it/s]
Adding requests:  35%|███▍      | 1424/4096 [00:06<00:12, 219.47it/s]
Adding requests:  35%|███▌      | 1448/4096 [00:06<00:11, 223.67it/s]
Adding requests:  36%|███▌      | 1471/4096 [00:06<00:12, 213.25it/s]
Adding requests:  37%|███▋      | 1496/4096 [00:06<00:11, 222.32it/s]
Adding requests:  37%|███▋      | 1520/4096 [00:06<00:11, 226.06it/s]
Adding requests:  38%|███▊      | 1543/4096 [00:06<00:11, 225.56it/s]
Adding requests:  38%|███▊      | 1566/4096 [00:07<00:12, 206.15it/s]
Adding requests:  39%|███▉      | 1589/4096 [00:07<00:11, 211.90it/s]
Adding requests:  39%|███▉      | 1613/4096 [00:07<00:11, 216.66it/s]
Adding requests:  40%|███▉      | 1635/4096 [00:07<00:11, 209.06it/s]
Adding requests:  40%|████      | 1657/4096 [00:07<00:12, 203.10it/s]
Adding requests:  41%|████      | 1682/4096 [00:07<00:11, 216.01it/s]
Adding requests:  42%|████▏     | 1709/4096 [00:07<00:10, 229.28it/s]
Adding requests:  42%|████▏     | 1733/4096 [00:07<00:10, 222.19it/s]
Adding requests:  43%|████▎     | 1757/4096 [00:07<00:10, 225.02it/s]
Adding requests:  44%|████▎     | 1783/4096 [00:07<00:09, 234.45it/s]
Adding requests:  44%|████▍     | 1808/4096 [00:08<00:09, 236.67it/s]
Adding requests:  45%|████▍     | 1832/4096 [00:08<00:09, 228.62it/s]
Adding requests:  45%|████▌     | 1857/4096 [00:08<00:09, 234.47it/s]
Adding requests:  46%|████▌     | 1883/4096 [00:08<00:09, 240.12it/s]
Adding requests:  47%|████▋     | 1908/4096 [00:08<00:09, 233.48it/s]
Adding requests:  47%|████▋     | 1932/4096 [00:08<00:09, 230.55it/s]
Adding requests:  48%|████▊     | 1959/4096 [00:08<00:08, 240.62it/s]
Adding requests:  48%|████▊     | 1984/4096 [00:08<00:08, 242.57it/s]
Adding requests:  49%|████▉     | 2009/4096 [00:08<00:09, 229.64it/s]
Adding requests:  50%|████▉     | 2033/4096 [00:09<00:09, 227.05it/s]
Adding requests:  50%|█████     | 2060/4096 [00:09<00:08, 236.22it/s]
Adding requests:  51%|█████     | 2084/4096 [00:09<00:08, 236.14it/s]
Adding requests:  51%|█████▏    | 2108/4096 [00:09<00:08, 232.06it/s]
Adding requests:  52%|█████▏    | 2132/4096 [00:09<00:08, 233.08it/s]
Adding requests:  53%|█████▎    | 2156/4096 [00:09<00:08, 234.92it/s]
Adding requests:  53%|█████▎    | 2180/4096 [00:09<00:08, 226.08it/s]
Adding requests:  54%|█████▍    | 2203/4096 [00:09<00:09, 208.95it/s]
Adding requests:  54%|█████▍    | 2226/4096 [00:09<00:08, 213.49it/s]
Adding requests:  55%|█████▍    | 2249/4096 [00:10<00:08, 217.96it/s]
Adding requests:  55%|█████▌    | 2272/4096 [00:10<00:08, 220.64it/s]
Adding requests:  56%|█████▌    | 2295/4096 [00:10<00:08, 214.13it/s]
Adding requests:  57%|█████▋    | 2319/4096 [00:10<00:08, 219.05it/s]
Adding requests:  57%|█████▋    | 2342/4096 [00:10<00:07, 220.04it/s]
Adding requests:  58%|█████▊    | 2365/4096 [00:10<00:07, 216.91it/s]
Adding requests:  58%|█████▊    | 2387/4096 [00:10<00:07, 213.74it/s]
Adding requests:  59%|█████▉    | 2411/4096 [00:10<00:07, 219.20it/s]
Adding requests:  59%|█████▉    | 2436/4096 [00:10<00:07, 225.53it/s]
Adding requests:  60%|██████    | 2459/4096 [00:10<00:07, 221.64it/s]
Adding requests:  61%|██████    | 2482/4096 [00:11<00:07, 212.37it/s]
Adding requests:  61%|██████    | 2508/4096 [00:11<00:07, 223.14it/s]
Adding requests:  62%|██████▏   | 2533/4096 [00:11<00:06, 229.38it/s]
Adding requests:  62%|██████▏   | 2557/4096 [00:11<00:06, 227.30it/s]
Adding requests:  63%|██████▎   | 2580/4096 [00:11<00:06, 222.93it/s]
Adding requests:  64%|██████▎   | 2605/4096 [00:11<00:06, 228.85it/s]
Adding requests:  64%|██████▍   | 2628/4096 [00:11<00:06, 227.98it/s]
Adding requests:  65%|██████▍   | 2651/4096 [00:11<00:06, 216.24it/s]
Adding requests:  65%|██████▌   | 2673/4096 [00:11<00:06, 208.33it/s]
Adding requests:  66%|██████▌   | 2696/4096 [00:12<00:06, 211.38it/s]
Adding requests:  66%|██████▋   | 2720/4096 [00:12<00:06, 218.93it/s]
Adding requests:  67%|██████▋   | 2743/4096 [00:12<00:06, 216.95it/s]
Adding requests:  68%|██████▊   | 2766/4096 [00:12<00:06, 220.33it/s]
Adding requests:  68%|██████▊   | 2792/4096 [00:12<00:05, 231.33it/s]
Adding requests:  69%|██████▉   | 2818/4096 [00:12<00:05, 238.49it/s]
Adding requests:  69%|██████▉   | 2842/4096 [00:12<00:05, 230.51it/s]
Adding requests:  70%|██████▉   | 2866/4096 [00:12<00:05, 223.92it/s]
Adding requests:  71%|███████   | 2890/4096 [00:12<00:05, 226.90it/s]
Adding requests:  71%|███████   | 2915/4096 [00:12<00:05, 231.09it/s]
Adding requests:  72%|███████▏  | 2939/4096 [00:13<00:05, 224.56it/s]
Adding requests:  72%|███████▏  | 2962/4096 [00:13<00:05, 219.52it/s]
Adding requests:  73%|███████▎  | 2986/4096 [00:13<00:04, 222.61it/s]
Adding requests:  74%|███████▎  | 3012/4096 [00:13<00:04, 231.35it/s]
Adding requests:  74%|███████▍  | 3036/4096 [00:13<00:04, 223.74it/s]
Adding requests:  75%|███████▍  | 3059/4096 [00:13<00:04, 219.18it/s]
Adding requests:  75%|███████▌  | 3084/4096 [00:13<00:04, 227.06it/s]
Adding requests:  76%|███████▌  | 3110/4096 [00:13<00:04, 233.49it/s]
Adding requests:  77%|███████▋  | 3134/4096 [00:13<00:04, 226.80it/s]
Adding requests:  77%|███████▋  | 3157/4096 [00:14<00:04, 220.28it/s]
Adding requests:  78%|███████▊  | 3180/4096 [00:14<00:04, 220.15it/s]
Adding requests:  78%|███████▊  | 3205/4096 [00:14<00:03, 228.34it/s]
Adding requests:  79%|███████▉  | 3228/4096 [00:14<00:03, 217.03it/s]
Adding requests:  79%|███████▉  | 3250/4096 [00:14<00:03, 215.79it/s]
Adding requests:  80%|███████▉  | 3272/4096 [00:14<00:03, 216.06it/s]
Adding requests:  80%|████████  | 3294/4096 [00:14<00:03, 216.10it/s]
Adding requests:  81%|████████  | 3316/4096 [00:14<00:03, 208.36it/s]
Adding requests:  82%|████████▏ | 3340/4096 [00:14<00:03, 215.52it/s]
Adding requests:  82%|████████▏ | 3366/4096 [00:15<00:03, 226.22it/s]
Adding requests:  83%|████████▎ | 3391/4096 [00:15<00:03, 233.00it/s]
Adding requests:  83%|████████▎ | 3415/4096 [00:15<00:03, 223.23it/s]
Adding requests:  84%|████████▍ | 3441/4096 [00:15<00:02, 232.47it/s]
Adding requests:  85%|████████▍ | 3469/4096 [00:15<00:02, 245.30it/s]
Adding requests:  85%|████████▌ | 3494/4096 [00:15<00:02, 238.00it/s]
Adding requests:  86%|████████▌ | 3520/4096 [00:15<00:02, 241.67it/s]
Adding requests:  87%|████████▋ | 3549/4096 [00:15<00:02, 254.47it/s]
Adding requests:  87%|████████▋ | 3577/4096 [00:15<00:01, 260.65it/s]
Adding requests:  88%|████████▊ | 3604/4096 [00:15<00:02, 245.90it/s]
Adding requests:  89%|████████▊ | 3629/4096 [00:16<00:01, 246.11it/s]
Adding requests:  89%|████████▉ | 3654/4096 [00:16<00:01, 246.90it/s]
Adding requests:  90%|████████▉ | 3679/4096 [00:16<00:01, 240.69it/s]
Adding requests:  90%|█████████ | 3704/4096 [00:16<00:01, 227.67it/s]
Adding requests:  91%|█████████ | 3727/4096 [00:16<00:01, 224.49it/s]
Adding requests:  92%|█████████▏| 3752/4096 [00:16<00:01, 230.23it/s]
Adding requests:  92%|█████████▏| 3776/4096 [00:16<00:01, 220.60it/s]
Adding requests:  93%|█████████▎| 3799/4096 [00:16<00:01, 214.18it/s]
Adding requests:  93%|█████████▎| 3823/4096 [00:16<00:01, 220.63it/s]
Adding requests:  94%|█████████▍| 3848/4096 [00:17<00:01, 225.88it/s]
Adding requests:  95%|█████████▍| 3871/4096 [00:17<00:01, 220.60it/s]
Adding requests:  95%|█████████▌| 3896/4096 [00:17<00:00, 227.07it/s]
Adding requests:  96%|█████████▌| 3920/4096 [00:17<00:00, 230.49it/s]
Adding requests:  96%|█████████▋| 3944/4096 [00:17<00:00, 225.17it/s]
Adding requests:  97%|█████████▋| 3967/4096 [00:17<00:00, 215.07it/s]
Adding requests:  97%|█████████▋| 3990/4096 [00:17<00:00, 218.18it/s]
Adding requests:  98%|█████████▊| 4013/4096 [00:17<00:00, 220.39it/s]
Adding requests:  99%|█████████▊| 4036/4096 [00:17<00:00, 209.34it/s]
Adding requests:  99%|█████████▉| 4058/4096 [00:18<00:00, 201.03it/s]
Adding requests: 100%|█████████▉| 4080/4096 [00:18<00:00, 203.76it/s]
Adding requests: 100%|██████████| 4096/4096 [00:18<00:00, 224.49it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 66/4096 [00:00<00:23, 168.94it/s, est. speed input: 173005.85 toks/s, output: 168.94 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:06<05:05, 13.07it/s, est. speed input: 16451.70 toks/s, output: 16.07 toks/s]   
Processed prompts:   3%|▎         | 130/4096 [00:10<06:22, 10.36it/s, est. speed input: 12946.32 toks/s, output: 12.64 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:15<08:09,  8.04it/s, est. speed input: 10397.78 toks/s, output: 10.15 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:21<09:22,  6.94it/s, est. speed input: 9093.06 toks/s, output: 8.88 toks/s]  
Processed prompts:   6%|▌         | 226/4096 [00:27<10:03,  6.41it/s, est. speed input: 8370.07 toks/s, output: 8.17 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:33<10:24,  6.14it/s, est. speed input: 7926.34 toks/s, output: 7.74 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:39<10:37,  5.97it/s, est. speed input: 7610.29 toks/s, output: 7.43 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:43<09:50,  6.39it/s, est. speed input: 7626.15 toks/s, output: 7.45 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:48<10:06,  6.17it/s, est. speed input: 7421.72 toks/s, output: 7.25 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:54<10:25,  5.93it/s, est. speed input: 7225.43 toks/s, output: 7.06 toks/s]
Processed prompts:  10%|█         | 418/4096 [01:00<10:36,  5.78it/s, est. speed input: 7066.76 toks/s, output: 6.90 toks/s]
Processed prompts:  11%|█         | 450/4096 [01:06<10:36,  5.73it/s, est. speed input: 6954.41 toks/s, output: 6.79 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:10<09:33,  6.31it/s, est. speed input: 7035.32 toks/s, output: 6.87 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:15<09:52,  6.04it/s, est. speed input: 6928.43 toks/s, output: 6.77 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:21<10:01,  5.91it/s, est. speed input: 6845.81 toks/s, output: 6.69 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:27<10:05,  5.81it/s, est. speed input: 6773.22 toks/s, output: 6.61 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:33<10:11,  5.70it/s, est. speed input: 6698.13 toks/s, output: 6.54 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:38<10:09,  5.66it/s, est. speed input: 6641.41 toks/s, output: 6.49 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:42<09:10,  6.21it/s, est. speed input: 6702.84 toks/s, output: 6.55 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:48<09:28,  5.96it/s, est. speed input: 6642.42 toks/s, output: 6.49 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:54<09:34,  5.85it/s, est. speed input: 6596.92 toks/s, output: 6.44 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [02:00<09:29,  5.84it/s, est. speed input: 6568.28 toks/s, output: 6.41 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [02:05<09:35,  5.73it/s, est. speed input: 6523.67 toks/s, output: 6.37 toks/s]
Processed prompts:  20%|██        | 834/4096 [02:11<09:35,  5.67it/s, est. speed input: 6486.74 toks/s, output: 6.33 toks/s]
Processed prompts:  21%|██        | 866/4096 [02:15<08:44,  6.16it/s, est. speed input: 6529.85 toks/s, output: 6.38 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:21<09:00,  5.92it/s, est. speed input: 6489.15 toks/s, output: 6.34 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:27<09:04,  5.81it/s, est. speed input: 6458.47 toks/s, output: 6.31 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:33<09:05,  5.75it/s, est. speed input: 6431.90 toks/s, output: 6.28 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:38<09:05,  5.69it/s, est. speed input: 6405.32 toks/s, output: 6.26 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:43<08:17,  6.17it/s, est. speed input: 6442.84 toks/s, output: 6.29 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [02:48<08:27,  5.99it/s, est. speed input: 6419.02 toks/s, output: 6.27 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [02:54<08:35,  5.83it/s, est. speed input: 6391.80 toks/s, output: 6.24 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [03:00<08:39,  5.73it/s, est. speed input: 6367.52 toks/s, output: 6.22 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [03:06<08:36,  5.70it/s, est. speed input: 6349.06 toks/s, output: 6.20 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [03:11<08:31,  5.69it/s, est. speed input: 6332.81 toks/s, output: 6.18 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [03:16<07:49,  6.13it/s, est. speed input: 6362.17 toks/s, output: 6.21 toks/s]
Processed prompts:  31%|███       | 1250/4096 [03:21<07:56,  5.97it/s, est. speed input: 6345.26 toks/s, output: 6.20 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:27<08:03,  5.83it/s, est. speed input: 6325.62 toks/s, output: 6.18 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:33<08:07,  5.71it/s, est. speed input: 6305.51 toks/s, output: 6.16 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:39<08:03,  5.68it/s, est. speed input: 6291.21 toks/s, output: 6.14 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:43<07:16,  6.22it/s, est. speed input: 6325.14 toks/s, output: 6.18 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [03:48<07:30,  5.96it/s, est. speed input: 6305.48 toks/s, output: 6.16 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [03:54<07:32,  5.87it/s, est. speed input: 6293.23 toks/s, output: 6.15 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [04:00<07:34,  5.76it/s, est. speed input: 6278.13 toks/s, output: 6.13 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [04:06<07:36,  5.67it/s, est. speed input: 6261.83 toks/s, output: 6.12 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [04:12<07:33,  5.64it/s, est. speed input: 6248.86 toks/s, output: 6.10 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [04:15<06:44,  6.24it/s, est. speed input: 6283.16 toks/s, output: 6.14 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [04:21<06:52,  6.05it/s, est. speed input: 6272.32 toks/s, output: 6.13 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [04:27<06:56,  5.91it/s, est. speed input: 6261.05 toks/s, output: 6.11 toks/s]
Processed prompts:  41%|████      | 1666/4096 [04:32<06:57,  5.82it/s, est. speed input: 6250.27 toks/s, output: 6.10 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:38<06:59,  5.72it/s, est. speed input: 6237.14 toks/s, output: 6.09 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [04:44<06:58,  5.66it/s, est. speed input: 6225.46 toks/s, output: 6.08 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [04:48<06:14,  6.23it/s, est. speed input: 6254.39 toks/s, output: 6.11 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [04:54<06:25,  5.96it/s, est. speed input: 6240.34 toks/s, output: 6.09 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [05:00<06:28,  5.84it/s, est. speed input: 6230.05 toks/s, output: 6.08 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [05:05<06:27,  5.77it/s, est. speed input: 6220.93 toks/s, output: 6.08 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [05:11<06:26,  5.70it/s, est. speed input: 6211.05 toks/s, output: 6.07 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [05:15<05:53,  6.14it/s, est. speed input: 6230.89 toks/s, output: 6.08 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [05:21<05:58,  5.97it/s, est. speed input: 6222.05 toks/s, output: 6.08 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [05:27<06:02,  5.82it/s, est. speed input: 6211.32 toks/s, output: 6.07 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [05:33<06:03,  5.72it/s, est. speed input: 6201.16 toks/s, output: 6.06 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [05:38<05:59,  5.69it/s, est. speed input: 6193.52 toks/s, output: 6.05 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [05:44<05:55,  5.67it/s, est. speed input: 6186.65 toks/s, output: 6.04 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [05:48<05:23,  6.13it/s, est. speed input: 6205.49 toks/s, output: 6.06 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [05:54<05:27,  5.96it/s, est. speed input: 6197.91 toks/s, output: 6.05 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [06:00<05:25,  5.89it/s, est. speed input: 6192.80 toks/s, output: 6.05 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [06:06<05:27,  5.75it/s, est. speed input: 6183.05 toks/s, output: 6.04 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [06:11<05:24,  5.72it/s, est. speed input: 6176.88 toks/s, output: 6.03 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [06:17<05:19,  5.70it/s, est. speed input: 6171.36 toks/s, output: 6.03 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [06:21<04:51,  6.14it/s, est. speed input: 6188.04 toks/s, output: 6.04 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [06:27<04:54,  5.98it/s, est. speed input: 6181.67 toks/s, output: 6.04 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [06:33<04:55,  5.84it/s, est. speed input: 6174.48 toks/s, output: 6.03 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [06:38<04:55,  5.73it/s, est. speed input: 6166.13 toks/s, output: 6.02 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [06:44<04:52,  5.68it/s, est. speed input: 6159.46 toks/s, output: 6.02 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [06:48<04:22,  6.22it/s, est. speed input: 6179.41 toks/s, output: 6.03 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [06:54<04:27,  5.98it/s, est. speed input: 6171.57 toks/s, output: 6.03 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [07:00<04:27,  5.86it/s, est. speed input: 6165.65 toks/s, output: 6.02 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [07:05<04:26,  5.76it/s, est. speed input: 6158.72 toks/s, output: 6.01 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [07:11<04:24,  5.68it/s, est. speed input: 6151.90 toks/s, output: 6.01 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [07:17<04:21,  5.63it/s, est. speed input: 6145.01 toks/s, output: 6.00 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [07:21<03:50,  6.24it/s, est. speed input: 6166.00 toks/s, output: 6.02 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [07:27<03:54,  5.99it/s, est. speed input: 6158.53 toks/s, output: 6.01 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [07:33<03:55,  5.85it/s, est. speed input: 6152.41 toks/s, output: 6.01 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [07:38<03:52,  5.77it/s, est. speed input: 6147.31 toks/s, output: 6.00 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [07:44<03:49,  5.71it/s, est. speed input: 6141.79 toks/s, output: 6.00 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [07:50<03:46,  5.63it/s, est. speed input: 6134.87 toks/s, output: 5.99 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [07:54<03:20,  6.21it/s, est. speed input: 6153.25 toks/s, output: 6.01 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [08:00<03:22,  5.98it/s, est. speed input: 6147.12 toks/s, output: 6.00 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [08:05<03:22,  5.83it/s, est. speed input: 6140.86 toks/s, output: 6.00 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [08:11<03:19,  5.76it/s, est. speed input: 6136.25 toks/s, output: 5.99 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [08:17<03:15,  5.72it/s, est. speed input: 6131.99 toks/s, output: 5.99 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [08:21<02:57,  6.13it/s, est. speed input: 6144.31 toks/s, output: 6.00 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [08:27<02:56,  5.96it/s, est. speed input: 6139.67 toks/s, output: 6.00 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [08:33<02:55,  5.84it/s, est. speed input: 6134.74 toks/s, output: 5.99 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [08:38<02:53,  5.71it/s, est. speed input: 6128.36 toks/s, output: 5.98 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [08:44<02:48,  5.68it/s, est. speed input: 6124.00 toks/s, output: 5.98 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [08:50<02:43,  5.67it/s, est. speed input: 6120.41 toks/s, output: 5.98 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [08:54<02:25,  6.12it/s, est. speed input: 6133.06 toks/s, output: 5.99 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [09:00<02:24,  5.95it/s, est. speed input: 6128.74 toks/s, output: 5.99 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [09:06<02:22,  5.84it/s, est. speed input: 6124.44 toks/s, output: 5.98 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [09:11<02:19,  5.73it/s, est. speed input: 6119.16 toks/s, output: 5.98 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [09:17<02:14,  5.68it/s, est. speed input: 6114.91 toks/s, output: 5.97 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [09:23<02:09,  5.68it/s, est. speed input: 6111.71 toks/s, output: 5.97 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [09:27<01:54,  6.11it/s, est. speed input: 6123.18 toks/s, output: 5.98 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [09:33<01:52,  5.93it/s, est. speed input: 6118.84 toks/s, output: 5.98 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [09:39<01:49,  5.83it/s, est. speed input: 6114.97 toks/s, output: 5.97 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [09:44<01:45,  5.76it/s, est. speed input: 6111.30 toks/s, output: 5.97 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [09:50<01:41,  5.67it/s, est. speed input: 6106.24 toks/s, output: 5.96 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [09:54<01:27,  6.21it/s, est. speed input: 6120.17 toks/s, output: 5.98 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [10:00<01:25,  6.00it/s, est. speed input: 6116.10 toks/s, output: 5.97 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [10:06<01:21,  5.84it/s, est. speed input: 6111.51 toks/s, output: 5.97 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [10:11<01:17,  5.75it/s, est. speed input: 6107.30 toks/s, output: 5.96 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [10:17<01:11,  5.77it/s, est. speed input: 6105.98 toks/s, output: 5.96 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [10:23<01:07,  5.67it/s, est. speed input: 6101.21 toks/s, output: 5.96 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [10:27<00:55,  6.27it/s, est. speed input: 6116.01 toks/s, output: 5.97 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [10:32<00:52,  6.05it/s, est. speed input: 6112.51 toks/s, output: 5.97 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [10:38<00:48,  5.87it/s, est. speed input: 6107.85 toks/s, output: 5.96 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [10:44<00:44,  5.77it/s, est. speed input: 6104.07 toks/s, output: 5.96 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [10:50<00:38,  5.72it/s, est. speed input: 6100.92 toks/s, output: 5.96 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [10:55<00:33,  5.71it/s, est. speed input: 6098.45 toks/s, output: 5.96 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [10:59<00:25,  6.24it/s, est. speed input: 6111.01 toks/s, output: 5.97 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [11:05<00:20,  6.03it/s, est. speed input: 6107.61 toks/s, output: 5.96 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [11:11<00:16,  5.83it/s, est. speed input: 6102.84 toks/s, output: 5.96 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [11:17<00:10,  5.76it/s, est. speed input: 6099.71 toks/s, output: 5.96 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [11:22<00:05,  5.79it/s, est. speed input: 6098.92 toks/s, output: 5.96 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [11:22<00:00,  5.79it/s, est. speed input: 6143.92 toks/s, output: 6.00 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [11:22<00:00,  6.00it/s, est. speed input: 6143.92 toks/s, output: 6.00 toks/s]
[rank0]:[W126 00:35:01.322955980 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 788.8s

测试结果:
  Requests/s:   5.56
  Tokens/s:     5694.31
  Total Reqs:   4096
  Elapsed:      737.30s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     5688.76

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:36:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:36:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=603314) WARNING 01-26 00:36:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=603314) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=603314) WARNING 01-26 00:36:37 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     def forward(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     raise e
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/tmp/torchinductor_root/3z/c3z2lkoxpfahq4kv2ge3bhmt6no6sdtnxkdisg4dk4fqqul2iafk.py", line 1093, in call
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 8)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) ERROR 01-26 00:36:49 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-26 00:36:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:36:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:36:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:36:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:36:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:36:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:36:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:36:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:36:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:36:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:36:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:36:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:36:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:36:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:36:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:36:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:36:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=603314) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=603314) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.00it/s]
(EngineCore_DP0 pid=603314) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.32s/it]
(EngineCore_DP0 pid=603314) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.27s/it]
(EngineCore_DP0 pid=603314) 
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=603314) [2026-01-26 00:36:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=603314) [rank0]:W0126 00:36:45.605000 603314 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=603314) [rank0]:W0126 00:36:45.725000 603314 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=603314) [rank0]:W0126 00:36:47.544000 603314 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=603314) [rank0]:W0126 00:36:47.728000 603314 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=603314) Process EngineCore_DP0:
(EngineCore_DP0 pid=603314) Traceback (most recent call last):
(EngineCore_DP0 pid=603314)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=603314)     self.run()
(EngineCore_DP0 pid=603314)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=603314)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=603314)     raise e
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=603314)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=603314)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=603314)     super().__init__(
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=603314)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=603314)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=603314)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=603314)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=603314)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=603314)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=603314)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=603314)     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=603314)     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=603314)     self.model_runner.profile_run()
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=603314)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=603314)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=603314)     return func(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=603314)     outputs = self.model(
(EngineCore_DP0 pid=603314)               ^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=603314)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=603314)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=603314)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=603314)     hidden_states = self.model(
(EngineCore_DP0 pid=603314)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=603314)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=603314)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=603314)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=603314)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=603314)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=603314)     def forward(
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=603314)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=603314)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=603314)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=603314)     raise e
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=603314)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=603314)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=603314)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=603314)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=603314)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=603314)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=603314)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=603314)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=603314)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=603314)     return compiled_fn(full_args)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=603314)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=603314)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=603314)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=603314)                             ^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=603314)     outs = compiled_fn(args)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=603314)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=603314)     return self.current_callable(inputs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=603314)     out = model(new_inputs)
(EngineCore_DP0 pid=603314)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/tmp/torchinductor_root/3z/c3z2lkoxpfahq4kv2ge3bhmt6no6sdtnxkdisg4dk4fqqul2iafk.py", line 1093, in call
(EngineCore_DP0 pid=603314)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 8)
(EngineCore_DP0 pid=603314)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=603314)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=603314)     return fn(input, L)
(EngineCore_DP0 pid=603314)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=603314)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=603314)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=603314)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=603314)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=603314)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=603314)     self._init_handles()
(EngineCore_DP0 pid=603314)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=603314)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=603314)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=603314) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 00:36:50.727861743 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,14.9876,7688.6374,8.5404
1024,1024,1,128,128,14.9539,15327.7161,8.5597
2048,1024,2,256,128,21.7469,22290.5434,11.7718
4096,1024,4,512,128,22.1204,22673.4045,23.1461
8192,1024,8,1024,128,22.7422,23310.7494,45.0264
16384,1024,16,2048,128,13.3680,13702.2156,153.2015
32768,1024,32,4096,128,5.5554,5694.3148,737.2968
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:37:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:37:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=604100) WARNING 01-26 00:37:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=604100) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=604100) WARNING 01-26 00:37:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.09 requests/s, 7742.41 total tokens/s, 15.09 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 00:37:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:37:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:37:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:37:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:37:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:37:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:37:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:37:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:37:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:37:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:37:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:37:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:37:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:37:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:37:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:37:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:37:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=604100) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=604100) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.32s/it]
(EngineCore_DP0 pid=604100) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.31s/it]
(EngineCore_DP0 pid=604100) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.16s/it]
(EngineCore_DP0 pid=604100) 
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=604100) [2026-01-26 00:37:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=604100) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.01s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=604100) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 437.40it/s]
Adding requests:  70%|███████   | 90/128 [00:00<00:00, 449.43it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 449.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:29,  4.28it/s, est. speed input: 2192.78 toks/s, output: 4.28 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:22,  5.60it/s, est. speed input: 2740.78 toks/s, output: 5.35 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:18,  6.82it/s, est. speed input: 3186.45 toks/s, output: 6.22 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:12,  9.92it/s, est. speed input: 4173.38 toks/s, output: 8.15 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:10, 11.68it/s, est. speed input: 4796.01 toks/s, output: 9.37 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:09, 12.92it/s, est. speed input: 5258.06 toks/s, output: 10.27 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:08, 13.79it/s, est. speed input: 5610.42 toks/s, output: 10.96 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:08, 14.37it/s, est. speed input: 5882.20 toks/s, output: 11.49 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 14.71it/s, est. speed input: 6091.69 toks/s, output: 11.90 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:07, 14.95it/s, est. speed input: 6261.69 toks/s, output: 12.23 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:07, 15.17it/s, est. speed input: 6410.29 toks/s, output: 12.52 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 15.37it/s, est. speed input: 6541.05 toks/s, output: 12.78 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 15.42it/s, est. speed input: 6643.58 toks/s, output: 12.98 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 15.44it/s, est. speed input: 6730.86 toks/s, output: 13.15 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:06, 15.62it/s, est. speed input: 6822.34 toks/s, output: 13.32 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:06, 15.73it/s, est. speed input: 6902.02 toks/s, output: 13.48 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:06, 15.77it/s, est. speed input: 6969.41 toks/s, output: 13.61 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:06, 15.83it/s, est. speed input: 7032.26 toks/s, output: 13.73 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:05, 15.86it/s, est. speed input: 7088.10 toks/s, output: 13.84 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 15.90it/s, est. speed input: 7139.86 toks/s, output: 13.94 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 15.93it/s, est. speed input: 7187.26 toks/s, output: 14.04 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 15.88it/s, est. speed input: 7225.64 toks/s, output: 14.11 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:03<00:05, 15.74it/s, est. speed input: 7254.49 toks/s, output: 14.17 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:03<00:05, 15.68it/s, est. speed input: 7282.82 toks/s, output: 14.22 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:05, 15.60it/s, est. speed input: 7306.92 toks/s, output: 14.27 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:05, 15.47it/s, est. speed input: 7325.10 toks/s, output: 14.31 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 15.47it/s, est. speed input: 7346.61 toks/s, output: 14.35 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 15.47it/s, est. speed input: 7366.80 toks/s, output: 14.39 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 15.44it/s, est. speed input: 7384.15 toks/s, output: 14.42 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 15.43it/s, est. speed input: 7400.84 toks/s, output: 14.45 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:04<00:04, 15.41it/s, est. speed input: 7415.54 toks/s, output: 14.48 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:04, 15.64it/s, est. speed input: 7441.40 toks/s, output: 14.53 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 15.85it/s, est. speed input: 7467.69 toks/s, output: 14.59 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 15.92it/s, est. speed input: 7489.54 toks/s, output: 14.63 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 16.02it/s, est. speed input: 7512.03 toks/s, output: 14.67 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 16.13it/s, est. speed input: 7534.81 toks/s, output: 14.72 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 16.13it/s, est. speed input: 7553.45 toks/s, output: 14.75 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 16.13it/s, est. speed input: 7571.24 toks/s, output: 14.79 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:05<00:03, 16.04it/s, est. speed input: 7584.69 toks/s, output: 14.81 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:05<00:03, 15.98it/s, est. speed input: 7597.47 toks/s, output: 14.84 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:03, 15.98it/s, est. speed input: 7611.16 toks/s, output: 14.87 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 15.95it/s, est. speed input: 7623.13 toks/s, output: 14.89 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 15.91it/s, est. speed input: 7633.96 toks/s, output: 14.91 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 16.20it/s, est. speed input: 7655.33 toks/s, output: 14.95 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 16.52it/s, est. speed input: 7679.37 toks/s, output: 15.00 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 16.77it/s, est. speed input: 7703.12 toks/s, output: 15.05 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:06<00:02, 16.95it/s, est. speed input: 7725.89 toks/s, output: 15.09 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:06<00:02, 17.06it/s, est. speed input: 7747.53 toks/s, output: 15.13 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:01, 17.14it/s, est. speed input: 7768.17 toks/s, output: 15.17 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:01, 17.23it/s, est. speed input: 7788.99 toks/s, output: 15.21 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 17.22it/s, est. speed input: 7807.20 toks/s, output: 15.25 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 17.27it/s, est. speed input: 7826.30 toks/s, output: 15.29 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 17.25it/s, est. speed input: 7843.22 toks/s, output: 15.32 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 17.24it/s, est. speed input: 7859.81 toks/s, output: 15.35 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 17.19it/s, est. speed input: 7874.58 toks/s, output: 15.38 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:07<00:01, 17.11it/s, est. speed input: 7887.87 toks/s, output: 15.41 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:00, 17.08it/s, est. speed input: 7901.32 toks/s, output: 15.43 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:00, 17.00it/s, est. speed input: 7912.72 toks/s, output: 15.45 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 16.97it/s, est. speed input: 7924.55 toks/s, output: 15.48 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 16.89it/s, est. speed input: 7934.49 toks/s, output: 15.50 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 16.94it/s, est. speed input: 7946.81 toks/s, output: 15.52 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 17.04it/s, est. speed input: 7960.10 toks/s, output: 15.55 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 17.06it/s, est. speed input: 7971.83 toks/s, output: 15.57 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:08<00:00, 17.10it/s, est. speed input: 7983.92 toks/s, output: 15.59 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 16.99it/s, est. speed input: 7992.69 toks/s, output: 15.61 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 16.99it/s, est. speed input: 7997.39 toks/s, output: 15.62 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.62it/s, est. speed input: 7997.39 toks/s, output: 15.62 toks/s]
[rank0]:[W126 00:38:06.504344762 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 73.8s

测试结果:
  Requests/s:   15.09
  Tokens/s:     7742.41
  Total Reqs:   128
  Elapsed:      8.48s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     7727.32

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:38:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:38:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=605220) WARNING 01-26 00:38:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=605220) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=605220) WARNING 01-26 00:38:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.09 requests/s, 15470.73 total tokens/s, 15.09 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 00:38:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:38:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:38:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:38:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:38:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:38:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:38:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:38:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:38:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:38:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:38:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:38:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:38:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:38:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:38:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:38:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:38:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:26] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=605220) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=605220) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.03s/it]
(EngineCore_DP0 pid=605220) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.51s/it]
(EngineCore_DP0 pid=605220) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.43s/it]
(EngineCore_DP0 pid=605220) 
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=605220) [2026-01-26 00:38:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=605220) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  2.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.91it/s]
(EngineCore_DP0 pid=605220) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 23/128 [00:00<00:00, 229.91it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 240.01it/s]
Adding requests:  58%|█████▊    | 74/128 [00:00<00:00, 248.70it/s]
Adding requests:  77%|███████▋  | 99/128 [00:00<00:00, 242.44it/s]
Adding requests:  98%|█████████▊| 126/128 [00:00<00:00, 248.86it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 245.40it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:07, 16.15it/s, est. speed input: 16546.28 toks/s, output: 16.16 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:07, 16.43it/s, est. speed input: 16783.54 toks/s, output: 16.39 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:07, 16.55it/s, est. speed input: 16886.49 toks/s, output: 16.49 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:07, 16.63it/s, est. speed input: 16952.02 toks/s, output: 16.55 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:07, 16.66it/s, est. speed input: 16983.96 toks/s, output: 16.59 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:06, 16.66it/s, est. speed input: 16996.38 toks/s, output: 16.60 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 16.66it/s, est. speed input: 17006.26 toks/s, output: 16.61 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 16.65it/s, est. speed input: 17007.46 toks/s, output: 16.61 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:06, 16.65it/s, est. speed input: 17011.15 toks/s, output: 16.61 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 16.72it/s, est. speed input: 17040.22 toks/s, output: 16.64 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 16.62it/s, est. speed input: 17017.91 toks/s, output: 16.62 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 16.48it/s, est. speed input: 16978.76 toks/s, output: 16.58 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:06, 16.70it/s, est. speed input: 17027.79 toks/s, output: 16.63 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 16.81it/s, est. speed input: 17059.78 toks/s, output: 16.66 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 16.54it/s, est. speed input: 17008.18 toks/s, output: 16.61 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 16.23it/s, est. speed input: 16936.20 toks/s, output: 16.54 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:02<00:05, 16.01it/s, est. speed input: 16871.31 toks/s, output: 16.48 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 15.90it/s, est. speed input: 16822.01 toks/s, output: 16.43 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 15.84it/s, est. speed input: 16781.73 toks/s, output: 16.39 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 15.80it/s, est. speed input: 16744.41 toks/s, output: 16.35 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 15.84it/s, est. speed input: 16723.10 toks/s, output: 16.33 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:05, 15.83it/s, est. speed input: 16698.25 toks/s, output: 16.31 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:05, 15.82it/s, est. speed input: 16674.92 toks/s, output: 16.28 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:05, 15.85it/s, est. speed input: 16658.66 toks/s, output: 16.27 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:04, 15.73it/s, est. speed input: 16624.37 toks/s, output: 16.23 toks/s]
Processed prompts:  41%|████      | 52/128 [00:03<00:04, 15.63it/s, est. speed input: 16589.60 toks/s, output: 16.20 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 15.54it/s, est. speed input: 16554.51 toks/s, output: 16.17 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 15.47it/s, est. speed input: 16522.31 toks/s, output: 16.13 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 15.49it/s, est. speed input: 16499.45 toks/s, output: 16.11 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:04, 15.44it/s, est. speed input: 16471.56 toks/s, output: 16.09 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:04, 15.45it/s, est. speed input: 16450.77 toks/s, output: 16.07 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:04, 15.40it/s, est. speed input: 16424.47 toks/s, output: 16.04 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:04<00:04, 15.41it/s, est. speed input: 16404.79 toks/s, output: 16.02 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:04<00:03, 15.51it/s, est. speed input: 16396.30 toks/s, output: 16.01 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 15.55it/s, est. speed input: 16385.91 toks/s, output: 16.00 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 15.54it/s, est. speed input: 16371.53 toks/s, output: 15.99 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 15.69it/s, est. speed input: 16373.00 toks/s, output: 15.99 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 15.79it/s, est. speed input: 16374.10 toks/s, output: 15.99 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:03, 15.89it/s, est. speed input: 16377.62 toks/s, output: 15.99 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:05<00:03, 15.75it/s, est. speed input: 16362.87 toks/s, output: 15.98 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:05<00:02, 15.66it/s, est. speed input: 16349.31 toks/s, output: 15.97 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:05<00:02, 15.60it/s, est. speed input: 16336.56 toks/s, output: 15.95 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:05<00:02, 15.59it/s, est. speed input: 16327.30 toks/s, output: 15.94 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 15.57it/s, est. speed input: 16317.56 toks/s, output: 15.94 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 15.61it/s, est. speed input: 16311.58 toks/s, output: 15.93 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 15.57it/s, est. speed input: 16301.62 toks/s, output: 15.92 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:02, 15.44it/s, est. speed input: 16283.53 toks/s, output: 15.90 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:06<00:02, 15.42it/s, est. speed input: 16272.31 toks/s, output: 15.89 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:06<00:01, 15.42it/s, est. speed input: 16262.23 toks/s, output: 15.88 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:06<00:01, 15.63it/s, est. speed input: 16267.41 toks/s, output: 15.89 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:06<00:01, 16.03it/s, est. speed input: 16289.17 toks/s, output: 15.91 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:06<00:01, 16.27it/s, est. speed input: 16306.61 toks/s, output: 15.92 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 16.43it/s, est. speed input: 16322.93 toks/s, output: 15.94 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 16.53it/s, est. speed input: 16338.15 toks/s, output: 15.96 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 16.59it/s, est. speed input: 16352.01 toks/s, output: 15.97 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:07<00:00, 16.67it/s, est. speed input: 16367.52 toks/s, output: 15.98 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:07<00:00, 16.69it/s, est. speed input: 16380.52 toks/s, output: 16.00 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:07<00:00, 16.70it/s, est. speed input: 16392.75 toks/s, output: 16.01 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:07<00:00, 16.73it/s, est. speed input: 16405.99 toks/s, output: 16.02 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:07<00:00, 16.76it/s, est. speed input: 16419.22 toks/s, output: 16.03 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 16.86it/s, est. speed input: 16435.66 toks/s, output: 16.05 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:07<00:00, 16.81it/s, est. speed input: 16446.05 toks/s, output: 16.06 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 16.81it/s, est. speed input: 16457.71 toks/s, output: 16.07 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.88it/s, est. speed input: 16472.18 toks/s, output: 16.09 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.88it/s, est. speed input: 16472.18 toks/s, output: 16.09 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.09it/s, est. speed input: 16472.18 toks/s, output: 16.09 toks/s]
[rank0]:[W126 00:39:09.680895417 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 61.4s

测试结果:
  Requests/s:   15.09
  Tokens/s:     15470.73
  Total Reqs:   128
  Elapsed:      8.48s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     15455.63

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:39:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:39:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=606198) WARNING 01-26 00:39:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=606198) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=606198) WARNING 01-26 00:39:42 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.44 requests/s, 20955.33 total tokens/s, 20.44 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 00:39:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:39:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:39:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:39:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:39:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:39:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:39:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:39:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:39:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:39:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:39:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:39:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:39:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:39:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:39:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:39:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:39:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=606198) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=606198) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.04s/it]
(EngineCore_DP0 pid=606198) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.34s/it]
(EngineCore_DP0 pid=606198) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.30s/it]
(EngineCore_DP0 pid=606198) 
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=606198) [2026-01-26 00:39:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=606198) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.80it/s]
(EngineCore_DP0 pid=606198) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  6.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.68it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 200.66it/s]
Adding requests:  17%|█▋        | 44/256 [00:00<00:00, 216.15it/s]
Adding requests:  27%|██▋       | 69/256 [00:00<00:00, 229.36it/s]
Adding requests:  36%|███▌      | 92/256 [00:00<00:00, 228.69it/s]
Adding requests:  46%|████▌     | 117/256 [00:00<00:00, 233.90it/s]
Adding requests:  55%|█████▌    | 141/256 [00:00<00:00, 235.45it/s]
Adding requests:  65%|██████▍   | 166/256 [00:00<00:00, 238.24it/s]
Adding requests:  75%|███████▌  | 193/256 [00:00<00:00, 247.18it/s]
Adding requests:  85%|████████▌ | 218/256 [00:00<00:00, 246.69it/s]
Adding requests:  95%|█████████▍| 243/256 [00:01<00:00, 242.36it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 236.67it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 14/256 [00:00<00:01, 122.28it/s, est. speed input: 125243.27 toks/s, output: 122.29 toks/s]
Processed prompts:  11%|█         | 27/256 [00:00<00:06, 34.50it/s, est. speed input: 39764.17 toks/s, output: 38.83 toks/s]   
Processed prompts:  13%|█▎        | 34/256 [00:01<00:08, 27.03it/s, est. speed input: 32172.78 toks/s, output: 31.42 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:01<00:08, 26.73it/s, est. speed input: 31302.47 toks/s, output: 30.57 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:01<00:08, 25.16it/s, est. speed input: 29968.22 toks/s, output: 29.27 toks/s]
Processed prompts:  18%|█▊        | 47/256 [00:01<00:08, 23.95it/s, est. speed input: 28948.34 toks/s, output: 28.27 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:01<00:09, 21.60it/s, est. speed input: 27586.35 toks/s, output: 26.94 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:09, 21.73it/s, est. speed input: 27143.55 toks/s, output: 26.51 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:09, 21.91it/s, est. speed input: 26803.08 toks/s, output: 26.17 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:02<00:08, 22.02it/s, est. speed input: 26507.02 toks/s, output: 25.89 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:08, 22.10it/s, est. speed input: 26249.00 toks/s, output: 25.63 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:02<00:08, 22.17it/s, est. speed input: 26030.76 toks/s, output: 25.42 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:02<00:08, 22.20it/s, est. speed input: 25831.92 toks/s, output: 25.23 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:08, 22.24it/s, est. speed input: 25662.17 toks/s, output: 25.06 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:07, 22.29it/s, est. speed input: 25515.18 toks/s, output: 24.92 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:03<00:07, 22.30it/s, est. speed input: 25377.25 toks/s, output: 24.78 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:07, 22.31it/s, est. speed input: 25254.94 toks/s, output: 24.66 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:03<00:07, 22.31it/s, est. speed input: 25141.17 toks/s, output: 24.55 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:04<00:07, 22.31it/s, est. speed input: 25039.64 toks/s, output: 24.45 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:06, 22.30it/s, est. speed input: 24943.95 toks/s, output: 24.36 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:04<00:06, 22.32it/s, est. speed input: 24859.85 toks/s, output: 24.28 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:04<00:06, 22.18it/s, est. speed input: 24760.80 toks/s, output: 24.18 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:04<00:06, 21.68it/s, est. speed input: 24609.58 toks/s, output: 24.03 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:04<00:06, 21.34it/s, est. speed input: 24471.75 toks/s, output: 23.90 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:05<00:06, 21.11it/s, est. speed input: 24343.61 toks/s, output: 23.77 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:05<00:06, 20.95it/s, est. speed input: 24224.29 toks/s, output: 23.66 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:05<00:06, 20.83it/s, est. speed input: 24112.01 toks/s, output: 23.55 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:05<00:05, 20.79it/s, est. speed input: 24013.91 toks/s, output: 23.45 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:05<00:05, 20.77it/s, est. speed input: 23922.19 toks/s, output: 23.36 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:06<00:05, 20.73it/s, est. speed input: 23833.78 toks/s, output: 23.28 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:06<00:05, 20.69it/s, est. speed input: 23749.08 toks/s, output: 23.19 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:06<00:05, 20.67it/s, est. speed input: 23670.04 toks/s, output: 23.12 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:06<00:04, 20.64it/s, est. speed input: 23594.18 toks/s, output: 23.04 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:06<00:04, 20.63it/s, est. speed input: 23524.01 toks/s, output: 22.97 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:07<00:04, 20.63it/s, est. speed input: 23457.97 toks/s, output: 22.91 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:07<00:04, 20.62it/s, est. speed input: 23394.42 toks/s, output: 22.85 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:07<00:04, 20.61it/s, est. speed input: 23334.31 toks/s, output: 22.79 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:07<00:03, 20.59it/s, est. speed input: 23275.79 toks/s, output: 22.73 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:07<00:03, 20.59it/s, est. speed input: 23221.42 toks/s, output: 22.68 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:08<00:03, 20.59it/s, est. speed input: 23169.59 toks/s, output: 22.63 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:08<00:03, 20.56it/s, est. speed input: 23118.14 toks/s, output: 22.58 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:08<00:03, 20.54it/s, est. speed input: 23068.97 toks/s, output: 22.53 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:08<00:03, 20.55it/s, est. speed input: 23024.08 toks/s, output: 22.48 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:08<00:02, 20.55it/s, est. speed input: 22979.94 toks/s, output: 22.44 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:09<00:02, 20.58it/s, est. speed input: 22940.68 toks/s, output: 22.40 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:09<00:02, 20.59it/s, est. speed input: 22902.18 toks/s, output: 22.37 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:09<00:02, 20.60it/s, est. speed input: 22865.16 toks/s, output: 22.33 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:09<00:01, 21.03it/s, est. speed input: 22860.78 toks/s, output: 22.32 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:09<00:01, 21.41it/s, est. speed input: 22861.73 toks/s, output: 22.33 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:09<00:01, 21.63it/s, est. speed input: 22858.51 toks/s, output: 22.32 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:10<00:01, 21.84it/s, est. speed input: 22858.91 toks/s, output: 22.32 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:10<00:01, 21.97it/s, est. speed input: 22858.31 toks/s, output: 22.32 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:10<00:00, 22.01it/s, est. speed input: 22854.57 toks/s, output: 22.32 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:10<00:00, 22.12it/s, est. speed input: 22855.35 toks/s, output: 22.32 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:10<00:00, 22.17it/s, est. speed input: 22855.06 toks/s, output: 22.32 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:11<00:00, 22.21it/s, est. speed input: 22854.74 toks/s, output: 22.32 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 22.21it/s, est. speed input: 26663.35 toks/s, output: 26.04 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 26.04it/s, est. speed input: 26663.35 toks/s, output: 26.04 toks/s]
[rank0]:[W126 00:40:12.973436235 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 64.6s

测试结果:
  Requests/s:   20.44
  Tokens/s:     20955.33
  Total Reqs:   256
  Elapsed:      12.52s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     20934.89

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:40:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:40:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=607188) WARNING 01-26 00:40:38 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=607188) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=607188) WARNING 01-26 00:40:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.42 requests/s, 21954.22 total tokens/s, 21.42 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 00:40:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:40:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:40:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:40:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:40:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:40:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:40:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:40:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:40:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:40:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:40:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:40:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:40:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:40:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:40:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:40:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:40:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=607188) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=607188) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
(EngineCore_DP0 pid=607188) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.48s/it]
(EngineCore_DP0 pid=607188) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.43s/it]
(EngineCore_DP0 pid=607188) 
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=607188) [2026-01-26 00:40:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=607188) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  7.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.98it/s]
(EngineCore_DP0 pid=607188) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.31it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  7.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.30it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 235.20it/s]
Adding requests:  10%|▉         | 51/512 [00:00<00:01, 251.20it/s]
Adding requests:  15%|█▌        | 79/512 [00:00<00:01, 261.32it/s]
Adding requests:  21%|██        | 106/512 [00:00<00:01, 263.35it/s]
Adding requests:  26%|██▌       | 133/512 [00:00<00:01, 261.58it/s]
Adding requests:  31%|███▏      | 160/512 [00:00<00:01, 260.01it/s]
Adding requests:  37%|███▋      | 187/512 [00:00<00:01, 259.37it/s]
Adding requests:  42%|████▏     | 213/512 [00:00<00:01, 258.27it/s]
Adding requests:  47%|████▋     | 239/512 [00:00<00:01, 255.44it/s]
Adding requests:  52%|█████▏    | 265/512 [00:01<00:01, 241.10it/s]
Adding requests:  57%|█████▋    | 290/512 [00:01<00:00, 239.47it/s]
Adding requests:  62%|██████▏   | 316/512 [00:01<00:00, 242.70it/s]
Adding requests:  67%|██████▋   | 341/512 [00:01<00:00, 242.95it/s]
Adding requests:  71%|███████▏  | 366/512 [00:01<00:00, 243.91it/s]
Adding requests:  76%|███████▋  | 391/512 [00:01<00:00, 245.57it/s]
Adding requests:  81%|████████▏ | 417/512 [00:01<00:00, 247.95it/s]
Adding requests:  86%|████████▋ | 442/512 [00:01<00:00, 243.77it/s]
Adding requests:  91%|█████████▏| 468/512 [00:01<00:00, 248.09it/s]
Adding requests:  97%|█████████▋| 495/512 [00:01<00:00, 252.86it/s]
Adding requests: 100%|██████████| 512/512 [00:02<00:00, 249.96it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:00<00:02, 178.68it/s, est. speed input: 182999.00 toks/s, output: 178.69 toks/s]
Processed prompts:  11%|█         | 56/512 [00:00<00:09, 49.78it/s, est. speed input: 59752.43 toks/s, output: 58.35 toks/s]   
Processed prompts:  13%|█▎        | 65/512 [00:01<00:11, 40.19it/s, est. speed input: 49920.51 toks/s, output: 48.75 toks/s]
Processed prompts:  14%|█▍        | 71/512 [00:01<00:13, 31.81it/s, est. speed input: 42604.50 toks/s, output: 41.61 toks/s]
Processed prompts:  15%|█▍        | 76/512 [00:01<00:14, 30.81it/s, est. speed input: 41106.52 toks/s, output: 40.14 toks/s]
Processed prompts:  16%|█▌        | 80/512 [00:02<00:15, 28.75it/s, est. speed input: 39397.06 toks/s, output: 38.47 toks/s]
Processed prompts:  16%|█▋        | 84/512 [00:02<00:15, 27.00it/s, est. speed input: 37962.60 toks/s, output: 37.07 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:02<00:05, 73.40it/s, est. speed input: 51203.13 toks/s, output: 50.00 toks/s]
Processed prompts:  26%|██▌       | 131/512 [00:02<00:07, 52.35it/s, est. speed input: 47673.45 toks/s, output: 46.56 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:09, 39.63it/s, est. speed input: 44337.57 toks/s, output: 43.30 toks/s]
Processed prompts:  28%|██▊       | 144/512 [00:03<00:09, 38.04it/s, est. speed input: 43705.40 toks/s, output: 42.68 toks/s]
Processed prompts:  29%|██▉       | 149/512 [00:03<00:10, 35.41it/s, est. speed input: 42849.43 toks/s, output: 41.85 toks/s]
Processed prompts:  30%|███       | 154/512 [00:03<00:13, 27.03it/s, est. speed input: 40232.94 toks/s, output: 39.29 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:13, 26.22it/s, est. speed input: 39537.85 toks/s, output: 38.61 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:13, 25.51it/s, est. speed input: 38899.01 toks/s, output: 37.99 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:04<00:13, 24.92it/s, est. speed input: 38307.14 toks/s, output: 37.41 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:04<00:13, 24.47it/s, est. speed input: 37762.75 toks/s, output: 36.88 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:04<00:14, 24.11it/s, est. speed input: 37254.57 toks/s, output: 36.38 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:04<00:14, 23.84it/s, est. speed input: 36782.11 toks/s, output: 35.92 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:13, 23.66it/s, est. speed input: 36343.77 toks/s, output: 35.49 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:13, 23.52it/s, est. speed input: 35933.25 toks/s, output: 35.09 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:05<00:13, 23.41it/s, est. speed input: 35547.88 toks/s, output: 34.71 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:05<00:13, 23.34it/s, est. speed input: 35185.96 toks/s, output: 34.36 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:05<00:13, 23.28it/s, est. speed input: 34844.24 toks/s, output: 34.03 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:05<00:13, 23.24it/s, est. speed input: 34523.49 toks/s, output: 33.71 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:13, 23.22it/s, est. speed input: 34221.56 toks/s, output: 33.42 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:12, 23.24it/s, est. speed input: 33940.04 toks/s, output: 33.14 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:12, 23.25it/s, est. speed input: 33672.62 toks/s, output: 32.88 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:06<00:12, 22.83it/s, est. speed input: 33366.31 toks/s, output: 32.58 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:12, 22.39it/s, est. speed input: 33055.52 toks/s, output: 32.28 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:12, 22.08it/s, est. speed input: 32760.63 toks/s, output: 31.99 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:12, 21.86it/s, est. speed input: 32479.21 toks/s, output: 31.72 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:12, 21.71it/s, est. speed input: 32213.18 toks/s, output: 31.46 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:12, 21.61it/s, est. speed input: 31959.71 toks/s, output: 31.21 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:07<00:12, 21.54it/s, est. speed input: 31718.35 toks/s, output: 30.97 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:08<00:12, 21.48it/s, est. speed input: 31487.44 toks/s, output: 30.75 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:08<00:12, 21.45it/s, est. speed input: 31268.14 toks/s, output: 30.54 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:12, 21.42it/s, est. speed input: 31057.94 toks/s, output: 30.33 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:11, 21.41it/s, est. speed input: 30857.44 toks/s, output: 30.13 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:08<00:11, 21.39it/s, est. speed input: 30665.22 toks/s, output: 29.95 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:08<00:11, 21.38it/s, est. speed input: 30481.03 toks/s, output: 29.77 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:09<00:11, 21.37it/s, est. speed input: 30303.77 toks/s, output: 29.59 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:09<00:11, 21.40it/s, est. speed input: 30137.13 toks/s, output: 29.43 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:10, 21.40it/s, est. speed input: 29975.56 toks/s, output: 29.27 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:10, 21.40it/s, est. speed input: 29820.07 toks/s, output: 29.12 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:10, 21.40it/s, est. speed input: 29669.83 toks/s, output: 28.97 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:10, 21.37it/s, est. speed input: 29523.07 toks/s, output: 28.83 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:10<00:10, 21.35it/s, est. speed input: 29382.05 toks/s, output: 28.69 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:10<00:10, 21.35it/s, est. speed input: 29246.91 toks/s, output: 28.56 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:09, 21.35it/s, est. speed input: 29116.60 toks/s, output: 28.43 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:09, 21.35it/s, est. speed input: 28990.65 toks/s, output: 28.31 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:09, 21.35it/s, est. speed input: 28869.47 toks/s, output: 28.19 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:11<00:09, 21.35it/s, est. speed input: 28751.85 toks/s, output: 28.08 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:11<00:09, 21.34it/s, est. speed input: 28637.49 toks/s, output: 27.97 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:08, 21.33it/s, est. speed input: 28527.00 toks/s, output: 27.86 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:08, 21.34it/s, est. speed input: 28420.77 toks/s, output: 27.75 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:08, 21.34it/s, est. speed input: 28317.66 toks/s, output: 27.65 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:12<00:08, 21.31it/s, est. speed input: 28215.72 toks/s, output: 27.55 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:12<00:08, 21.32it/s, est. speed input: 28118.55 toks/s, output: 27.46 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:12<00:07, 21.44it/s, est. speed input: 28032.39 toks/s, output: 27.38 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:07, 21.91it/s, est. speed input: 27972.15 toks/s, output: 27.32 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:07, 22.28it/s, est. speed input: 27915.25 toks/s, output: 27.26 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:13<00:07, 22.54it/s, est. speed input: 27859.62 toks/s, output: 27.21 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:13<00:06, 22.71it/s, est. speed input: 27804.90 toks/s, output: 27.15 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:13<00:06, 22.85it/s, est. speed input: 27752.40 toks/s, output: 27.10 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:13<00:06, 22.92it/s, est. speed input: 27699.88 toks/s, output: 27.05 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:06, 22.98it/s, est. speed input: 27648.86 toks/s, output: 27.00 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:05, 23.01it/s, est. speed input: 27598.87 toks/s, output: 26.95 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:14<00:05, 23.05it/s, est. speed input: 27550.71 toks/s, output: 26.90 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:14<00:05, 23.06it/s, est. speed input: 27503.01 toks/s, output: 26.86 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:14<00:05, 23.06it/s, est. speed input: 27456.37 toks/s, output: 26.81 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:14<00:05, 23.08it/s, est. speed input: 27411.54 toks/s, output: 26.77 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:05, 22.53it/s, est. speed input: 27340.72 toks/s, output: 26.70 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:05, 22.17it/s, est. speed input: 27272.30 toks/s, output: 26.63 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:15<00:05, 21.90it/s, est. speed input: 27204.41 toks/s, output: 26.57 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:15<00:04, 21.72it/s, est. speed input: 27138.60 toks/s, output: 26.50 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:15<00:04, 21.59it/s, est. speed input: 27074.14 toks/s, output: 26.44 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:04, 21.53it/s, est. speed input: 27012.24 toks/s, output: 26.38 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:04, 21.47it/s, est. speed input: 26951.25 toks/s, output: 26.32 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:16<00:04, 21.43it/s, est. speed input: 26891.64 toks/s, output: 26.26 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:16<00:04, 21.38it/s, est. speed input: 26832.59 toks/s, output: 26.20 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:16<00:03, 21.35it/s, est. speed input: 26775.11 toks/s, output: 26.15 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:16<00:03, 21.31it/s, est. speed input: 26717.95 toks/s, output: 26.09 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:03, 21.31it/s, est. speed input: 26662.95 toks/s, output: 26.04 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:17<00:03, 21.30it/s, est. speed input: 26609.38 toks/s, output: 25.99 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:17<00:03, 21.26it/s, est. speed input: 26554.83 toks/s, output: 25.93 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:17<00:02, 21.27it/s, est. speed input: 26503.46 toks/s, output: 25.88 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:17<00:02, 21.26it/s, est. speed input: 26452.61 toks/s, output: 25.83 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:17<00:02, 21.25it/s, est. speed input: 26402.52 toks/s, output: 25.78 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:17<00:02, 21.25it/s, est. speed input: 26354.02 toks/s, output: 25.74 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:18<00:02, 21.26it/s, est. speed input: 26306.66 toks/s, output: 25.69 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:18<00:01, 21.25it/s, est. speed input: 26259.84 toks/s, output: 25.64 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:18<00:01, 21.25it/s, est. speed input: 26214.05 toks/s, output: 25.60 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:18<00:01, 21.24it/s, est. speed input: 26168.78 toks/s, output: 25.56 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:18<00:01, 21.24it/s, est. speed input: 26124.83 toks/s, output: 25.51 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:19<00:01, 21.26it/s, est. speed input: 26082.46 toks/s, output: 25.47 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:19<00:01, 21.28it/s, est. speed input: 26040.91 toks/s, output: 25.43 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:19<00:00, 21.28it/s, est. speed input: 26000.09 toks/s, output: 25.39 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:19<00:00, 21.28it/s, est. speed input: 25959.88 toks/s, output: 25.35 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:19<00:00, 21.26it/s, est. speed input: 25919.67 toks/s, output: 25.31 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:20<00:00, 21.26it/s, est. speed input: 25880.73 toks/s, output: 25.27 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:20<00:00, 23.08it/s, est. speed input: 25905.82 toks/s, output: 25.30 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:20<00:00, 23.08it/s, est. speed input: 26007.12 toks/s, output: 25.40 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:20<00:00, 25.40it/s, est. speed input: 26007.12 toks/s, output: 25.40 toks/s]
[rank0]:[W126 00:41:33.274662135 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 81.3s

测试结果:
  Requests/s:   21.42
  Tokens/s:     21954.22
  Total Reqs:   512
  Elapsed:      23.90s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     21932.81

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:41:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:41:52 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=608340) WARNING 01-26 00:42:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=608340) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=608340) WARNING 01-26 00:42:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.80 requests/s, 22339.96 total tokens/s, 21.80 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 00:41:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:41:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:41:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:41:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:41:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:41:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:41:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:41:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:41:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:42:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:42:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:42:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:42:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:42:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:42:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:42:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:42:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:42:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=608340) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=608340) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
(EngineCore_DP0 pid=608340) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.40s/it]
(EngineCore_DP0 pid=608340) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.36s/it]
(EngineCore_DP0 pid=608340) 
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=608340) [2026-01-26 00:42:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=608340) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  4.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  4.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.05it/s]
(EngineCore_DP0 pid=608340) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  5.62it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.92it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  3.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.20it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 21/1024 [00:00<00:04, 209.76it/s]
Adding requests:   4%|▍         | 44/1024 [00:00<00:04, 221.17it/s]
Adding requests:   7%|▋         | 70/1024 [00:00<00:04, 233.82it/s]
Adding requests:   9%|▉         | 94/1024 [00:00<00:04, 223.26it/s]
Adding requests:  12%|█▏        | 118/1024 [00:00<00:04, 225.88it/s]
Adding requests:  14%|█▍        | 141/1024 [00:00<00:03, 226.28it/s]
Adding requests:  16%|█▌        | 166/1024 [00:00<00:03, 231.84it/s]
Adding requests:  19%|█▉        | 193/1024 [00:00<00:03, 242.07it/s]
Adding requests:  21%|██▏       | 218/1024 [00:00<00:03, 242.34it/s]
Adding requests:  24%|██▍       | 244/1024 [00:01<00:03, 246.98it/s]
Adding requests:  26%|██▋       | 271/1024 [00:01<00:02, 251.19it/s]
Adding requests:  29%|██▉       | 298/1024 [00:01<00:02, 254.99it/s]
Adding requests:  32%|███▏      | 325/1024 [00:01<00:02, 257.96it/s]
Adding requests:  34%|███▍      | 353/1024 [00:01<00:02, 262.47it/s]
Adding requests:  37%|███▋      | 380/1024 [00:01<00:02, 262.50it/s]
Adding requests:  40%|███▉      | 408/1024 [00:01<00:02, 267.12it/s]
Adding requests:  43%|████▎     | 436/1024 [00:01<00:02, 269.41it/s]
Adding requests:  45%|████▌     | 464/1024 [00:01<00:02, 270.59it/s]
Adding requests:  48%|████▊     | 495/1024 [00:01<00:01, 281.42it/s]
Adding requests:  51%|█████▏    | 526/1024 [00:02<00:01, 289.34it/s]
Adding requests:  54%|█████▍    | 555/1024 [00:02<00:01, 283.62it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:02<00:01, 278.95it/s]
Adding requests:  60%|█████▉    | 612/1024 [00:02<00:01, 274.99it/s]
Adding requests:  62%|██████▎   | 640/1024 [00:02<00:01, 265.33it/s]
Adding requests:  65%|██████▌   | 667/1024 [00:02<00:01, 258.09it/s]
Adding requests:  68%|██████▊   | 695/1024 [00:02<00:01, 261.78it/s]
Adding requests:  71%|███████   | 722/1024 [00:02<00:01, 260.27it/s]
Adding requests:  73%|███████▎  | 749/1024 [00:02<00:01, 256.06it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:03<00:00, 259.82it/s]
Adding requests:  78%|███████▊  | 803/1024 [00:03<00:00, 261.78it/s]
Adding requests:  81%|████████  | 831/1024 [00:03<00:00, 266.62it/s]
Adding requests:  84%|████████▍ | 858/1024 [00:03<00:00, 266.65it/s]
Adding requests:  86%|████████▋ | 885/1024 [00:03<00:00, 267.57it/s]
Adding requests:  89%|████████▉ | 912/1024 [00:03<00:00, 265.90it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:03<00:00, 256.07it/s]
Adding requests:  94%|█████████▍| 965/1024 [00:03<00:00, 253.31it/s]
Adding requests:  97%|█████████▋| 991/1024 [00:03<00:00, 246.53it/s]
Adding requests:  99%|█████████▉| 1016/1024 [00:03<00:00, 235.76it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 255.48it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:00<00:03, 278.14it/s, est. speed input: 284857.09 toks/s, output: 278.15 toks/s]
Processed prompts:   9%|▉         | 94/1024 [00:01<00:15, 58.19it/s, est. speed input: 71492.50 toks/s, output: 69.82 toks/s]   
Processed prompts:  10%|█         | 107/1024 [00:02<00:23, 39.82it/s, est. speed input: 52566.28 toks/s, output: 51.33 toks/s]
Processed prompts:  11%|█         | 115/1024 [00:02<00:25, 35.39it/s, est. speed input: 47994.72 toks/s, output: 46.87 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:02<00:28, 31.14it/s, est. speed input: 44260.95 toks/s, output: 43.22 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:31, 28.58it/s, est. speed input: 41703.65 toks/s, output: 40.73 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:03<00:33, 26.65it/s, est. speed input: 39678.02 toks/s, output: 38.75 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:03<00:34, 25.22it/s, est. speed input: 38026.29 toks/s, output: 37.13 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:35, 24.57it/s, est. speed input: 36836.28 toks/s, output: 35.97 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:04<00:35, 24.25it/s, est. speed input: 35887.98 toks/s, output: 35.05 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:04<00:35, 24.02it/s, est. speed input: 35070.53 toks/s, output: 34.25 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:35, 23.85it/s, est. speed input: 34358.90 toks/s, output: 33.55 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:05<00:35, 23.72it/s, est. speed input: 33729.64 toks/s, output: 32.94 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:05<00:35, 23.63it/s, est. speed input: 33172.90 toks/s, output: 32.40 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:34, 23.57it/s, est. speed input: 32677.48 toks/s, output: 31.91 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:06<00:34, 23.53it/s, est. speed input: 32232.90 toks/s, output: 31.48 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:34, 23.49it/s, est. speed input: 31829.88 toks/s, output: 31.08 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:34, 23.46it/s, est. speed input: 31464.31 toks/s, output: 30.73 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:07<00:13, 55.27it/s, est. speed input: 36142.94 toks/s, output: 35.30 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:16, 45.19it/s, est. speed input: 35524.41 toks/s, output: 34.69 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:19, 38.15it/s, est. speed input: 34957.79 toks/s, output: 34.14 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:21, 33.24it/s, est. speed input: 34436.84 toks/s, output: 33.63 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:24, 29.81it/s, est. speed input: 33957.93 toks/s, output: 33.16 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:25, 27.41it/s, est. speed input: 33514.25 toks/s, output: 32.73 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:27, 25.73it/s, est. speed input: 33103.84 toks/s, output: 32.33 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:10<00:28, 24.56it/s, est. speed input: 32722.55 toks/s, output: 31.96 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:10<00:28, 23.74it/s, est. speed input: 32366.63 toks/s, output: 31.61 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:11<00:29, 23.15it/s, est. speed input: 32033.05 toks/s, output: 31.28 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:29, 22.76it/s, est. speed input: 31722.71 toks/s, output: 30.98 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:11<00:29, 22.48it/s, est. speed input: 31431.07 toks/s, output: 30.69 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:12<00:29, 22.27it/s, est. speed input: 31155.60 toks/s, output: 30.43 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:12<00:29, 22.13it/s, est. speed input: 30896.64 toks/s, output: 30.17 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:12<00:28, 22.12it/s, est. speed input: 30664.43 toks/s, output: 29.95 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:13<00:28, 22.46it/s, est. speed input: 30488.26 toks/s, output: 29.77 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:13<00:27, 22.70it/s, est. speed input: 30320.54 toks/s, output: 29.61 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:13<00:26, 22.87it/s, est. speed input: 30160.25 toks/s, output: 29.45 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:14<00:26, 22.99it/s, est. speed input: 30008.09 toks/s, output: 29.30 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:14<00:25, 23.08it/s, est. speed input: 29862.94 toks/s, output: 29.16 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:14<00:25, 23.13it/s, est. speed input: 29723.40 toks/s, output: 29.03 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:15<00:25, 23.16it/s, est. speed input: 29590.44 toks/s, output: 28.90 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:15<00:24, 23.15it/s, est. speed input: 29459.11 toks/s, output: 28.77 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:16<00:25, 22.62it/s, est. speed input: 29285.22 toks/s, output: 28.60 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:16<00:25, 22.25it/s, est. speed input: 29118.64 toks/s, output: 28.44 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:16<00:24, 22.01it/s, est. speed input: 28959.31 toks/s, output: 28.28 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:17<00:24, 21.83it/s, est. speed input: 28806.88 toks/s, output: 28.13 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:17<00:24, 21.72it/s, est. speed input: 28661.23 toks/s, output: 27.99 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:17<00:24, 21.63it/s, est. speed input: 28521.19 toks/s, output: 27.85 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:18<00:24, 21.58it/s, est. speed input: 28387.20 toks/s, output: 27.72 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:18<00:23, 21.54it/s, est. speed input: 28258.66 toks/s, output: 27.60 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:18<00:23, 21.51it/s, est. speed input: 28135.08 toks/s, output: 27.48 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:19<00:22, 21.49it/s, est. speed input: 28015.72 toks/s, output: 27.36 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:19<00:22, 21.47it/s, est. speed input: 27900.58 toks/s, output: 27.25 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:20<00:22, 21.46it/s, est. speed input: 27790.19 toks/s, output: 27.14 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:20<00:21, 21.45it/s, est. speed input: 27683.59 toks/s, output: 27.03 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:20<00:21, 21.44it/s, est. speed input: 27580.65 toks/s, output: 26.93 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:21<00:21, 21.43it/s, est. speed input: 27481.34 toks/s, output: 26.84 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:21<00:20, 21.43it/s, est. speed input: 27385.49 toks/s, output: 26.74 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:21<00:20, 21.43it/s, est. speed input: 27292.79 toks/s, output: 26.65 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:22<00:19, 21.78it/s, est. speed input: 27228.24 toks/s, output: 26.59 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:22<00:19, 22.19it/s, est. speed input: 27175.55 toks/s, output: 26.54 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:23<00:18, 22.49it/s, est. speed input: 27124.43 toks/s, output: 26.49 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:23<00:17, 22.70it/s, est. speed input: 27074.91 toks/s, output: 26.44 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:23<00:17, 22.73it/s, est. speed input: 27019.85 toks/s, output: 26.39 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:24<00:17, 22.32it/s, est. speed input: 26941.01 toks/s, output: 26.31 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:24<00:17, 22.04it/s, est. speed input: 26864.74 toks/s, output: 26.24 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:24<00:17, 21.87it/s, est. speed input: 26791.42 toks/s, output: 26.16 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:25<00:16, 21.73it/s, est. speed input: 26719.62 toks/s, output: 26.09 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:25<00:16, 21.64it/s, est. speed input: 26649.93 toks/s, output: 26.03 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:25<00:16, 21.58it/s, est. speed input: 26582.44 toks/s, output: 25.96 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:26<00:15, 21.54it/s, est. speed input: 26516.88 toks/s, output: 25.90 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:26<00:15, 21.50it/s, est. speed input: 26452.64 toks/s, output: 25.83 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:27<00:15, 21.48it/s, est. speed input: 26390.41 toks/s, output: 25.77 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:27<00:14, 21.46it/s, est. speed input: 26329.91 toks/s, output: 25.71 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:27<00:14, 21.45it/s, est. speed input: 26270.99 toks/s, output: 25.66 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:28<00:14, 21.43it/s, est. speed input: 26213.31 toks/s, output: 25.60 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:28<00:13, 21.43it/s, est. speed input: 26157.26 toks/s, output: 25.54 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:28<00:13, 21.47it/s, est. speed input: 26105.25 toks/s, output: 25.49 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:29<00:12, 21.97it/s, est. speed input: 26077.71 toks/s, output: 25.47 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:29<00:12, 22.32it/s, est. speed input: 26050.81 toks/s, output: 25.44 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:29<00:11, 22.58it/s, est. speed input: 26024.56 toks/s, output: 25.41 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:30<00:11, 22.78it/s, est. speed input: 25999.17 toks/s, output: 25.39 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:30<00:10, 22.91it/s, est. speed input: 25974.24 toks/s, output: 25.37 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:30<00:10, 23.65it/s, est. speed input: 25976.64 toks/s, output: 25.37 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:31<00:09, 23.52it/s, est. speed input: 25952.21 toks/s, output: 25.34 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:31<00:09, 23.43it/s, est. speed input: 25928.52 toks/s, output: 25.32 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:32<00:09, 22.81it/s, est. speed input: 25882.90 toks/s, output: 25.28 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:32<00:09, 22.38it/s, est. speed input: 25837.65 toks/s, output: 25.23 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:32<00:08, 22.08it/s, est. speed input: 25793.03 toks/s, output: 25.19 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:33<00:08, 21.88it/s, est. speed input: 25749.55 toks/s, output: 25.15 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:33<00:08, 21.74it/s, est. speed input: 25707.21 toks/s, output: 25.10 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:33<00:08, 21.64it/s, est. speed input: 25665.63 toks/s, output: 25.06 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:34<00:07, 21.58it/s, est. speed input: 25625.28 toks/s, output: 25.02 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:34<00:07, 21.54it/s, est. speed input: 25585.70 toks/s, output: 24.99 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:35<00:06, 21.50it/s, est. speed input: 25546.62 toks/s, output: 24.95 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:35<00:06, 21.48it/s, est. speed input: 25508.58 toks/s, output: 24.91 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:35<00:06, 21.46it/s, est. speed input: 25471.22 toks/s, output: 24.87 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:36<00:05, 21.45it/s, est. speed input: 25434.78 toks/s, output: 24.84 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:36<00:05, 21.43it/s, est. speed input: 25398.73 toks/s, output: 24.80 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:36<00:05, 21.86it/s, est. speed input: 25380.56 toks/s, output: 24.79 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:37<00:04, 22.24it/s, est. speed input: 25365.43 toks/s, output: 24.77 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:37<00:04, 22.53it/s, est. speed input: 25350.90 toks/s, output: 24.76 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:37<00:03, 22.73it/s, est. speed input: 25336.50 toks/s, output: 24.74 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:38<00:00, 63.32it/s, est. speed input: 26343.88 toks/s, output: 25.73 toks/s]
Processed prompts:  97%|█████████▋| 991/1024 [00:38<00:00, 54.45it/s, est. speed input: 26454.27 toks/s, output: 25.83 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:39<00:00, 35.28it/s, est. speed input: 26275.80 toks/s, output: 25.66 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:39<00:00, 32.10it/s, est. speed input: 26253.55 toks/s, output: 25.64 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:39<00:00, 30.66it/s, est. speed input: 26258.62 toks/s, output: 25.64 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 30.66it/s, est. speed input: 26413.22 toks/s, output: 25.79 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 25.79it/s, est. speed input: 26413.22 toks/s, output: 25.79 toks/s]
[rank0]:[W126 00:43:20.847356498 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 107.2s

测试结果:
  Requests/s:   21.80
  Tokens/s:     22339.96
  Total Reqs:   1024
  Elapsed:      46.98s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     22318.17

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:43:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:43:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=609891) WARNING 01-26 00:43:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=609891) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=609891) WARNING 01-26 00:44:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.48 requests/s, 10743.04 total tokens/s, 10.48 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 00:43:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:43:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:43:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:43:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:43:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:43:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:43:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:43:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:43:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:43:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:43:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:43:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:43:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:43:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:43:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:43:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:43:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=609891) [2026-01-26 00:43:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=609891) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=609891) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.04s/it]
(EngineCore_DP0 pid=609891) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.36s/it]
(EngineCore_DP0 pid=609891) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.31s/it]
(EngineCore_DP0 pid=609891) 
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=609891) [2026-01-26 00:44:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=609891) [rank0]:W0126 00:44:19.598000 609891 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=609891) [rank0]:W0126 00:44:19.716000 609891 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=609891) [rank0]:W0126 00:44:20.095000 609891 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=609891) [rank0]:W0126 00:44:20.284000 609891 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=609891) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:03,  1.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:02,  2.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:01<00:02,  2.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:01,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  3.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:02<00:00,  4.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:02<00:00,  3.37it/s]
(EngineCore_DP0 pid=609891) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  6.93it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  7.90it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.20it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.36it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.17it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 22/2048 [00:00<00:09, 219.12it/s]
Adding requests:   2%|▏         | 48/2048 [00:00<00:08, 238.60it/s]
Adding requests:   4%|▎         | 74/2048 [00:00<00:08, 245.64it/s]
Adding requests:   5%|▍         | 99/2048 [00:00<00:07, 246.87it/s]
Adding requests:   6%|▌         | 125/2048 [00:00<00:07, 251.43it/s]
Adding requests:   7%|▋         | 151/2048 [00:00<00:07, 244.87it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:07, 247.09it/s]
Adding requests:  10%|▉         | 204/2048 [00:00<00:07, 251.13it/s]
Adding requests:  11%|█▏        | 231/2048 [00:00<00:07, 255.29it/s]
Adding requests:  13%|█▎        | 257/2048 [00:01<00:07, 251.63it/s]
Adding requests:  14%|█▍        | 283/2048 [00:01<00:07, 251.07it/s]
Adding requests:  15%|█▌        | 309/2048 [00:01<00:06, 252.72it/s]
Adding requests:  16%|█▋        | 335/2048 [00:01<00:06, 252.89it/s]
Adding requests:  18%|█▊        | 361/2048 [00:01<00:06, 248.66it/s]
Adding requests:  19%|█▉        | 386/2048 [00:01<00:06, 245.29it/s]
Adding requests:  20%|██        | 411/2048 [00:01<00:06, 241.38it/s]
Adding requests:  21%|██▏       | 436/2048 [00:01<00:06, 235.33it/s]
Adding requests:  22%|██▏       | 460/2048 [00:01<00:06, 229.93it/s]
Adding requests:  24%|██▎       | 485/2048 [00:01<00:06, 233.81it/s]
Adding requests:  25%|██▍       | 509/2048 [00:02<00:06, 232.32it/s]
Adding requests:  26%|██▌       | 533/2048 [00:02<00:06, 232.12it/s]
Adding requests:  27%|██▋       | 557/2048 [00:02<00:06, 227.72it/s]
Adding requests:  28%|██▊       | 580/2048 [00:02<00:06, 224.53it/s]
Adding requests:  29%|██▉       | 603/2048 [00:02<00:06, 216.81it/s]
Adding requests:  31%|███       | 626/2048 [00:02<00:06, 219.54it/s]
Adding requests:  32%|███▏      | 649/2048 [00:02<00:06, 214.92it/s]
Adding requests:  33%|███▎      | 671/2048 [00:02<00:06, 214.20it/s]
Adding requests:  34%|███▍      | 694/2048 [00:02<00:06, 216.90it/s]
Adding requests:  35%|███▌      | 717/2048 [00:03<00:06, 218.56it/s]
Adding requests:  36%|███▌      | 739/2048 [00:03<00:06, 214.68it/s]
Adding requests:  37%|███▋      | 761/2048 [00:03<00:06, 212.14it/s]
Adding requests:  38%|███▊      | 785/2048 [00:03<00:05, 218.58it/s]
Adding requests:  39%|███▉      | 807/2048 [00:03<00:05, 215.98it/s]
Adding requests:  41%|████      | 831/2048 [00:03<00:05, 220.72it/s]
Adding requests:  42%|████▏     | 854/2048 [00:03<00:05, 212.14it/s]
Adding requests:  43%|████▎     | 877/2048 [00:03<00:05, 215.08it/s]
Adding requests:  44%|████▍     | 902/2048 [00:03<00:05, 223.95it/s]
Adding requests:  45%|████▌     | 925/2048 [00:04<00:05, 221.92it/s]
Adding requests:  46%|████▋     | 948/2048 [00:04<00:04, 222.98it/s]
Adding requests:  47%|████▋     | 971/2048 [00:04<00:04, 224.52it/s]
Adding requests:  49%|████▊     | 994/2048 [00:04<00:04, 221.27it/s]
Adding requests:  50%|████▉     | 1017/2048 [00:04<00:04, 223.75it/s]
Adding requests:  51%|█████     | 1041/2048 [00:04<00:04, 224.23it/s]
Adding requests:  52%|█████▏    | 1064/2048 [00:04<00:04, 221.40it/s]
Adding requests:  53%|█████▎    | 1087/2048 [00:04<00:04, 218.73it/s]
Adding requests:  54%|█████▍    | 1109/2048 [00:04<00:04, 217.80it/s]
Adding requests:  55%|█████▌    | 1133/2048 [00:04<00:04, 223.88it/s]
Adding requests:  56%|█████▋    | 1156/2048 [00:05<00:04, 216.22it/s]
Adding requests:  58%|█████▊    | 1178/2048 [00:05<00:04, 216.31it/s]
Adding requests:  59%|█████▊    | 1200/2048 [00:05<00:03, 214.74it/s]
Adding requests:  60%|█████▉    | 1225/2048 [00:05<00:03, 222.76it/s]
Adding requests:  61%|██████    | 1248/2048 [00:05<00:03, 219.04it/s]
Adding requests:  62%|██████▏   | 1270/2048 [00:05<00:03, 218.30it/s]
Adding requests:  63%|██████▎   | 1292/2048 [00:05<00:03, 213.55it/s]
Adding requests:  64%|██████▍   | 1315/2048 [00:05<00:03, 216.30it/s]
Adding requests:  65%|██████▌   | 1338/2048 [00:05<00:03, 217.76it/s]
Adding requests:  67%|██████▋   | 1362/2048 [00:05<00:03, 223.04it/s]
Adding requests:  68%|██████▊   | 1385/2048 [00:06<00:02, 221.27it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:06<00:02, 220.30it/s]
Adding requests:  70%|██████▉   | 1431/2048 [00:06<00:02, 219.21it/s]
Adding requests:  71%|███████   | 1454/2048 [00:06<00:02, 221.41it/s]
Adding requests:  72%|███████▏  | 1477/2048 [00:06<00:02, 223.59it/s]
Adding requests:  73%|███████▎  | 1500/2048 [00:06<00:02, 223.75it/s]
Adding requests:  74%|███████▍  | 1523/2048 [00:06<00:02, 223.66it/s]
Adding requests:  75%|███████▌  | 1546/2048 [00:06<00:02, 216.76it/s]
Adding requests:  77%|███████▋  | 1568/2048 [00:06<00:02, 212.13it/s]
Adding requests:  78%|███████▊  | 1592/2048 [00:07<00:02, 219.06it/s]
Adding requests:  79%|███████▉  | 1616/2048 [00:07<00:01, 224.65it/s]
Adding requests:  80%|████████  | 1639/2048 [00:07<00:01, 225.97it/s]
Adding requests:  81%|████████  | 1662/2048 [00:07<00:01, 225.00it/s]
Adding requests:  82%|████████▏ | 1687/2048 [00:07<00:01, 231.76it/s]
Adding requests:  84%|████████▎ | 1714/2048 [00:07<00:01, 240.99it/s]
Adding requests:  85%|████████▍ | 1739/2048 [00:07<00:01, 242.31it/s]
Adding requests:  86%|████████▌ | 1766/2048 [00:07<00:01, 249.36it/s]
Adding requests:  87%|████████▋ | 1791/2048 [00:07<00:01, 245.02it/s]
Adding requests:  89%|████████▊ | 1816/2048 [00:07<00:00, 243.07it/s]
Adding requests:  90%|████████▉ | 1841/2048 [00:08<00:00, 241.92it/s]
Adding requests:  91%|█████████ | 1866/2048 [00:08<00:00, 241.83it/s]
Adding requests:  92%|█████████▏| 1891/2048 [00:08<00:00, 242.14it/s]
Adding requests:  94%|█████████▎| 1916/2048 [00:08<00:00, 241.44it/s]
Adding requests:  95%|█████████▍| 1941/2048 [00:08<00:00, 242.62it/s]
Adding requests:  96%|█████████▌| 1966/2048 [00:08<00:00, 241.62it/s]
Adding requests:  97%|█████████▋| 1991/2048 [00:08<00:00, 240.70it/s]
Adding requests:  98%|█████████▊| 2016/2048 [00:08<00:00, 237.01it/s]
Adding requests: 100%|█████████▉| 2040/2048 [00:08<00:00, 227.46it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 228.78it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:00<00:16, 121.82it/s, est. speed input: 124753.17 toks/s, output: 121.83 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:02<00:54, 36.01it/s, est. speed input: 44800.32 toks/s, output: 43.75 toks/s]   
Processed prompts:   6%|▌         | 114/2048 [00:03<01:25, 22.51it/s, est. speed input: 30667.00 toks/s, output: 29.95 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:05<01:51, 17.24it/s, est. speed input: 24769.14 toks/s, output: 24.19 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:06<02:07, 14.94it/s, est. speed input: 21857.18 toks/s, output: 21.34 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:08<02:18, 13.63it/s, est. speed input: 20019.56 toks/s, output: 19.55 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:09<02:29, 12.54it/s, est. speed input: 18560.55 toks/s, output: 18.13 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:11<01:58, 15.54it/s, est. speed input: 19083.01 toks/s, output: 18.64 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:12<02:12, 13.80it/s, est. speed input: 18028.32 toks/s, output: 17.61 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:14<02:21, 12.75it/s, est. speed input: 17246.57 toks/s, output: 16.84 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:15<02:26, 12.24it/s, est. speed input: 16703.63 toks/s, output: 16.31 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:17<02:30, 11.78it/s, est. speed input: 16210.48 toks/s, output: 15.83 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:18<02:35, 11.28it/s, est. speed input: 15730.84 toks/s, output: 15.36 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:20<02:39, 10.93it/s, est. speed input: 15319.04 toks/s, output: 14.96 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:22<02:41, 10.71it/s, est. speed input: 14971.78 toks/s, output: 14.62 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:23<02:40, 10.69it/s, est. speed input: 14711.27 toks/s, output: 14.37 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:24<02:37, 10.76it/s, est. speed input: 14505.06 toks/s, output: 14.17 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:26<02:38, 10.58it/s, est. speed input: 14264.57 toks/s, output: 13.93 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:28<02:38, 10.46it/s, est. speed input: 14050.95 toks/s, output: 13.72 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:29<02:38, 10.38it/s, est. speed input: 13860.02 toks/s, output: 13.54 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:31<02:35, 10.49it/s, est. speed input: 13725.22 toks/s, output: 13.40 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:32<02:31, 10.65it/s, est. speed input: 13617.48 toks/s, output: 13.30 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:34<02:31, 10.54it/s, est. speed input: 13477.64 toks/s, output: 13.16 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:35<02:31, 10.43it/s, est. speed input: 13343.89 toks/s, output: 13.03 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:37<02:31, 10.36it/s, est. speed input: 13221.23 toks/s, output: 12.91 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:38<02:27, 10.53it/s, est. speed input: 13145.07 toks/s, output: 12.84 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:40<02:23, 10.67it/s, est. speed input: 13078.56 toks/s, output: 12.77 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:41<02:22, 10.63it/s, est. speed input: 12994.61 toks/s, output: 12.69 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:43<01:46, 13.89it/s, est. speed input: 13308.22 toks/s, output: 13.00 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:44<01:55, 12.74it/s, est. speed input: 13207.26 toks/s, output: 12.90 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:46<02:00, 12.05it/s, est. speed input: 13124.65 toks/s, output: 12.82 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:47<02:02, 11.76it/s, est. speed input: 13069.19 toks/s, output: 12.76 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:49<02:03, 11.47it/s, est. speed input: 13008.79 toks/s, output: 12.70 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:50<02:07, 11.07it/s, est. speed input: 12928.81 toks/s, output: 12.63 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:52<02:08, 10.80it/s, est. speed input: 12853.72 toks/s, output: 12.55 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:53<02:09, 10.61it/s, est. speed input: 12783.07 toks/s, output: 12.48 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:55<02:08, 10.55it/s, est. speed input: 12724.02 toks/s, output: 12.43 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:56<02:05, 10.67it/s, est. speed input: 12685.99 toks/s, output: 12.39 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:58<02:06, 10.52it/s, est. speed input: 12625.30 toks/s, output: 12.33 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [01:00<02:05, 10.42it/s, est. speed input: 12567.71 toks/s, output: 12.27 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [01:01<02:05, 10.34it/s, est. speed input: 12513.10 toks/s, output: 12.22 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [01:03<02:01, 10.50it/s, est. speed input: 12481.74 toks/s, output: 12.19 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [01:04<01:53, 11.09it/s, est. speed input: 12493.04 toks/s, output: 12.20 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [01:05<01:54, 10.89it/s, est. speed input: 12451.48 toks/s, output: 12.16 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [01:07<01:55, 10.67it/s, est. speed input: 12404.33 toks/s, output: 12.11 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:09<01:55, 10.52it/s, est. speed input: 12359.25 toks/s, output: 12.07 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:10<01:53, 10.55it/s, est. speed input: 12327.78 toks/s, output: 12.04 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:12<01:50, 10.69it/s, est. speed input: 12306.91 toks/s, output: 12.02 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:13<01:18, 14.62it/s, est. speed input: 12544.33 toks/s, output: 12.25 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:14<01:25, 13.29it/s, est. speed input: 12505.44 toks/s, output: 12.21 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:16<01:30, 12.39it/s, est. speed input: 12468.06 toks/s, output: 12.18 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:17<01:33, 11.78it/s, est. speed input: 12432.21 toks/s, output: 12.14 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:19<01:34, 11.46it/s, est. speed input: 12404.64 toks/s, output: 12.11 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:20<01:34, 11.33it/s, est. speed input: 12384.67 toks/s, output: 12.09 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:22<01:35, 10.99it/s, est. speed input: 12348.74 toks/s, output: 12.06 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:23<01:36, 10.74it/s, est. speed input: 12312.72 toks/s, output: 12.02 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:25<01:36, 10.57it/s, est. speed input: 12277.92 toks/s, output: 11.99 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:27<01:36, 10.45it/s, est. speed input: 12244.46 toks/s, output: 11.96 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:28<01:33, 10.61it/s, est. speed input: 12228.58 toks/s, output: 11.94 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:30<01:32, 10.55it/s, est. speed input: 12201.85 toks/s, output: 11.92 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:31<01:31, 10.44it/s, est. speed input: 12171.28 toks/s, output: 11.89 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:33<01:30, 10.36it/s, est. speed input: 12141.82 toks/s, output: 11.86 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:34<01:29, 10.36it/s, est. speed input: 12116.96 toks/s, output: 11.83 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:36<01:26, 10.55it/s, est. speed input: 12104.48 toks/s, output: 11.82 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:37<01:24, 10.57it/s, est. speed input: 12085.52 toks/s, output: 11.80 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:39<01:24, 10.45it/s, est. speed input: 12059.19 toks/s, output: 11.78 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:40<01:23, 10.37it/s, est. speed input: 12033.65 toks/s, output: 11.75 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:42<01:21, 10.37it/s, est. speed input: 12012.29 toks/s, output: 11.73 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:43<00:57, 14.17it/s, est. speed input: 12178.56 toks/s, output: 11.89 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:45<01:00, 13.21it/s, est. speed input: 12165.16 toks/s, output: 11.88 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:46<01:03, 12.25it/s, est. speed input: 12139.53 toks/s, output: 11.86 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:48<01:05, 11.61it/s, est. speed input: 12114.66 toks/s, output: 11.83 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [01:49<01:07, 11.17it/s, est. speed input: 12090.46 toks/s, output: 11.81 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:51<01:06, 11.04it/s, est. speed input: 12075.45 toks/s, output: 11.79 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:52<01:05, 11.03it/s, est. speed input: 12065.38 toks/s, output: 11.78 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:54<01:04, 10.81it/s, est. speed input: 12044.98 toks/s, output: 11.76 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:56<01:04, 10.62it/s, est. speed input: 12022.97 toks/s, output: 11.74 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:57<01:03, 10.48it/s, est. speed input: 12001.56 toks/s, output: 11.72 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:59<01:02, 10.48it/s, est. speed input: 11985.26 toks/s, output: 11.70 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [02:00<00:59, 10.64it/s, est. speed input: 11976.89 toks/s, output: 11.70 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [02:02<00:58, 10.60it/s, est. speed input: 11961.89 toks/s, output: 11.68 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [02:03<00:57, 10.47it/s, est. speed input: 11942.30 toks/s, output: 11.66 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [02:05<00:56, 10.38it/s, est. speed input: 11923.22 toks/s, output: 11.64 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [02:06<00:55, 10.37it/s, est. speed input: 11907.08 toks/s, output: 11.63 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [02:08<00:52, 10.56it/s, est. speed input: 11900.08 toks/s, output: 11.62 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [02:09<00:51, 10.61it/s, est. speed input: 11889.67 toks/s, output: 11.61 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [02:11<00:50, 10.48it/s, est. speed input: 11872.05 toks/s, output: 11.59 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [02:12<00:49, 10.39it/s, est. speed input: 11854.88 toks/s, output: 11.58 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [02:14<00:47, 10.32it/s, est. speed input: 11838.08 toks/s, output: 11.56 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:15<00:32, 14.18it/s, est. speed input: 11968.48 toks/s, output: 11.69 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [02:17<00:33, 13.24it/s, est. speed input: 11961.27 toks/s, output: 11.68 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [02:18<00:33, 12.84it/s, est. speed input: 11962.81 toks/s, output: 11.68 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [02:20<00:34, 11.99it/s, est. speed input: 11945.48 toks/s, output: 11.67 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [02:21<00:34, 11.42it/s, est. speed input: 11928.56 toks/s, output: 11.65 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [02:23<00:34, 11.08it/s, est. speed input: 11913.90 toks/s, output: 11.63 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [02:24<00:33, 11.07it/s, est. speed input: 11907.64 toks/s, output: 11.63 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [02:26<00:32, 10.90it/s, est. speed input: 11895.80 toks/s, output: 11.62 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [02:27<00:31, 10.68it/s, est. speed input: 11880.12 toks/s, output: 11.60 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [02:29<00:30, 10.52it/s, est. speed input: 11864.77 toks/s, output: 11.59 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [02:30<00:28, 10.44it/s, est. speed input: 11850.66 toks/s, output: 11.57 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [02:32<00:26, 10.61it/s, est. speed input: 11845.34 toks/s, output: 11.57 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [02:33<00:25, 10.65it/s, est. speed input: 11837.10 toks/s, output: 11.56 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:35<00:24, 10.50it/s, est. speed input: 11822.80 toks/s, output: 11.55 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:36<00:22, 10.40it/s, est. speed input: 11808.79 toks/s, output: 11.53 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:38<00:21, 10.33it/s, est. speed input: 11795.02 toks/s, output: 11.52 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [02:39<00:19, 10.53it/s, est. speed input: 11790.33 toks/s, output: 11.51 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:41<00:17, 10.66it/s, est. speed input: 11785.24 toks/s, output: 11.51 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:43<00:16, 10.51it/s, est. speed input: 11772.11 toks/s, output: 11.50 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [02:44<00:15, 10.41it/s, est. speed input: 11759.23 toks/s, output: 11.48 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [02:46<00:09, 13.46it/s, est. speed input: 11845.70 toks/s, output: 11.57 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:47<00:08, 12.64it/s, est. speed input: 11837.62 toks/s, output: 11.56 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:49<00:07, 12.18it/s, est. speed input: 11832.92 toks/s, output: 11.56 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:50<00:06, 11.61it/s, est. speed input: 11821.44 toks/s, output: 11.54 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [02:52<00:05, 11.17it/s, est. speed input: 11808.64 toks/s, output: 11.53 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:53<00:04, 10.87it/s, est. speed input: 11796.09 toks/s, output: 11.52 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:55<00:02, 10.69it/s, est. speed input: 11784.80 toks/s, output: 11.51 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:56<00:01, 11.25it/s, est. speed input: 11794.74 toks/s, output: 11.52 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:56<00:00, 11.25it/s, est. speed input: 11875.90 toks/s, output: 11.60 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:56<00:00, 11.60it/s, est. speed input: 11875.90 toks/s, output: 11.60 toks/s]
[rank0]:[W126 00:47:36.498821457 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 256.4s

测试结果:
  Requests/s:   10.48
  Tokens/s:     10743.04
  Total Reqs:   2048
  Elapsed:      195.40s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     10732.56

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 00:48:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 00:48:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=613648) WARNING 01-26 00:48:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=613648) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=613648) WARNING 01-26 00:48:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.22 requests/s, 5354.36 total tokens/s, 5.22 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 00:48:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:48:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:48:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:48:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:48:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:48:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:48:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:48:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 00:48:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 00:48:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:48:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 00:48:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 00:48:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 00:48:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 00:48:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 00:48:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 00:48:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=613648) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=613648) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.09s/it]
(EngineCore_DP0 pid=613648) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.39s/it]
(EngineCore_DP0 pid=613648) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.35s/it]
(EngineCore_DP0 pid=613648) 
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=613648) [2026-01-26 00:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=613648) [rank0]:W0126 00:48:52.219000 613648 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=613648) [rank0]:W0126 00:48:52.338000 613648 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=613648) [rank0]:W0126 00:48:54.509000 613648 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=613648) [rank0]:W0126 00:48:54.698000 613648 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=613648) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:07,  1.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  1.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:01<00:04,  1.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:02,  2.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:02<00:01,  3.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:02<00:01,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:02<00:00,  5.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:02<00:00,  5.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  6.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  6.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  3.97it/s]
(EngineCore_DP0 pid=613648) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.82it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  7.55it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.07it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  6.78it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:01<00:00,  3.31it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  4.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  4.89it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/4096 [00:00<00:17, 228.17it/s]
Adding requests:   1%|          | 49/4096 [00:00<00:16, 243.66it/s]
Adding requests:   2%|▏         | 76/4096 [00:00<00:15, 252.33it/s]
Adding requests:   2%|▏         | 102/4096 [00:00<00:15, 252.65it/s]
Adding requests:   3%|▎         | 128/4096 [00:00<00:15, 252.08it/s]
Adding requests:   4%|▍         | 154/4096 [00:00<00:15, 251.49it/s]
Adding requests:   4%|▍         | 182/4096 [00:00<00:15, 259.69it/s]
Adding requests:   5%|▌         | 208/4096 [00:00<00:14, 259.66it/s]
Adding requests:   6%|▌         | 234/4096 [00:00<00:15, 251.28it/s]
Adding requests:   6%|▋         | 260/4096 [00:01<00:15, 241.34it/s]
Adding requests:   7%|▋         | 285/4096 [00:01<00:15, 241.71it/s]
Adding requests:   8%|▊         | 310/4096 [00:01<00:15, 243.53it/s]
Adding requests:   8%|▊         | 336/4096 [00:01<00:15, 247.22it/s]
Adding requests:   9%|▉         | 361/4096 [00:01<00:15, 243.59it/s]
Adding requests:   9%|▉         | 386/4096 [00:01<00:15, 245.04it/s]
Adding requests:  10%|█         | 413/4096 [00:01<00:14, 249.77it/s]
Adding requests:  11%|█         | 439/4096 [00:01<00:15, 238.60it/s]
Adding requests:  11%|█▏        | 463/4096 [00:01<00:16, 224.18it/s]
Adding requests:  12%|█▏        | 491/4096 [00:02<00:15, 236.51it/s]
Adding requests:  13%|█▎        | 515/4096 [00:02<00:15, 232.58it/s]
Adding requests:  13%|█▎        | 541/4096 [00:02<00:15, 236.69it/s]
Adding requests:  14%|█▍        | 565/4096 [00:02<00:15, 233.30it/s]
Adding requests:  14%|█▍        | 589/4096 [00:02<00:15, 231.10it/s]
Adding requests:  15%|█▍        | 614/4096 [00:02<00:14, 235.82it/s]
Adding requests:  16%|█▌        | 640/4096 [00:02<00:14, 240.52it/s]
Adding requests:  16%|█▌        | 665/4096 [00:02<00:15, 225.60it/s]
Adding requests:  17%|█▋        | 690/4096 [00:02<00:14, 231.85it/s]
Adding requests:  17%|█▋        | 714/4096 [00:02<00:14, 234.06it/s]
Adding requests:  18%|█▊        | 738/4096 [00:03<00:14, 234.34it/s]
Adding requests:  19%|█▊        | 762/4096 [00:03<00:15, 216.90it/s]
Adding requests:  19%|█▉        | 785/4096 [00:03<00:15, 219.30it/s]
Adding requests:  20%|█▉        | 809/4096 [00:03<00:14, 222.88it/s]
Adding requests:  20%|██        | 836/4096 [00:03<00:13, 235.69it/s]
Adding requests:  21%|██        | 860/4096 [00:03<00:14, 224.41it/s]
Adding requests:  22%|██▏       | 883/4096 [00:03<00:14, 221.30it/s]
Adding requests:  22%|██▏       | 908/4096 [00:03<00:13, 228.17it/s]
Adding requests:  23%|██▎       | 931/4096 [00:03<00:13, 228.17it/s]
Adding requests:  23%|██▎       | 954/4096 [00:04<00:13, 226.04it/s]
Adding requests:  24%|██▍       | 977/4096 [00:04<00:14, 216.22it/s]
Adding requests:  24%|██▍       | 999/4096 [00:04<00:14, 217.17it/s]
Adding requests:  25%|██▍       | 1023/4096 [00:04<00:13, 223.04it/s]
Adding requests:  26%|██▌       | 1046/4096 [00:04<00:13, 219.75it/s]
Adding requests:  26%|██▌       | 1069/4096 [00:04<00:14, 210.99it/s]
Adding requests:  27%|██▋       | 1092/4096 [00:04<00:13, 214.99it/s]
Adding requests:  27%|██▋       | 1117/4096 [00:04<00:13, 222.60it/s]
Adding requests:  28%|██▊       | 1142/4096 [00:04<00:12, 228.97it/s]
Adding requests:  28%|██▊       | 1165/4096 [00:05<00:13, 210.92it/s]
Adding requests:  29%|██▉       | 1188/4096 [00:05<00:13, 214.86it/s]
Adding requests:  30%|██▉       | 1211/4096 [00:05<00:13, 218.45it/s]
Adding requests:  30%|███       | 1235/4096 [00:05<00:12, 221.03it/s]
Adding requests:  31%|███       | 1258/4096 [00:05<00:13, 213.68it/s]
Adding requests:  31%|███▏      | 1280/4096 [00:05<00:13, 213.82it/s]
Adding requests:  32%|███▏      | 1303/4096 [00:05<00:12, 218.06it/s]
Adding requests:  32%|███▏      | 1328/4096 [00:05<00:12, 225.25it/s]
Adding requests:  33%|███▎      | 1351/4096 [00:05<00:12, 220.99it/s]
Adding requests:  34%|███▎      | 1374/4096 [00:05<00:12, 221.48it/s]
Adding requests:  34%|███▍      | 1399/4096 [00:06<00:11, 229.65it/s]
Adding requests:  35%|███▍      | 1424/4096 [00:06<00:11, 233.33it/s]
Adding requests:  35%|███▌      | 1448/4096 [00:06<00:11, 228.75it/s]
Adding requests:  36%|███▌      | 1471/4096 [00:06<00:11, 223.19it/s]
Adding requests:  37%|███▋      | 1497/4096 [00:06<00:11, 232.61it/s]
Adding requests:  37%|███▋      | 1523/4096 [00:06<00:10, 237.91it/s]
Adding requests:  38%|███▊      | 1547/4096 [00:06<00:10, 234.73it/s]
Adding requests:  38%|███▊      | 1571/4096 [00:06<00:11, 213.74it/s]
Adding requests:  39%|███▉      | 1596/4096 [00:06<00:11, 220.89it/s]
Adding requests:  40%|███▉      | 1619/4096 [00:07<00:11, 221.90it/s]
Adding requests:  40%|████      | 1642/4096 [00:07<00:11, 219.38it/s]
Adding requests:  41%|████      | 1665/4096 [00:07<00:11, 208.51it/s]
Adding requests:  41%|████▏     | 1693/4096 [00:07<00:10, 226.12it/s]
Adding requests:  42%|████▏     | 1720/4096 [00:07<00:09, 237.63it/s]
Adding requests:  43%|████▎     | 1745/4096 [00:07<00:09, 240.85it/s]
Adding requests:  43%|████▎     | 1770/4096 [00:07<00:09, 237.33it/s]
Adding requests:  44%|████▍     | 1795/4096 [00:07<00:09, 240.77it/s]
Adding requests:  44%|████▍     | 1820/4096 [00:07<00:09, 242.52it/s]
Adding requests:  45%|████▌     | 1847/4096 [00:07<00:09, 248.79it/s]
Adding requests:  46%|████▌     | 1872/4096 [00:08<00:09, 240.81it/s]
Adding requests:  46%|████▋     | 1898/4096 [00:08<00:08, 245.37it/s]
Adding requests:  47%|████▋     | 1926/4096 [00:08<00:08, 255.00it/s]
Adding requests:  48%|████▊     | 1954/4096 [00:08<00:08, 260.78it/s]
Adding requests:  48%|████▊     | 1981/4096 [00:08<00:08, 245.44it/s]
Adding requests:  49%|████▉     | 2006/4096 [00:08<00:08, 245.96it/s]
Adding requests:  50%|████▉     | 2031/4096 [00:08<00:08, 245.23it/s]
Adding requests:  50%|█████     | 2056/4096 [00:08<00:08, 241.06it/s]
Adding requests:  51%|█████     | 2081/4096 [00:08<00:09, 222.99it/s]
Adding requests:  51%|█████▏    | 2108/4096 [00:09<00:08, 233.45it/s]
Adding requests:  52%|█████▏    | 2132/4096 [00:09<00:08, 231.69it/s]
Adding requests:  53%|█████▎    | 2156/4096 [00:09<00:08, 231.72it/s]
Adding requests:  53%|█████▎    | 2180/4096 [00:09<00:08, 221.72it/s]
Adding requests:  54%|█████▍    | 2204/4096 [00:09<00:08, 225.10it/s]
Adding requests:  54%|█████▍    | 2229/4096 [00:09<00:08, 229.87it/s]
Adding requests:  55%|█████▌    | 2255/4096 [00:09<00:07, 237.82it/s]
Adding requests:  56%|█████▌    | 2279/4096 [00:09<00:08, 223.05it/s]
Adding requests:  56%|█████▋    | 2304/4096 [00:09<00:07, 229.67it/s]
Adding requests:  57%|█████▋    | 2330/4096 [00:10<00:07, 235.28it/s]
Adding requests:  58%|█████▊    | 2357/4096 [00:10<00:07, 241.87it/s]
Adding requests:  58%|█████▊    | 2382/4096 [00:10<00:07, 233.78it/s]
Adding requests:  59%|█████▊    | 2406/4096 [00:10<00:07, 230.95it/s]
Adding requests:  59%|█████▉    | 2432/4096 [00:10<00:06, 238.51it/s]
Adding requests:  60%|█████▉    | 2456/4096 [00:10<00:07, 228.82it/s]
Adding requests:  61%|██████    | 2480/4096 [00:10<00:07, 219.75it/s]
Adding requests:  61%|██████    | 2504/4096 [00:10<00:07, 223.09it/s]
Adding requests:  62%|██████▏   | 2531/4096 [00:10<00:06, 235.87it/s]
Adding requests:  62%|██████▏   | 2559/4096 [00:11<00:06, 246.29it/s]
Adding requests:  63%|██████▎   | 2584/4096 [00:11<00:06, 236.51it/s]
Adding requests:  64%|██████▎   | 2608/4096 [00:11<00:06, 227.00it/s]
Adding requests:  64%|██████▍   | 2632/4096 [00:11<00:06, 229.50it/s]
Adding requests:  65%|██████▍   | 2657/4096 [00:11<00:06, 234.82it/s]
Adding requests:  65%|██████▌   | 2681/4096 [00:11<00:06, 226.14it/s]
Adding requests:  66%|██████▌   | 2704/4096 [00:11<00:06, 217.59it/s]
Adding requests:  67%|██████▋   | 2728/4096 [00:11<00:06, 222.60it/s]
Adding requests:  67%|██████▋   | 2754/4096 [00:11<00:05, 233.15it/s]
Adding requests:  68%|██████▊   | 2778/4096 [00:11<00:05, 230.21it/s]
Adding requests:  68%|██████▊   | 2802/4096 [00:12<00:05, 232.64it/s]
Adding requests:  69%|██████▉   | 2828/4096 [00:12<00:05, 239.96it/s]
Adding requests:  70%|██████▉   | 2855/4096 [00:12<00:05, 247.99it/s]
Adding requests:  70%|███████   | 2881/4096 [00:12<00:04, 247.96it/s]
Adding requests:  71%|███████   | 2906/4096 [00:12<00:05, 235.54it/s]
Adding requests:  72%|███████▏  | 2931/4096 [00:12<00:04, 236.99it/s]
Adding requests:  72%|███████▏  | 2959/4096 [00:12<00:04, 247.27it/s]
Adding requests:  73%|███████▎  | 2984/4096 [00:12<00:04, 243.45it/s]
Adding requests:  73%|███████▎  | 3009/4096 [00:12<00:04, 232.45it/s]
Adding requests:  74%|███████▍  | 3033/4096 [00:13<00:04, 233.73it/s]
Adding requests:  75%|███████▍  | 3059/4096 [00:13<00:04, 240.06it/s]
Adding requests:  75%|███████▌  | 3085/4096 [00:13<00:04, 244.99it/s]
Adding requests:  76%|███████▌  | 3110/4096 [00:13<00:04, 233.62it/s]
Adding requests:  77%|███████▋  | 3134/4096 [00:13<00:04, 234.34it/s]
Adding requests:  77%|███████▋  | 3158/4096 [00:13<00:04, 231.64it/s]
Adding requests:  78%|███████▊  | 3183/4096 [00:13<00:03, 236.79it/s]
Adding requests:  78%|███████▊  | 3207/4096 [00:13<00:03, 230.54it/s]
Adding requests:  79%|███████▉  | 3231/4096 [00:13<00:03, 227.00it/s]
Adding requests:  79%|███████▉  | 3255/4096 [00:14<00:03, 230.55it/s]
Adding requests:  80%|████████  | 3279/4096 [00:14<00:03, 233.24it/s]
Adding requests:  81%|████████  | 3303/4096 [00:14<00:03, 234.36it/s]
Adding requests:  81%|████████  | 3327/4096 [00:14<00:03, 226.38it/s]
Adding requests:  82%|████████▏ | 3353/4096 [00:14<00:03, 234.96it/s]
Adding requests:  83%|████████▎ | 3381/4096 [00:14<00:02, 245.23it/s]
Adding requests:  83%|████████▎ | 3407/4096 [00:14<00:02, 248.03it/s]
Adding requests:  84%|████████▍ | 3432/4096 [00:14<00:02, 240.98it/s]
Adding requests:  84%|████████▍ | 3459/4096 [00:14<00:02, 248.46it/s]
Adding requests:  85%|████████▌ | 3486/4096 [00:14<00:02, 251.29it/s]
Adding requests:  86%|████████▌ | 3513/4096 [00:15<00:02, 255.78it/s]
Adding requests:  86%|████████▋ | 3539/4096 [00:15<00:02, 249.51it/s]
Adding requests:  87%|████████▋ | 3567/4096 [00:15<00:02, 258.21it/s]
Adding requests:  88%|████████▊ | 3595/4096 [00:15<00:01, 262.53it/s]
Adding requests:  88%|████████▊ | 3622/4096 [00:15<00:01, 261.85it/s]
Adding requests:  89%|████████▉ | 3649/4096 [00:15<00:01, 249.58it/s]
Adding requests:  90%|████████▉ | 3676/4096 [00:15<00:01, 252.96it/s]
Adding requests:  90%|█████████ | 3705/4096 [00:15<00:01, 263.33it/s]
Adding requests:  91%|█████████ | 3732/4096 [00:15<00:01, 255.98it/s]
Adding requests:  92%|█████████▏| 3758/4096 [00:16<00:01, 240.86it/s]
Adding requests:  92%|█████████▏| 3783/4096 [00:16<00:01, 242.21it/s]
Adding requests:  93%|█████████▎| 3808/4096 [00:16<00:01, 240.27it/s]
Adding requests:  94%|█████████▎| 3833/4096 [00:16<00:01, 222.39it/s]
Adding requests:  94%|█████████▍| 3857/4096 [00:16<00:01, 226.55it/s]
Adding requests:  95%|█████████▍| 3884/4096 [00:16<00:00, 236.95it/s]
Adding requests:  95%|█████████▌| 3910/4096 [00:16<00:00, 241.79it/s]
Adding requests:  96%|█████████▌| 3935/4096 [00:16<00:00, 229.99it/s]
Adding requests:  97%|█████████▋| 3959/4096 [00:16<00:00, 230.23it/s]
Adding requests:  97%|█████████▋| 3983/4096 [00:16<00:00, 232.32it/s]
Adding requests:  98%|█████████▊| 4008/4096 [00:17<00:00, 235.11it/s]
Adding requests:  98%|█████████▊| 4032/4096 [00:17<00:00, 221.69it/s]
Adding requests:  99%|█████████▉| 4055/4096 [00:17<00:00, 215.99it/s]
Adding requests: 100%|█████████▉| 4079/4096 [00:17<00:00, 222.23it/s]
Adding requests: 100%|██████████| 4096/4096 [00:17<00:00, 233.90it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 66/4096 [00:02<02:42, 24.78it/s, est. speed input: 25377.77 toks/s, output: 24.78 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:06<05:10, 12.89it/s, est. speed input: 14614.62 toks/s, output: 14.27 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:13<07:58,  8.29it/s, est. speed input: 10172.32 toks/s, output: 9.93 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:19<09:29,  6.90it/s, est. speed input: 8645.65 toks/s, output: 8.44 toks/s] 
Processed prompts:   5%|▍         | 194/4096 [00:25<10:22,  6.26it/s, est. speed input: 7864.84 toks/s, output: 7.68 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:31<10:54,  5.91it/s, est. speed input: 7387.96 toks/s, output: 7.21 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:35<10:18,  6.21it/s, est. speed input: 7356.96 toks/s, output: 7.18 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:41<10:44,  5.91it/s, est. speed input: 7085.50 toks/s, output: 6.92 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:47<11:03,  5.69it/s, est. speed input: 6869.63 toks/s, output: 6.71 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:54<11:17,  5.52it/s, est. speed input: 6690.69 toks/s, output: 6.53 toks/s]
Processed prompts:   9%|▉         | 386/4096 [01:00<11:25,  5.41it/s, est. speed input: 6548.14 toks/s, output: 6.39 toks/s]
Processed prompts:  10%|█         | 418/4096 [01:06<11:24,  5.37it/s, est. speed input: 6444.29 toks/s, output: 6.29 toks/s]
Processed prompts:  11%|█         | 450/4096 [01:10<10:30,  5.78it/s, est. speed input: 6492.19 toks/s, output: 6.34 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:17<10:49,  5.57it/s, est. speed input: 6391.56 toks/s, output: 6.24 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:23<10:55,  5.47it/s, est. speed input: 6317.33 toks/s, output: 6.17 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:29<10:56,  5.41it/s, est. speed input: 6254.59 toks/s, output: 6.11 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:35<10:55,  5.37it/s, est. speed input: 6201.07 toks/s, output: 6.06 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:40<10:04,  5.77it/s, est. speed input: 6244.08 toks/s, output: 6.10 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:46<10:15,  5.61it/s, est. speed input: 6195.39 toks/s, output: 6.05 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:52<10:23,  5.49it/s, est. speed input: 6150.08 toks/s, output: 6.01 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:58<10:28,  5.39it/s, est. speed input: 6105.57 toks/s, output: 5.96 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [02:04<10:29,  5.33it/s, est. speed input: 6066.87 toks/s, output: 5.92 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [02:08<09:26,  5.87it/s, est. speed input: 6125.56 toks/s, output: 5.98 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [02:14<09:42,  5.65it/s, est. speed input: 6088.50 toks/s, output: 5.95 toks/s]
Processed prompts:  20%|██        | 834/4096 [02:21<09:53,  5.49it/s, est. speed input: 6052.80 toks/s, output: 5.91 toks/s]
Processed prompts:  21%|██        | 866/4096 [02:27<09:57,  5.41it/s, est. speed input: 6023.74 toks/s, output: 5.88 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:33<09:55,  5.37it/s, est. speed input: 5999.95 toks/s, output: 5.86 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:39<09:53,  5.34it/s, est. speed input: 5976.06 toks/s, output: 5.84 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:43<09:04,  5.76it/s, est. speed input: 6010.45 toks/s, output: 5.87 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:49<09:11,  5.62it/s, est. speed input: 5991.02 toks/s, output: 5.85 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:56<09:19,  5.49it/s, est. speed input: 5967.39 toks/s, output: 5.83 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [03:02<09:24,  5.38it/s, est. speed input: 5943.68 toks/s, output: 5.80 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [03:08<09:24,  5.33it/s, est. speed input: 5923.89 toks/s, output: 5.79 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [03:12<08:27,  5.86it/s, est. speed input: 5965.55 toks/s, output: 5.83 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [03:18<08:41,  5.64it/s, est. speed input: 5944.65 toks/s, output: 5.81 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [03:24<08:49,  5.49it/s, est. speed input: 5925.30 toks/s, output: 5.79 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [03:31<08:50,  5.42it/s, est. speed input: 5910.02 toks/s, output: 5.77 toks/s]
Processed prompts:  31%|███       | 1250/4096 [03:37<08:49,  5.38it/s, est. speed input: 5895.92 toks/s, output: 5.76 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:41<08:05,  5.80it/s, est. speed input: 5923.75 toks/s, output: 5.78 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:47<08:14,  5.63it/s, est. speed input: 5909.63 toks/s, output: 5.77 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:53<08:19,  5.51it/s, est. speed input: 5895.76 toks/s, output: 5.76 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:59<08:21,  5.42it/s, est. speed input: 5882.14 toks/s, output: 5.74 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [04:06<08:22,  5.34it/s, est. speed input: 5866.88 toks/s, output: 5.73 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [04:12<08:19,  5.31it/s, est. speed input: 5854.78 toks/s, output: 5.72 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [04:16<07:36,  5.75it/s, est. speed input: 5879.84 toks/s, output: 5.74 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [04:22<07:46,  5.55it/s, est. speed input: 5865.19 toks/s, output: 5.73 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [04:29<07:50,  5.44it/s, est. speed input: 5852.49 toks/s, output: 5.72 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [04:35<07:49,  5.39it/s, est. speed input: 5842.49 toks/s, output: 5.71 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [04:40<07:40,  5.42it/s, est. speed input: 5838.19 toks/s, output: 5.70 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [04:45<07:04,  5.80it/s, est. speed input: 5858.66 toks/s, output: 5.72 toks/s]
Processed prompts:  41%|████      | 1666/4096 [04:51<07:11,  5.63it/s, est. speed input: 5848.75 toks/s, output: 5.71 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:57<07:15,  5.51it/s, est. speed input: 5838.91 toks/s, output: 5.70 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [05:03<07:16,  5.42it/s, est. speed input: 5829.02 toks/s, output: 5.69 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [05:10<07:15,  5.35it/s, est. speed input: 5819.26 toks/s, output: 5.68 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [05:14<06:36,  5.80it/s, est. speed input: 5841.27 toks/s, output: 5.70 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [05:20<06:43,  5.63it/s, est. speed input: 5832.81 toks/s, output: 5.70 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [05:26<06:49,  5.46it/s, est. speed input: 5821.08 toks/s, output: 5.68 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [05:32<06:49,  5.38it/s, est. speed input: 5812.21 toks/s, output: 5.68 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [05:39<06:45,  5.36it/s, est. speed input: 5805.23 toks/s, output: 5.67 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [05:45<06:41,  5.34it/s, est. speed input: 5798.56 toks/s, output: 5.66 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [05:49<06:07,  5.74it/s, est. speed input: 5816.27 toks/s, output: 5.68 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [05:55<06:10,  5.61it/s, est. speed input: 5809.81 toks/s, output: 5.67 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [06:01<06:13,  5.48it/s, est. speed input: 5801.43 toks/s, output: 5.67 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [06:07<06:13,  5.39it/s, est. speed input: 5793.67 toks/s, output: 5.66 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [06:14<06:12,  5.32it/s, est. speed input: 5785.36 toks/s, output: 5.65 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [06:18<05:33,  5.85it/s, est. speed input: 5807.51 toks/s, output: 5.67 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [06:24<05:35,  5.71it/s, est. speed input: 5803.41 toks/s, output: 5.67 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [06:30<05:41,  5.52it/s, est. speed input: 5794.74 toks/s, output: 5.66 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [06:36<05:40,  5.44it/s, est. speed input: 5788.48 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [06:42<05:37,  5.39it/s, est. speed input: 5782.65 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [06:47<05:07,  5.83it/s, est. speed input: 5799.99 toks/s, output: 5.66 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [06:53<05:12,  5.63it/s, est. speed input: 5793.26 toks/s, output: 5.66 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [06:59<05:12,  5.52it/s, est. speed input: 5787.43 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [07:05<05:11,  5.44it/s, est. speed input: 5781.81 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [07:11<05:10,  5.36it/s, est. speed input: 5774.84 toks/s, output: 5.64 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [07:17<05:07,  5.31it/s, est. speed input: 5768.41 toks/s, output: 5.63 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [07:22<04:38,  5.74it/s, est. speed input: 5783.74 toks/s, output: 5.65 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [07:28<04:41,  5.57it/s, est. speed input: 5777.34 toks/s, output: 5.64 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [07:34<04:42,  5.43it/s, est. speed input: 5770.33 toks/s, output: 5.64 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [07:40<04:39,  5.38it/s, est. speed input: 5765.40 toks/s, output: 5.63 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [07:46<04:34,  5.36it/s, est. speed input: 5761.06 toks/s, output: 5.63 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [07:51<04:09,  5.76it/s, est. speed input: 5774.52 toks/s, output: 5.64 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [07:57<04:11,  5.59it/s, est. speed input: 5769.07 toks/s, output: 5.63 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [08:03<04:10,  5.48it/s, est. speed input: 5764.05 toks/s, output: 5.63 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [08:09<04:07,  5.42it/s, est. speed input: 5759.66 toks/s, output: 5.62 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [08:15<04:04,  5.36it/s, est. speed input: 5754.63 toks/s, output: 5.62 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [08:20<03:41,  5.78it/s, est. speed input: 5768.15 toks/s, output: 5.63 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [08:26<03:42,  5.60it/s, est. speed input: 5763.16 toks/s, output: 5.63 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [08:32<03:42,  5.47it/s, est. speed input: 5757.50 toks/s, output: 5.62 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [08:38<03:39,  5.39it/s, est. speed input: 5752.42 toks/s, output: 5.62 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [08:44<03:34,  5.35it/s, est. speed input: 5748.44 toks/s, output: 5.61 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [08:49<03:12,  5.82it/s, est. speed input: 5762.75 toks/s, output: 5.63 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [08:55<03:13,  5.60it/s, est. speed input: 5757.20 toks/s, output: 5.62 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [09:01<03:11,  5.49it/s, est. speed input: 5752.82 toks/s, output: 5.62 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [09:07<03:09,  5.40it/s, est. speed input: 5747.99 toks/s, output: 5.61 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [09:13<03:04,  5.36it/s, est. speed input: 5744.22 toks/s, output: 5.61 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [09:19<03:00,  5.30it/s, est. speed input: 5739.14 toks/s, output: 5.60 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [09:24<02:39,  5.82it/s, est. speed input: 5754.13 toks/s, output: 5.62 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [09:30<02:38,  5.65it/s, est. speed input: 5750.58 toks/s, output: 5.62 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [09:36<02:37,  5.48it/s, est. speed input: 5745.10 toks/s, output: 5.61 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [09:42<02:34,  5.39it/s, est. speed input: 5740.41 toks/s, output: 5.61 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [09:48<02:29,  5.35it/s, est. speed input: 5736.78 toks/s, output: 5.60 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [09:53<02:11,  5.82it/s, est. speed input: 5749.77 toks/s, output: 5.62 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [09:59<02:11,  5.60it/s, est. speed input: 5744.70 toks/s, output: 5.61 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [10:05<02:07,  5.49it/s, est. speed input: 5741.17 toks/s, output: 5.61 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [10:11<02:03,  5.42it/s, est. speed input: 5737.63 toks/s, output: 5.60 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [10:17<01:58,  5.37it/s, est. speed input: 5734.08 toks/s, output: 5.60 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [10:22<01:45,  5.75it/s, est. speed input: 5744.00 toks/s, output: 5.61 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [10:28<01:42,  5.60it/s, est. speed input: 5740.60 toks/s, output: 5.61 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [10:34<01:38,  5.49it/s, est. speed input: 5736.99 toks/s, output: 5.60 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [10:40<01:34,  5.38it/s, est. speed input: 5732.57 toks/s, output: 5.60 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [10:46<01:29,  5.32it/s, est. speed input: 5728.54 toks/s, output: 5.59 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [10:52<01:23,  5.31it/s, est. speed input: 5725.71 toks/s, output: 5.59 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [10:57<01:11,  5.83it/s, est. speed input: 5738.62 toks/s, output: 5.60 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [11:03<01:08,  5.61it/s, est. speed input: 5734.35 toks/s, output: 5.60 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [11:09<01:03,  5.49it/s, est. speed input: 5730.85 toks/s, output: 5.60 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [11:15<00:58,  5.42it/s, est. speed input: 5727.82 toks/s, output: 5.59 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [11:21<00:53,  5.38it/s, est. speed input: 5724.93 toks/s, output: 5.59 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [11:26<00:43,  5.78it/s, est. speed input: 5734.50 toks/s, output: 5.60 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [11:32<00:39,  5.62it/s, est. speed input: 5731.54 toks/s, output: 5.60 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [11:38<00:34,  5.55it/s, est. speed input: 5729.76 toks/s, output: 5.60 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [11:44<00:29,  5.43it/s, est. speed input: 5725.85 toks/s, output: 5.59 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [11:50<00:23,  5.37it/s, est. speed input: 5722.66 toks/s, output: 5.59 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [11:54<00:16,  5.83it/s, est. speed input: 5733.49 toks/s, output: 5.60 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [12:00<00:11,  5.64it/s, est. speed input: 5730.26 toks/s, output: 5.60 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [12:06<00:05,  5.56it/s, est. speed input: 5728.57 toks/s, output: 5.59 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [12:06<00:00,  5.56it/s, est. speed input: 5770.83 toks/s, output: 5.64 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [12:06<00:00,  5.64it/s, est. speed input: 5770.83 toks/s, output: 5.64 toks/s]
[rank0]:[W126 01:01:29.287561086 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 833.2s

测试结果:
  Requests/s:   5.22
  Tokens/s:     5354.36
  Total Reqs:   4096
  Elapsed:      784.11s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     5349.14

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:02:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:02:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=625703) WARNING 01-26 01:02:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=625703) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=625703) WARNING 01-26 01:03:11 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     def forward(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     raise e
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/tmp/torchinductor_root/eq/ceqgg2b5od57a2ayhnybjtujmzypeuhpekg6vjyjbhdblz52tdmg.py", line 1093, in call
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) ERROR 01-26 01:03:22 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-26 01:02:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:02:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:02:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:02:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:02:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:02:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:02:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:02:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:02:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:02:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:02:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:02:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:02:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:02:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:02:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:02:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:02:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=625703) [2026-01-26 01:02:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=625703) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=625703) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.19s/it]
(EngineCore_DP0 pid=625703) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.42s/it]
(EngineCore_DP0 pid=625703) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.39s/it]
(EngineCore_DP0 pid=625703) 
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=625703) [2026-01-26 01:03:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=625703) [rank0]:W0126 01:03:19.912000 625703 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=625703) [rank0]:W0126 01:03:20.030000 625703 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=625703) [rank0]:W0126 01:03:21.744000 625703 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=625703) [rank0]:W0126 01:03:20.241000 625703 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=625703) Process EngineCore_DP0:
(EngineCore_DP0 pid=625703) Traceback (most recent call last):
(EngineCore_DP0 pid=625703)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=625703)     self.run()
(EngineCore_DP0 pid=625703)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=625703)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=625703)     raise e
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=625703)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=625703)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=625703)     super().__init__(
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=625703)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=625703)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=625703)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=625703)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=625703)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=625703)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=625703)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=625703)     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=625703)     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=625703)     self.model_runner.profile_run()
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=625703)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=625703)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=625703)     return func(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=625703)     outputs = self.model(
(EngineCore_DP0 pid=625703)               ^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=625703)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=625703)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=625703)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=625703)     hidden_states = self.model(
(EngineCore_DP0 pid=625703)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=625703)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=625703)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=625703)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=625703)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=625703)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=625703)     def forward(
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=625703)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=625703)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=625703)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=625703)     raise e
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=625703)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=625703)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=625703)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=625703)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=625703)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=625703)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=625703)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=625703)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=625703)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=625703)     return compiled_fn(full_args)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=625703)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=625703)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=625703)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=625703)                             ^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=625703)     outs = compiled_fn(args)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=625703)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=625703)     return self.current_callable(inputs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=625703)     out = model(new_inputs)
(EngineCore_DP0 pid=625703)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/tmp/torchinductor_root/eq/ceqgg2b5od57a2ayhnybjtujmzypeuhpekg6vjyjbhdblz52tdmg.py", line 1093, in call
(EngineCore_DP0 pid=625703)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=625703)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=625703)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=625703)     return fn(input, L)
(EngineCore_DP0 pid=625703)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=625703)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=625703)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=625703)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=625703)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=625703)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=625703)     self._init_handles()
(EngineCore_DP0 pid=625703)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=625703)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=625703)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=625703) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 01:03:23.399185798 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,15.0924,7742.4143,8.4811
1024,1024,1,128,128,15.0934,15470.7281,8.4805
2048,1024,2,256,128,20.4442,20955.3336,12.5219
4096,1024,4,512,128,21.4188,21954.2246,23.9043
8192,1024,8,1024,128,21.7951,22339.9630,46.9831
16384,1024,16,2048,128,10.4810,10743.0431,195.4009
32768,1024,32,4096,128,5.2238,5354.3638,784.1081
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败


============================================================
  Benchmark 完成!
============================================================


总计: 35 成功, 5 失败
============================================================
