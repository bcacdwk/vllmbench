======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-25 22:09:19
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-14b-fp8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX5080
  Compute Capability: cc120
  VRAM: 15.5 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:09:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     raise e
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) ERROR 01-25 22:09:28 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:09:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:09:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=560719) [2026-01-25 22:09:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=560719) [2026-01-25 22:09:28] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=560719) [2026-01-25 22:09:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=560719) [2026-01-25 22:09:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=560719) [2026-01-25 22:09:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=560719) Process EngineCore_DP0:
(EngineCore_DP0 pid=560719) Traceback (most recent call last):
(EngineCore_DP0 pid=560719)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=560719)     self.run()
(EngineCore_DP0 pid=560719)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=560719)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=560719)     raise e
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=560719)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=560719)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=560719)     super().__init__(
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=560719)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=560719)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=560719)     self._init_executor()
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=560719)     self.driver_worker.load_model()
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=560719)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=560719)     raise e
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=560719)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=560719)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=560719)     model = initialize_model(
(EngineCore_DP0 pid=560719)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=560719)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=560719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=560719)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=560719)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=560719)     super().__init__(
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=560719)     self.quant_method.create_weights(
(EngineCore_DP0 pid=560719)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=560719)     torch.empty(
(EngineCore_DP0 pid=560719)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=560719)     return func(*args, **kwargs)
(EngineCore_DP0 pid=560719)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=560719) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:09:28.779331984 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:09:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     raise e
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) ERROR 01-25 22:09:39 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:09:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:09:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=561123) [2026-01-25 22:09:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=561123) [2026-01-25 22:09:39] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=561123) [2026-01-25 22:09:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=561123) [2026-01-25 22:09:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=561123) [2026-01-25 22:09:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=561123) Process EngineCore_DP0:
(EngineCore_DP0 pid=561123) Traceback (most recent call last):
(EngineCore_DP0 pid=561123)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=561123)     self.run()
(EngineCore_DP0 pid=561123)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=561123)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=561123)     raise e
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561123)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561123)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561123)     super().__init__(
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561123)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561123)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561123)     self._init_executor()
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561123)     self.driver_worker.load_model()
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561123)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561123)     raise e
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561123)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561123)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561123)     model = initialize_model(
(EngineCore_DP0 pid=561123)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561123)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561123)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561123)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561123)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561123)     super().__init__(
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561123)     self.quant_method.create_weights(
(EngineCore_DP0 pid=561123)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561123)     torch.empty(
(EngineCore_DP0 pid=561123)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561123)     return func(*args, **kwargs)
(EngineCore_DP0 pid=561123)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561123) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:09:40.093893542 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:09:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     raise e
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) ERROR 01-25 22:09:51 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:09:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:09:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=561527) [2026-01-25 22:09:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=561527) [2026-01-25 22:09:50] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=561527) [2026-01-25 22:09:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=561527) [2026-01-25 22:09:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=561527) [2026-01-25 22:09:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=561527) Process EngineCore_DP0:
(EngineCore_DP0 pid=561527) Traceback (most recent call last):
(EngineCore_DP0 pid=561527)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=561527)     self.run()
(EngineCore_DP0 pid=561527)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=561527)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=561527)     raise e
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561527)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561527)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561527)     super().__init__(
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561527)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561527)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561527)     self._init_executor()
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561527)     self.driver_worker.load_model()
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561527)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561527)     raise e
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561527)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561527)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561527)     model = initialize_model(
(EngineCore_DP0 pid=561527)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561527)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561527)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561527)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561527)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561527)     super().__init__(
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561527)     self.quant_method.create_weights(
(EngineCore_DP0 pid=561527)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561527)     torch.empty(
(EngineCore_DP0 pid=561527)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561527)     return func(*args, **kwargs)
(EngineCore_DP0 pid=561527)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561527) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:09:51.631671573 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:09:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     raise e
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) ERROR 01-25 22:10:03 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:09:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:09:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:09:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:09:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:09:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:09:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:09:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:09:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:10:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=561941) [2026-01-25 22:10:03] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=561941) [2026-01-25 22:10:03] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=561941) [2026-01-25 22:10:03] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=561941) [2026-01-25 22:10:03] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=561941) [2026-01-25 22:10:03] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=561941) Process EngineCore_DP0:
(EngineCore_DP0 pid=561941) Traceback (most recent call last):
(EngineCore_DP0 pid=561941)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=561941)     self.run()
(EngineCore_DP0 pid=561941)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=561941)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=561941)     raise e
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=561941)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=561941)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=561941)     super().__init__(
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=561941)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=561941)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=561941)     self._init_executor()
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=561941)     self.driver_worker.load_model()
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=561941)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=561941)     raise e
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=561941)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=561941)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=561941)     model = initialize_model(
(EngineCore_DP0 pid=561941)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=561941)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=561941)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=561941)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=561941)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=561941)     super().__init__(
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=561941)     self.quant_method.create_weights(
(EngineCore_DP0 pid=561941)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=561941)     torch.empty(
(EngineCore_DP0 pid=561941)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=561941)     return func(*args, **kwargs)
(EngineCore_DP0 pid=561941)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=561941) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:10:04.057828396 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:10:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     raise e
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) ERROR 01-25 22:10:18 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:10:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:10:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=562381) [2026-01-25 22:10:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=562381) [2026-01-25 22:10:17] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=562381) [2026-01-25 22:10:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=562381) [2026-01-25 22:10:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=562381) [2026-01-25 22:10:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=562381) Process EngineCore_DP0:
(EngineCore_DP0 pid=562381) Traceback (most recent call last):
(EngineCore_DP0 pid=562381)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=562381)     self.run()
(EngineCore_DP0 pid=562381)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=562381)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=562381)     raise e
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=562381)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=562381)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=562381)     super().__init__(
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=562381)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=562381)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=562381)     self._init_executor()
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=562381)     self.driver_worker.load_model()
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=562381)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=562381)     raise e
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=562381)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=562381)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=562381)     model = initialize_model(
(EngineCore_DP0 pid=562381)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=562381)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=562381)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=562381)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=562381)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=562381)     super().__init__(
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=562381)     self.quant_method.create_weights(
(EngineCore_DP0 pid=562381)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=562381)     torch.empty(
(EngineCore_DP0 pid=562381)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=562381)     return func(*args, **kwargs)
(EngineCore_DP0 pid=562381)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562381) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:10:18.268415820 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:10:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     raise e
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) ERROR 01-25 22:10:35 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:10:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:10:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=562880) [2026-01-25 22:10:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=562880) [2026-01-25 22:10:35] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=562880) [2026-01-25 22:10:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=562880) [2026-01-25 22:10:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=562880) [2026-01-25 22:10:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=562880) Process EngineCore_DP0:
(EngineCore_DP0 pid=562880) Traceback (most recent call last):
(EngineCore_DP0 pid=562880)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=562880)     self.run()
(EngineCore_DP0 pid=562880)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=562880)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=562880)     raise e
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=562880)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=562880)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=562880)     super().__init__(
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=562880)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=562880)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=562880)     self._init_executor()
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=562880)     self.driver_worker.load_model()
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=562880)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=562880)     raise e
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=562880)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=562880)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=562880)     model = initialize_model(
(EngineCore_DP0 pid=562880)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=562880)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=562880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=562880)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=562880)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=562880)     super().__init__(
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=562880)     self.quant_method.create_weights(
(EngineCore_DP0 pid=562880)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=562880)     torch.empty(
(EngineCore_DP0 pid=562880)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=562880)     return func(*args, **kwargs)
(EngineCore_DP0 pid=562880)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=562880) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:10:36.045416897 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:10:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     raise e
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) ERROR 01-25 22:11:01 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:10:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:10:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:10:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:10:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=563466) [2026-01-25 22:11:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=563466) [2026-01-25 22:11:00] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=563466) [2026-01-25 22:11:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=563466) [2026-01-25 22:11:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=563466) [2026-01-25 22:11:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=563466) Process EngineCore_DP0:
(EngineCore_DP0 pid=563466) Traceback (most recent call last):
(EngineCore_DP0 pid=563466)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=563466)     self.run()
(EngineCore_DP0 pid=563466)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=563466)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=563466)     raise e
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=563466)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=563466)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=563466)     super().__init__(
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=563466)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=563466)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=563466)     self._init_executor()
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=563466)     self.driver_worker.load_model()
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=563466)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=563466)     raise e
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=563466)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=563466)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=563466)     model = initialize_model(
(EngineCore_DP0 pid=563466)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=563466)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=563466)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=563466)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=563466)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=563466)     super().__init__(
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=563466)     self.quant_method.create_weights(
(EngineCore_DP0 pid=563466)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=563466)     torch.empty(
(EngineCore_DP0 pid=563466)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=563466)     return func(*args, **kwargs)
(EngineCore_DP0 pid=563466)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=563466) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:11:01.185844023 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:11:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     raise e
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) ERROR 01-25 22:11:41 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:11:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:11:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=564259) [2026-01-25 22:11:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=564259) [2026-01-25 22:11:40] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=564259) [2026-01-25 22:11:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=564259) [2026-01-25 22:11:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=564259) [2026-01-25 22:11:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuBLASLt
(EngineCore_DP0 pid=564259) Process EngineCore_DP0:
(EngineCore_DP0 pid=564259) Traceback (most recent call last):
(EngineCore_DP0 pid=564259)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=564259)     self.run()
(EngineCore_DP0 pid=564259)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=564259)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=564259)     raise e
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=564259)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=564259)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=564259)     super().__init__(
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=564259)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=564259)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=564259)     self._init_executor()
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=564259)     self.driver_worker.load_model()
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=564259)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=564259)     raise e
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=564259)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=564259)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=564259)     model = initialize_model(
(EngineCore_DP0 pid=564259)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=564259)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=564259)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=564259)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=564259)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=564259)     super().__init__(
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=564259)     self.quant_method.create_weights(
(EngineCore_DP0 pid=564259)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=564259)     torch.empty(
(EngineCore_DP0 pid=564259)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=564259)     return func(*args, **kwargs)
(EngineCore_DP0 pid=564259)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564259) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:11:41.173466279 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:11:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     raise e
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) ERROR 01-25 22:11:52 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:11:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:11:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=564672) [2026-01-25 22:11:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=564672) Process EngineCore_DP0:
(EngineCore_DP0 pid=564672) Traceback (most recent call last):
(EngineCore_DP0 pid=564672)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=564672)     self.run()
(EngineCore_DP0 pid=564672)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=564672)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=564672)     raise e
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=564672)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=564672)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=564672)     super().__init__(
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=564672)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=564672)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=564672)     self._init_executor()
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=564672)     self.driver_worker.load_model()
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=564672)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=564672)     raise e
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=564672)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=564672)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=564672)     model = initialize_model(
(EngineCore_DP0 pid=564672)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=564672)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=564672)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=564672)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=564672)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=564672)     super().__init__(
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=564672)     self.quant_method.create_weights(
(EngineCore_DP0 pid=564672)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=564672)     torch.empty(
(EngineCore_DP0 pid=564672)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=564672)     return func(*args, **kwargs)
(EngineCore_DP0 pid=564672)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=564672) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 948.94 MiB is free. Including non-PyTorch memory, this process has 14.31 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 8.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:11:52.205467624 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:11:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     raise e
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) ERROR 01-25 22:12:02 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:11:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:11:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:11:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=565066) [2026-01-25 22:12:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=565066) Process EngineCore_DP0:
(EngineCore_DP0 pid=565066) Traceback (most recent call last):
(EngineCore_DP0 pid=565066)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=565066)     self.run()
(EngineCore_DP0 pid=565066)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=565066)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=565066)     raise e
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565066)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565066)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565066)     super().__init__(
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565066)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565066)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565066)     self._init_executor()
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565066)     self.driver_worker.load_model()
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565066)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565066)     raise e
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565066)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565066)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565066)     model = initialize_model(
(EngineCore_DP0 pid=565066)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565066)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565066)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565066)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565066)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565066)     super().__init__(
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565066)     self.quant_method.create_weights(
(EngineCore_DP0 pid=565066)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565066)     torch.empty(
(EngineCore_DP0 pid=565066)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565066)     return func(*args, **kwargs)
(EngineCore_DP0 pid=565066)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565066) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 936.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:12:03.115336296 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:12:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     raise e
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) ERROR 01-25 22:12:14 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:12:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=565474) [2026-01-25 22:12:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=565474) Process EngineCore_DP0:
(EngineCore_DP0 pid=565474) Traceback (most recent call last):
(EngineCore_DP0 pid=565474)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=565474)     self.run()
(EngineCore_DP0 pid=565474)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=565474)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=565474)     raise e
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565474)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565474)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565474)     super().__init__(
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565474)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565474)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565474)     self._init_executor()
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565474)     self.driver_worker.load_model()
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565474)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565474)     raise e
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565474)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565474)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565474)     model = initialize_model(
(EngineCore_DP0 pid=565474)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565474)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565474)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565474)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565474)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565474)     super().__init__(
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565474)     self.quant_method.create_weights(
(EngineCore_DP0 pid=565474)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565474)     torch.empty(
(EngineCore_DP0 pid=565474)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565474)     return func(*args, **kwargs)
(EngineCore_DP0 pid=565474)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565474) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 928.94 MiB is free. Including non-PyTorch memory, this process has 14.33 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, and 13.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:12:14.687593982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:12:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     raise e
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) ERROR 01-25 22:12:26 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:12:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=565884) [2026-01-25 22:12:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=565884) Process EngineCore_DP0:
(EngineCore_DP0 pid=565884) Traceback (most recent call last):
(EngineCore_DP0 pid=565884)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=565884)     self.run()
(EngineCore_DP0 pid=565884)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=565884)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=565884)     raise e
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=565884)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=565884)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=565884)     super().__init__(
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=565884)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=565884)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=565884)     self._init_executor()
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=565884)     self.driver_worker.load_model()
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=565884)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=565884)     raise e
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=565884)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=565884)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=565884)     model = initialize_model(
(EngineCore_DP0 pid=565884)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=565884)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=565884)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=565884)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=565884)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=565884)     super().__init__(
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=565884)     self.quant_method.create_weights(
(EngineCore_DP0 pid=565884)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=565884)     torch.empty(
(EngineCore_DP0 pid=565884)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=565884)     return func(*args, **kwargs)
(EngineCore_DP0 pid=565884)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=565884) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 908.94 MiB is free. Including non-PyTorch memory, this process has 14.35 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:12:27.043247975 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:12:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     raise e
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) ERROR 01-25 22:12:40 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:12:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=566319) [2026-01-25 22:12:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=566319) Process EngineCore_DP0:
(EngineCore_DP0 pid=566319) Traceback (most recent call last):
(EngineCore_DP0 pid=566319)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=566319)     self.run()
(EngineCore_DP0 pid=566319)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=566319)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=566319)     raise e
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=566319)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=566319)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=566319)     super().__init__(
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=566319)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=566319)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=566319)     self._init_executor()
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=566319)     self.driver_worker.load_model()
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=566319)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=566319)     raise e
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=566319)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=566319)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=566319)     model = initialize_model(
(EngineCore_DP0 pid=566319)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=566319)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=566319)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=566319)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=566319)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=566319)     super().__init__(
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=566319)     self.quant_method.create_weights(
(EngineCore_DP0 pid=566319)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=566319)     torch.empty(
(EngineCore_DP0 pid=566319)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=566319)     return func(*args, **kwargs)
(EngineCore_DP0 pid=566319)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566319) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 868.94 MiB is free. Including non-PyTorch memory, this process has 14.39 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 13.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:12:41.092413654 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:12:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     raise e
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) ERROR 01-25 22:12:58 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:12:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:12:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:12:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=566801) [2026-01-25 22:12:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=566801) Process EngineCore_DP0:
(EngineCore_DP0 pid=566801) Traceback (most recent call last):
(EngineCore_DP0 pid=566801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=566801)     self.run()
(EngineCore_DP0 pid=566801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=566801)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=566801)     raise e
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=566801)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=566801)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=566801)     super().__init__(
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=566801)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=566801)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=566801)     self._init_executor()
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=566801)     self.driver_worker.load_model()
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=566801)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=566801)     raise e
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=566801)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=566801)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=566801)     model = initialize_model(
(EngineCore_DP0 pid=566801)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=566801)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=566801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=566801)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=566801)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=566801)     super().__init__(
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=566801)     self.quant_method.create_weights(
(EngineCore_DP0 pid=566801)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=566801)     torch.empty(
(EngineCore_DP0 pid=566801)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=566801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=566801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=566801) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 788.94 MiB is free. Including non-PyTorch memory, this process has 14.47 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:12:59.803352084 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:13:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     raise e
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) ERROR 01-25 22:13:23 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:13:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:13:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:13:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:13:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:13:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:13:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:13:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:13:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:13:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:13:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:13:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:13:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=567389) [2026-01-25 22:13:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=567389) Process EngineCore_DP0:
(EngineCore_DP0 pid=567389) Traceback (most recent call last):
(EngineCore_DP0 pid=567389)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=567389)     self.run()
(EngineCore_DP0 pid=567389)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=567389)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=567389)     raise e
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=567389)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=567389)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=567389)     super().__init__(
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=567389)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=567389)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=567389)     self._init_executor()
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=567389)     self.driver_worker.load_model()
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=567389)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=567389)     raise e
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=567389)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=567389)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=567389)     model = initialize_model(
(EngineCore_DP0 pid=567389)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=567389)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=567389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=567389)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=567389)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=567389)     super().__init__(
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=567389)     self.quant_method.create_weights(
(EngineCore_DP0 pid=567389)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=567389)     torch.empty(
(EngineCore_DP0 pid=567389)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=567389)     return func(*args, **kwargs)
(EngineCore_DP0 pid=567389)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=567389) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 628.94 MiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:13:23.596037214 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:13:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     raise e
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     torch.empty(
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) ERROR 01-25 22:14:02 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:13:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:13:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:13:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:13:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:13:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:13:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:13:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:13:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=568179) [2026-01-25 22:14:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=568179) Process EngineCore_DP0:
(EngineCore_DP0 pid=568179) Traceback (most recent call last):
(EngineCore_DP0 pid=568179)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=568179)     self.run()
(EngineCore_DP0 pid=568179)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=568179)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=568179)     raise e
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568179)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568179)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568179)     super().__init__(
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568179)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568179)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568179)     self._init_executor()
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568179)     self.driver_worker.load_model()
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568179)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568179)     raise e
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568179)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568179)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568179)     model = initialize_model(
(EngineCore_DP0 pid=568179)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568179)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568179)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 551, in __init__
(EngineCore_DP0 pid=568179)     self.lm_head = ParallelLMHead(
(EngineCore_DP0 pid=568179)                    ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
(EngineCore_DP0 pid=568179)     super().__init__(
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
(EngineCore_DP0 pid=568179)     self.quant_method.create_weights(
(EngineCore_DP0 pid=568179)   File "/root/vllmbench/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
(EngineCore_DP0 pid=568179)     torch.empty(
(EngineCore_DP0 pid=568179)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568179)     return func(*args, **kwargs)
(EngineCore_DP0 pid=568179)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568179) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 15.46 GiB of which 306.94 MiB is free. Including non-PyTorch memory, this process has 14.94 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 12.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:14:03.051203093 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 184.94 MiB is free. Including non-PyTorch memory, this process has 15.06 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 109.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     raise e
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) ERROR 01-25 22:14:13 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 184.94 MiB is free. Including non-PyTorch memory, this process has 15.06 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 109.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:14:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=568573) [2026-01-25 22:14:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=568573) Process EngineCore_DP0:
(EngineCore_DP0 pid=568573) Traceback (most recent call last):
(EngineCore_DP0 pid=568573)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=568573)     self.run()
(EngineCore_DP0 pid=568573)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=568573)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=568573)     raise e
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568573)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568573)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568573)     super().__init__(
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568573)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568573)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568573)     self._init_executor()
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568573)     self.driver_worker.load_model()
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568573)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568573)     raise e
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568573)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568573)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568573)     model = initialize_model(
(EngineCore_DP0 pid=568573)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568573)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=568573)     self.model = Qwen2Model(
(EngineCore_DP0 pid=568573)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=568573)     old_init(self, **kwargs)
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=568573)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=568573)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=568573)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=568573)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=568573)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=568573)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=568573)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=568573)                ^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=568573)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=568573)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=568573)     super().__init__(
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=568573)     self.quant_method.create_weights(
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=568573)     layer.scheme.create_weights(
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=568573)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=568573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=568573)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=568573)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=568573)     data=torch.empty(
(EngineCore_DP0 pid=568573)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=568573)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568573)     return func(*args, **kwargs)
(EngineCore_DP0 pid=568573)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568573) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 184.94 MiB is free. Including non-PyTorch memory, this process has 15.06 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 109.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:14:14.905510462 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 172.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 116.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     raise e
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) ERROR 01-25 22:14:24 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 172.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 116.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:14:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=568979) [2026-01-25 22:14:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=568979) Process EngineCore_DP0:
(EngineCore_DP0 pid=568979) Traceback (most recent call last):
(EngineCore_DP0 pid=568979)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=568979)     self.run()
(EngineCore_DP0 pid=568979)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=568979)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=568979)     raise e
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=568979)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=568979)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=568979)     super().__init__(
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=568979)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=568979)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=568979)     self._init_executor()
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=568979)     self.driver_worker.load_model()
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=568979)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=568979)     raise e
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=568979)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=568979)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=568979)     model = initialize_model(
(EngineCore_DP0 pid=568979)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=568979)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=568979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=568979)     self.model = Qwen2Model(
(EngineCore_DP0 pid=568979)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=568979)     old_init(self, **kwargs)
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=568979)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=568979)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=568979)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=568979)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=568979)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=568979)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=568979)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=568979)                ^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=568979)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=568979)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=568979)     super().__init__(
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=568979)     self.quant_method.create_weights(
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=568979)     layer.scheme.create_weights(
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=568979)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=568979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=568979)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=568979)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=568979)     data=torch.empty(
(EngineCore_DP0 pid=568979)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=568979)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=568979)     return func(*args, **kwargs)
(EngineCore_DP0 pid=568979)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=568979) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 172.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 116.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:14:25.931100719 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 164.94 MiB is free. Including non-PyTorch memory, this process has 15.08 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 114.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     raise e
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) ERROR 01-25 22:14:36 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 164.94 MiB is free. Including non-PyTorch memory, this process has 15.08 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 114.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:14:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=569383) [2026-01-25 22:14:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=569383) Process EngineCore_DP0:
(EngineCore_DP0 pid=569383) Traceback (most recent call last):
(EngineCore_DP0 pid=569383)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=569383)     self.run()
(EngineCore_DP0 pid=569383)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=569383)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=569383)     raise e
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=569383)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=569383)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=569383)     super().__init__(
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=569383)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=569383)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=569383)     self._init_executor()
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=569383)     self.driver_worker.load_model()
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=569383)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=569383)     raise e
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=569383)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=569383)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=569383)     model = initialize_model(
(EngineCore_DP0 pid=569383)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=569383)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=569383)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=569383)     self.model = Qwen2Model(
(EngineCore_DP0 pid=569383)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=569383)     old_init(self, **kwargs)
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=569383)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=569383)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=569383)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=569383)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=569383)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=569383)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=569383)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=569383)                ^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=569383)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=569383)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=569383)     super().__init__(
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=569383)     self.quant_method.create_weights(
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=569383)     layer.scheme.create_weights(
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=569383)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=569383)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=569383)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=569383)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=569383)     data=torch.empty(
(EngineCore_DP0 pid=569383)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=569383)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=569383)     return func(*args, **kwargs)
(EngineCore_DP0 pid=569383)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569383) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 164.94 MiB is free. Including non-PyTorch memory, this process has 15.08 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 114.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:14:36.407441962 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Of the allocated memory 14.62 GiB is allocated by PyTorch, and 114.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     raise e
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) ERROR 01-25 22:14:48 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Of the allocated memory 14.62 GiB is allocated by PyTorch, and 114.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:14:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=569797) [2026-01-25 22:14:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=569797) Process EngineCore_DP0:
(EngineCore_DP0 pid=569797) Traceback (most recent call last):
(EngineCore_DP0 pid=569797)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=569797)     self.run()
(EngineCore_DP0 pid=569797)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=569797)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=569797)     raise e
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=569797)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=569797)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=569797)     super().__init__(
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=569797)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=569797)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=569797)     self._init_executor()
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=569797)     self.driver_worker.load_model()
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=569797)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=569797)     raise e
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=569797)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=569797)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=569797)     model = initialize_model(
(EngineCore_DP0 pid=569797)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=569797)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=569797)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=569797)     self.model = Qwen2Model(
(EngineCore_DP0 pid=569797)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=569797)     old_init(self, **kwargs)
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=569797)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=569797)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=569797)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=569797)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=569797)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=569797)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=569797)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=569797)                ^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=569797)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=569797)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=569797)     super().__init__(
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=569797)     self.quant_method.create_weights(
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=569797)     layer.scheme.create_weights(
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=569797)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=569797)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=569797)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=569797)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=569797)     data=torch.empty(
(EngineCore_DP0 pid=569797)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=569797)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=569797)     return func(*args, **kwargs)
(EngineCore_DP0 pid=569797)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=569797) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Of the allocated memory 14.62 GiB is allocated by PyTorch, and 114.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:14:49.042432759 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:02 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 104.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.66 GiB is allocated by PyTorch, and 114.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     raise e
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) ERROR 01-25 22:15:03 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 104.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.66 GiB is allocated by PyTorch, and 114.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:14:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:14:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:14:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:15:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=570248) [2026-01-25 22:15:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=570248) Process EngineCore_DP0:
(EngineCore_DP0 pid=570248) Traceback (most recent call last):
(EngineCore_DP0 pid=570248)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=570248)     self.run()
(EngineCore_DP0 pid=570248)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=570248)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=570248)     raise e
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=570248)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=570248)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=570248)     super().__init__(
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=570248)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=570248)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=570248)     self._init_executor()
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=570248)     self.driver_worker.load_model()
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=570248)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=570248)     raise e
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=570248)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=570248)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=570248)     model = initialize_model(
(EngineCore_DP0 pid=570248)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=570248)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=570248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=570248)     self.model = Qwen2Model(
(EngineCore_DP0 pid=570248)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=570248)     old_init(self, **kwargs)
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=570248)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=570248)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=570248)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=570248)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=570248)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=570248)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=570248)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=570248)                ^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=570248)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=570248)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=570248)     super().__init__(
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=570248)     self.quant_method.create_weights(
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=570248)     layer.scheme.create_weights(
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=570248)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=570248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=570248)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=570248)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=570248)     data=torch.empty(
(EngineCore_DP0 pid=570248)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=570248)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=570248)     return func(*args, **kwargs)
(EngineCore_DP0 pid=570248)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570248) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 104.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.66 GiB is allocated by PyTorch, and 114.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:15:03.154911360 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:15:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 15.22 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     raise e
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) ERROR 01-25 22:15:20 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 15.22 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:15:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:15:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=570767) [2026-01-25 22:15:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=570767) Process EngineCore_DP0:
(EngineCore_DP0 pid=570767) Traceback (most recent call last):
(EngineCore_DP0 pid=570767)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=570767)     self.run()
(EngineCore_DP0 pid=570767)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=570767)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=570767)     raise e
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=570767)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=570767)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=570767)     super().__init__(
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=570767)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=570767)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=570767)     self._init_executor()
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=570767)     self.driver_worker.load_model()
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=570767)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=570767)     raise e
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=570767)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=570767)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=570767)     model = initialize_model(
(EngineCore_DP0 pid=570767)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=570767)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=570767)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=570767)     self.model = Qwen2Model(
(EngineCore_DP0 pid=570767)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=570767)     old_init(self, **kwargs)
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=570767)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=570767)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=570767)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=570767)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=570767)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=570767)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=570767)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=570767)                ^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=570767)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=570767)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=570767)     super().__init__(
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=570767)     self.quant_method.create_weights(
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=570767)     layer.scheme.create_weights(
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=570767)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=570767)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=570767)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=570767)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=570767)     data=torch.empty(
(EngineCore_DP0 pid=570767)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=570767)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=570767)     return func(*args, **kwargs)
(EngineCore_DP0 pid=570767)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=570767) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 15.22 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:15:21.818554635 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:15:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 36.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 113.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     raise e
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) ERROR 01-25 22:15:45 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 36.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 113.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:15:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:15:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:15:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:15:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=571356) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=571356) Process EngineCore_DP0:
(EngineCore_DP0 pid=571356) Traceback (most recent call last):
(EngineCore_DP0 pid=571356)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=571356)     self.run()
(EngineCore_DP0 pid=571356)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=571356)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=571356)     raise e
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=571356)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=571356)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=571356)     super().__init__(
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=571356)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=571356)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=571356)     self._init_executor()
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=571356)     self.driver_worker.load_model()
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=571356)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=571356)     raise e
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=571356)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=571356)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=571356)     model = initialize_model(
(EngineCore_DP0 pid=571356)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=571356)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=571356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=571356)     self.model = Qwen2Model(
(EngineCore_DP0 pid=571356)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=571356)     old_init(self, **kwargs)
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=571356)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=571356)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=571356)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=571356)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=571356)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=571356)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=571356)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=571356)                ^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=571356)     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=571356)                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=571356)     self.quant_method.create_weights(
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=571356)     layer.scheme.create_weights(
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=571356)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=571356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=571356)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=571356)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=571356)     data=torch.empty(
(EngineCore_DP0 pid=571356)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=571356)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=571356)     return func(*args, **kwargs)
(EngineCore_DP0 pid=571356)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=571356) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 36.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 113.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:15:46.940868083 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:16:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 68.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 110.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     raise e
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) ERROR 01-25 22:16:25 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 68.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 110.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:16:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:16:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=572142) [2026-01-25 22:16:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=572142) Process EngineCore_DP0:
(EngineCore_DP0 pid=572142) Traceback (most recent call last):
(EngineCore_DP0 pid=572142)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=572142)     self.run()
(EngineCore_DP0 pid=572142)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=572142)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=572142)     raise e
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572142)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572142)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572142)     super().__init__(
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572142)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572142)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572142)     self._init_executor()
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572142)     self.driver_worker.load_model()
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572142)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572142)     raise e
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572142)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572142)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572142)     model = initialize_model(
(EngineCore_DP0 pid=572142)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572142)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572142)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572142)     self.model = Qwen2Model(
(EngineCore_DP0 pid=572142)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572142)     old_init(self, **kwargs)
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572142)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572142)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572142)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572142)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572142)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572142)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572142)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572142)                ^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=572142)     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=572142)                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=572142)     self.quant_method.create_weights(
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572142)     layer.scheme.create_weights(
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572142)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572142)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572142)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572142)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572142)     data=torch.empty(
(EngineCore_DP0 pid=572142)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572142)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572142)     return func(*args, **kwargs)
(EngineCore_DP0 pid=572142)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572142) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 68.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 110.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:16:25.259834761 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:16:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 96.94 MiB is free. Including non-PyTorch memory, this process has 15.15 GiB memory in use. Of the allocated memory 14.67 GiB is allocated by PyTorch, and 111.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     raise e
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) ERROR 01-25 22:16:36 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 96.94 MiB is free. Including non-PyTorch memory, this process has 15.15 GiB memory in use. Of the allocated memory 14.67 GiB is allocated by PyTorch, and 111.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:16:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:16:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=572535) [2026-01-25 22:16:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=572535) Process EngineCore_DP0:
(EngineCore_DP0 pid=572535) Traceback (most recent call last):
(EngineCore_DP0 pid=572535)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=572535)     self.run()
(EngineCore_DP0 pid=572535)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=572535)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=572535)     raise e
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572535)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572535)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572535)     super().__init__(
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572535)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572535)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572535)     self._init_executor()
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572535)     self.driver_worker.load_model()
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572535)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572535)     raise e
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572535)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572535)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572535)     model = initialize_model(
(EngineCore_DP0 pid=572535)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572535)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572535)     self.model = Qwen2Model(
(EngineCore_DP0 pid=572535)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572535)     old_init(self, **kwargs)
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572535)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572535)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572535)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572535)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572535)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572535)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572535)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572535)                ^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=572535)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=572535)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=572535)     super().__init__(
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=572535)     self.quant_method.create_weights(
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572535)     layer.scheme.create_weights(
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572535)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572535)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572535)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572535)     data=torch.empty(
(EngineCore_DP0 pid=572535)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572535)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572535)     return func(*args, **kwargs)
(EngineCore_DP0 pid=572535)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572535) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 96.94 MiB is free. Including non-PyTorch memory, this process has 15.15 GiB memory in use. Of the allocated memory 14.67 GiB is allocated by PyTorch, and 111.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:16:36.164616248 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:16:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 84.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.68 GiB is allocated by PyTorch, and 118.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     raise e
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) ERROR 01-25 22:16:46 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 84.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.68 GiB is allocated by PyTorch, and 118.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:16:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:16:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=572939) [2026-01-25 22:16:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=572939) Process EngineCore_DP0:
(EngineCore_DP0 pid=572939) Traceback (most recent call last):
(EngineCore_DP0 pid=572939)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=572939)     self.run()
(EngineCore_DP0 pid=572939)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=572939)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=572939)     raise e
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=572939)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=572939)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=572939)     super().__init__(
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=572939)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=572939)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=572939)     self._init_executor()
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=572939)     self.driver_worker.load_model()
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=572939)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=572939)     raise e
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=572939)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=572939)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=572939)     model = initialize_model(
(EngineCore_DP0 pid=572939)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=572939)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=572939)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=572939)     self.model = Qwen2Model(
(EngineCore_DP0 pid=572939)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=572939)     old_init(self, **kwargs)
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=572939)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=572939)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=572939)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=572939)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=572939)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=572939)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=572939)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=572939)                ^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=572939)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=572939)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=572939)     super().__init__(
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=572939)     self.quant_method.create_weights(
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=572939)     layer.scheme.create_weights(
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=572939)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=572939)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=572939)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=572939)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=572939)     data=torch.empty(
(EngineCore_DP0 pid=572939)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=572939)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=572939)     return func(*args, **kwargs)
(EngineCore_DP0 pid=572939)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=572939) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 84.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.68 GiB is allocated by PyTorch, and 118.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:16:47.052136168 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:16:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 116.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     raise e
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) ERROR 01-25 22:16:58 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 116.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:16:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:16:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:16:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:16:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=573336) [2026-01-25 22:16:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=573336) Process EngineCore_DP0:
(EngineCore_DP0 pid=573336) Traceback (most recent call last):
(EngineCore_DP0 pid=573336)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=573336)     self.run()
(EngineCore_DP0 pid=573336)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=573336)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=573336)     raise e
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=573336)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=573336)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=573336)     super().__init__(
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=573336)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=573336)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=573336)     self._init_executor()
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=573336)     self.driver_worker.load_model()
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=573336)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=573336)     raise e
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=573336)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=573336)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=573336)     model = initialize_model(
(EngineCore_DP0 pid=573336)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=573336)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=573336)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=573336)     self.model = Qwen2Model(
(EngineCore_DP0 pid=573336)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=573336)     old_init(self, **kwargs)
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=573336)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=573336)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=573336)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=573336)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=573336)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=573336)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=573336)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=573336)                ^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=573336)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=573336)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=573336)     super().__init__(
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=573336)     self.quant_method.create_weights(
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=573336)     layer.scheme.create_weights(
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=573336)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=573336)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=573336)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=573336)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=573336)     data=torch.empty(
(EngineCore_DP0 pid=573336)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=573336)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=573336)     return func(*args, **kwargs)
(EngineCore_DP0 pid=573336)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573336) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 15.17 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 116.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:16:59.823291342 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:17:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     raise e
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) ERROR 01-25 22:17:11 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:17:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:17:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=573755) [2026-01-25 22:17:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=573755) Process EngineCore_DP0:
(EngineCore_DP0 pid=573755) Traceback (most recent call last):
(EngineCore_DP0 pid=573755)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=573755)     self.run()
(EngineCore_DP0 pid=573755)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=573755)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=573755)     raise e
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=573755)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=573755)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=573755)     super().__init__(
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=573755)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=573755)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=573755)     self._init_executor()
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=573755)     self.driver_worker.load_model()
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=573755)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=573755)     raise e
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=573755)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=573755)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=573755)     model = initialize_model(
(EngineCore_DP0 pid=573755)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=573755)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=573755)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=573755)     self.model = Qwen2Model(
(EngineCore_DP0 pid=573755)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=573755)     old_init(self, **kwargs)
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=573755)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=573755)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=573755)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=573755)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=573755)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=573755)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=573755)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=573755)                ^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=573755)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=573755)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=573755)     super().__init__(
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=573755)     self.quant_method.create_weights(
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=573755)     layer.scheme.create_weights(
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=573755)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=573755)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=573755)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=573755)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=573755)     data=torch.empty(
(EngineCore_DP0 pid=573755)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=573755)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=573755)     return func(*args, **kwargs)
(EngineCore_DP0 pid=573755)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=573755) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:17:11.237982981 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:17:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 54.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     raise e
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 160, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.o_proj = RowParallelLinear(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) ERROR 01-25 22:17:25 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 54.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:17:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:17:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=574199) [2026-01-25 22:17:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=574199) Process EngineCore_DP0:
(EngineCore_DP0 pid=574199) Traceback (most recent call last):
(EngineCore_DP0 pid=574199)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=574199)     self.run()
(EngineCore_DP0 pid=574199)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=574199)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=574199)     raise e
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=574199)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=574199)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=574199)     super().__init__(
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=574199)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=574199)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=574199)     self._init_executor()
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=574199)     self.driver_worker.load_model()
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=574199)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=574199)     raise e
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=574199)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=574199)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=574199)     model = initialize_model(
(EngineCore_DP0 pid=574199)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=574199)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=574199)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=574199)     self.model = Qwen2Model(
(EngineCore_DP0 pid=574199)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=574199)     old_init(self, **kwargs)
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=574199)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=574199)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=574199)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=574199)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=574199)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=574199)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=574199)     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=574199)                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 160, in __init__
(EngineCore_DP0 pid=574199)     self.o_proj = RowParallelLinear(
(EngineCore_DP0 pid=574199)                   ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=574199)     self.quant_method.create_weights(
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=574199)     layer.scheme.create_weights(
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=574199)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=574199)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=574199)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=574199)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=574199)     data=torch.empty(
(EngineCore_DP0 pid=574199)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=574199)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=574199)     return func(*args, **kwargs)
(EngineCore_DP0 pid=574199)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574199) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 54.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 116.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:17:25.763514203 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:17:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 28.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     raise e
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 151, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.qkv_proj = QKVParallelLinear(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 935, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) ERROR 01-25 22:17:43 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 28.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:17:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:17:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:17:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:17:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:17:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:17:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:17:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:17:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:17:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=574690) [2026-01-25 22:17:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=574690) Process EngineCore_DP0:
(EngineCore_DP0 pid=574690) Traceback (most recent call last):
(EngineCore_DP0 pid=574690)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=574690)     self.run()
(EngineCore_DP0 pid=574690)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=574690)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=574690)     raise e
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=574690)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=574690)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=574690)     super().__init__(
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=574690)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=574690)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=574690)     self._init_executor()
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=574690)     self.driver_worker.load_model()
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=574690)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=574690)     raise e
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=574690)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=574690)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=574690)     model = initialize_model(
(EngineCore_DP0 pid=574690)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=574690)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=574690)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=574690)     self.model = Qwen2Model(
(EngineCore_DP0 pid=574690)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=574690)     old_init(self, **kwargs)
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=574690)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=574690)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=574690)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=574690)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=574690)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=574690)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=574690)     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=574690)                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 151, in __init__
(EngineCore_DP0 pid=574690)     self.qkv_proj = QKVParallelLinear(
(EngineCore_DP0 pid=574690)                     ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 935, in __init__
(EngineCore_DP0 pid=574690)     super().__init__(
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=574690)     self.quant_method.create_weights(
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=574690)     layer.scheme.create_weights(
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=574690)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=574690)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=574690)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=574690)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=574690)     data=torch.empty(
(EngineCore_DP0 pid=574690)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=574690)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=574690)     return func(*args, **kwargs)
(EngineCore_DP0 pid=574690)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=574690) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 28.94 MiB is free. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 114.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:17:43.736009447 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:18:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 174.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 112.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     raise e
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) ERROR 01-25 22:18:08 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 174.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 112.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:18:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:18:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=575283) [2026-01-25 22:18:08] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=575283) Process EngineCore_DP0:
(EngineCore_DP0 pid=575283) Traceback (most recent call last):
(EngineCore_DP0 pid=575283)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=575283)     self.run()
(EngineCore_DP0 pid=575283)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=575283)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=575283)     raise e
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=575283)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=575283)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=575283)     super().__init__(
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=575283)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=575283)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=575283)     self._init_executor()
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=575283)     self.driver_worker.load_model()
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=575283)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=575283)     raise e
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=575283)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=575283)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=575283)     model = initialize_model(
(EngineCore_DP0 pid=575283)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=575283)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=575283)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=575283)     self.model = Qwen2Model(
(EngineCore_DP0 pid=575283)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=575283)     old_init(self, **kwargs)
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=575283)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=575283)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=575283)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=575283)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=575283)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=575283)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=575283)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=575283)                ^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=575283)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=575283)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=575283)     super().__init__(
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=575283)     self.quant_method.create_weights(
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=575283)     layer.scheme.create_weights(
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=575283)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=575283)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=575283)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=575283)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=575283)     data=torch.empty(
(EngineCore_DP0 pid=575283)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=575283)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=575283)     return func(*args, **kwargs)
(EngineCore_DP0 pid=575283)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=575283) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 174.94 MiB is free. Including non-PyTorch memory, this process has 15.07 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 112.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:18:08.639438295 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:18:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 44.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.72 GiB is allocated by PyTorch, and 112.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     raise e
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) ERROR 01-25 22:18:47 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 44.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.72 GiB is allocated by PyTorch, and 112.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:18:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:18:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=576066) [2026-01-25 22:18:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=576066) Process EngineCore_DP0:
(EngineCore_DP0 pid=576066) Traceback (most recent call last):
(EngineCore_DP0 pid=576066)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=576066)     self.run()
(EngineCore_DP0 pid=576066)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=576066)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=576066)     raise e
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576066)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576066)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576066)     super().__init__(
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576066)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576066)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576066)     self._init_executor()
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576066)     self.driver_worker.load_model()
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576066)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576066)     raise e
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576066)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576066)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576066)     model = initialize_model(
(EngineCore_DP0 pid=576066)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576066)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576066)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576066)     self.model = Qwen2Model(
(EngineCore_DP0 pid=576066)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576066)     old_init(self, **kwargs)
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576066)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576066)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576066)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576066)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576066)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576066)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576066)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576066)                ^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=576066)     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=576066)                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=576066)     self.quant_method.create_weights(
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576066)     layer.scheme.create_weights(
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576066)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576066)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576066)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576066)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576066)     data=torch.empty(
(EngineCore_DP0 pid=576066)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576066)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576066)     return func(*args, **kwargs)
(EngineCore_DP0 pid=576066)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576066) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 44.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.72 GiB is allocated by PyTorch, and 112.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:18:48.958844949 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败

============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:18:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     raise e
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) ERROR 01-25 22:18:58 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:18:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:18:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:18:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:18:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=576466) [2026-01-25 22:18:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=576466) Process EngineCore_DP0:
(EngineCore_DP0 pid=576466) Traceback (most recent call last):
(EngineCore_DP0 pid=576466)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=576466)     self.run()
(EngineCore_DP0 pid=576466)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=576466)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=576466)     raise e
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576466)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576466)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576466)     super().__init__(
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576466)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576466)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576466)     self._init_executor()
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576466)     self.driver_worker.load_model()
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576466)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576466)     raise e
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576466)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576466)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576466)     model = initialize_model(
(EngineCore_DP0 pid=576466)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576466)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576466)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576466)     self.model = Qwen2Model(
(EngineCore_DP0 pid=576466)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576466)     old_init(self, **kwargs)
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576466)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576466)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576466)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576466)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576466)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576466)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576466)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576466)                ^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=576466)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=576466)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=576466)     super().__init__(
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=576466)     self.quant_method.create_weights(
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576466)     layer.scheme.create_weights(
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576466)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576466)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576466)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576466)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576466)     data=torch.empty(
(EngineCore_DP0 pid=576466)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576466)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576466)     return func(*args, **kwargs)
(EngineCore_DP0 pid=576466)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576466) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:18:58.727462431 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=512 (exit code: 1)

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:19:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 108.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 75.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     raise e
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) ERROR 01-25 22:19:09 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 108.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 75.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:19:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:19:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=576864) [2026-01-25 22:19:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=576864) Process EngineCore_DP0:
(EngineCore_DP0 pid=576864) Traceback (most recent call last):
(EngineCore_DP0 pid=576864)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=576864)     self.run()
(EngineCore_DP0 pid=576864)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=576864)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=576864)     raise e
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=576864)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=576864)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=576864)     super().__init__(
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=576864)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=576864)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=576864)     self._init_executor()
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=576864)     self.driver_worker.load_model()
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=576864)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=576864)     raise e
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=576864)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=576864)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=576864)     model = initialize_model(
(EngineCore_DP0 pid=576864)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=576864)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=576864)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=576864)     self.model = Qwen2Model(
(EngineCore_DP0 pid=576864)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=576864)     old_init(self, **kwargs)
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=576864)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=576864)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=576864)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=576864)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=576864)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=576864)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=576864)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=576864)                ^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=576864)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=576864)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=576864)     super().__init__(
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=576864)     self.quant_method.create_weights(
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=576864)     layer.scheme.create_weights(
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=576864)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=576864)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=576864)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=576864)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=576864)     data=torch.empty(
(EngineCore_DP0 pid=576864)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=576864)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=576864)     return func(*args, **kwargs)
(EngineCore_DP0 pid=576864)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=576864) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 108.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 75.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:19:10.880519652 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=1024 (exit code: 1)

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:19:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 100.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 73.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     raise e
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) ERROR 01-25 22:19:20 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 100.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 73.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:19:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:19:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=577261) [2026-01-25 22:19:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=577261) Process EngineCore_DP0:
(EngineCore_DP0 pid=577261) Traceback (most recent call last):
(EngineCore_DP0 pid=577261)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=577261)     self.run()
(EngineCore_DP0 pid=577261)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=577261)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=577261)     raise e
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=577261)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=577261)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=577261)     super().__init__(
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=577261)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=577261)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=577261)     self._init_executor()
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=577261)     self.driver_worker.load_model()
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=577261)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=577261)     raise e
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=577261)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=577261)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=577261)     model = initialize_model(
(EngineCore_DP0 pid=577261)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=577261)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=577261)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=577261)     self.model = Qwen2Model(
(EngineCore_DP0 pid=577261)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=577261)     old_init(self, **kwargs)
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=577261)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=577261)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=577261)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=577261)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=577261)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=577261)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=577261)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=577261)                ^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=577261)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=577261)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=577261)     super().__init__(
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=577261)     self.quant_method.create_weights(
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=577261)     layer.scheme.create_weights(
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=577261)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=577261)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=577261)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=577261)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=577261)     data=torch.empty(
(EngineCore_DP0 pid=577261)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=577261)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=577261)     return func(*args, **kwargs)
(EngineCore_DP0 pid=577261)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577261) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 100.94 MiB is free. Including non-PyTorch memory, this process has 15.14 GiB memory in use. Of the allocated memory 14.71 GiB is allocated by PyTorch, and 73.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:19:21.091930281 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=2048 (exit code: 1)

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:19:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 73.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     raise e
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) ERROR 01-25 22:19:33 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 73.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:19:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:19:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=577683) [2026-01-25 22:19:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=577683) Process EngineCore_DP0:
(EngineCore_DP0 pid=577683) Traceback (most recent call last):
(EngineCore_DP0 pid=577683)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=577683)     self.run()
(EngineCore_DP0 pid=577683)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=577683)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=577683)     raise e
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=577683)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=577683)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=577683)     super().__init__(
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=577683)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=577683)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=577683)     self._init_executor()
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=577683)     self.driver_worker.load_model()
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=577683)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=577683)     raise e
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=577683)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=577683)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=577683)     model = initialize_model(
(EngineCore_DP0 pid=577683)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=577683)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=577683)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=577683)     self.model = Qwen2Model(
(EngineCore_DP0 pid=577683)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=577683)     old_init(self, **kwargs)
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=577683)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=577683)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=577683)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=577683)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=577683)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=577683)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=577683)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=577683)                ^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=577683)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=577683)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=577683)     super().__init__(
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=577683)     self.quant_method.create_weights(
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=577683)     layer.scheme.create_weights(
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=577683)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=577683)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=577683)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=577683)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=577683)     data=torch.empty(
(EngineCore_DP0 pid=577683)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=577683)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=577683)     return func(*args, **kwargs)
(EngineCore_DP0 pid=577683)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=577683) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 15.16 GiB memory in use. Of the allocated memory 14.73 GiB is allocated by PyTorch, and 73.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:19:33.773908305 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=4096 (exit code: 1)

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:19:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 40.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 73.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     raise e
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) ERROR 01-25 22:19:47 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 40.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 73.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:19:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:19:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:19:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:19:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:19:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:19:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:19:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:19:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:19:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=578129) [2026-01-25 22:19:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=578129) Process EngineCore_DP0:
(EngineCore_DP0 pid=578129) Traceback (most recent call last):
(EngineCore_DP0 pid=578129)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=578129)     self.run()
(EngineCore_DP0 pid=578129)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=578129)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=578129)     raise e
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=578129)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=578129)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=578129)     super().__init__(
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=578129)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=578129)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=578129)     self._init_executor()
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=578129)     self.driver_worker.load_model()
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=578129)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=578129)     raise e
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=578129)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=578129)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=578129)     model = initialize_model(
(EngineCore_DP0 pid=578129)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=578129)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=578129)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=578129)     self.model = Qwen2Model(
(EngineCore_DP0 pid=578129)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=578129)     old_init(self, **kwargs)
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=578129)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=578129)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=578129)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=578129)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=578129)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=578129)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=578129)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=578129)                ^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=578129)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=578129)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=578129)     super().__init__(
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=578129)     self.quant_method.create_weights(
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=578129)     layer.scheme.create_weights(
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=578129)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=578129)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=578129)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=578129)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=578129)     data=torch.empty(
(EngineCore_DP0 pid=578129)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=578129)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=578129)     return func(*args, **kwargs)
(EngineCore_DP0 pid=578129)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578129) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 40.94 MiB is free. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 73.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:19:48.803942390 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:20:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.75 GiB is allocated by PyTorch, and 72.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     raise e
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 151, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.qkv_proj = QKVParallelLinear(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]                     ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 935, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) ERROR 01-25 22:20:05 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.75 GiB is allocated by PyTorch, and 72.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:20:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:20:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=578621) [2026-01-25 22:20:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=578621) Process EngineCore_DP0:
(EngineCore_DP0 pid=578621) Traceback (most recent call last):
(EngineCore_DP0 pid=578621)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=578621)     self.run()
(EngineCore_DP0 pid=578621)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=578621)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=578621)     raise e
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=578621)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=578621)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=578621)     super().__init__(
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=578621)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=578621)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=578621)     self._init_executor()
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=578621)     self.driver_worker.load_model()
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=578621)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=578621)     raise e
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=578621)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=578621)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=578621)     model = initialize_model(
(EngineCore_DP0 pid=578621)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=578621)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=578621)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=578621)     self.model = Qwen2Model(
(EngineCore_DP0 pid=578621)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=578621)     old_init(self, **kwargs)
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=578621)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=578621)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=578621)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=578621)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=578621)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=578621)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 258, in __init__
(EngineCore_DP0 pid=578621)     self.self_attn = Qwen2Attention(
(EngineCore_DP0 pid=578621)                      ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 151, in __init__
(EngineCore_DP0 pid=578621)     self.qkv_proj = QKVParallelLinear(
(EngineCore_DP0 pid=578621)                     ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 935, in __init__
(EngineCore_DP0 pid=578621)     super().__init__(
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=578621)     self.quant_method.create_weights(
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=578621)     layer.scheme.create_weights(
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=578621)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=578621)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=578621)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=578621)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=578621)     data=torch.empty(
(EngineCore_DP0 pid=578621)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=578621)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=578621)     return func(*args, **kwargs)
(EngineCore_DP0 pid=578621)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=578621) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 14.75 GiB is allocated by PyTorch, and 72.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:20:05.735911126 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:20:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 222.94 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 70.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     raise e
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) ERROR 01-25 22:20:30 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 222.94 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 70.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:20:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:20:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:20:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:20:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=579195) [2026-01-25 22:20:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=579195) Process EngineCore_DP0:
(EngineCore_DP0 pid=579195) Traceback (most recent call last):
(EngineCore_DP0 pid=579195)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=579195)     self.run()
(EngineCore_DP0 pid=579195)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=579195)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=579195)     raise e
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579195)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579195)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579195)     super().__init__(
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=579195)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=579195)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=579195)     self._init_executor()
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=579195)     self.driver_worker.load_model()
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=579195)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=579195)     raise e
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=579195)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=579195)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=579195)     model = initialize_model(
(EngineCore_DP0 pid=579195)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=579195)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=579195)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=579195)     self.model = Qwen2Model(
(EngineCore_DP0 pid=579195)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=579195)     old_init(self, **kwargs)
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=579195)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=579195)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=579195)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=579195)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=579195)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=579195)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=579195)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=579195)                ^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=579195)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=579195)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=579195)     super().__init__(
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=579195)     self.quant_method.create_weights(
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=579195)     layer.scheme.create_weights(
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=579195)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=579195)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=579195)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=579195)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=579195)     data=torch.empty(
(EngineCore_DP0 pid=579195)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=579195)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=579195)     return func(*args, **kwargs)
(EngineCore_DP0 pid=579195)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579195) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 222.94 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 70.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:20:30.746888935 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:21:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 106.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 68.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     raise e
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) ERROR 01-25 22:21:10 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 106.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 68.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 22:21:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:21:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:21:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:21:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:21:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:21:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:21:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:21:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:21:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:21:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:21:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-25 22:21:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-25 22:21:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:21:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:21:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:21:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:21:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=579990) [2026-01-25 22:21:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=579990) Process EngineCore_DP0:
(EngineCore_DP0 pid=579990) Traceback (most recent call last):
(EngineCore_DP0 pid=579990)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=579990)     self.run()
(EngineCore_DP0 pid=579990)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=579990)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=579990)     raise e
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=579990)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=579990)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=579990)     super().__init__(
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=579990)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=579990)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=579990)     self._init_executor()
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=579990)     self.driver_worker.load_model()
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=579990)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=579990)     raise e
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=579990)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=579990)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=579990)     model = initialize_model(
(EngineCore_DP0 pid=579990)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=579990)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=579990)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=579990)     self.model = Qwen2Model(
(EngineCore_DP0 pid=579990)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=579990)     old_init(self, **kwargs)
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=579990)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=579990)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=579990)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=579990)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=579990)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=579990)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=579990)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=579990)                ^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 92, in __init__
(EngineCore_DP0 pid=579990)     self.down_proj = RowParallelLinear(
(EngineCore_DP0 pid=579990)                      ^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1312, in __init__
(EngineCore_DP0 pid=579990)     self.quant_method.create_weights(
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=579990)     layer.scheme.create_weights(
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 592, in create_weights
(EngineCore_DP0 pid=579990)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=579990)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py", line 117, in create_weights
(EngineCore_DP0 pid=579990)     weight = create_fp8_weight_parameter(
(EngineCore_DP0 pid=579990)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/root/vllmbench/vllm/model_executor/layers/quantization/utils/fp8_utils.py", line 1296, in create_fp8_weight_parameter
(EngineCore_DP0 pid=579990)     data=torch.empty(
(EngineCore_DP0 pid=579990)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=579990)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=579990)     return func(*args, **kwargs)
(EngineCore_DP0 pid=579990)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=579990) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 106.94 MiB is free. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, and 68.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 22:21:10.234534603 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-14B-FP8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-14B-FP8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,-1.0000,-1.0000,-1.0000
1024,1024,1,128,128,-1.0000,-1.0000,-1.0000
2048,1024,2,256,128,-1.0000,-1.0000,-1.0000
4096,1024,4,512,128,-1.0000,-1.0000,-1.0000
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 0 成功, 8 失败


============================================================
  Benchmark 完成!
============================================================


总计: 0 成功, 40 失败
============================================================
