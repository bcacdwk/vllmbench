======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-23 03:31:20
======================================================================

原始命令:
  throughput_benchmark.py --model int8 --backend cutlass --dry-run --M quick

命令行参数:
  --model: int8
  --backend: cutlass
  --sparsity: None
  --stage: None
  --M: quick
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: True
  --list-models: False

硬件信息:
  GPU: RTX5080
  Compute Capability: cc120
  VRAM: 15.5 GB
  CUDA: 12.9
  Python: py312

======================================================================

[WARNING] Backend 不支持，跳过: Qwen2.5-0.5B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Llama3.2-1B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Qwen2.5-1.5B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Qwen2.5-3B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Llama3.2-3B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Qwen2.5-7B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100
[WARNING] Backend 不支持，跳过: Qwen2.5-14B-INT8 + cutlass
[WARNING]   原因: vLLM CUTLASS INT8 不支持: sm_120 >= sm_100


============================================================
  Benchmark 完成!
============================================================


总计: 0 成功, 0 失败
============================================================
