======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-25 20:44:28
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-7b-int8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX5080
  Compute Capability: cc120
  VRAM: 15.5 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-7B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:44:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=456715) WARNING 01-25 20:44:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.60 requests/s, 15186.05 total tokens/s, 29.60 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:44:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:44:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:44:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:44:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:44:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:44:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:44:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:44:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:44:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:44:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:44:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:44:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=456715) [2026-01-25 20:44:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=456715) [2026-01-25 20:44:40] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=456715) [2026-01-25 20:44:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=456715) [2026-01-25 20:44:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=456715) [2026-01-25 20:44:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=456715) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=456715) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.56s/it]
(EngineCore_DP0 pid=456715) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.33s/it]
(EngineCore_DP0 pid=456715) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.22s/it]
(EngineCore_DP0 pid=456715) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=456715) 2026-01-25 20:44:59,460 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=456715) 2026-01-25 20:44:59,475 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=456715) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]
(EngineCore_DP0 pid=456715) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  72%|███████▏  | 92/128 [00:00<00:00, 910.42it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 928.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:40,  3.10it/s, est. speed input: 1587.07 toks/s, output: 3.10 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 13.53it/s, est. speed input: 5764.30 toks/s, output: 11.26 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 19.94it/s, est. speed input: 8132.76 toks/s, output: 15.88 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 24.11it/s, est. speed input: 9671.47 toks/s, output: 18.89 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 26.89it/s, est. speed input: 10749.88 toks/s, output: 21.00 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.77it/s, est. speed input: 11547.42 toks/s, output: 22.55 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 29.94it/s, est. speed input: 12145.02 toks/s, output: 23.72 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 30.77it/s, est. speed input: 12620.69 toks/s, output: 24.65 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 31.40it/s, est. speed input: 13015.14 toks/s, output: 25.42 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 31.83it/s, est. speed input: 13340.17 toks/s, output: 26.05 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.14it/s, est. speed input: 13615.66 toks/s, output: 26.59 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.40it/s, est. speed input: 13854.83 toks/s, output: 27.06 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.58it/s, est. speed input: 14061.76 toks/s, output: 27.46 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.64it/s, est. speed input: 14235.70 toks/s, output: 27.80 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 32.72it/s, est. speed input: 14392.22 toks/s, output: 28.11 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.80it/s, est. speed input: 14533.15 toks/s, output: 28.38 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.83it/s, est. speed input: 14657.05 toks/s, output: 28.63 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.85it/s, est. speed input: 14767.97 toks/s, output: 28.84 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.90it/s, est. speed input: 14870.87 toks/s, output: 29.04 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.92it/s, est. speed input: 14963.34 toks/s, output: 29.23 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.90it/s, est. speed input: 15045.75 toks/s, output: 29.39 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.93it/s, est. speed input: 15123.28 toks/s, output: 29.54 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 32.90it/s, est. speed input: 15192.22 toks/s, output: 29.67 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.92it/s, est. speed input: 15257.67 toks/s, output: 29.80 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.87it/s, est. speed input: 15314.53 toks/s, output: 29.91 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.84it/s, est. speed input: 15367.46 toks/s, output: 30.01 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.85it/s, est. speed input: 15418.82 toks/s, output: 30.11 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.88it/s, est. speed input: 15467.41 toks/s, output: 30.21 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.92it/s, est. speed input: 15514.40 toks/s, output: 30.30 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.94it/s, est. speed input: 15557.69 toks/s, output: 30.39 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.96it/s, est. speed input: 15598.31 toks/s, output: 30.47 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 32.95it/s, est. speed input: 15635.84 toks/s, output: 30.54 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.95it/s, est. speed input: 15662.39 toks/s, output: 30.59 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.59it/s, est. speed input: 15662.39 toks/s, output: 30.59 toks/s]
[rank0]:[W125 20:45:05.710910390 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 38.3s

测试结果:
  Requests/s:   29.60
  Tokens/s:     15186.05
  Total Reqs:   128
  Elapsed:      4.32s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     15156.45

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:45:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=457806) WARNING 01-25 20:45:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.14 requests/s, 17570.17 total tokens/s, 17.14 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:45:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:45:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:45:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:45:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=457806) [2026-01-25 20:45:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=457806) [2026-01-25 20:45:16] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=457806) [2026-01-25 20:45:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=457806) [2026-01-25 20:45:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=457806) [2026-01-25 20:45:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=457806) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=457806) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.87it/s]
(EngineCore_DP0 pid=457806) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.19it/s]
(EngineCore_DP0 pid=457806) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.27it/s]
(EngineCore_DP0 pid=457806) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=457806) 2026-01-25 20:45:27,488 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=457806) 2026-01-25 20:45:27,504 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=457806) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 22.61it/s]
(EngineCore_DP0 pid=457806) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 49/128 [00:00<00:00, 483.58it/s]
Adding requests:  80%|████████  | 103/128 [00:00<00:00, 512.95it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 511.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 21.06it/s, est. speed input: 21568.05 toks/s, output: 21.06 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:06, 18.98it/s, est. speed input: 19730.31 toks/s, output: 19.27 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 18.46it/s, est. speed input: 19274.14 toks/s, output: 18.82 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:06, 18.22it/s, est. speed input: 19048.30 toks/s, output: 18.60 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:06, 18.05it/s, est. speed input: 18889.61 toks/s, output: 18.45 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 17.95it/s, est. speed input: 18782.13 toks/s, output: 18.34 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 17.86it/s, est. speed input: 18691.83 toks/s, output: 18.25 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:06, 17.76it/s, est. speed input: 18608.06 toks/s, output: 18.17 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 17.74it/s, est. speed input: 18557.68 toks/s, output: 18.12 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 17.71it/s, est. speed input: 18511.75 toks/s, output: 18.08 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 17.73it/s, est. speed input: 18484.45 toks/s, output: 18.05 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.72it/s, est. speed input: 18455.99 toks/s, output: 18.02 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 17.68it/s, est. speed input: 18424.60 toks/s, output: 17.99 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 17.65it/s, est. speed input: 18396.34 toks/s, output: 17.96 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 17.65it/s, est. speed input: 18375.93 toks/s, output: 17.95 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 17.68it/s, est. speed input: 18362.84 toks/s, output: 17.93 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 17.69it/s, est. speed input: 18351.23 toks/s, output: 17.92 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 17.68it/s, est. speed input: 18335.94 toks/s, output: 17.91 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:04, 17.69it/s, est. speed input: 18326.27 toks/s, output: 17.90 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 17.68it/s, est. speed input: 18314.55 toks/s, output: 17.89 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.69it/s, est. speed input: 18306.83 toks/s, output: 17.88 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.70it/s, est. speed input: 18300.30 toks/s, output: 17.87 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 17.72it/s, est. speed input: 18295.18 toks/s, output: 17.87 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 17.70it/s, est. speed input: 18286.47 toks/s, output: 17.86 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 17.69it/s, est. speed input: 18279.15 toks/s, output: 17.85 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 17.68it/s, est. speed input: 18270.89 toks/s, output: 17.84 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 17.68it/s, est. speed input: 18265.05 toks/s, output: 17.84 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:03, 17.67it/s, est. speed input: 18258.45 toks/s, output: 17.83 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.69it/s, est. speed input: 18254.75 toks/s, output: 17.83 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.70it/s, est. speed input: 18251.49 toks/s, output: 17.82 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.69it/s, est. speed input: 18246.99 toks/s, output: 17.82 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.69it/s, est. speed input: 18242.84 toks/s, output: 17.82 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 17.68it/s, est. speed input: 18237.39 toks/s, output: 17.81 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.68it/s, est. speed input: 18233.56 toks/s, output: 17.81 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 17.67it/s, est. speed input: 18228.81 toks/s, output: 17.80 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 17.67it/s, est. speed input: 18225.69 toks/s, output: 17.80 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:02, 17.68it/s, est. speed input: 18223.06 toks/s, output: 17.80 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.67it/s, est. speed input: 18219.28 toks/s, output: 17.79 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.67it/s, est. speed input: 18216.20 toks/s, output: 17.79 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.66it/s, est. speed input: 18212.55 toks/s, output: 17.79 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 17.67it/s, est. speed input: 18210.25 toks/s, output: 17.78 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 17.66it/s, est. speed input: 18206.27 toks/s, output: 17.78 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 17.66it/s, est. speed input: 18203.74 toks/s, output: 17.78 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 17.64it/s, est. speed input: 18199.43 toks/s, output: 17.77 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.64it/s, est. speed input: 18196.36 toks/s, output: 17.77 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.65it/s, est. speed input: 18194.66 toks/s, output: 17.77 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.66it/s, est. speed input: 18192.35 toks/s, output: 17.77 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.66it/s, est. speed input: 18190.28 toks/s, output: 17.76 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.67it/s, est. speed input: 18189.10 toks/s, output: 17.76 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.67it/s, est. speed input: 18187.34 toks/s, output: 17.76 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 17.63it/s, est. speed input: 18182.46 toks/s, output: 17.76 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 17.64it/s, est. speed input: 18180.59 toks/s, output: 17.75 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.66it/s, est. speed input: 18179.91 toks/s, output: 17.75 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.67it/s, est. speed input: 18179.01 toks/s, output: 17.75 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.68it/s, est. speed input: 18178.03 toks/s, output: 17.75 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.69it/s, est. speed input: 18177.29 toks/s, output: 17.75 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.67it/s, est. speed input: 18175.22 toks/s, output: 17.75 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.69it/s, est. speed input: 18174.93 toks/s, output: 17.75 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.69it/s, est. speed input: 18174.12 toks/s, output: 17.75 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 17.68it/s, est. speed input: 18172.39 toks/s, output: 17.75 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 17.66it/s, est. speed input: 18170.00 toks/s, output: 17.74 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.66it/s, est. speed input: 18169.02 toks/s, output: 17.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.65it/s, est. speed input: 18167.05 toks/s, output: 17.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.65it/s, est. speed input: 18167.05 toks/s, output: 17.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.74it/s, est. speed input: 18167.05 toks/s, output: 17.74 toks/s]
[rank0]:[W125 20:45:36.119654404 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 30.4s

测试结果:
  Requests/s:   17.14
  Tokens/s:     17570.17
  Total Reqs:   128
  Elapsed:      7.47s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     17553.03

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:45:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=458532) WARNING 01-25 20:45:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.92 requests/s, 18369.70 total tokens/s, 17.92 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 20:45:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:45:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:45:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:45:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=458532) [2026-01-25 20:45:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=458532) [2026-01-25 20:45:46] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=458532) [2026-01-25 20:45:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=458532) [2026-01-25 20:45:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=458532) [2026-01-25 20:45:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=458532) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=458532) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.82it/s]
(EngineCore_DP0 pid=458532) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.15it/s]
(EngineCore_DP0 pid=458532) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.23it/s]
(EngineCore_DP0 pid=458532) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=458532) 2026-01-25 20:45:58,138 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=458532) 2026-01-25 20:45:58,154 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=458532) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 22.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 21.99it/s]
(EngineCore_DP0 pid=458532) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.82it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 45/256 [00:00<00:00, 445.35it/s]
Adding requests:  39%|███▉      | 101/256 [00:00<00:00, 509.51it/s]
Adding requests:  61%|██████▏   | 157/256 [00:00<00:00, 532.41it/s]
Adding requests:  84%|████████▍ | 216/256 [00:00<00:00, 551.04it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 540.41it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:04, 53.84it/s, est. speed input: 55138.97 toks/s, output: 53.84 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:08, 28.10it/s, est. speed input: 31608.88 toks/s, output: 30.87 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:09, 24.00it/s, est. speed input: 27661.73 toks/s, output: 27.01 toks/s]
Processed prompts:   9%|▉         | 23/256 [00:00<00:09, 24.68it/s, est. speed input: 27664.02 toks/s, output: 27.02 toks/s]
Processed prompts:  10%|█         | 26/256 [00:01<00:11, 20.31it/s, est. speed input: 24805.46 toks/s, output: 24.22 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:01<00:10, 21.79it/s, est. speed input: 25077.60 toks/s, output: 24.49 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:01<00:12, 18.62it/s, est. speed input: 23311.22 toks/s, output: 22.76 toks/s]
Processed prompts:  14%|█▎        | 35/256 [00:01<00:10, 20.44it/s, est. speed input: 23631.27 toks/s, output: 23.08 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:01<00:12, 17.79it/s, est. speed input: 22379.89 toks/s, output: 21.86 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:12, 17.82it/s, est. speed input: 22136.99 toks/s, output: 21.62 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:01<00:11, 17.86it/s, est. speed input: 21927.09 toks/s, output: 21.41 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:02<00:11, 17.90it/s, est. speed input: 21740.62 toks/s, output: 21.23 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:02<00:11, 17.94it/s, est. speed input: 21575.94 toks/s, output: 21.07 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:02<00:11, 17.96it/s, est. speed input: 21424.40 toks/s, output: 20.92 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:02<00:11, 17.98it/s, est. speed input: 21288.29 toks/s, output: 20.79 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:11, 18.00it/s, est. speed input: 21164.16 toks/s, output: 20.67 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:11, 18.00it/s, est. speed input: 21047.95 toks/s, output: 20.55 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:11, 18.01it/s, est. speed input: 20944.22 toks/s, output: 20.45 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:10, 18.02it/s, est. speed input: 20847.99 toks/s, output: 20.36 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:10, 18.01it/s, est. speed input: 20756.55 toks/s, output: 20.27 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:03<00:10, 18.00it/s, est. speed input: 20671.38 toks/s, output: 20.19 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:03<00:10, 18.00it/s, est. speed input: 20593.63 toks/s, output: 20.11 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:03<00:10, 18.00it/s, est. speed input: 20520.25 toks/s, output: 20.04 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:03<00:10, 18.01it/s, est. speed input: 20452.98 toks/s, output: 19.97 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:03<00:10, 18.00it/s, est. speed input: 20388.81 toks/s, output: 19.91 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:10, 17.99it/s, est. speed input: 20328.12 toks/s, output: 19.85 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:03<00:10, 17.99it/s, est. speed input: 20271.42 toks/s, output: 19.80 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:10, 17.98it/s, est. speed input: 20216.44 toks/s, output: 19.74 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 17.98it/s, est. speed input: 20166.12 toks/s, output: 19.69 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:04<00:09, 17.98it/s, est. speed input: 20118.20 toks/s, output: 19.65 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:04<00:09, 17.99it/s, est. speed input: 20073.33 toks/s, output: 19.60 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:04<00:09, 18.00it/s, est. speed input: 20031.43 toks/s, output: 19.56 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:04<00:09, 18.01it/s, est. speed input: 19992.67 toks/s, output: 19.52 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:04<00:09, 18.01it/s, est. speed input: 19953.85 toks/s, output: 19.49 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:04<00:09, 18.00it/s, est. speed input: 19916.74 toks/s, output: 19.45 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:04<00:09, 18.00it/s, est. speed input: 19882.16 toks/s, output: 19.42 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:09, 17.98it/s, est. speed input: 19847.45 toks/s, output: 19.38 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 17.99it/s, est. speed input: 19816.13 toks/s, output: 19.35 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:05<00:08, 17.99it/s, est. speed input: 19785.43 toks/s, output: 19.32 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:05<00:08, 18.00it/s, est. speed input: 19756.79 toks/s, output: 19.29 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:05<00:08, 18.01it/s, est. speed input: 19729.57 toks/s, output: 19.27 toks/s]
Processed prompts:  41%|████      | 104/256 [00:05<00:08, 18.02it/s, est. speed input: 19704.05 toks/s, output: 19.24 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:05<00:08, 18.03it/s, est. speed input: 19679.35 toks/s, output: 19.22 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:05<00:08, 18.02it/s, est. speed input: 19654.62 toks/s, output: 19.19 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:05<00:08, 18.01it/s, est. speed input: 19630.65 toks/s, output: 19.17 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:08, 17.99it/s, est. speed input: 19607.00 toks/s, output: 19.15 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:07, 17.99it/s, est. speed input: 19584.51 toks/s, output: 19.13 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:06<00:07, 18.00it/s, est. speed input: 19563.87 toks/s, output: 19.11 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:06<00:07, 17.98it/s, est. speed input: 19542.12 toks/s, output: 19.08 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:06<00:07, 17.99it/s, est. speed input: 19522.99 toks/s, output: 19.07 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:06<00:07, 18.00it/s, est. speed input: 19504.36 toks/s, output: 19.05 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:06<00:07, 17.99it/s, est. speed input: 19485.75 toks/s, output: 19.03 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:06<00:07, 17.98it/s, est. speed input: 19467.42 toks/s, output: 19.01 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:06<00:07, 17.98it/s, est. speed input: 19449.52 toks/s, output: 18.99 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:06<00:07, 17.95it/s, est. speed input: 19431.17 toks/s, output: 18.98 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:06<00:06, 17.96it/s, est. speed input: 19414.65 toks/s, output: 18.96 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:07<00:06, 17.96it/s, est. speed input: 19398.92 toks/s, output: 18.94 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:07<00:06, 17.98it/s, est. speed input: 19384.00 toks/s, output: 18.93 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:07<00:06, 17.99it/s, est. speed input: 19369.82 toks/s, output: 18.92 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:07<00:06, 18.00it/s, est. speed input: 19355.96 toks/s, output: 18.90 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:07<00:06, 18.01it/s, est. speed input: 19343.04 toks/s, output: 18.89 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:07<00:06, 18.00it/s, est. speed input: 19329.30 toks/s, output: 18.88 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:07<00:06, 18.01it/s, est. speed input: 19316.87 toks/s, output: 18.86 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:07<00:06, 17.98it/s, est. speed input: 19303.20 toks/s, output: 18.85 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:07<00:05, 17.98it/s, est. speed input: 19290.58 toks/s, output: 18.84 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:08<00:05, 17.96it/s, est. speed input: 19277.71 toks/s, output: 18.83 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:08<00:05, 17.96it/s, est. speed input: 19265.36 toks/s, output: 18.81 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:08<00:05, 17.96it/s, est. speed input: 19253.90 toks/s, output: 18.80 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:08<00:05, 17.97it/s, est. speed input: 19243.05 toks/s, output: 18.79 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:08<00:05, 18.00it/s, est. speed input: 19233.27 toks/s, output: 18.78 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:08<00:05, 18.00it/s, est. speed input: 19222.79 toks/s, output: 18.77 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:08<00:05, 17.98it/s, est. speed input: 19212.07 toks/s, output: 18.76 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:08<00:05, 17.97it/s, est. speed input: 19201.25 toks/s, output: 18.75 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:08<00:04, 17.97it/s, est. speed input: 19191.47 toks/s, output: 18.74 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:09<00:04, 17.97it/s, est. speed input: 19181.74 toks/s, output: 18.73 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:09<00:04, 17.98it/s, est. speed input: 19172.67 toks/s, output: 18.72 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:09<00:04, 17.98it/s, est. speed input: 19163.78 toks/s, output: 18.71 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:09<00:04, 18.00it/s, est. speed input: 19155.41 toks/s, output: 18.71 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:09<00:04, 17.98it/s, est. speed input: 19146.49 toks/s, output: 18.70 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:09<00:04, 17.98it/s, est. speed input: 19137.88 toks/s, output: 18.69 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:09<00:04, 17.97it/s, est. speed input: 19129.08 toks/s, output: 18.68 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:09<00:04, 17.96it/s, est. speed input: 19120.50 toks/s, output: 18.67 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:09<00:03, 17.96it/s, est. speed input: 19112.49 toks/s, output: 18.66 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:10<00:03, 17.96it/s, est. speed input: 19104.41 toks/s, output: 18.66 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:10<00:03, 17.95it/s, est. speed input: 19096.27 toks/s, output: 18.65 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:10<00:03, 17.94it/s, est. speed input: 19088.30 toks/s, output: 18.64 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:10<00:03, 17.95it/s, est. speed input: 19081.04 toks/s, output: 18.63 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:10<00:03, 17.96it/s, est. speed input: 19074.04 toks/s, output: 18.63 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:10<00:03, 17.99it/s, est. speed input: 19067.71 toks/s, output: 18.62 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:10<00:03, 17.99it/s, est. speed input: 19061.06 toks/s, output: 18.61 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:10<00:03, 17.95it/s, est. speed input: 19053.09 toks/s, output: 18.61 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:10<00:02, 17.94it/s, est. speed input: 19045.98 toks/s, output: 18.60 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:11<00:02, 17.96it/s, est. speed input: 19039.84 toks/s, output: 18.59 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:11<00:02, 17.95it/s, est. speed input: 19032.99 toks/s, output: 18.59 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:11<00:02, 17.95it/s, est. speed input: 19026.61 toks/s, output: 18.58 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:11<00:02, 17.97it/s, est. speed input: 19021.04 toks/s, output: 18.58 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:11<00:02, 17.98it/s, est. speed input: 19015.48 toks/s, output: 18.57 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:11<00:02, 17.99it/s, est. speed input: 19010.02 toks/s, output: 18.56 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:11<00:02, 17.97it/s, est. speed input: 19003.85 toks/s, output: 18.56 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:11<00:02, 17.95it/s, est. speed input: 18997.50 toks/s, output: 18.55 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:11<00:01, 17.96it/s, est. speed input: 18992.20 toks/s, output: 18.55 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:12<00:01, 17.97it/s, est. speed input: 18987.04 toks/s, output: 18.54 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:12<00:01, 17.96it/s, est. speed input: 18981.33 toks/s, output: 18.54 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:12<00:01, 17.96it/s, est. speed input: 18975.86 toks/s, output: 18.53 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:12<00:01, 17.95it/s, est. speed input: 18970.45 toks/s, output: 18.53 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:12<00:01, 17.95it/s, est. speed input: 18965.01 toks/s, output: 18.52 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:12<00:01, 17.94it/s, est. speed input: 18959.51 toks/s, output: 18.52 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:12<00:01, 17.95it/s, est. speed input: 18954.68 toks/s, output: 18.51 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:12<00:01, 17.93it/s, est. speed input: 18949.29 toks/s, output: 18.51 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:12<00:00, 17.94it/s, est. speed input: 18944.44 toks/s, output: 18.50 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:13<00:00, 17.94it/s, est. speed input: 18939.55 toks/s, output: 18.50 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:13<00:00, 17.94it/s, est. speed input: 18934.64 toks/s, output: 18.49 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:13<00:00, 17.94it/s, est. speed input: 18930.07 toks/s, output: 18.49 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:13<00:00, 17.96it/s, est. speed input: 18925.79 toks/s, output: 18.48 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:13<00:00, 17.97it/s, est. speed input: 18921.68 toks/s, output: 18.48 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:13<00:00, 17.97it/s, est. speed input: 18917.56 toks/s, output: 18.47 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:13<00:00, 17.98it/s, est. speed input: 18913.59 toks/s, output: 18.47 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 17.98it/s, est. speed input: 18983.78 toks/s, output: 18.54 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 18.54it/s, est. speed input: 18983.78 toks/s, output: 18.54 toks/s]
[rank0]:[W125 20:46:13.643657429 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 37.5s

测试结果:
  Requests/s:   17.92
  Tokens/s:     18369.70
  Total Reqs:   256
  Elapsed:      14.28s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     18351.77

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:46:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=459326) WARNING 01-25 20:46:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.96 requests/s, 18406.73 total tokens/s, 17.96 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 20:46:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:46:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:46:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:46:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:46:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:46:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:46:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:46:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:46:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:46:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:46:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:46:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:46:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:46:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:46:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:46:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:46:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=459326) [2026-01-25 20:46:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=459326) [2026-01-25 20:46:25] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=459326) [2026-01-25 20:46:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=459326) [2026-01-25 20:46:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=459326) [2026-01-25 20:46:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=459326) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=459326) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.76it/s]
(EngineCore_DP0 pid=459326) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=459326) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.19it/s]
(EngineCore_DP0 pid=459326) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=459326) 2026-01-25 20:46:36,513 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=459326) 2026-01-25 20:46:36,530 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=459326) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 25.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 23.85it/s]
(EngineCore_DP0 pid=459326) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 14.99it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|█         | 52/512 [00:00<00:00, 511.65it/s]
Adding requests:  21%|██▏       | 109/512 [00:00<00:00, 543.55it/s]
Adding requests:  32%|███▏      | 164/512 [00:00<00:00, 530.70it/s]
Adding requests:  44%|████▍     | 224/512 [00:00<00:00, 556.85it/s]
Adding requests:  55%|█████▌    | 283/512 [00:00<00:00, 565.85it/s]
Adding requests:  67%|██████▋   | 345/512 [00:00<00:00, 581.66it/s]
Adding requests:  79%|███████▉  | 407/512 [00:00<00:00, 590.07it/s]
Adding requests:  91%|█████████ | 467/512 [00:00<00:00, 590.64it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 575.16it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:08, 57.47it/s, est. speed input: 58847.80 toks/s, output: 57.47 toks/s]
Processed prompts:   5%|▍         | 24/512 [00:00<00:11, 42.22it/s, est. speed input: 45976.89 toks/s, output: 44.90 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:00<00:15, 32.10it/s, est. speed input: 37905.46 toks/s, output: 37.02 toks/s]
Processed prompts:   6%|▌         | 31/512 [00:00<00:19, 25.15it/s, est. speed input: 32451.87 toks/s, output: 31.69 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:01<00:22, 21.11it/s, est. speed input: 29020.79 toks/s, output: 28.34 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:01<00:23, 20.10it/s, est. speed input: 27382.57 toks/s, output: 26.74 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:01<00:24, 19.44it/s, est. speed input: 26182.37 toks/s, output: 25.57 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:01<00:24, 19.00it/s, est. speed input: 25267.75 toks/s, output: 24.68 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:02<00:24, 18.71it/s, est. speed input: 24549.65 toks/s, output: 23.97 toks/s]
Processed prompts:  11%|█         | 54/512 [00:02<00:24, 18.52it/s, est. speed input: 23969.14 toks/s, output: 23.41 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:02<00:24, 18.39it/s, est. speed input: 23493.27 toks/s, output: 22.94 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:02<00:24, 18.29it/s, est. speed input: 23090.19 toks/s, output: 22.55 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:24, 18.20it/s, est. speed input: 22742.32 toks/s, output: 22.21 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:03<00:24, 18.15it/s, est. speed input: 22445.85 toks/s, output: 21.92 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:03<00:24, 18.12it/s, est. speed input: 22188.11 toks/s, output: 21.67 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:03<00:23, 18.09it/s, est. speed input: 21960.68 toks/s, output: 21.45 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:03<00:23, 18.06it/s, est. speed input: 21757.44 toks/s, output: 21.25 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:04<00:23, 18.06it/s, est. speed input: 21580.30 toks/s, output: 21.07 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:04<00:23, 18.07it/s, est. speed input: 21422.31 toks/s, output: 20.92 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:04<00:23, 18.06it/s, est. speed input: 21278.64 toks/s, output: 20.78 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:04<00:22, 18.06it/s, est. speed input: 21148.04 toks/s, output: 20.65 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:04<00:22, 18.05it/s, est. speed input: 21027.78 toks/s, output: 20.53 toks/s]
Processed prompts:  21%|██        | 106/512 [00:05<00:22, 18.04it/s, est. speed input: 20917.40 toks/s, output: 20.43 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:05<00:22, 18.04it/s, est. speed input: 20817.34 toks/s, output: 20.33 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:05<00:22, 18.04it/s, est. speed input: 20725.40 toks/s, output: 20.24 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:05<00:21, 18.03it/s, est. speed input: 20638.40 toks/s, output: 20.15 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:06<00:21, 18.03it/s, est. speed input: 20559.14 toks/s, output: 20.08 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:06<00:21, 18.03it/s, est. speed input: 20484.86 toks/s, output: 20.00 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:06<00:21, 18.03it/s, est. speed input: 20416.04 toks/s, output: 19.94 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:06<00:20, 18.03it/s, est. speed input: 20351.40 toks/s, output: 19.87 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:06<00:20, 18.01it/s, est. speed input: 20289.31 toks/s, output: 19.81 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:07<00:20, 18.01it/s, est. speed input: 20232.00 toks/s, output: 19.76 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:07<00:20, 18.01it/s, est. speed input: 20178.17 toks/s, output: 19.71 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:07<00:20, 18.01it/s, est. speed input: 20128.19 toks/s, output: 19.66 toks/s]
Processed prompts:  30%|███       | 154/512 [00:07<00:19, 18.01it/s, est. speed input: 20080.18 toks/s, output: 19.61 toks/s]
Processed prompts:  31%|███       | 158/512 [00:08<00:19, 18.01it/s, est. speed input: 20034.74 toks/s, output: 19.57 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:08<00:19, 18.00it/s, est. speed input: 19991.84 toks/s, output: 19.52 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:08<00:19, 18.01it/s, est. speed input: 19951.72 toks/s, output: 19.48 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:08<00:18, 18.02it/s, est. speed input: 19914.03 toks/s, output: 19.45 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:08<00:18, 18.00it/s, est. speed input: 19876.60 toks/s, output: 19.41 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:09<00:18, 18.00it/s, est. speed input: 19841.39 toks/s, output: 19.38 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:09<00:18, 17.99it/s, est. speed input: 19807.48 toks/s, output: 19.34 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:09<00:18, 17.98it/s, est. speed input: 19774.74 toks/s, output: 19.31 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:09<00:17, 17.98it/s, est. speed input: 19743.83 toks/s, output: 19.28 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:10<00:17, 17.98it/s, est. speed input: 19714.52 toks/s, output: 19.25 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:10<00:17, 17.99it/s, est. speed input: 19686.84 toks/s, output: 19.23 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:10<00:17, 17.99it/s, est. speed input: 19660.60 toks/s, output: 19.20 toks/s]
Processed prompts:  40%|████      | 206/512 [00:10<00:16, 18.00it/s, est. speed input: 19635.80 toks/s, output: 19.18 toks/s]
Processed prompts:  41%|████      | 210/512 [00:10<00:16, 17.99it/s, est. speed input: 19610.68 toks/s, output: 19.15 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:11<00:16, 17.98it/s, est. speed input: 19586.16 toks/s, output: 19.13 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:11<00:16, 17.98it/s, est. speed input: 19562.97 toks/s, output: 19.10 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:11<00:16, 17.98it/s, est. speed input: 19541.31 toks/s, output: 19.08 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:11<00:15, 17.98it/s, est. speed input: 19520.34 toks/s, output: 19.06 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:12<00:15, 17.98it/s, est. speed input: 19499.82 toks/s, output: 19.04 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:12<00:15, 17.97it/s, est. speed input: 19479.59 toks/s, output: 19.02 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:12<00:15, 17.97it/s, est. speed input: 19460.54 toks/s, output: 19.00 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:12<00:15, 17.98it/s, est. speed input: 19442.33 toks/s, output: 18.99 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:12<00:14, 17.97it/s, est. speed input: 19424.09 toks/s, output: 18.97 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:13<00:14, 17.97it/s, est. speed input: 19406.59 toks/s, output: 18.95 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:13<00:14, 17.96it/s, est. speed input: 19389.62 toks/s, output: 18.94 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:13<00:14, 17.96it/s, est. speed input: 19373.35 toks/s, output: 18.92 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:13<00:13, 17.97it/s, est. speed input: 19357.87 toks/s, output: 18.90 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:14<00:13, 17.97it/s, est. speed input: 19342.86 toks/s, output: 18.89 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:14<00:13, 17.96it/s, est. speed input: 19327.70 toks/s, output: 18.87 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:14<00:13, 17.97it/s, est. speed input: 19313.78 toks/s, output: 18.86 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:14<00:13, 17.97it/s, est. speed input: 19300.27 toks/s, output: 18.85 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:14<00:12, 17.97it/s, est. speed input: 19286.52 toks/s, output: 18.83 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:15<00:12, 17.96it/s, est. speed input: 19273.20 toks/s, output: 18.82 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:15<00:12, 17.96it/s, est. speed input: 19260.45 toks/s, output: 18.81 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:15<00:12, 17.97it/s, est. speed input: 19248.42 toks/s, output: 18.80 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:15<00:11, 17.95it/s, est. speed input: 19235.89 toks/s, output: 18.79 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:16<00:11, 17.96it/s, est. speed input: 19224.45 toks/s, output: 18.77 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:16<00:11, 17.97it/s, est. speed input: 19213.25 toks/s, output: 18.76 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:16<00:11, 17.97it/s, est. speed input: 19202.61 toks/s, output: 18.75 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:16<00:11, 17.97it/s, est. speed input: 19192.03 toks/s, output: 18.74 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:16<00:10, 17.97it/s, est. speed input: 19181.33 toks/s, output: 18.73 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:17<00:10, 17.97it/s, est. speed input: 19171.25 toks/s, output: 18.72 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:17<00:10, 17.96it/s, est. speed input: 19161.22 toks/s, output: 18.71 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:17<00:10, 17.96it/s, est. speed input: 19151.45 toks/s, output: 18.70 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:17<00:09, 17.96it/s, est. speed input: 19142.07 toks/s, output: 18.69 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:18<00:09, 17.96it/s, est. speed input: 19132.68 toks/s, output: 18.68 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:18<00:09, 17.95it/s, est. speed input: 19123.43 toks/s, output: 18.68 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:18<00:09, 17.95it/s, est. speed input: 19114.52 toks/s, output: 18.67 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:18<00:09, 17.95it/s, est. speed input: 19105.70 toks/s, output: 18.66 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:18<00:08, 17.94it/s, est. speed input: 19096.90 toks/s, output: 18.65 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:19<00:08, 17.95it/s, est. speed input: 19088.72 toks/s, output: 18.64 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:19<00:08, 17.94it/s, est. speed input: 19080.40 toks/s, output: 18.63 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:19<00:08, 17.95it/s, est. speed input: 19072.51 toks/s, output: 18.63 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:19<00:07, 17.95it/s, est. speed input: 19064.86 toks/s, output: 18.62 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:20<00:07, 17.95it/s, est. speed input: 19057.23 toks/s, output: 18.61 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:20<00:07, 17.95it/s, est. speed input: 19049.84 toks/s, output: 18.60 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:20<00:07, 17.95it/s, est. speed input: 19042.72 toks/s, output: 18.60 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:20<00:07, 17.96it/s, est. speed input: 19035.82 toks/s, output: 18.59 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:20<00:06, 17.95it/s, est. speed input: 19028.84 toks/s, output: 18.58 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:21<00:06, 17.95it/s, est. speed input: 19022.04 toks/s, output: 18.58 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:21<00:06, 17.95it/s, est. speed input: 19015.22 toks/s, output: 18.57 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:21<00:06, 17.94it/s, est. speed input: 19008.41 toks/s, output: 18.56 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:21<00:05, 17.94it/s, est. speed input: 19001.76 toks/s, output: 18.56 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:22<00:05, 17.94it/s, est. speed input: 18995.60 toks/s, output: 18.55 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:22<00:05, 17.94it/s, est. speed input: 18989.27 toks/s, output: 18.54 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:22<00:05, 17.94it/s, est. speed input: 18983.23 toks/s, output: 18.54 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:22<00:05, 17.95it/s, est. speed input: 18977.53 toks/s, output: 18.53 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:22<00:04, 17.95it/s, est. speed input: 18971.66 toks/s, output: 18.53 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:23<00:04, 17.94it/s, est. speed input: 18965.81 toks/s, output: 18.52 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:23<00:04, 17.94it/s, est. speed input: 18960.12 toks/s, output: 18.52 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:23<00:04, 17.93it/s, est. speed input: 18954.35 toks/s, output: 18.51 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:23<00:03, 17.93it/s, est. speed input: 18948.66 toks/s, output: 18.50 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:24<00:03, 17.93it/s, est. speed input: 18943.21 toks/s, output: 18.50 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:24<00:03, 17.93it/s, est. speed input: 18937.99 toks/s, output: 18.49 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:24<00:03, 17.93it/s, est. speed input: 18932.77 toks/s, output: 18.49 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:24<00:03, 17.93it/s, est. speed input: 18927.67 toks/s, output: 18.48 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:25<00:02, 17.94it/s, est. speed input: 18922.69 toks/s, output: 18.48 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:25<00:02, 17.94it/s, est. speed input: 18917.79 toks/s, output: 18.47 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:25<00:02, 17.93it/s, est. speed input: 18912.80 toks/s, output: 18.47 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:25<00:02, 17.94it/s, est. speed input: 18908.17 toks/s, output: 18.46 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:25<00:01, 17.93it/s, est. speed input: 18903.32 toks/s, output: 18.46 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:26<00:01, 17.94it/s, est. speed input: 18898.84 toks/s, output: 18.46 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:26<00:01, 17.94it/s, est. speed input: 18894.57 toks/s, output: 18.45 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:26<00:01, 17.94it/s, est. speed input: 18890.18 toks/s, output: 18.45 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:26<00:01, 17.94it/s, est. speed input: 18885.82 toks/s, output: 18.44 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:27<00:00, 17.93it/s, est. speed input: 18881.39 toks/s, output: 18.44 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:27<00:00, 17.94it/s, est. speed input: 18877.21 toks/s, output: 18.43 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:27<00:00, 17.94it/s, est. speed input: 18873.09 toks/s, output: 18.43 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:27<00:00, 19.43it/s, est. speed input: 18907.93 toks/s, output: 18.46 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:27<00:00, 19.43it/s, est. speed input: 18982.02 toks/s, output: 18.54 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:27<00:00, 18.54it/s, est. speed input: 18982.02 toks/s, output: 18.54 toks/s]
[rank0]:[W125 20:47:06.486267900 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 52.9s

测试结果:
  Requests/s:   17.96
  Tokens/s:     18406.73
  Total Reqs:   512
  Elapsed:      28.51s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     18388.77

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:47:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=460352) WARNING 01-25 20:47:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.70 requests/s, 18141.90 total tokens/s, 17.70 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 20:47:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:47:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:47:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:47:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:47:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:47:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:47:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:47:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:47:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:47:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:47:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:47:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=460352) [2026-01-25 20:47:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=460352) [2026-01-25 20:47:19] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=460352) [2026-01-25 20:47:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=460352) [2026-01-25 20:47:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=460352) [2026-01-25 20:47:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=460352) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=460352) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.80it/s]
(EngineCore_DP0 pid=460352) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.16it/s]
(EngineCore_DP0 pid=460352) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.23it/s]
(EngineCore_DP0 pid=460352) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=460352) 2026-01-25 20:47:31,285 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=460352) 2026-01-25 20:47:31,301 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=460352) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:02,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  7.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.29it/s]
(EngineCore_DP0 pid=460352) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 18.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.71it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 49/1024 [00:00<00:02, 482.48it/s]
Adding requests:  10%|█         | 103/1024 [00:00<00:01, 515.25it/s]
Adding requests:  15%|█▌        | 155/1024 [00:00<00:01, 505.03it/s]
Adding requests:  21%|██        | 214/1024 [00:00<00:01, 536.05it/s]
Adding requests:  27%|██▋       | 272/1024 [00:00<00:01, 548.80it/s]
Adding requests:  33%|███▎      | 334/1024 [00:00<00:01, 571.30it/s]
Adding requests:  38%|███▊      | 394/1024 [00:00<00:01, 578.51it/s]
Adding requests:  44%|████▍     | 454/1024 [00:00<00:00, 582.86it/s]
Adding requests:  51%|█████     | 519/1024 [00:00<00:00, 600.62it/s]
Adding requests:  57%|█████▋    | 580/1024 [00:01<00:00, 596.48it/s]
Adding requests:  62%|██████▎   | 640/1024 [00:01<00:00, 589.58it/s]
Adding requests:  68%|██████▊   | 701/1024 [00:01<00:00, 595.24it/s]
Adding requests:  74%|███████▍  | 761/1024 [00:01<00:00, 582.53it/s]
Adding requests:  80%|████████  | 820/1024 [00:01<00:00, 583.73it/s]
Adding requests:  86%|████████▌ | 880/1024 [00:01<00:00, 587.58it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:01<00:00, 588.12it/s]
Adding requests:  98%|█████████▊| 999/1024 [00:01<00:00, 591.63it/s]
Adding requests: 100%|██████████| 1024/1024 [00:01<00:00, 577.21it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 26/1024 [00:00<00:06, 154.32it/s, est. speed input: 158035.95 toks/s, output: 154.32 toks/s]
Processed prompts:   4%|▍         | 42/1024 [00:01<00:29, 33.68it/s, est. speed input: 40347.39 toks/s, output: 39.40 toks/s]   
Processed prompts:   5%|▍         | 50/1024 [00:01<00:35, 27.54it/s, est. speed input: 33794.06 toks/s, output: 33.00 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:01<00:40, 24.07it/s, est. speed input: 30236.88 toks/s, output: 29.53 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:02<00:43, 21.97it/s, est. speed input: 28007.10 toks/s, output: 27.35 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:02<00:46, 20.61it/s, est. speed input: 26469.86 toks/s, output: 25.85 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:03<00:47, 19.72it/s, est. speed input: 25352.40 toks/s, output: 24.76 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:03<00:48, 19.12it/s, est. speed input: 24501.42 toks/s, output: 23.93 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:04<00:49, 18.71it/s, est. speed input: 23830.56 toks/s, output: 23.27 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:04<00:49, 18.43it/s, est. speed input: 23288.99 toks/s, output: 22.74 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:05<00:49, 18.23it/s, est. speed input: 22841.01 toks/s, output: 22.31 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:05<00:49, 18.10it/s, est. speed input: 22467.70 toks/s, output: 21.94 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:06<00:49, 18.00it/s, est. speed input: 22148.61 toks/s, output: 21.63 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:06<00:49, 17.94it/s, est. speed input: 21874.64 toks/s, output: 21.36 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:06<00:49, 17.89it/s, est. speed input: 21635.29 toks/s, output: 21.13 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:07<00:48, 17.86it/s, est. speed input: 21425.55 toks/s, output: 20.92 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:07<00:48, 17.82it/s, est. speed input: 21238.40 toks/s, output: 20.74 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:08<00:47, 17.81it/s, est. speed input: 21072.84 toks/s, output: 20.58 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:08<00:47, 17.80it/s, est. speed input: 20924.63 toks/s, output: 20.43 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:09<00:47, 17.79it/s, est. speed input: 20789.92 toks/s, output: 20.30 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:09<00:46, 17.78it/s, est. speed input: 20668.60 toks/s, output: 20.18 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:10<00:46, 17.78it/s, est. speed input: 20557.44 toks/s, output: 20.08 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:10<00:45, 17.78it/s, est. speed input: 20456.52 toks/s, output: 19.98 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:10<00:45, 17.77it/s, est. speed input: 20362.95 toks/s, output: 19.89 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:11<00:44, 17.77it/s, est. speed input: 20277.39 toks/s, output: 19.80 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:11<00:44, 17.76it/s, est. speed input: 20197.36 toks/s, output: 19.72 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:12<00:44, 17.76it/s, est. speed input: 20123.71 toks/s, output: 19.65 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:12<00:43, 17.76it/s, est. speed input: 20055.21 toks/s, output: 19.59 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:13<00:43, 17.75it/s, est. speed input: 19990.66 toks/s, output: 19.52 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:13<00:42, 17.75it/s, est. speed input: 19931.09 toks/s, output: 19.46 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:14<00:42, 17.75it/s, est. speed input: 19875.13 toks/s, output: 19.41 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:14<00:41, 17.75it/s, est. speed input: 19822.78 toks/s, output: 19.36 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:15<00:41, 17.75it/s, est. speed input: 19772.96 toks/s, output: 19.31 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:15<00:40, 17.75it/s, est. speed input: 19726.60 toks/s, output: 19.26 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:15<00:40, 17.75it/s, est. speed input: 19682.80 toks/s, output: 19.22 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:16<00:40, 17.74it/s, est. speed input: 19640.59 toks/s, output: 19.18 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:16<00:39, 17.75it/s, est. speed input: 19601.27 toks/s, output: 19.14 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:17<00:39, 17.75it/s, est. speed input: 19563.96 toks/s, output: 19.11 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:17<00:38, 17.75it/s, est. speed input: 19528.78 toks/s, output: 19.07 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:18<00:38, 17.74it/s, est. speed input: 19494.73 toks/s, output: 19.04 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:18<00:37, 17.75it/s, est. speed input: 19462.92 toks/s, output: 19.01 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:19<00:37, 17.74it/s, est. speed input: 19432.18 toks/s, output: 18.98 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:19<00:36, 17.74it/s, est. speed input: 19402.71 toks/s, output: 18.95 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:19<00:36, 17.74it/s, est. speed input: 19374.43 toks/s, output: 18.92 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:20<00:35, 17.74it/s, est. speed input: 19347.80 toks/s, output: 18.89 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:20<00:35, 17.74it/s, est. speed input: 19322.08 toks/s, output: 18.87 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:21<00:35, 17.74it/s, est. speed input: 19297.54 toks/s, output: 18.85 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:21<00:34, 17.74it/s, est. speed input: 19274.00 toks/s, output: 18.82 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:22<00:34, 17.73it/s, est. speed input: 19251.35 toks/s, output: 18.80 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:22<00:33, 17.73it/s, est. speed input: 19229.53 toks/s, output: 18.78 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:23<00:33, 17.73it/s, est. speed input: 19208.36 toks/s, output: 18.76 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:23<00:32, 17.73it/s, est. speed input: 19188.13 toks/s, output: 18.74 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:24<00:32, 17.72it/s, est. speed input: 19168.46 toks/s, output: 18.72 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:24<00:31, 17.73it/s, est. speed input: 19149.91 toks/s, output: 18.70 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:24<00:31, 17.73it/s, est. speed input: 19131.78 toks/s, output: 18.68 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:25<00:31, 17.73it/s, est. speed input: 19114.48 toks/s, output: 18.67 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:25<00:30, 17.72it/s, est. speed input: 19097.47 toks/s, output: 18.65 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:26<00:30, 17.72it/s, est. speed input: 19081.22 toks/s, output: 18.63 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:26<00:29, 17.72it/s, est. speed input: 19065.50 toks/s, output: 18.62 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:27<00:29, 17.72it/s, est. speed input: 19050.04 toks/s, output: 18.60 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:27<00:28, 17.72it/s, est. speed input: 19035.17 toks/s, output: 18.59 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:28<00:28, 17.72it/s, est. speed input: 19021.04 toks/s, output: 18.58 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:28<00:27, 17.72it/s, est. speed input: 19007.22 toks/s, output: 18.56 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:29<00:27, 17.72it/s, est. speed input: 18993.61 toks/s, output: 18.55 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:29<00:26, 17.72it/s, est. speed input: 18980.49 toks/s, output: 18.54 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:29<00:26, 17.71it/s, est. speed input: 18967.68 toks/s, output: 18.52 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:30<00:26, 17.72it/s, est. speed input: 18955.43 toks/s, output: 18.51 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:30<00:25, 17.71it/s, est. speed input: 18943.32 toks/s, output: 18.50 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:31<00:25, 17.71it/s, est. speed input: 18931.76 toks/s, output: 18.49 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:31<00:24, 17.71it/s, est. speed input: 18920.47 toks/s, output: 18.48 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:32<00:24, 17.71it/s, est. speed input: 18909.41 toks/s, output: 18.47 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:32<00:23, 17.71it/s, est. speed input: 18898.67 toks/s, output: 18.46 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:33<00:23, 17.71it/s, est. speed input: 18888.24 toks/s, output: 18.45 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:33<00:22, 17.71it/s, est. speed input: 18878.06 toks/s, output: 18.44 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:33<00:22, 17.71it/s, est. speed input: 18868.08 toks/s, output: 18.43 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:34<00:22, 17.71it/s, est. speed input: 18858.51 toks/s, output: 18.42 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:34<00:21, 17.71it/s, est. speed input: 18849.04 toks/s, output: 18.41 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:35<00:21, 17.71it/s, est. speed input: 18839.86 toks/s, output: 18.40 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:35<00:20, 17.70it/s, est. speed input: 18830.79 toks/s, output: 18.39 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:36<00:20, 17.71it/s, est. speed input: 18822.12 toks/s, output: 18.38 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:36<00:19, 17.71it/s, est. speed input: 18813.74 toks/s, output: 18.37 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:37<00:19, 17.70it/s, est. speed input: 18805.22 toks/s, output: 18.36 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:37<00:18, 17.70it/s, est. speed input: 18797.15 toks/s, output: 18.36 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:38<00:18, 17.70it/s, est. speed input: 18788.97 toks/s, output: 18.35 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:38<00:17, 17.70it/s, est. speed input: 18781.35 toks/s, output: 18.34 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:38<00:17, 17.70it/s, est. speed input: 18773.52 toks/s, output: 18.33 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:39<00:17, 17.70it/s, est. speed input: 18766.06 toks/s, output: 18.33 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:39<00:16, 17.69it/s, est. speed input: 18758.62 toks/s, output: 18.32 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:40<00:16, 17.69it/s, est. speed input: 18751.47 toks/s, output: 18.31 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:40<00:15, 17.70it/s, est. speed input: 18744.48 toks/s, output: 18.31 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:41<00:15, 17.69it/s, est. speed input: 18737.43 toks/s, output: 18.30 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:41<00:14, 17.69it/s, est. speed input: 18730.71 toks/s, output: 18.29 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:42<00:14, 17.69it/s, est. speed input: 18723.98 toks/s, output: 18.29 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:42<00:13, 17.69it/s, est. speed input: 18717.66 toks/s, output: 18.28 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:43<00:13, 17.69it/s, est. speed input: 18711.30 toks/s, output: 18.27 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:43<00:13, 17.69it/s, est. speed input: 18705.10 toks/s, output: 18.27 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:43<00:12, 17.69it/s, est. speed input: 18698.84 toks/s, output: 18.26 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:44<00:12, 17.69it/s, est. speed input: 18692.87 toks/s, output: 18.25 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:44<00:11, 17.69it/s, est. speed input: 18687.01 toks/s, output: 18.25 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:45<00:11, 17.69it/s, est. speed input: 18681.47 toks/s, output: 18.24 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:45<00:10, 17.69it/s, est. speed input: 18675.85 toks/s, output: 18.24 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:46<00:10, 17.69it/s, est. speed input: 18670.28 toks/s, output: 18.23 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:46<00:09, 17.69it/s, est. speed input: 18664.86 toks/s, output: 18.23 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:47<00:09, 17.69it/s, est. speed input: 18659.45 toks/s, output: 18.22 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:47<00:08, 17.69it/s, est. speed input: 18654.27 toks/s, output: 18.22 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:47<00:08, 17.69it/s, est. speed input: 18649.12 toks/s, output: 18.21 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:48<00:08, 17.69it/s, est. speed input: 18644.06 toks/s, output: 18.21 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:48<00:07, 17.68it/s, est. speed input: 18639.02 toks/s, output: 18.20 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:49<00:07, 17.69it/s, est. speed input: 18634.27 toks/s, output: 18.20 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:49<00:06, 17.68it/s, est. speed input: 18629.27 toks/s, output: 18.19 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:50<00:06, 17.68it/s, est. speed input: 18624.50 toks/s, output: 18.19 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:50<00:05, 17.68it/s, est. speed input: 18619.92 toks/s, output: 18.18 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:51<00:05, 17.68it/s, est. speed input: 18615.39 toks/s, output: 18.18 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:51<00:04, 17.67it/s, est. speed input: 18610.72 toks/s, output: 18.17 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:52<00:04, 17.67it/s, est. speed input: 18606.17 toks/s, output: 18.17 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:52<00:03, 17.67it/s, est. speed input: 18601.87 toks/s, output: 18.17 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:52<00:03, 17.67it/s, est. speed input: 18597.46 toks/s, output: 18.16 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:53<00:03, 17.67it/s, est. speed input: 18593.30 toks/s, output: 18.16 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:53<00:02, 17.67it/s, est. speed input: 18589.05 toks/s, output: 18.15 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:54<00:02, 17.67it/s, est. speed input: 18584.97 toks/s, output: 18.15 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:54<00:01, 17.66it/s, est. speed input: 18580.71 toks/s, output: 18.15 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:55<00:01, 17.67it/s, est. speed input: 18576.80 toks/s, output: 18.14 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:55<00:00, 17.67it/s, est. speed input: 18572.89 toks/s, output: 18.14 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:56<00:00, 18.38it/s, est. speed input: 18588.42 toks/s, output: 18.15 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:56<00:00, 18.38it/s, est. speed input: 18697.90 toks/s, output: 18.26 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:56<00:00, 18.26it/s, est. speed input: 18697.90 toks/s, output: 18.26 toks/s]
[rank0]:[W125 20:48:31.013297895 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 84.5s

测试结果:
  Requests/s:   17.70
  Tokens/s:     18141.90
  Total Reqs:   1024
  Elapsed:      57.86s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     18124.20

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:48:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=461873) WARNING 01-25 20:48:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.71 requests/s, 18150.98 total tokens/s, 17.71 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 20:48:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:48:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:48:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:48:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=461873) [2026-01-25 20:48:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=461873) [2026-01-25 20:48:47] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=461873) [2026-01-25 20:48:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=461873) [2026-01-25 20:48:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=461873) [2026-01-25 20:48:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=461873) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=461873) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.75it/s]
(EngineCore_DP0 pid=461873) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.13it/s]
(EngineCore_DP0 pid=461873) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.20it/s]
(EngineCore_DP0 pid=461873) 
(EngineCore_DP0 pid=461873) [rank0]:W0125 20:48:55.620000 461873 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=461873) [rank0]:W0125 20:48:56.272000 461873 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=461873) [rank0]:W0125 20:48:57.473000 461873 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=461873) [rank0]:W0125 20:48:57.551000 461873 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=461873) 2026-01-25 20:49:00,943 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=461873) 2026-01-25 20:49:00,959 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=461873) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:03,  1.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  6.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.88it/s]
(EngineCore_DP0 pid=461873) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.42it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 18.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 18.53it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 51/2048 [00:00<00:03, 508.52it/s]
Adding requests:   5%|▌         | 108/2048 [00:00<00:03, 542.61it/s]
Adding requests:   8%|▊         | 164/2048 [00:00<00:03, 550.30it/s]
Adding requests:  11%|█         | 224/2048 [00:00<00:03, 568.79it/s]
Adding requests:  14%|█▍        | 283/2048 [00:00<00:03, 574.52it/s]
Adding requests:  17%|█▋        | 345/2048 [00:00<00:02, 588.25it/s]
Adding requests:  20%|█▉        | 407/2048 [00:00<00:02, 595.10it/s]
Adding requests:  23%|██▎       | 467/2048 [00:00<00:02, 594.68it/s]
Adding requests:  26%|██▌       | 533/2048 [00:00<00:02, 614.39it/s]
Adding requests:  29%|██▉       | 595/2048 [00:01<00:02, 606.53it/s]
Adding requests:  32%|███▏      | 656/2048 [00:01<00:02, 602.06it/s]
Adding requests:  35%|███▌      | 718/2048 [00:01<00:02, 606.59it/s]
Adding requests:  38%|███▊      | 779/2048 [00:01<00:02, 590.86it/s]
Adding requests:  41%|████      | 839/2048 [00:01<00:02, 591.12it/s]
Adding requests:  44%|████▍     | 899/2048 [00:01<00:01, 593.59it/s]
Adding requests:  47%|████▋     | 959/2048 [00:01<00:01, 588.01it/s]
Adding requests:  50%|████▉     | 1018/2048 [00:01<00:01, 583.01it/s]
Adding requests:  53%|█████▎    | 1077/2048 [00:01<00:01, 584.16it/s]
Adding requests:  56%|█████▌    | 1138/2048 [00:01<00:01, 591.68it/s]
Adding requests:  58%|█████▊    | 1198/2048 [00:02<00:01, 585.60it/s]
Adding requests:  61%|██████▏   | 1257/2048 [00:02<00:01, 583.33it/s]
Adding requests:  64%|██████▍   | 1317/2048 [00:02<00:01, 586.71it/s]
Adding requests:  67%|██████▋   | 1379/2048 [00:02<00:01, 595.58it/s]
Adding requests:  70%|███████   | 1440/2048 [00:02<00:01, 599.58it/s]
Adding requests:  73%|███████▎  | 1502/2048 [00:02<00:00, 604.04it/s]
Adding requests:  76%|███████▋  | 1563/2048 [00:02<00:00, 602.28it/s]
Adding requests:  79%|███████▉  | 1624/2048 [00:02<00:00, 586.60it/s]
Adding requests:  82%|████████▏ | 1683/2048 [00:02<00:00, 570.09it/s]
Adding requests:  85%|████████▌ | 1741/2048 [00:02<00:00, 572.60it/s]
Adding requests:  88%|████████▊ | 1802/2048 [00:03<00:00, 582.23it/s]
Adding requests:  91%|█████████ | 1861/2048 [00:03<00:00, 583.13it/s]
Adding requests:  94%|█████████▍| 1923/2048 [00:03<00:00, 591.70it/s]
Adding requests:  97%|█████████▋| 1983/2048 [00:03<00:00, 581.25it/s]
Adding requests: 100%|█████████▉| 2042/2048 [00:03<00:00, 565.86it/s]
Adding requests: 100%|██████████| 2048/2048 [00:03<00:00, 584.78it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 62/2048 [00:00<00:08, 237.71it/s, est. speed input: 243424.34 toks/s, output: 237.71 toks/s]
Processed prompts:   4%|▍         | 86/2048 [00:01<00:38, 51.63it/s, est. speed input: 63641.80 toks/s, output: 62.15 toks/s]   
Processed prompts:   5%|▍         | 98/2048 [00:02<00:57, 33.71it/s, est. speed input: 45090.34 toks/s, output: 44.03 toks/s]
Processed prompts:   5%|▌         | 105/2048 [00:02<01:00, 32.07it/s, est. speed input: 42897.11 toks/s, output: 41.89 toks/s]
Processed prompts:   5%|▌         | 111/2048 [00:02<01:04, 29.82it/s, est. speed input: 40778.27 toks/s, output: 39.82 toks/s]
Processed prompts:   6%|▌         | 115/2048 [00:03<01:13, 26.23it/s, est. speed input: 38380.31 toks/s, output: 37.48 toks/s]
Processed prompts:   6%|▌         | 119/2048 [00:03<01:22, 23.26it/s, est. speed input: 36384.95 toks/s, output: 35.53 toks/s]
Processed prompts:   6%|▌         | 122/2048 [00:03<01:36, 19.97it/s, est. speed input: 34414.57 toks/s, output: 33.61 toks/s]
Processed prompts:   6%|▌         | 127/2048 [00:03<01:39, 19.38it/s, est. speed input: 33251.70 toks/s, output: 32.47 toks/s]
Processed prompts:   6%|▋         | 132/2048 [00:04<01:41, 18.94it/s, est. speed input: 32245.14 toks/s, output: 31.49 toks/s]
Processed prompts:   7%|▋         | 137/2048 [00:04<01:42, 18.61it/s, est. speed input: 31363.61 toks/s, output: 30.63 toks/s]
Processed prompts:   7%|▋         | 142/2048 [00:04<01:43, 18.38it/s, est. speed input: 30588.02 toks/s, output: 29.87 toks/s]
Processed prompts:   7%|▋         | 147/2048 [00:05<01:44, 18.20it/s, est. speed input: 29896.94 toks/s, output: 29.20 toks/s]
Processed prompts:   7%|▋         | 152/2048 [00:05<01:44, 18.08it/s, est. speed input: 29279.07 toks/s, output: 28.59 toks/s]
Processed prompts:   8%|▊         | 157/2048 [00:05<01:45, 18.00it/s, est. speed input: 28724.22 toks/s, output: 28.05 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:05<01:45, 17.94it/s, est. speed input: 28221.93 toks/s, output: 27.56 toks/s]
Processed prompts:   8%|▊         | 167/2048 [00:06<01:45, 17.89it/s, est. speed input: 27764.71 toks/s, output: 27.11 toks/s]
Processed prompts:   8%|▊         | 172/2048 [00:06<01:45, 17.86it/s, est. speed input: 27347.66 toks/s, output: 26.71 toks/s]
Processed prompts:   9%|▊         | 177/2048 [00:06<01:44, 17.84it/s, est. speed input: 26965.66 toks/s, output: 26.33 toks/s]
Processed prompts:   9%|▉         | 182/2048 [00:07<01:44, 17.82it/s, est. speed input: 26613.71 toks/s, output: 25.99 toks/s]
Processed prompts:   9%|▉         | 187/2048 [00:07<01:44, 17.81it/s, est. speed input: 26289.01 toks/s, output: 25.67 toks/s]
Processed prompts:   9%|▉         | 192/2048 [00:07<01:44, 17.81it/s, est. speed input: 25990.01 toks/s, output: 25.38 toks/s]
Processed prompts:  10%|▉         | 197/2048 [00:07<01:43, 17.80it/s, est. speed input: 25711.98 toks/s, output: 25.11 toks/s]
Processed prompts:  10%|▉         | 202/2048 [00:08<01:43, 17.79it/s, est. speed input: 25451.19 toks/s, output: 24.85 toks/s]
Processed prompts:  10%|█         | 207/2048 [00:08<01:43, 17.79it/s, est. speed input: 25209.39 toks/s, output: 24.62 toks/s]
Processed prompts:  10%|█         | 212/2048 [00:08<01:43, 17.79it/s, est. speed input: 24982.69 toks/s, output: 24.40 toks/s]
Processed prompts:  11%|█         | 217/2048 [00:08<01:42, 17.79it/s, est. speed input: 24770.29 toks/s, output: 24.19 toks/s]
Processed prompts:  11%|█         | 222/2048 [00:09<01:42, 17.78it/s, est. speed input: 24569.73 toks/s, output: 23.99 toks/s]
Processed prompts:  11%|█         | 227/2048 [00:09<01:42, 17.79it/s, est. speed input: 24383.21 toks/s, output: 23.81 toks/s]
Processed prompts:  11%|█▏        | 232/2048 [00:09<01:42, 17.79it/s, est. speed input: 24206.86 toks/s, output: 23.64 toks/s]
Processed prompts:  12%|█▏        | 237/2048 [00:10<01:41, 17.78it/s, est. speed input: 24039.23 toks/s, output: 23.48 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:10<01:41, 17.77it/s, est. speed input: 23880.08 toks/s, output: 23.32 toks/s]
Processed prompts:  12%|█▏        | 247/2048 [00:10<01:41, 17.78it/s, est. speed input: 23730.59 toks/s, output: 23.17 toks/s]
Processed prompts:  12%|█▏        | 252/2048 [00:10<01:41, 17.78it/s, est. speed input: 23588.94 toks/s, output: 23.04 toks/s]
Processed prompts:  13%|█▎        | 257/2048 [00:11<01:40, 17.77it/s, est. speed input: 23453.22 toks/s, output: 22.90 toks/s]
Processed prompts:  13%|█▎        | 262/2048 [00:11<01:40, 17.77it/s, est. speed input: 23324.78 toks/s, output: 22.78 toks/s]
Processed prompts:  13%|█▎        | 267/2048 [00:11<01:40, 17.78it/s, est. speed input: 23202.63 toks/s, output: 22.66 toks/s]
Processed prompts:  13%|█▎        | 272/2048 [00:12<01:39, 17.77it/s, est. speed input: 23085.67 toks/s, output: 22.54 toks/s]
Processed prompts:  14%|█▎        | 277/2048 [00:12<01:39, 17.77it/s, est. speed input: 22974.23 toks/s, output: 22.44 toks/s]
Processed prompts:  14%|█▍        | 282/2048 [00:12<01:39, 17.77it/s, est. speed input: 22868.14 toks/s, output: 22.33 toks/s]
Processed prompts:  14%|█▍        | 287/2048 [00:12<01:39, 17.77it/s, est. speed input: 22766.34 toks/s, output: 22.23 toks/s]
Processed prompts:  14%|█▍        | 292/2048 [00:13<01:38, 17.77it/s, est. speed input: 22668.26 toks/s, output: 22.14 toks/s]
Processed prompts:  15%|█▍        | 297/2048 [00:13<01:38, 17.77it/s, est. speed input: 22574.90 toks/s, output: 22.05 toks/s]
Processed prompts:  15%|█▍        | 302/2048 [00:13<01:38, 17.78it/s, est. speed input: 22485.97 toks/s, output: 21.96 toks/s]
Processed prompts:  15%|█▍        | 307/2048 [00:14<01:37, 17.77it/s, est. speed input: 22399.84 toks/s, output: 21.87 toks/s]
Processed prompts:  15%|█▌        | 312/2048 [00:14<01:37, 17.77it/s, est. speed input: 22316.99 toks/s, output: 21.79 toks/s]
Processed prompts:  15%|█▌        | 317/2048 [00:14<01:37, 17.77it/s, est. speed input: 22237.78 toks/s, output: 21.72 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:14<01:37, 17.77it/s, est. speed input: 22161.32 toks/s, output: 21.64 toks/s]
Processed prompts:  16%|█▌        | 327/2048 [00:15<01:36, 17.76it/s, est. speed input: 22087.25 toks/s, output: 21.57 toks/s]
Processed prompts:  16%|█▌        | 332/2048 [00:15<01:36, 17.76it/s, est. speed input: 22016.11 toks/s, output: 21.50 toks/s]
Processed prompts:  16%|█▋        | 337/2048 [00:15<01:36, 17.76it/s, est. speed input: 21947.71 toks/s, output: 21.43 toks/s]
Processed prompts:  17%|█▋        | 342/2048 [00:16<01:35, 17.77it/s, est. speed input: 21882.13 toks/s, output: 21.37 toks/s]
Processed prompts:  17%|█▋        | 347/2048 [00:16<01:35, 17.77it/s, est. speed input: 21818.14 toks/s, output: 21.31 toks/s]
Processed prompts:  17%|█▋        | 352/2048 [00:16<01:35, 17.77it/s, est. speed input: 21756.81 toks/s, output: 21.25 toks/s]
Processed prompts:  17%|█▋        | 357/2048 [00:16<01:35, 17.77it/s, est. speed input: 21697.45 toks/s, output: 21.19 toks/s]
Processed prompts:  18%|█▊        | 362/2048 [00:17<01:34, 17.77it/s, est. speed input: 21640.12 toks/s, output: 21.13 toks/s]
Processed prompts:  18%|█▊        | 367/2048 [00:17<01:34, 17.78it/s, est. speed input: 21584.69 toks/s, output: 21.08 toks/s]
Processed prompts:  18%|█▊        | 372/2048 [00:17<01:34, 17.77it/s, est. speed input: 21530.49 toks/s, output: 21.03 toks/s]
Processed prompts:  18%|█▊        | 377/2048 [00:17<01:34, 17.77it/s, est. speed input: 21478.34 toks/s, output: 20.97 toks/s]
Processed prompts:  19%|█▊        | 382/2048 [00:18<01:33, 17.76it/s, est. speed input: 21427.21 toks/s, output: 20.92 toks/s]
Processed prompts:  19%|█▉        | 387/2048 [00:18<01:33, 17.77it/s, est. speed input: 21378.56 toks/s, output: 20.88 toks/s]
Processed prompts:  19%|█▉        | 392/2048 [00:18<01:33, 17.77it/s, est. speed input: 21330.89 toks/s, output: 20.83 toks/s]
Processed prompts:  19%|█▉        | 397/2048 [00:19<01:32, 17.76it/s, est. speed input: 21284.28 toks/s, output: 20.79 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:19<01:32, 17.76it/s, est. speed input: 21239.03 toks/s, output: 20.74 toks/s]
Processed prompts:  20%|█▉        | 407/2048 [00:19<01:32, 17.76it/s, est. speed input: 21195.25 toks/s, output: 20.70 toks/s]
Processed prompts:  20%|██        | 412/2048 [00:19<01:32, 17.76it/s, est. speed input: 21152.66 toks/s, output: 20.66 toks/s]
Processed prompts:  20%|██        | 417/2048 [00:20<01:31, 17.76it/s, est. speed input: 21111.36 toks/s, output: 20.62 toks/s]
Processed prompts:  21%|██        | 422/2048 [00:20<01:31, 17.76it/s, est. speed input: 21071.18 toks/s, output: 20.58 toks/s]
Processed prompts:  21%|██        | 427/2048 [00:20<01:31, 17.76it/s, est. speed input: 21032.03 toks/s, output: 20.54 toks/s]
Processed prompts:  21%|██        | 432/2048 [00:21<01:31, 17.75it/s, est. speed input: 20993.80 toks/s, output: 20.50 toks/s]
Processed prompts:  21%|██▏       | 437/2048 [00:21<01:30, 17.75it/s, est. speed input: 20956.37 toks/s, output: 20.47 toks/s]
Processed prompts:  22%|██▏       | 442/2048 [00:21<01:30, 17.75it/s, est. speed input: 20920.20 toks/s, output: 20.43 toks/s]
Processed prompts:  22%|██▏       | 447/2048 [00:21<01:30, 17.76it/s, est. speed input: 20885.39 toks/s, output: 20.40 toks/s]
Processed prompts:  22%|██▏       | 452/2048 [00:22<01:29, 17.76it/s, est. speed input: 20851.16 toks/s, output: 20.36 toks/s]
Processed prompts:  22%|██▏       | 457/2048 [00:22<01:29, 17.76it/s, est. speed input: 20817.65 toks/s, output: 20.33 toks/s]
Processed prompts:  23%|██▎       | 462/2048 [00:22<01:29, 17.76it/s, est. speed input: 20785.28 toks/s, output: 20.30 toks/s]
Processed prompts:  23%|██▎       | 467/2048 [00:23<01:29, 17.76it/s, est. speed input: 20753.49 toks/s, output: 20.27 toks/s]
Processed prompts:  23%|██▎       | 472/2048 [00:23<01:28, 17.75it/s, est. speed input: 20722.13 toks/s, output: 20.24 toks/s]
Processed prompts:  23%|██▎       | 477/2048 [00:23<01:28, 17.76it/s, est. speed input: 20691.94 toks/s, output: 20.21 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:23<01:28, 17.76it/s, est. speed input: 20662.42 toks/s, output: 20.18 toks/s]
Processed prompts:  24%|██▍       | 487/2048 [00:24<01:27, 17.74it/s, est. speed input: 20632.96 toks/s, output: 20.15 toks/s]
Processed prompts:  24%|██▍       | 492/2048 [00:24<01:27, 17.75it/s, est. speed input: 20604.86 toks/s, output: 20.12 toks/s]
Processed prompts:  24%|██▍       | 497/2048 [00:24<01:27, 17.75it/s, est. speed input: 20577.09 toks/s, output: 20.09 toks/s]
Processed prompts:  25%|██▍       | 502/2048 [00:25<01:27, 17.74it/s, est. speed input: 20549.75 toks/s, output: 20.07 toks/s]
Processed prompts:  25%|██▍       | 507/2048 [00:25<01:26, 17.74it/s, est. speed input: 20523.11 toks/s, output: 20.04 toks/s]
Processed prompts:  25%|██▌       | 512/2048 [00:25<01:26, 17.75it/s, est. speed input: 20497.48 toks/s, output: 20.02 toks/s]
Processed prompts:  25%|██▌       | 517/2048 [00:25<01:26, 17.75it/s, est. speed input: 20472.36 toks/s, output: 19.99 toks/s]
Processed prompts:  25%|██▌       | 522/2048 [00:26<01:25, 17.76it/s, est. speed input: 20447.81 toks/s, output: 19.97 toks/s]
Processed prompts:  26%|██▌       | 527/2048 [00:26<01:25, 17.76it/s, est. speed input: 20423.64 toks/s, output: 19.94 toks/s]
Processed prompts:  26%|██▌       | 532/2048 [00:26<01:25, 17.75it/s, est. speed input: 20399.73 toks/s, output: 19.92 toks/s]
Processed prompts:  26%|██▌       | 537/2048 [00:26<01:25, 17.75it/s, est. speed input: 20376.57 toks/s, output: 19.90 toks/s]
Processed prompts:  26%|██▋       | 542/2048 [00:27<01:24, 17.74it/s, est. speed input: 20353.57 toks/s, output: 19.88 toks/s]
Processed prompts:  27%|██▋       | 547/2048 [00:27<01:24, 17.75it/s, est. speed input: 20331.30 toks/s, output: 19.85 toks/s]
Processed prompts:  27%|██▋       | 552/2048 [00:27<01:24, 17.75it/s, est. speed input: 20309.69 toks/s, output: 19.83 toks/s]
Processed prompts:  27%|██▋       | 557/2048 [00:28<01:23, 17.75it/s, est. speed input: 20288.36 toks/s, output: 19.81 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:28<01:23, 17.74it/s, est. speed input: 20267.12 toks/s, output: 19.79 toks/s]
Processed prompts:  28%|██▊       | 567/2048 [00:28<01:23, 17.75it/s, est. speed input: 20246.61 toks/s, output: 19.77 toks/s]
Processed prompts:  28%|██▊       | 572/2048 [00:28<01:23, 17.75it/s, est. speed input: 20226.53 toks/s, output: 19.75 toks/s]
Processed prompts:  28%|██▊       | 577/2048 [00:29<01:22, 17.75it/s, est. speed input: 20206.65 toks/s, output: 19.73 toks/s]
Processed prompts:  28%|██▊       | 582/2048 [00:29<01:22, 17.75it/s, est. speed input: 20187.34 toks/s, output: 19.71 toks/s]
Processed prompts:  29%|██▊       | 587/2048 [00:29<01:22, 17.74it/s, est. speed input: 20168.14 toks/s, output: 19.70 toks/s]
Processed prompts:  29%|██▉       | 592/2048 [00:30<01:22, 17.74it/s, est. speed input: 20149.40 toks/s, output: 19.68 toks/s]
Processed prompts:  29%|██▉       | 597/2048 [00:30<01:21, 17.74it/s, est. speed input: 20130.91 toks/s, output: 19.66 toks/s]
Processed prompts:  29%|██▉       | 602/2048 [00:30<01:21, 17.74it/s, est. speed input: 20112.97 toks/s, output: 19.64 toks/s]
Processed prompts:  30%|██▉       | 607/2048 [00:30<01:21, 17.74it/s, est. speed input: 20095.27 toks/s, output: 19.62 toks/s]
Processed prompts:  30%|██▉       | 612/2048 [00:31<01:20, 17.74it/s, est. speed input: 20077.67 toks/s, output: 19.61 toks/s]
Processed prompts:  30%|███       | 617/2048 [00:31<01:20, 17.75it/s, est. speed input: 20060.85 toks/s, output: 19.59 toks/s]
Processed prompts:  30%|███       | 622/2048 [00:31<01:20, 17.75it/s, est. speed input: 20044.17 toks/s, output: 19.57 toks/s]
Processed prompts:  31%|███       | 627/2048 [00:32<01:20, 17.75it/s, est. speed input: 20027.66 toks/s, output: 19.56 toks/s]
Processed prompts:  31%|███       | 632/2048 [00:32<01:19, 17.74it/s, est. speed input: 20011.15 toks/s, output: 19.54 toks/s]
Processed prompts:  31%|███       | 637/2048 [00:32<01:19, 17.74it/s, est. speed input: 19995.17 toks/s, output: 19.53 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:32<01:19, 17.74it/s, est. speed input: 19979.47 toks/s, output: 19.51 toks/s]
Processed prompts:  32%|███▏      | 647/2048 [00:33<01:19, 17.73it/s, est. speed input: 19963.92 toks/s, output: 19.50 toks/s]
Processed prompts:  32%|███▏      | 652/2048 [00:33<01:18, 17.74it/s, est. speed input: 19948.92 toks/s, output: 19.48 toks/s]
Processed prompts:  32%|███▏      | 657/2048 [00:33<01:18, 17.74it/s, est. speed input: 19934.10 toks/s, output: 19.47 toks/s]
Processed prompts:  32%|███▏      | 662/2048 [00:34<01:18, 17.74it/s, est. speed input: 19919.43 toks/s, output: 19.45 toks/s]
Processed prompts:  33%|███▎      | 667/2048 [00:34<01:17, 17.73it/s, est. speed input: 19904.82 toks/s, output: 19.44 toks/s]
Processed prompts:  33%|███▎      | 672/2048 [00:34<01:17, 17.74it/s, est. speed input: 19890.83 toks/s, output: 19.42 toks/s]
Processed prompts:  33%|███▎      | 677/2048 [00:34<01:17, 17.74it/s, est. speed input: 19876.92 toks/s, output: 19.41 toks/s]
Processed prompts:  33%|███▎      | 682/2048 [00:35<01:16, 17.74it/s, est. speed input: 19863.27 toks/s, output: 19.40 toks/s]
Processed prompts:  34%|███▎      | 687/2048 [00:35<01:16, 17.74it/s, est. speed input: 19849.73 toks/s, output: 19.38 toks/s]
Processed prompts:  34%|███▍      | 692/2048 [00:35<01:16, 17.73it/s, est. speed input: 19836.25 toks/s, output: 19.37 toks/s]
Processed prompts:  34%|███▍      | 697/2048 [00:36<01:16, 17.73it/s, est. speed input: 19823.13 toks/s, output: 19.36 toks/s]
Processed prompts:  34%|███▍      | 702/2048 [00:36<01:15, 17.73it/s, est. speed input: 19810.19 toks/s, output: 19.35 toks/s]
Processed prompts:  35%|███▍      | 707/2048 [00:36<01:15, 17.74it/s, est. speed input: 19797.63 toks/s, output: 19.33 toks/s]
Processed prompts:  35%|███▍      | 712/2048 [00:36<01:15, 17.74it/s, est. speed input: 19785.22 toks/s, output: 19.32 toks/s]
Processed prompts:  35%|███▌      | 717/2048 [00:37<01:15, 17.73it/s, est. speed input: 19772.70 toks/s, output: 19.31 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:37<01:14, 17.73it/s, est. speed input: 19760.37 toks/s, output: 19.30 toks/s]
Processed prompts:  35%|███▌      | 727/2048 [00:37<01:14, 17.73it/s, est. speed input: 19748.38 toks/s, output: 19.29 toks/s]
Processed prompts:  36%|███▌      | 732/2048 [00:37<01:14, 17.74it/s, est. speed input: 19736.79 toks/s, output: 19.27 toks/s]
Processed prompts:  36%|███▌      | 737/2048 [00:38<01:13, 17.74it/s, est. speed input: 19725.15 toks/s, output: 19.26 toks/s]
Processed prompts:  36%|███▌      | 742/2048 [00:38<01:13, 17.72it/s, est. speed input: 19713.39 toks/s, output: 19.25 toks/s]
Processed prompts:  36%|███▋      | 747/2048 [00:38<01:13, 17.73it/s, est. speed input: 19702.23 toks/s, output: 19.24 toks/s]
Processed prompts:  37%|███▋      | 752/2048 [00:39<01:13, 17.73it/s, est. speed input: 19691.12 toks/s, output: 19.23 toks/s]
Processed prompts:  37%|███▋      | 757/2048 [00:39<01:12, 17.73it/s, est. speed input: 19680.09 toks/s, output: 19.22 toks/s]
Processed prompts:  37%|███▋      | 762/2048 [00:39<01:12, 17.73it/s, est. speed input: 19669.32 toks/s, output: 19.21 toks/s]
Processed prompts:  37%|███▋      | 767/2048 [00:39<01:12, 17.73it/s, est. speed input: 19658.53 toks/s, output: 19.20 toks/s]
Processed prompts:  38%|███▊      | 772/2048 [00:40<01:11, 17.73it/s, est. speed input: 19647.97 toks/s, output: 19.19 toks/s]
Processed prompts:  38%|███▊      | 777/2048 [00:40<01:11, 17.73it/s, est. speed input: 19637.51 toks/s, output: 19.18 toks/s]
Processed prompts:  38%|███▊      | 782/2048 [00:40<01:11, 17.73it/s, est. speed input: 19627.46 toks/s, output: 19.17 toks/s]
Processed prompts:  38%|███▊      | 787/2048 [00:41<01:11, 17.74it/s, est. speed input: 19617.47 toks/s, output: 19.16 toks/s]
Processed prompts:  39%|███▊      | 792/2048 [00:41<01:10, 17.72it/s, est. speed input: 19607.08 toks/s, output: 19.15 toks/s]
Processed prompts:  39%|███▉      | 797/2048 [00:41<01:10, 17.72it/s, est. speed input: 19597.21 toks/s, output: 19.14 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:41<01:10, 17.72it/s, est. speed input: 19587.53 toks/s, output: 19.13 toks/s]
Processed prompts:  39%|███▉      | 807/2048 [00:42<01:10, 17.72it/s, est. speed input: 19577.88 toks/s, output: 19.12 toks/s]
Processed prompts:  40%|███▉      | 812/2048 [00:42<01:09, 17.72it/s, est. speed input: 19568.30 toks/s, output: 19.11 toks/s]
Processed prompts:  40%|███▉      | 817/2048 [00:42<01:09, 17.72it/s, est. speed input: 19558.84 toks/s, output: 19.10 toks/s]
Processed prompts:  40%|████      | 822/2048 [00:43<01:09, 17.72it/s, est. speed input: 19549.62 toks/s, output: 19.09 toks/s]
Processed prompts:  40%|████      | 827/2048 [00:43<01:08, 17.71it/s, est. speed input: 19540.32 toks/s, output: 19.08 toks/s]
Processed prompts:  41%|████      | 832/2048 [00:43<01:08, 17.72it/s, est. speed input: 19531.38 toks/s, output: 19.07 toks/s]
Processed prompts:  41%|████      | 837/2048 [00:43<01:08, 17.71it/s, est. speed input: 19522.31 toks/s, output: 19.06 toks/s]
Processed prompts:  41%|████      | 842/2048 [00:44<01:08, 17.72it/s, est. speed input: 19513.61 toks/s, output: 19.06 toks/s]
Processed prompts:  41%|████▏     | 847/2048 [00:44<01:07, 17.72it/s, est. speed input: 19505.01 toks/s, output: 19.05 toks/s]
Processed prompts:  42%|████▏     | 852/2048 [00:44<01:07, 17.72it/s, est. speed input: 19496.48 toks/s, output: 19.04 toks/s]
Processed prompts:  42%|████▏     | 857/2048 [00:45<01:07, 17.72it/s, est. speed input: 19487.89 toks/s, output: 19.03 toks/s]
Processed prompts:  42%|████▏     | 862/2048 [00:45<01:06, 17.71it/s, est. speed input: 19479.34 toks/s, output: 19.02 toks/s]
Processed prompts:  42%|████▏     | 867/2048 [00:45<01:06, 17.72it/s, est. speed input: 19471.31 toks/s, output: 19.01 toks/s]
Processed prompts:  43%|████▎     | 872/2048 [00:45<01:06, 17.72it/s, est. speed input: 19463.08 toks/s, output: 19.01 toks/s]
Processed prompts:  43%|████▎     | 877/2048 [00:46<01:06, 17.72it/s, est. speed input: 19455.02 toks/s, output: 19.00 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:46<01:05, 17.71it/s, est. speed input: 19446.85 toks/s, output: 18.99 toks/s]
Processed prompts:  43%|████▎     | 887/2048 [00:46<01:05, 17.72it/s, est. speed input: 19439.15 toks/s, output: 18.98 toks/s]
Processed prompts:  44%|████▎     | 892/2048 [00:47<01:05, 17.72it/s, est. speed input: 19431.43 toks/s, output: 18.98 toks/s]
Processed prompts:  44%|████▍     | 897/2048 [00:47<01:04, 17.72it/s, est. speed input: 19423.78 toks/s, output: 18.97 toks/s]
Processed prompts:  44%|████▍     | 902/2048 [00:47<01:04, 17.72it/s, est. speed input: 19416.07 toks/s, output: 18.96 toks/s]
Processed prompts:  44%|████▍     | 907/2048 [00:47<01:04, 17.71it/s, est. speed input: 19408.39 toks/s, output: 18.95 toks/s]
Processed prompts:  45%|████▍     | 912/2048 [00:48<01:04, 17.71it/s, est. speed input: 19400.94 toks/s, output: 18.95 toks/s]
Processed prompts:  45%|████▍     | 917/2048 [00:48<01:03, 17.71it/s, est. speed input: 19393.63 toks/s, output: 18.94 toks/s]
Processed prompts:  45%|████▌     | 922/2048 [00:48<01:03, 17.72it/s, est. speed input: 19386.41 toks/s, output: 18.93 toks/s]
Processed prompts:  45%|████▌     | 927/2048 [00:48<01:03, 17.72it/s, est. speed input: 19379.27 toks/s, output: 18.93 toks/s]
Processed prompts:  46%|████▌     | 932/2048 [00:49<01:03, 17.71it/s, est. speed input: 19371.99 toks/s, output: 18.92 toks/s]
Processed prompts:  46%|████▌     | 937/2048 [00:49<01:02, 17.71it/s, est. speed input: 19364.97 toks/s, output: 18.91 toks/s]
Processed prompts:  46%|████▌     | 942/2048 [00:49<01:02, 17.70it/s, est. speed input: 19357.89 toks/s, output: 18.90 toks/s]
Processed prompts:  46%|████▌     | 947/2048 [00:50<01:02, 17.70it/s, est. speed input: 19350.95 toks/s, output: 18.90 toks/s]
Processed prompts:  46%|████▋     | 952/2048 [00:50<01:01, 17.71it/s, est. speed input: 19344.24 toks/s, output: 18.89 toks/s]
Processed prompts:  47%|████▋     | 957/2048 [00:50<01:01, 17.71it/s, est. speed input: 19337.59 toks/s, output: 18.88 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:50<01:01, 17.72it/s, est. speed input: 19330.97 toks/s, output: 18.88 toks/s]
Processed prompts:  47%|████▋     | 967/2048 [00:51<01:01, 17.71it/s, est. speed input: 19324.26 toks/s, output: 18.87 toks/s]
Processed prompts:  47%|████▋     | 972/2048 [00:51<01:00, 17.70it/s, est. speed input: 19317.48 toks/s, output: 18.86 toks/s]
Processed prompts:  48%|████▊     | 977/2048 [00:51<01:00, 17.71it/s, est. speed input: 19311.24 toks/s, output: 18.86 toks/s]
Processed prompts:  48%|████▊     | 982/2048 [00:52<01:00, 17.71it/s, est. speed input: 19304.85 toks/s, output: 18.85 toks/s]
Processed prompts:  48%|████▊     | 987/2048 [00:52<00:59, 17.70it/s, est. speed input: 19298.39 toks/s, output: 18.85 toks/s]
Processed prompts:  48%|████▊     | 992/2048 [00:52<00:59, 17.70it/s, est. speed input: 19292.11 toks/s, output: 18.84 toks/s]
Processed prompts:  49%|████▊     | 997/2048 [00:52<00:59, 17.70it/s, est. speed input: 19285.94 toks/s, output: 18.83 toks/s]
Processed prompts:  49%|████▉     | 1002/2048 [00:53<00:59, 17.70it/s, est. speed input: 19279.80 toks/s, output: 18.83 toks/s]
Processed prompts:  49%|████▉     | 1007/2048 [00:53<00:58, 17.71it/s, est. speed input: 19273.91 toks/s, output: 18.82 toks/s]
Processed prompts:  49%|████▉     | 1012/2048 [00:53<00:58, 17.71it/s, est. speed input: 19267.81 toks/s, output: 18.82 toks/s]
Processed prompts:  50%|████▉     | 1017/2048 [00:54<00:58, 17.70it/s, est. speed input: 19261.76 toks/s, output: 18.81 toks/s]
Processed prompts:  50%|████▉     | 1022/2048 [00:54<00:57, 17.69it/s, est. speed input: 19255.75 toks/s, output: 18.80 toks/s]
Processed prompts:  50%|█████     | 1027/2048 [00:54<00:57, 17.71it/s, est. speed input: 19250.14 toks/s, output: 18.80 toks/s]
Processed prompts:  50%|█████     | 1032/2048 [00:54<00:57, 17.70it/s, est. speed input: 19244.29 toks/s, output: 18.79 toks/s]
Processed prompts:  51%|█████     | 1037/2048 [00:55<00:57, 17.70it/s, est. speed input: 19238.61 toks/s, output: 18.79 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:55<00:56, 17.71it/s, est. speed input: 19232.98 toks/s, output: 18.78 toks/s]
Processed prompts:  51%|█████     | 1047/2048 [00:55<00:56, 17.71it/s, est. speed input: 19227.40 toks/s, output: 18.78 toks/s]
Processed prompts:  51%|█████▏    | 1052/2048 [00:56<00:56, 17.70it/s, est. speed input: 19221.78 toks/s, output: 18.77 toks/s]
Processed prompts:  52%|█████▏    | 1057/2048 [00:56<00:55, 17.70it/s, est. speed input: 19216.26 toks/s, output: 18.77 toks/s]
Processed prompts:  52%|█████▏    | 1062/2048 [00:56<00:55, 17.70it/s, est. speed input: 19210.82 toks/s, output: 18.76 toks/s]
Processed prompts:  52%|█████▏    | 1067/2048 [00:56<00:55, 17.70it/s, est. speed input: 19205.47 toks/s, output: 18.76 toks/s]
Processed prompts:  52%|█████▏    | 1072/2048 [00:57<00:55, 17.69it/s, est. speed input: 19199.98 toks/s, output: 18.75 toks/s]
Processed prompts:  53%|█████▎    | 1077/2048 [00:57<00:54, 17.70it/s, est. speed input: 19194.84 toks/s, output: 18.74 toks/s]
Processed prompts:  53%|█████▎    | 1082/2048 [00:57<00:54, 17.70it/s, est. speed input: 19189.60 toks/s, output: 18.74 toks/s]
Processed prompts:  53%|█████▎    | 1087/2048 [00:58<00:54, 17.71it/s, est. speed input: 19184.61 toks/s, output: 18.73 toks/s]
Processed prompts:  53%|█████▎    | 1092/2048 [00:58<00:53, 17.71it/s, est. speed input: 19179.43 toks/s, output: 18.73 toks/s]
Processed prompts:  54%|█████▎    | 1097/2048 [00:58<00:53, 17.70it/s, est. speed input: 19174.28 toks/s, output: 18.72 toks/s]
Processed prompts:  54%|█████▍    | 1102/2048 [00:58<00:53, 17.71it/s, est. speed input: 19169.37 toks/s, output: 18.72 toks/s]
Processed prompts:  54%|█████▍    | 1107/2048 [00:59<00:53, 17.71it/s, est. speed input: 19164.44 toks/s, output: 18.72 toks/s]
Processed prompts:  54%|█████▍    | 1112/2048 [00:59<00:52, 17.70it/s, est. speed input: 19159.39 toks/s, output: 18.71 toks/s]
Processed prompts:  55%|█████▍    | 1117/2048 [00:59<00:52, 17.70it/s, est. speed input: 19154.44 toks/s, output: 18.71 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:59<00:52, 17.69it/s, est. speed input: 19149.50 toks/s, output: 18.70 toks/s]
Processed prompts:  55%|█████▌    | 1127/2048 [01:00<00:52, 17.69it/s, est. speed input: 19144.68 toks/s, output: 18.70 toks/s]
Processed prompts:  55%|█████▌    | 1132/2048 [01:00<00:51, 17.69it/s, est. speed input: 19139.88 toks/s, output: 18.69 toks/s]
Processed prompts:  56%|█████▌    | 1137/2048 [01:00<00:51, 17.70it/s, est. speed input: 19135.24 toks/s, output: 18.69 toks/s]
Processed prompts:  56%|█████▌    | 1142/2048 [01:01<00:51, 17.69it/s, est. speed input: 19130.50 toks/s, output: 18.68 toks/s]
Processed prompts:  56%|█████▌    | 1147/2048 [01:01<00:50, 17.70it/s, est. speed input: 19125.88 toks/s, output: 18.68 toks/s]
Processed prompts:  56%|█████▋    | 1152/2048 [01:01<00:50, 17.70it/s, est. speed input: 19121.25 toks/s, output: 18.67 toks/s]
Processed prompts:  56%|█████▋    | 1157/2048 [01:01<00:50, 17.70it/s, est. speed input: 19116.72 toks/s, output: 18.67 toks/s]
Processed prompts:  57%|█████▋    | 1162/2048 [01:02<00:50, 17.70it/s, est. speed input: 19112.22 toks/s, output: 18.66 toks/s]
Processed prompts:  57%|█████▋    | 1167/2048 [01:02<00:49, 17.70it/s, est. speed input: 19107.80 toks/s, output: 18.66 toks/s]
Processed prompts:  57%|█████▋    | 1172/2048 [01:02<00:49, 17.70it/s, est. speed input: 19103.37 toks/s, output: 18.66 toks/s]
Processed prompts:  57%|█████▋    | 1177/2048 [01:03<00:49, 17.70it/s, est. speed input: 19098.93 toks/s, output: 18.65 toks/s]
Processed prompts:  58%|█████▊    | 1182/2048 [01:03<00:48, 17.69it/s, est. speed input: 19094.50 toks/s, output: 18.65 toks/s]
Processed prompts:  58%|█████▊    | 1187/2048 [01:03<00:48, 17.70it/s, est. speed input: 19090.28 toks/s, output: 18.64 toks/s]
Processed prompts:  58%|█████▊    | 1192/2048 [01:03<00:48, 17.70it/s, est. speed input: 19085.98 toks/s, output: 18.64 toks/s]
Processed prompts:  58%|█████▊    | 1197/2048 [01:04<00:48, 17.70it/s, est. speed input: 19081.70 toks/s, output: 18.63 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:04<00:47, 17.70it/s, est. speed input: 19077.52 toks/s, output: 18.63 toks/s]
Processed prompts:  59%|█████▉    | 1207/2048 [01:04<00:47, 17.70it/s, est. speed input: 19073.48 toks/s, output: 18.63 toks/s]
Processed prompts:  59%|█████▉    | 1212/2048 [01:05<00:47, 17.70it/s, est. speed input: 19069.37 toks/s, output: 18.62 toks/s]
Processed prompts:  59%|█████▉    | 1217/2048 [01:05<00:46, 17.69it/s, est. speed input: 19065.16 toks/s, output: 18.62 toks/s]
Processed prompts:  60%|█████▉    | 1222/2048 [01:05<00:46, 17.69it/s, est. speed input: 19061.02 toks/s, output: 18.61 toks/s]
Processed prompts:  60%|█████▉    | 1227/2048 [01:05<00:46, 17.69it/s, est. speed input: 19056.89 toks/s, output: 18.61 toks/s]
Processed prompts:  60%|██████    | 1232/2048 [01:06<00:46, 17.68it/s, est. speed input: 19052.75 toks/s, output: 18.61 toks/s]
Processed prompts:  60%|██████    | 1237/2048 [01:06<00:45, 17.68it/s, est. speed input: 19048.73 toks/s, output: 18.60 toks/s]
Processed prompts:  61%|██████    | 1242/2048 [01:06<00:45, 17.68it/s, est. speed input: 19044.79 toks/s, output: 18.60 toks/s]
Processed prompts:  61%|██████    | 1247/2048 [01:07<00:45, 17.70it/s, est. speed input: 19041.02 toks/s, output: 18.59 toks/s]
Processed prompts:  61%|██████    | 1252/2048 [01:07<00:44, 17.69it/s, est. speed input: 19037.05 toks/s, output: 18.59 toks/s]
Processed prompts:  61%|██████▏   | 1257/2048 [01:07<00:44, 17.69it/s, est. speed input: 19033.14 toks/s, output: 18.59 toks/s]
Processed prompts:  62%|██████▏   | 1262/2048 [01:07<00:44, 17.69it/s, est. speed input: 19029.42 toks/s, output: 18.58 toks/s]
Processed prompts:  62%|██████▏   | 1267/2048 [01:08<00:44, 17.69it/s, est. speed input: 19025.59 toks/s, output: 18.58 toks/s]
Processed prompts:  62%|██████▏   | 1272/2048 [01:08<00:43, 17.69it/s, est. speed input: 19021.87 toks/s, output: 18.58 toks/s]
Processed prompts:  62%|██████▏   | 1277/2048 [01:08<00:43, 17.69it/s, est. speed input: 19018.13 toks/s, output: 18.57 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:09<00:43, 17.69it/s, est. speed input: 19014.46 toks/s, output: 18.57 toks/s]
Processed prompts:  63%|██████▎   | 1287/2048 [01:09<00:43, 17.68it/s, est. speed input: 19010.61 toks/s, output: 18.57 toks/s]
Processed prompts:  63%|██████▎   | 1292/2048 [01:09<00:42, 17.68it/s, est. speed input: 19006.93 toks/s, output: 18.56 toks/s]
Processed prompts:  63%|██████▎   | 1297/2048 [01:09<00:42, 17.68it/s, est. speed input: 19003.31 toks/s, output: 18.56 toks/s]
Processed prompts:  64%|██████▎   | 1302/2048 [01:10<00:42, 17.68it/s, est. speed input: 18999.63 toks/s, output: 18.55 toks/s]
Processed prompts:  64%|██████▍   | 1307/2048 [01:10<00:41, 17.68it/s, est. speed input: 18996.07 toks/s, output: 18.55 toks/s]
Processed prompts:  64%|██████▍   | 1312/2048 [01:10<00:41, 17.68it/s, est. speed input: 18992.55 toks/s, output: 18.55 toks/s]
Processed prompts:  64%|██████▍   | 1317/2048 [01:11<00:41, 17.70it/s, est. speed input: 18989.19 toks/s, output: 18.54 toks/s]
Processed prompts:  65%|██████▍   | 1322/2048 [01:11<00:41, 17.68it/s, est. speed input: 18985.57 toks/s, output: 18.54 toks/s]
Processed prompts:  65%|██████▍   | 1327/2048 [01:11<00:40, 17.69it/s, est. speed input: 18982.18 toks/s, output: 18.54 toks/s]
Processed prompts:  65%|██████▌   | 1332/2048 [01:11<00:40, 17.69it/s, est. speed input: 18978.76 toks/s, output: 18.53 toks/s]
Processed prompts:  65%|██████▌   | 1337/2048 [01:12<00:40, 17.69it/s, est. speed input: 18975.44 toks/s, output: 18.53 toks/s]
Processed prompts:  66%|██████▌   | 1342/2048 [01:12<00:39, 17.69it/s, est. speed input: 18972.06 toks/s, output: 18.53 toks/s]
Processed prompts:  66%|██████▌   | 1347/2048 [01:12<00:39, 17.69it/s, est. speed input: 18968.66 toks/s, output: 18.52 toks/s]
Processed prompts:  66%|██████▌   | 1352/2048 [01:12<00:39, 17.69it/s, est. speed input: 18965.33 toks/s, output: 18.52 toks/s]
Processed prompts:  66%|██████▋   | 1357/2048 [01:13<00:39, 17.68it/s, est. speed input: 18961.98 toks/s, output: 18.52 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:13<00:38, 17.68it/s, est. speed input: 18958.68 toks/s, output: 18.51 toks/s]
Processed prompts:  67%|██████▋   | 1367/2048 [01:13<00:38, 17.68it/s, est. speed input: 18955.39 toks/s, output: 18.51 toks/s]
Processed prompts:  67%|██████▋   | 1372/2048 [01:14<00:38, 17.69it/s, est. speed input: 18952.28 toks/s, output: 18.51 toks/s]
Processed prompts:  67%|██████▋   | 1377/2048 [01:14<00:37, 17.68it/s, est. speed input: 18948.96 toks/s, output: 18.50 toks/s]
Processed prompts:  67%|██████▋   | 1382/2048 [01:14<00:37, 17.68it/s, est. speed input: 18945.75 toks/s, output: 18.50 toks/s]
Processed prompts:  68%|██████▊   | 1387/2048 [01:14<00:37, 17.68it/s, est. speed input: 18942.58 toks/s, output: 18.50 toks/s]
Processed prompts:  68%|██████▊   | 1392/2048 [01:15<00:37, 17.68it/s, est. speed input: 18939.48 toks/s, output: 18.50 toks/s]
Processed prompts:  68%|██████▊   | 1397/2048 [01:15<00:36, 17.68it/s, est. speed input: 18936.35 toks/s, output: 18.49 toks/s]
Processed prompts:  68%|██████▊   | 1402/2048 [01:15<00:36, 17.69it/s, est. speed input: 18933.30 toks/s, output: 18.49 toks/s]
Processed prompts:  69%|██████▊   | 1407/2048 [01:16<00:36, 17.68it/s, est. speed input: 18930.19 toks/s, output: 18.49 toks/s]
Processed prompts:  69%|██████▉   | 1412/2048 [01:16<00:35, 17.68it/s, est. speed input: 18927.10 toks/s, output: 18.48 toks/s]
Processed prompts:  69%|██████▉   | 1417/2048 [01:16<00:35, 17.68it/s, est. speed input: 18924.12 toks/s, output: 18.48 toks/s]
Processed prompts:  69%|██████▉   | 1422/2048 [01:16<00:35, 17.69it/s, est. speed input: 18921.17 toks/s, output: 18.48 toks/s]
Processed prompts:  70%|██████▉   | 1427/2048 [01:17<00:35, 17.69it/s, est. speed input: 18918.24 toks/s, output: 18.47 toks/s]
Processed prompts:  70%|██████▉   | 1432/2048 [01:17<00:34, 17.69it/s, est. speed input: 18915.31 toks/s, output: 18.47 toks/s]
Processed prompts:  70%|███████   | 1437/2048 [01:17<00:34, 17.69it/s, est. speed input: 18912.37 toks/s, output: 18.47 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:18<00:34, 17.68it/s, est. speed input: 18909.42 toks/s, output: 18.47 toks/s]
Processed prompts:  71%|███████   | 1447/2048 [01:18<00:33, 17.68it/s, est. speed input: 18906.50 toks/s, output: 18.46 toks/s]
Processed prompts:  71%|███████   | 1452/2048 [01:18<00:33, 17.69it/s, est. speed input: 18903.68 toks/s, output: 18.46 toks/s]
Processed prompts:  71%|███████   | 1457/2048 [01:18<00:33, 17.69it/s, est. speed input: 18900.86 toks/s, output: 18.46 toks/s]
Processed prompts:  71%|███████▏  | 1462/2048 [01:19<00:33, 17.68it/s, est. speed input: 18897.97 toks/s, output: 18.46 toks/s]
Processed prompts:  72%|███████▏  | 1467/2048 [01:19<00:32, 17.69it/s, est. speed input: 18895.21 toks/s, output: 18.45 toks/s]
Processed prompts:  72%|███████▏  | 1472/2048 [01:19<00:32, 17.69it/s, est. speed input: 18892.48 toks/s, output: 18.45 toks/s]
Processed prompts:  72%|███████▏  | 1477/2048 [01:20<00:32, 17.69it/s, est. speed input: 18889.72 toks/s, output: 18.45 toks/s]
Processed prompts:  72%|███████▏  | 1482/2048 [01:20<00:31, 17.69it/s, est. speed input: 18886.97 toks/s, output: 18.44 toks/s]
Processed prompts:  73%|███████▎  | 1487/2048 [01:20<00:31, 17.69it/s, est. speed input: 18884.24 toks/s, output: 18.44 toks/s]
Processed prompts:  73%|███████▎  | 1492/2048 [01:20<00:31, 17.69it/s, est. speed input: 18881.53 toks/s, output: 18.44 toks/s]
Processed prompts:  73%|███████▎  | 1497/2048 [01:21<00:31, 17.68it/s, est. speed input: 18878.75 toks/s, output: 18.44 toks/s]
Processed prompts:  73%|███████▎  | 1502/2048 [01:21<00:30, 17.69it/s, est. speed input: 18876.21 toks/s, output: 18.43 toks/s]
Processed prompts:  74%|███████▎  | 1507/2048 [01:21<00:30, 17.69it/s, est. speed input: 18873.60 toks/s, output: 18.43 toks/s]
Processed prompts:  74%|███████▍  | 1512/2048 [01:22<00:30, 17.68it/s, est. speed input: 18870.88 toks/s, output: 18.43 toks/s]
Processed prompts:  74%|███████▍  | 1517/2048 [01:22<00:30, 17.68it/s, est. speed input: 18868.21 toks/s, output: 18.43 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:22<00:29, 17.68it/s, est. speed input: 18865.63 toks/s, output: 18.42 toks/s]
Processed prompts:  75%|███████▍  | 1527/2048 [01:22<00:29, 17.68it/s, est. speed input: 18863.04 toks/s, output: 18.42 toks/s]
Processed prompts:  75%|███████▍  | 1532/2048 [01:23<00:29, 17.68it/s, est. speed input: 18860.40 toks/s, output: 18.42 toks/s]
Processed prompts:  75%|███████▌  | 1537/2048 [01:23<00:28, 17.69it/s, est. speed input: 18857.97 toks/s, output: 18.42 toks/s]
Processed prompts:  75%|███████▌  | 1542/2048 [01:23<00:28, 17.68it/s, est. speed input: 18855.39 toks/s, output: 18.41 toks/s]
Processed prompts:  76%|███████▌  | 1547/2048 [01:24<00:28, 17.68it/s, est. speed input: 18852.86 toks/s, output: 18.41 toks/s]
Processed prompts:  76%|███████▌  | 1552/2048 [01:24<00:28, 17.68it/s, est. speed input: 18850.30 toks/s, output: 18.41 toks/s]
Processed prompts:  76%|███████▌  | 1557/2048 [01:24<00:27, 17.68it/s, est. speed input: 18847.81 toks/s, output: 18.41 toks/s]
Processed prompts:  76%|███████▋  | 1562/2048 [01:24<00:27, 17.68it/s, est. speed input: 18845.32 toks/s, output: 18.40 toks/s]
Processed prompts:  77%|███████▋  | 1567/2048 [01:25<00:27, 17.68it/s, est. speed input: 18842.93 toks/s, output: 18.40 toks/s]
Processed prompts:  77%|███████▋  | 1572/2048 [01:25<00:26, 17.69it/s, est. speed input: 18840.51 toks/s, output: 18.40 toks/s]
Processed prompts:  77%|███████▋  | 1577/2048 [01:25<00:26, 17.69it/s, est. speed input: 18838.14 toks/s, output: 18.40 toks/s]
Processed prompts:  77%|███████▋  | 1582/2048 [01:26<00:26, 17.69it/s, est. speed input: 18835.74 toks/s, output: 18.39 toks/s]
Processed prompts:  77%|███████▋  | 1587/2048 [01:26<00:26, 17.68it/s, est. speed input: 18833.28 toks/s, output: 18.39 toks/s]
Processed prompts:  78%|███████▊  | 1592/2048 [01:26<00:25, 17.69it/s, est. speed input: 18830.99 toks/s, output: 18.39 toks/s]
Processed prompts:  78%|███████▊  | 1597/2048 [01:26<00:25, 17.69it/s, est. speed input: 18828.63 toks/s, output: 18.39 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:27<00:25, 17.68it/s, est. speed input: 18826.27 toks/s, output: 18.39 toks/s]
Processed prompts:  78%|███████▊  | 1607/2048 [01:27<00:24, 17.68it/s, est. speed input: 18823.86 toks/s, output: 18.38 toks/s]
Processed prompts:  79%|███████▊  | 1612/2048 [01:27<00:24, 17.68it/s, est. speed input: 18821.57 toks/s, output: 18.38 toks/s]
Processed prompts:  79%|███████▉  | 1617/2048 [01:27<00:24, 17.68it/s, est. speed input: 18819.29 toks/s, output: 18.38 toks/s]
Processed prompts:  79%|███████▉  | 1622/2048 [01:28<00:24, 17.68it/s, est. speed input: 18816.95 toks/s, output: 18.38 toks/s]
Processed prompts:  79%|███████▉  | 1627/2048 [01:28<00:23, 17.68it/s, est. speed input: 18814.72 toks/s, output: 18.37 toks/s]
Processed prompts:  80%|███████▉  | 1632/2048 [01:28<00:23, 17.68it/s, est. speed input: 18812.41 toks/s, output: 18.37 toks/s]
Processed prompts:  80%|███████▉  | 1637/2048 [01:29<00:23, 17.68it/s, est. speed input: 18810.18 toks/s, output: 18.37 toks/s]
Processed prompts:  80%|████████  | 1642/2048 [01:29<00:22, 17.68it/s, est. speed input: 18807.93 toks/s, output: 18.37 toks/s]
Processed prompts:  80%|████████  | 1647/2048 [01:29<00:22, 17.68it/s, est. speed input: 18805.71 toks/s, output: 18.36 toks/s]
Processed prompts:  81%|████████  | 1652/2048 [01:29<00:22, 17.68it/s, est. speed input: 18803.47 toks/s, output: 18.36 toks/s]
Processed prompts:  81%|████████  | 1657/2048 [01:30<00:22, 17.67it/s, est. speed input: 18801.21 toks/s, output: 18.36 toks/s]
Processed prompts:  81%|████████  | 1662/2048 [01:30<00:21, 17.68it/s, est. speed input: 18799.10 toks/s, output: 18.36 toks/s]
Processed prompts:  81%|████████▏ | 1667/2048 [01:30<00:21, 17.68it/s, est. speed input: 18796.96 toks/s, output: 18.36 toks/s]
Processed prompts:  82%|████████▏ | 1672/2048 [01:31<00:21, 17.68it/s, est. speed input: 18794.78 toks/s, output: 18.35 toks/s]
Processed prompts:  82%|████████▏ | 1677/2048 [01:31<00:20, 17.68it/s, est. speed input: 18792.61 toks/s, output: 18.35 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:31<00:20, 17.67it/s, est. speed input: 18790.44 toks/s, output: 18.35 toks/s]
Processed prompts:  82%|████████▏ | 1687/2048 [01:31<00:20, 17.68it/s, est. speed input: 18788.33 toks/s, output: 18.35 toks/s]
Processed prompts:  83%|████████▎ | 1692/2048 [01:32<00:20, 17.67it/s, est. speed input: 18786.18 toks/s, output: 18.35 toks/s]
Processed prompts:  83%|████████▎ | 1697/2048 [01:32<00:19, 17.68it/s, est. speed input: 18784.14 toks/s, output: 18.34 toks/s]
Processed prompts:  83%|████████▎ | 1702/2048 [01:32<00:19, 17.68it/s, est. speed input: 18782.03 toks/s, output: 18.34 toks/s]
Processed prompts:  83%|████████▎ | 1707/2048 [01:33<00:19, 17.67it/s, est. speed input: 18779.93 toks/s, output: 18.34 toks/s]
Processed prompts:  84%|████████▎ | 1712/2048 [01:33<00:19, 17.67it/s, est. speed input: 18777.81 toks/s, output: 18.34 toks/s]
Processed prompts:  84%|████████▍ | 1717/2048 [01:33<00:18, 17.67it/s, est. speed input: 18775.77 toks/s, output: 18.34 toks/s]
Processed prompts:  84%|████████▍ | 1722/2048 [01:33<00:18, 17.67it/s, est. speed input: 18773.72 toks/s, output: 18.33 toks/s]
Processed prompts:  84%|████████▍ | 1727/2048 [01:34<00:18, 17.67it/s, est. speed input: 18771.71 toks/s, output: 18.33 toks/s]
Processed prompts:  85%|████████▍ | 1732/2048 [01:34<00:17, 17.68it/s, est. speed input: 18769.79 toks/s, output: 18.33 toks/s]
Processed prompts:  85%|████████▍ | 1737/2048 [01:34<00:17, 17.69it/s, est. speed input: 18767.88 toks/s, output: 18.33 toks/s]
Processed prompts:  85%|████████▌ | 1742/2048 [01:35<00:17, 17.69it/s, est. speed input: 18765.92 toks/s, output: 18.33 toks/s]
Processed prompts:  85%|████████▌ | 1747/2048 [01:35<00:17, 17.68it/s, est. speed input: 18763.92 toks/s, output: 18.32 toks/s]
Processed prompts:  86%|████████▌ | 1752/2048 [01:35<00:16, 17.68it/s, est. speed input: 18761.98 toks/s, output: 18.32 toks/s]
Processed prompts:  86%|████████▌ | 1757/2048 [01:35<00:16, 17.68it/s, est. speed input: 18760.01 toks/s, output: 18.32 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:36<00:16, 17.67it/s, est. speed input: 18758.02 toks/s, output: 18.32 toks/s]
Processed prompts:  86%|████████▋ | 1767/2048 [01:36<00:15, 17.67it/s, est. speed input: 18756.02 toks/s, output: 18.32 toks/s]
Processed prompts:  87%|████████▋ | 1772/2048 [01:36<00:15, 17.67it/s, est. speed input: 18754.13 toks/s, output: 18.31 toks/s]
Processed prompts:  87%|████████▋ | 1777/2048 [01:37<00:15, 17.68it/s, est. speed input: 18752.25 toks/s, output: 18.31 toks/s]
Processed prompts:  87%|████████▋ | 1782/2048 [01:37<00:15, 17.67it/s, est. speed input: 18750.25 toks/s, output: 18.31 toks/s]
Processed prompts:  87%|████████▋ | 1787/2048 [01:37<00:14, 17.67it/s, est. speed input: 18748.33 toks/s, output: 18.31 toks/s]
Processed prompts:  88%|████████▊ | 1792/2048 [01:37<00:14, 17.67it/s, est. speed input: 18746.45 toks/s, output: 18.31 toks/s]
Processed prompts:  88%|████████▊ | 1797/2048 [01:38<00:14, 17.67it/s, est. speed input: 18744.57 toks/s, output: 18.31 toks/s]
Processed prompts:  88%|████████▊ | 1802/2048 [01:38<00:13, 17.68it/s, est. speed input: 18742.79 toks/s, output: 18.30 toks/s]
Processed prompts:  88%|████████▊ | 1807/2048 [01:38<00:13, 17.68it/s, est. speed input: 18740.94 toks/s, output: 18.30 toks/s]
Processed prompts:  88%|████████▊ | 1812/2048 [01:39<00:13, 17.68it/s, est. speed input: 18739.13 toks/s, output: 18.30 toks/s]
Processed prompts:  89%|████████▊ | 1817/2048 [01:39<00:13, 17.67it/s, est. speed input: 18737.22 toks/s, output: 18.30 toks/s]
Processed prompts:  89%|████████▉ | 1822/2048 [01:39<00:12, 17.67it/s, est. speed input: 18735.41 toks/s, output: 18.30 toks/s]
Processed prompts:  89%|████████▉ | 1827/2048 [01:39<00:12, 17.66it/s, est. speed input: 18733.52 toks/s, output: 18.29 toks/s]
Processed prompts:  89%|████████▉ | 1832/2048 [01:40<00:12, 17.67it/s, est. speed input: 18731.71 toks/s, output: 18.29 toks/s]
Processed prompts:  90%|████████▉ | 1837/2048 [01:40<00:11, 17.66it/s, est. speed input: 18729.88 toks/s, output: 18.29 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:40<00:11, 17.66it/s, est. speed input: 18728.09 toks/s, output: 18.29 toks/s]
Processed prompts:  90%|█████████ | 1847/2048 [01:40<00:11, 17.67it/s, est. speed input: 18726.31 toks/s, output: 18.29 toks/s]
Processed prompts:  90%|█████████ | 1852/2048 [01:41<00:11, 17.67it/s, est. speed input: 18724.55 toks/s, output: 18.29 toks/s]
Processed prompts:  91%|█████████ | 1857/2048 [01:41<00:10, 17.67it/s, est. speed input: 18722.81 toks/s, output: 18.28 toks/s]
Processed prompts:  91%|█████████ | 1862/2048 [01:41<00:10, 17.66it/s, est. speed input: 18721.01 toks/s, output: 18.28 toks/s]
Processed prompts:  91%|█████████ | 1867/2048 [01:42<00:10, 17.67it/s, est. speed input: 18719.26 toks/s, output: 18.28 toks/s]
Processed prompts:  91%|█████████▏| 1872/2048 [01:42<00:09, 17.66it/s, est. speed input: 18717.48 toks/s, output: 18.28 toks/s]
Processed prompts:  92%|█████████▏| 1877/2048 [01:42<00:09, 17.67it/s, est. speed input: 18715.81 toks/s, output: 18.28 toks/s]
Processed prompts:  92%|█████████▏| 1882/2048 [01:42<00:09, 17.67it/s, est. speed input: 18714.12 toks/s, output: 18.28 toks/s]
Processed prompts:  92%|█████████▏| 1887/2048 [01:43<00:09, 17.67it/s, est. speed input: 18712.39 toks/s, output: 18.27 toks/s]
Processed prompts:  92%|█████████▏| 1892/2048 [01:43<00:08, 17.67it/s, est. speed input: 18710.71 toks/s, output: 18.27 toks/s]
Processed prompts:  93%|█████████▎| 1897/2048 [01:43<00:08, 17.68it/s, est. speed input: 18709.08 toks/s, output: 18.27 toks/s]
Processed prompts:  93%|█████████▎| 1902/2048 [01:44<00:08, 17.68it/s, est. speed input: 18707.51 toks/s, output: 18.27 toks/s]
Processed prompts:  93%|█████████▎| 1907/2048 [01:44<00:07, 17.68it/s, est. speed input: 18705.84 toks/s, output: 18.27 toks/s]
Processed prompts:  93%|█████████▎| 1912/2048 [01:44<00:07, 17.67it/s, est. speed input: 18704.16 toks/s, output: 18.27 toks/s]
Processed prompts:  94%|█████████▎| 1917/2048 [01:44<00:07, 17.67it/s, est. speed input: 18702.48 toks/s, output: 18.26 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:45<00:07, 17.66it/s, est. speed input: 18700.74 toks/s, output: 18.26 toks/s]
Processed prompts:  94%|█████████▍| 1927/2048 [01:45<00:06, 17.66it/s, est. speed input: 18699.12 toks/s, output: 18.26 toks/s]
Processed prompts:  94%|█████████▍| 1932/2048 [01:45<00:06, 17.67it/s, est. speed input: 18697.59 toks/s, output: 18.26 toks/s]
Processed prompts:  95%|█████████▍| 1937/2048 [01:46<00:06, 17.67it/s, est. speed input: 18695.98 toks/s, output: 18.26 toks/s]
Processed prompts:  95%|█████████▍| 1942/2048 [01:46<00:06, 17.66it/s, est. speed input: 18694.30 toks/s, output: 18.26 toks/s]
Processed prompts:  95%|█████████▌| 1947/2048 [01:46<00:05, 17.67it/s, est. speed input: 18692.73 toks/s, output: 18.25 toks/s]
Processed prompts:  95%|█████████▌| 1952/2048 [01:46<00:05, 17.67it/s, est. speed input: 18691.16 toks/s, output: 18.25 toks/s]
Processed prompts:  96%|█████████▌| 1957/2048 [01:47<00:05, 17.66it/s, est. speed input: 18689.51 toks/s, output: 18.25 toks/s]
Processed prompts:  96%|█████████▌| 1962/2048 [01:47<00:04, 17.66it/s, est. speed input: 18687.93 toks/s, output: 18.25 toks/s]
Processed prompts:  96%|█████████▌| 1967/2048 [01:47<00:04, 17.66it/s, est. speed input: 18686.34 toks/s, output: 18.25 toks/s]
Processed prompts:  96%|█████████▋| 1972/2048 [01:48<00:04, 17.67it/s, est. speed input: 18684.81 toks/s, output: 18.25 toks/s]
Processed prompts:  97%|█████████▋| 1977/2048 [01:48<00:04, 17.66it/s, est. speed input: 18683.18 toks/s, output: 18.25 toks/s]
Processed prompts:  97%|█████████▋| 1982/2048 [01:48<00:03, 17.67it/s, est. speed input: 18681.69 toks/s, output: 18.24 toks/s]
Processed prompts:  97%|█████████▋| 1987/2048 [01:48<00:03, 17.66it/s, est. speed input: 18680.13 toks/s, output: 18.24 toks/s]
Processed prompts:  97%|█████████▋| 1992/2048 [01:49<00:03, 17.66it/s, est. speed input: 18678.53 toks/s, output: 18.24 toks/s]
Processed prompts:  98%|█████████▊| 1997/2048 [01:49<00:02, 17.66it/s, est. speed input: 18677.03 toks/s, output: 18.24 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:49<00:02, 17.67it/s, est. speed input: 18675.57 toks/s, output: 18.24 toks/s]
Processed prompts:  98%|█████████▊| 2007/2048 [01:50<00:02, 17.67it/s, est. speed input: 18674.09 toks/s, output: 18.24 toks/s]
Processed prompts:  98%|█████████▊| 2012/2048 [01:50<00:02, 17.66it/s, est. speed input: 18672.53 toks/s, output: 18.23 toks/s]
Processed prompts:  98%|█████████▊| 2017/2048 [01:50<00:01, 17.66it/s, est. speed input: 18671.03 toks/s, output: 18.23 toks/s]
Processed prompts:  99%|█████████▊| 2022/2048 [01:50<00:01, 17.66it/s, est. speed input: 18669.55 toks/s, output: 18.23 toks/s]
Processed prompts:  99%|█████████▉| 2027/2048 [01:51<00:01, 17.66it/s, est. speed input: 18668.07 toks/s, output: 18.23 toks/s]
Processed prompts:  99%|█████████▉| 2032/2048 [01:51<00:00, 17.66it/s, est. speed input: 18666.60 toks/s, output: 18.23 toks/s]
Processed prompts:  99%|█████████▉| 2037/2048 [01:51<00:00, 17.67it/s, est. speed input: 18665.17 toks/s, output: 18.23 toks/s]
Processed prompts: 100%|█████████▉| 2042/2048 [01:52<00:00, 17.68it/s, est. speed input: 18663.82 toks/s, output: 18.23 toks/s]
Processed prompts: 100%|█████████▉| 2047/2048 [01:52<00:00, 21.55it/s, est. speed input: 18690.59 toks/s, output: 18.25 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:52<00:00, 21.55it/s, est. speed input: 18699.70 toks/s, output: 18.26 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:52<00:00, 18.26it/s, est. speed input: 18699.70 toks/s, output: 18.26 toks/s]
[rank0]:[W125 20:50:58.710607207 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 147.7s

测试结果:
  Requests/s:   17.71
  Tokens/s:     18150.98
  Total Reqs:   2048
  Elapsed:      115.65s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     18133.27

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:51:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=464431) WARNING 01-25 20:51:27 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     def forward(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     raise e
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/tmp/torchinductor_root/kd/ckdstq2kdp6ahdss75n3ubb4qomtfqyvtza4562h56rn5447pvuf.py", line 1078, in call
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) ERROR 01-25 20:51:32 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 214.94 MiB is free. Including non-PyTorch memory, this process has 15.03 GiB memory in use. Of the allocated memory 13.67 GiB is allocated by PyTorch, and 1014.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 20:51:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:51:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:51:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:51:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:51:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:51:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:51:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:51:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:51:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:51:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:51:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:51:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:51:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:51:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:51:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:51:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:51:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=464431) [2026-01-25 20:51:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=464431) [2026-01-25 20:51:22] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=464431) [2026-01-25 20:51:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=464431) [2026-01-25 20:51:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=464431) [2026-01-25 20:51:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=464431) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=464431) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.82it/s]
(EngineCore_DP0 pid=464431) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.18it/s]
(EngineCore_DP0 pid=464431) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.25it/s]
(EngineCore_DP0 pid=464431) 
(EngineCore_DP0 pid=464431) [rank0]:W0125 20:51:30.738000 464431 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=464431) [rank0]:W0125 20:51:31.017000 464431 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=464431) [rank0]:W0125 20:51:31.839000 464431 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=464431) [rank0]:W0125 20:51:31.915000 464431 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=464431) Process EngineCore_DP0:
(EngineCore_DP0 pid=464431) Traceback (most recent call last):
(EngineCore_DP0 pid=464431)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=464431)     self.run()
(EngineCore_DP0 pid=464431)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=464431)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=464431)     raise e
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=464431)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=464431)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=464431)     super().__init__(
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=464431)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=464431)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=464431)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=464431)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=464431)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=464431)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=464431)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=464431)     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=464431)     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=464431)     self.model_runner.profile_run()
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=464431)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=464431)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=464431)     return func(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=464431)     outputs = self.model(
(EngineCore_DP0 pid=464431)               ^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=464431)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=464431)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=464431)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=464431)     hidden_states = self.model(
(EngineCore_DP0 pid=464431)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=464431)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=464431)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=464431)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=464431)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=464431)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=464431)     def forward(
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=464431)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=464431)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=464431)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=464431)     raise e
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=464431)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=464431)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=464431)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=464431)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=464431)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=464431)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=464431)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=464431)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=464431)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=464431)     return compiled_fn(full_args)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=464431)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=464431)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=464431)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=464431)                             ^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=464431)     outs = compiled_fn(args)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=464431)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=464431)     return self.current_callable(inputs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=464431)     out = model(new_inputs)
(EngineCore_DP0 pid=464431)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/tmp/torchinductor_root/kd/ckdstq2kdp6ahdss75n3ubb4qomtfqyvtza4562h56rn5447pvuf.py", line 1078, in call
(EngineCore_DP0 pid=464431)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=464431)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=464431)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=464431)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=464431)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=464431)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=464431)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=464431) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 214.94 MiB is free. Including non-PyTorch memory, this process has 15.03 GiB memory in use. Of the allocated memory 13.67 GiB is allocated by PyTorch, and 1014.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 20:51:32.528328768 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:52:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=465362) WARNING 01-25 20:52:16 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=465362) ERROR 01-25 20:52:21 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 3.55 GiB is free. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 10.36 GiB is allocated by PyTorch, and 982.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 20:52:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:52:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:52:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:52:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:11] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=465362) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=465362) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.79it/s]
(EngineCore_DP0 pid=465362) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=465362) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.19it/s]
(EngineCore_DP0 pid=465362) 
(EngineCore_DP0 pid=465362) [rank0]:W0125 20:52:19.639000 465362 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=465362) [2026-01-25 20:52:20] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=465362) [rank0]:W0125 20:52:21.156000 465362 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=465362) Process EngineCore_DP0:
(EngineCore_DP0 pid=465362) Traceback (most recent call last):
(EngineCore_DP0 pid=465362)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=465362)     self.run()
(EngineCore_DP0 pid=465362)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=465362)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=465362)     raise e
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=465362)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=465362)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=465362)     super().__init__(
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=465362)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=465362)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=465362)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=465362)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=465362)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=465362)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=465362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=465362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=465362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=465362)     self.model_runner.profile_run()
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=465362)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=465362)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=465362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=465362)     outputs = self.model(
(EngineCore_DP0 pid=465362)               ^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=465362)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=465362)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=465362)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=465362)     hidden_states = self.model(
(EngineCore_DP0 pid=465362)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=465362)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=465362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=465362)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=465362)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=465362)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=465362)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=465362)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=465362)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=465362)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=465362)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=465362)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=465362)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=465362)     return self._compile_to_module()
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=465362)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=465362)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=465362)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=465362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=465362)     return self._generate(is_inference)
(EngineCore_DP0 pid=465362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=465362)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=465362)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=465362)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=465362) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 3.55 GiB is free. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 10.36 GiB is allocated by PyTorch, and 982.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 20:52:22.981795062 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,29.6024,15186.0503,4.3240
1024,1024,1,128,128,17.1416,17570.1689,7.4672
2048,1024,2,256,128,17.9217,18369.6953,14.2844
4096,1024,4,512,128,17.9578,18406.7307,28.5113
8192,1024,8,1024,128,17.6994,18141.8969,57.8550
16384,1024,16,2048,128,17.7083,18150.9809,115.6522
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 6 成功, 2 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:52:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=466033) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466033) WARNING 01-25 20:52:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.11 requests/s, 20062.26 total tokens/s, 39.11 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:52:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:52:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:52:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:52:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=466033) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=466033) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=466033) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.29s/it]
(EngineCore_DP0 pid=466033) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.24s/it]
(EngineCore_DP0 pid=466033) 
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=466033) [2026-01-25 20:52:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=466033) 2026-01-25 20:52:45,939 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=466033) 2026-01-25 20:52:45,959 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=466033) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=466033) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  67%|██████▋   | 86/128 [00:00<00:00, 851.38it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 886.10it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:52,  2.44it/s, est. speed input: 1250.32 toks/s, output: 2.44 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:08, 14.47it/s, est. speed input: 5943.91 toks/s, output: 11.61 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:04, 23.48it/s, est. speed input: 9026.07 toks/s, output: 17.63 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 30.08it/s, est. speed input: 11200.82 toks/s, output: 21.88 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 34.88it/s, est. speed input: 12822.88 toks/s, output: 25.04 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 38.37it/s, est. speed input: 14082.96 toks/s, output: 27.51 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:02, 40.86it/s, est. speed input: 15086.33 toks/s, output: 29.47 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 42.63it/s, est. speed input: 15906.12 toks/s, output: 31.07 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:01, 43.82it/s, est. speed input: 16580.75 toks/s, output: 32.38 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:01, 44.69it/s, est. speed input: 17153.48 toks/s, output: 33.50 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 45.30it/s, est. speed input: 17643.59 toks/s, output: 34.46 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 45.77it/s, est. speed input: 18070.26 toks/s, output: 35.29 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 46.07it/s, est. speed input: 18441.85 toks/s, output: 36.02 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 46.27it/s, est. speed input: 18767.98 toks/s, output: 36.66 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 46.42it/s, est. speed input: 19057.92 toks/s, output: 37.22 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 46.49it/s, est. speed input: 19314.70 toks/s, output: 37.72 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 46.53it/s, est. speed input: 19545.09 toks/s, output: 38.17 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:00, 46.58it/s, est. speed input: 19754.93 toks/s, output: 38.58 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 46.60it/s, est. speed input: 19944.08 toks/s, output: 38.95 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 46.64it/s, est. speed input: 20118.71 toks/s, output: 39.29 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 46.66it/s, est. speed input: 20277.94 toks/s, output: 39.61 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 46.68it/s, est. speed input: 20424.80 toks/s, output: 39.89 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:02<00:00, 46.63it/s, est. speed input: 20556.78 toks/s, output: 40.15 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:02<00:00, 46.68it/s, est. speed input: 20683.14 toks/s, output: 40.40 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:02<00:00, 46.67it/s, est. speed input: 20798.27 toks/s, output: 40.62 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 46.74it/s, est. speed input: 20909.63 toks/s, output: 40.84 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 46.74it/s, est. speed input: 20952.57 toks/s, output: 40.92 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 40.92it/s, est. speed input: 20952.57 toks/s, output: 40.92 toks/s]
[rank0]:[W125 20:52:51.085779592 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 28.8s

测试结果:
  Requests/s:   39.11
  Tokens/s:     20062.26
  Total Reqs:   128
  Elapsed:      3.27s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     20023.15

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:52:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=466861) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466861) WARNING 01-25 20:53:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.06 requests/s, 23639.38 total tokens/s, 23.06 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:52:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:52:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:53:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:53:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:53:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:53:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:53:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:53:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=466861) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=466861) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.98it/s]
(EngineCore_DP0 pid=466861) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.18it/s]
(EngineCore_DP0 pid=466861) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.27it/s]
(EngineCore_DP0 pid=466861) 
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=466861) [2026-01-25 20:53:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=466861) 2026-01-25 20:53:13,004 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=466861) 2026-01-25 20:53:13,019 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=466861) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 23.48it/s]
(EngineCore_DP0 pid=466861) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  39%|███▉      | 50/128 [00:00<00:00, 487.40it/s]
Adding requests:  82%|████████▏ | 105/128 [00:00<00:00, 518.59it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 511.32it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:14,  8.69it/s, est. speed input: 8895.11 toks/s, output: 8.69 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:06, 18.23it/s, est. speed input: 17244.83 toks/s, output: 16.84 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:05, 21.14it/s, est. speed input: 19916.33 toks/s, output: 19.45 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 22.41it/s, est. speed input: 21190.12 toks/s, output: 20.69 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 23.20it/s, est. speed input: 21996.97 toks/s, output: 21.48 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 23.69it/s, est. speed input: 22536.65 toks/s, output: 22.01 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 23.95it/s, est. speed input: 22902.81 toks/s, output: 22.37 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:04, 24.08it/s, est. speed input: 23161.93 toks/s, output: 22.62 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 24.14it/s, est. speed input: 23352.73 toks/s, output: 22.81 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 24.25it/s, est. speed input: 23525.67 toks/s, output: 22.97 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:03, 24.33it/s, est. speed input: 23669.77 toks/s, output: 23.11 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:03, 24.41it/s, est. speed input: 23796.30 toks/s, output: 23.24 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 24.46it/s, est. speed input: 23901.68 toks/s, output: 23.34 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 24.51it/s, est. speed input: 23994.57 toks/s, output: 23.43 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 24.51it/s, est. speed input: 24068.38 toks/s, output: 23.50 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:03, 24.51it/s, est. speed input: 24132.98 toks/s, output: 23.57 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 24.53it/s, est. speed input: 24193.93 toks/s, output: 23.63 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 24.55it/s, est. speed input: 24248.27 toks/s, output: 23.68 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:02, 24.54it/s, est. speed input: 24293.82 toks/s, output: 23.72 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 24.50it/s, est. speed input: 24328.88 toks/s, output: 23.76 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 24.47it/s, est. speed input: 24360.94 toks/s, output: 23.79 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 24.51it/s, est. speed input: 24399.27 toks/s, output: 23.83 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:02<00:02, 24.53it/s, est. speed input: 24432.78 toks/s, output: 23.86 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:02<00:02, 24.53it/s, est. speed input: 24461.39 toks/s, output: 23.89 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 24.54it/s, est. speed input: 24488.43 toks/s, output: 23.91 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 24.52it/s, est. speed input: 24510.80 toks/s, output: 23.94 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 24.50it/s, est. speed input: 24530.03 toks/s, output: 23.96 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 24.52it/s, est. speed input: 24552.58 toks/s, output: 23.98 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 24.49it/s, est. speed input: 24567.85 toks/s, output: 23.99 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 24.48it/s, est. speed input: 24584.67 toks/s, output: 24.01 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:03<00:01, 24.50it/s, est. speed input: 24602.16 toks/s, output: 24.03 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:03<00:01, 24.47it/s, est. speed input: 24614.40 toks/s, output: 24.04 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 24.45it/s, est. speed input: 24625.50 toks/s, output: 24.05 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 24.45it/s, est. speed input: 24637.64 toks/s, output: 24.06 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 24.46it/s, est. speed input: 24650.31 toks/s, output: 24.07 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 24.47it/s, est. speed input: 24661.66 toks/s, output: 24.08 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 24.49it/s, est. speed input: 24674.48 toks/s, output: 24.10 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 24.49it/s, est. speed input: 24684.77 toks/s, output: 24.11 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:04<00:00, 24.51it/s, est. speed input: 24696.76 toks/s, output: 24.12 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:04<00:00, 24.53it/s, est. speed input: 24708.34 toks/s, output: 24.13 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 24.53it/s, est. speed input: 24718.70 toks/s, output: 24.14 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 24.55it/s, est. speed input: 24729.50 toks/s, output: 24.15 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 24.49it/s, est. speed input: 24734.54 toks/s, output: 24.15 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.49it/s, est. speed input: 24735.51 toks/s, output: 24.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.16it/s, est. speed input: 24735.51 toks/s, output: 24.16 toks/s]
[rank0]:[W125 20:53:19.701985099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 28.6s

测试结果:
  Requests/s:   23.06
  Tokens/s:     23639.38
  Total Reqs:   128
  Elapsed:      5.55s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     23616.32

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:53:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=467579) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467579) WARNING 01-25 20:53:35 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.02 requests/s, 25645.54 total tokens/s, 25.02 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 20:53:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:53:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:53:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:53:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:53:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:53:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=467579) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=467579) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.97it/s]
(EngineCore_DP0 pid=467579) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.17it/s]
(EngineCore_DP0 pid=467579) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.27it/s]
(EngineCore_DP0 pid=467579) 
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=467579) [2026-01-25 20:53:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=467579) 2026-01-25 20:53:42,101 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=467579) 2026-01-25 20:53:42,119 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=467579) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 13.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 12.10it/s]
(EngineCore_DP0 pid=467579) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.01it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 50/256 [00:00<00:00, 499.68it/s]
Adding requests:  42%|████▏     | 107/256 [00:00<00:00, 537.24it/s]
Adding requests:  64%|██████▍   | 164/256 [00:00<00:00, 548.54it/s]
Adding requests:  88%|████████▊ | 224/256 [00:00<00:00, 563.70it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 555.28it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:00<00:02, 117.40it/s, est. speed input: 120234.24 toks/s, output: 117.41 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:06, 37.27it/s, est. speed input: 42513.33 toks/s, output: 41.52 toks/s]   
Processed prompts:  12%|█▏        | 31/256 [00:00<00:06, 34.22it/s, est. speed input: 38867.73 toks/s, output: 37.96 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:07, 29.52it/s, est. speed input: 34928.32 toks/s, output: 34.11 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:07, 28.38it/s, est. speed input: 33706.01 toks/s, output: 32.92 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:07, 27.55it/s, est. speed input: 32795.49 toks/s, output: 32.03 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:07, 26.88it/s, est. speed input: 32061.47 toks/s, output: 31.31 toks/s]
Processed prompts:  20%|██        | 52/256 [00:01<00:07, 26.39it/s, est. speed input: 31467.33 toks/s, output: 30.73 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:01<00:07, 26.05it/s, est. speed input: 30979.96 toks/s, output: 30.25 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:07, 25.78it/s, est. speed input: 30565.06 toks/s, output: 29.85 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:07, 25.62it/s, est. speed input: 30219.64 toks/s, output: 29.51 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:07, 25.49it/s, est. speed input: 29916.88 toks/s, output: 29.22 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:07, 25.40it/s, est. speed input: 29652.91 toks/s, output: 28.96 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:02<00:07, 25.34it/s, est. speed input: 29422.85 toks/s, output: 28.73 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:02<00:06, 25.27it/s, est. speed input: 29210.34 toks/s, output: 28.53 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:02<00:06, 25.24it/s, est. speed input: 29026.58 toks/s, output: 28.35 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:06, 25.22it/s, est. speed input: 28860.39 toks/s, output: 28.18 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:06, 25.14it/s, est. speed input: 28699.48 toks/s, output: 28.03 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:03<00:06, 25.14it/s, est. speed input: 28562.30 toks/s, output: 27.89 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:03<00:06, 25.17it/s, est. speed input: 28443.37 toks/s, output: 27.78 toks/s]
Processed prompts:  41%|████      | 104/256 [00:03<00:06, 25.19it/s, est. speed input: 28333.51 toks/s, output: 27.67 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:03<00:05, 25.17it/s, est. speed input: 28228.01 toks/s, output: 27.57 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:05, 25.14it/s, est. speed input: 28127.09 toks/s, output: 27.47 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:04<00:05, 25.16it/s, est. speed input: 28041.20 toks/s, output: 27.38 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:04<00:05, 25.16it/s, est. speed input: 27958.50 toks/s, output: 27.30 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:04<00:05, 25.15it/s, est. speed input: 27880.34 toks/s, output: 27.23 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:04<00:05, 25.14it/s, est. speed input: 27807.72 toks/s, output: 27.16 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:04<00:04, 25.11it/s, est. speed input: 27736.84 toks/s, output: 27.09 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:05<00:04, 25.13it/s, est. speed input: 27675.35 toks/s, output: 27.03 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:05<00:04, 25.14it/s, est. speed input: 27616.25 toks/s, output: 26.97 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:05<00:04, 25.12it/s, est. speed input: 27558.24 toks/s, output: 26.91 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:05<00:04, 25.13it/s, est. speed input: 27506.95 toks/s, output: 26.86 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:05<00:04, 25.15it/s, est. speed input: 27459.37 toks/s, output: 26.82 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:05<00:03, 25.15it/s, est. speed input: 27412.41 toks/s, output: 26.77 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:05<00:03, 25.16it/s, est. speed input: 27369.04 toks/s, output: 26.73 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:06<00:03, 25.15it/s, est. speed input: 27326.65 toks/s, output: 26.69 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:06<00:03, 25.13it/s, est. speed input: 27284.97 toks/s, output: 26.65 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:06<00:03, 25.14it/s, est. speed input: 27247.47 toks/s, output: 26.61 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:06<00:03, 25.15it/s, est. speed input: 27212.41 toks/s, output: 26.57 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:06<00:03, 25.15it/s, est. speed input: 27178.27 toks/s, output: 26.54 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:06<00:02, 25.12it/s, est. speed input: 27143.39 toks/s, output: 26.51 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:07<00:02, 25.13it/s, est. speed input: 27112.00 toks/s, output: 26.48 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:07<00:02, 25.14it/s, est. speed input: 27082.52 toks/s, output: 26.45 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:07<00:02, 25.13it/s, est. speed input: 27053.14 toks/s, output: 26.42 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:07<00:02, 25.09it/s, est. speed input: 27022.70 toks/s, output: 26.39 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:07<00:02, 25.11it/s, est. speed input: 26996.17 toks/s, output: 26.36 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:07<00:01, 25.11it/s, est. speed input: 26970.61 toks/s, output: 26.34 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:08<00:01, 25.13it/s, est. speed input: 26946.92 toks/s, output: 26.32 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:08<00:01, 25.12it/s, est. speed input: 26923.12 toks/s, output: 26.29 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:08<00:01, 25.13it/s, est. speed input: 26900.45 toks/s, output: 26.27 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:08<00:01, 25.12it/s, est. speed input: 26878.43 toks/s, output: 26.25 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:08<00:01, 25.15it/s, est. speed input: 26859.01 toks/s, output: 26.23 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:08<00:00, 25.12it/s, est. speed input: 26837.51 toks/s, output: 26.21 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:09<00:00, 25.12it/s, est. speed input: 26817.62 toks/s, output: 26.19 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:09<00:00, 25.11it/s, est. speed input: 26797.96 toks/s, output: 26.17 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:09<00:00, 25.13it/s, est. speed input: 26780.75 toks/s, output: 26.15 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:09<00:00, 25.12it/s, est. speed input: 26762.27 toks/s, output: 26.13 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:09<00:00, 25.12it/s, est. speed input: 26745.18 toks/s, output: 26.12 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 27.11it/s, est. speed input: 26835.13 toks/s, output: 26.21 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 27.11it/s, est. speed input: 26835.13 toks/s, output: 26.21 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 26.21it/s, est. speed input: 26835.13 toks/s, output: 26.21 toks/s]
[rank0]:[W125 20:53:53.690047053 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 33.9s

测试结果:
  Requests/s:   25.02
  Tokens/s:     25645.54
  Total Reqs:   256
  Elapsed:      10.23s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     25620.52

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:54:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=468348) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468348) WARNING 01-25 20:54:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.73 requests/s, 25344.91 total tokens/s, 24.73 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 20:54:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:54:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:54:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:54:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=468348) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=468348) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.88it/s]
(EngineCore_DP0 pid=468348) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=468348) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.20it/s]
(EngineCore_DP0 pid=468348) 
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=468348) [2026-01-25 20:54:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=468348) 2026-01-25 20:54:16,668 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=468348) 2026-01-25 20:54:16,682 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=468348) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 28.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 26.08it/s]
(EngineCore_DP0 pid=468348) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 14.24it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 49/512 [00:00<00:00, 487.36it/s]
Adding requests:  20%|█▉        | 100/512 [00:00<00:00, 496.29it/s]
Adding requests:  29%|██▉       | 150/512 [00:00<00:00, 495.47it/s]
Adding requests:  39%|███▉      | 200/512 [00:00<00:00, 493.01it/s]
Adding requests:  50%|████▉     | 254/512 [00:00<00:00, 509.60it/s]
Adding requests:  61%|██████    | 310/512 [00:00<00:00, 524.93it/s]
Adding requests:  73%|███████▎  | 373/512 [00:00<00:00, 557.68it/s]
Adding requests:  85%|████████▍ | 434/512 [00:00<00:00, 571.98it/s]
Adding requests:  97%|█████████▋| 498/512 [00:00<00:00, 590.98it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 549.18it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 22/512 [00:00<00:03, 144.32it/s, est. speed input: 147803.24 toks/s, output: 144.33 toks/s]
Processed prompts:   7%|▋         | 37/512 [00:00<00:09, 51.59it/s, est. speed input: 59664.78 toks/s, output: 58.27 toks/s]   
Processed prompts:   9%|▉         | 45/512 [00:00<00:11, 39.86it/s, est. speed input: 48145.64 toks/s, output: 47.02 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:01<00:14, 31.71it/s, est. speed input: 40848.85 toks/s, output: 39.89 toks/s]
Processed prompts:  11%|█         | 55/512 [00:01<00:15, 30.25it/s, est. speed input: 39139.93 toks/s, output: 38.22 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:01<00:15, 28.99it/s, est. speed input: 37769.29 toks/s, output: 36.88 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:01<00:16, 27.96it/s, est. speed input: 36649.74 toks/s, output: 35.79 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:01<00:17, 25.49it/s, est. speed input: 35176.08 toks/s, output: 34.35 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:17, 25.32it/s, est. speed input: 34427.37 toks/s, output: 33.62 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:17, 25.18it/s, est. speed input: 33780.32 toks/s, output: 32.99 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:17, 25.09it/s, est. speed input: 33222.61 toks/s, output: 32.44 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:17, 25.00it/s, est. speed input: 32731.02 toks/s, output: 31.96 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:02<00:17, 24.97it/s, est. speed input: 32303.28 toks/s, output: 31.55 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:16, 24.92it/s, est. speed input: 31917.50 toks/s, output: 31.17 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:16, 24.90it/s, est. speed input: 31576.05 toks/s, output: 30.84 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:16, 24.89it/s, est. speed input: 31269.94 toks/s, output: 30.54 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:16, 24.89it/s, est. speed input: 30993.40 toks/s, output: 30.27 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:16, 24.90it/s, est. speed input: 30744.35 toks/s, output: 30.02 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:16, 24.89it/s, est. speed input: 30514.45 toks/s, output: 29.80 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:03<00:16, 24.84it/s, est. speed input: 30297.10 toks/s, output: 29.59 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:15, 24.86it/s, est. speed input: 30104.16 toks/s, output: 29.40 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:15, 24.86it/s, est. speed input: 29925.78 toks/s, output: 29.22 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:15, 24.87it/s, est. speed input: 29760.74 toks/s, output: 29.06 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:15, 24.85it/s, est. speed input: 29604.30 toks/s, output: 28.91 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:15, 24.85it/s, est. speed input: 29460.20 toks/s, output: 28.77 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:04<00:15, 24.83it/s, est. speed input: 29323.76 toks/s, output: 28.64 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:14, 24.83it/s, est. speed input: 29197.96 toks/s, output: 28.51 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:14, 24.85it/s, est. speed input: 29081.49 toks/s, output: 28.40 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:14, 24.85it/s, est. speed input: 28971.17 toks/s, output: 28.29 toks/s]
Processed prompts:  30%|███       | 154/512 [00:05<00:14, 24.84it/s, est. speed input: 28866.30 toks/s, output: 28.19 toks/s]
Processed prompts:  31%|███       | 158/512 [00:05<00:14, 24.85it/s, est. speed input: 28768.73 toks/s, output: 28.09 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:05<00:14, 24.85it/s, est. speed input: 28676.71 toks/s, output: 28.00 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:13, 24.83it/s, est. speed input: 28587.19 toks/s, output: 27.92 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:13, 24.84it/s, est. speed input: 28504.53 toks/s, output: 27.84 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:06<00:13, 24.84it/s, est. speed input: 28426.15 toks/s, output: 27.76 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:06<00:13, 24.84it/s, est. speed input: 28351.36 toks/s, output: 27.69 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:06<00:13, 24.85it/s, est. speed input: 28280.61 toks/s, output: 27.62 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:06<00:13, 24.86it/s, est. speed input: 28213.84 toks/s, output: 27.55 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:06<00:12, 24.86it/s, est. speed input: 28149.50 toks/s, output: 27.49 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:07<00:12, 24.84it/s, est. speed input: 28087.03 toks/s, output: 27.43 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:07<00:12, 24.84it/s, est. speed input: 28028.20 toks/s, output: 27.37 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:07<00:12, 24.85it/s, est. speed input: 27972.05 toks/s, output: 27.32 toks/s]
Processed prompts:  40%|████      | 206/512 [00:07<00:12, 24.87it/s, est. speed input: 27919.65 toks/s, output: 27.27 toks/s]
Processed prompts:  41%|████      | 210/512 [00:07<00:12, 24.86it/s, est. speed input: 27868.02 toks/s, output: 27.21 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:07<00:11, 24.86it/s, est. speed input: 27818.44 toks/s, output: 27.17 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:08<00:11, 24.84it/s, est. speed input: 27770.01 toks/s, output: 27.12 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:08<00:11, 24.84it/s, est. speed input: 27723.99 toks/s, output: 27.07 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:08<00:11, 24.84it/s, est. speed input: 27679.66 toks/s, output: 27.03 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:08<00:11, 24.83it/s, est. speed input: 27636.88 toks/s, output: 26.99 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:08<00:11, 24.83it/s, est. speed input: 27595.94 toks/s, output: 26.95 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:08<00:11, 24.83it/s, est. speed input: 27556.39 toks/s, output: 26.91 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:09<00:10, 24.84it/s, est. speed input: 27518.66 toks/s, output: 26.87 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:09<00:10, 24.82it/s, est. speed input: 27481.00 toks/s, output: 26.84 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:09<00:10, 24.82it/s, est. speed input: 27445.17 toks/s, output: 26.80 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:09<00:10, 24.83it/s, est. speed input: 27411.21 toks/s, output: 26.77 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:09<00:10, 24.85it/s, est. speed input: 27379.36 toks/s, output: 26.74 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:09<00:10, 24.83it/s, est. speed input: 27346.60 toks/s, output: 26.71 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:09<00:09, 24.85it/s, est. speed input: 27316.46 toks/s, output: 26.68 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:10<00:09, 24.83it/s, est. speed input: 27285.64 toks/s, output: 26.65 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:10<00:09, 24.82it/s, est. speed input: 27256.15 toks/s, output: 26.62 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:10<00:09, 24.84it/s, est. speed input: 27228.72 toks/s, output: 26.59 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:10<00:09, 24.82it/s, est. speed input: 27200.47 toks/s, output: 26.56 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:10<00:09, 24.82it/s, est. speed input: 27174.00 toks/s, output: 26.54 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:08, 24.82it/s, est. speed input: 27148.08 toks/s, output: 26.51 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:11<00:08, 24.83it/s, est. speed input: 27123.44 toks/s, output: 26.49 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:11<00:08, 24.81it/s, est. speed input: 27097.86 toks/s, output: 26.46 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:11<00:08, 24.81it/s, est. speed input: 27074.30 toks/s, output: 26.44 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:11<00:08, 24.82it/s, est. speed input: 27051.58 toks/s, output: 26.42 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:11<00:08, 24.81it/s, est. speed input: 27028.72 toks/s, output: 26.40 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:11<00:07, 24.81it/s, est. speed input: 27006.53 toks/s, output: 26.37 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:12<00:07, 24.82it/s, est. speed input: 26985.50 toks/s, output: 26.35 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:12<00:07, 24.81it/s, est. speed input: 26964.56 toks/s, output: 26.33 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:12<00:07, 24.82it/s, est. speed input: 26944.54 toks/s, output: 26.31 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:12<00:07, 24.82it/s, est. speed input: 26925.10 toks/s, output: 26.29 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:12<00:07, 24.81it/s, est. speed input: 26905.38 toks/s, output: 26.27 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:12<00:07, 24.79it/s, est. speed input: 26885.92 toks/s, output: 26.26 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:13<00:06, 24.81it/s, est. speed input: 26868.23 toks/s, output: 26.24 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:13<00:06, 24.82it/s, est. speed input: 26850.58 toks/s, output: 26.22 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:13<00:06, 24.82it/s, est. speed input: 26833.16 toks/s, output: 26.20 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:13<00:06, 24.81it/s, est. speed input: 26815.97 toks/s, output: 26.19 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:13<00:06, 24.84it/s, est. speed input: 26800.60 toks/s, output: 26.17 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:13<00:06, 24.82it/s, est. speed input: 26783.90 toks/s, output: 26.16 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:14<00:05, 24.83it/s, est. speed input: 26768.51 toks/s, output: 26.14 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:14<00:05, 24.82it/s, est. speed input: 26752.88 toks/s, output: 26.13 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:14<00:05, 24.81it/s, est. speed input: 26737.27 toks/s, output: 26.11 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:14<00:05, 24.80it/s, est. speed input: 26722.21 toks/s, output: 26.10 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:14<00:05, 24.80it/s, est. speed input: 26707.42 toks/s, output: 26.08 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:14<00:05, 24.79it/s, est. speed input: 26692.64 toks/s, output: 26.07 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:14<00:04, 24.78it/s, est. speed input: 26678.19 toks/s, output: 26.05 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:15<00:04, 24.80it/s, est. speed input: 26665.10 toks/s, output: 26.04 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:15<00:04, 24.82it/s, est. speed input: 26652.41 toks/s, output: 26.03 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:15<00:04, 24.81it/s, est. speed input: 26639.07 toks/s, output: 26.01 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:15<00:04, 24.82it/s, est. speed input: 26626.68 toks/s, output: 26.00 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:15<00:04, 24.81it/s, est. speed input: 26614.16 toks/s, output: 25.99 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:03, 24.80it/s, est. speed input: 26601.51 toks/s, output: 25.98 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:16<00:03, 24.82it/s, est. speed input: 26590.25 toks/s, output: 25.97 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:16<00:03, 24.82it/s, est. speed input: 26578.60 toks/s, output: 25.96 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:16<00:03, 24.83it/s, est. speed input: 26567.37 toks/s, output: 25.94 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:16<00:03, 24.82it/s, est. speed input: 26555.93 toks/s, output: 25.93 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:16<00:03, 24.79it/s, est. speed input: 26544.08 toks/s, output: 25.92 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:02, 24.78it/s, est. speed input: 26532.49 toks/s, output: 25.91 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:17<00:02, 24.78it/s, est. speed input: 26521.57 toks/s, output: 25.90 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:17<00:02, 24.78it/s, est. speed input: 26510.81 toks/s, output: 25.89 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:17<00:02, 24.79it/s, est. speed input: 26500.69 toks/s, output: 25.88 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:17<00:02, 24.78it/s, est. speed input: 26490.16 toks/s, output: 25.87 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:17<00:02, 24.78it/s, est. speed input: 26479.93 toks/s, output: 25.86 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:17<00:02, 24.76it/s, est. speed input: 26469.21 toks/s, output: 25.85 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:18<00:01, 24.77it/s, est. speed input: 26459.69 toks/s, output: 25.84 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:18<00:01, 24.78it/s, est. speed input: 26450.21 toks/s, output: 25.83 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:18<00:01, 24.79it/s, est. speed input: 26441.02 toks/s, output: 25.82 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:18<00:01, 24.77it/s, est. speed input: 26431.38 toks/s, output: 25.81 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:18<00:01, 24.78it/s, est. speed input: 26422.44 toks/s, output: 25.80 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:18<00:01, 24.76it/s, est. speed input: 26412.90 toks/s, output: 25.79 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:19<00:00, 24.76it/s, est. speed input: 26403.93 toks/s, output: 25.79 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:19<00:00, 24.79it/s, est. speed input: 26395.79 toks/s, output: 25.78 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:19<00:00, 24.79it/s, est. speed input: 26387.33 toks/s, output: 25.77 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:19<00:00, 24.77it/s, est. speed input: 26378.63 toks/s, output: 25.76 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:19<00:00, 24.79it/s, est. speed input: 26370.80 toks/s, output: 25.75 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:19<00:00, 26.62it/s, est. speed input: 26412.03 toks/s, output: 25.79 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 26.62it/s, est. speed input: 26515.52 toks/s, output: 25.89 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 25.89it/s, est. speed input: 26515.52 toks/s, output: 25.89 toks/s]
[rank0]:[W125 20:54:38.663892825 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 44.9s

测试结果:
  Requests/s:   24.73
  Tokens/s:     25344.91
  Total Reqs:   512
  Elapsed:      20.71s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     25320.18

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:54:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=469265) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=469265) WARNING 01-25 20:54:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.44 requests/s, 25055.39 total tokens/s, 24.44 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 20:54:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:54:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:54:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:54:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=469265) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=469265) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.85it/s]
(EngineCore_DP0 pid=469265) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=469265) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.19it/s]
(EngineCore_DP0 pid=469265) 
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=469265) [2026-01-25 20:54:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=469265) 2026-01-25 20:55:03,542 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=469265) 2026-01-25 20:55:03,556 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=469265) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 13.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 11.28it/s]
(EngineCore_DP0 pid=469265) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 17.90it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 51/1024 [00:00<00:01, 505.51it/s]
Adding requests:  11%|█         | 109/1024 [00:00<00:01, 544.83it/s]
Adding requests:  16%|█▋        | 167/1024 [00:00<00:01, 560.11it/s]
Adding requests:  22%|██▏       | 229/1024 [00:00<00:01, 583.34it/s]
Adding requests:  28%|██▊       | 288/1024 [00:00<00:01, 580.80it/s]
Adding requests:  34%|███▍      | 350/1024 [00:00<00:01, 592.96it/s]
Adding requests:  40%|████      | 410/1024 [00:00<00:01, 590.95it/s]
Adding requests:  46%|████▌     | 470/1024 [00:00<00:00, 593.31it/s]
Adding requests:  52%|█████▏    | 535/1024 [00:00<00:00, 607.51it/s]
Adding requests:  58%|█████▊    | 596/1024 [00:01<00:00, 596.04it/s]
Adding requests:  64%|██████▍   | 656/1024 [00:01<00:00, 589.12it/s]
Adding requests:  70%|██████▉   | 716/1024 [00:01<00:00, 592.33it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:01<00:00, 576.52it/s]
Adding requests:  82%|████████▏ | 836/1024 [00:01<00:00, 581.86it/s]
Adding requests:  88%|████████▊ | 898/1024 [00:01<00:00, 589.95it/s]
Adding requests:  94%|█████████▎| 958/1024 [00:01<00:00, 581.68it/s]
Adding requests:  99%|█████████▉| 1018/1024 [00:01<00:00, 583.92it/s]
Adding requests: 100%|██████████| 1024/1024 [00:01<00:00, 584.07it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 42/1024 [00:00<00:06, 145.93it/s, est. speed input: 149445.61 toks/s, output: 145.94 toks/s]
Processed prompts:   6%|▌         | 57/1024 [00:00<00:11, 84.18it/s, est. speed input: 95099.54 toks/s, output: 92.87 toks/s]   
Processed prompts:   6%|▋         | 66/1024 [00:01<00:24, 39.24it/s, est. speed input: 53380.35 toks/s, output: 52.13 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:01<00:27, 34.63it/s, est. speed input: 47591.86 toks/s, output: 46.48 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:01<00:29, 31.49it/s, est. speed input: 43759.87 toks/s, output: 42.73 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:02<00:31, 29.35it/s, est. speed input: 41047.31 toks/s, output: 40.08 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:02<00:33, 27.89it/s, est. speed input: 39026.89 toks/s, output: 38.11 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:02<00:34, 26.86it/s, est. speed input: 37454.93 toks/s, output: 36.58 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:03<00:34, 26.15it/s, est. speed input: 36206.82 toks/s, output: 35.36 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:03<00:35, 25.66it/s, est. speed input: 35185.74 toks/s, output: 34.36 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:35, 25.31it/s, est. speed input: 34334.16 toks/s, output: 33.53 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:04<00:35, 25.07it/s, est. speed input: 33616.70 toks/s, output: 32.83 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:04<00:35, 24.89it/s, est. speed input: 33001.12 toks/s, output: 32.23 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:35, 24.77it/s, est. speed input: 32466.94 toks/s, output: 31.71 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:05<00:34, 24.68it/s, est. speed input: 32000.33 toks/s, output: 31.25 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:05<00:34, 24.63it/s, est. speed input: 31592.44 toks/s, output: 30.85 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:34, 24.59it/s, est. speed input: 31227.93 toks/s, output: 30.50 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:06<00:34, 24.57it/s, est. speed input: 30903.20 toks/s, output: 30.18 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:06<00:33, 24.55it/s, est. speed input: 30611.07 toks/s, output: 29.89 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:33, 24.53it/s, est. speed input: 30346.47 toks/s, output: 29.64 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:07<00:33, 24.53it/s, est. speed input: 30106.91 toks/s, output: 29.40 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:32, 24.52it/s, est. speed input: 29887.64 toks/s, output: 29.19 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:32, 24.51it/s, est. speed input: 29685.88 toks/s, output: 28.99 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:08<00:32, 24.51it/s, est. speed input: 29500.92 toks/s, output: 28.81 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:31, 24.50it/s, est. speed input: 29329.52 toks/s, output: 28.64 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:08<00:31, 24.49it/s, est. speed input: 29170.95 toks/s, output: 28.49 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:09<00:31, 24.50it/s, est. speed input: 29024.46 toks/s, output: 28.34 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:30, 24.49it/s, est. speed input: 28887.53 toks/s, output: 28.21 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:09<00:30, 24.48it/s, est. speed input: 28758.91 toks/s, output: 28.08 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:10<00:30, 24.48it/s, est. speed input: 28639.15 toks/s, output: 27.97 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:10<00:29, 24.48it/s, est. speed input: 28526.73 toks/s, output: 27.86 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:10<00:29, 24.48it/s, est. speed input: 28421.98 toks/s, output: 27.76 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:29, 24.47it/s, est. speed input: 28321.23 toks/s, output: 27.66 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:11<00:29, 24.47it/s, est. speed input: 28227.69 toks/s, output: 27.57 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:11<00:28, 24.47it/s, est. speed input: 28139.33 toks/s, output: 27.48 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:28, 24.47it/s, est. speed input: 28055.32 toks/s, output: 27.40 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:12<00:28, 24.47it/s, est. speed input: 27975.92 toks/s, output: 27.32 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:12<00:27, 24.47it/s, est. speed input: 27901.07 toks/s, output: 27.25 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:13<00:27, 24.46it/s, est. speed input: 27829.16 toks/s, output: 27.18 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:13<00:27, 24.47it/s, est. speed input: 27761.81 toks/s, output: 27.11 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:13<00:26, 24.48it/s, est. speed input: 27697.53 toks/s, output: 27.05 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:14<00:26, 24.47it/s, est. speed input: 27635.16 toks/s, output: 26.99 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:14<00:26, 24.46it/s, est. speed input: 27576.14 toks/s, output: 26.93 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:14<00:25, 24.46it/s, est. speed input: 27519.64 toks/s, output: 26.87 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:14<00:25, 24.45it/s, est. speed input: 27464.80 toks/s, output: 26.82 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:15<00:25, 24.46it/s, est. speed input: 27413.66 toks/s, output: 26.77 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:15<00:24, 24.46it/s, est. speed input: 27364.39 toks/s, output: 26.72 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:15<00:24, 24.46it/s, est. speed input: 27316.63 toks/s, output: 26.68 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:16<00:24, 24.46it/s, est. speed input: 27271.07 toks/s, output: 26.63 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:16<00:23, 24.45it/s, est. speed input: 27226.55 toks/s, output: 26.59 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:16<00:23, 24.45it/s, est. speed input: 27184.30 toks/s, output: 26.55 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:17<00:23, 24.45it/s, est. speed input: 27143.53 toks/s, output: 26.51 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:17<00:22, 24.44it/s, est. speed input: 27104.06 toks/s, output: 26.47 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:17<00:22, 24.44it/s, est. speed input: 27066.26 toks/s, output: 26.43 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:18<00:22, 24.45it/s, est. speed input: 27029.95 toks/s, output: 26.40 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:18<00:21, 24.45it/s, est. speed input: 26995.02 toks/s, output: 26.36 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:18<00:21, 24.45it/s, est. speed input: 26961.07 toks/s, output: 26.33 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:19<00:21, 24.44it/s, est. speed input: 26928.02 toks/s, output: 26.30 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:19<00:20, 24.45it/s, est. speed input: 26896.46 toks/s, output: 26.27 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:19<00:20, 24.45it/s, est. speed input: 26866.17 toks/s, output: 26.24 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:20<00:20, 24.45it/s, est. speed input: 26836.74 toks/s, output: 26.21 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:20<00:19, 24.45it/s, est. speed input: 26807.94 toks/s, output: 26.18 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:20<00:19, 24.44it/s, est. speed input: 26779.53 toks/s, output: 26.15 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:21<00:19, 24.44it/s, est. speed input: 26752.51 toks/s, output: 26.13 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:21<00:18, 24.44it/s, est. speed input: 26726.41 toks/s, output: 26.10 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:21<00:18, 24.44it/s, est. speed input: 26700.59 toks/s, output: 26.07 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:22<00:18, 24.44it/s, est. speed input: 26675.86 toks/s, output: 26.05 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:22<00:17, 24.44it/s, est. speed input: 26652.18 toks/s, output: 26.03 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:22<00:17, 24.44it/s, est. speed input: 26628.72 toks/s, output: 26.00 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:23<00:17, 24.44it/s, est. speed input: 26606.12 toks/s, output: 25.98 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:23<00:16, 24.43it/s, est. speed input: 26583.67 toks/s, output: 25.96 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:23<00:16, 24.43it/s, est. speed input: 26561.87 toks/s, output: 25.94 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:24<00:16, 24.43it/s, est. speed input: 26540.88 toks/s, output: 25.92 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:24<00:15, 24.43it/s, est. speed input: 26520.65 toks/s, output: 25.90 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:24<00:15, 24.43it/s, est. speed input: 26500.62 toks/s, output: 25.88 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:25<00:15, 24.43it/s, est. speed input: 26481.46 toks/s, output: 25.86 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:25<00:14, 24.42it/s, est. speed input: 26462.07 toks/s, output: 25.84 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:25<00:14, 24.42it/s, est. speed input: 26443.48 toks/s, output: 25.82 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:26<00:14, 24.43it/s, est. speed input: 26425.88 toks/s, output: 25.81 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:26<00:14, 24.43it/s, est. speed input: 26408.33 toks/s, output: 25.79 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:26<00:13, 24.42it/s, est. speed input: 26391.00 toks/s, output: 25.77 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:27<00:13, 24.41it/s, est. speed input: 26373.99 toks/s, output: 25.76 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:27<00:13, 24.42it/s, est. speed input: 26357.67 toks/s, output: 25.74 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:27<00:12, 24.42it/s, est. speed input: 26341.74 toks/s, output: 25.72 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:28<00:12, 24.41it/s, est. speed input: 26325.91 toks/s, output: 25.71 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:28<00:12, 24.42it/s, est. speed input: 26310.94 toks/s, output: 25.69 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:28<00:11, 24.43it/s, est. speed input: 26296.44 toks/s, output: 25.68 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:29<00:11, 24.42it/s, est. speed input: 26281.66 toks/s, output: 25.67 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:29<00:11, 24.42it/s, est. speed input: 26267.47 toks/s, output: 25.65 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:29<00:10, 24.42it/s, est. speed input: 26253.33 toks/s, output: 25.64 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:30<00:10, 24.41it/s, est. speed input: 26239.42 toks/s, output: 25.62 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:30<00:10, 24.41it/s, est. speed input: 26226.02 toks/s, output: 25.61 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:30<00:09, 25.24it/s, est. speed input: 26243.57 toks/s, output: 25.63 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:30<00:09, 24.98it/s, est. speed input: 26230.08 toks/s, output: 25.62 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:31<00:08, 24.80it/s, est. speed input: 26217.17 toks/s, output: 25.60 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:31<00:08, 24.69it/s, est. speed input: 26204.56 toks/s, output: 25.59 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:31<00:08, 24.60it/s, est. speed input: 26192.15 toks/s, output: 25.58 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:32<00:08, 24.54it/s, est. speed input: 26179.93 toks/s, output: 25.57 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:32<00:07, 24.50it/s, est. speed input: 26167.99 toks/s, output: 25.55 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:32<00:07, 24.47it/s, est. speed input: 26156.17 toks/s, output: 25.54 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:33<00:07, 24.45it/s, est. speed input: 26144.79 toks/s, output: 25.53 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:33<00:06, 24.44it/s, est. speed input: 26133.46 toks/s, output: 25.52 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:33<00:06, 24.42it/s, est. speed input: 26122.35 toks/s, output: 25.51 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:34<00:06, 24.41it/s, est. speed input: 26111.36 toks/s, output: 25.50 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:34<00:05, 24.41it/s, est. speed input: 26100.86 toks/s, output: 25.49 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:34<00:05, 24.42it/s, est. speed input: 26090.58 toks/s, output: 25.48 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:35<00:05, 24.41it/s, est. speed input: 26080.40 toks/s, output: 25.47 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:35<00:04, 24.41it/s, est. speed input: 26070.27 toks/s, output: 25.46 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:35<00:04, 24.40it/s, est. speed input: 26060.21 toks/s, output: 25.45 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:36<00:04, 24.41it/s, est. speed input: 26050.71 toks/s, output: 25.44 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:36<00:03, 24.41it/s, est. speed input: 26041.31 toks/s, output: 25.43 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:36<00:03, 24.40it/s, est. speed input: 26031.86 toks/s, output: 25.42 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:37<00:03, 24.41it/s, est. speed input: 26022.93 toks/s, output: 25.41 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:37<00:02, 24.41it/s, est. speed input: 26013.93 toks/s, output: 25.40 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:37<00:02, 24.41it/s, est. speed input: 26005.05 toks/s, output: 25.40 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:38<00:02, 24.40it/s, est. speed input: 25996.24 toks/s, output: 25.39 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:38<00:01, 24.40it/s, est. speed input: 25987.51 toks/s, output: 25.38 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:38<00:01, 24.40it/s, est. speed input: 25978.95 toks/s, output: 25.37 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:39<00:01, 24.40it/s, est. speed input: 25970.68 toks/s, output: 25.36 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:39<00:00, 24.39it/s, est. speed input: 25962.36 toks/s, output: 25.35 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:39<00:00, 24.40it/s, est. speed input: 25954.32 toks/s, output: 25.35 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:40<00:00, 25.31it/s, est. speed input: 25971.80 toks/s, output: 25.36 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:40<00:00, 25.31it/s, est. speed input: 26124.77 toks/s, output: 25.51 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:40<00:00, 25.51it/s, est. speed input: 26124.77 toks/s, output: 25.51 toks/s]
[rank0]:[W125 20:55:47.088156972 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 68.5s

测试结果:
  Requests/s:   24.44
  Tokens/s:     25055.39
  Total Reqs:   1024
  Elapsed:      41.89s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     25030.95

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:55:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=470560) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=470560) WARNING 01-25 20:56:09 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     def forward(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     raise e
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/tmp/torchinductor_root/wo/cwoyfipdx5fhtwflvutfg4noqkqyaiucdnft2ww7yqsflkfsrwmb.py", line 1078, in call
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) ERROR 01-25 20:56:15 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 884.94 MiB is free. Including non-PyTorch memory, this process has 14.38 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 20:55:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:55:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:55:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:55:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:55:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:55:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:55:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:55:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:55:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:56:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:56:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:56:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:56:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:56:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:56:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=470560) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=470560) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.74it/s]
(EngineCore_DP0 pid=470560) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=470560) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.13it/s]
(EngineCore_DP0 pid=470560) 
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=470560) [2026-01-25 20:56:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=470560) [rank0]:W0125 20:56:12.238000 470560 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=470560) [rank0]:W0125 20:56:12.286000 470560 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=470560) [rank0]:W0125 20:56:12.853000 470560 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=470560) [rank0]:W0125 20:56:12.928000 470560 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=470560) 2026-01-25 20:56:15,514 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=470560) 2026-01-25 20:56:15,553 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=470560) Process EngineCore_DP0:
(EngineCore_DP0 pid=470560) Traceback (most recent call last):
(EngineCore_DP0 pid=470560)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=470560)     self.run()
(EngineCore_DP0 pid=470560)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=470560)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=470560)     raise e
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=470560)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=470560)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=470560)     super().__init__(
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=470560)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=470560)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=470560)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=470560)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=470560)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=470560)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=470560)     return func(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=470560)     kernel_warmup(self)
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=470560)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=470560)     runner._dummy_run(
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470560)     return func(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=470560)     outputs = self.model(
(EngineCore_DP0 pid=470560)               ^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=470560)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470560)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470560)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=470560)     hidden_states = self.model(
(EngineCore_DP0 pid=470560)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=470560)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=470560)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=470560)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=470560)     def forward(
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=470560)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=470560)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=470560)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=470560)     raise e
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=470560)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470560)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470560)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=470560)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=470560)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=470560)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=470560)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=470560)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=470560)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=470560)     return compiled_fn(full_args)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=470560)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=470560)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=470560)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=470560)                             ^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=470560)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=470560)     return self.current_callable(inputs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=470560)     out = model(new_inputs)
(EngineCore_DP0 pid=470560)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/tmp/torchinductor_root/wo/cwoyfipdx5fhtwflvutfg4noqkqyaiucdnft2ww7yqsflkfsrwmb.py", line 1078, in call
(EngineCore_DP0 pid=470560)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=470560)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=470560)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=470560)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=470560)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=470560)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=470560)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470560) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 884.94 MiB is free. Including non-PyTorch memory, this process has 14.38 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 2.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 20:56:16.883552610 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:56:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=471316) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=471316) WARNING 01-25 20:56:45 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     def forward(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     raise e
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/tmp/torchinductor_root/uh/cuhjk66tpkacyjr3tunftqid3hw564ybbxhlbtqhxdd2sqoz7wog.py", line 1078, in call
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) ERROR 01-25 20:56:49 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 600.94 MiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 9.86 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 20:56:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:56:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:56:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:56:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:56:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:56:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=471316) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=471316) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.81it/s]
(EngineCore_DP0 pid=471316) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=471316) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.18it/s]
(EngineCore_DP0 pid=471316) 
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=471316) [2026-01-25 20:56:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=471316) [rank0]:W0125 20:56:48.545000 471316 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=471316) [rank0]:W0125 20:56:48.594000 471316 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=471316) [rank0]:W0125 20:56:49.147000 471316 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=471316) [rank0]:W0125 20:56:49.223000 471316 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=471316) Process EngineCore_DP0:
(EngineCore_DP0 pid=471316) Traceback (most recent call last):
(EngineCore_DP0 pid=471316)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=471316)     self.run()
(EngineCore_DP0 pid=471316)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=471316)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=471316)     raise e
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=471316)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=471316)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=471316)     super().__init__(
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=471316)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=471316)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=471316)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=471316)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=471316)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=471316)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=471316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=471316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=471316)     self.model_runner.profile_run()
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=471316)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=471316)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=471316)     outputs = self.model(
(EngineCore_DP0 pid=471316)               ^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=471316)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=471316)     hidden_states = self.model(
(EngineCore_DP0 pid=471316)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=471316)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=471316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=471316)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=471316)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=471316)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=471316)     def forward(
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=471316)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=471316)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=471316)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=471316)     raise e
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=471316)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=471316)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=471316)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=471316)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=471316)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=471316)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=471316)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=471316)     return compiled_fn(full_args)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=471316)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=471316)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=471316)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=471316)                             ^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=471316)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=471316)     return self.current_callable(inputs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=471316)     out = model(new_inputs)
(EngineCore_DP0 pid=471316)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/tmp/torchinductor_root/uh/cuhjk66tpkacyjr3tunftqid3hw564ybbxhlbtqhxdd2sqoz7wog.py", line 1078, in call
(EngineCore_DP0 pid=471316)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=471316)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=471316)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=471316)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=471316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=471316)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=471316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471316) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 600.94 MiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 9.86 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 20:56:50.888302809 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:57:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=472238) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472238) WARNING 01-25 20:57:33 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=472238) ERROR 01-25 20:57:37 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 4.34 GiB is free. Including non-PyTorch memory, this process has 10.90 GiB memory in use. Of the allocated memory 8.86 GiB is allocated by PyTorch, and 1.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 20:57:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:57:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:57:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:57:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=472238) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=472238) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.84it/s]
(EngineCore_DP0 pid=472238) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=472238) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.19it/s]
(EngineCore_DP0 pid=472238) 
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=472238) [2026-01-25 20:57:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=472238) [rank0]:W0125 20:57:36.457000 472238 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=472238) [rank0]:W0125 20:57:37.168000 472238 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=472238) Process EngineCore_DP0:
(EngineCore_DP0 pid=472238) Traceback (most recent call last):
(EngineCore_DP0 pid=472238)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=472238)     self.run()
(EngineCore_DP0 pid=472238)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=472238)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=472238)     raise e
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=472238)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=472238)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=472238)     super().__init__(
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=472238)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=472238)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=472238)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=472238)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=472238)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=472238)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=472238)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=472238)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472238)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=472238)     self.model_runner.profile_run()
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=472238)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=472238)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472238)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=472238)     outputs = self.model(
(EngineCore_DP0 pid=472238)               ^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=472238)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472238)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472238)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=472238)     hidden_states = self.model(
(EngineCore_DP0 pid=472238)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=472238)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=472238)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=472238)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=472238)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=472238)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=472238)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=472238)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=472238)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=472238)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=472238)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=472238)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=472238)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=472238)     return self._compile_to_module()
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=472238)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=472238)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=472238)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=472238)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=472238)     return self._generate(is_inference)
(EngineCore_DP0 pid=472238)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=472238)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=472238)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=472238)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=472238) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 4.34 GiB is free. Including non-PyTorch memory, this process has 10.90 GiB memory in use. Of the allocated memory 8.86 GiB is allocated by PyTorch, and 1.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 20:57:37.682916863 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,39.1077,20062.2597,3.2730
1024,1024,1,128,128,23.0628,23639.3843,5.5501
2048,1024,2,256,128,25.0200,25645.5417,10.2318
4096,1024,4,512,128,24.7267,25344.9106,20.7063
8192,1024,8,1024,128,24.4443,25055.3939,41.8912
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 5 成功, 3 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:57:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=472785) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472785) WARNING 01-25 20:57:56 [backends.py:609] Failed to read file <frozen os>
Throughput: 36.18 requests/s, 18559.30 total tokens/s, 36.18 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:57:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:57:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:57:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:57:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=472785) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=472785) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.68s/it]
(EngineCore_DP0 pid=472785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  2.01s/it]
(EngineCore_DP0 pid=472785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.96s/it]
(EngineCore_DP0 pid=472785) 
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=472785) [2026-01-25 20:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=472785) 2026-01-25 20:58:02,427 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=472785) 2026-01-25 20:58:02,441 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=472785) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
(EngineCore_DP0 pid=472785) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  65%|██████▍   | 83/128 [00:00<00:00, 823.51it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 873.14it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:18,  7.05it/s, est. speed input: 3611.20 toks/s, output: 7.05 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 23.24it/s, est. speed input: 10460.58 toks/s, output: 20.43 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:03, 29.90it/s, est. speed input: 13278.90 toks/s, output: 25.93 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 33.38it/s, est. speed input: 14822.70 toks/s, output: 28.95 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 35.39it/s, est. speed input: 15791.20 toks/s, output: 30.84 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 36.55it/s, est. speed input: 16435.64 toks/s, output: 32.10 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 37.39it/s, est. speed input: 16924.14 toks/s, output: 33.05 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 37.92it/s, est. speed input: 17291.74 toks/s, output: 33.77 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 38.27it/s, est. speed input: 17579.12 toks/s, output: 34.33 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 38.55it/s, est. speed input: 17817.59 toks/s, output: 34.80 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 38.71it/s, est. speed input: 18010.53 toks/s, output: 35.18 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 38.83it/s, est. speed input: 18172.57 toks/s, output: 35.49 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 38.96it/s, est. speed input: 18315.81 toks/s, output: 35.77 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 38.98it/s, est. speed input: 18431.32 toks/s, output: 36.00 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 39.00it/s, est. speed input: 18533.00 toks/s, output: 36.20 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 38.99it/s, est. speed input: 18619.63 toks/s, output: 36.37 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 39.03it/s, est. speed input: 18700.78 toks/s, output: 36.52 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 39.06it/s, est. speed input: 18773.36 toks/s, output: 36.67 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:01<00:01, 39.12it/s, est. speed input: 18841.53 toks/s, output: 36.80 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 39.17it/s, est. speed input: 18903.65 toks/s, output: 36.92 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 39.18it/s, est. speed input: 18958.36 toks/s, output: 37.03 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 39.15it/s, est. speed input: 19004.99 toks/s, output: 37.12 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:00, 39.12it/s, est. speed input: 19047.26 toks/s, output: 37.20 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 39.09it/s, est. speed input: 19085.46 toks/s, output: 37.28 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 39.11it/s, est. speed input: 19123.68 toks/s, output: 37.35 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 39.07it/s, est. speed input: 19154.88 toks/s, output: 37.41 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 39.05it/s, est. speed input: 19184.86 toks/s, output: 37.47 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:02<00:00, 39.09it/s, est. speed input: 19215.61 toks/s, output: 37.53 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 39.10it/s, est. speed input: 19243.31 toks/s, output: 37.58 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 39.10it/s, est. speed input: 19268.96 toks/s, output: 37.63 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 39.13it/s, est. speed input: 19294.35 toks/s, output: 37.68 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 39.19it/s, est. speed input: 19320.38 toks/s, output: 37.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.19it/s, est. speed input: 19336.28 toks/s, output: 37.77 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.77it/s, est. speed input: 19336.28 toks/s, output: 37.77 toks/s]
[rank0]:[W125 20:58:07.463967402 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 29.3s

测试结果:
  Requests/s:   36.18
  Tokens/s:     18559.30
  Total Reqs:   128
  Elapsed:      3.54s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     18523.12

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:58:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=473510) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=473510) WARNING 01-25 20:58:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.03 requests/s, 20531.52 total tokens/s, 20.03 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:58:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:58:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:58:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:58:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:58:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:58:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:58:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:58:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:58:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:58:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:58:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:58:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=473510) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=473510) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.37it/s]
(EngineCore_DP0 pid=473510) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=473510) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.83it/s]
(EngineCore_DP0 pid=473510) 
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=473510) [2026-01-25 20:58:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=473510) 2026-01-25 20:58:29,038 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=473510) 2026-01-25 20:58:29,053 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=473510) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 25.24it/s]
(EngineCore_DP0 pid=473510) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 49/128 [00:00<00:00, 486.39it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 521.65it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 520.91it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:03, 34.15it/s, est. speed input: 34975.19 toks/s, output: 34.15 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.21it/s, est. speed input: 26994.85 toks/s, output: 26.36 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:04, 23.29it/s, est. speed input: 25210.88 toks/s, output: 24.62 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:05, 22.25it/s, est. speed input: 24233.00 toks/s, output: 23.66 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 21.63it/s, est. speed input: 23615.34 toks/s, output: 23.06 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:05, 21.25it/s, est. speed input: 23199.81 toks/s, output: 22.66 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:04, 21.02it/s, est. speed input: 22905.22 toks/s, output: 22.37 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:04, 20.89it/s, est. speed input: 22688.65 toks/s, output: 22.16 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:04, 20.75it/s, est. speed input: 22499.08 toks/s, output: 21.97 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:04, 20.69it/s, est. speed input: 22360.25 toks/s, output: 21.84 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:04, 20.66it/s, est. speed input: 22246.54 toks/s, output: 21.73 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:04, 20.61it/s, est. speed input: 22144.28 toks/s, output: 21.63 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:04, 20.57it/s, est. speed input: 22056.07 toks/s, output: 21.54 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 20.56it/s, est. speed input: 21984.74 toks/s, output: 21.47 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:03, 20.56it/s, est. speed input: 21924.14 toks/s, output: 21.41 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:03, 20.55it/s, est. speed input: 21868.59 toks/s, output: 21.36 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:03, 20.51it/s, est. speed input: 21813.31 toks/s, output: 21.30 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 20.52it/s, est. speed input: 21770.67 toks/s, output: 21.26 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:03, 20.49it/s, est. speed input: 21726.09 toks/s, output: 21.22 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:02<00:03, 20.51it/s, est. speed input: 21692.51 toks/s, output: 21.18 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 20.49it/s, est. speed input: 21656.29 toks/s, output: 21.15 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:02, 20.49it/s, est. speed input: 21627.01 toks/s, output: 21.12 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:02, 20.48it/s, est. speed input: 21597.01 toks/s, output: 21.09 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 20.50it/s, est. speed input: 21574.68 toks/s, output: 21.07 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:03<00:02, 20.51it/s, est. speed input: 21552.80 toks/s, output: 21.05 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:02, 20.51it/s, est. speed input: 21532.54 toks/s, output: 21.03 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:03<00:02, 20.50it/s, est. speed input: 21511.50 toks/s, output: 21.01 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:01, 20.51it/s, est. speed input: 21494.66 toks/s, output: 20.99 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:01, 20.51it/s, est. speed input: 21477.83 toks/s, output: 20.97 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 20.51it/s, est. speed input: 21462.26 toks/s, output: 20.96 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:04<00:01, 20.52it/s, est. speed input: 21449.08 toks/s, output: 20.95 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 20.52it/s, est. speed input: 21434.99 toks/s, output: 20.93 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:04<00:01, 20.50it/s, est. speed input: 21420.67 toks/s, output: 20.92 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 20.51it/s, est. speed input: 21409.43 toks/s, output: 20.91 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:00, 20.52it/s, est. speed input: 21398.92 toks/s, output: 20.90 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:00, 20.53it/s, est. speed input: 21389.30 toks/s, output: 20.89 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 20.51it/s, est. speed input: 21377.04 toks/s, output: 20.88 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 20.51it/s, est. speed input: 21367.46 toks/s, output: 20.87 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:05<00:00, 20.52it/s, est. speed input: 21359.35 toks/s, output: 20.86 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:05<00:00, 20.53it/s, est. speed input: 21351.29 toks/s, output: 20.85 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 20.49it/s, est. speed input: 21340.22 toks/s, output: 20.84 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 20.49it/s, est. speed input: 21334.35 toks/s, output: 20.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 20.83it/s, est. speed input: 21334.35 toks/s, output: 20.83 toks/s]
[rank0]:[W125 20:58:36.562065467 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 29.3s

测试结果:
  Requests/s:   20.03
  Tokens/s:     20531.52
  Total Reqs:   128
  Elapsed:      6.39s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     20511.49

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:58:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=474218) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474218) WARNING 01-25 20:58:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.64 requests/s, 21159.63 total tokens/s, 20.64 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 20:58:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:58:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:58:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:58:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:58:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:58:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:58:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:58:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:58:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:58:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:58:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:58:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:58:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:58:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=474218) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=474218) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=474218) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
(EngineCore_DP0 pid=474218) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
(EngineCore_DP0 pid=474218) 
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=474218) [2026-01-25 20:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=474218) 2026-01-25 20:58:58,750 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=474218) 2026-01-25 20:58:58,764 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=474218) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 23.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 23.71it/s]
(EngineCore_DP0 pid=474218) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.57it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 12.31it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 45/256 [00:00<00:00, 446.28it/s]
Adding requests:  39%|███▉      | 101/256 [00:00<00:00, 507.91it/s]
Adding requests:  62%|██████▏   | 159/256 [00:00<00:00, 540.53it/s]
Adding requests:  85%|████████▍ | 217/256 [00:00<00:00, 554.80it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 535.20it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:03, 68.78it/s, est. speed input: 70437.13 toks/s, output: 68.78 toks/s]
Processed prompts:   7%|▋         | 17/256 [00:00<00:06, 35.87it/s, est. speed input: 40113.93 toks/s, output: 39.17 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:08, 26.38it/s, est. speed input: 31211.84 toks/s, output: 30.48 toks/s]
Processed prompts:  10%|█         | 26/256 [00:00<00:09, 24.55it/s, est. speed input: 29130.34 toks/s, output: 28.45 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:01<00:09, 23.37it/s, est. speed input: 27783.06 toks/s, output: 27.13 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:01<00:09, 22.58it/s, est. speed input: 26828.79 toks/s, output: 26.20 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:01<00:09, 22.02it/s, est. speed input: 26113.93 toks/s, output: 25.50 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:01<00:09, 21.66it/s, est. speed input: 25568.22 toks/s, output: 24.97 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:01<00:09, 21.43it/s, est. speed input: 25140.96 toks/s, output: 24.55 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:02<00:09, 21.25it/s, est. speed input: 24790.28 toks/s, output: 24.21 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:09, 21.13it/s, est. speed input: 24495.67 toks/s, output: 23.92 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:09, 21.03it/s, est. speed input: 24245.98 toks/s, output: 23.68 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:02<00:09, 20.97it/s, est. speed input: 24033.33 toks/s, output: 23.47 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:09, 20.92it/s, est. speed input: 23848.44 toks/s, output: 23.29 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:03<00:08, 20.87it/s, est. speed input: 23684.22 toks/s, output: 23.13 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:03<00:08, 20.86it/s, est. speed input: 23543.58 toks/s, output: 22.99 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:08, 20.85it/s, est. speed input: 23418.12 toks/s, output: 22.87 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:08, 20.83it/s, est. speed input: 23305.07 toks/s, output: 22.76 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:03<00:08, 20.84it/s, est. speed input: 23205.81 toks/s, output: 22.66 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:07, 20.84it/s, est. speed input: 23116.24 toks/s, output: 22.57 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:07, 20.85it/s, est. speed input: 23035.90 toks/s, output: 22.50 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:04<00:07, 20.83it/s, est. speed input: 22958.72 toks/s, output: 22.42 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:07, 20.83it/s, est. speed input: 22890.38 toks/s, output: 22.35 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:04<00:07, 20.85it/s, est. speed input: 22829.62 toks/s, output: 22.29 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:04<00:07, 20.84it/s, est. speed input: 22771.69 toks/s, output: 22.24 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:06, 20.82it/s, est. speed input: 22715.03 toks/s, output: 22.18 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:05<00:06, 20.82it/s, est. speed input: 22665.09 toks/s, output: 22.13 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:05<00:06, 20.80it/s, est. speed input: 22615.94 toks/s, output: 22.09 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:05<00:06, 20.80it/s, est. speed input: 22571.05 toks/s, output: 22.04 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:05<00:06, 20.80it/s, est. speed input: 22530.02 toks/s, output: 22.00 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:06<00:05, 20.78it/s, est. speed input: 22489.32 toks/s, output: 21.96 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:06<00:05, 20.80it/s, est. speed input: 22453.78 toks/s, output: 21.93 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:06<00:05, 20.80it/s, est. speed input: 22420.12 toks/s, output: 21.89 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:06<00:05, 20.80it/s, est. speed input: 22387.68 toks/s, output: 21.86 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:06<00:05, 20.82it/s, est. speed input: 22359.19 toks/s, output: 21.84 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:07<00:04, 20.81it/s, est. speed input: 22330.06 toks/s, output: 21.81 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:07<00:04, 20.80it/s, est. speed input: 22302.03 toks/s, output: 21.78 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:07<00:04, 20.81it/s, est. speed input: 22277.45 toks/s, output: 21.76 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:07<00:04, 20.82it/s, est. speed input: 22253.65 toks/s, output: 21.73 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:07<00:04, 20.80it/s, est. speed input: 22229.44 toks/s, output: 21.71 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:08<00:03, 20.82it/s, est. speed input: 22208.83 toks/s, output: 21.69 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:08<00:03, 20.81it/s, est. speed input: 22187.31 toks/s, output: 21.67 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:08<00:03, 20.80it/s, est. speed input: 22166.31 toks/s, output: 21.65 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:08<00:03, 20.80it/s, est. speed input: 22146.50 toks/s, output: 21.63 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:08<00:03, 20.79it/s, est. speed input: 22127.06 toks/s, output: 21.61 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:08<00:02, 20.80it/s, est. speed input: 22109.96 toks/s, output: 21.59 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:09<00:02, 20.77it/s, est. speed input: 22090.62 toks/s, output: 21.57 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:09<00:02, 20.77it/s, est. speed input: 22073.54 toks/s, output: 21.56 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:09<00:02, 20.79it/s, est. speed input: 22058.90 toks/s, output: 21.54 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:09<00:02, 20.80it/s, est. speed input: 22044.43 toks/s, output: 21.53 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:09<00:02, 20.80it/s, est. speed input: 22030.18 toks/s, output: 21.51 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:10<00:01, 20.81it/s, est. speed input: 22017.22 toks/s, output: 21.50 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:10<00:01, 20.80it/s, est. speed input: 22003.38 toks/s, output: 21.49 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:10<00:01, 20.81it/s, est. speed input: 21990.81 toks/s, output: 21.48 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:10<00:01, 20.79it/s, est. speed input: 21977.73 toks/s, output: 21.46 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:10<00:01, 20.80it/s, est. speed input: 21965.97 toks/s, output: 21.45 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:11<00:00, 20.80it/s, est. speed input: 21954.58 toks/s, output: 21.44 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:11<00:00, 20.78it/s, est. speed input: 21941.83 toks/s, output: 21.43 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:11<00:00, 20.79it/s, est. speed input: 21931.27 toks/s, output: 21.42 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:11<00:00, 20.79it/s, est. speed input: 21920.95 toks/s, output: 21.41 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:11<00:00, 20.78it/s, est. speed input: 21909.95 toks/s, output: 21.40 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 20.78it/s, est. speed input: 21991.84 toks/s, output: 21.48 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 21.48it/s, est. speed input: 21991.84 toks/s, output: 21.48 toks/s]
[rank0]:[W125 20:59:12.352300699 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 35.6s

测试结果:
  Requests/s:   20.64
  Tokens/s:     21159.63
  Total Reqs:   256
  Elapsed:      12.40s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     21138.98

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:59:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=474986) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474986) WARNING 01-25 20:59:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.83 requests/s, 21354.27 total tokens/s, 20.83 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 20:59:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:59:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:59:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:59:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:59:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:59:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:59:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:59:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:59:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:59:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:59:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:59:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=474986) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=474986) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.34it/s]
(EngineCore_DP0 pid=474986) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=474986) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.81it/s]
(EngineCore_DP0 pid=474986) 
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=474986) [2026-01-25 20:59:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=474986) 2026-01-25 20:59:35,324 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=474986) 2026-01-25 20:59:35,338 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=474986) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 28.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 25.97it/s]
(EngineCore_DP0 pid=474986) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  6.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 14.03it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|█         | 52/512 [00:00<00:00, 511.28it/s]
Adding requests:  21%|██▏       | 110/512 [00:00<00:00, 547.74it/s]
Adding requests:  33%|███▎      | 169/512 [00:00<00:00, 565.85it/s]
Adding requests:  45%|████▍     | 229/512 [00:00<00:00, 576.78it/s]
Adding requests:  56%|█████▌    | 287/512 [00:00<00:00, 573.68it/s]
Adding requests:  68%|██████▊   | 348/512 [00:00<00:00, 585.50it/s]
Adding requests:  80%|███████▉  | 408/512 [00:00<00:00, 588.59it/s]
Adding requests:  92%|█████████▏| 470/512 [00:00<00:00, 595.26it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 585.25it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:05, 98.68it/s, est. speed input: 101054.88 toks/s, output: 98.68 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:00<00:10, 44.35it/s, est. speed input: 50807.16 toks/s, output: 49.62 toks/s] 
Processed prompts:   7%|▋         | 34/512 [00:00<00:16, 29.55it/s, est. speed input: 36800.41 toks/s, output: 35.94 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:01<00:17, 27.21it/s, est. speed input: 34212.47 toks/s, output: 33.41 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:01<00:18, 25.45it/s, est. speed input: 32365.82 toks/s, output: 31.61 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:01<00:19, 24.16it/s, est. speed input: 30984.75 toks/s, output: 30.26 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:01<00:19, 23.21it/s, est. speed input: 29909.91 toks/s, output: 29.21 toks/s]
Processed prompts:  11%|█         | 54/512 [00:01<00:20, 22.54it/s, est. speed input: 29058.80 toks/s, output: 28.38 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:02<00:20, 22.07it/s, est. speed input: 28363.25 toks/s, output: 27.70 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:02<00:20, 21.73it/s, est. speed input: 27784.06 toks/s, output: 27.13 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:20, 21.49it/s, est. speed input: 27293.04 toks/s, output: 26.65 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:20, 21.33it/s, est. speed input: 26873.98 toks/s, output: 26.24 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:20, 21.21it/s, est. speed input: 26511.62 toks/s, output: 25.89 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:03<00:20, 21.14it/s, est. speed input: 26195.18 toks/s, output: 25.58 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:03<00:20, 21.06it/s, est. speed input: 25909.85 toks/s, output: 25.30 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:20, 21.02it/s, est. speed input: 25661.76 toks/s, output: 25.06 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:20, 21.00it/s, est. speed input: 25440.14 toks/s, output: 24.84 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:19, 20.97it/s, est. speed input: 25237.43 toks/s, output: 24.65 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:04<00:19, 20.96it/s, est. speed input: 25056.16 toks/s, output: 24.47 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:04<00:19, 20.95it/s, est. speed input: 24890.22 toks/s, output: 24.31 toks/s]
Processed prompts:  21%|██        | 106/512 [00:04<00:19, 20.94it/s, est. speed input: 24739.02 toks/s, output: 24.16 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:04<00:19, 20.93it/s, est. speed input: 24599.50 toks/s, output: 24.02 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:19, 20.93it/s, est. speed input: 24473.13 toks/s, output: 23.90 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:18, 20.93it/s, est. speed input: 24355.56 toks/s, output: 23.78 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:05<00:18, 20.91it/s, est. speed input: 24244.82 toks/s, output: 23.68 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:05<00:18, 20.91it/s, est. speed input: 24143.65 toks/s, output: 23.58 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:05<00:18, 20.92it/s, est. speed input: 24049.95 toks/s, output: 23.49 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:18, 20.92it/s, est. speed input: 23962.31 toks/s, output: 23.40 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:17, 20.92it/s, est. speed input: 23879.80 toks/s, output: 23.32 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:06<00:17, 20.92it/s, est. speed input: 23802.82 toks/s, output: 23.24 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:06<00:17, 20.91it/s, est. speed input: 23729.69 toks/s, output: 23.17 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:06<00:17, 20.90it/s, est. speed input: 23660.35 toks/s, output: 23.11 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:17, 20.90it/s, est. speed input: 23595.89 toks/s, output: 23.04 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:16, 20.90it/s, est. speed input: 23534.84 toks/s, output: 22.98 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:07<00:16, 20.90it/s, est. speed input: 23476.85 toks/s, output: 22.93 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:07<00:16, 20.89it/s, est. speed input: 23421.11 toks/s, output: 22.87 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:07<00:16, 20.88it/s, est. speed input: 23368.33 toks/s, output: 22.82 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:16, 20.88it/s, est. speed input: 23318.62 toks/s, output: 22.77 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:15, 20.90it/s, est. speed input: 23272.72 toks/s, output: 22.73 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:08<00:15, 20.90it/s, est. speed input: 23228.02 toks/s, output: 22.68 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:08<00:15, 20.89it/s, est. speed input: 23184.67 toks/s, output: 22.64 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:08<00:15, 20.90it/s, est. speed input: 23144.71 toks/s, output: 22.60 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:15, 20.90it/s, est. speed input: 23106.11 toks/s, output: 22.56 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:15, 20.90it/s, est. speed input: 23068.80 toks/s, output: 22.53 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:14, 20.90it/s, est. speed input: 23033.50 toks/s, output: 22.49 toks/s]
Processed prompts:  40%|████      | 206/512 [00:09<00:14, 20.89it/s, est. speed input: 22998.75 toks/s, output: 22.46 toks/s]
Processed prompts:  41%|████      | 210/512 [00:09<00:14, 20.89it/s, est. speed input: 22965.72 toks/s, output: 22.43 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:09<00:14, 20.89it/s, est. speed input: 22934.25 toks/s, output: 22.40 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:14, 20.90it/s, est. speed input: 22904.91 toks/s, output: 22.37 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:13, 20.91it/s, est. speed input: 22876.16 toks/s, output: 22.34 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:10<00:13, 20.90it/s, est. speed input: 22847.77 toks/s, output: 22.31 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:10<00:13, 20.89it/s, est. speed input: 22820.74 toks/s, output: 22.29 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:10<00:13, 20.89it/s, est. speed input: 22794.26 toks/s, output: 22.26 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:13, 20.89it/s, est. speed input: 22769.32 toks/s, output: 22.24 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:12, 20.88it/s, est. speed input: 22744.73 toks/s, output: 22.21 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:11<00:12, 20.88it/s, est. speed input: 22721.29 toks/s, output: 22.19 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:11<00:12, 20.87it/s, est. speed input: 22697.83 toks/s, output: 22.17 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:11<00:12, 20.87it/s, est. speed input: 22675.76 toks/s, output: 22.14 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:12, 20.88it/s, est. speed input: 22654.71 toks/s, output: 22.12 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:11, 20.89it/s, est. speed input: 22634.99 toks/s, output: 22.10 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:12<00:11, 20.89it/s, est. speed input: 22615.18 toks/s, output: 22.09 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:12<00:11, 20.88it/s, est. speed input: 22595.13 toks/s, output: 22.07 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:12<00:11, 20.87it/s, est. speed input: 22576.24 toks/s, output: 22.05 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:12<00:11, 20.89it/s, est. speed input: 22558.76 toks/s, output: 22.03 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:11, 20.88it/s, est. speed input: 22541.12 toks/s, output: 22.01 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:13<00:10, 20.88it/s, est. speed input: 22523.66 toks/s, output: 22.00 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:13<00:10, 20.88it/s, est. speed input: 22506.96 toks/s, output: 21.98 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:13<00:10, 20.87it/s, est. speed input: 22490.48 toks/s, output: 21.96 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:13<00:10, 20.87it/s, est. speed input: 22474.57 toks/s, output: 21.95 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:10, 20.86it/s, est. speed input: 22458.64 toks/s, output: 21.93 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:13<00:09, 20.86it/s, est. speed input: 22443.76 toks/s, output: 21.92 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:14<00:09, 20.85it/s, est. speed input: 22428.42 toks/s, output: 21.90 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:14<00:09, 20.85it/s, est. speed input: 22413.92 toks/s, output: 21.89 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:14<00:09, 20.86it/s, est. speed input: 22400.31 toks/s, output: 21.88 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:09, 20.87it/s, est. speed input: 22387.46 toks/s, output: 21.86 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:14<00:08, 20.87it/s, est. speed input: 22374.45 toks/s, output: 21.85 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:15<00:08, 20.87it/s, est. speed input: 22361.77 toks/s, output: 21.84 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:15<00:08, 20.85it/s, est. speed input: 22348.54 toks/s, output: 21.82 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:15<00:08, 20.85it/s, est. speed input: 22336.16 toks/s, output: 21.81 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:15<00:08, 20.85it/s, est. speed input: 22324.06 toks/s, output: 21.80 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:15<00:07, 20.86it/s, est. speed input: 22312.66 toks/s, output: 21.79 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:16<00:07, 20.87it/s, est. speed input: 22301.57 toks/s, output: 21.78 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:16<00:07, 20.86it/s, est. speed input: 22290.18 toks/s, output: 21.77 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:16<00:07, 20.85it/s, est. speed input: 22279.10 toks/s, output: 21.76 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:16<00:07, 20.86it/s, est. speed input: 22268.54 toks/s, output: 21.75 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:16<00:06, 20.86it/s, est. speed input: 22258.37 toks/s, output: 21.74 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:17<00:06, 20.86it/s, est. speed input: 22248.16 toks/s, output: 21.73 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:17<00:06, 20.84it/s, est. speed input: 22237.74 toks/s, output: 21.72 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:17<00:06, 20.85it/s, est. speed input: 22228.05 toks/s, output: 21.71 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:17<00:06, 20.86it/s, est. speed input: 22218.75 toks/s, output: 21.70 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:17<00:06, 20.85it/s, est. speed input: 22209.39 toks/s, output: 21.69 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:17<00:05, 20.86it/s, est. speed input: 22200.49 toks/s, output: 21.68 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:18<00:05, 20.86it/s, est. speed input: 22191.69 toks/s, output: 21.67 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:18<00:05, 20.85it/s, est. speed input: 22182.67 toks/s, output: 21.66 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:18<00:05, 20.85it/s, est. speed input: 22174.20 toks/s, output: 21.65 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:18<00:05, 20.86it/s, est. speed input: 22166.10 toks/s, output: 21.65 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:18<00:04, 20.86it/s, est. speed input: 22157.80 toks/s, output: 21.64 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:19<00:04, 20.85it/s, est. speed input: 22149.67 toks/s, output: 21.63 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:19<00:04, 20.85it/s, est. speed input: 22141.52 toks/s, output: 21.62 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:19<00:04, 20.85it/s, est. speed input: 22133.81 toks/s, output: 21.62 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:19<00:04, 20.85it/s, est. speed input: 22126.33 toks/s, output: 21.61 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:19<00:03, 20.85it/s, est. speed input: 22118.62 toks/s, output: 21.60 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:20<00:03, 20.84it/s, est. speed input: 22111.07 toks/s, output: 21.59 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:20<00:03, 20.83it/s, est. speed input: 22103.44 toks/s, output: 21.59 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:20<00:03, 20.84it/s, est. speed input: 22096.40 toks/s, output: 21.58 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:20<00:03, 20.85it/s, est. speed input: 22089.66 toks/s, output: 21.57 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:20<00:02, 20.85it/s, est. speed input: 22083.06 toks/s, output: 21.57 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:21<00:02, 20.86it/s, est. speed input: 22076.55 toks/s, output: 21.56 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:21<00:02, 20.83it/s, est. speed input: 22069.35 toks/s, output: 21.55 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:21<00:02, 20.84it/s, est. speed input: 22063.05 toks/s, output: 21.55 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:21<00:02, 20.86it/s, est. speed input: 22057.19 toks/s, output: 21.54 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:21<00:02, 20.86it/s, est. speed input: 22051.03 toks/s, output: 21.53 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:22<00:01, 20.86it/s, est. speed input: 22044.97 toks/s, output: 21.53 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:22<00:01, 20.84it/s, est. speed input: 22038.61 toks/s, output: 21.52 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:22<00:01, 20.85it/s, est. speed input: 22032.96 toks/s, output: 21.52 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:22<00:01, 20.85it/s, est. speed input: 22027.01 toks/s, output: 21.51 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:22<00:01, 20.84it/s, est. speed input: 22020.95 toks/s, output: 21.50 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:22<00:00, 20.82it/s, est. speed input: 22014.88 toks/s, output: 21.50 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:23<00:00, 20.82it/s, est. speed input: 22009.04 toks/s, output: 21.49 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:23<00:00, 20.82it/s, est. speed input: 22003.45 toks/s, output: 21.49 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:23<00:00, 20.84it/s, est. speed input: 21998.25 toks/s, output: 21.48 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:23<00:00, 22.43it/s, est. speed input: 22035.18 toks/s, output: 21.52 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:23<00:00, 22.43it/s, est. speed input: 22121.52 toks/s, output: 21.60 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:23<00:00, 21.60it/s, est. speed input: 22121.52 toks/s, output: 21.60 toks/s]
[rank0]:[W125 21:00:01.242901089 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 48.8s

测试结果:
  Requests/s:   20.83
  Tokens/s:     21354.27
  Total Reqs:   512
  Elapsed:      24.58s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     21333.43

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:00:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=475979) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=475979) WARNING 01-25 21:00:20 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     def forward(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     raise e
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/tmp/torchinductor_root/si/csiatjsx2i27zyfwf3d6jrlepws7ewu7omi6myhvh4c4sb5r7dj6.py", line 958, in call
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) ERROR 01-25 21:00:26 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 410.94 MiB is free. Including non-PyTorch memory, this process has 14.84 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:00:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:00:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:00:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:00:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=475979) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=475979) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.25it/s]
(EngineCore_DP0 pid=475979) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]
(EngineCore_DP0 pid=475979) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.75it/s]
(EngineCore_DP0 pid=475979) 
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=475979) [2026-01-25 21:00:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=475979) 2026-01-25 21:00:26,344 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=475979) 2026-01-25 21:00:26,370 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=475979) Process EngineCore_DP0:
(EngineCore_DP0 pid=475979) Traceback (most recent call last):
(EngineCore_DP0 pid=475979)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=475979)     self.run()
(EngineCore_DP0 pid=475979)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=475979)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=475979)     raise e
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=475979)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=475979)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=475979)     super().__init__(
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=475979)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=475979)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=475979)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=475979)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=475979)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=475979)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=475979)     return func(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=475979)     kernel_warmup(self)
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=475979)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=475979)     runner._dummy_run(
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=475979)     return func(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=475979)     outputs = self.model(
(EngineCore_DP0 pid=475979)               ^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=475979)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=475979)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=475979)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=475979)     hidden_states = self.model(
(EngineCore_DP0 pid=475979)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=475979)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=475979)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=475979)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=475979)     def forward(
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=475979)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=475979)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=475979)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=475979)     raise e
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=475979)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=475979)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=475979)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=475979)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=475979)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=475979)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=475979)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=475979)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=475979)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=475979)     return compiled_fn(full_args)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=475979)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=475979)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=475979)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=475979)                             ^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=475979)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=475979)     return self.current_callable(inputs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=475979)     out = model(new_inputs)
(EngineCore_DP0 pid=475979)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/tmp/torchinductor_root/si/csiatjsx2i27zyfwf3d6jrlepws7ewu7omi6myhvh4c4sb5r7dj6.py", line 958, in call
(EngineCore_DP0 pid=475979)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=475979)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=475979)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=475979)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=475979)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=475979)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=475979)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=475979) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 410.94 MiB is free. Including non-PyTorch memory, this process has 14.84 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:00:26.691079467 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:00:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=476636) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=476636) WARNING 01-25 21:00:49 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     def forward(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     raise e
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/tmp/torchinductor_root/h3/ch3z4j5zv4cgls3cstbg4tginq7yjwyo6voq2a2nhcqcn3cyotn5.py", line 1078, in call
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) ERROR 01-25 21:00:55 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 454.94 MiB is free. Including non-PyTorch memory, this process has 14.79 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:00:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:00:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:00:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:00:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=476636) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=476636) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.30it/s]
(EngineCore_DP0 pid=476636) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.73it/s]
(EngineCore_DP0 pid=476636) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
(EngineCore_DP0 pid=476636) 
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=476636) [2026-01-25 21:00:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=476636) [rank0]:W0125 21:00:52.532000 476636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=476636) [rank0]:W0125 21:00:52.581000 476636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=476636) [rank0]:W0125 21:00:53.151000 476636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=476636) [rank0]:W0125 21:00:53.228000 476636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=476636) 2026-01-25 21:00:55,501 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=476636) 2026-01-25 21:00:55,546 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=476636) Process EngineCore_DP0:
(EngineCore_DP0 pid=476636) Traceback (most recent call last):
(EngineCore_DP0 pid=476636)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=476636)     self.run()
(EngineCore_DP0 pid=476636)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=476636)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=476636)     raise e
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=476636)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=476636)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=476636)     super().__init__(
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=476636)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=476636)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=476636)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=476636)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=476636)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=476636)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=476636)     return func(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=476636)     kernel_warmup(self)
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=476636)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=476636)     runner._dummy_run(
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476636)     return func(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=476636)     outputs = self.model(
(EngineCore_DP0 pid=476636)               ^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=476636)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476636)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476636)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=476636)     hidden_states = self.model(
(EngineCore_DP0 pid=476636)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=476636)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=476636)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=476636)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=476636)     def forward(
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=476636)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=476636)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=476636)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=476636)     raise e
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=476636)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476636)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476636)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=476636)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=476636)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=476636)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=476636)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=476636)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=476636)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=476636)     return compiled_fn(full_args)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=476636)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=476636)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=476636)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=476636)                             ^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=476636)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=476636)     return self.current_callable(inputs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=476636)     out = model(new_inputs)
(EngineCore_DP0 pid=476636)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/tmp/torchinductor_root/h3/ch3z4j5zv4cgls3cstbg4tginq7yjwyo6voq2a2nhcqcn3cyotn5.py", line 1078, in call
(EngineCore_DP0 pid=476636)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=476636)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=476636)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=476636)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=476636)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=476636)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=476636)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476636) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 454.94 MiB is free. Including non-PyTorch memory, this process has 14.79 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:00:56.864581286 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:01:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=477390) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=477390) WARNING 01-25 21:01:25 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=477390) ERROR 01-25 21:01:29 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 586.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.63 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:01:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:01:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:01:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:01:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:01:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:01:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:01:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:01:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:01:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:01:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:01:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:01:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=477390) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=477390) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.31it/s]
(EngineCore_DP0 pid=477390) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.73it/s]
(EngineCore_DP0 pid=477390) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
(EngineCore_DP0 pid=477390) 
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=477390) [2026-01-25 21:01:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=477390) [rank0]:W0125 21:01:28.575000 477390 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=477390) [rank0]:W0125 21:01:28.625000 477390 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=477390) [rank0]:W0125 21:01:29.174000 477390 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=477390) [rank0]:W0125 21:01:29.250000 477390 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=477390) Process EngineCore_DP0:
(EngineCore_DP0 pid=477390) Traceback (most recent call last):
(EngineCore_DP0 pid=477390)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=477390)     self.run()
(EngineCore_DP0 pid=477390)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=477390)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=477390)     raise e
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=477390)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=477390)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=477390)     super().__init__(
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=477390)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=477390)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=477390)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=477390)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=477390)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=477390)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=477390)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=477390)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477390)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=477390)     self.model_runner.profile_run()
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=477390)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=477390)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477390)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=477390)     outputs = self.model(
(EngineCore_DP0 pid=477390)               ^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=477390)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477390)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477390)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=477390)     hidden_states = self.model(
(EngineCore_DP0 pid=477390)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=477390)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=477390)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=477390)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=477390)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=477390)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=477390)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=477390)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=477390)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=477390)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=477390)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=477390)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=477390)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=477390)     return self._compile_to_module()
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=477390)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=477390)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=477390)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=477390)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=477390)     return self._generate(is_inference)
(EngineCore_DP0 pid=477390)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=477390)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=477390)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=477390)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=477390) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 586.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.63 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:01:29.583911649 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:02:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=478312) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=478312) WARNING 01-25 21:02:13 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=478312) ERROR 01-25 21:02:17 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.23 GiB is free. Including non-PyTorch memory, this process has 13.01 GiB memory in use. Of the allocated memory 10.41 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:02:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:02:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:02:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:02:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:02:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:02:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:02:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:02:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:02:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:02:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:02:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:02:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=478312) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=478312) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.30it/s]
(EngineCore_DP0 pid=478312) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
(EngineCore_DP0 pid=478312) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
(EngineCore_DP0 pid=478312) 
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=478312) [2026-01-25 21:02:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=478312) [rank0]:W0125 21:02:16.666000 478312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=478312) [rank0]:W0125 21:02:17.394000 478312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=478312) Process EngineCore_DP0:
(EngineCore_DP0 pid=478312) Traceback (most recent call last):
(EngineCore_DP0 pid=478312)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=478312)     self.run()
(EngineCore_DP0 pid=478312)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=478312)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=478312)     raise e
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=478312)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=478312)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=478312)     super().__init__(
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=478312)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=478312)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=478312)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=478312)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=478312)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=478312)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=478312)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=478312)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478312)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=478312)     self.model_runner.profile_run()
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=478312)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=478312)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478312)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=478312)     outputs = self.model(
(EngineCore_DP0 pid=478312)               ^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=478312)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478312)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478312)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=478312)     hidden_states = self.model(
(EngineCore_DP0 pid=478312)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=478312)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=478312)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=478312)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=478312)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=478312)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=478312)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=478312)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=478312)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=478312)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=478312)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=478312)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=478312)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=478312)     return self._compile_to_module()
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=478312)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=478312)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=478312)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=478312)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=478312)     return self._generate(is_inference)
(EngineCore_DP0 pid=478312)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=478312)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=478312)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=478312)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=478312) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.23 GiB is free. Including non-PyTorch memory, this process has 13.01 GiB memory in use. Of the allocated memory 10.41 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:02:18.810688447 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,36.1780,18559.2977,3.5381
1024,1024,1,128,128,20.0307,20531.5187,6.3902
2048,1024,2,256,128,20.6435,21159.6268,12.4010
4096,1024,4,512,128,20.8334,21354.2654,24.5759
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 4 成功, 4 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:02:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=478857) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=478857) WARNING 01-25 21:02:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.62 requests/s, 17244.65 total tokens/s, 33.62 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 21:02:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:02:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:02:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:02:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:02:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:02:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:02:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:02:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:02:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:02:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:02:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:02:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=478857) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=478857) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.69s/it]
(EngineCore_DP0 pid=478857) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.55s/it]
(EngineCore_DP0 pid=478857) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.27s/it]
(EngineCore_DP0 pid=478857) 
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=478857) [2026-01-25 21:02:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=478857) 2026-01-25 21:02:45,233 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=478857) 2026-01-25 21:02:45,255 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=478857) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.40it/s]
(EngineCore_DP0 pid=478857) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  72%|███████▏  | 92/128 [00:00<00:00, 915.68it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 932.95it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:19,  6.68it/s, est. speed input: 3422.53 toks/s, output: 6.68 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 21.81it/s, est. speed input: 9832.92 toks/s, output: 19.20 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 27.86it/s, est. speed input: 12414.87 toks/s, output: 24.25 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 31.00it/s, est. speed input: 13817.85 toks/s, output: 26.99 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 32.78it/s, est. speed input: 14690.52 toks/s, output: 28.69 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.86it/s, est. speed input: 15282.88 toks/s, output: 29.85 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.65it/s, est. speed input: 15731.36 toks/s, output: 30.72 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 35.11it/s, est. speed input: 16061.90 toks/s, output: 31.37 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 35.35it/s, est. speed input: 16310.42 toks/s, output: 31.86 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 35.60it/s, est. speed input: 16522.20 toks/s, output: 32.27 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 35.70it/s, est. speed input: 16688.98 toks/s, output: 32.60 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 35.69it/s, est. speed input: 16817.01 toks/s, output: 32.85 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 35.82it/s, est. speed input: 16942.55 toks/s, output: 33.09 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 35.84it/s, est. speed input: 17043.75 toks/s, output: 33.29 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 35.96it/s, est. speed input: 17140.49 toks/s, output: 33.48 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 36.02it/s, est. speed input: 17224.07 toks/s, output: 33.64 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 35.96it/s, est. speed input: 17289.31 toks/s, output: 33.77 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 36.03it/s, est. speed input: 17356.88 toks/s, output: 33.90 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 36.07it/s, est. speed input: 17416.50 toks/s, output: 34.02 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 36.08it/s, est. speed input: 17468.87 toks/s, output: 34.12 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 36.13it/s, est. speed input: 17519.65 toks/s, output: 34.22 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 36.12it/s, est. speed input: 17562.89 toks/s, output: 34.30 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 36.16it/s, est. speed input: 17605.44 toks/s, output: 34.39 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 36.15it/s, est. speed input: 17642.04 toks/s, output: 34.46 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 36.10it/s, est. speed input: 17673.20 toks/s, output: 34.52 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 36.02it/s, est. speed input: 17698.52 toks/s, output: 34.57 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 36.06it/s, est. speed input: 17728.34 toks/s, output: 34.63 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 36.08it/s, est. speed input: 17755.50 toks/s, output: 34.68 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 36.10it/s, est. speed input: 17781.08 toks/s, output: 34.73 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 36.08it/s, est. speed input: 17803.31 toks/s, output: 34.77 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 36.05it/s, est. speed input: 17822.87 toks/s, output: 34.81 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 36.08it/s, est. speed input: 17843.84 toks/s, output: 34.85 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.08it/s, est. speed input: 17858.20 toks/s, output: 34.88 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.88it/s, est. speed input: 17858.20 toks/s, output: 34.88 toks/s]
[rank0]:[W125 21:02:50.504225541 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 32.3s

测试结果:
  Requests/s:   33.62
  Tokens/s:     17244.65
  Total Reqs:   128
  Elapsed:      3.81s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     17211.04

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:02:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=479634) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=479634) WARNING 01-25 21:03:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.68 requests/s, 19146.57 total tokens/s, 18.68 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 21:02:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:02:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:02:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:02:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:02:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:02:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:02:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:02:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:03:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:03:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:03:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:03:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:03:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:03:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=479634) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=479634) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.27s/it]
(EngineCore_DP0 pid=479634) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.08s/it]
(EngineCore_DP0 pid=479634) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.10s/it]
(EngineCore_DP0 pid=479634) 
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=479634) [2026-01-25 21:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=479634) 2026-01-25 21:03:13,836 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=479634) 2026-01-25 21:03:13,850 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=479634) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 25.69it/s]
(EngineCore_DP0 pid=479634) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 437.54it/s]
Adding requests:  77%|███████▋  | 98/128 [00:00<00:00, 495.08it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 499.17it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:03, 33.97it/s, est. speed input: 34787.41 toks/s, output: 33.97 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:05, 23.32it/s, est. speed input: 25061.28 toks/s, output: 24.47 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 21.49it/s, est. speed input: 23279.68 toks/s, output: 22.73 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 20.61it/s, est. speed input: 22394.59 toks/s, output: 21.87 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:05, 20.12it/s, est. speed input: 21864.17 toks/s, output: 21.35 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:05, 19.82it/s, est. speed input: 21504.09 toks/s, output: 21.00 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 19.60it/s, est. speed input: 21234.10 toks/s, output: 20.74 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 19.49it/s, est. speed input: 21096.07 toks/s, output: 20.60 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 19.43it/s, est. speed input: 20985.23 toks/s, output: 20.49 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 19.36it/s, est. speed input: 20885.93 toks/s, output: 20.40 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 19.30it/s, est. speed input: 20797.83 toks/s, output: 20.31 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:04, 19.28it/s, est. speed input: 20726.37 toks/s, output: 20.24 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:04, 19.25it/s, est. speed input: 20662.03 toks/s, output: 20.18 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:04, 19.24it/s, est. speed input: 20604.99 toks/s, output: 20.12 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:04, 19.23it/s, est. speed input: 20554.53 toks/s, output: 20.07 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:04, 19.19it/s, est. speed input: 20504.27 toks/s, output: 20.02 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 19.19it/s, est. speed input: 20462.81 toks/s, output: 19.98 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 19.14it/s, est. speed input: 20417.56 toks/s, output: 19.94 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 19.16it/s, est. speed input: 20384.55 toks/s, output: 19.91 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 19.13it/s, est. speed input: 20347.73 toks/s, output: 19.87 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 19.14it/s, est. speed input: 20317.63 toks/s, output: 19.84 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 19.12it/s, est. speed input: 20286.58 toks/s, output: 19.81 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 19.14it/s, est. speed input: 20262.90 toks/s, output: 19.79 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 19.15it/s, est. speed input: 20240.25 toks/s, output: 19.77 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:03, 19.18it/s, est. speed input: 20221.29 toks/s, output: 19.75 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 19.18it/s, est. speed input: 20202.36 toks/s, output: 19.73 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 19.13it/s, est. speed input: 20177.98 toks/s, output: 19.70 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 19.12it/s, est. speed input: 20158.60 toks/s, output: 19.69 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 19.15it/s, est. speed input: 20143.90 toks/s, output: 19.67 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:03, 19.14it/s, est. speed input: 20127.42 toks/s, output: 19.66 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:02, 19.16it/s, est. speed input: 20113.58 toks/s, output: 19.64 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 19.17it/s, est. speed input: 20100.61 toks/s, output: 19.63 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 19.16it/s, est. speed input: 20086.78 toks/s, output: 19.62 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 19.15it/s, est. speed input: 20073.84 toks/s, output: 19.60 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 19.15it/s, est. speed input: 20061.73 toks/s, output: 19.59 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 19.15it/s, est. speed input: 20050.70 toks/s, output: 19.58 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 19.14it/s, est. speed input: 20038.51 toks/s, output: 19.57 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 19.14it/s, est. speed input: 20027.74 toks/s, output: 19.56 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 19.15it/s, est. speed input: 20019.07 toks/s, output: 19.55 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:02, 19.11it/s, est. speed input: 20006.14 toks/s, output: 19.54 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 19.14it/s, est. speed input: 19998.47 toks/s, output: 19.53 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 19.15it/s, est. speed input: 19990.81 toks/s, output: 19.52 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:01, 19.15it/s, est. speed input: 19982.74 toks/s, output: 19.51 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 19.17it/s, est. speed input: 19975.93 toks/s, output: 19.51 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 19.16it/s, est. speed input: 19968.25 toks/s, output: 19.50 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 19.16it/s, est. speed input: 19961.14 toks/s, output: 19.49 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 19.15it/s, est. speed input: 19953.76 toks/s, output: 19.49 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 19.16it/s, est. speed input: 19947.50 toks/s, output: 19.48 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 19.14it/s, est. speed input: 19940.45 toks/s, output: 19.47 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:00, 19.15it/s, est. speed input: 19934.85 toks/s, output: 19.47 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:00, 19.16it/s, est. speed input: 19929.64 toks/s, output: 19.46 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:05<00:00, 19.16it/s, est. speed input: 19924.04 toks/s, output: 19.46 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 19.16it/s, est. speed input: 19918.75 toks/s, output: 19.45 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 19.16it/s, est. speed input: 19913.38 toks/s, output: 19.45 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 19.15it/s, est. speed input: 19907.95 toks/s, output: 19.44 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 19.11it/s, est. speed input: 19900.32 toks/s, output: 19.43 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 19.07it/s, est. speed input: 19892.76 toks/s, output: 19.43 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 19.07it/s, est. speed input: 19887.38 toks/s, output: 19.42 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 19.07it/s, est. speed input: 19880.95 toks/s, output: 19.41 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.07it/s, est. speed input: 19878.49 toks/s, output: 19.41 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.41it/s, est. speed input: 19878.49 toks/s, output: 19.41 toks/s]
[rank0]:[W125 21:03:22.827128395 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 31.5s

测试结果:
  Requests/s:   18.68
  Tokens/s:     19146.57
  Total Reqs:   128
  Elapsed:      6.85s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     19127.89

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:03:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=480353) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=480353) WARNING 01-25 21:03:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.31 requests/s, 19790.10 total tokens/s, 19.31 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 21:03:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:03:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:03:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:03:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:03:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:03:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:03:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:03:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:03:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:03:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:03:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:03:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=480353) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=480353) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.27it/s]
(EngineCore_DP0 pid=480353) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.63it/s]
(EngineCore_DP0 pid=480353) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.70it/s]
(EngineCore_DP0 pid=480353) 
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=480353) [2026-01-25 21:03:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=480353) 2026-01-25 21:03:44,155 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=480353) 2026-01-25 21:03:44,176 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=480353) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 24.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 24.77it/s]
(EngineCore_DP0 pid=480353) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 12.30it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 47/256 [00:00<00:00, 462.61it/s]
Adding requests:  41%|████      | 104/256 [00:00<00:00, 520.11it/s]
Adding requests:  63%|██████▎   | 162/256 [00:00<00:00, 543.94it/s]
Adding requests:  86%|████████▋ | 221/256 [00:00<00:00, 561.14it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 544.85it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:03, 66.09it/s, est. speed input: 67679.38 toks/s, output: 66.09 toks/s]
Processed prompts:   7%|▋         | 17/256 [00:00<00:07, 33.76it/s, est. speed input: 37841.81 toks/s, output: 36.95 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:09, 24.72it/s, est. speed input: 29315.99 toks/s, output: 28.63 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:00<00:09, 25.58it/s, est. speed input: 29371.46 toks/s, output: 28.68 toks/s]
Processed prompts:  11%|█         | 28/256 [00:01<00:10, 21.62it/s, est. speed input: 26613.85 toks/s, output: 25.99 toks/s]
Processed prompts:  12%|█▏        | 31/256 [00:01<00:09, 23.16it/s, est. speed input: 26896.80 toks/s, output: 26.27 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:01<00:11, 19.98it/s, est. speed input: 25110.32 toks/s, output: 24.52 toks/s]
Processed prompts:  14%|█▍        | 37/256 [00:01<00:10, 21.88it/s, est. speed input: 25435.87 toks/s, output: 24.84 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:11, 19.16it/s, est. speed input: 24162.68 toks/s, output: 23.60 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:01<00:10, 21.27it/s, est. speed input: 24488.89 toks/s, output: 23.91 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:02<00:11, 18.73it/s, est. speed input: 23497.97 toks/s, output: 22.95 toks/s]
Processed prompts:  19%|█▉        | 49/256 [00:02<00:09, 20.91it/s, est. speed input: 23801.89 toks/s, output: 23.24 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:11, 18.51it/s, est. speed input: 23007.59 toks/s, output: 22.47 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:02<00:09, 20.77it/s, est. speed input: 23301.36 toks/s, output: 22.76 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:10, 18.43it/s, est. speed input: 22641.88 toks/s, output: 22.11 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:02<00:09, 20.69it/s, est. speed input: 22910.96 toks/s, output: 22.37 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:10, 18.38it/s, est. speed input: 22349.67 toks/s, output: 21.83 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:03<00:09, 20.66it/s, est. speed input: 22603.87 toks/s, output: 22.07 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:03<00:10, 18.37it/s, est. speed input: 22116.15 toks/s, output: 21.60 toks/s]
Processed prompts:  29%|██▊       | 73/256 [00:03<00:08, 20.64it/s, est. speed input: 22351.88 toks/s, output: 21.83 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:09, 18.34it/s, est. speed input: 21919.76 toks/s, output: 21.41 toks/s]
Processed prompts:  31%|███       | 79/256 [00:03<00:08, 20.64it/s, est. speed input: 22142.90 toks/s, output: 21.62 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:09, 18.33it/s, est. speed input: 21754.41 toks/s, output: 21.24 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:03<00:08, 20.62it/s, est. speed input: 21963.74 toks/s, output: 21.45 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:04<00:09, 18.33it/s, est. speed input: 21614.57 toks/s, output: 21.11 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:04<00:08, 20.61it/s, est. speed input: 21811.17 toks/s, output: 21.30 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:08, 18.33it/s, est. speed input: 21494.27 toks/s, output: 20.99 toks/s]
Processed prompts:  38%|███▊      | 97/256 [00:04<00:07, 20.61it/s, est. speed input: 21680.62 toks/s, output: 21.17 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:08, 18.33it/s, est. speed input: 21390.00 toks/s, output: 20.89 toks/s]
Processed prompts:  40%|████      | 103/256 [00:04<00:07, 20.62it/s, est. speed input: 21566.44 toks/s, output: 21.06 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:05<00:08, 18.33it/s, est. speed input: 21297.46 toks/s, output: 20.80 toks/s]
Processed prompts:  43%|████▎     | 109/256 [00:05<00:07, 20.62it/s, est. speed input: 21466.03 toks/s, output: 20.96 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:07, 18.31it/s, est. speed input: 21214.04 toks/s, output: 20.72 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:05<00:06, 20.60it/s, est. speed input: 21374.01 toks/s, output: 20.87 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:05<00:07, 18.31it/s, est. speed input: 21139.85 toks/s, output: 20.64 toks/s]
Processed prompts:  47%|████▋     | 121/256 [00:05<00:06, 20.59it/s, est. speed input: 21292.73 toks/s, output: 20.79 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:06<00:07, 18.30it/s, est. speed input: 21072.26 toks/s, output: 20.58 toks/s]
Processed prompts:  50%|████▉     | 127/256 [00:06<00:06, 20.57it/s, est. speed input: 21217.69 toks/s, output: 20.72 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:06<00:06, 18.31it/s, est. speed input: 21012.84 toks/s, output: 20.52 toks/s]
Processed prompts:  52%|█████▏    | 133/256 [00:06<00:05, 20.61it/s, est. speed input: 21154.25 toks/s, output: 20.66 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:06, 18.32it/s, est. speed input: 20959.82 toks/s, output: 20.47 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:06<00:05, 20.62it/s, est. speed input: 21095.41 toks/s, output: 20.60 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:06<00:06, 18.33it/s, est. speed input: 20912.09 toks/s, output: 20.42 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:07<00:05, 20.61it/s, est. speed input: 21041.00 toks/s, output: 20.55 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:07<00:05, 18.32it/s, est. speed input: 20867.20 toks/s, output: 20.38 toks/s]
Processed prompts:  59%|█████▉    | 151/256 [00:07<00:05, 20.61it/s, est. speed input: 20992.14 toks/s, output: 20.50 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:07<00:05, 18.31it/s, est. speed input: 20825.41 toks/s, output: 20.34 toks/s]
Processed prompts:  61%|██████▏   | 157/256 [00:07<00:04, 20.60it/s, est. speed input: 20945.75 toks/s, output: 20.45 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:07<00:05, 18.31it/s, est. speed input: 20786.89 toks/s, output: 20.30 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:07<00:04, 20.59it/s, est. speed input: 20902.94 toks/s, output: 20.41 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:08<00:04, 18.29it/s, est. speed input: 20750.22 toks/s, output: 20.26 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:08<00:04, 20.59it/s, est. speed input: 20862.94 toks/s, output: 20.37 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:08<00:04, 18.31it/s, est. speed input: 20718.09 toks/s, output: 20.23 toks/s]
Processed prompts:  68%|██████▊   | 175/256 [00:08<00:03, 20.59it/s, est. speed input: 20826.61 toks/s, output: 20.34 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:08<00:04, 18.30it/s, est. speed input: 20686.83 toks/s, output: 20.20 toks/s]
Processed prompts:  71%|███████   | 181/256 [00:08<00:03, 20.58it/s, est. speed input: 20791.46 toks/s, output: 20.30 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:09<00:03, 18.30it/s, est. speed input: 20658.19 toks/s, output: 20.17 toks/s]
Processed prompts:  73%|███████▎  | 187/256 [00:09<00:03, 20.60it/s, est. speed input: 20760.56 toks/s, output: 20.27 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:09<00:03, 18.31it/s, est. speed input: 20632.40 toks/s, output: 20.15 toks/s]
Processed prompts:  75%|███████▌  | 193/256 [00:09<00:03, 20.60it/s, est. speed input: 20731.22 toks/s, output: 20.25 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:09<00:03, 18.31it/s, est. speed input: 20607.59 toks/s, output: 20.12 toks/s]
Processed prompts:  78%|███████▊  | 199/256 [00:09<00:02, 20.59it/s, est. speed input: 20703.24 toks/s, output: 20.22 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:10<00:02, 18.30it/s, est. speed input: 20583.26 toks/s, output: 20.10 toks/s]
Processed prompts:  80%|████████  | 205/256 [00:10<00:02, 20.58it/s, est. speed input: 20676.51 toks/s, output: 20.19 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:10<00:02, 18.30it/s, est. speed input: 20561.18 toks/s, output: 20.08 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:10<00:02, 20.58it/s, est. speed input: 20651.49 toks/s, output: 20.17 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:10<00:02, 18.29it/s, est. speed input: 20539.49 toks/s, output: 20.06 toks/s]
Processed prompts:  85%|████████▍ | 217/256 [00:10<00:01, 20.59it/s, est. speed input: 20628.33 toks/s, output: 20.14 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:10<00:01, 18.29it/s, est. speed input: 20519.87 toks/s, output: 20.04 toks/s]
Processed prompts:  87%|████████▋ | 223/256 [00:11<00:01, 20.56it/s, est. speed input: 20605.19 toks/s, output: 20.12 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:11<00:01, 18.29it/s, est. speed input: 20500.51 toks/s, output: 20.02 toks/s]
Processed prompts:  89%|████████▉ | 229/256 [00:11<00:01, 20.58it/s, est. speed input: 20584.59 toks/s, output: 20.10 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:11<00:01, 18.28it/s, est. speed input: 20482.20 toks/s, output: 20.00 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:11<00:01, 20.55it/s, est. speed input: 20563.26 toks/s, output: 20.08 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:11<00:00, 18.26it/s, est. speed input: 20463.60 toks/s, output: 19.98 toks/s]
Processed prompts:  94%|█████████▍| 241/256 [00:12<00:00, 20.55it/s, est. speed input: 20543.52 toks/s, output: 20.06 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:12<00:00, 18.29it/s, est. speed input: 20448.46 toks/s, output: 19.97 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:12<00:00, 20.58it/s, est. speed input: 20526.45 toks/s, output: 20.05 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:12<00:00, 18.29it/s, est. speed input: 20433.35 toks/s, output: 19.95 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:12<00:00, 20.58it/s, est. speed input: 20509.54 toks/s, output: 20.03 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.18it/s, est. speed input: 20500.33 toks/s, output: 20.02 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.18it/s, est. speed input: 20500.33 toks/s, output: 20.02 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.02it/s, est. speed input: 20500.33 toks/s, output: 20.02 toks/s]
[rank0]:[W125 21:03:58.622472907 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 36.7s

测试结果:
  Requests/s:   19.31
  Tokens/s:     19790.10
  Total Reqs:   256
  Elapsed:      13.26s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     19770.80

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:04:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=481147) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=481147) WARNING 01-25 21:04:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.53 requests/s, 20022.88 total tokens/s, 19.53 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 21:04:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:04:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:04:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:04:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:04:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:04:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:04:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:04:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:04:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:04:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:04:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:04:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=481147) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=481147) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.30it/s]
(EngineCore_DP0 pid=481147) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.64it/s]
(EngineCore_DP0 pid=481147) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.71it/s]
(EngineCore_DP0 pid=481147) 
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=481147) [2026-01-25 21:04:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=481147) 2026-01-25 21:04:22,192 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=481147) 2026-01-25 21:04:22,209 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=481147) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 28.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 26.13it/s]
(EngineCore_DP0 pid=481147) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.64it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 15.72it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 50/512 [00:00<00:00, 491.34it/s]
Adding requests:  21%|██        | 106/512 [00:00<00:00, 530.74it/s]
Adding requests:  31%|███▏      | 161/512 [00:00<00:00, 535.41it/s]
Adding requests:  43%|████▎     | 221/512 [00:00<00:00, 560.49it/s]
Adding requests:  54%|█████▍    | 278/512 [00:00<00:00, 563.06it/s]
Adding requests:  66%|██████▌   | 338/512 [00:00<00:00, 573.80it/s]
Adding requests:  78%|███████▊  | 397/512 [00:00<00:00, 577.54it/s]
Adding requests:  89%|████████▉ | 455/512 [00:00<00:00, 571.07it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 565.61it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:05, 84.84it/s, est. speed input: 86877.39 toks/s, output: 84.84 toks/s]
Processed prompts:   5%|▌         | 27/512 [00:00<00:12, 38.85it/s, est. speed input: 44620.34 toks/s, output: 43.57 toks/s]
Processed prompts:   6%|▋         | 32/512 [00:00<00:14, 33.94it/s, est. speed input: 39802.13 toks/s, output: 38.87 toks/s]
Processed prompts:   7%|▋         | 36/512 [00:01<00:16, 29.24it/s, est. speed input: 35904.75 toks/s, output: 35.06 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:01<00:18, 26.16it/s, est. speed input: 33281.76 toks/s, output: 32.50 toks/s]
Processed prompts:   8%|▊         | 43/512 [00:01<00:20, 22.57it/s, est. speed input: 30695.28 toks/s, output: 29.98 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:01<00:23, 20.14it/s, est. speed input: 28754.35 toks/s, output: 28.08 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:01<00:23, 19.99it/s, est. speed input: 27801.26 toks/s, output: 27.15 toks/s]
Processed prompts:  11%|█         | 54/512 [00:02<00:23, 19.89it/s, est. speed input: 27038.24 toks/s, output: 26.40 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:02<00:22, 19.81it/s, est. speed input: 26409.33 toks/s, output: 25.79 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:02<00:22, 19.76it/s, est. speed input: 25885.05 toks/s, output: 25.28 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:22, 19.72it/s, est. speed input: 25441.43 toks/s, output: 24.85 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:22, 19.69it/s, est. speed input: 25059.31 toks/s, output: 24.47 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:03<00:22, 19.67it/s, est. speed input: 24729.46 toks/s, output: 24.15 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:03<00:22, 19.65it/s, est. speed input: 24438.00 toks/s, output: 23.87 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:03<00:21, 19.63it/s, est. speed input: 24180.80 toks/s, output: 23.61 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:21, 19.63it/s, est. speed input: 23953.98 toks/s, output: 23.39 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:21, 19.63it/s, est. speed input: 23752.04 toks/s, output: 23.20 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:04<00:21, 19.63it/s, est. speed input: 23570.13 toks/s, output: 23.02 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:04<00:21, 19.62it/s, est. speed input: 23403.08 toks/s, output: 22.85 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:04<00:20, 19.63it/s, est. speed input: 23253.91 toks/s, output: 22.71 toks/s]
Processed prompts:  21%|██        | 106/512 [00:04<00:20, 19.62it/s, est. speed input: 23115.63 toks/s, output: 22.57 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:04<00:20, 19.62it/s, est. speed input: 22989.74 toks/s, output: 22.45 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:05<00:20, 19.62it/s, est. speed input: 22874.24 toks/s, output: 22.34 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:05<00:20, 19.61it/s, est. speed input: 22765.93 toks/s, output: 22.23 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:05<00:19, 19.60it/s, est. speed input: 22665.24 toks/s, output: 22.13 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:05<00:19, 19.60it/s, est. speed input: 22572.31 toks/s, output: 22.04 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:05<00:19, 19.60it/s, est. speed input: 22486.00 toks/s, output: 21.96 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:06<00:19, 19.60it/s, est. speed input: 22405.46 toks/s, output: 21.88 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:06<00:19, 19.59it/s, est. speed input: 22329.43 toks/s, output: 21.81 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:06<00:18, 19.60it/s, est. speed input: 22259.50 toks/s, output: 21.74 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:06<00:18, 19.60it/s, est. speed input: 22193.25 toks/s, output: 21.67 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:06<00:18, 19.60it/s, est. speed input: 22130.60 toks/s, output: 21.61 toks/s]
Processed prompts:  30%|███       | 154/512 [00:07<00:18, 19.60it/s, est. speed input: 22072.30 toks/s, output: 21.55 toks/s]
Processed prompts:  31%|███       | 158/512 [00:07<00:18, 19.59it/s, est. speed input: 22014.91 toks/s, output: 21.50 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:07<00:17, 19.59it/s, est. speed input: 21962.36 toks/s, output: 21.45 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:07<00:17, 19.59it/s, est. speed input: 21912.54 toks/s, output: 21.40 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:07<00:17, 19.60it/s, est. speed input: 21865.96 toks/s, output: 21.35 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:08<00:17, 19.60it/s, est. speed input: 21821.13 toks/s, output: 21.31 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:08<00:17, 19.60it/s, est. speed input: 21778.14 toks/s, output: 21.27 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:08<00:16, 19.60it/s, est. speed input: 21737.57 toks/s, output: 21.23 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:08<00:16, 19.59it/s, est. speed input: 21697.95 toks/s, output: 21.19 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:08<00:16, 19.59it/s, est. speed input: 21660.78 toks/s, output: 21.15 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:09<00:16, 19.58it/s, est. speed input: 21624.74 toks/s, output: 21.12 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:09<00:16, 19.58it/s, est. speed input: 21590.23 toks/s, output: 21.08 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:09<00:15, 19.58it/s, est. speed input: 21557.58 toks/s, output: 21.05 toks/s]
Processed prompts:  40%|████      | 206/512 [00:09<00:15, 19.58it/s, est. speed input: 21526.14 toks/s, output: 21.02 toks/s]
Processed prompts:  41%|████      | 210/512 [00:10<00:15, 19.58it/s, est. speed input: 21496.02 toks/s, output: 20.99 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:10<00:15, 19.58it/s, est. speed input: 21466.94 toks/s, output: 20.96 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:10<00:15, 19.58it/s, est. speed input: 21438.94 toks/s, output: 20.94 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:10<00:14, 19.57it/s, est. speed input: 21411.49 toks/s, output: 20.91 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:10<00:14, 19.56it/s, est. speed input: 21385.32 toks/s, output: 20.88 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:11<00:14, 19.56it/s, est. speed input: 21360.28 toks/s, output: 20.86 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:11<00:14, 19.57it/s, est. speed input: 21336.32 toks/s, output: 20.84 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:11<00:14, 19.57it/s, est. speed input: 21313.14 toks/s, output: 20.81 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:11<00:13, 19.56it/s, est. speed input: 21290.18 toks/s, output: 20.79 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:11<00:13, 19.55it/s, est. speed input: 21268.06 toks/s, output: 20.77 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:12<00:13, 19.56it/s, est. speed input: 21247.26 toks/s, output: 20.75 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:12<00:13, 19.55it/s, est. speed input: 21226.62 toks/s, output: 20.73 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:12<00:12, 19.57it/s, est. speed input: 21207.66 toks/s, output: 20.71 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:12<00:12, 19.58it/s, est. speed input: 21189.22 toks/s, output: 20.69 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:12<00:12, 19.58it/s, est. speed input: 21171.37 toks/s, output: 20.68 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:13<00:12, 19.57it/s, est. speed input: 21153.43 toks/s, output: 20.66 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:13<00:12, 19.56it/s, est. speed input: 21135.55 toks/s, output: 20.64 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:13<00:11, 19.56it/s, est. speed input: 21118.67 toks/s, output: 20.62 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:13<00:11, 19.55it/s, est. speed input: 21101.76 toks/s, output: 20.61 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:13<00:11, 19.55it/s, est. speed input: 21085.75 toks/s, output: 20.59 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:14<00:11, 19.56it/s, est. speed input: 21070.72 toks/s, output: 20.58 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:14<00:11, 19.55it/s, est. speed input: 21055.63 toks/s, output: 20.56 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:14<00:10, 19.56it/s, est. speed input: 21041.21 toks/s, output: 20.55 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:14<00:10, 19.55it/s, est. speed input: 21026.73 toks/s, output: 20.53 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:14<00:10, 19.55it/s, est. speed input: 21012.90 toks/s, output: 20.52 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:15<00:10, 19.55it/s, est. speed input: 20999.58 toks/s, output: 20.51 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:15<00:10, 19.55it/s, est. speed input: 20986.20 toks/s, output: 20.49 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:15<00:09, 19.54it/s, est. speed input: 20973.13 toks/s, output: 20.48 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:15<00:09, 19.55it/s, est. speed input: 20960.83 toks/s, output: 20.47 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:15<00:09, 19.55it/s, est. speed input: 20948.68 toks/s, output: 20.46 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:16<00:09, 19.56it/s, est. speed input: 20937.30 toks/s, output: 20.45 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:16<00:09, 19.55it/s, est. speed input: 20925.53 toks/s, output: 20.44 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:16<00:08, 19.55it/s, est. speed input: 20914.54 toks/s, output: 20.42 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:16<00:08, 19.57it/s, est. speed input: 20904.35 toks/s, output: 20.41 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:16<00:08, 19.56it/s, est. speed input: 20893.71 toks/s, output: 20.40 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:17<00:08, 19.56it/s, est. speed input: 20883.15 toks/s, output: 20.39 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:17<00:08, 19.55it/s, est. speed input: 20872.79 toks/s, output: 20.38 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:17<00:07, 19.55it/s, est. speed input: 20862.64 toks/s, output: 20.37 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:17<00:07, 19.54it/s, est. speed input: 20852.84 toks/s, output: 20.36 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:17<00:07, 19.55it/s, est. speed input: 20843.35 toks/s, output: 20.35 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:18<00:07, 19.54it/s, est. speed input: 20833.61 toks/s, output: 20.35 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:18<00:07, 19.54it/s, est. speed input: 20824.49 toks/s, output: 20.34 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:18<00:06, 19.54it/s, est. speed input: 20815.74 toks/s, output: 20.33 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:18<00:06, 19.56it/s, est. speed input: 20807.45 toks/s, output: 20.32 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:19<00:06, 19.56it/s, est. speed input: 20799.01 toks/s, output: 20.31 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:19<00:06, 19.54it/s, est. speed input: 20790.31 toks/s, output: 20.30 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:19<00:06, 19.54it/s, est. speed input: 20782.15 toks/s, output: 20.30 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:19<00:05, 19.54it/s, est. speed input: 20774.00 toks/s, output: 20.29 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:19<00:05, 19.54it/s, est. speed input: 20766.21 toks/s, output: 20.28 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:20<00:05, 19.55it/s, est. speed input: 20758.72 toks/s, output: 20.27 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:20<00:05, 19.54it/s, est. speed input: 20750.77 toks/s, output: 20.26 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:20<00:05, 19.53it/s, est. speed input: 20743.21 toks/s, output: 20.26 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:20<00:04, 19.52it/s, est. speed input: 20735.55 toks/s, output: 20.25 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:20<00:04, 19.53it/s, est. speed input: 20728.51 toks/s, output: 20.24 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:21<00:04, 19.54it/s, est. speed input: 20721.55 toks/s, output: 20.24 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:21<00:04, 19.53it/s, est. speed input: 20714.38 toks/s, output: 20.23 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:21<00:03, 19.52it/s, est. speed input: 20707.38 toks/s, output: 20.22 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:21<00:03, 19.53it/s, est. speed input: 20700.69 toks/s, output: 20.22 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:21<00:03, 19.53it/s, est. speed input: 20694.34 toks/s, output: 20.21 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:22<00:03, 19.54it/s, est. speed input: 20688.10 toks/s, output: 20.20 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:22<00:03, 19.53it/s, est. speed input: 20681.70 toks/s, output: 20.20 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:22<00:02, 19.53it/s, est. speed input: 20675.50 toks/s, output: 20.19 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:22<00:02, 19.54it/s, est. speed input: 20669.65 toks/s, output: 20.19 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:22<00:02, 19.54it/s, est. speed input: 20663.87 toks/s, output: 20.18 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:23<00:02, 19.55it/s, est. speed input: 20658.41 toks/s, output: 20.17 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:23<00:02, 19.54it/s, est. speed input: 20652.32 toks/s, output: 20.17 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:23<00:01, 19.53it/s, est. speed input: 20646.56 toks/s, output: 20.16 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:23<00:01, 19.52it/s, est. speed input: 20640.65 toks/s, output: 20.16 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:23<00:01, 19.52it/s, est. speed input: 20635.04 toks/s, output: 20.15 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:24<00:01, 19.53it/s, est. speed input: 20629.77 toks/s, output: 20.15 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:24<00:01, 19.52it/s, est. speed input: 20624.23 toks/s, output: 20.14 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:24<00:00, 19.53it/s, est. speed input: 20619.08 toks/s, output: 20.14 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:24<00:00, 19.53it/s, est. speed input: 20614.03 toks/s, output: 20.13 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:24<00:00, 19.53it/s, est. speed input: 20609.11 toks/s, output: 20.13 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:25<00:00, 19.55it/s, est. speed input: 20604.51 toks/s, output: 20.12 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:25<00:00, 21.03it/s, est. speed input: 20638.85 toks/s, output: 20.16 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:25<00:00, 21.03it/s, est. speed input: 20719.71 toks/s, output: 20.23 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:25<00:00, 20.23it/s, est. speed input: 20719.71 toks/s, output: 20.23 toks/s]
[rank0]:[W125 21:04:50.826762324 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 51.1s

测试结果:
  Requests/s:   19.53
  Tokens/s:     20022.88
  Total Reqs:   512
  Elapsed:      26.21s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     20003.34

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:04:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=482162) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482162) WARNING 01-25 21:05:08 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     def forward(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     raise e
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/tmp/torchinductor_root/vp/cvp3urmrbzg25mqrpttqu5ejzeu4mf6gy4mfedv7nmoggrdno3md.py", line 958, in call
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) ERROR 01-25 21:05:14 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 220.94 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 2.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:04:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:04:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:04:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:04:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:04:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:04:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:05:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:05:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:05:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:05:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:05:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:05:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=482162) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=482162) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.24it/s]
(EngineCore_DP0 pid=482162) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=482162) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]
(EngineCore_DP0 pid=482162) 
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=482162) [2026-01-25 21:05:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=482162) 2026-01-25 21:05:14,616 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=482162) 2026-01-25 21:05:14,642 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=482162) Process EngineCore_DP0:
(EngineCore_DP0 pid=482162) Traceback (most recent call last):
(EngineCore_DP0 pid=482162)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=482162)     self.run()
(EngineCore_DP0 pid=482162)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=482162)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=482162)     raise e
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482162)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482162)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482162)     super().__init__(
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482162)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482162)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=482162)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=482162)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482162)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482162)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482162)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=482162)     kernel_warmup(self)
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=482162)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=482162)     runner._dummy_run(
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482162)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482162)     outputs = self.model(
(EngineCore_DP0 pid=482162)               ^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482162)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482162)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482162)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482162)     hidden_states = self.model(
(EngineCore_DP0 pid=482162)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=482162)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=482162)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=482162)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=482162)     def forward(
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482162)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=482162)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=482162)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=482162)     raise e
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=482162)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482162)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482162)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=482162)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=482162)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482162)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=482162)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=482162)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482162)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=482162)     return compiled_fn(full_args)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=482162)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=482162)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=482162)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=482162)                             ^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=482162)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=482162)     return self.current_callable(inputs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=482162)     out = model(new_inputs)
(EngineCore_DP0 pid=482162)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/tmp/torchinductor_root/vp/cvp3urmrbzg25mqrpttqu5ejzeu4mf6gy4mfedv7nmoggrdno3md.py", line 958, in call
(EngineCore_DP0 pid=482162)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=482162)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=482162)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=482162)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=482162)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=482162)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=482162)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482162) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 220.94 MiB is free. Including non-PyTorch memory, this process has 15.02 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 2.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:05:15.919737235 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:05:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=482830) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482830) WARNING 01-25 21:05:38 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     def forward(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     raise e
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/tmp/torchinductor_root/ym/cymejugwfo4ynt3g5vecn4t4bafgeplcxhhgirqpjux5ni6ricrj.py", line 1078, in call
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) ERROR 01-25 21:05:43 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 924.94 MiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:05:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:05:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:05:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:05:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:05:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:05:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:05:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:05:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:05:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:05:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:05:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:05:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:05:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:05:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=482830) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=482830) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.26it/s]
(EngineCore_DP0 pid=482830) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=482830) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.69it/s]
(EngineCore_DP0 pid=482830) 
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=482830) [2026-01-25 21:05:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=482830) [rank0]:W0125 21:05:40.803000 482830 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=482830) [rank0]:W0125 21:05:40.854000 482830 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=482830) [rank0]:W0125 21:05:41.415000 482830 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=482830) [rank0]:W0125 21:05:41.492000 482830 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=482830) 2026-01-25 21:05:43,796 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=482830) 2026-01-25 21:05:43,844 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=482830) Process EngineCore_DP0:
(EngineCore_DP0 pid=482830) Traceback (most recent call last):
(EngineCore_DP0 pid=482830)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=482830)     self.run()
(EngineCore_DP0 pid=482830)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=482830)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=482830)     raise e
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482830)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482830)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482830)     super().__init__(
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482830)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482830)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=482830)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=482830)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482830)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482830)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482830)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=482830)     kernel_warmup(self)
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=482830)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=482830)     runner._dummy_run(
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482830)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482830)     outputs = self.model(
(EngineCore_DP0 pid=482830)               ^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482830)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482830)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482830)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482830)     hidden_states = self.model(
(EngineCore_DP0 pid=482830)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=482830)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=482830)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=482830)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=482830)     def forward(
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482830)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=482830)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=482830)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=482830)     raise e
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=482830)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482830)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482830)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=482830)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=482830)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=482830)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=482830)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=482830)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=482830)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=482830)     return compiled_fn(full_args)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=482830)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=482830)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=482830)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=482830)                             ^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=482830)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=482830)     return self.current_callable(inputs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=482830)     out = model(new_inputs)
(EngineCore_DP0 pid=482830)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/tmp/torchinductor_root/ym/cymejugwfo4ynt3g5vecn4t4bafgeplcxhhgirqpjux5ni6ricrj.py", line 1078, in call
(EngineCore_DP0 pid=482830)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=482830)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=482830)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=482830)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=482830)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=482830)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=482830)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482830) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 924.94 MiB is free. Including non-PyTorch memory, this process has 14.34 GiB memory in use. Of the allocated memory 11.25 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:05:44.177053102 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:06:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=483573) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=483573) WARNING 01-25 21:06:14 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=483573) ERROR 01-25 21:06:17 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.91 GiB is free. Including non-PyTorch memory, this process has 13.32 GiB memory in use. Of the allocated memory 10.04 GiB is allocated by PyTorch, and 2.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:06:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:06:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:06:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:06:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=483573) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=483573) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.20it/s]
(EngineCore_DP0 pid=483573) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.62it/s]
(EngineCore_DP0 pid=483573) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.69it/s]
(EngineCore_DP0 pid=483573) 
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=483573) [2026-01-25 21:06:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=483573) [rank0]:W0125 21:06:17.248000 483573 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=483573) [rank0]:W0125 21:06:17.296000 483573 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=483573) [rank0]:W0125 21:06:17.840000 483573 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=483573) [rank0]:W0125 21:06:17.915000 483573 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=483573) Process EngineCore_DP0:
(EngineCore_DP0 pid=483573) Traceback (most recent call last):
(EngineCore_DP0 pid=483573)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=483573)     self.run()
(EngineCore_DP0 pid=483573)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=483573)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=483573)     raise e
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=483573)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=483573)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=483573)     super().__init__(
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=483573)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=483573)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=483573)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=483573)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=483573)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=483573)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=483573)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=483573)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483573)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=483573)     self.model_runner.profile_run()
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=483573)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=483573)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483573)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=483573)     outputs = self.model(
(EngineCore_DP0 pid=483573)               ^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=483573)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483573)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483573)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=483573)     hidden_states = self.model(
(EngineCore_DP0 pid=483573)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=483573)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=483573)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=483573)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=483573)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=483573)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=483573)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=483573)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=483573)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=483573)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=483573)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=483573)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=483573)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=483573)     return self._compile_to_module()
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=483573)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=483573)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=483573)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=483573)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=483573)     return self._generate(is_inference)
(EngineCore_DP0 pid=483573)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=483573)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=483573)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=483573)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=483573) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.91 GiB is free. Including non-PyTorch memory, this process has 13.32 GiB memory in use. Of the allocated memory 10.04 GiB is allocated by PyTorch, and 2.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:06:18.229520703 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:06:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=484503) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=484503) WARNING 01-25 21:07:02 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=484503) ERROR 01-25 21:07:06 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 13.98 GiB memory in use. Of the allocated memory 11.13 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:06:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:06:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:06:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:06:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=484503) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=484503) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.20it/s]
(EngineCore_DP0 pid=484503) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]
(EngineCore_DP0 pid=484503) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.64it/s]
(EngineCore_DP0 pid=484503) 
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=484503) [2026-01-25 21:06:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=484503) [rank0]:W0125 21:07:05.519000 484503 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=484503) [rank0]:W0125 21:07:06.246000 484503 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=484503) Process EngineCore_DP0:
(EngineCore_DP0 pid=484503) Traceback (most recent call last):
(EngineCore_DP0 pid=484503)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=484503)     self.run()
(EngineCore_DP0 pid=484503)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=484503)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=484503)     raise e
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=484503)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=484503)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=484503)     super().__init__(
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=484503)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=484503)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=484503)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=484503)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=484503)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=484503)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=484503)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=484503)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484503)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=484503)     self.model_runner.profile_run()
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=484503)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=484503)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484503)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=484503)     outputs = self.model(
(EngineCore_DP0 pid=484503)               ^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=484503)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484503)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484503)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=484503)     hidden_states = self.model(
(EngineCore_DP0 pid=484503)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=484503)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=484503)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=484503)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=484503)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=484503)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=484503)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=484503)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=484503)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=484503)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=484503)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=484503)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=484503)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=484503)     return self._compile_to_module()
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=484503)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=484503)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=484503)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=484503)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=484503)     return self._generate(is_inference)
(EngineCore_DP0 pid=484503)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=484503)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=484503)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=484503)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=484503) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 13.98 GiB memory in use. Of the allocated memory 11.13 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:07:06.689276903 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,33.6153,17244.6514,3.8078
1024,1024,1,128,128,18.6796,19146.5651,6.8524
2048,1024,2,256,128,19.3074,19790.1048,13.2592
4096,1024,4,512,128,19.5345,20022.8771,26.2100
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 4 成功, 4 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:07:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=485049) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=485049) WARNING 01-25 21:07:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.84 requests/s, 16333.23 total tokens/s, 31.84 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 21:07:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:07:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:07:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:07:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=485049) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=485049) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.39s/it]
(EngineCore_DP0 pid=485049) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.86s/it]
(EngineCore_DP0 pid=485049) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.79s/it]
(EngineCore_DP0 pid=485049) 
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=485049) [2026-01-25 21:07:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=485049) 2026-01-25 21:07:31,282 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=485049) 2026-01-25 21:07:31,297 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=485049) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.29it/s]
(EngineCore_DP0 pid=485049) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  66%|██████▌   | 84/128 [00:00<00:00, 839.11it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 875.00it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:21,  5.79it/s, est. speed input: 2966.89 toks/s, output: 5.79 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 19.78it/s, est. speed input: 8845.48 toks/s, output: 17.28 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.79it/s, est. speed input: 11358.27 toks/s, output: 22.18 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 28.91it/s, est. speed input: 12732.45 toks/s, output: 24.87 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 30.81it/s, est. speed input: 13622.41 toks/s, output: 26.61 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 31.99it/s, est. speed input: 14234.74 toks/s, output: 27.80 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 32.69it/s, est. speed input: 14671.69 toks/s, output: 28.66 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 33.20it/s, est. speed input: 15013.51 toks/s, output: 29.32 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 33.59it/s, est. speed input: 15289.59 toks/s, output: 29.86 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.84it/s, est. speed input: 15510.94 toks/s, output: 30.29 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 34.00it/s, est. speed input: 15692.12 toks/s, output: 30.65 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 34.13it/s, est. speed input: 15847.57 toks/s, output: 30.95 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 34.22it/s, est. speed input: 15978.60 toks/s, output: 31.21 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 34.30it/s, est. speed input: 16094.12 toks/s, output: 31.43 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 34.27it/s, est. speed input: 16186.40 toks/s, output: 31.61 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 34.25it/s, est. speed input: 16266.87 toks/s, output: 31.77 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 34.29it/s, est. speed input: 16343.03 toks/s, output: 31.92 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 34.31it/s, est. speed input: 16410.43 toks/s, output: 32.05 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 34.33it/s, est. speed input: 16471.38 toks/s, output: 32.17 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 34.35it/s, est. speed input: 16527.40 toks/s, output: 32.28 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 34.32it/s, est. speed input: 16574.49 toks/s, output: 32.37 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 34.32it/s, est. speed input: 16618.80 toks/s, output: 32.46 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 34.34it/s, est. speed input: 16660.89 toks/s, output: 32.54 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 34.32it/s, est. speed input: 16697.24 toks/s, output: 32.61 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 34.27it/s, est. speed input: 16728.34 toks/s, output: 32.67 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 34.28it/s, est. speed input: 16760.14 toks/s, output: 32.73 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 34.33it/s, est. speed input: 16791.77 toks/s, output: 32.80 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 34.37it/s, est. speed input: 16821.38 toks/s, output: 32.85 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 34.39it/s, est. speed input: 16848.75 toks/s, output: 32.91 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 34.39it/s, est. speed input: 16873.55 toks/s, output: 32.96 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 34.32it/s, est. speed input: 16893.37 toks/s, output: 32.99 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 34.32it/s, est. speed input: 16914.41 toks/s, output: 33.04 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.32it/s, est. speed input: 16925.20 toks/s, output: 33.06 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.06it/s, est. speed input: 16925.20 toks/s, output: 33.06 toks/s]
[rank0]:[W125 21:07:36.752143547 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 29.6s

测试结果:
  Requests/s:   31.84
  Tokens/s:     16333.23
  Total Reqs:   128
  Elapsed:      4.02s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     16301.40

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:07:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=485782) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=485782) WARNING 01-25 21:07:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.80 requests/s, 18242.62 total tokens/s, 17.80 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 21:07:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:07:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:07:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:07:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=485782) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=485782) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=485782) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.50it/s]
(EngineCore_DP0 pid=485782) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]
(EngineCore_DP0 pid=485782) 
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=485782) [2026-01-25 21:07:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=485782) 2026-01-25 21:07:58,746 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=485782) 2026-01-25 21:07:58,761 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=485782) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 25.08it/s]
(EngineCore_DP0 pid=485782) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  39%|███▉      | 50/128 [00:00<00:00, 492.66it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 516.62it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 513.25it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:04, 30.35it/s, est. speed input: 31083.82 toks/s, output: 30.35 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:05, 21.78it/s, est. speed input: 23288.15 toks/s, output: 22.74 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 20.28it/s, est. speed input: 21834.60 toks/s, output: 21.32 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 19.48it/s, est. speed input: 21053.18 toks/s, output: 20.56 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 19.15it/s, est. speed input: 20723.55 toks/s, output: 20.24 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 18.87it/s, est. speed input: 20461.93 toks/s, output: 19.98 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:05, 18.69it/s, est. speed input: 20268.91 toks/s, output: 19.79 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 18.58it/s, est. speed input: 20117.62 toks/s, output: 19.65 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 18.49it/s, est. speed input: 19994.51 toks/s, output: 19.53 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 18.42it/s, est. speed input: 19886.89 toks/s, output: 19.42 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 18.37it/s, est. speed input: 19795.85 toks/s, output: 19.33 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 18.32it/s, est. speed input: 19713.69 toks/s, output: 19.25 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 18.30it/s, est. speed input: 19646.89 toks/s, output: 19.19 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 18.27it/s, est. speed input: 19585.51 toks/s, output: 19.13 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 18.28it/s, est. speed input: 19536.44 toks/s, output: 19.08 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:04, 18.27it/s, est. speed input: 19489.00 toks/s, output: 19.03 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:04, 18.24it/s, est. speed input: 19442.99 toks/s, output: 18.99 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 18.23it/s, est. speed input: 19404.05 toks/s, output: 18.95 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 18.22it/s, est. speed input: 19366.87 toks/s, output: 18.91 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 18.24it/s, est. speed input: 19338.54 toks/s, output: 18.89 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 18.24it/s, est. speed input: 19310.25 toks/s, output: 18.86 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 18.24it/s, est. speed input: 19283.26 toks/s, output: 18.83 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 18.20it/s, est. speed input: 19254.71 toks/s, output: 18.80 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:04, 18.20it/s, est. speed input: 19231.29 toks/s, output: 18.78 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 18.18it/s, est. speed input: 19206.93 toks/s, output: 18.76 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:03, 18.20it/s, est. speed input: 19188.09 toks/s, output: 18.74 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 18.23it/s, est. speed input: 19172.30 toks/s, output: 18.72 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 18.20it/s, est. speed input: 19152.49 toks/s, output: 18.70 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 18.17it/s, est. speed input: 19132.51 toks/s, output: 18.68 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 18.19it/s, est. speed input: 19118.22 toks/s, output: 18.67 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 18.19it/s, est. speed input: 19103.22 toks/s, output: 18.66 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 18.21it/s, est. speed input: 19091.22 toks/s, output: 18.64 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 18.20it/s, est. speed input: 19078.20 toks/s, output: 18.63 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 18.24it/s, est. speed input: 19069.37 toks/s, output: 18.62 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:02, 18.24it/s, est. speed input: 19058.75 toks/s, output: 18.61 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 18.20it/s, est. speed input: 19045.31 toks/s, output: 18.60 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 18.19it/s, est. speed input: 19034.05 toks/s, output: 18.59 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 18.19it/s, est. speed input: 19024.19 toks/s, output: 18.58 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 18.20it/s, est. speed input: 19015.43 toks/s, output: 18.57 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 18.18it/s, est. speed input: 19004.81 toks/s, output: 18.56 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 18.19it/s, est. speed input: 18996.78 toks/s, output: 18.55 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:02, 18.21it/s, est. speed input: 18989.87 toks/s, output: 18.54 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:01, 18.22it/s, est. speed input: 18982.95 toks/s, output: 18.54 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 18.19it/s, est. speed input: 18973.83 toks/s, output: 18.53 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 18.20it/s, est. speed input: 18966.85 toks/s, output: 18.52 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 18.20it/s, est. speed input: 18959.98 toks/s, output: 18.52 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 18.21it/s, est. speed input: 18954.52 toks/s, output: 18.51 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 18.19it/s, est. speed input: 18947.03 toks/s, output: 18.50 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 18.18it/s, est. speed input: 18939.75 toks/s, output: 18.50 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 18.19it/s, est. speed input: 18934.50 toks/s, output: 18.49 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:01, 18.19it/s, est. speed input: 18928.27 toks/s, output: 18.48 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:05<00:00, 18.21it/s, est. speed input: 18924.17 toks/s, output: 18.48 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 18.22it/s, est. speed input: 18919.51 toks/s, output: 18.48 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 18.23it/s, est. speed input: 18915.67 toks/s, output: 18.47 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 18.18it/s, est. speed input: 18908.57 toks/s, output: 18.47 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 18.15it/s, est. speed input: 18901.59 toks/s, output: 18.46 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 18.17it/s, est. speed input: 18897.59 toks/s, output: 18.45 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 18.16it/s, est. speed input: 18891.77 toks/s, output: 18.45 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 18.17it/s, est. speed input: 18887.81 toks/s, output: 18.45 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 18.19it/s, est. speed input: 18884.30 toks/s, output: 18.44 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.21it/s, est. speed input: 18881.49 toks/s, output: 18.44 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.21it/s, est. speed input: 18881.49 toks/s, output: 18.44 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.44it/s, est. speed input: 18881.49 toks/s, output: 18.44 toks/s]
[rank0]:[W125 21:08:07.069706508 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 30.5s

测试结果:
  Requests/s:   17.80
  Tokens/s:     18242.62
  Total Reqs:   128
  Elapsed:      7.19s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     18224.82

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:08:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=486500) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=486500) WARNING 01-25 21:08:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.41 requests/s, 18865.77 total tokens/s, 18.41 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 21:08:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:08:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:08:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:08:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:08:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:08:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:08:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:08:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:08:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:08:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:08:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:08:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=486500) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=486500) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.08it/s]
(EngineCore_DP0 pid=486500) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.51it/s]
(EngineCore_DP0 pid=486500) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]
(EngineCore_DP0 pid=486500) 
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=486500) [2026-01-25 21:08:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=486500) 2026-01-25 21:08:29,511 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=486500) 2026-01-25 21:08:29,525 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=486500) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 24.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 24.21it/s]
(EngineCore_DP0 pid=486500) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.03it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  18%|█▊        | 47/256 [00:00<00:00, 460.45it/s]
Adding requests:  41%|████      | 104/256 [00:00<00:00, 522.55it/s]
Adding requests:  64%|██████▎   | 163/256 [00:00<00:00, 550.44it/s]
Adding requests:  87%|████████▋ | 223/256 [00:00<00:00, 569.59it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 553.98it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:04, 54.42it/s, est. speed input: 55734.21 toks/s, output: 54.43 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:08, 28.71it/s, est. speed input: 32261.20 toks/s, output: 31.50 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:09, 24.55it/s, est. speed input: 28268.13 toks/s, output: 27.61 toks/s]
Processed prompts:   9%|▉         | 23/256 [00:00<00:09, 25.27it/s, est. speed input: 28284.34 toks/s, output: 27.62 toks/s]
Processed prompts:  10%|█         | 26/256 [00:01<00:11, 20.83it/s, est. speed input: 25389.55 toks/s, output: 24.79 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:01<00:10, 22.35it/s, est. speed input: 25680.38 toks/s, output: 25.08 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:01<00:11, 19.09it/s, est. speed input: 23870.59 toks/s, output: 23.31 toks/s]
Processed prompts:  14%|█▎        | 35/256 [00:01<00:10, 20.94it/s, est. speed input: 24194.78 toks/s, output: 23.63 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:01<00:11, 18.25it/s, est. speed input: 22922.70 toks/s, output: 22.39 toks/s]
Processed prompts:  16%|█▌        | 41/256 [00:01<00:10, 20.27it/s, est. speed input: 23249.48 toks/s, output: 22.70 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:02<00:11, 17.84it/s, est. speed input: 22280.89 toks/s, output: 21.76 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:02<00:11, 17.99it/s, est. speed input: 22113.40 toks/s, output: 21.59 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:02<00:11, 18.11it/s, est. speed input: 21959.52 toks/s, output: 21.44 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:02<00:11, 18.20it/s, est. speed input: 21818.93 toks/s, output: 21.31 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:11, 18.28it/s, est. speed input: 21692.54 toks/s, output: 21.18 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:11, 18.32it/s, est. speed input: 21574.10 toks/s, output: 21.07 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:10, 18.37it/s, est. speed input: 21467.12 toks/s, output: 20.96 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:10, 18.41it/s, est. speed input: 21369.13 toks/s, output: 20.87 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:10, 18.43it/s, est. speed input: 21277.22 toks/s, output: 20.78 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:02<00:10, 18.46it/s, est. speed input: 21193.96 toks/s, output: 20.70 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:03<00:10, 18.48it/s, est. speed input: 21116.62 toks/s, output: 20.62 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:03<00:10, 18.48it/s, est. speed input: 21043.42 toks/s, output: 20.55 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:03<00:10, 18.50it/s, est. speed input: 20975.98 toks/s, output: 20.48 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:03<00:10, 18.49it/s, est. speed input: 20911.61 toks/s, output: 20.42 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:09, 18.47it/s, est. speed input: 20848.90 toks/s, output: 20.36 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:03<00:09, 18.47it/s, est. speed input: 20791.00 toks/s, output: 20.30 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:09, 18.49it/s, est. speed input: 20739.30 toks/s, output: 20.25 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 18.50it/s, est. speed input: 20689.30 toks/s, output: 20.20 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:09, 18.51it/s, est. speed input: 20642.84 toks/s, output: 20.16 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:04<00:09, 18.51it/s, est. speed input: 20598.32 toks/s, output: 20.12 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:04<00:09, 18.52it/s, est. speed input: 20556.75 toks/s, output: 20.07 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:04<00:09, 18.52it/s, est. speed input: 20516.67 toks/s, output: 20.04 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:04<00:09, 18.52it/s, est. speed input: 20478.37 toks/s, output: 20.00 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:04<00:08, 18.49it/s, est. speed input: 20439.60 toks/s, output: 19.96 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:04<00:08, 18.48it/s, est. speed input: 20403.37 toks/s, output: 19.93 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:08, 18.46it/s, est. speed input: 20368.11 toks/s, output: 19.89 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 18.46it/s, est. speed input: 20335.41 toks/s, output: 19.86 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:04<00:08, 18.46it/s, est. speed input: 20304.18 toks/s, output: 19.83 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:05<00:08, 18.47it/s, est. speed input: 20274.48 toks/s, output: 19.80 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:05<00:08, 18.48it/s, est. speed input: 20246.94 toks/s, output: 19.77 toks/s]
Processed prompts:  41%|████      | 104/256 [00:05<00:08, 18.48it/s, est. speed input: 20219.87 toks/s, output: 19.75 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:05<00:08, 18.48it/s, est. speed input: 20193.50 toks/s, output: 19.72 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:05<00:08, 18.47it/s, est. speed input: 20167.75 toks/s, output: 19.69 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:05<00:07, 18.46it/s, est. speed input: 20142.97 toks/s, output: 19.67 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:07, 18.46it/s, est. speed input: 20119.13 toks/s, output: 19.65 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:07, 18.48it/s, est. speed input: 20097.89 toks/s, output: 19.63 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:05<00:07, 18.49it/s, est. speed input: 20077.27 toks/s, output: 19.61 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:06<00:07, 18.50it/s, est. speed input: 20057.43 toks/s, output: 19.59 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:06<00:07, 18.52it/s, est. speed input: 20038.76 toks/s, output: 19.57 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:06<00:07, 18.52it/s, est. speed input: 20020.05 toks/s, output: 19.55 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:06<00:07, 18.52it/s, est. speed input: 20001.98 toks/s, output: 19.53 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:06<00:07, 18.52it/s, est. speed input: 19984.85 toks/s, output: 19.52 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:06<00:06, 18.49it/s, est. speed input: 19966.37 toks/s, output: 19.50 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:06<00:06, 18.48it/s, est. speed input: 19948.74 toks/s, output: 19.48 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:06<00:06, 18.47it/s, est. speed input: 19932.13 toks/s, output: 19.46 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:06<00:06, 18.46it/s, est. speed input: 19915.62 toks/s, output: 19.45 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:06, 18.45it/s, est. speed input: 19899.34 toks/s, output: 19.43 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:07<00:06, 18.45it/s, est. speed input: 19884.02 toks/s, output: 19.42 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:07<00:06, 18.46it/s, est. speed input: 19869.77 toks/s, output: 19.40 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:07<00:06, 18.48it/s, est. speed input: 19856.51 toks/s, output: 19.39 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:07<00:06, 18.50it/s, est. speed input: 19843.66 toks/s, output: 19.38 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:07<00:05, 18.48it/s, est. speed input: 19829.72 toks/s, output: 19.36 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:07<00:05, 18.48it/s, est. speed input: 19817.21 toks/s, output: 19.35 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:07<00:05, 18.46it/s, est. speed input: 19803.78 toks/s, output: 19.34 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:07<00:05, 18.47it/s, est. speed input: 19791.69 toks/s, output: 19.33 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:07<00:05, 18.46it/s, est. speed input: 19779.43 toks/s, output: 19.32 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:08<00:05, 18.46it/s, est. speed input: 19767.59 toks/s, output: 19.30 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:08<00:05, 18.46it/s, est. speed input: 19756.40 toks/s, output: 19.29 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:08<00:05, 18.46it/s, est. speed input: 19745.22 toks/s, output: 19.28 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:08<00:05, 18.47it/s, est. speed input: 19734.55 toks/s, output: 19.27 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:08<00:04, 18.46it/s, est. speed input: 19723.75 toks/s, output: 19.26 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:08<00:04, 18.46it/s, est. speed input: 19713.26 toks/s, output: 19.25 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:08<00:04, 18.45it/s, est. speed input: 19702.98 toks/s, output: 19.24 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:08<00:04, 18.44it/s, est. speed input: 19692.75 toks/s, output: 19.23 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:08<00:04, 18.45it/s, est. speed input: 19683.06 toks/s, output: 19.22 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:09<00:04, 18.44it/s, est. speed input: 19673.36 toks/s, output: 19.21 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:09<00:04, 18.44it/s, est. speed input: 19664.05 toks/s, output: 19.20 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:09<00:04, 18.46it/s, est. speed input: 19655.54 toks/s, output: 19.19 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:09<00:04, 18.48it/s, est. speed input: 19647.74 toks/s, output: 19.19 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:09<00:04, 18.47it/s, est. speed input: 19639.12 toks/s, output: 19.18 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:09<00:03, 18.47it/s, est. speed input: 19631.04 toks/s, output: 19.17 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:09<00:03, 18.47it/s, est. speed input: 19623.07 toks/s, output: 19.16 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:09<00:03, 18.48it/s, est. speed input: 19615.43 toks/s, output: 19.16 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:09<00:03, 18.47it/s, est. speed input: 19607.50 toks/s, output: 19.15 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:10<00:03, 18.46it/s, est. speed input: 19599.85 toks/s, output: 19.14 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:10<00:03, 18.47it/s, est. speed input: 19592.65 toks/s, output: 19.13 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:10<00:03, 18.48it/s, est. speed input: 19585.97 toks/s, output: 19.13 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:10<00:03, 18.48it/s, est. speed input: 19579.09 toks/s, output: 19.12 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:10<00:03, 18.47it/s, est. speed input: 19572.03 toks/s, output: 19.11 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:10<00:02, 18.46it/s, est. speed input: 19564.86 toks/s, output: 19.11 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:10<00:02, 18.44it/s, est. speed input: 19557.50 toks/s, output: 19.10 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:10<00:02, 18.44it/s, est. speed input: 19550.78 toks/s, output: 19.09 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:10<00:02, 18.45it/s, est. speed input: 19544.25 toks/s, output: 19.09 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:11<00:02, 18.44it/s, est. speed input: 19537.74 toks/s, output: 19.08 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:11<00:02, 18.44it/s, est. speed input: 19531.26 toks/s, output: 19.07 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:11<00:02, 18.44it/s, est. speed input: 19524.91 toks/s, output: 19.07 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:11<00:02, 18.44it/s, est. speed input: 19518.87 toks/s, output: 19.06 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:11<00:02, 18.45it/s, est. speed input: 19513.19 toks/s, output: 19.06 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:11<00:01, 18.44it/s, est. speed input: 19506.95 toks/s, output: 19.05 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:11<00:01, 18.44it/s, est. speed input: 19501.17 toks/s, output: 19.04 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:11<00:01, 18.45it/s, est. speed input: 19495.76 toks/s, output: 19.04 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:11<00:01, 18.45it/s, est. speed input: 19490.30 toks/s, output: 19.03 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:11<00:01, 18.45it/s, est. speed input: 19484.78 toks/s, output: 19.03 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:12<00:01, 18.45it/s, est. speed input: 19479.66 toks/s, output: 19.02 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:12<00:01, 18.46it/s, est. speed input: 19474.71 toks/s, output: 19.02 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:12<00:01, 18.45it/s, est. speed input: 19469.34 toks/s, output: 19.01 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:12<00:01, 18.48it/s, est. speed input: 19465.14 toks/s, output: 19.01 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:12<00:00, 18.48it/s, est. speed input: 19460.38 toks/s, output: 19.00 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:12<00:00, 18.47it/s, est. speed input: 19455.67 toks/s, output: 19.00 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:12<00:00, 18.47it/s, est. speed input: 19450.89 toks/s, output: 18.99 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:12<00:00, 18.46it/s, est. speed input: 19446.08 toks/s, output: 18.99 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:12<00:00, 18.47it/s, est. speed input: 19441.82 toks/s, output: 18.99 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:13<00:00, 18.45it/s, est. speed input: 19437.02 toks/s, output: 18.98 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:13<00:00, 18.45it/s, est. speed input: 19432.50 toks/s, output: 18.98 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:13<00:00, 18.44it/s, est. speed input: 19427.65 toks/s, output: 18.97 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:13<00:00, 18.44it/s, est. speed input: 19423.35 toks/s, output: 18.97 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 18.44it/s, est. speed input: 19496.39 toks/s, output: 19.04 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 19.04it/s, est. speed input: 19496.39 toks/s, output: 19.04 toks/s]
[rank0]:[W125 21:08:44.663912071 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 37.5s

测试结果:
  Requests/s:   18.41
  Tokens/s:     18865.77
  Total Reqs:   256
  Elapsed:      13.91s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     18847.37

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:08:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=487302) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=487302) WARNING 01-25 21:09:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.58 requests/s, 19044.47 total tokens/s, 18.58 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 21:08:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:08:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:08:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:08:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:08:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:08:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:08:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:08:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:08:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:08:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:08:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:08:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:08:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:08:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=487302) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=487302) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=487302) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.50it/s]
(EngineCore_DP0 pid=487302) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]
(EngineCore_DP0 pid=487302) 
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=487302) [2026-01-25 21:08:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=487302) 2026-01-25 21:09:07,765 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=487302) 2026-01-25 21:09:07,779 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=487302) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 28.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 26.09it/s]
(EngineCore_DP0 pid=487302) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 15.51it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 51/512 [00:00<00:00, 502.86it/s]
Adding requests:  21%|██        | 107/512 [00:00<00:00, 534.14it/s]
Adding requests:  32%|███▏      | 163/512 [00:00<00:00, 541.57it/s]
Adding requests:  44%|████▍     | 224/512 [00:00<00:00, 567.26it/s]
Adding requests:  55%|█████▌    | 283/512 [00:00<00:00, 573.78it/s]
Adding requests:  67%|██████▋   | 343/512 [00:00<00:00, 579.80it/s]
Adding requests:  79%|███████▉  | 404/512 [00:00<00:00, 585.89it/s]
Adding requests:  90%|█████████ | 463/512 [00:00<00:00, 582.79it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 576.36it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 14/512 [00:00<00:03, 131.06it/s, est. speed input: 134221.02 toks/s, output: 131.07 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:00<00:14, 33.21it/s, est. speed input: 38298.56 toks/s, output: 37.40 toks/s]   
Processed prompts:   7%|▋         | 35/512 [00:01<00:18, 25.46it/s, est. speed input: 30470.70 toks/s, output: 29.76 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:01<00:18, 24.95it/s, est. speed input: 29465.73 toks/s, output: 28.78 toks/s]
Processed prompts:   9%|▊         | 44/512 [00:01<00:20, 23.32it/s, est. speed input: 28091.56 toks/s, output: 27.43 toks/s]
Processed prompts:   9%|▉         | 47/512 [00:01<00:22, 20.79it/s, est. speed input: 26474.29 toks/s, output: 25.85 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:02<00:24, 18.89it/s, est. speed input: 25195.36 toks/s, output: 24.60 toks/s]
Processed prompts:  11%|█         | 54/512 [00:02<00:24, 18.84it/s, est. speed input: 24622.80 toks/s, output: 24.05 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:02<00:24, 18.80it/s, est. speed input: 24147.11 toks/s, output: 23.58 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:02<00:23, 18.76it/s, est. speed input: 23743.55 toks/s, output: 23.19 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:23, 18.74it/s, est. speed input: 23403.43 toks/s, output: 22.85 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:03<00:23, 18.73it/s, est. speed input: 23109.98 toks/s, output: 22.57 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:03<00:23, 18.71it/s, est. speed input: 22852.43 toks/s, output: 22.32 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:03<00:23, 18.72it/s, est. speed input: 22630.26 toks/s, output: 22.10 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:03<00:22, 18.71it/s, est. speed input: 22429.64 toks/s, output: 21.90 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:22, 18.70it/s, est. speed input: 22252.18 toks/s, output: 21.73 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:04<00:22, 18.68it/s, est. speed input: 22089.44 toks/s, output: 21.57 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:04<00:22, 18.69it/s, est. speed input: 21946.12 toks/s, output: 21.43 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:04<00:22, 18.70it/s, est. speed input: 21817.46 toks/s, output: 21.31 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:04<00:21, 18.70it/s, est. speed input: 21698.81 toks/s, output: 21.19 toks/s]
Processed prompts:  21%|██        | 106/512 [00:05<00:21, 18.70it/s, est. speed input: 21589.79 toks/s, output: 21.08 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:05<00:21, 18.69it/s, est. speed input: 21488.54 toks/s, output: 20.98 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:05<00:21, 18.68it/s, est. speed input: 21395.52 toks/s, output: 20.89 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:05<00:21, 18.68it/s, est. speed input: 21310.15 toks/s, output: 20.81 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:05<00:20, 18.68it/s, est. speed input: 21230.62 toks/s, output: 20.73 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:06<00:20, 18.68it/s, est. speed input: 21156.18 toks/s, output: 20.66 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:06<00:20, 18.67it/s, est. speed input: 21086.55 toks/s, output: 20.59 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:06<00:20, 18.68it/s, est. speed input: 21023.33 toks/s, output: 20.53 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:06<00:20, 18.67it/s, est. speed input: 20962.12 toks/s, output: 20.47 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:06<00:19, 18.67it/s, est. speed input: 20904.55 toks/s, output: 20.41 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:07<00:19, 18.67it/s, est. speed input: 20851.32 toks/s, output: 20.36 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:07<00:19, 18.67it/s, est. speed input: 20800.80 toks/s, output: 20.31 toks/s]
Processed prompts:  30%|███       | 154/512 [00:07<00:19, 18.67it/s, est. speed input: 20754.07 toks/s, output: 20.27 toks/s]
Processed prompts:  31%|███       | 158/512 [00:07<00:18, 18.67it/s, est. speed input: 20708.91 toks/s, output: 20.22 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:08<00:18, 18.67it/s, est. speed input: 20666.39 toks/s, output: 20.18 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:08<00:18, 18.66it/s, est. speed input: 20625.43 toks/s, output: 20.14 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:08<00:18, 18.66it/s, est. speed input: 20586.87 toks/s, output: 20.10 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:08<00:18, 18.65it/s, est. speed input: 20549.26 toks/s, output: 20.07 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:08<00:17, 18.65it/s, est. speed input: 20514.63 toks/s, output: 20.03 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:09<00:17, 18.65it/s, est. speed input: 20481.15 toks/s, output: 20.00 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:09<00:17, 18.65it/s, est. speed input: 20449.18 toks/s, output: 19.97 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:09<00:17, 18.66it/s, est. speed input: 20419.70 toks/s, output: 19.94 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:09<00:17, 18.66it/s, est. speed input: 20390.44 toks/s, output: 19.91 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:09<00:16, 18.66it/s, est. speed input: 20363.38 toks/s, output: 19.89 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:10<00:16, 18.66it/s, est. speed input: 20336.80 toks/s, output: 19.86 toks/s]
Processed prompts:  40%|████      | 206/512 [00:10<00:16, 18.66it/s, est. speed input: 20311.23 toks/s, output: 19.84 toks/s]
Processed prompts:  41%|████      | 210/512 [00:10<00:16, 18.66it/s, est. speed input: 20286.90 toks/s, output: 19.81 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:10<00:15, 18.65it/s, est. speed input: 20263.06 toks/s, output: 19.79 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:11<00:15, 18.64it/s, est. speed input: 20239.88 toks/s, output: 19.77 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:11<00:15, 18.65it/s, est. speed input: 20218.18 toks/s, output: 19.74 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:11<00:15, 18.64it/s, est. speed input: 20196.52 toks/s, output: 19.72 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:11<00:15, 18.63it/s, est. speed input: 20175.66 toks/s, output: 19.70 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:11<00:14, 18.64it/s, est. speed input: 20156.15 toks/s, output: 19.68 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:12<00:14, 18.65it/s, est. speed input: 20137.71 toks/s, output: 19.67 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:12<00:14, 18.64it/s, est. speed input: 20119.46 toks/s, output: 19.65 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:12<00:14, 18.64it/s, est. speed input: 20101.84 toks/s, output: 19.63 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:12<00:14, 18.64it/s, est. speed input: 20084.76 toks/s, output: 19.61 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:12<00:13, 18.64it/s, est. speed input: 20068.32 toks/s, output: 19.60 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:13<00:13, 18.64it/s, est. speed input: 20052.33 toks/s, output: 19.58 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:13<00:13, 18.64it/s, est. speed input: 20036.94 toks/s, output: 19.57 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:13<00:13, 18.65it/s, est. speed input: 20022.23 toks/s, output: 19.55 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:13<00:12, 18.63it/s, est. speed input: 20006.86 toks/s, output: 19.54 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:14<00:12, 18.63it/s, est. speed input: 19992.82 toks/s, output: 19.52 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:14<00:12, 18.63it/s, est. speed input: 19979.07 toks/s, output: 19.51 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:14<00:12, 18.62it/s, est. speed input: 19965.30 toks/s, output: 19.50 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:14<00:12, 18.61it/s, est. speed input: 19951.50 toks/s, output: 19.48 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:14<00:11, 18.61it/s, est. speed input: 19938.79 toks/s, output: 19.47 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:15<00:11, 18.62it/s, est. speed input: 19926.80 toks/s, output: 19.46 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:15<00:11, 18.62it/s, est. speed input: 19914.49 toks/s, output: 19.45 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:15<00:11, 18.62it/s, est. speed input: 19902.94 toks/s, output: 19.44 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:15<00:11, 18.62it/s, est. speed input: 19891.66 toks/s, output: 19.43 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:15<00:10, 18.63it/s, est. speed input: 19880.72 toks/s, output: 19.41 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:16<00:10, 18.63it/s, est. speed input: 19870.17 toks/s, output: 19.40 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:16<00:10, 18.63it/s, est. speed input: 19859.94 toks/s, output: 19.39 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:16<00:10, 18.62it/s, est. speed input: 19849.29 toks/s, output: 19.38 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:16<00:09, 18.62it/s, est. speed input: 19839.11 toks/s, output: 19.37 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:17<00:09, 18.61it/s, est. speed input: 19829.14 toks/s, output: 19.36 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:17<00:09, 18.62it/s, est. speed input: 19819.82 toks/s, output: 19.36 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:17<00:09, 18.61it/s, est. speed input: 19810.21 toks/s, output: 19.35 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:17<00:09, 18.61it/s, est. speed input: 19801.08 toks/s, output: 19.34 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:17<00:08, 18.61it/s, est. speed input: 19792.20 toks/s, output: 19.33 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:18<00:08, 18.61it/s, est. speed input: 19783.46 toks/s, output: 19.32 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:18<00:08, 18.61it/s, est. speed input: 19774.82 toks/s, output: 19.31 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:18<00:08, 18.61it/s, est. speed input: 19766.59 toks/s, output: 19.30 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:18<00:08, 18.60it/s, est. speed input: 19758.12 toks/s, output: 19.30 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:18<00:07, 18.61it/s, est. speed input: 19750.41 toks/s, output: 19.29 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:19<00:07, 18.62it/s, est. speed input: 19742.90 toks/s, output: 19.28 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:19<00:07, 18.61it/s, est. speed input: 19734.95 toks/s, output: 19.27 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:19<00:07, 18.61it/s, est. speed input: 19727.77 toks/s, output: 19.27 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:19<00:06, 18.62it/s, est. speed input: 19720.66 toks/s, output: 19.26 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:20<00:06, 18.61it/s, est. speed input: 19713.45 toks/s, output: 19.25 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:20<00:06, 18.61it/s, est. speed input: 19706.38 toks/s, output: 19.24 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:20<00:06, 18.61it/s, est. speed input: 19699.57 toks/s, output: 19.24 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:20<00:06, 18.59it/s, est. speed input: 19692.34 toks/s, output: 19.23 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:20<00:05, 18.60it/s, est. speed input: 19685.96 toks/s, output: 19.22 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:21<00:05, 18.61it/s, est. speed input: 19679.62 toks/s, output: 19.22 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:21<00:05, 18.61it/s, est. speed input: 19673.29 toks/s, output: 19.21 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:21<00:05, 18.60it/s, est. speed input: 19666.99 toks/s, output: 19.21 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:21<00:05, 18.60it/s, est. speed input: 19660.72 toks/s, output: 19.20 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:21<00:04, 18.61it/s, est. speed input: 19655.13 toks/s, output: 19.19 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:22<00:04, 18.61it/s, est. speed input: 19649.37 toks/s, output: 19.19 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:22<00:04, 18.62it/s, est. speed input: 19643.84 toks/s, output: 19.18 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:22<00:04, 18.61it/s, est. speed input: 19638.08 toks/s, output: 19.18 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:22<00:03, 18.61it/s, est. speed input: 19632.54 toks/s, output: 19.17 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:23<00:03, 18.61it/s, est. speed input: 19627.12 toks/s, output: 19.17 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:23<00:03, 18.61it/s, est. speed input: 19621.80 toks/s, output: 19.16 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:23<00:03, 18.59it/s, est. speed input: 19616.14 toks/s, output: 19.16 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:23<00:03, 18.58it/s, est. speed input: 19610.63 toks/s, output: 19.15 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:23<00:02, 18.60it/s, est. speed input: 19605.78 toks/s, output: 19.15 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:24<00:02, 18.60it/s, est. speed input: 19600.88 toks/s, output: 19.14 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:24<00:02, 18.60it/s, est. speed input: 19596.03 toks/s, output: 19.14 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:24<00:02, 18.60it/s, est. speed input: 19591.16 toks/s, output: 19.13 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:24<00:02, 18.59it/s, est. speed input: 19586.18 toks/s, output: 19.13 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:24<00:01, 18.59it/s, est. speed input: 19581.51 toks/s, output: 19.12 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:25<00:01, 18.60it/s, est. speed input: 19577.06 toks/s, output: 19.12 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:25<00:01, 18.60it/s, est. speed input: 19572.72 toks/s, output: 19.11 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:25<00:01, 18.60it/s, est. speed input: 19568.10 toks/s, output: 19.11 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:25<00:00, 18.59it/s, est. speed input: 19563.55 toks/s, output: 19.11 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:26<00:00, 18.58it/s, est. speed input: 19558.94 toks/s, output: 19.10 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:26<00:00, 18.58it/s, est. speed input: 19554.68 toks/s, output: 19.10 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:26<00:00, 18.59it/s, est. speed input: 19550.67 toks/s, output: 19.09 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:26<00:00, 20.00it/s, est. speed input: 19583.53 toks/s, output: 19.12 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:26<00:00, 20.00it/s, est. speed input: 19660.26 toks/s, output: 19.20 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:26<00:00, 19.20it/s, est. speed input: 19660.26 toks/s, output: 19.20 toks/s]
[rank0]:[W125 21:09:36.727699989 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 52.0s

测试结果:
  Requests/s:   18.58
  Tokens/s:     19044.47
  Total Reqs:   512
  Elapsed:      27.56s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     19025.89

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:09:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=488321) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488321) WARNING 01-25 21:09:56 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     kernel_warmup(self)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     runner._dummy_run(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     def forward(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     raise e
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/tmp/torchinductor_root/gv/cgvqchyzae4gcuaf7y34t7pu2lihpiph46itm7ym36xpx763bn6w.py", line 958, in call
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) ERROR 01-25 21:10:01 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 94.94 MiB is free. Including non-PyTorch memory, this process has 15.15 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:09:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:09:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:09:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:09:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:09:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:09:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:09:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:09:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:09:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:09:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:09:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:09:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:09:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:09:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:09:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:09:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:09:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=488321) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=488321) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.96it/s]
(EngineCore_DP0 pid=488321) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.43it/s]
(EngineCore_DP0 pid=488321) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.49it/s]
(EngineCore_DP0 pid=488321) 
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=488321) [2026-01-25 21:09:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=488321) 2026-01-25 21:10:01,847 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=488321) 2026-01-25 21:10:01,876 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=488321) Process EngineCore_DP0:
(EngineCore_DP0 pid=488321) Traceback (most recent call last):
(EngineCore_DP0 pid=488321)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=488321)     self.run()
(EngineCore_DP0 pid=488321)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=488321)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=488321)     raise e
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488321)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488321)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488321)     super().__init__(
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488321)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488321)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=488321)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=488321)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488321)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488321)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488321)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 455, in compile_or_warm_up_model
(EngineCore_DP0 pid=488321)     kernel_warmup(self)
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 41, in kernel_warmup
(EngineCore_DP0 pid=488321)     flashinfer_autotune(worker.model_runner)
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/model_executor/warmup/kernel_warmup.py", line 94, in flashinfer_autotune
(EngineCore_DP0 pid=488321)     runner._dummy_run(
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488321)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488321)     outputs = self.model(
(EngineCore_DP0 pid=488321)               ^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488321)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488321)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488321)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488321)     hidden_states = self.model(
(EngineCore_DP0 pid=488321)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=488321)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=488321)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=488321)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=488321)     def forward(
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488321)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=488321)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=488321)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=488321)     raise e
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=488321)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488321)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488321)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "<eval_with_key>.58", line 332, in forward
(EngineCore_DP0 pid=488321)     submod_4 = self.submod_4(getitem_8, s72, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_, getitem_9, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_8 = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_post_attention_layernorm_parameters_weight_ = getitem_9 = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=488321)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488321)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=488321)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=488321)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488321)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=488321)     return compiled_fn(full_args)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=488321)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=488321)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=488321)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=488321)                             ^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=488321)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=488321)     return self.current_callable(inputs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=488321)     out = model(new_inputs)
(EngineCore_DP0 pid=488321)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/tmp/torchinductor_root/gv/cgvqchyzae4gcuaf7y34t7pu2lihpiph46itm7ym36xpx763bn6w.py", line 958, in call
(EngineCore_DP0 pid=488321)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=488321)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=488321)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=488321)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=488321)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=488321)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=488321)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488321) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 94.94 MiB is free. Including non-PyTorch memory, this process has 15.15 GiB memory in use. Of the allocated memory 11.77 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:10:02.164234253 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=8192 (exit code: 1)

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:10:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=488981) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488981) WARNING 01-25 21:10:25 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     def forward(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     raise e
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/tmp/torchinductor_root/42/c424begxyaqtjc3ez64touk2oxkoe2uah7ehpgcf2nvt677rsosm.py", line 1078, in call
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) ERROR 01-25 21:10:29 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 604.94 MiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 11.02 GiB is allocated by PyTorch, and 3.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:10:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:10:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:10:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:10:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:10:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:10:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:10:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:10:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:10:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:10:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:10:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:10:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=488981) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=488981) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.99it/s]
(EngineCore_DP0 pid=488981) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.46it/s]
(EngineCore_DP0 pid=488981) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.52it/s]
(EngineCore_DP0 pid=488981) 
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=488981) [2026-01-25 21:10:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=488981) [rank0]:W0125 21:10:28.460000 488981 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=488981) [rank0]:W0125 21:10:28.509000 488981 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=488981) [rank0]:W0125 21:10:29.065000 488981 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=488981) [rank0]:W0125 21:10:29.141000 488981 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=488981) Process EngineCore_DP0:
(EngineCore_DP0 pid=488981) Traceback (most recent call last):
(EngineCore_DP0 pid=488981)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=488981)     self.run()
(EngineCore_DP0 pid=488981)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=488981)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=488981)     raise e
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488981)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488981)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488981)     super().__init__(
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488981)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488981)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=488981)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=488981)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=488981)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488981)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488981)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488981)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488981)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=488981)     self.model_runner.profile_run()
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=488981)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=488981)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488981)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488981)     outputs = self.model(
(EngineCore_DP0 pid=488981)               ^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488981)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488981)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488981)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488981)     hidden_states = self.model(
(EngineCore_DP0 pid=488981)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=488981)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=488981)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=488981)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=488981)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=488981)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=488981)     def forward(
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488981)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=488981)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=488981)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=488981)     raise e
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=488981)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488981)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488981)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=488981)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=488981)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=488981)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=488981)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=488981)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=488981)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=488981)     return compiled_fn(full_args)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=488981)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=488981)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=488981)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=488981)                             ^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=488981)     outs = compiled_fn(args)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=488981)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=488981)     return self.current_callable(inputs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=488981)     out = model(new_inputs)
(EngineCore_DP0 pid=488981)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/tmp/torchinductor_root/42/c424begxyaqtjc3ez64touk2oxkoe2uah7ehpgcf2nvt677rsosm.py", line 1078, in call
(EngineCore_DP0 pid=488981)     buf14 = torch.ops.slidesparse.dequant_bias.default(reinterpret_tensor(buf13, (s72, 37888), (37888, 1), 0), reinterpret_tensor(buf11, (s72, ), (1, ), 0), arg7_1, None, 'bfloat16', 'Qwen2.5-7B-INT8')
(EngineCore_DP0 pid=488981)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=488981)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/slidesparse/core/kernels.py", line 483, in _dequant_bias_impl
(EngineCore_DP0 pid=488981)     return fn(gemm_output, scale_a, scale_b, bias, out_dtype)
(EngineCore_DP0 pid=488981)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981)   File "/root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/build/RTX5080_cc120_py312_cu129_x86_64/dequant_bias_tuned_Qwen2.5-7B.py", line 110, in dequant_bias_triton
(EngineCore_DP0 pid=488981)     output = torch.empty((M, N), dtype=torch.bfloat16, device=gemm_output.device)
(EngineCore_DP0 pid=488981)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488981) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.46 GiB of which 604.94 MiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 11.02 GiB is allocated by PyTorch, and 3.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:10:29.486642106 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=16384 (exit code: 1)

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:10:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=489700) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=489700) WARNING 01-25 21:10:59 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=489700) ERROR 01-25 21:11:03 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 10.52 GiB is allocated by PyTorch, and 3.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:10:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:10:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:10:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:10:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:10:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:10:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:10:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:10:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:10:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:10:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:10:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:10:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:10:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:10:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=489700) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=489700) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.00it/s]
(EngineCore_DP0 pid=489700) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.48it/s]
(EngineCore_DP0 pid=489700) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=489700) 
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=489700) [2026-01-25 21:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=489700) [rank0]:W0125 21:11:02.560000 489700 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=489700) [rank0]:W0125 21:11:02.608000 489700 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=489700) [rank0]:W0125 21:11:03.172000 489700 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=489700) [rank0]:W0125 21:11:03.249000 489700 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=489700) Process EngineCore_DP0:
(EngineCore_DP0 pid=489700) Traceback (most recent call last):
(EngineCore_DP0 pid=489700)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=489700)     self.run()
(EngineCore_DP0 pid=489700)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=489700)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=489700)     raise e
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=489700)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=489700)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=489700)     super().__init__(
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=489700)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=489700)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=489700)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=489700)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=489700)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=489700)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=489700)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=489700)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489700)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=489700)     self.model_runner.profile_run()
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=489700)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=489700)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489700)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=489700)     outputs = self.model(
(EngineCore_DP0 pid=489700)               ^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=489700)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489700)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489700)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=489700)     hidden_states = self.model(
(EngineCore_DP0 pid=489700)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=489700)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=489700)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=489700)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=489700)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=489700)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=489700)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=489700)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=489700)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=489700)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=489700)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=489700)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=489700)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=489700)     return self._compile_to_module()
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=489700)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=489700)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=489700)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=489700)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=489700)     return self._generate(is_inference)
(EngineCore_DP0 pid=489700)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=489700)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=489700)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=489700)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=489700) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 15.46 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 10.52 GiB is allocated by PyTorch, and 3.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:11:03.599702372 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=32768 (exit code: 1)

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:11:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=490641) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=490641) WARNING 01-25 21:11:48 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=490641) ERROR 01-25 21:11:52 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 668.94 MiB is free. Including non-PyTorch memory, this process has 14.59 GiB memory in use. Of the allocated memory 11.61 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)


─── STDERR ───
[2026-01-25 21:11:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:11:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:11:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:11:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:11:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:11:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:11:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:11:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:11:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:11:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:11:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:11:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:11:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:11:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:11:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:11:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:11:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=490641) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=490641) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=490641) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.45it/s]
(EngineCore_DP0 pid=490641) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.51it/s]
(EngineCore_DP0 pid=490641) 
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=490641) [2026-01-25 21:11:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=490641) [rank0]:W0125 21:11:51.150000 490641 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=490641) [rank0]:W0125 21:11:51.902000 490641 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=490641) Process EngineCore_DP0:
(EngineCore_DP0 pid=490641) Traceback (most recent call last):
(EngineCore_DP0 pid=490641)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=490641)     self.run()
(EngineCore_DP0 pid=490641)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=490641)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=490641)     raise e
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=490641)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=490641)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=490641)     super().__init__(
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=490641)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=490641)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=490641)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=490641)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=490641)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=490641)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=490641)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=490641)     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=490641)     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=490641)     self.model_runner.profile_run()
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=490641)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=490641)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=490641)     return func(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=490641)     outputs = self.model(
(EngineCore_DP0 pid=490641)               ^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=490641)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=490641)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=490641)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=490641)     hidden_states = self.model(
(EngineCore_DP0 pid=490641)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=490641)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=490641)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=490641)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=490641)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=490641)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=490641)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=490641)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=490641)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=490641)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=490641)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=490641)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=490641)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=490641)     return self._compile_to_module()
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=490641)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=490641)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=490641)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=490641)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=490641)     return self._generate(is_inference)
(EngineCore_DP0 pid=490641)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=490641)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=490641)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=490641)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=490641) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 15.46 GiB of which 668.94 MiB is free. Including non-PyTorch memory, this process has 14.59 GiB memory in use. Of the allocated memory 11.61 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 21:11:52.313076888 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,31.8387,16333.2346,4.0203
1024,1024,1,128,128,17.7977,18242.6197,7.1919
2048,1024,2,256,128,18.4056,18865.7739,13.9088
4096,1024,4,512,128,18.5800,19044.4685,27.5566
8192,1024,8,1024,128,-1.0000,-1.0000,-1.0000
16384,1024,16,2048,128,-1.0000,-1.0000,-1.0000
32768,1024,32,4096,128,-1.0000,-1.0000,-1.0000
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 4 成功, 4 失败


============================================================
  Benchmark 完成!
============================================================


总计: 23 成功, 17 失败
============================================================
