
========== M=512 ==========
Time: 2026-01-25 16:07:59
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M512.json


========== M=16 ==========
Time: 2026-01-25 21:56:27
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:56:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=474114) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474114) WARNING 01-25 21:56:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.19 requests/s, 530.19 total tokens/s, 31.19 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-25 21:56:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:56:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:56:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:56:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:56:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:56:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:56:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:56:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:56:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:56:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:56:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:56:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:56:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:56:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:56:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:56:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:56:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=474114) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=474114) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.18it/s]
(EngineCore_DP0 pid=474114) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.18it/s]
(EngineCore_DP0 pid=474114) 
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=474114) [2026-01-25 21:56:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=474114) 2026-01-25 21:56:54,755 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=474114) 2026-01-25 21:56:54,786 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=474114) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.73it/s]
(EngineCore_DP0 pid=474114) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2555.60it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:32,  3.95it/s, est. speed input: 63.22 toks/s, output: 3.95 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 15.92it/s, est. speed input: 215.55 toks/s, output: 13.47 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 22.35it/s, est. speed input: 293.52 toks/s, output: 18.34 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 26.08it/s, est. speed input: 340.26 toks/s, output: 21.27 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 28.39it/s, est. speed input: 371.41 toks/s, output: 23.21 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 30.07it/s, est. speed input: 394.77 toks/s, output: 24.67 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.26it/s, est. speed input: 412.78 toks/s, output: 25.80 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.09it/s, est. speed input: 426.93 toks/s, output: 26.68 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.63it/s, est. speed input: 438.19 toks/s, output: 27.39 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.04it/s, est. speed input: 447.59 toks/s, output: 27.97 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.31it/s, est. speed input: 455.37 toks/s, output: 28.46 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.50it/s, est. speed input: 462.01 toks/s, output: 28.87 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.35it/s, est. speed input: 466.77 toks/s, output: 29.17 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.20it/s, est. speed input: 470.76 toks/s, output: 29.42 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.15it/s, est. speed input: 474.41 toks/s, output: 29.65 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 33.13it/s, est. speed input: 477.66 toks/s, output: 29.85 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.11it/s, est. speed input: 480.52 toks/s, output: 30.03 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.10it/s, est. speed input: 483.09 toks/s, output: 30.19 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.08it/s, est. speed input: 485.39 toks/s, output: 30.34 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.08it/s, est. speed input: 487.49 toks/s, output: 30.47 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.16it/s, est. speed input: 489.58 toks/s, output: 30.60 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.37it/s, est. speed input: 491.82 toks/s, output: 30.74 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.52it/s, est. speed input: 493.88 toks/s, output: 30.87 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.66it/s, est. speed input: 495.84 toks/s, output: 30.99 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.57it/s, est. speed input: 497.29 toks/s, output: 31.08 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.58it/s, est. speed input: 498.77 toks/s, output: 31.17 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.58it/s, est. speed input: 500.13 toks/s, output: 31.26 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.50it/s, est. speed input: 501.27 toks/s, output: 31.33 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.37it/s, est. speed input: 502.21 toks/s, output: 31.39 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.34it/s, est. speed input: 503.19 toks/s, output: 31.45 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.10it/s, est. speed input: 503.75 toks/s, output: 31.48 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.15it/s, est. speed input: 504.61 toks/s, output: 31.54 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.15it/s, est. speed input: 505.44 toks/s, output: 31.59 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.59it/s, est. speed input: 505.44 toks/s, output: 31.59 toks/s]
[rank0]:[W125 21:57:01.103731339 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 21:57:03
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:57:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=475169) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=475169) WARNING 01-25 21:57:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.55 requests/s, 3940.90 total tokens/s, 30.55 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-25 21:57:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:57:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:57:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:57:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:57:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:57:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:57:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:57:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:57:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:57:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:57:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:57:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=475169) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=475169) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.91it/s]
(EngineCore_DP0 pid=475169) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.90it/s]
(EngineCore_DP0 pid=475169) 
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=475169) [2026-01-25 21:57:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=475169) 2026-01-25 21:57:31,151 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=475169) 2026-01-25 21:57:31,205 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=475169) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.28it/s]
(EngineCore_DP0 pid=475169) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1379.80it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:31,  3.99it/s, est. speed input: 511.27 toks/s, output: 3.99 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 15.94it/s, est. speed input: 1730.32 toks/s, output: 13.52 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 22.41it/s, est. speed input: 2356.54 toks/s, output: 18.41 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 26.26it/s, est. speed input: 2737.80 toks/s, output: 21.39 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 28.62it/s, est. speed input: 2990.96 toks/s, output: 23.37 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.94it/s, est. speed input: 3162.35 toks/s, output: 24.70 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 30.78it/s, est. speed input: 3289.58 toks/s, output: 25.70 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.29it/s, est. speed input: 3386.30 toks/s, output: 26.45 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 31.95it/s, est. speed input: 3474.55 toks/s, output: 27.14 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.42it/s, est. speed input: 3547.23 toks/s, output: 27.71 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.77it/s, est. speed input: 3608.97 toks/s, output: 28.19 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.00it/s, est. speed input: 3660.71 toks/s, output: 28.60 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.10it/s, est. speed input: 3703.53 toks/s, output: 28.93 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.25it/s, est. speed input: 3742.77 toks/s, output: 29.24 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.37it/s, est. speed input: 3777.66 toks/s, output: 29.51 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 33.43it/s, est. speed input: 3807.81 toks/s, output: 29.75 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.48it/s, est. speed input: 3834.90 toks/s, output: 29.96 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.38it/s, est. speed input: 3856.43 toks/s, output: 30.13 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.21it/s, est. speed input: 3873.86 toks/s, output: 30.26 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.08it/s, est. speed input: 3889.41 toks/s, output: 30.39 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.00it/s, est. speed input: 3903.63 toks/s, output: 30.50 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.93it/s, est. speed input: 3916.45 toks/s, output: 30.60 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 32.92it/s, est. speed input: 3928.69 toks/s, output: 30.69 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.82it/s, est. speed input: 3938.63 toks/s, output: 30.77 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.77it/s, est. speed input: 3948.03 toks/s, output: 30.84 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.74it/s, est. speed input: 3956.80 toks/s, output: 30.91 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.71it/s, est. speed input: 3964.80 toks/s, output: 30.97 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.67it/s, est. speed input: 3971.89 toks/s, output: 31.03 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.68it/s, est. speed input: 3979.07 toks/s, output: 31.09 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.70it/s, est. speed input: 3986.07 toks/s, output: 31.14 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.53it/s, est. speed input: 3990.13 toks/s, output: 31.17 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 32.60it/s, est. speed input: 3996.33 toks/s, output: 31.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.60it/s, est. speed input: 4000.55 toks/s, output: 31.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.25it/s, est. speed input: 4000.55 toks/s, output: 31.25 toks/s]
[rank0]:[W125 21:57:37.520439814 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 21:57:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:57:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=476213) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=476213) WARNING 01-25 21:57:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.42 requests/s, 8332.19 total tokens/s, 32.42 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-25 21:57:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:57:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:57:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:57:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:57:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:57:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:57:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:57:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:57:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:57:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:57:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:57:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:57:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:57:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=476213) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=476213) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.85it/s]
(EngineCore_DP0 pid=476213) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.85it/s]
(EngineCore_DP0 pid=476213) 
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=476213) [2026-01-25 21:57:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=476213) 2026-01-25 21:58:06,980 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=476213) 2026-01-25 21:58:07,047 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=476213) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.71it/s]
(EngineCore_DP0 pid=476213) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.75it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  72%|███████▏  | 92/128 [00:00<00:00, 916.35it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1045.03it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 42.31it/s, est. speed input: 10834.39 toks/s, output: 42.31 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:03, 36.61it/s, est. speed input: 9567.39 toks/s, output: 37.37 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:03, 35.15it/s, est. speed input: 9234.08 toks/s, output: 36.07 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:03, 34.22it/s, est. speed input: 9028.42 toks/s, output: 35.26 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:03, 33.72it/s, est. speed input: 8905.92 toks/s, output: 34.79 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:03, 33.47it/s, est. speed input: 8831.32 toks/s, output: 34.50 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 33.43it/s, est. speed input: 8790.29 toks/s, output: 34.34 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 33.46it/s, est. speed input: 8765.50 toks/s, output: 34.24 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 33.34it/s, est. speed input: 8733.06 toks/s, output: 34.11 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 33.26it/s, est. speed input: 8707.16 toks/s, output: 34.01 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 33.20it/s, est. speed input: 8685.16 toks/s, output: 33.93 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 33.15it/s, est. speed input: 8666.59 toks/s, output: 33.85 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 33.13it/s, est. speed input: 8651.75 toks/s, output: 33.80 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:02, 33.07it/s, est. speed input: 8636.34 toks/s, output: 33.74 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 33.05it/s, est. speed input: 8624.00 toks/s, output: 33.69 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 33.13it/s, est. speed input: 8618.17 toks/s, output: 33.66 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:02<00:01, 33.15it/s, est. speed input: 8611.05 toks/s, output: 33.64 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 33.06it/s, est. speed input: 8600.15 toks/s, output: 33.59 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 32.99it/s, est. speed input: 8589.69 toks/s, output: 33.55 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 32.93it/s, est. speed input: 8580.07 toks/s, output: 33.52 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 32.91it/s, est. speed input: 8572.20 toks/s, output: 33.48 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 32.91it/s, est. speed input: 8565.33 toks/s, output: 33.46 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:01, 33.16it/s, est. speed input: 8568.47 toks/s, output: 33.47 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 33.28it/s, est. speed input: 8569.61 toks/s, output: 33.47 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:03<00:00, 33.39it/s, est. speed input: 8571.21 toks/s, output: 33.48 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:03<00:00, 33.46it/s, est. speed input: 8572.91 toks/s, output: 33.49 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 33.52it/s, est. speed input: 8574.43 toks/s, output: 33.49 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 33.36it/s, est. speed input: 8569.75 toks/s, output: 33.48 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 33.50it/s, est. speed input: 8572.84 toks/s, output: 33.49 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 33.28it/s, est. speed input: 8566.60 toks/s, output: 33.46 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 33.38it/s, est. speed input: 8568.02 toks/s, output: 33.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.38it/s, est. speed input: 8569.47 toks/s, output: 33.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.47it/s, est. speed input: 8569.47 toks/s, output: 33.47 toks/s]
[rank0]:[W125 21:58:12.971907014 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16 ==========
Time: 2026-01-26 07:38:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:38:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=979703) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=979703) WARNING 01-26 07:39:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.07 requests/s, 528.22 total tokens/s, 31.07 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:38:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:38:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:38:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:38:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:38:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:38:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:38:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:38:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:38:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:39:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:39:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:39:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:39:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:39:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:39:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=979703) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=979703) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=979703) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=979703) 
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=979703) [2026-01-26 07:39:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=979703) 2026-01-26 07:39:14,066 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=979703) 2026-01-26 07:39:14,135 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=979703) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.71it/s]
(EngineCore_DP0 pid=979703) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.43it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4137.13it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:44,  2.88it/s, est. speed input: 46.14 toks/s, output: 2.88 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 13.06it/s, est. speed input: 172.48 toks/s, output: 10.78 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 19.74it/s, est. speed input: 247.71 toks/s, output: 15.48 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 24.20it/s, est. speed input: 297.63 toks/s, output: 18.60 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 27.24it/s, est. speed input: 333.20 toks/s, output: 20.82 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.41it/s, est. speed input: 360.26 toks/s, output: 22.52 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 31.00it/s, est. speed input: 381.70 toks/s, output: 23.86 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.03it/s, est. speed input: 398.55 toks/s, output: 24.91 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.57it/s, est. speed input: 411.66 toks/s, output: 25.73 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.94it/s, est. speed input: 422.55 toks/s, output: 26.41 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.20it/s, est. speed input: 431.78 toks/s, output: 26.99 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.38it/s, est. speed input: 439.65 toks/s, output: 27.48 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.54it/s, est. speed input: 446.57 toks/s, output: 27.91 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.67it/s, est. speed input: 452.66 toks/s, output: 28.29 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.69it/s, est. speed input: 457.84 toks/s, output: 28.61 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:01, 33.77it/s, est. speed input: 462.62 toks/s, output: 28.91 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.82it/s, est. speed input: 466.88 toks/s, output: 29.18 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.85it/s, est. speed input: 470.69 toks/s, output: 29.42 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.88it/s, est. speed input: 474.15 toks/s, output: 29.63 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.92it/s, est. speed input: 477.36 toks/s, output: 29.83 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.93it/s, est. speed input: 480.23 toks/s, output: 30.01 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 34.00it/s, est. speed input: 483.00 toks/s, output: 30.19 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.97it/s, est. speed input: 485.37 toks/s, output: 30.34 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.93it/s, est. speed input: 487.56 toks/s, output: 30.47 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.92it/s, est. speed input: 489.59 toks/s, output: 30.60 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.89it/s, est. speed input: 491.44 toks/s, output: 30.71 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.84it/s, est. speed input: 493.11 toks/s, output: 30.82 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.78it/s, est. speed input: 494.63 toks/s, output: 30.91 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.72it/s, est. speed input: 496.04 toks/s, output: 31.00 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.81it/s, est. speed input: 497.55 toks/s, output: 31.10 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.96it/s, est. speed input: 499.09 toks/s, output: 31.19 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.88it/s, est. speed input: 500.28 toks/s, output: 31.27 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.88it/s, est. speed input: 501.11 toks/s, output: 31.32 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.32it/s, est. speed input: 501.11 toks/s, output: 31.32 toks/s]
[rank0]:[W126 07:39:20.341192816 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 07:39:22
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:39:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=980726) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=980726) WARNING 01-26 07:39:42 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.89 requests/s, 3856.28 total tokens/s, 29.89 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 07:39:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:39:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:39:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:39:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:39:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:39:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:39:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:39:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:39:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:39:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:39:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:39:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=980726) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=980726) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.65it/s]
(EngineCore_DP0 pid=980726) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.64it/s]
(EngineCore_DP0 pid=980726) 
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=980726) [2026-01-26 07:39:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=980726) 2026-01-26 07:39:47,142 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=980726) 2026-01-26 07:39:47,187 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=980726) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.14it/s]
(EngineCore_DP0 pid=980726) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.74it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2512.21it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:53,  2.40it/s, est. speed input: 306.64 toks/s, output: 2.40 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:13,  9.31it/s, est. speed input: 979.55 toks/s, output: 7.65 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:07, 16.58it/s, est. speed input: 1595.27 toks/s, output: 12.46 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:05, 21.66it/s, est. speed input: 2017.72 toks/s, output: 15.76 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 25.27it/s, est. speed input: 2327.87 toks/s, output: 18.19 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:03, 27.70it/s, est. speed input: 2560.43 toks/s, output: 20.00 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:03, 29.39it/s, est. speed input: 2743.03 toks/s, output: 21.43 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:03, 30.60it/s, est. speed input: 2891.26 toks/s, output: 22.59 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:03, 31.41it/s, est. speed input: 3012.22 toks/s, output: 23.53 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 31.98it/s, est. speed input: 3113.75 toks/s, output: 24.33 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 32.39it/s, est. speed input: 3200.43 toks/s, output: 25.00 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 32.69it/s, est. speed input: 3275.22 toks/s, output: 25.59 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 32.82it/s, est. speed input: 3338.40 toks/s, output: 26.08 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 33.06it/s, est. speed input: 3397.06 toks/s, output: 26.54 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:02, 33.16it/s, est. speed input: 3447.59 toks/s, output: 26.93 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:02, 33.20it/s, est. speed input: 3492.09 toks/s, output: 27.28 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:01, 33.30it/s, est. speed input: 3533.18 toks/s, output: 27.60 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:01, 33.30it/s, est. speed input: 3569.09 toks/s, output: 27.88 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:01, 33.32it/s, est. speed input: 3601.92 toks/s, output: 28.14 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 33.33it/s, est. speed input: 3631.81 toks/s, output: 28.37 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 33.55it/s, est. speed input: 3662.42 toks/s, output: 28.61 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 33.66it/s, est. speed input: 3689.98 toks/s, output: 28.83 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 33.64it/s, est. speed input: 3713.93 toks/s, output: 29.01 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 33.59it/s, est. speed input: 3735.60 toks/s, output: 29.18 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:00, 33.55it/s, est. speed input: 3755.50 toks/s, output: 29.34 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:03<00:00, 33.51it/s, est. speed input: 3774.00 toks/s, output: 29.48 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:03<00:00, 33.48it/s, est. speed input: 3791.03 toks/s, output: 29.62 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:03<00:00, 33.47it/s, est. speed input: 3807.18 toks/s, output: 29.74 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 33.40it/s, est. speed input: 3821.61 toks/s, output: 29.86 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 33.42it/s, est. speed input: 3835.80 toks/s, output: 29.97 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 33.43it/s, est. speed input: 3849.20 toks/s, output: 30.07 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:04<00:00, 33.43it/s, est. speed input: 3861.75 toks/s, output: 30.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.46it/s, est. speed input: 3873.85 toks/s, output: 30.26 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.46it/s, est. speed input: 3873.85 toks/s, output: 30.26 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.26it/s, est. speed input: 3873.85 toks/s, output: 30.26 toks/s]
[rank0]:[W126 07:39:53.528502394 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 07:39:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:40:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=981696) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=981696) WARNING 01-26 07:40:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.85 requests/s, 7929.59 total tokens/s, 30.85 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 07:40:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:40:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:40:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:40:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:40:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:40:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:40:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=981696) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=981696) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.81it/s]
(EngineCore_DP0 pid=981696) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.81it/s]
(EngineCore_DP0 pid=981696) 
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=981696) [2026-01-26 07:40:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=981696) 2026-01-26 07:40:21,217 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=981696) 2026-01-26 07:40:21,254 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=981696) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.98it/s]
(EngineCore_DP0 pid=981696) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.13it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  60%|██████    | 77/128 [00:00<00:00, 768.19it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 961.82it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:33,  3.81it/s, est. speed input: 976.32 toks/s, output: 3.81 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 15.68it/s, est. speed input: 3383.73 toks/s, output: 13.22 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 22.38it/s, est. speed input: 4661.01 toks/s, output: 18.21 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 26.44it/s, est. speed input: 5451.03 toks/s, output: 21.29 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 29.04it/s, est. speed input: 5988.88 toks/s, output: 23.39 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 30.71it/s, est. speed input: 6374.29 toks/s, output: 24.90 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.64it/s, est. speed input: 6651.06 toks/s, output: 25.98 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.30it/s, est. speed input: 6869.64 toks/s, output: 26.83 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.77it/s, est. speed input: 7046.24 toks/s, output: 27.52 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.08it/s, est. speed input: 7190.05 toks/s, output: 28.09 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.26it/s, est. speed input: 7308.39 toks/s, output: 28.55 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.41it/s, est. speed input: 7410.29 toks/s, output: 28.95 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.50it/s, est. speed input: 7496.32 toks/s, output: 29.28 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.55it/s, est. speed input: 7570.80 toks/s, output: 29.57 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.63it/s, est. speed input: 7637.87 toks/s, output: 29.84 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:01, 33.66it/s, est. speed input: 7696.14 toks/s, output: 30.06 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.68it/s, est. speed input: 7748.21 toks/s, output: 30.27 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.72it/s, est. speed input: 7795.61 toks/s, output: 30.45 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.76it/s, est. speed input: 7838.58 toks/s, output: 30.62 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.77it/s, est. speed input: 7877.02 toks/s, output: 30.77 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.75it/s, est. speed input: 7911.01 toks/s, output: 30.90 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.72it/s, est. speed input: 7941.57 toks/s, output: 31.02 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.72it/s, est. speed input: 7970.33 toks/s, output: 31.13 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.75it/s, est. speed input: 7997.68 toks/s, output: 31.24 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.74it/s, est. speed input: 8021.74 toks/s, output: 31.33 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.78it/s, est. speed input: 8045.72 toks/s, output: 31.43 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.76it/s, est. speed input: 8066.43 toks/s, output: 31.51 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.79it/s, est. speed input: 8087.01 toks/s, output: 31.59 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.78it/s, est. speed input: 8105.55 toks/s, output: 31.66 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.78it/s, est. speed input: 8122.93 toks/s, output: 31.73 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.77it/s, est. speed input: 8139.03 toks/s, output: 31.79 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.73it/s, est. speed input: 8153.34 toks/s, output: 31.85 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.73it/s, est. speed input: 8164.27 toks/s, output: 31.89 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.89it/s, est. speed input: 8164.27 toks/s, output: 31.89 toks/s]
[rank0]:[W126 07:40:27.717312850 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:17:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:17:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1042121) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1042121) WARNING 01-26 08:18:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.83 requests/s, 16327.19 total tokens/s, 31.83 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:17:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:17:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:17:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:17:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:17:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:17:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:17:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:17:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:17:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:18:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:18:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:18:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:18:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:18:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:18:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1042121) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1042121) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.89it/s]
(EngineCore_DP0 pid=1042121) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.88it/s]
(EngineCore_DP0 pid=1042121) 
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1042121) [2026-01-26 08:18:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1042121) 2026-01-26 08:18:15,617 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1042121) 2026-01-26 08:18:15,693 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1042121) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.82it/s]
(EngineCore_DP0 pid=1042121) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.61it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  54%|█████▍    | 69/128 [00:00<00:00, 686.23it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 781.36it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 47.92it/s, est. speed input: 24540.99 toks/s, output: 47.93 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 38.66it/s, est. speed input: 20443.43 toks/s, output: 39.92 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 36.46it/s, est. speed input: 19430.29 toks/s, output: 37.95 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:03, 35.03it/s, est. speed input: 18793.56 toks/s, output: 36.70 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:03, 34.20it/s, est. speed input: 18396.66 toks/s, output: 35.93 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 33.70it/s, est. speed input: 18131.65 toks/s, output: 35.41 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 33.37it/s, est. speed input: 17939.56 toks/s, output: 35.04 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:02, 33.17it/s, est. speed input: 17795.02 toks/s, output: 34.75 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 33.01it/s, est. speed input: 17679.26 toks/s, output: 34.53 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 32.87it/s, est. speed input: 17579.28 toks/s, output: 34.33 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 32.83it/s, est. speed input: 17507.65 toks/s, output: 34.19 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:02, 32.73it/s, est. speed input: 17437.03 toks/s, output: 34.06 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:02, 32.73it/s, est. speed input: 17385.41 toks/s, output: 33.96 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:02, 32.76it/s, est. speed input: 17345.10 toks/s, output: 33.88 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 32.80it/s, est. speed input: 17312.08 toks/s, output: 33.81 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 32.82it/s, est. speed input: 17282.66 toks/s, output: 33.75 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:01, 32.80it/s, est. speed input: 17252.28 toks/s, output: 33.70 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 32.74it/s, est. speed input: 17221.62 toks/s, output: 33.64 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 32.69it/s, est. speed input: 17193.11 toks/s, output: 33.58 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 32.63it/s, est. speed input: 17165.08 toks/s, output: 33.53 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 32.60it/s, est. speed input: 17140.87 toks/s, output: 33.48 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:01, 32.61it/s, est. speed input: 17121.66 toks/s, output: 33.44 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:01, 32.62it/s, est. speed input: 17104.36 toks/s, output: 33.41 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 32.60it/s, est. speed input: 17086.04 toks/s, output: 33.37 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:03<00:00, 32.62it/s, est. speed input: 17071.66 toks/s, output: 33.34 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:03<00:00, 32.61it/s, est. speed input: 17056.88 toks/s, output: 33.31 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:03<00:00, 32.59it/s, est. speed input: 17042.50 toks/s, output: 33.29 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 32.57it/s, est. speed input: 17028.64 toks/s, output: 33.26 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 32.59it/s, est. speed input: 17017.51 toks/s, output: 33.24 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 32.60it/s, est. speed input: 17007.10 toks/s, output: 33.22 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 32.61it/s, est. speed input: 16997.58 toks/s, output: 33.20 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.61it/s, est. speed input: 16994.93 toks/s, output: 33.19 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.19it/s, est. speed input: 16994.93 toks/s, output: 33.19 toks/s]
[rank0]:[W126 08:18:21.611865880 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:18:23
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:18:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1043126) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1043126) WARNING 01-26 08:18:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.17 requests/s, 31944.61 total tokens/s, 31.17 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:18:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:18:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:18:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:18:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:18:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:18:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:18:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:18:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:18:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:18:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:18:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:18:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1043126) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1043126) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.66it/s]
(EngineCore_DP0 pid=1043126) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.66it/s]
(EngineCore_DP0 pid=1043126) 
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1043126) [2026-01-26 08:18:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1043126) 2026-01-26 08:18:51,785 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1043126) 2026-01-26 08:18:51,848 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1043126) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.57it/s]
(EngineCore_DP0 pid=1043126) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.19it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|██▎       | 29/128 [00:00<00:00, 286.67it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 425.35it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 435.34it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:01, 68.18it/s, est. speed input: 69834.27 toks/s, output: 68.19 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:02, 41.21it/s, est. speed input: 44862.51 toks/s, output: 43.81 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:02, 37.32it/s, est. speed input: 40992.99 toks/s, output: 40.03 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:02, 35.42it/s, est. speed input: 39061.57 toks/s, output: 38.14 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:00<00:02, 34.69it/s, est. speed input: 38209.73 toks/s, output: 37.31 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:02, 34.21it/s, est. speed input: 37605.65 toks/s, output: 36.72 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:00<00:02, 33.65it/s, est. speed input: 37053.10 toks/s, output: 36.18 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 33.30it/s, est. speed input: 36635.52 toks/s, output: 35.78 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 33.07it/s, est. speed input: 36306.49 toks/s, output: 35.45 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 32.94it/s, est. speed input: 36048.19 toks/s, output: 35.20 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 32.79it/s, est. speed input: 35812.46 toks/s, output: 34.97 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:02, 32.69it/s, est. speed input: 35616.46 toks/s, output: 34.78 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:01<00:02, 32.61it/s, est. speed input: 35445.28 toks/s, output: 34.61 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:01<00:01, 32.60it/s, est. speed input: 35306.16 toks/s, output: 34.48 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:01<00:01, 32.56it/s, est. speed input: 35178.05 toks/s, output: 34.35 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:01, 32.55it/s, est. speed input: 35069.44 toks/s, output: 34.25 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 32.62it/s, est. speed input: 34987.13 toks/s, output: 34.17 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 32.60it/s, est. speed input: 34899.94 toks/s, output: 34.08 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 32.64it/s, est. speed input: 34832.30 toks/s, output: 34.02 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 32.64it/s, est. speed input: 34765.06 toks/s, output: 33.95 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:02<00:01, 32.68it/s, est. speed input: 34710.33 toks/s, output: 33.90 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 32.64it/s, est. speed input: 34651.41 toks/s, output: 33.84 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:02<00:00, 32.79it/s, est. speed input: 34622.09 toks/s, output: 33.81 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:03<00:00, 32.78it/s, est. speed input: 34580.25 toks/s, output: 33.77 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:03<00:00, 32.68it/s, est. speed input: 34527.03 toks/s, output: 33.72 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 32.65it/s, est. speed input: 34484.57 toks/s, output: 33.68 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 32.77it/s, est. speed input: 34462.48 toks/s, output: 33.65 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 32.90it/s, est. speed input: 34446.23 toks/s, output: 33.64 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:03<00:00, 32.95it/s, est. speed input: 34427.57 toks/s, output: 33.62 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.83it/s, est. speed input: 34391.86 toks/s, output: 33.59 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.83it/s, est. speed input: 34391.86 toks/s, output: 33.59 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.58it/s, est. speed input: 34391.86 toks/s, output: 33.59 toks/s]
[rank0]:[W126 08:18:57.943277510 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:19:00
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:19:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1044143) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1044143) WARNING 01-26 08:19:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 55.41 requests/s, 56798.09 total tokens/s, 55.41 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:19:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:19:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:19:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:19:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1044143) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1044143) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=1044143) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=1044143) 
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1044143) [2026-01-26 08:19:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1044143) 2026-01-26 08:19:28,803 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1044143) 2026-01-26 08:19:28,832 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1044143) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.26it/s]
(EngineCore_DP0 pid=1044143) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  5.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.31it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  12%|█▏        | 30/256 [00:00<00:00, 296.82it/s]
Adding requests:  32%|███▏      | 83/256 [00:00<00:00, 431.84it/s]
Adding requests:  52%|█████▏    | 134/256 [00:00<00:00, 465.23it/s]
Adding requests:  72%|███████▏  | 184/256 [00:00<00:00, 477.88it/s]
Adding requests:  92%|█████████▏| 236/256 [00:00<00:00, 491.92it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 471.53it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 154.53it/s, est. speed input: 158287.00 toks/s, output: 154.54 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:00<00:02, 82.85it/s, est. speed input: 91957.51 toks/s, output: 89.79 toks/s]   
Processed prompts:  18%|█▊        | 46/256 [00:00<00:02, 73.50it/s, est. speed input: 82755.95 toks/s, output: 80.81 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:00<00:02, 71.43it/s, est. speed input: 80024.47 toks/s, output: 78.15 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:00<00:02, 67.59it/s, est. speed input: 76867.47 toks/s, output: 75.07 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:00<00:02, 62.55it/s, est. speed input: 73464.19 toks/s, output: 71.74 toks/s]
Processed prompts:  30%|███       | 78/256 [00:01<00:02, 62.04it/s, est. speed input: 72137.90 toks/s, output: 70.45 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:02, 61.70it/s, est. speed input: 71102.53 toks/s, output: 69.43 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:01<00:02, 61.33it/s, est. speed input: 70215.71 toks/s, output: 68.57 toks/s]
Processed prompts:  39%|███▉      | 101/256 [00:01<00:02, 63.41it/s, est. speed input: 70299.30 toks/s, output: 68.65 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:01<00:02, 59.83it/s, est. speed input: 68892.63 toks/s, output: 67.28 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:01<00:02, 62.31it/s, est. speed input: 69028.98 toks/s, output: 67.41 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:01<00:02, 58.94it/s, est. speed input: 67876.64 toks/s, output: 66.29 toks/s]
Processed prompts:  50%|█████     | 129/256 [00:01<00:02, 61.79it/s, est. speed input: 68071.15 toks/s, output: 66.48 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:02<00:02, 58.53it/s, est. speed input: 67107.59 toks/s, output: 65.53 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:02<00:01, 58.67it/s, est. speed input: 66798.69 toks/s, output: 65.23 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:02<00:01, 59.18it/s, est. speed input: 66503.62 toks/s, output: 64.94 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:02<00:01, 59.25it/s, est. speed input: 66267.52 toks/s, output: 64.71 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:02<00:01, 59.37it/s, est. speed input: 66061.31 toks/s, output: 64.51 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:02<00:01, 59.52it/s, est. speed input: 65879.27 toks/s, output: 64.33 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:02<00:01, 59.96it/s, est. speed input: 65705.86 toks/s, output: 64.17 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:02<00:01, 62.68it/s, est. speed input: 65914.03 toks/s, output: 64.37 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:02<00:01, 59.13it/s, est. speed input: 65359.14 toks/s, output: 63.83 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:03<00:00, 59.41it/s, est. speed input: 65190.20 toks/s, output: 63.66 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:03<00:00, 59.55it/s, est. speed input: 65071.97 toks/s, output: 63.55 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:03<00:00, 59.61it/s, est. speed input: 64955.06 toks/s, output: 63.43 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:03<00:00, 59.77it/s, est. speed input: 64821.98 toks/s, output: 63.30 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:03<00:00, 62.50it/s, est. speed input: 65014.53 toks/s, output: 63.49 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:03<00:00, 59.02it/s, est. speed input: 64594.19 toks/s, output: 63.08 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:03<00:00, 59.39it/s, est. speed input: 64489.86 toks/s, output: 62.98 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:03<00:00, 59.39it/s, est. speed input: 64394.56 toks/s, output: 62.89 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:04<00:00, 59.93it/s, est. speed input: 64334.19 toks/s, output: 62.83 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 59.93it/s, est. speed input: 64327.69 toks/s, output: 62.82 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 62.82it/s, est. speed input: 64327.69 toks/s, output: 62.82 toks/s]
[rank0]:[W126 08:19:35.769864639 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:19:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:19:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1045173) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1045173) WARNING 01-26 08:20:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 109.51 requests/s, 112250.16 total tokens/s, 109.51 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:19:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:19:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:19:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:19:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:19:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:19:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1045173) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1045173) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.83it/s]
(EngineCore_DP0 pid=1045173) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.83it/s]
(EngineCore_DP0 pid=1045173) 
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1045173) [2026-01-26 08:19:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1045173) 2026-01-26 08:20:07,383 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1045173) 2026-01-26 08:20:07,413 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1045173) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  6.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  9.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.75it/s]
(EngineCore_DP0 pid=1045173) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  4.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.33it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 28/512 [00:00<00:01, 276.69it/s]
Adding requests:  16%|█▌        | 80/512 [00:00<00:01, 418.50it/s]
Adding requests:  26%|██▌       | 132/512 [00:00<00:00, 461.43it/s]
Adding requests:  36%|███▌      | 182/512 [00:00<00:00, 472.93it/s]
Adding requests:  46%|████▌     | 234/512 [00:00<00:00, 488.64it/s]
Adding requests:  56%|█████▌    | 286/512 [00:00<00:00, 497.01it/s]
Adding requests:  66%|██████▌   | 336/512 [00:00<00:00, 496.29it/s]
Adding requests:  76%|███████▌  | 388/512 [00:00<00:00, 503.29it/s]
Adding requests:  86%|████████▌ | 440/512 [00:00<00:00, 505.82it/s]
Adding requests:  96%|█████████▌| 491/512 [00:01<00:00, 506.24it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 486.48it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:00<00:00, 584.46it/s, est. speed input: 598582.75 toks/s, output: 584.49 toks/s]
Processed prompts:  24%|██▍       | 125/512 [00:00<00:01, 202.77it/s, est. speed input: 231599.75 toks/s, output: 226.17 toks/s]
Processed prompts:  31%|███       | 157/512 [00:00<00:02, 171.56it/s, est. speed input: 199646.51 toks/s, output: 194.96 toks/s]
Processed prompts:  35%|███▌      | 181/512 [00:00<00:02, 158.01it/s, est. speed input: 186440.92 toks/s, output: 182.07 toks/s]
Processed prompts:  39%|███▉      | 201/512 [00:01<00:02, 149.69it/s, est. speed input: 178689.64 toks/s, output: 174.50 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:01<00:02, 138.12it/s, est. speed input: 170460.93 toks/s, output: 166.46 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:01<00:02, 135.55it/s, est. speed input: 166954.14 toks/s, output: 163.04 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:01<00:01, 133.29it/s, est. speed input: 163944.72 toks/s, output: 160.10 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:01<00:01, 131.47it/s, est. speed input: 161366.30 toks/s, output: 157.58 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:01<00:01, 130.17it/s, est. speed input: 159170.74 toks/s, output: 155.44 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:01<00:01, 129.16it/s, est. speed input: 157246.74 toks/s, output: 153.56 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:02<00:01, 128.61it/s, est. speed input: 155606.95 toks/s, output: 151.96 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:02<00:01, 128.02it/s, est. speed input: 154108.54 toks/s, output: 150.49 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:02<00:01, 126.60it/s, est. speed input: 152554.26 toks/s, output: 148.97 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:02<00:01, 126.52it/s, est. speed input: 151352.51 toks/s, output: 147.80 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:02<00:01, 126.57it/s, est. speed input: 150292.49 toks/s, output: 146.77 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:02<00:00, 126.45it/s, est. speed input: 149303.81 toks/s, output: 145.80 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:02<00:00, 126.81it/s, est. speed input: 148479.34 toks/s, output: 145.00 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:02<00:00, 127.05it/s, est. speed input: 147723.04 toks/s, output: 144.26 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:03<00:00, 126.82it/s, est. speed input: 146966.16 toks/s, output: 143.52 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:03<00:00, 126.34it/s, est. speed input: 146220.00 toks/s, output: 142.79 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:03<00:00, 126.27it/s, est. speed input: 145570.35 toks/s, output: 142.16 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:03<00:00, 126.31it/s, est. speed input: 144980.24 toks/s, output: 141.58 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:03<00:00, 126.25it/s, est. speed input: 144419.90 toks/s, output: 141.03 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 126.25it/s, est. speed input: 144803.61 toks/s, output: 141.41 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 141.40it/s, est. speed input: 144803.61 toks/s, output: 141.41 toks/s]
[rank0]:[W126 08:20:14.792919107 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:20:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:20:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1046226) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1046226) WARNING 01-26 08:20:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 158.41 requests/s, 162372.72 total tokens/s, 158.41 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:20:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:20:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:20:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:20:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:20:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:20:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:20:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:20:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:20:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:20:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:20:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:20:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:20:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:20:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:20:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:20:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:20:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1046226) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1046226) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=1046226) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]
(EngineCore_DP0 pid=1046226) 
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1046226) [2026-01-26 08:20:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1046226) 2026-01-26 08:20:49,016 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1046226) 2026-01-26 08:20:49,084 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1046226) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 14.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 13.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 13.18it/s]
(EngineCore_DP0 pid=1046226) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 10.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.68it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 27/1024 [00:00<00:03, 265.98it/s]
Adding requests:   8%|▊         | 80/1024 [00:00<00:02, 418.16it/s]
Adding requests:  13%|█▎        | 131/1024 [00:00<00:01, 459.60it/s]
Adding requests:  18%|█▊        | 180/1024 [00:00<00:01, 471.40it/s]
Adding requests:  23%|██▎       | 232/1024 [00:00<00:01, 486.43it/s]
Adding requests:  28%|██▊       | 283/1024 [00:00<00:01, 492.17it/s]
Adding requests:  33%|███▎      | 333/1024 [00:00<00:01, 493.15it/s]
Adding requests:  38%|███▊      | 384/1024 [00:00<00:01, 498.21it/s]
Adding requests:  42%|████▏     | 435/1024 [00:00<00:01, 500.38it/s]
Adding requests:  48%|████▊     | 487/1024 [00:01<00:01, 503.10it/s]
Adding requests:  53%|█████▎    | 538/1024 [00:01<00:00, 492.67it/s]
Adding requests:  58%|█████▊    | 592/1024 [00:01<00:00, 504.69it/s]
Adding requests:  63%|██████▎   | 643/1024 [00:01<00:00, 499.95it/s]
Adding requests:  68%|██████▊   | 696/1024 [00:01<00:00, 508.07it/s]
Adding requests:  73%|███████▎  | 748/1024 [00:01<00:00, 508.60it/s]
Adding requests:  78%|███████▊  | 799/1024 [00:01<00:00, 508.03it/s]
Adding requests:  83%|████████▎ | 850/1024 [00:01<00:00, 500.65it/s]
Adding requests:  88%|████████▊ | 903/1024 [00:01<00:00, 508.80it/s]
Adding requests:  93%|█████████▎| 955/1024 [00:01<00:00, 509.68it/s]
Adding requests:  98%|█████████▊| 1007/1024 [00:02<00:00, 511.61it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 495.65it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:00<00:00, 2288.48it/s, est. speed input: 2344376.18 toks/s, output: 2288.77 toks/s]
Processed prompts:  45%|████▌     | 463/1024 [00:01<00:01, 293.37it/s, est. speed input: 346172.79 toks/s, output: 338.06 toks/s]   
Processed prompts:  55%|█████▌    | 568/1024 [00:01<00:01, 252.77it/s, est. speed input: 300500.42 toks/s, output: 293.46 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:02<00:01, 230.27it/s, est. speed input: 279242.13 toks/s, output: 272.69 toks/s]
Processed prompts:  67%|██████▋   | 681/1024 [00:02<00:01, 227.72it/s, est. speed input: 274254.99 toks/s, output: 267.83 toks/s]
Processed prompts:  70%|███████   | 719/1024 [00:02<00:01, 217.01it/s, est. speed input: 266742.74 toks/s, output: 260.49 toks/s]
Processed prompts:  73%|███████▎  | 750/1024 [00:02<00:01, 209.79it/s, est. speed input: 261772.45 toks/s, output: 255.64 toks/s]
Processed prompts:  76%|███████▌  | 777/1024 [00:03<00:01, 209.52it/s, est. speed input: 259714.12 toks/s, output: 253.63 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:03<00:01, 193.95it/s, est. speed input: 253771.70 toks/s, output: 247.82 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:03<00:01, 191.87it/s, est. speed input: 251232.65 toks/s, output: 245.34 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:03<00:00, 190.19it/s, est. speed input: 248911.41 toks/s, output: 243.08 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:03<00:00, 188.68it/s, est. speed input: 246738.75 toks/s, output: 240.95 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:03<00:00, 187.64it/s, est. speed input: 244744.47 toks/s, output: 239.01 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:03<00:00, 186.51it/s, est. speed input: 242830.44 toks/s, output: 237.14 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:04<00:00, 187.68it/s, est. speed input: 241344.59 toks/s, output: 235.69 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:04<00:00, 186.82it/s, est. speed input: 239706.76 toks/s, output: 234.09 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:04<00:00, 187.86it/s, est. speed input: 238387.99 toks/s, output: 232.80 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:04<00:00, 188.69it/s, est. speed input: 237155.52 toks/s, output: 231.60 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 188.69it/s, est. speed input: 238532.72 toks/s, output: 232.94 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 232.93it/s, est. speed input: 238532.72 toks/s, output: 232.94 toks/s]
[rank0]:[W126 08:20:58.136899437 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:21:00
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:21:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1047400) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1047400) WARNING 01-26 08:21:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 183.56 requests/s, 188150.78 total tokens/s, 183.56 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:21:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:21:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:21:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:21:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:21:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:21:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:21:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:21:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:21:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:21:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:21:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:21:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:21:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:21:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:21:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:21:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:21:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1047400) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1047400) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.88it/s]
(EngineCore_DP0 pid=1047400) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.88it/s]
(EngineCore_DP0 pid=1047400) 
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1047400) [2026-01-26 08:21:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1047400) 2026-01-26 08:21:36,283 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1047400) 2026-01-26 08:21:36,326 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1047400) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  6.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 12.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 10.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.46it/s]
(EngineCore_DP0 pid=1047400) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  8.95it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  5.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  6.30it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 40/2048 [00:00<00:05, 394.21it/s]
Adding requests:   4%|▍         | 91/2048 [00:00<00:04, 458.94it/s]
Adding requests:   7%|▋         | 140/2048 [00:00<00:04, 471.96it/s]
Adding requests:   9%|▉         | 188/2048 [00:00<00:03, 474.35it/s]
Adding requests:  12%|█▏        | 239/2048 [00:00<00:03, 485.12it/s]
Adding requests:  14%|█▍        | 288/2048 [00:00<00:03, 486.01it/s]
Adding requests:  16%|█▋        | 337/2048 [00:00<00:03, 487.15it/s]
Adding requests:  19%|█▉        | 388/2048 [00:00<00:03, 492.87it/s]
Adding requests:  21%|██▏       | 438/2048 [00:00<00:03, 494.86it/s]
Adding requests:  24%|██▍       | 489/2048 [00:01<00:03, 494.75it/s]
Adding requests:  26%|██▋       | 539/2048 [00:01<00:03, 487.22it/s]
Adding requests:  29%|██▉       | 591/2048 [00:01<00:02, 496.76it/s]
Adding requests:  31%|███▏      | 642/2048 [00:01<00:02, 498.70it/s]
Adding requests:  34%|███▍      | 695/2048 [00:01<00:02, 504.18it/s]
Adding requests:  36%|███▋      | 746/2048 [00:01<00:02, 497.35it/s]
Adding requests:  39%|███▉      | 796/2048 [00:01<00:02, 497.38it/s]
Adding requests:  41%|████▏     | 846/2048 [00:01<00:02, 490.83it/s]
Adding requests:  44%|████▍     | 899/2048 [00:01<00:02, 500.22it/s]
Adding requests:  46%|████▋     | 950/2048 [00:01<00:02, 501.23it/s]
Adding requests:  49%|████▉     | 1002/2048 [00:02<00:02, 504.74it/s]
Adding requests:  51%|█████▏    | 1054/2048 [00:02<00:01, 506.46it/s]
Adding requests:  54%|█████▍    | 1105/2048 [00:02<00:01, 502.21it/s]
Adding requests:  56%|█████▋    | 1156/2048 [00:02<00:01, 503.01it/s]
Adding requests:  59%|█████▉    | 1210/2048 [00:02<00:01, 511.50it/s]
Adding requests:  62%|██████▏   | 1262/2048 [00:02<00:01, 506.60it/s]
Adding requests:  64%|██████▍   | 1313/2048 [00:02<00:01, 506.37it/s]
Adding requests:  67%|██████▋   | 1366/2048 [00:02<00:01, 510.54it/s]
Adding requests:  69%|██████▉   | 1418/2048 [00:02<00:01, 509.53it/s]
Adding requests:  72%|███████▏  | 1470/2048 [00:02<00:01, 510.81it/s]
Adding requests:  74%|███████▍  | 1522/2048 [00:03<00:01, 511.89it/s]
Adding requests:  77%|███████▋  | 1574/2048 [00:03<00:00, 511.94it/s]
Adding requests:  79%|███████▉  | 1627/2048 [00:03<00:00, 516.43it/s]
Adding requests:  82%|████████▏ | 1679/2048 [00:03<00:00, 511.61it/s]
Adding requests:  85%|████████▍ | 1732/2048 [00:03<00:00, 514.21it/s]
Adding requests:  87%|████████▋ | 1784/2048 [00:03<00:00, 507.14it/s]
Adding requests:  90%|████████▉ | 1836/2048 [00:03<00:00, 510.54it/s]
Adding requests:  92%|█████████▏| 1888/2048 [00:03<00:00, 500.88it/s]
Adding requests:  95%|█████████▍| 1939/2048 [00:03<00:00, 502.14it/s]
Adding requests:  97%|█████████▋| 1990/2048 [00:03<00:00, 503.19it/s]
Adding requests: 100%|█████████▉| 2042/2048 [00:04<00:00, 505.43it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 500.38it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:00<00:00, 4420.05it/s, est. speed input: 4527931.28 toks/s, output: 4420.39 toks/s]
Processed prompts:  56%|█████▌    | 1149/2048 [00:02<00:02, 396.48it/s, est. speed input: 487858.10 toks/s, output: 476.42 toks/s]  
Processed prompts:  66%|██████▌   | 1343/2048 [00:03<00:02, 321.85it/s, est. speed input: 404695.78 toks/s, output: 395.21 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:04<00:02, 281.63it/s, est. speed input: 366787.47 toks/s, output: 358.19 toks/s]
Processed prompts:  75%|███████▍  | 1534/2048 [00:04<00:01, 273.01it/s, est. speed input: 356632.42 toks/s, output: 348.27 toks/s]
Processed prompts:  78%|███████▊  | 1591/2048 [00:04<00:01, 254.40it/s, est. speed input: 343987.94 toks/s, output: 335.92 toks/s]
Processed prompts:  80%|███████▉  | 1635/2048 [00:04<00:01, 241.11it/s, est. speed input: 335645.68 toks/s, output: 327.78 toks/s]
Processed prompts:  82%|████████▏ | 1670/2048 [00:05<00:01, 237.43it/s, est. speed input: 331927.88 toks/s, output: 324.15 toks/s]
Processed prompts:  83%|████████▎ | 1701/2048 [00:05<00:01, 229.17it/s, est. speed input: 327528.74 toks/s, output: 319.85 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:05<00:01, 218.41it/s, est. speed input: 322913.51 toks/s, output: 315.34 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:05<00:01, 212.17it/s, est. speed input: 319056.47 toks/s, output: 311.58 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:05<00:01, 207.03it/s, est. speed input: 315465.98 toks/s, output: 308.07 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:05<00:01, 202.72it/s, est. speed input: 312059.62 toks/s, output: 304.74 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:06<00:00, 199.43it/s, est. speed input: 308856.61 toks/s, output: 301.62 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:06<00:00, 198.57it/s, est. speed input: 306073.53 toks/s, output: 298.90 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:06<00:00, 196.39it/s, est. speed input: 303214.92 toks/s, output: 296.11 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:06<00:00, 196.18it/s, est. speed input: 300685.68 toks/s, output: 293.64 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:06<00:00, 195.81it/s, est. speed input: 298251.03 toks/s, output: 291.26 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:06<00:00, 195.29it/s, est. speed input: 295900.24 toks/s, output: 288.96 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:07<00:00, 195.29it/s, est. speed input: 296984.35 toks/s, output: 290.02 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:07<00:00, 290.01it/s, est. speed input: 296984.35 toks/s, output: 290.02 toks/s]
[rank0]:[W126 08:21:50.708296729 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:21:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:22:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1048717) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1048717) WARNING 01-26 08:22:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 191.88 requests/s, 196677.61 total tokens/s, 191.88 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:22:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:22:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:22:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:22:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:22:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:22:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:22:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:22:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:22:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1048717) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1048717) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.89it/s]
(EngineCore_DP0 pid=1048717) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.89it/s]
(EngineCore_DP0 pid=1048717) 
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1048717) [2026-01-26 08:22:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1048717) [rank0]:W0126 08:22:32.735000 1048717 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1048717) [rank0]:W0126 08:22:32.789000 1048717 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1048717) [rank0]:W0126 08:22:33.524000 1048717 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1048717) [rank0]:W0126 08:22:33.601000 1048717 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1048717) 2026-01-26 08:22:36,524 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1048717) 2026-01-26 08:22:36,629 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1048717) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 12.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00, 15.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:00<00:00, 13.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 11.32it/s]
(EngineCore_DP0 pid=1048717) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 16.06it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 13.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  7.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.67it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 34/4096 [00:00<00:11, 338.60it/s]
Adding requests:   2%|▏         | 86/4096 [00:00<00:09, 440.85it/s]
Adding requests:   3%|▎         | 137/4096 [00:00<00:08, 469.67it/s]
Adding requests:   5%|▍         | 187/4096 [00:00<00:08, 479.12it/s]
Adding requests:   6%|▌         | 238/4096 [00:00<00:07, 488.85it/s]
Adding requests:   7%|▋         | 288/4096 [00:00<00:07, 491.27it/s]
Adding requests:   8%|▊         | 338/4096 [00:00<00:07, 492.10it/s]
Adding requests:  10%|▉         | 390/4096 [00:00<00:07, 499.14it/s]
Adding requests:  11%|█         | 440/4096 [00:00<00:07, 495.33it/s]
Adding requests:  12%|█▏        | 491/4096 [00:01<00:07, 499.80it/s]
Adding requests:  13%|█▎        | 541/4096 [00:01<00:07, 493.28it/s]
Adding requests:  15%|█▍        | 594/4096 [00:01<00:06, 503.93it/s]
Adding requests:  16%|█▌        | 646/4096 [00:01<00:06, 507.31it/s]
Adding requests:  17%|█▋        | 700/4096 [00:01<00:06, 515.23it/s]
Adding requests:  18%|█▊        | 752/4096 [00:01<00:06, 514.11it/s]
Adding requests:  20%|█▉        | 804/4096 [00:01<00:06, 509.30it/s]
Adding requests:  21%|██        | 855/4096 [00:01<00:06, 505.15it/s]
Adding requests:  22%|██▏       | 908/4096 [00:01<00:06, 511.98it/s]
Adding requests:  23%|██▎       | 960/4096 [00:01<00:06, 514.30it/s]
Adding requests:  25%|██▍       | 1013/4096 [00:02<00:05, 516.79it/s]
Adding requests:  26%|██▌       | 1065/4096 [00:02<00:05, 507.61it/s]
Adding requests:  27%|██▋       | 1116/4096 [00:02<00:05, 501.97it/s]
Adding requests:  29%|██▊       | 1170/4096 [00:02<00:05, 510.33it/s]
Adding requests:  30%|██▉       | 1224/4096 [00:02<00:05, 518.77it/s]
Adding requests:  31%|███       | 1276/4096 [00:02<00:05, 511.51it/s]
Adding requests:  32%|███▏      | 1330/4096 [00:02<00:05, 517.48it/s]
Adding requests:  34%|███▍      | 1383/4096 [00:02<00:05, 518.98it/s]
Adding requests:  35%|███▌      | 1436/4096 [00:02<00:05, 519.22it/s]
Adding requests:  36%|███▋      | 1490/4096 [00:02<00:04, 523.46it/s]
Adding requests:  38%|███▊      | 1543/4096 [00:03<00:04, 524.67it/s]
Adding requests:  39%|███▉      | 1597/4096 [00:03<00:04, 529.14it/s]
Adding requests:  40%|████      | 1650/4096 [00:03<00:04, 527.79it/s]
Adding requests:  42%|████▏     | 1703/4096 [00:03<00:04, 523.33it/s]
Adding requests:  43%|████▎     | 1756/4096 [00:03<00:04, 522.27it/s]
Adding requests:  44%|████▍     | 1809/4096 [00:03<00:04, 522.16it/s]
Adding requests:  45%|████▌     | 1862/4096 [00:03<00:04, 520.55it/s]
Adding requests:  47%|████▋     | 1915/4096 [00:03<00:04, 520.50it/s]
Adding requests:  48%|████▊     | 1968/4096 [00:03<00:04, 518.90it/s]
Adding requests:  49%|████▉     | 2021/4096 [00:03<00:03, 521.77it/s]
Adding requests:  51%|█████     | 2075/4096 [00:04<00:03, 526.48it/s]
Adding requests:  52%|█████▏    | 2128/4096 [00:04<00:03, 520.36it/s]
Adding requests:  53%|█████▎    | 2181/4096 [00:04<00:03, 513.21it/s]
Adding requests:  55%|█████▍    | 2233/4096 [00:04<00:03, 505.24it/s]
Adding requests:  56%|█████▌    | 2285/4096 [00:04<00:03, 507.77it/s]
Adding requests:  57%|█████▋    | 2337/4096 [00:04<00:03, 509.65it/s]
Adding requests:  58%|█████▊    | 2390/4096 [00:04<00:03, 512.72it/s]
Adding requests:  60%|█████▉    | 2442/4096 [00:04<00:03, 513.36it/s]
Adding requests:  61%|██████    | 2494/4096 [00:04<00:03, 513.52it/s]
Adding requests:  62%|██████▏   | 2546/4096 [00:04<00:03, 515.25it/s]
Adding requests:  63%|██████▎   | 2599/4096 [00:05<00:02, 517.82it/s]
Adding requests:  65%|██████▍   | 2652/4096 [00:05<00:02, 519.32it/s]
Adding requests:  66%|██████▌   | 2704/4096 [00:05<00:02, 516.24it/s]
Adding requests:  67%|██████▋   | 2756/4096 [00:05<00:02, 515.28it/s]
Adding requests:  69%|██████▊   | 2808/4096 [00:05<00:02, 515.48it/s]
Adding requests:  70%|██████▉   | 2860/4096 [00:05<00:02, 515.21it/s]
Adding requests:  71%|███████   | 2913/4096 [00:05<00:02, 517.82it/s]
Adding requests:  72%|███████▏  | 2965/4096 [00:05<00:02, 513.63it/s]
Adding requests:  74%|███████▎  | 3018/4096 [00:05<00:02, 517.17it/s]
Adding requests:  75%|███████▍  | 3070/4096 [00:06<00:01, 515.74it/s]
Adding requests:  76%|███████▌  | 3123/4096 [00:06<00:01, 517.91it/s]
Adding requests:  78%|███████▊  | 3175/4096 [00:06<00:01, 516.18it/s]
Adding requests:  79%|███████▉  | 3227/4096 [00:06<00:01, 516.04it/s]
Adding requests:  80%|████████  | 3281/4096 [00:06<00:01, 520.59it/s]
Adding requests:  81%|████████▏ | 3334/4096 [00:06<00:01, 519.15it/s]
Adding requests:  83%|████████▎ | 3387/4096 [00:06<00:01, 521.42it/s]
Adding requests:  84%|████████▍ | 3440/4096 [00:06<00:01, 521.92it/s]
Adding requests:  85%|████████▌ | 3493/4096 [00:06<00:01, 512.32it/s]
Adding requests:  87%|████████▋ | 3545/4096 [00:06<00:01, 501.22it/s]
Adding requests:  88%|████████▊ | 3597/4096 [00:07<00:00, 505.42it/s]
Adding requests:  89%|████████▉ | 3648/4096 [00:07<00:00, 504.15it/s]
Adding requests:  90%|█████████ | 3701/4096 [00:07<00:00, 509.22it/s]
Adding requests:  92%|█████████▏| 3753/4096 [00:07<00:00, 510.98it/s]
Adding requests:  93%|█████████▎| 3807/4096 [00:07<00:00, 518.52it/s]
Adding requests:  94%|█████████▍| 3861/4096 [00:07<00:00, 524.62it/s]
Adding requests:  96%|█████████▌| 3914/4096 [00:07<00:00, 521.28it/s]
Adding requests:  97%|█████████▋| 3967/4096 [00:07<00:00, 522.19it/s]
Adding requests:  98%|█████████▊| 4020/4096 [00:07<00:00, 521.23it/s]
Adding requests:  99%|█████████▉| 4073/4096 [00:07<00:00, 512.87it/s]
Adding requests: 100%|██████████| 4096/4096 [00:07<00:00, 512.12it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  36%|███▌      | 1464/4096 [00:00<00:00, 11565.87it/s, est. speed input: 11845708.02 toks/s, output: 11566.53 toks/s]
Processed prompts:  64%|██████▍   | 2621/4096 [00:05<00:03, 368.96it/s, est. speed input: 450977.23 toks/s, output: 440.41 toks/s]      
Processed prompts:  76%|███████▌  | 3109/4096 [00:08<00:03, 305.78it/s, est. speed input: 378883.83 toks/s, output: 370.00 toks/s]
Processed prompts:  83%|████████▎ | 3384/4096 [00:09<00:02, 277.16it/s, est. speed input: 351046.75 toks/s, output: 342.82 toks/s]
Processed prompts:  87%|████████▋ | 3558/4096 [00:10<00:02, 267.46it/s, est. speed input: 341264.38 toks/s, output: 333.27 toks/s]
Processed prompts:  90%|████████▉ | 3677/4096 [00:11<00:01, 253.79it/s, est. speed input: 332152.54 toks/s, output: 324.37 toks/s]
Processed prompts:  92%|█████████▏| 3762/4096 [00:11<00:01, 254.34it/s, est. speed input: 330280.07 toks/s, output: 322.54 toks/s]
Processed prompts:  93%|█████████▎| 3828/4096 [00:11<00:01, 247.31it/s, est. speed input: 326774.12 toks/s, output: 319.12 toks/s]
Processed prompts:  95%|█████████▍| 3879/4096 [00:12<00:00, 234.25it/s, est. speed input: 322523.15 toks/s, output: 314.96 toks/s]
Processed prompts:  96%|█████████▌| 3919/4096 [00:12<00:00, 235.13it/s, est. speed input: 321554.12 toks/s, output: 314.02 toks/s]
Processed prompts:  97%|█████████▋| 3955/4096 [00:12<00:00, 232.82it/s, est. speed input: 320241.96 toks/s, output: 312.74 toks/s]
Processed prompts:  97%|█████████▋| 3986/4096 [00:12<00:00, 225.96it/s, est. speed input: 318580.00 toks/s, output: 311.11 toks/s]
Processed prompts:  98%|█████████▊| 4014/4096 [00:12<00:00, 216.14it/s, est. speed input: 316749.14 toks/s, output: 309.33 toks/s]
Processed prompts:  99%|█████████▊| 4039/4096 [00:13<00:00, 205.47it/s, est. speed input: 314942.98 toks/s, output: 307.56 toks/s]
Processed prompts:  99%|█████████▉| 4061/4096 [00:13<00:00, 191.04it/s, est. speed input: 312893.76 toks/s, output: 305.56 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:13<00:00, 191.04it/s, est. speed input: 314294.17 toks/s, output: 306.93 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:13<00:00, 306.92it/s, est. speed input: 314294.17 toks/s, output: 306.93 toks/s]
[rank0]:[W126 08:23:01.667196203 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:23:03
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:23:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1050363) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1050363) WARNING 01-26 08:23:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 196.87 requests/s, 201793.59 total tokens/s, 196.87 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:23:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:23:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:23:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:23:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:23:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:23:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:23:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:23:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:23:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:23:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:23:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:23:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:23:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:23:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:23:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:23:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:23:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1050363) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1050363) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.93it/s]
(EngineCore_DP0 pid=1050363) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1050363) 
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5283840 bytes
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3522560 bytes
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28180480 bytes
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1050363) [2026-01-26 08:23:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14008320 bytes
(EngineCore_DP0 pid=1050363) [rank0]:W0126 08:24:02.212000 1050363 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1050363) [rank0]:W0126 08:24:02.267000 1050363 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1050363) [rank0]:W0126 08:24:03.146000 1050363 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1050363) [rank0]:W0126 08:24:03.222000 1050363 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1050363) 2026-01-26 08:24:05,991 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1050363) 2026-01-26 08:24:06,024 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1050363) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:03,  5.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:04,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:04,  3.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  6.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  7.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00,  9.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00, 11.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00, 13.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:01<00:00, 15.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  9.22it/s]
(EngineCore_DP0 pid=1050363) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  5.03it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:03,  2.58it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:01,  5.30it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00,  8.11it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00, 11.62it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  9.12it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 50/8192 [00:00<00:16, 493.61it/s]
Adding requests:   1%|          | 102/8192 [00:00<00:16, 503.41it/s]
Adding requests:   2%|▏         | 153/8192 [00:00<00:16, 499.33it/s]
Adding requests:   2%|▏         | 204/8192 [00:00<00:15, 500.64it/s]
Adding requests:   3%|▎         | 257/8192 [00:00<00:15, 508.20it/s]
Adding requests:   4%|▍         | 308/8192 [00:00<00:15, 504.62it/s]
Adding requests:   4%|▍         | 359/8192 [00:00<00:15, 506.14it/s]
Adding requests:   5%|▌         | 411/8192 [00:00<00:15, 507.14it/s]
Adding requests:   6%|▌         | 463/8192 [00:00<00:15, 509.64it/s]
Adding requests:   6%|▋         | 514/8192 [00:01<00:15, 505.30it/s]
Adding requests:   7%|▋         | 565/8192 [00:01<00:15, 504.08it/s]
Adding requests:   8%|▊         | 616/8192 [00:01<00:15, 498.07it/s]
Adding requests:   8%|▊         | 669/8192 [00:01<00:14, 507.21it/s]
Adding requests:   9%|▉         | 722/8192 [00:01<00:14, 513.45it/s]
Adding requests:   9%|▉         | 774/8192 [00:01<00:14, 509.81it/s]
Adding requests:  10%|█         | 826/8192 [00:01<00:14, 503.39it/s]
Adding requests:  11%|█         | 878/8192 [00:01<00:14, 507.30it/s]
Adding requests:  11%|█▏        | 932/8192 [00:01<00:14, 515.03it/s]
Adding requests:  12%|█▏        | 984/8192 [00:01<00:13, 515.71it/s]
Adding requests:  13%|█▎        | 1037/8192 [00:02<00:13, 519.60it/s]
Adding requests:  13%|█▎        | 1089/8192 [00:02<00:13, 516.56it/s]
Adding requests:  14%|█▍        | 1141/8192 [00:02<00:13, 513.22it/s]
Adding requests:  15%|█▍        | 1196/8192 [00:02<00:13, 523.83it/s]
Adding requests:  15%|█▌        | 1249/8192 [00:02<00:13, 523.90it/s]
Adding requests:  16%|█▌        | 1302/8192 [00:02<00:13, 520.14it/s]
Adding requests:  17%|█▋        | 1355/8192 [00:02<00:13, 522.95it/s]
Adding requests:  17%|█▋        | 1409/8192 [00:02<00:12, 527.42it/s]
Adding requests:  18%|█▊        | 1462/8192 [00:02<00:12, 526.15it/s]
Adding requests:  18%|█▊        | 1515/8192 [00:02<00:12, 526.83it/s]
Adding requests:  19%|█▉        | 1568/8192 [00:03<00:12, 526.07it/s]
Adding requests:  20%|█▉        | 1622/8192 [00:03<00:12, 529.28it/s]
Adding requests:  20%|██        | 1675/8192 [00:03<00:12, 526.95it/s]
Adding requests:  21%|██        | 1728/8192 [00:03<00:12, 517.19it/s]
Adding requests:  22%|██▏       | 1780/8192 [00:03<00:12, 514.20it/s]
Adding requests:  22%|██▏       | 1833/8192 [00:03<00:12, 518.45it/s]
Adding requests:  23%|██▎       | 1886/8192 [00:03<00:12, 520.22it/s]
Adding requests:  24%|██▎       | 1939/8192 [00:03<00:12, 519.62it/s]
Adding requests:  24%|██▍       | 1991/8192 [00:03<00:11, 518.75it/s]
Adding requests:  25%|██▍       | 2044/8192 [00:03<00:11, 519.83it/s]
Adding requests:  26%|██▌       | 2098/8192 [00:04<00:11, 523.30it/s]
Adding requests:  26%|██▋       | 2151/8192 [00:04<00:11, 517.26it/s]
Adding requests:  27%|██▋       | 2203/8192 [00:04<00:11, 514.09it/s]
Adding requests:  28%|██▊       | 2257/8192 [00:04<00:11, 520.84it/s]
Adding requests:  28%|██▊       | 2310/8192 [00:04<00:11, 520.63it/s]
Adding requests:  29%|██▉       | 2363/8192 [00:04<00:11, 518.57it/s]
Adding requests:  29%|██▉       | 2416/8192 [00:04<00:11, 519.96it/s]
Adding requests:  30%|███       | 2469/8192 [00:04<00:11, 519.50it/s]
Adding requests:  31%|███       | 2521/8192 [00:04<00:10, 519.64it/s]
Adding requests:  31%|███▏      | 2575/8192 [00:04<00:10, 523.40it/s]
Adding requests:  32%|███▏      | 2628/8192 [00:05<00:10, 522.67it/s]
Adding requests:  33%|███▎      | 2681/8192 [00:05<00:10, 522.73it/s]
Adding requests:  33%|███▎      | 2734/8192 [00:05<00:10, 518.63it/s]
Adding requests:  34%|███▍      | 2786/8192 [00:05<00:10, 519.02it/s]
Adding requests:  35%|███▍      | 2838/8192 [00:05<00:10, 517.12it/s]
Adding requests:  35%|███▌      | 2892/8192 [00:05<00:10, 520.57it/s]
Adding requests:  36%|███▌      | 2945/8192 [00:05<00:10, 517.07it/s]
Adding requests:  37%|███▋      | 2997/8192 [00:05<00:10, 507.64it/s]
Adding requests:  37%|███▋      | 3049/8192 [00:05<00:10, 509.96it/s]
Adding requests:  38%|███▊      | 3101/8192 [00:06<00:09, 510.10it/s]
Adding requests:  38%|███▊      | 3153/8192 [00:06<00:09, 511.38it/s]
Adding requests:  39%|███▉      | 3205/8192 [00:06<00:09, 512.01it/s]
Adding requests:  40%|███▉      | 3258/8192 [00:06<00:09, 515.35it/s]
Adding requests:  40%|████      | 3311/8192 [00:06<00:09, 519.37it/s]
Adding requests:  41%|████      | 3365/8192 [00:06<00:09, 524.10it/s]
Adding requests:  42%|████▏     | 3418/8192 [00:06<00:09, 523.69it/s]
Adding requests:  42%|████▏     | 3471/8192 [00:06<00:09, 514.17it/s]
Adding requests:  43%|████▎     | 3524/8192 [00:06<00:09, 516.22it/s]
Adding requests:  44%|████▎     | 3576/8192 [00:06<00:08, 516.42it/s]
Adding requests:  44%|████▍     | 3628/8192 [00:07<00:08, 512.94it/s]
Adding requests:  45%|████▍     | 3681/8192 [00:07<00:08, 515.63it/s]
Adding requests:  46%|████▌     | 3733/8192 [00:07<00:08, 514.20it/s]
Adding requests:  46%|████▌     | 3788/8192 [00:07<00:08, 522.38it/s]
Adding requests:  47%|████▋     | 3841/8192 [00:07<00:08, 523.55it/s]
Adding requests:  48%|████▊     | 3894/8192 [00:07<00:08, 524.81it/s]
Adding requests:  48%|████▊     | 3947/8192 [00:07<00:08, 524.56it/s]
Adding requests:  49%|████▉     | 4000/8192 [00:07<00:08, 521.17it/s]
Adding requests:  49%|████▉     | 4053/8192 [00:07<00:07, 519.75it/s]
Adding requests:  50%|█████     | 4105/8192 [00:07<00:07, 518.64it/s]
Adding requests:  51%|█████     | 4158/8192 [00:08<00:07, 519.50it/s]
Adding requests:  51%|█████▏    | 4212/8192 [00:08<00:07, 523.88it/s]
Adding requests:  52%|█████▏    | 4265/8192 [00:08<00:07, 511.60it/s]
Adding requests:  53%|█████▎    | 4317/8192 [00:08<00:07, 512.31it/s]
Adding requests:  53%|█████▎    | 4371/8192 [00:08<00:07, 520.35it/s]
Adding requests:  54%|█████▍    | 4424/8192 [00:08<00:07, 521.38it/s]
Adding requests:  55%|█████▍    | 4478/8192 [00:08<00:07, 525.38it/s]
Adding requests:  55%|█████▌    | 4531/8192 [00:08<00:07, 516.70it/s]
Adding requests:  56%|█████▌    | 4584/8192 [00:08<00:06, 517.64it/s]
Adding requests:  57%|█████▋    | 4638/8192 [00:08<00:06, 523.13it/s]
Adding requests:  57%|█████▋    | 4691/8192 [00:09<00:06, 518.94it/s]
Adding requests:  58%|█████▊    | 4745/8192 [00:09<00:06, 524.04it/s]
Adding requests:  59%|█████▊    | 4798/8192 [00:09<00:06, 519.63it/s]
Adding requests:  59%|█████▉    | 4851/8192 [00:09<00:06, 519.97it/s]
Adding requests:  60%|█████▉    | 4904/8192 [00:09<00:06, 515.32it/s]
Adding requests:  61%|██████    | 4957/8192 [00:09<00:06, 515.95it/s]
Adding requests:  61%|██████    | 5010/8192 [00:09<00:06, 519.38it/s]
Adding requests:  62%|██████▏   | 5064/8192 [00:09<00:05, 523.04it/s]
Adding requests:  62%|██████▏   | 5119/8192 [00:09<00:05, 529.00it/s]
Adding requests:  63%|██████▎   | 5172/8192 [00:09<00:05, 526.10it/s]
Adding requests:  64%|██████▍   | 5225/8192 [00:10<00:05, 520.56it/s]
Adding requests:  64%|██████▍   | 5278/8192 [00:10<00:05, 518.74it/s]
Adding requests:  65%|██████▌   | 5332/8192 [00:10<00:05, 524.09it/s]
Adding requests:  66%|██████▌   | 5385/8192 [00:10<00:05, 522.50it/s]
Adding requests:  66%|██████▋   | 5438/8192 [00:10<00:05, 524.03it/s]
Adding requests:  67%|██████▋   | 5491/8192 [00:10<00:05, 516.34it/s]
Adding requests:  68%|██████▊   | 5543/8192 [00:10<00:05, 515.83it/s]
Adding requests:  68%|██████▊   | 5595/8192 [00:10<00:05, 501.29it/s]
Adding requests:  69%|██████▉   | 5647/8192 [00:10<00:05, 504.27it/s]
Adding requests:  70%|██████▉   | 5698/8192 [00:11<00:04, 502.66it/s]
Adding requests:  70%|███████   | 5751/8192 [00:11<00:04, 510.44it/s]
Adding requests:  71%|███████   | 5803/8192 [00:11<00:04, 512.10it/s]
Adding requests:  71%|███████▏  | 5855/8192 [00:11<00:04, 514.37it/s]
Adding requests:  72%|███████▏  | 5909/8192 [00:11<00:04, 521.13it/s]
Adding requests:  73%|███████▎  | 5962/8192 [00:11<00:04, 518.56it/s]
Adding requests:  73%|███████▎  | 6016/8192 [00:11<00:04, 522.97it/s]
Adding requests:  74%|███████▍  | 6070/8192 [00:11<00:04, 527.42it/s]
Adding requests:  75%|███████▍  | 6123/8192 [00:11<00:03, 523.13it/s]
Adding requests:  75%|███████▌  | 6176/8192 [00:11<00:03, 522.79it/s]
Adding requests:  76%|███████▌  | 6231/8192 [00:12<00:03, 529.75it/s]
Adding requests:  77%|███████▋  | 6285/8192 [00:12<00:03, 531.64it/s]
Adding requests:  77%|███████▋  | 6339/8192 [00:12<00:03, 532.48it/s]
Adding requests:  78%|███████▊  | 6393/8192 [00:12<00:03, 533.47it/s]
Adding requests:  79%|███████▊  | 6448/8192 [00:12<00:03, 535.99it/s]
Adding requests:  79%|███████▉  | 6502/8192 [00:12<00:03, 536.62it/s]
Adding requests:  80%|████████  | 6556/8192 [00:12<00:03, 537.24it/s]
Adding requests:  81%|████████  | 6610/8192 [00:12<00:02, 532.17it/s]
Adding requests:  81%|████████▏ | 6664/8192 [00:12<00:02, 528.86it/s]
Adding requests:  82%|████████▏ | 6718/8192 [00:12<00:02, 530.89it/s]
Adding requests:  83%|████████▎ | 6772/8192 [00:13<00:02, 528.64it/s]
Adding requests:  83%|████████▎ | 6827/8192 [00:13<00:02, 532.68it/s]
Adding requests:  84%|████████▍ | 6881/8192 [00:13<00:02, 520.67it/s]
Adding requests:  85%|████████▍ | 6937/8192 [00:13<00:02, 530.20it/s]
Adding requests:  85%|████████▌ | 6991/8192 [00:13<00:02, 528.85it/s]
Adding requests:  86%|████████▌ | 7044/8192 [00:13<00:02, 525.89it/s]
Adding requests:  87%|████████▋ | 7097/8192 [00:13<00:02, 526.86it/s]
Adding requests:  87%|████████▋ | 7151/8192 [00:13<00:01, 528.45it/s]
Adding requests:  88%|████████▊ | 7204/8192 [00:13<00:01, 526.89it/s]
Adding requests:  89%|████████▊ | 7258/8192 [00:13<00:01, 529.27it/s]
Adding requests:  89%|████████▉ | 7312/8192 [00:14<00:01, 531.15it/s]
Adding requests:  90%|████████▉ | 7366/8192 [00:14<00:01, 530.45it/s]
Adding requests:  91%|█████████ | 7421/8192 [00:14<00:01, 536.18it/s]
Adding requests:  91%|█████████▏| 7476/8192 [00:14<00:01, 538.15it/s]
Adding requests:  92%|█████████▏| 7530/8192 [00:14<00:01, 536.52it/s]
Adding requests:  93%|█████████▎| 7584/8192 [00:14<00:01, 533.46it/s]
Adding requests:  93%|█████████▎| 7638/8192 [00:14<00:01, 530.60it/s]
Adding requests:  94%|█████████▍| 7693/8192 [00:14<00:00, 536.21it/s]
Adding requests:  95%|█████████▍| 7747/8192 [00:14<00:00, 533.16it/s]
Adding requests:  95%|█████████▌| 7801/8192 [00:14<00:00, 525.49it/s]
Adding requests:  96%|█████████▌| 7855/8192 [00:15<00:00, 528.92it/s]
Adding requests:  97%|█████████▋| 7908/8192 [00:15<00:00, 525.63it/s]
Adding requests:  97%|█████████▋| 7961/8192 [00:15<00:00, 524.05it/s]
Adding requests:  98%|█████████▊| 8014/8192 [00:15<00:00, 523.24it/s]
Adding requests:  98%|█████████▊| 8067/8192 [00:15<00:00, 523.10it/s]
Adding requests:  99%|█████████▉| 8121/8192 [00:15<00:00, 527.73it/s]
Adding requests: 100%|█████████▉| 8174/8192 [00:15<00:00, 513.46it/s]
Adding requests: 100%|██████████| 8192/8192 [00:15<00:00, 520.24it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  38%|███▊      | 3073/8192 [00:00<00:00, 9582.97it/s, est. speed input: 9813699.39 toks/s, output: 9583.18 toks/s]
Processed prompts:  49%|████▉     | 4032/8192 [00:04<00:06, 651.88it/s, est. speed input: 848297.01 toks/s, output: 828.41 toks/s]   
Processed prompts:  54%|█████▍    | 4440/8192 [00:07<00:08, 461.97it/s, est. speed input: 638274.38 toks/s, output: 623.31 toks/s]
Processed prompts:  57%|█████▋    | 4670/8192 [00:08<00:08, 417.67it/s, est. speed input: 591154.60 toks/s, output: 577.30 toks/s]
Processed prompts:  59%|█████▉    | 4819/8192 [00:09<00:09, 359.13it/s, est. speed input: 544578.87 toks/s, output: 531.81 toks/s]
Processed prompts:  60%|██████    | 4920/8192 [00:09<00:09, 354.04it/s, est. speed input: 536487.40 toks/s, output: 523.91 toks/s]
Processed prompts:  61%|██████    | 4997/8192 [00:10<00:10, 304.42it/s, est. speed input: 510058.54 toks/s, output: 498.10 toks/s]
Processed prompts:  62%|██████▏   | 5057/8192 [00:10<00:10, 289.31it/s, est. speed input: 500328.72 toks/s, output: 488.60 toks/s]
Processed prompts:  63%|██████▎   | 5121/8192 [00:10<00:11, 273.69it/s, est. speed input: 490955.17 toks/s, output: 479.45 toks/s]
Processed prompts:  63%|██████▎   | 5185/8192 [00:10<00:11, 260.66it/s, est. speed input: 482773.86 toks/s, output: 471.46 toks/s]
Processed prompts:  64%|██████▍   | 5249/8192 [00:11<00:11, 248.59it/s, est. speed input: 475057.36 toks/s, output: 463.92 toks/s]
Processed prompts:  65%|██████▍   | 5313/8192 [00:11<00:12, 237.82it/s, est. speed input: 467712.60 toks/s, output: 456.75 toks/s]
Processed prompts:  66%|██████▌   | 5377/8192 [00:11<00:12, 227.60it/s, est. speed input: 460482.91 toks/s, output: 449.69 toks/s]
Processed prompts:  66%|██████▋   | 5441/8192 [00:12<00:12, 220.98it/s, est. speed input: 453933.01 toks/s, output: 443.29 toks/s]
Processed prompts:  67%|██████▋   | 5505/8192 [00:12<00:12, 214.51it/s, est. speed input: 447452.73 toks/s, output: 436.96 toks/s]
Processed prompts:  68%|██████▊   | 5569/8192 [00:12<00:12, 209.49it/s, est. speed input: 441258.58 toks/s, output: 430.92 toks/s]
Processed prompts:  69%|██████▉   | 5633/8192 [00:13<00:12, 207.38it/s, est. speed input: 435649.99 toks/s, output: 425.44 toks/s]
Processed prompts:  70%|██████▉   | 5697/8192 [00:13<00:12, 204.86it/s, est. speed input: 430135.32 toks/s, output: 420.05 toks/s]
Processed prompts:  70%|███████   | 5761/8192 [00:13<00:12, 201.88it/s, est. speed input: 424681.39 toks/s, output: 414.73 toks/s]
Processed prompts:  71%|███████   | 5825/8192 [00:14<00:11, 199.40it/s, est. speed input: 419418.73 toks/s, output: 409.59 toks/s]
Processed prompts:  72%|███████▏  | 5889/8192 [00:14<00:11, 199.86it/s, est. speed input: 414739.77 toks/s, output: 405.02 toks/s]
Processed prompts:  73%|███████▎  | 5953/8192 [00:14<00:11, 199.22it/s, est. speed input: 410116.38 toks/s, output: 400.50 toks/s]
Processed prompts:  73%|███████▎  | 6017/8192 [00:15<00:10, 199.27it/s, est. speed input: 405763.39 toks/s, output: 396.25 toks/s]
Processed prompts:  74%|███████▍  | 6081/8192 [00:15<00:10, 198.26it/s, est. speed input: 401443.11 toks/s, output: 392.03 toks/s]
Processed prompts:  75%|███████▌  | 6145/8192 [00:15<00:10, 198.85it/s, est. speed input: 397478.63 toks/s, output: 388.16 toks/s]
Processed prompts:  76%|███████▌  | 6209/8192 [00:16<00:09, 198.42it/s, est. speed input: 393558.23 toks/s, output: 384.33 toks/s]
Processed prompts:  77%|███████▋  | 6273/8192 [00:16<00:09, 197.57it/s, est. speed input: 389721.98 toks/s, output: 380.59 toks/s]
Processed prompts:  77%|███████▋  | 6337/8192 [00:16<00:09, 197.42it/s, est. speed input: 386090.95 toks/s, output: 377.04 toks/s]
Processed prompts:  78%|███████▊  | 6401/8192 [00:17<00:09, 197.39it/s, est. speed input: 382606.98 toks/s, output: 373.64 toks/s]
Processed prompts:  79%|███████▉  | 6465/8192 [00:17<00:08, 196.29it/s, est. speed input: 379123.19 toks/s, output: 370.24 toks/s]
Processed prompts:  80%|███████▉  | 6529/8192 [00:17<00:08, 197.06it/s, est. speed input: 375948.07 toks/s, output: 367.14 toks/s]
Processed prompts:  80%|████████  | 6593/8192 [00:18<00:08, 197.73it/s, est. speed input: 372899.30 toks/s, output: 364.16 toks/s]
Processed prompts:  81%|████████▏ | 6657/8192 [00:18<00:07, 198.04it/s, est. speed input: 369940.36 toks/s, output: 361.27 toks/s]
Processed prompts:  82%|████████▏ | 6721/8192 [00:18<00:07, 197.33it/s, est. speed input: 366983.63 toks/s, output: 358.38 toks/s]
Processed prompts:  83%|████████▎ | 6785/8192 [00:19<00:07, 197.09it/s, est. speed input: 364155.04 toks/s, output: 355.62 toks/s]
Processed prompts:  84%|████████▎ | 6849/8192 [00:19<00:06, 197.52it/s, est. speed input: 361481.87 toks/s, output: 353.01 toks/s]
Processed prompts:  84%|████████▍ | 6913/8192 [00:19<00:06, 197.39it/s, est. speed input: 358853.68 toks/s, output: 350.44 toks/s]
Processed prompts:  85%|████████▌ | 6977/8192 [00:20<00:06, 197.36it/s, est. speed input: 356316.37 toks/s, output: 347.96 toks/s]
Processed prompts:  86%|████████▌ | 7041/8192 [00:20<00:05, 197.43it/s, est. speed input: 353869.04 toks/s, output: 345.57 toks/s]
Processed prompts:  87%|████████▋ | 7105/8192 [00:20<00:05, 199.38it/s, est. speed input: 351672.57 toks/s, output: 343.43 toks/s]
Processed prompts:  88%|████████▊ | 7169/8192 [00:21<00:05, 198.40it/s, est. speed input: 349330.56 toks/s, output: 341.14 toks/s]
Processed prompts:  88%|████████▊ | 7233/8192 [00:21<00:04, 198.85it/s, est. speed input: 347160.41 toks/s, output: 339.02 toks/s]
Processed prompts:  89%|████████▉ | 7297/8192 [00:21<00:04, 198.43it/s, est. speed input: 344991.59 toks/s, output: 336.91 toks/s]
Processed prompts:  90%|████████▉ | 7361/8192 [00:21<00:04, 198.33it/s, est. speed input: 342902.50 toks/s, output: 334.87 toks/s]
Processed prompts:  91%|█████████ | 7425/8192 [00:22<00:03, 198.56it/s, est. speed input: 340898.69 toks/s, output: 332.91 toks/s]
Processed prompts:  91%|█████████▏| 7489/8192 [00:22<00:03, 198.50it/s, est. speed input: 338933.93 toks/s, output: 330.99 toks/s]
Processed prompts:  92%|█████████▏| 7553/8192 [00:22<00:03, 199.48it/s, est. speed input: 337105.59 toks/s, output: 329.20 toks/s]
Processed prompts:  93%|█████████▎| 7617/8192 [00:23<00:02, 199.21it/s, est. speed input: 335252.55 toks/s, output: 327.39 toks/s]
Processed prompts:  94%|█████████▍| 7681/8192 [00:23<00:02, 198.69it/s, est. speed input: 333424.85 toks/s, output: 325.61 toks/s]
Processed prompts:  95%|█████████▍| 7745/8192 [00:23<00:02, 197.36it/s, est. speed input: 331573.56 toks/s, output: 323.80 toks/s]
Processed prompts:  95%|█████████▌| 7809/8192 [00:24<00:01, 197.13it/s, est. speed input: 329824.52 toks/s, output: 322.09 toks/s]
Processed prompts:  96%|█████████▌| 7873/8192 [00:24<00:01, 196.60it/s, est. speed input: 328095.10 toks/s, output: 320.40 toks/s]
Processed prompts:  97%|█████████▋| 7937/8192 [00:24<00:01, 196.21it/s, est. speed input: 326408.75 toks/s, output: 318.76 toks/s]
Processed prompts:  98%|█████████▊| 8001/8192 [00:25<00:00, 196.86it/s, est. speed input: 324832.25 toks/s, output: 317.22 toks/s]
Processed prompts:  98%|█████████▊| 8065/8192 [00:25<00:00, 198.23it/s, est. speed input: 323358.85 toks/s, output: 315.78 toks/s]
Processed prompts:  99%|█████████▉| 8129/8192 [00:25<00:00, 199.13it/s, est. speed input: 321916.87 toks/s, output: 314.37 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:25<00:00, 199.13it/s, est. speed input: 324390.28 toks/s, output: 316.79 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:25<00:00, 316.79it/s, est. speed input: 324390.28 toks/s, output: 316.79 toks/s]
[rank0]:[W126 08:24:52.904174978 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 09:33:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:34:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1146635) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1146635) WARNING 01-26 09:34:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.57 requests/s, 17735.48 total tokens/s, 34.57 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 09:33:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:34:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:34:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:34:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:34:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:34:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:34:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:34:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:34:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:34:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:34:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:34:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1146635) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1146635) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1146635) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1146635) 
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1146635) [2026-01-26 09:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1146635) 2026-01-26 09:34:23,087 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1146635) 2026-01-26 09:34:23,110 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1146635) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]
(EngineCore_DP0 pid=1146635) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.92it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  44%|████▍     | 56/128 [00:00<00:00, 555.74it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 720.78it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:23,  5.36it/s, est. speed input: 2745.81 toks/s, output: 5.36 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 19.88it/s, est. speed input: 8755.86 toks/s, output: 17.10 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 26.90it/s, est. speed input: 11583.26 toks/s, output: 22.62 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 30.87it/s, est. speed input: 13232.36 toks/s, output: 25.84 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 33.29it/s, est. speed input: 14311.26 toks/s, output: 27.95 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 34.79it/s, est. speed input: 15064.75 toks/s, output: 29.42 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 35.82it/s, est. speed input: 15629.85 toks/s, output: 30.53 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 36.47it/s, est. speed input: 16061.06 toks/s, output: 31.37 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 36.94it/s, est. speed input: 16407.95 toks/s, output: 32.05 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 37.29it/s, est. speed input: 16694.44 toks/s, output: 32.61 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 37.54it/s, est. speed input: 16932.93 toks/s, output: 33.07 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 37.69it/s, est. speed input: 17131.95 toks/s, output: 33.46 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 37.82it/s, est. speed input: 17304.14 toks/s, output: 33.80 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 37.91it/s, est. speed input: 17453.20 toks/s, output: 34.09 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 37.90it/s, est. speed input: 17577.23 toks/s, output: 34.33 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 37.94it/s, est. speed input: 17689.84 toks/s, output: 34.55 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 37.97it/s, est. speed input: 17790.44 toks/s, output: 34.75 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 38.01it/s, est. speed input: 17882.03 toks/s, output: 34.93 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 38.05it/s, est. speed input: 17965.00 toks/s, output: 35.09 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 38.04it/s, est. speed input: 18037.28 toks/s, output: 35.23 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 38.06it/s, est. speed input: 18104.87 toks/s, output: 35.36 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 38.09it/s, est. speed input: 18167.25 toks/s, output: 35.48 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 38.00it/s, est. speed input: 18217.45 toks/s, output: 35.58 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 38.01it/s, est. speed input: 18268.08 toks/s, output: 35.68 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 38.04it/s, est. speed input: 18316.37 toks/s, output: 35.77 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 38.06it/s, est. speed input: 18360.53 toks/s, output: 35.86 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 38.12it/s, est. speed input: 18404.62 toks/s, output: 35.95 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 38.16it/s, est. speed input: 18445.65 toks/s, output: 36.03 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 38.14it/s, est. speed input: 18481.25 toks/s, output: 36.10 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 38.18it/s, est. speed input: 18516.88 toks/s, output: 36.17 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 38.17it/s, est. speed input: 18548.73 toks/s, output: 36.23 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 38.20it/s, est. speed input: 18580.53 toks/s, output: 36.29 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 38.20it/s, est. speed input: 18602.20 toks/s, output: 36.33 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.33it/s, est. speed input: 18602.20 toks/s, output: 36.33 toks/s]
[rank0]:[W126 09:34:29.574869099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 09:34:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:34:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1147718) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1147718) WARNING 01-26 09:34:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.69 requests/s, 35554.25 total tokens/s, 34.69 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 09:34:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:34:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:34:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:34:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:34:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:34:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:34:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:34:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:34:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:34:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:34:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:34:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:34:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:34:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1147718) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1147718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1147718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1147718) 
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1147718) [2026-01-26 09:34:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1147718) 2026-01-26 09:35:06,570 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1147718) 2026-01-26 09:35:06,594 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1147718) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.80it/s]
(EngineCore_DP0 pid=1147718) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.30it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  22%|██▏       | 28/128 [00:00<00:00, 278.99it/s]
Adding requests:  63%|██████▎   | 81/128 [00:00<00:00, 424.31it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 435.43it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 65.24it/s, est. speed input: 66815.37 toks/s, output: 65.24 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:02, 45.82it/s, est. speed input: 49272.90 toks/s, output: 48.11 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:02, 42.19it/s, est. speed input: 45832.74 toks/s, output: 44.76 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 40.35it/s, est. speed input: 44047.15 toks/s, output: 43.01 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 39.24it/s, est. speed input: 42917.17 toks/s, output: 41.91 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 38.69it/s, est. speed input: 42298.78 toks/s, output: 41.31 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:00<00:02, 38.26it/s, est. speed input: 41814.17 toks/s, output: 40.83 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 37.94it/s, est. speed input: 41425.22 toks/s, output: 40.45 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 37.67it/s, est. speed input: 41093.10 toks/s, output: 40.13 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 37.48it/s, est. speed input: 40818.41 toks/s, output: 39.86 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:01, 37.39it/s, est. speed input: 40603.37 toks/s, output: 39.65 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:01, 37.31it/s, est. speed input: 40412.77 toks/s, output: 39.46 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 37.29it/s, est. speed input: 40258.36 toks/s, output: 39.31 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 37.19it/s, est. speed input: 40102.27 toks/s, output: 39.16 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 37.15it/s, est. speed input: 39973.73 toks/s, output: 39.04 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:01<00:01, 37.21it/s, est. speed input: 39876.22 toks/s, output: 38.94 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 37.03it/s, est. speed input: 39746.26 toks/s, output: 38.81 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 37.15it/s, est. speed input: 39675.22 toks/s, output: 38.74 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 37.18it/s, est. speed input: 39600.77 toks/s, output: 38.67 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 37.22it/s, est. speed input: 39536.60 toks/s, output: 38.61 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:00, 36.78it/s, est. speed input: 39404.56 toks/s, output: 38.48 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 36.47it/s, est. speed input: 39282.63 toks/s, output: 38.36 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 36.28it/s, est. speed input: 39174.25 toks/s, output: 38.26 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 36.11it/s, est. speed input: 39070.04 toks/s, output: 38.15 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:02<00:00, 35.97it/s, est. speed input: 38969.95 toks/s, output: 38.06 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 35.85it/s, est. speed input: 38875.67 toks/s, output: 37.96 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 35.84it/s, est. speed input: 38796.17 toks/s, output: 37.89 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 35.78it/s, est. speed input: 38716.25 toks/s, output: 37.81 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 35.78it/s, est. speed input: 38646.54 toks/s, output: 37.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.78it/s, est. speed input: 38612.43 toks/s, output: 37.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.71it/s, est. speed input: 38612.43 toks/s, output: 37.71 toks/s]
[rank0]:[W126 09:35:12.425608228 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 09:35:14
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:35:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1148826) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1148826) WARNING 01-26 09:35:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 65.44 requests/s, 67073.01 total tokens/s, 65.44 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 09:35:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:35:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:35:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:35:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:35:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:35:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:35:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:35:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:35:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:35:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:35:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:35:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:35:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:35:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:35:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:35:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:35:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1148826) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1148826) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1148826) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1148826) 
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1148826) [2026-01-26 09:35:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1148826) 2026-01-26 09:35:48,929 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1148826) 2026-01-26 09:35:48,952 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1148826) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.01it/s]
(EngineCore_DP0 pid=1148826) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.86it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 27/256 [00:00<00:00, 265.77it/s]
Adding requests:  31%|███▏      | 80/256 [00:00<00:00, 419.15it/s]
Adding requests:  51%|█████     | 131/256 [00:00<00:00, 459.00it/s]
Adding requests:  71%|███████   | 181/256 [00:00<00:00, 473.60it/s]
Adding requests:  91%|█████████ | 233/256 [00:00<00:00, 488.89it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 466.20it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 210.74it/s, est. speed input: 215828.49 toks/s, output: 210.74 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:00<00:02, 100.50it/s, est. speed input: 111686.75 toks/s, output: 109.06 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:00<00:02, 88.52it/s, est. speed input: 99511.65 toks/s, output: 97.17 toks/s]   
Processed prompts:  27%|██▋       | 69/256 [00:00<00:02, 85.50it/s, est. speed input: 95907.16 toks/s, output: 93.66 toks/s]
Processed prompts:  31%|███       | 79/256 [00:00<00:02, 81.32it/s, est. speed input: 92327.99 toks/s, output: 90.16 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:01<00:02, 76.20it/s, est. speed input: 88703.57 toks/s, output: 86.62 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:01<00:02, 75.08it/s, est. speed input: 87206.89 toks/s, output: 85.16 toks/s]
Processed prompts:  41%|████      | 104/256 [00:01<00:02, 74.15it/s, est. speed input: 85955.23 toks/s, output: 83.94 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:01<00:01, 73.42it/s, est. speed input: 84902.59 toks/s, output: 82.91 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:01<00:01, 72.95it/s, est. speed input: 84032.93 toks/s, output: 82.06 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:01<00:01, 72.62it/s, est. speed input: 83287.21 toks/s, output: 81.33 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:01<00:01, 72.26it/s, est. speed input: 82611.80 toks/s, output: 80.67 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:01<00:01, 72.09it/s, est. speed input: 82038.53 toks/s, output: 80.11 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:01<00:01, 71.98it/s, est. speed input: 81536.76 toks/s, output: 79.62 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:02<00:01, 71.93it/s, est. speed input: 81095.13 toks/s, output: 79.19 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:02<00:01, 71.84it/s, est. speed input: 80691.01 toks/s, output: 78.80 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:02<00:01, 71.85it/s, est. speed input: 80336.87 toks/s, output: 78.45 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:02<00:01, 71.72it/s, est. speed input: 79995.36 toks/s, output: 78.12 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:02<00:00, 71.69it/s, est. speed input: 79693.51 toks/s, output: 77.82 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:02<00:00, 71.59it/s, est. speed input: 79405.53 toks/s, output: 77.54 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:02<00:00, 71.55it/s, est. speed input: 79146.03 toks/s, output: 77.29 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:02<00:00, 71.52it/s, est. speed input: 78906.90 toks/s, output: 77.06 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:02<00:00, 71.50it/s, est. speed input: 78686.75 toks/s, output: 76.84 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:03<00:00, 71.55it/s, est. speed input: 78491.20 toks/s, output: 76.65 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:03<00:00, 71.57it/s, est. speed input: 78307.75 toks/s, output: 76.47 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:03<00:00, 71.70it/s, est. speed input: 78151.99 toks/s, output: 76.32 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.73it/s, est. speed input: 77998.21 toks/s, output: 76.17 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.73it/s, est. speed input: 77998.21 toks/s, output: 76.17 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 76.16it/s, est. speed input: 77998.21 toks/s, output: 76.17 toks/s]
[rank0]:[W126 09:35:55.611888516 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 09:35:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:36:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1149938) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1149938) WARNING 01-26 09:36:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 74.20 requests/s, 76059.43 total tokens/s, 74.20 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 09:36:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:36:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:36:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:36:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:36:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:36:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:36:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:36:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:36:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:36:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:36:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:36:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1149938) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1149938) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1149938) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1149938) 
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1149938) [2026-01-26 09:36:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1149938) 2026-01-26 09:36:33,875 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1149938) 2026-01-26 09:36:33,901 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1149938) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  6.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 13.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 12.42it/s]
(EngineCore_DP0 pid=1149938) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 19.16it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 19.62it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 31/512 [00:00<00:01, 304.74it/s]
Adding requests:  16%|█▌        | 83/512 [00:00<00:01, 426.93it/s]
Adding requests:  26%|██▌       | 134/512 [00:00<00:00, 461.19it/s]
Adding requests:  36%|███▌      | 183/512 [00:00<00:00, 470.01it/s]
Adding requests:  46%|████▌     | 234/512 [00:00<00:00, 483.33it/s]
Adding requests:  56%|█████▌    | 285/512 [00:00<00:00, 490.09it/s]
Adding requests:  65%|██████▌   | 335/512 [00:00<00:00, 489.90it/s]
Adding requests:  75%|███████▌  | 386/512 [00:00<00:00, 495.72it/s]
Adding requests:  85%|████████▌ | 437/512 [00:00<00:00, 499.07it/s]
Adding requests:  95%|█████████▌| 488/512 [00:01<00:00, 501.40it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 482.31it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:00<00:00, 660.13it/s, est. speed input: 676100.54 toks/s, output: 660.17 toks/s]
Processed prompts:  27%|██▋       | 137/512 [00:00<00:02, 127.09it/s, est. speed input: 148529.52 toks/s, output: 145.05 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:01<00:03, 107.29it/s, est. speed input: 127177.80 toks/s, output: 124.20 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:01<00:03, 95.37it/s, est. speed input: 116285.61 toks/s, output: 113.56 toks/s] 
Processed prompts:  40%|████      | 206/512 [00:01<00:03, 90.87it/s, est. speed input: 111866.82 toks/s, output: 109.24 toks/s]
Processed prompts:  43%|████▎     | 219/512 [00:02<00:03, 89.27it/s, est. speed input: 109754.64 toks/s, output: 107.18 toks/s]
Processed prompts:  45%|████▌     | 231/512 [00:02<00:03, 86.58it/s, est. speed input: 107533.34 toks/s, output: 105.01 toks/s]
Processed prompts:  47%|████▋     | 241/512 [00:02<00:03, 88.21it/s, est. speed input: 107128.66 toks/s, output: 104.62 toks/s]
Processed prompts:  49%|████▉     | 251/512 [00:02<00:03, 81.91it/s, est. speed input: 104529.69 toks/s, output: 102.08 toks/s]
Processed prompts:  51%|█████     | 260/512 [00:02<00:03, 82.79it/s, est. speed input: 103870.04 toks/s, output: 101.44 toks/s]
Processed prompts:  53%|█████▎    | 269/512 [00:02<00:02, 83.51it/s, est. speed input: 103248.84 toks/s, output: 100.83 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:02<00:03, 74.77it/s, est. speed input: 100724.23 toks/s, output: 98.36 toks/s] 
Processed prompts:  56%|█████▌    | 286/512 [00:02<00:03, 74.96it/s, est. speed input: 99882.03 toks/s, output: 97.54 toks/s] 
Processed prompts:  57%|█████▋    | 294/512 [00:03<00:02, 75.28it/s, est. speed input: 99127.36 toks/s, output: 96.80 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:03<00:02, 75.48it/s, est. speed input: 98414.65 toks/s, output: 96.11 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:03<00:02, 75.88it/s, est. speed input: 97786.72 toks/s, output: 95.49 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:03<00:02, 76.13it/s, est. speed input: 97189.64 toks/s, output: 94.91 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:03<00:02, 76.41it/s, est. speed input: 96642.98 toks/s, output: 94.38 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:03<00:02, 76.48it/s, est. speed input: 96110.63 toks/s, output: 93.86 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:03<00:02, 77.73it/s, est. speed input: 95527.50 toks/s, output: 93.29 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:03<00:02, 77.30it/s, est. speed input: 95043.83 toks/s, output: 92.82 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:03<00:01, 76.91it/s, est. speed input: 94578.36 toks/s, output: 92.36 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:04<00:01, 76.81it/s, est. speed input: 94158.39 toks/s, output: 91.95 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:04<00:01, 76.59it/s, est. speed input: 93743.12 toks/s, output: 91.55 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:04<00:01, 76.68it/s, est. speed input: 93374.59 toks/s, output: 91.19 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:04<00:01, 76.65it/s, est. speed input: 93014.99 toks/s, output: 90.83 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:04<00:01, 76.65it/s, est. speed input: 92673.22 toks/s, output: 90.50 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:04<00:01, 76.63it/s, est. speed input: 92345.68 toks/s, output: 90.18 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:04<00:01, 76.44it/s, est. speed input: 92017.07 toks/s, output: 89.86 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:04<00:01, 76.36it/s, est. speed input: 91707.54 toks/s, output: 89.56 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:04<00:01, 76.23it/s, est. speed input: 91405.34 toks/s, output: 89.26 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:04<00:00, 76.38it/s, est. speed input: 91135.75 toks/s, output: 89.00 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:05<00:00, 78.33it/s, est. speed input: 90916.81 toks/s, output: 88.79 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:05<00:00, 77.85it/s, est. speed input: 90667.20 toks/s, output: 88.54 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:05<00:00, 77.40it/s, est. speed input: 90419.19 toks/s, output: 88.30 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:05<00:00, 77.25it/s, est. speed input: 90195.01 toks/s, output: 88.08 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:05<00:00, 76.97it/s, est. speed input: 89965.95 toks/s, output: 87.86 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:05<00:00, 76.81it/s, est. speed input: 89748.06 toks/s, output: 87.64 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:05<00:00, 76.53it/s, est. speed input: 89526.93 toks/s, output: 87.43 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 76.53it/s, est. speed input: 89833.74 toks/s, output: 87.73 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 87.72it/s, est. speed input: 89833.74 toks/s, output: 87.73 toks/s]
[rank0]:[W126 09:36:43.065559648 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 09:36:44
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:36:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1151117) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1151117) WARNING 01-26 09:37:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 79.44 requests/s, 81429.09 total tokens/s, 79.44 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 09:36:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:36:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:36:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:36:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:36:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:36:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:36:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:36:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:37:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:37:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:37:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:37:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:37:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:37:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:37:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:37:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1151117) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1151117) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1151117) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1151117) 
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1151117) [2026-01-26 09:37:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1151117) 2026-01-26 09:37:23,044 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1151117) 2026-01-26 09:37:23,069 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1151117) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.25it/s]
(EngineCore_DP0 pid=1151117) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.20it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.81it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 30/1024 [00:00<00:03, 296.25it/s]
Adding requests:   8%|▊         | 83/1024 [00:00<00:02, 428.87it/s]
Adding requests:  13%|█▎        | 134/1024 [00:00<00:01, 464.46it/s]
Adding requests:  18%|█▊        | 183/1024 [00:00<00:01, 474.35it/s]
Adding requests:  23%|██▎       | 235/1024 [00:00<00:01, 488.38it/s]
Adding requests:  28%|██▊       | 284/1024 [00:00<00:01, 488.12it/s]
Adding requests:  33%|███▎      | 335/1024 [00:00<00:01, 491.45it/s]
Adding requests:  38%|███▊      | 387/1024 [00:00<00:01, 500.03it/s]
Adding requests:  43%|████▎     | 439/1024 [00:00<00:01, 503.25it/s]
Adding requests:  48%|████▊     | 491/1024 [00:01<00:01, 505.51it/s]
Adding requests:  53%|█████▎    | 542/1024 [00:01<00:00, 493.15it/s]
Adding requests:  58%|█████▊    | 596/1024 [00:01<00:00, 503.31it/s]
Adding requests:  63%|██████▎   | 649/1024 [00:01<00:00, 509.79it/s]
Adding requests:  69%|██████▊   | 703/1024 [00:01<00:00, 517.67it/s]
Adding requests:  74%|███████▎  | 755/1024 [00:01<00:00, 515.78it/s]
Adding requests:  79%|███████▉  | 807/1024 [00:01<00:00, 509.88it/s]
Adding requests:  84%|████████▍ | 859/1024 [00:01<00:00, 509.06it/s]
Adding requests:  89%|████████▉ | 912/1024 [00:01<00:00, 514.36it/s]
Adding requests:  94%|█████████▍| 965/1024 [00:01<00:00, 516.82it/s]
Adding requests:  99%|█████████▉| 1017/1024 [00:02<00:00, 515.25it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 499.20it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:00<00:00, 896.23it/s, est. speed input: 917862.44 toks/s, output: 896.27 toks/s]
Processed prompts:  25%|██▍       | 252/1024 [00:01<00:04, 165.91it/s, est. speed input: 201566.55 toks/s, output: 196.84 toks/s]
Processed prompts:  29%|██▊       | 294/1024 [00:01<00:05, 136.11it/s, est. speed input: 169451.36 toks/s, output: 165.48 toks/s]
Processed prompts:  31%|███▏      | 321/1024 [00:02<00:05, 124.77it/s, est. speed input: 158091.43 toks/s, output: 154.39 toks/s]
Processed prompts:  33%|███▎      | 341/1024 [00:02<00:06, 110.68it/s, est. speed input: 147251.66 toks/s, output: 143.80 toks/s]
Processed prompts:  35%|███▍      | 356/1024 [00:02<00:06, 103.79it/s, est. speed input: 141839.26 toks/s, output: 138.51 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:02<00:06, 96.54it/s, est. speed input: 136851.05 toks/s, output: 133.64 toks/s] 
Processed prompts:  38%|███▊      | 386/1024 [00:02<00:06, 92.65it/s, est. speed input: 133179.38 toks/s, output: 130.06 toks/s]
Processed prompts:  39%|███▊      | 396/1024 [00:03<00:06, 93.71it/s, est. speed input: 132167.96 toks/s, output: 129.07 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:03<00:07, 86.87it/s, est. speed input: 128510.85 toks/s, output: 125.50 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:03<00:07, 84.97it/s, est. speed input: 125860.25 toks/s, output: 122.91 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:03<00:06, 83.77it/s, est. speed input: 123538.25 toks/s, output: 120.64 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:03<00:06, 83.77it/s, est. speed input: 121668.35 toks/s, output: 118.82 toks/s]
Processed prompts:  46%|████▌     | 467/1024 [00:03<00:06, 84.78it/s, est. speed input: 120899.80 toks/s, output: 118.07 toks/s]
Processed prompts:  46%|████▋     | 476/1024 [00:04<00:06, 85.66it/s, est. speed input: 120161.40 toks/s, output: 117.34 toks/s]
Processed prompts:  47%|████▋     | 485/1024 [00:04<00:06, 86.50it/s, est. speed input: 119468.46 toks/s, output: 116.67 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:04<00:06, 78.16it/s, est. speed input: 117048.11 toks/s, output: 114.30 toks/s]
Processed prompts:  50%|████▉     | 507/1024 [00:04<00:06, 80.70it/s, est. speed input: 116482.33 toks/s, output: 113.75 toks/s]
Processed prompts:  50%|█████     | 516/1024 [00:04<00:06, 82.83it/s, est. speed input: 115939.03 toks/s, output: 113.22 toks/s]
Processed prompts:  51%|█████▏    | 525/1024 [00:04<00:05, 84.60it/s, est. speed input: 115423.55 toks/s, output: 112.72 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:04<00:06, 76.36it/s, est. speed input: 113409.31 toks/s, output: 110.75 toks/s]
Processed prompts:  54%|█████▍    | 551/1024 [00:04<00:05, 88.72it/s, est. speed input: 113805.61 toks/s, output: 111.14 toks/s]
Processed prompts:  55%|█████▍    | 561/1024 [00:05<00:05, 91.32it/s, est. speed input: 113560.53 toks/s, output: 110.90 toks/s]
Processed prompts:  56%|█████▌    | 571/1024 [00:05<00:06, 74.13it/s, est. speed input: 111176.82 toks/s, output: 108.57 toks/s]
Processed prompts:  57%|█████▋    | 580/1024 [00:05<00:05, 77.71it/s, est. speed input: 110817.60 toks/s, output: 108.22 toks/s]
Processed prompts:  58%|█████▊    | 589/1024 [00:05<00:05, 80.68it/s, est. speed input: 110471.03 toks/s, output: 107.88 toks/s]
Processed prompts:  58%|█████▊    | 598/1024 [00:05<00:05, 83.00it/s, est. speed input: 110132.83 toks/s, output: 107.55 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:05<00:05, 73.31it/s, est. speed input: 108454.81 toks/s, output: 105.91 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:05<00:05, 74.71it/s, est. speed input: 107984.50 toks/s, output: 105.45 toks/s]
Processed prompts:  62%|██████▏   | 631/1024 [00:05<00:04, 88.51it/s, est. speed input: 108405.29 toks/s, output: 105.86 toks/s]
Processed prompts:  63%|██████▎   | 641/1024 [00:06<00:04, 91.42it/s, est. speed input: 108298.45 toks/s, output: 105.76 toks/s]
Processed prompts:  64%|██████▎   | 651/1024 [00:06<00:05, 73.55it/s, est. speed input: 106461.52 toks/s, output: 103.97 toks/s]
Processed prompts:  64%|██████▍   | 660/1024 [00:06<00:04, 77.38it/s, est. speed input: 106235.09 toks/s, output: 103.74 toks/s]
Processed prompts:  65%|██████▌   | 669/1024 [00:06<00:04, 80.48it/s, est. speed input: 106011.58 toks/s, output: 103.53 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:06<00:04, 74.06it/s, est. speed input: 104831.89 toks/s, output: 102.37 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:06<00:04, 75.40it/s, est. speed input: 104490.92 toks/s, output: 102.04 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:06<00:04, 77.21it/s, est. speed input: 103841.77 toks/s, output: 101.41 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:07<00:03, 77.73it/s, est. speed input: 103522.67 toks/s, output: 101.10 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:07<00:03, 78.23it/s, est. speed input: 103217.55 toks/s, output: 100.80 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:07<00:03, 79.03it/s, est. speed input: 102645.72 toks/s, output: 100.24 toks/s]
Processed prompts:  73%|███████▎  | 752/1024 [00:07<00:02, 92.74it/s, est. speed input: 103190.73 toks/s, output: 100.77 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:07<00:03, 76.08it/s, est. speed input: 101839.71 toks/s, output: 99.45 toks/s] 
Processed prompts:  75%|███████▌  | 771/1024 [00:07<00:03, 79.11it/s, est. speed input: 101714.33 toks/s, output: 99.33 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:07<00:03, 77.63it/s, est. speed input: 101096.73 toks/s, output: 98.73 toks/s]
Processed prompts:  78%|███████▊  | 795/1024 [00:08<00:02, 80.22it/s, est. speed input: 100980.25 toks/s, output: 98.61 toks/s]
Processed prompts:  79%|███████▊  | 804/1024 [00:08<00:02, 82.38it/s, est. speed input: 100862.73 toks/s, output: 98.50 toks/s]
Processed prompts:  79%|███████▉  | 813/1024 [00:08<00:02, 84.27it/s, est. speed input: 100755.84 toks/s, output: 98.39 toks/s]
Processed prompts:  80%|████████  | 822/1024 [00:08<00:02, 85.77it/s, est. speed input: 100652.42 toks/s, output: 98.29 toks/s]
Processed prompts:  81%|████████  | 831/1024 [00:08<00:02, 86.87it/s, est. speed input: 100549.33 toks/s, output: 98.19 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:08<00:02, 73.06it/s, est. speed input: 99541.09 toks/s, output: 97.21 toks/s] 
Processed prompts:  83%|████████▎ | 850/1024 [00:08<00:02, 74.64it/s, est. speed input: 99335.20 toks/s, output: 97.01 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:08<00:02, 75.90it/s, est. speed input: 99132.69 toks/s, output: 96.81 toks/s]
Processed prompts:  85%|████████▍ | 867/1024 [00:08<00:01, 79.65it/s, est. speed input: 99054.29 toks/s, output: 96.73 toks/s]
Processed prompts:  86%|████████▌ | 876/1024 [00:09<00:01, 82.41it/s, est. speed input: 98973.51 toks/s, output: 96.65 toks/s]
Processed prompts:  86%|████████▋ | 885/1024 [00:09<00:01, 84.37it/s, est. speed input: 98890.78 toks/s, output: 96.57 toks/s]
Processed prompts:  87%|████████▋ | 894/1024 [00:09<00:01, 85.93it/s, est. speed input: 98815.63 toks/s, output: 96.50 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:09<00:01, 74.30it/s, est. speed input: 98029.43 toks/s, output: 95.73 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:09<00:01, 75.67it/s, est. speed input: 97859.78 toks/s, output: 95.57 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:09<00:01, 76.77it/s, est. speed input: 97693.66 toks/s, output: 95.40 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:09<00:01, 77.58it/s, est. speed input: 97529.18 toks/s, output: 95.24 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:09<00:00, 80.19it/s, est. speed input: 97303.15 toks/s, output: 95.02 toks/s]
Processed prompts:  93%|█████████▎| 955/1024 [00:10<00:00, 82.38it/s, est. speed input: 97243.60 toks/s, output: 94.96 toks/s]
Processed prompts:  94%|█████████▍| 964/1024 [00:10<00:00, 84.09it/s, est. speed input: 97182.96 toks/s, output: 94.91 toks/s]
Processed prompts:  95%|█████████▌| 973/1024 [00:10<00:00, 85.54it/s, est. speed input: 97128.80 toks/s, output: 94.85 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:10<00:00, 78.24it/s, est. speed input: 96630.41 toks/s, output: 94.37 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:10<00:00, 78.85it/s, est. speed input: 96350.16 toks/s, output: 94.09 toks/s]
Processed prompts:  99%|█████████▉| 1012/1024 [00:10<00:00, 83.42it/s, est. speed input: 96405.97 toks/s, output: 94.15 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:10<00:00, 83.42it/s, est. speed input: 96764.37 toks/s, output: 94.50 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:10<00:00, 94.49it/s, est. speed input: 96764.37 toks/s, output: 94.50 toks/s]
[rank0]:[W126 09:37:39.295752305 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 09:37:41
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:37:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1152433) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1152433) WARNING 01-26 09:38:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 82.28 requests/s, 84338.30 total tokens/s, 82.28 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 09:37:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:37:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:37:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:37:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:37:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:37:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:37:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:37:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:37:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:38:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:38:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:38:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:38:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:38:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:38:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:38:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:38:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:38:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1152433) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1152433) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=1152433) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=1152433) 
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1152433) [2026-01-26 09:38:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1152433) 2026-01-26 09:38:23,267 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1152433) 2026-01-26 09:38:23,301 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1152433) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  5.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 11.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 15.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 13.71it/s]
(EngineCore_DP0 pid=1152433) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.27it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  3.41it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  4.07it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.90it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 34/2048 [00:00<00:06, 334.59it/s]
Adding requests:   4%|▍         | 87/2048 [00:00<00:04, 445.80it/s]
Adding requests:   7%|▋         | 138/2048 [00:00<00:04, 473.40it/s]
Adding requests:   9%|▉         | 188/2048 [00:00<00:03, 482.23it/s]
Adding requests:  12%|█▏        | 241/2048 [00:00<00:03, 497.83it/s]
Adding requests:  14%|█▍        | 292/2048 [00:00<00:03, 500.02it/s]
Adding requests:  17%|█▋        | 343/2048 [00:00<00:03, 500.64it/s]
Adding requests:  19%|█▉        | 396/2048 [00:00<00:03, 508.21it/s]
Adding requests:  22%|██▏       | 447/2048 [00:00<00:03, 508.46it/s]
Adding requests:  24%|██▍       | 498/2048 [00:01<00:03, 507.56it/s]
Adding requests:  27%|██▋       | 549/2048 [00:01<00:02, 500.78it/s]
Adding requests:  29%|██▉       | 601/2048 [00:01<00:02, 504.64it/s]
Adding requests:  32%|███▏      | 654/2048 [00:01<00:02, 511.31it/s]
Adding requests:  35%|███▍      | 708/2048 [00:01<00:02, 518.14it/s]
Adding requests:  37%|███▋      | 760/2048 [00:01<00:02, 507.81it/s]
Adding requests:  40%|███▉      | 811/2048 [00:01<00:02, 503.37it/s]
Adding requests:  42%|████▏     | 862/2048 [00:01<00:02, 503.94it/s]
Adding requests:  45%|████▍     | 915/2048 [00:01<00:02, 510.73it/s]
Adding requests:  47%|████▋     | 968/2048 [00:01<00:02, 514.22it/s]
Adding requests:  50%|████▉     | 1021/2048 [00:02<00:01, 516.09it/s]
Adding requests:  52%|█████▏    | 1073/2048 [00:02<00:01, 512.06it/s]
Adding requests:  55%|█████▍    | 1125/2048 [00:02<00:01, 511.00it/s]
Adding requests:  58%|█████▊    | 1179/2048 [00:02<00:01, 517.76it/s]
Adding requests:  60%|██████    | 1233/2048 [00:02<00:01, 521.94it/s]
Adding requests:  63%|██████▎   | 1286/2048 [00:02<00:01, 516.23it/s]
Adding requests:  65%|██████▌   | 1340/2048 [00:02<00:01, 520.72it/s]
Adding requests:  68%|██████▊   | 1393/2048 [00:02<00:01, 523.15it/s]
Adding requests:  71%|███████   | 1446/2048 [00:02<00:01, 519.93it/s]
Adding requests:  73%|███████▎  | 1500/2048 [00:02<00:01, 525.61it/s]
Adding requests:  76%|███████▌  | 1553/2048 [00:03<00:00, 522.98it/s]
Adding requests:  79%|███████▊  | 1608/2048 [00:03<00:00, 528.53it/s]
Adding requests:  81%|████████  | 1661/2048 [00:03<00:00, 525.78it/s]
Adding requests:  84%|████████▎ | 1714/2048 [00:03<00:00, 525.60it/s]
Adding requests:  86%|████████▋ | 1767/2048 [00:03<00:00, 523.47it/s]
Adding requests:  89%|████████▉ | 1820/2048 [00:03<00:00, 524.34it/s]
Adding requests:  91%|█████████▏| 1873/2048 [00:03<00:00, 521.89it/s]
Adding requests:  94%|█████████▍| 1926/2048 [00:03<00:00, 510.01it/s]
Adding requests:  97%|█████████▋| 1978/2048 [00:03<00:00, 512.67it/s]
Adding requests:  99%|█████████▉| 2032/2048 [00:03<00:00, 518.90it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 511.11it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:00<00:00, 2186.93it/s, est. speed input: 2239794.66 toks/s, output: 2187.05 toks/s]
Processed prompts:  26%|██▌       | 525/2048 [00:02<00:09, 167.72it/s, est. speed input: 204816.15 toks/s, output: 200.01 toks/s]   
Processed prompts:  30%|███       | 621/2048 [00:03<00:10, 134.71it/s, est. speed input: 168206.86 toks/s, output: 164.26 toks/s]
Processed prompts:  33%|███▎      | 677/2048 [00:04<00:11, 117.83it/s, est. speed input: 152266.30 toks/s, output: 148.70 toks/s]
Processed prompts:  35%|███▍      | 714/2048 [00:04<00:11, 114.34it/s, est. speed input: 148083.50 toks/s, output: 144.61 toks/s]
Processed prompts:  36%|███▌      | 741/2048 [00:05<00:12, 106.12it/s, est. speed input: 142611.16 toks/s, output: 139.27 toks/s]
Processed prompts:  37%|███▋      | 762/2048 [00:05<00:12, 106.35it/s, est. speed input: 141484.18 toks/s, output: 138.17 toks/s]
Processed prompts:  38%|███▊      | 780/2048 [00:05<00:12, 104.52it/s, est. speed input: 139948.08 toks/s, output: 136.67 toks/s]
Processed prompts:  39%|███▉      | 795/2048 [00:05<00:12, 99.89it/s, est. speed input: 137967.34 toks/s, output: 134.73 toks/s] 
Processed prompts:  39%|███▉      | 808/2048 [00:06<00:13, 93.52it/s, est. speed input: 135788.51 toks/s, output: 132.61 toks/s]
Processed prompts:  40%|███▉      | 819/2048 [00:06<00:14, 85.59it/s, est. speed input: 133430.04 toks/s, output: 130.30 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:06<00:14, 83.67it/s, est. speed input: 131818.95 toks/s, output: 128.73 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:06<00:14, 83.39it/s, est. speed input: 130445.74 toks/s, output: 127.39 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:06<00:14, 83.44it/s, est. speed input: 129194.56 toks/s, output: 126.17 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:07<00:14, 83.27it/s, est. speed input: 127980.39 toks/s, output: 124.98 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:07<00:13, 83.08it/s, est. speed input: 126821.08 toks/s, output: 123.85 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:07<00:13, 82.96it/s, est. speed input: 125724.20 toks/s, output: 122.78 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:07<00:13, 84.27it/s, est. speed input: 124862.86 toks/s, output: 121.94 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:07<00:13, 83.83it/s, est. speed input: 123872.80 toks/s, output: 120.97 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:08<00:12, 83.55it/s, est. speed input: 122933.59 toks/s, output: 120.05 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:08<00:12, 84.83it/s, est. speed input: 122206.02 toks/s, output: 119.34 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:08<00:12, 84.21it/s, est. speed input: 121342.98 toks/s, output: 118.50 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:08<00:12, 83.89it/s, est. speed input: 120531.35 toks/s, output: 117.71 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:08<00:12, 83.61it/s, est. speed input: 119749.65 toks/s, output: 116.94 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:08<00:12, 83.56it/s, est. speed input: 119015.81 toks/s, output: 116.23 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:09<00:11, 83.28it/s, est. speed input: 118288.88 toks/s, output: 115.52 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:09<00:11, 83.06it/s, est. speed input: 117589.31 toks/s, output: 114.83 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:09<00:11, 83.00it/s, est. speed input: 116927.01 toks/s, output: 114.19 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:09<00:11, 82.93it/s, est. speed input: 116288.32 toks/s, output: 113.56 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:09<00:11, 82.96it/s, est. speed input: 115681.45 toks/s, output: 112.97 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:10<00:10, 83.02it/s, est. speed input: 115101.21 toks/s, output: 112.40 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:10<00:10, 84.43it/s, est. speed input: 114658.48 toks/s, output: 111.97 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:10<00:10, 83.90it/s, est. speed input: 114105.78 toks/s, output: 111.43 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:10<00:10, 83.49it/s, est. speed input: 113569.95 toks/s, output: 110.91 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:10<00:10, 83.20it/s, est. speed input: 113052.20 toks/s, output: 110.40 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:11<00:09, 83.06it/s, est. speed input: 112557.70 toks/s, output: 109.92 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:11<00:09, 82.97it/s, est. speed input: 112080.62 toks/s, output: 109.45 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:11<00:09, 82.91it/s, est. speed input: 111620.07 toks/s, output: 109.00 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:11<00:09, 82.91it/s, est. speed input: 111177.96 toks/s, output: 108.57 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:11<00:09, 82.77it/s, est. speed input: 110739.90 toks/s, output: 108.14 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:12<00:09, 82.81it/s, est. speed input: 110325.74 toks/s, output: 107.74 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:12<00:08, 82.77it/s, est. speed input: 109920.23 toks/s, output: 107.34 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:12<00:08, 82.66it/s, est. speed input: 109521.62 toks/s, output: 106.95 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:12<00:08, 82.83it/s, est. speed input: 109151.80 toks/s, output: 106.59 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:12<00:08, 82.73it/s, est. speed input: 108778.26 toks/s, output: 106.23 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:13<00:08, 82.75it/s, est. speed input: 108421.73 toks/s, output: 105.88 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:13<00:07, 82.78it/s, est. speed input: 108077.38 toks/s, output: 105.54 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:13<00:07, 82.88it/s, est. speed input: 107746.99 toks/s, output: 105.22 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:13<00:07, 82.89it/s, est. speed input: 107422.62 toks/s, output: 104.90 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:13<00:07, 82.83it/s, est. speed input: 107103.70 toks/s, output: 104.59 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:13<00:07, 82.83it/s, est. speed input: 106795.68 toks/s, output: 104.29 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:14<00:06, 82.98it/s, est. speed input: 106505.08 toks/s, output: 104.01 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:14<00:06, 82.81it/s, est. speed input: 106206.15 toks/s, output: 103.72 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:14<00:06, 82.92it/s, est. speed input: 105928.45 toks/s, output: 103.45 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:14<00:06, 82.87it/s, est. speed input: 105650.82 toks/s, output: 103.17 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:14<00:06, 82.93it/s, est. speed input: 105385.09 toks/s, output: 102.91 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:15<00:05, 83.11it/s, est. speed input: 105133.95 toks/s, output: 102.67 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:15<00:05, 82.80it/s, est. speed input: 104866.21 toks/s, output: 102.41 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:15<00:05, 84.52it/s, est. speed input: 104704.52 toks/s, output: 102.25 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:15<00:05, 84.03it/s, est. speed input: 104460.97 toks/s, output: 102.01 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:15<00:05, 83.59it/s, est. speed input: 104218.40 toks/s, output: 101.78 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:16<00:04, 83.40it/s, est. speed input: 103987.61 toks/s, output: 101.55 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:16<00:04, 83.19it/s, est. speed input: 103758.46 toks/s, output: 101.33 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:16<00:04, 83.08it/s, est. speed input: 103535.91 toks/s, output: 101.11 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:16<00:04, 83.03it/s, est. speed input: 103320.85 toks/s, output: 100.90 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:16<00:04, 83.06it/s, est. speed input: 103112.73 toks/s, output: 100.70 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:17<00:04, 82.97it/s, est. speed input: 102904.60 toks/s, output: 100.49 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:17<00:03, 82.88it/s, est. speed input: 102699.64 toks/s, output: 100.29 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:17<00:03, 83.10it/s, est. speed input: 102512.24 toks/s, output: 100.11 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:17<00:03, 82.95it/s, est. speed input: 102315.52 toks/s, output: 99.92 toks/s] 
Processed prompts:  87%|████████▋ | 1778/2048 [00:17<00:03, 82.95it/s, est. speed input: 102127.46 toks/s, output: 99.73 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:18<00:03, 82.92it/s, est. speed input: 101942.21 toks/s, output: 99.55 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:18<00:02, 82.73it/s, est. speed input: 101753.73 toks/s, output: 99.37 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:18<00:02, 82.86it/s, est. speed input: 101580.24 toks/s, output: 99.20 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:18<00:02, 82.99it/s, est. speed input: 101411.95 toks/s, output: 99.03 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:18<00:02, 82.87it/s, est. speed input: 101238.33 toks/s, output: 98.87 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:18<00:02, 84.40it/s, est. speed input: 101133.75 toks/s, output: 98.76 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:19<00:01, 83.83it/s, est. speed input: 100965.59 toks/s, output: 98.60 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:19<00:01, 83.68it/s, est. speed input: 100810.60 toks/s, output: 98.45 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:19<00:01, 83.36it/s, est. speed input: 100650.46 toks/s, output: 98.29 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:19<00:01, 83.10it/s, est. speed input: 100491.46 toks/s, output: 98.14 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:19<00:01, 84.69it/s, est. speed input: 100403.43 toks/s, output: 98.05 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:20<00:00, 84.15it/s, est. speed input: 100254.83 toks/s, output: 97.90 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:20<00:00, 83.78it/s, est. speed input: 100109.02 toks/s, output: 97.76 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:20<00:00, 83.57it/s, est. speed input: 99968.06 toks/s, output: 97.62 toks/s] 
Processed prompts:  99%|█████████▊| 2018/2048 [00:20<00:00, 83.28it/s, est. speed input: 99824.18 toks/s, output: 97.48 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:20<00:00, 84.97it/s, est. speed input: 99751.36 toks/s, output: 97.41 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:20<00:00, 84.97it/s, est. speed input: 100435.06 toks/s, output: 98.08 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:20<00:00, 98.08it/s, est. speed input: 100435.06 toks/s, output: 98.08 toks/s]
[rank0]:[W126 09:38:51.561435648 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 09:38:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:39:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1154006) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1154006) WARNING 01-26 09:39:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 84.11 requests/s, 86216.94 total tokens/s, 84.11 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 09:39:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:39:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:39:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:39:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:39:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:39:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:39:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:39:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:39:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:39:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:39:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:39:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:39:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:39:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:39:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:39:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:39:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1154006) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1154006) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=1154006) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=1154006) 
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1154006) [2026-01-26 09:39:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1154006) [rank0]:W0126 09:39:38.540000 1154006 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1154006) [rank0]:W0126 09:39:38.630000 1154006 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1154006) [rank0]:W0126 09:39:39.542000 1154006 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1154006) [rank0]:W0126 09:39:39.676000 1154006 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1154006) 2026-01-26 09:39:43,315 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1154006) 2026-01-26 09:39:43,344 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1154006) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 12.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 11.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00, 11.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00, 10.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  5.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  5.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.04it/s]
(EngineCore_DP0 pid=1154006) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.92it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 10.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 14.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 13.22it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 32/4096 [00:00<00:12, 317.72it/s]
Adding requests:   2%|▏         | 84/4096 [00:00<00:09, 434.58it/s]
Adding requests:   3%|▎         | 135/4096 [00:00<00:08, 468.59it/s]
Adding requests:   5%|▍         | 185/4096 [00:00<00:08, 478.83it/s]
Adding requests:   6%|▌         | 237/4096 [00:00<00:07, 492.64it/s]
Adding requests:   7%|▋         | 288/4096 [00:00<00:07, 496.96it/s]
Adding requests:   8%|▊         | 338/4096 [00:00<00:07, 497.27it/s]
Adding requests:  10%|▉         | 391/4096 [00:00<00:07, 505.23it/s]
Adding requests:  11%|█         | 442/4096 [00:00<00:07, 504.80it/s]
Adding requests:  12%|█▏        | 494/4096 [00:01<00:07, 507.44it/s]
Adding requests:  13%|█▎        | 545/4096 [00:01<00:07, 499.34it/s]
Adding requests:  15%|█▍        | 598/4096 [00:01<00:06, 506.69it/s]
Adding requests:  16%|█▌        | 650/4096 [00:01<00:06, 509.85it/s]
Adding requests:  17%|█▋        | 704/4096 [00:01<00:06, 517.12it/s]
Adding requests:  18%|█▊        | 756/4096 [00:01<00:06, 515.38it/s]
Adding requests:  20%|█▉        | 808/4096 [00:01<00:06, 508.74it/s]
Adding requests:  21%|██        | 859/4096 [00:01<00:06, 507.26it/s]
Adding requests:  22%|██▏       | 912/4096 [00:01<00:06, 512.96it/s]
Adding requests:  24%|██▎       | 965/4096 [00:01<00:06, 516.71it/s]
Adding requests:  25%|██▍       | 1017/4096 [00:02<00:05, 517.58it/s]
Adding requests:  26%|██▌       | 1069/4096 [00:02<00:05, 516.56it/s]
Adding requests:  27%|██▋       | 1121/4096 [00:02<00:05, 500.90it/s]
Adding requests:  29%|██▊       | 1175/4096 [00:02<00:05, 510.71it/s]
Adding requests:  30%|███       | 1229/4096 [00:02<00:05, 516.67it/s]
Adding requests:  31%|███▏      | 1281/4096 [00:02<00:05, 511.83it/s]
Adding requests:  33%|███▎      | 1335/4096 [00:02<00:05, 518.38it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:02<00:05, 519.46it/s]
Adding requests:  35%|███▌      | 1441/4096 [00:02<00:05, 519.75it/s]
Adding requests:  36%|███▋      | 1495/4096 [00:02<00:04, 523.61it/s]
Adding requests:  38%|███▊      | 1548/4096 [00:03<00:04, 524.36it/s]
Adding requests:  39%|███▉      | 1603/4096 [00:03<00:04, 530.38it/s]
Adding requests:  40%|████      | 1657/4096 [00:03<00:04, 528.11it/s]
Adding requests:  42%|████▏     | 1710/4096 [00:03<00:04, 524.73it/s]
Adding requests:  43%|████▎     | 1763/4096 [00:03<00:04, 525.02it/s]
Adding requests:  44%|████▍     | 1816/4096 [00:03<00:04, 524.94it/s]
Adding requests:  46%|████▌     | 1869/4096 [00:03<00:04, 519.94it/s]
Adding requests:  47%|████▋     | 1923/4096 [00:03<00:04, 523.48it/s]
Adding requests:  48%|████▊     | 1976/4096 [00:03<00:04, 520.64it/s]
Adding requests:  50%|████▉     | 2030/4096 [00:03<00:03, 524.50it/s]
Adding requests:  51%|█████     | 2083/4096 [00:04<00:03, 525.92it/s]
Adding requests:  52%|█████▏    | 2136/4096 [00:04<00:03, 520.40it/s]
Adding requests:  53%|█████▎    | 2189/4096 [00:04<00:03, 514.40it/s]
Adding requests:  55%|█████▍    | 2243/4096 [00:04<00:03, 520.32it/s]
Adding requests:  56%|█████▌    | 2296/4096 [00:04<00:03, 506.26it/s]
Adding requests:  57%|█████▋    | 2348/4096 [00:04<00:03, 508.75it/s]
Adding requests:  59%|█████▊    | 2400/4096 [00:04<00:03, 511.85it/s]
Adding requests:  60%|█████▉    | 2452/4096 [00:04<00:03, 512.73it/s]
Adding requests:  61%|██████    | 2504/4096 [00:04<00:03, 514.12it/s]
Adding requests:  62%|██████▏   | 2558/4096 [00:04<00:02, 520.57it/s]
Adding requests:  64%|██████▎   | 2611/4096 [00:05<00:02, 519.38it/s]
Adding requests:  65%|██████▌   | 2665/4096 [00:05<00:02, 524.17it/s]
Adding requests:  66%|██████▋   | 2718/4096 [00:05<00:02, 518.43it/s]
Adding requests:  68%|██████▊   | 2771/4096 [00:05<00:02, 518.99it/s]
Adding requests:  69%|██████▉   | 2823/4096 [00:05<00:02, 514.02it/s]
Adding requests:  70%|███████   | 2876/4096 [00:05<00:02, 517.42it/s]
Adding requests:  71%|███████▏  | 2928/4096 [00:05<00:02, 515.65it/s]
Adding requests:  73%|███████▎  | 2981/4096 [00:05<00:02, 517.66it/s]
Adding requests:  74%|███████▍  | 3033/4096 [00:05<00:02, 516.07it/s]
Adding requests:  75%|███████▌  | 3085/4096 [00:06<00:01, 514.35it/s]
Adding requests:  77%|███████▋  | 3138/4096 [00:06<00:01, 515.89it/s]
Adding requests:  78%|███████▊  | 3190/4096 [00:06<00:01, 516.74it/s]
Adding requests:  79%|███████▉  | 3243/4096 [00:06<00:01, 520.18it/s]
Adding requests:  80%|████████  | 3296/4096 [00:06<00:01, 521.89it/s]
Adding requests:  82%|████████▏ | 3349/4096 [00:06<00:01, 522.64it/s]
Adding requests:  83%|████████▎ | 3402/4096 [00:06<00:01, 519.95it/s]
Adding requests:  84%|████████▍ | 3455/4096 [00:06<00:01, 519.48it/s]
Adding requests:  86%|████████▌ | 3507/4096 [00:06<00:01, 515.40it/s]
Adding requests:  87%|████████▋ | 3560/4096 [00:06<00:01, 517.30it/s]
Adding requests:  88%|████████▊ | 3612/4096 [00:07<00:00, 516.47it/s]
Adding requests:  89%|████████▉ | 3664/4096 [00:07<00:00, 499.94it/s]
Adding requests:  91%|█████████ | 3717/4096 [00:07<00:00, 507.41it/s]
Adding requests:  92%|█████████▏| 3770/4096 [00:07<00:00, 513.72it/s]
Adding requests:  93%|█████████▎| 3824/4096 [00:07<00:00, 519.86it/s]
Adding requests:  95%|█████████▍| 3878/4096 [00:07<00:00, 525.53it/s]
Adding requests:  96%|█████████▌| 3931/4096 [00:07<00:00, 524.05it/s]
Adding requests:  97%|█████████▋| 3984/4096 [00:07<00:00, 522.10it/s]
Adding requests:  99%|█████████▊| 4037/4096 [00:07<00:00, 519.72it/s]
Adding requests: 100%|█████████▉| 4089/4096 [00:07<00:00, 519.79it/s]
Adding requests: 100%|██████████| 4096/4096 [00:07<00:00, 514.02it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▋        | 668/4096 [00:00<00:02, 1397.08it/s, est. speed input: 1430750.48 toks/s, output: 1397.12 toks/s]
Processed prompts:  20%|█▉        | 808/4096 [00:01<00:10, 327.84it/s, est. speed input: 414362.40 toks/s, output: 404.65 toks/s]   
Processed prompts:  21%|██▏       | 871/4096 [00:02<00:13, 237.01it/s, est. speed input: 323176.91 toks/s, output: 315.60 toks/s]
Processed prompts:  22%|██▏       | 909/4096 [00:03<00:15, 208.75it/s, est. speed input: 296716.02 toks/s, output: 289.76 toks/s]
Processed prompts:  23%|██▎       | 936/4096 [00:03<00:17, 178.02it/s, est. speed input: 273176.83 toks/s, output: 266.77 toks/s]
Processed prompts:  23%|██▎       | 956/4096 [00:03<00:21, 147.90it/s, est. speed input: 252416.44 toks/s, output: 246.50 toks/s]
Processed prompts:  24%|██▍       | 988/4096 [00:04<00:23, 131.20it/s, est. speed input: 237615.48 toks/s, output: 232.04 toks/s]
Processed prompts:  25%|██▍       | 1020/4096 [00:04<00:26, 118.20it/s, est. speed input: 225119.54 toks/s, output: 219.84 toks/s]
Processed prompts:  26%|██▌       | 1052/4096 [00:05<00:27, 108.88it/s, est. speed input: 214716.29 toks/s, output: 209.68 toks/s]
Processed prompts:  26%|██▋       | 1084/4096 [00:05<00:29, 101.71it/s, est. speed input: 205617.21 toks/s, output: 200.80 toks/s]
Processed prompts:  27%|██▋       | 1116/4096 [00:05<00:30, 96.52it/s, est. speed input: 197716.80 toks/s, output: 193.08 toks/s] 
Processed prompts:  28%|██▊       | 1148/4096 [00:06<00:31, 93.92it/s, est. speed input: 191267.90 toks/s, output: 186.78 toks/s]
Processed prompts:  29%|██▉       | 1180/4096 [00:06<00:31, 91.14it/s, est. speed input: 185194.88 toks/s, output: 180.85 toks/s]
Processed prompts:  30%|██▉       | 1212/4096 [00:06<00:32, 89.14it/s, est. speed input: 179773.68 toks/s, output: 175.56 toks/s]
Processed prompts:  30%|███       | 1244/4096 [00:07<00:32, 87.68it/s, est. speed input: 174898.68 toks/s, output: 170.80 toks/s]
Processed prompts:  31%|███       | 1276/4096 [00:07<00:32, 86.61it/s, est. speed input: 170489.78 toks/s, output: 166.49 toks/s]
Processed prompts:  32%|███▏      | 1308/4096 [00:08<00:32, 85.93it/s, est. speed input: 166522.25 toks/s, output: 162.62 toks/s]
Processed prompts:  33%|███▎      | 1340/4096 [00:08<00:32, 85.43it/s, est. speed input: 162902.97 toks/s, output: 159.08 toks/s]
Processed prompts:  33%|███▎      | 1372/4096 [00:08<00:32, 84.97it/s, est. speed input: 159568.73 toks/s, output: 155.83 toks/s]
Processed prompts:  34%|███▍      | 1404/4096 [00:09<00:31, 84.77it/s, est. speed input: 156541.25 toks/s, output: 152.87 toks/s]
Processed prompts:  35%|███▌      | 1436/4096 [00:09<00:31, 84.64it/s, est. speed input: 153756.32 toks/s, output: 150.15 toks/s]
Processed prompts:  36%|███▌      | 1468/4096 [00:09<00:31, 84.38it/s, est. speed input: 151145.80 toks/s, output: 147.60 toks/s]
Processed prompts:  37%|███▋      | 1500/4096 [00:10<00:30, 84.48it/s, est. speed input: 148789.65 toks/s, output: 145.30 toks/s]
Processed prompts:  37%|███▋      | 1532/4096 [00:10<00:30, 84.39it/s, est. speed input: 146566.30 toks/s, output: 143.13 toks/s]
Processed prompts:  38%|███▊      | 1564/4096 [00:11<00:30, 84.30it/s, est. speed input: 144490.86 toks/s, output: 141.10 toks/s]
Processed prompts:  39%|███▉      | 1596/4096 [00:11<00:29, 84.19it/s, est. speed input: 142543.43 toks/s, output: 139.20 toks/s]
Processed prompts:  40%|███▉      | 1628/4096 [00:11<00:29, 84.27it/s, est. speed input: 140750.28 toks/s, output: 137.45 toks/s]
Processed prompts:  41%|████      | 1660/4096 [00:12<00:28, 84.24it/s, est. speed input: 139053.08 toks/s, output: 135.79 toks/s]
Processed prompts:  41%|████▏     | 1692/4096 [00:12<00:28, 84.21it/s, est. speed input: 137457.06 toks/s, output: 134.23 toks/s]
Processed prompts:  42%|████▏     | 1724/4096 [00:12<00:28, 84.25it/s, est. speed input: 135964.07 toks/s, output: 132.78 toks/s]
Processed prompts:  43%|████▎     | 1756/4096 [00:13<00:27, 84.17it/s, est. speed input: 134540.61 toks/s, output: 131.39 toks/s]
Processed prompts:  44%|████▎     | 1788/4096 [00:13<00:27, 84.22it/s, est. speed input: 133210.52 toks/s, output: 130.09 toks/s]
Processed prompts:  44%|████▍     | 1820/4096 [00:14<00:27, 84.18it/s, est. speed input: 131941.59 toks/s, output: 128.85 toks/s]
Processed prompts:  45%|████▌     | 1852/4096 [00:14<00:26, 84.83it/s, est. speed input: 130830.06 toks/s, output: 127.76 toks/s]
Processed prompts:  46%|████▌     | 1884/4096 [00:14<00:26, 84.53it/s, est. speed input: 129675.60 toks/s, output: 126.64 toks/s]
Processed prompts:  47%|████▋     | 1916/4096 [00:15<00:25, 84.37it/s, est. speed input: 128585.54 toks/s, output: 125.57 toks/s]
Processed prompts:  48%|████▊     | 1948/4096 [00:15<00:25, 85.04it/s, est. speed input: 127643.57 toks/s, output: 124.65 toks/s]
Processed prompts:  48%|████▊     | 1980/4096 [00:16<00:24, 84.94it/s, est. speed input: 126678.04 toks/s, output: 123.71 toks/s]
Processed prompts:  49%|████▉     | 2012/4096 [00:16<00:24, 84.74it/s, est. speed input: 125742.70 toks/s, output: 122.80 toks/s]
Processed prompts:  50%|████▉     | 2044/4096 [00:16<00:24, 84.59it/s, est. speed input: 124848.27 toks/s, output: 121.92 toks/s]
Processed prompts:  51%|█████     | 2076/4096 [00:17<00:23, 84.52it/s, est. speed input: 123997.03 toks/s, output: 121.09 toks/s]
Processed prompts:  51%|█████▏    | 2108/4096 [00:17<00:23, 84.39it/s, est. speed input: 123173.73 toks/s, output: 120.29 toks/s]
Processed prompts:  52%|█████▏    | 2140/4096 [00:17<00:23, 84.31it/s, est. speed input: 122387.05 toks/s, output: 119.52 toks/s]
Processed prompts:  53%|█████▎    | 2172/4096 [00:18<00:22, 84.25it/s, est. speed input: 121632.52 toks/s, output: 118.78 toks/s]
Processed prompts:  54%|█████▍    | 2204/4096 [00:18<00:22, 84.30it/s, est. speed input: 120918.26 toks/s, output: 118.08 toks/s]
Processed prompts:  55%|█████▍    | 2236/4096 [00:19<00:21, 85.85it/s, est. speed input: 120373.06 toks/s, output: 117.55 toks/s]
Processed prompts:  55%|█████▌    | 2268/4096 [00:19<00:21, 85.31it/s, est. speed input: 119700.09 toks/s, output: 116.89 toks/s]
Processed prompts:  56%|█████▌    | 2300/4096 [00:19<00:20, 85.68it/s, est. speed input: 119119.65 toks/s, output: 116.33 toks/s]
Processed prompts:  57%|█████▋    | 2332/4096 [00:20<00:20, 85.82it/s, est. speed input: 118549.40 toks/s, output: 115.77 toks/s]
Processed prompts:  58%|█████▊    | 2364/4096 [00:20<00:20, 85.26it/s, est. speed input: 117944.85 toks/s, output: 115.18 toks/s]
Processed prompts:  58%|█████▊    | 2396/4096 [00:20<00:20, 84.86it/s, est. speed input: 117361.42 toks/s, output: 114.61 toks/s]
Processed prompts:  59%|█████▉    | 2428/4096 [00:21<00:19, 84.70it/s, est. speed input: 116808.70 toks/s, output: 114.07 toks/s]
Processed prompts:  60%|██████    | 2460/4096 [00:21<00:19, 84.58it/s, est. speed input: 116274.92 toks/s, output: 113.55 toks/s]
Processed prompts:  61%|██████    | 2492/4096 [00:22<00:18, 85.09it/s, est. speed input: 115805.63 toks/s, output: 113.09 toks/s]
Processed prompts:  62%|██████▏   | 2524/4096 [00:22<00:18, 84.67it/s, est. speed input: 115292.37 toks/s, output: 112.59 toks/s]
Processed prompts:  62%|██████▏   | 2556/4096 [00:22<00:18, 84.55it/s, est. speed input: 114808.98 toks/s, output: 112.12 toks/s]
Processed prompts:  63%|██████▎   | 2588/4096 [00:23<00:17, 85.05it/s, est. speed input: 114384.70 toks/s, output: 111.70 toks/s]
Processed prompts:  64%|██████▍   | 2620/4096 [00:23<00:17, 84.60it/s, est. speed input: 113916.28 toks/s, output: 111.25 toks/s]
Processed prompts:  65%|██████▍   | 2652/4096 [00:23<00:17, 84.47it/s, est. speed input: 113475.61 toks/s, output: 110.82 toks/s]
Processed prompts:  66%|██████▌   | 2684/4096 [00:24<00:16, 84.33it/s, est. speed input: 113045.62 toks/s, output: 110.40 toks/s]
Processed prompts:  66%|██████▋   | 2716/4096 [00:24<00:16, 84.31it/s, est. speed input: 112634.34 toks/s, output: 109.99 toks/s]
Processed prompts:  67%|██████▋   | 2748/4096 [00:25<00:15, 84.32it/s, est. speed input: 112236.71 toks/s, output: 109.61 toks/s]
Processed prompts:  68%|██████▊   | 2780/4096 [00:25<00:15, 84.20it/s, est. speed input: 111842.77 toks/s, output: 109.22 toks/s]
Processed prompts:  69%|██████▊   | 2812/4096 [00:25<00:15, 84.21it/s, est. speed input: 111466.07 toks/s, output: 108.85 toks/s]
Processed prompts:  69%|██████▉   | 2844/4096 [00:26<00:14, 84.22it/s, est. speed input: 111101.39 toks/s, output: 108.50 toks/s]
Processed prompts:  70%|███████   | 2876/4096 [00:26<00:14, 84.22it/s, est. speed input: 110745.91 toks/s, output: 108.15 toks/s]
Processed prompts:  71%|███████   | 2908/4096 [00:26<00:14, 84.24it/s, est. speed input: 110401.90 toks/s, output: 107.81 toks/s]
Processed prompts:  72%|███████▏  | 2940/4096 [00:27<00:13, 84.19it/s, est. speed input: 110063.42 toks/s, output: 107.48 toks/s]
Processed prompts:  73%|███████▎  | 2972/4096 [00:27<00:13, 84.19it/s, est. speed input: 109736.38 toks/s, output: 107.16 toks/s]
Processed prompts:  73%|███████▎  | 3004/4096 [00:28<00:12, 84.19it/s, est. speed input: 109418.22 toks/s, output: 106.85 toks/s]
Processed prompts:  74%|███████▍  | 3036/4096 [00:28<00:12, 84.25it/s, est. speed input: 109112.34 toks/s, output: 106.55 toks/s]
Processed prompts:  75%|███████▍  | 3068/4096 [00:28<00:12, 84.18it/s, est. speed input: 108808.11 toks/s, output: 106.26 toks/s]
Processed prompts:  76%|███████▌  | 3100/4096 [00:29<00:11, 84.23it/s, est. speed input: 108516.78 toks/s, output: 105.97 toks/s]
Processed prompts:  76%|███████▋  | 3132/4096 [00:29<00:11, 84.76it/s, est. speed input: 108260.55 toks/s, output: 105.72 toks/s]
Processed prompts:  77%|███████▋  | 3164/4096 [00:30<00:11, 84.53it/s, est. speed input: 107977.95 toks/s, output: 105.45 toks/s]
Processed prompts:  78%|███████▊  | 3196/4096 [00:30<00:10, 84.45it/s, est. speed input: 107707.10 toks/s, output: 105.18 toks/s]
Processed prompts:  79%|███████▉  | 3228/4096 [00:30<00:10, 84.33it/s, est. speed input: 107439.24 toks/s, output: 104.92 toks/s]
Processed prompts:  80%|███████▉  | 3260/4096 [00:31<00:09, 84.35it/s, est. speed input: 107183.09 toks/s, output: 104.67 toks/s]
Processed prompts:  80%|████████  | 3292/4096 [00:31<00:09, 84.28it/s, est. speed input: 106929.12 toks/s, output: 104.42 toks/s]
Processed prompts:  81%|████████  | 3324/4096 [00:31<00:09, 84.23it/s, est. speed input: 106681.12 toks/s, output: 104.18 toks/s]
Processed prompts:  82%|████████▏ | 3356/4096 [00:32<00:08, 84.25it/s, est. speed input: 106441.96 toks/s, output: 103.95 toks/s]
Processed prompts:  83%|████████▎ | 3388/4096 [00:32<00:08, 84.18it/s, est. speed input: 106203.75 toks/s, output: 103.71 toks/s]
Processed prompts:  83%|████████▎ | 3420/4096 [00:33<00:08, 84.19it/s, est. speed input: 105974.14 toks/s, output: 103.49 toks/s]
Processed prompts:  84%|████████▍ | 3452/4096 [00:33<00:07, 84.22it/s, est. speed input: 105750.99 toks/s, output: 103.27 toks/s]
Processed prompts:  85%|████████▌ | 3484/4096 [00:33<00:07, 84.21it/s, est. speed input: 105531.34 toks/s, output: 103.06 toks/s]
Processed prompts:  86%|████████▌ | 3516/4096 [00:34<00:06, 84.21it/s, est. speed input: 105316.62 toks/s, output: 102.85 toks/s]
Processed prompts:  87%|████████▋ | 3548/4096 [00:34<00:06, 84.15it/s, est. speed input: 105104.18 toks/s, output: 102.64 toks/s]
Processed prompts:  87%|████████▋ | 3580/4096 [00:34<00:06, 84.03it/s, est. speed input: 104892.58 toks/s, output: 102.43 toks/s]
Processed prompts:  88%|████████▊ | 3612/4096 [00:35<00:05, 83.88it/s, est. speed input: 104682.77 toks/s, output: 102.23 toks/s]
Processed prompts:  89%|████████▉ | 3644/4096 [00:35<00:05, 83.92it/s, est. speed input: 104483.62 toks/s, output: 102.03 toks/s]
Processed prompts:  90%|████████▉ | 3676/4096 [00:36<00:04, 84.02it/s, est. speed input: 104292.38 toks/s, output: 101.85 toks/s]
Processed prompts:  91%|█████████ | 3708/4096 [00:36<00:04, 83.78it/s, est. speed input: 104091.31 toks/s, output: 101.65 toks/s]
Processed prompts:  91%|█████████▏| 3740/4096 [00:36<00:04, 84.50it/s, est. speed input: 103932.22 toks/s, output: 101.50 toks/s]
Processed prompts:  92%|█████████▏| 3772/4096 [00:37<00:03, 84.17it/s, est. speed input: 103741.40 toks/s, output: 101.31 toks/s]
Processed prompts:  93%|█████████▎| 3804/4096 [00:37<00:03, 83.84it/s, est. speed input: 103550.11 toks/s, output: 101.12 toks/s]
Processed prompts:  94%|█████████▎| 3836/4096 [00:37<00:03, 83.86it/s, est. speed input: 103373.35 toks/s, output: 100.95 toks/s]
Processed prompts:  94%|█████████▍| 3868/4096 [00:38<00:02, 83.93it/s, est. speed input: 103202.20 toks/s, output: 100.78 toks/s]
Processed prompts:  95%|█████████▌| 3900/4096 [00:38<00:02, 83.90it/s, est. speed input: 103031.00 toks/s, output: 100.62 toks/s]
Processed prompts:  96%|█████████▌| 3932/4096 [00:39<00:01, 83.75it/s, est. speed input: 102858.52 toks/s, output: 100.45 toks/s]
Processed prompts:  97%|█████████▋| 3964/4096 [00:39<00:01, 83.76it/s, est. speed input: 102693.32 toks/s, output: 100.29 toks/s]
Processed prompts:  98%|█████████▊| 3996/4096 [00:39<00:01, 83.92it/s, est. speed input: 102537.62 toks/s, output: 100.13 toks/s]
Processed prompts:  98%|█████████▊| 4028/4096 [00:40<00:00, 84.42it/s, est. speed input: 102399.65 toks/s, output: 100.00 toks/s]
Processed prompts:  99%|█████████▉| 4060/4096 [00:40<00:00, 84.51it/s, est. speed input: 102254.38 toks/s, output: 99.86 toks/s] 
Processed prompts: 100%|██████████| 4096/4096 [00:40<00:00, 84.51it/s, est. speed input: 102993.36 toks/s, output: 100.58 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:40<00:00, 100.58it/s, est. speed input: 102993.36 toks/s, output: 100.58 toks/s]
[rank0]:[W126 09:40:36.027235565 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 09:40:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:41:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1156104) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1156104) WARNING 01-26 09:41:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 84.64 requests/s, 86752.06 total tokens/s, 84.64 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 09:41:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:41:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:41:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:41:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:41:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:41:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:41:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:41:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:41:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:41:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:41:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:41:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:41:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:41:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:41:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:41:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:41:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1156104) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1156104) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1156104) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=1156104) 
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13107200 bytes
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41943040 bytes
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1156104) [2026-01-26 09:41:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21012480 bytes
(EngineCore_DP0 pid=1156104) [rank0]:W0126 09:41:40.265000 1156104 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1156104) [rank0]:W0126 09:41:40.348000 1156104 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1156104) [rank0]:W0126 09:41:41.394000 1156104 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1156104) [rank0]:W0126 09:41:41.517000 1156104 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1156104) 2026-01-26 09:41:45,300 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1156104) 2026-01-26 09:41:45,326 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1156104) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:08,  2.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:07,  2.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:07,  2.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:03,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:01<00:01,  6.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  7.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00,  9.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:00,  8.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00,  9.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00,  8.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.77it/s]
(EngineCore_DP0 pid=1156104) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  5.20it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00,  9.01it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 13.65it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:00<00:00, 16.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 14.67it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 50/8192 [00:00<00:16, 496.21it/s]
Adding requests:   1%|          | 102/8192 [00:00<00:16, 504.85it/s]
Adding requests:   2%|▏         | 153/8192 [00:00<00:16, 501.15it/s]
Adding requests:   2%|▏         | 204/8192 [00:00<00:15, 501.55it/s]
Adding requests:   3%|▎         | 257/8192 [00:00<00:15, 509.46it/s]
Adding requests:   4%|▍         | 308/8192 [00:00<00:15, 506.32it/s]
Adding requests:   4%|▍         | 360/8192 [00:00<00:15, 507.31it/s]
Adding requests:   5%|▌         | 412/8192 [00:00<00:15, 509.43it/s]
Adding requests:   6%|▌         | 464/8192 [00:00<00:15, 511.09it/s]
Adding requests:   6%|▋         | 516/8192 [00:01<00:15, 507.16it/s]
Adding requests:   7%|▋         | 567/8192 [00:01<00:15, 504.61it/s]
Adding requests:   8%|▊         | 618/8192 [00:01<00:15, 502.06it/s]
Adding requests:   8%|▊         | 671/8192 [00:01<00:14, 508.22it/s]
Adding requests:   9%|▉         | 724/8192 [00:01<00:14, 512.67it/s]
Adding requests:   9%|▉         | 776/8192 [00:01<00:14, 508.32it/s]
Adding requests:  10%|█         | 827/8192 [00:01<00:14, 500.62it/s]
Adding requests:  11%|█         | 879/8192 [00:01<00:14, 505.54it/s]
Adding requests:  11%|█▏        | 932/8192 [00:01<00:14, 512.26it/s]
Adding requests:  12%|█▏        | 984/8192 [00:01<00:14, 513.56it/s]
Adding requests:  13%|█▎        | 1037/8192 [00:02<00:13, 516.26it/s]
Adding requests:  13%|█▎        | 1089/8192 [00:02<00:13, 512.85it/s]
Adding requests:  14%|█▍        | 1141/8192 [00:02<00:13, 508.58it/s]
Adding requests:  15%|█▍        | 1196/8192 [00:02<00:13, 519.98it/s]
Adding requests:  15%|█▌        | 1249/8192 [00:02<00:13, 521.61it/s]
Adding requests:  16%|█▌        | 1302/8192 [00:02<00:13, 517.60it/s]
Adding requests:  17%|█▋        | 1355/8192 [00:02<00:13, 521.03it/s]
Adding requests:  17%|█▋        | 1409/8192 [00:02<00:12, 524.81it/s]
Adding requests:  18%|█▊        | 1462/8192 [00:02<00:12, 525.01it/s]
Adding requests:  18%|█▊        | 1515/8192 [00:02<00:12, 524.05it/s]
Adding requests:  19%|█▉        | 1568/8192 [00:03<00:12, 524.25it/s]
Adding requests:  20%|█▉        | 1622/8192 [00:03<00:12, 527.76it/s]
Adding requests:  20%|██        | 1675/8192 [00:03<00:12, 524.64it/s]
Adding requests:  21%|██        | 1729/8192 [00:03<00:12, 527.55it/s]
Adding requests:  22%|██▏       | 1782/8192 [00:03<00:12, 510.39it/s]
Adding requests:  22%|██▏       | 1836/8192 [00:03<00:12, 516.63it/s]
Adding requests:  23%|██▎       | 1889/8192 [00:03<00:12, 518.73it/s]
Adding requests:  24%|██▎       | 1941/8192 [00:03<00:12, 518.82it/s]
Adding requests:  24%|██▍       | 1993/8192 [00:03<00:11, 517.87it/s]
Adding requests:  25%|██▍       | 2047/8192 [00:03<00:11, 522.13it/s]
Adding requests:  26%|██▌       | 2100/8192 [00:04<00:11, 524.34it/s]
Adding requests:  26%|██▋       | 2153/8192 [00:04<00:11, 517.57it/s]
Adding requests:  27%|██▋       | 2205/8192 [00:04<00:11, 513.05it/s]
Adding requests:  28%|██▊       | 2260/8192 [00:04<00:11, 519.11it/s]
Adding requests:  28%|██▊       | 2313/8192 [00:04<00:11, 521.95it/s]
Adding requests:  29%|██▉       | 2366/8192 [00:04<00:11, 517.52it/s]
Adding requests:  30%|██▉       | 2418/8192 [00:04<00:11, 518.00it/s]
Adding requests:  30%|███       | 2470/8192 [00:04<00:11, 518.33it/s]
Adding requests:  31%|███       | 2522/8192 [00:04<00:10, 516.65it/s]
Adding requests:  31%|███▏      | 2576/8192 [00:04<00:10, 522.48it/s]
Adding requests:  32%|███▏      | 2629/8192 [00:05<00:10, 520.41it/s]
Adding requests:  33%|███▎      | 2682/8192 [00:05<00:10, 521.59it/s]
Adding requests:  33%|███▎      | 2735/8192 [00:05<00:10, 516.29it/s]
Adding requests:  34%|███▍      | 2788/8192 [00:05<00:10, 517.20it/s]
Adding requests:  35%|███▍      | 2840/8192 [00:05<00:10, 515.97it/s]
Adding requests:  35%|███▌      | 2893/8192 [00:05<00:10, 519.05it/s]
Adding requests:  36%|███▌      | 2945/8192 [00:05<00:10, 515.12it/s]
Adding requests:  37%|███▋      | 2998/8192 [00:05<00:10, 517.65it/s]
Adding requests:  37%|███▋      | 3051/8192 [00:05<00:09, 518.64it/s]
Adding requests:  38%|███▊      | 3103/8192 [00:06<00:10, 505.10it/s]
Adding requests:  39%|███▊      | 3155/8192 [00:06<00:09, 509.15it/s]
Adding requests:  39%|███▉      | 3207/8192 [00:06<00:09, 511.86it/s]
Adding requests:  40%|███▉      | 3260/8192 [00:06<00:09, 516.79it/s]
Adding requests:  40%|████      | 3313/8192 [00:06<00:09, 518.97it/s]
Adding requests:  41%|████      | 3367/8192 [00:06<00:09, 523.51it/s]
Adding requests:  42%|████▏     | 3420/8192 [00:06<00:09, 523.90it/s]
Adding requests:  42%|████▏     | 3473/8192 [00:06<00:09, 513.42it/s]
Adding requests:  43%|████▎     | 3526/8192 [00:06<00:09, 515.50it/s]
Adding requests:  44%|████▎     | 3578/8192 [00:06<00:08, 516.44it/s]
Adding requests:  44%|████▍     | 3630/8192 [00:07<00:08, 513.00it/s]
Adding requests:  45%|████▍     | 3683/8192 [00:07<00:08, 515.98it/s]
Adding requests:  46%|████▌     | 3735/8192 [00:07<00:08, 514.07it/s]
Adding requests:  46%|████▋     | 3790/8192 [00:07<00:08, 523.43it/s]
Adding requests:  47%|████▋     | 3843/8192 [00:07<00:08, 524.88it/s]
Adding requests:  48%|████▊     | 3896/8192 [00:07<00:08, 525.10it/s]
Adding requests:  48%|████▊     | 3949/8192 [00:07<00:08, 525.27it/s]
Adding requests:  49%|████▉     | 4002/8192 [00:07<00:08, 522.54it/s]
Adding requests:  49%|████▉     | 4055/8192 [00:07<00:07, 520.18it/s]
Adding requests:  50%|█████     | 4108/8192 [00:07<00:07, 520.92it/s]
Adding requests:  51%|█████     | 4161/8192 [00:08<00:07, 522.53it/s]
Adding requests:  51%|█████▏    | 4215/8192 [00:08<00:07, 525.23it/s]
Adding requests:  52%|█████▏    | 4268/8192 [00:08<00:07, 524.12it/s]
Adding requests:  53%|█████▎    | 4321/8192 [00:08<00:07, 525.86it/s]
Adding requests:  53%|█████▎    | 4376/8192 [00:08<00:07, 530.92it/s]
Adding requests:  54%|█████▍    | 4430/8192 [00:08<00:07, 516.25it/s]
Adding requests:  55%|█████▍    | 4483/8192 [00:08<00:07, 516.64it/s]
Adding requests:  55%|█████▌    | 4535/8192 [00:08<00:07, 515.78it/s]
Adding requests:  56%|█████▌    | 4588/8192 [00:08<00:06, 519.56it/s]
Adding requests:  57%|█████▋    | 4642/8192 [00:08<00:06, 525.06it/s]
Adding requests:  57%|█████▋    | 4695/8192 [00:09<00:06, 520.82it/s]
Adding requests:  58%|█████▊    | 4749/8192 [00:09<00:06, 522.74it/s]
Adding requests:  59%|█████▊    | 4802/8192 [00:09<00:06, 523.20it/s]
Adding requests:  59%|█████▉    | 4855/8192 [00:09<00:06, 523.02it/s]
Adding requests:  60%|█████▉    | 4908/8192 [00:09<00:06, 520.40it/s]
Adding requests:  61%|██████    | 4961/8192 [00:09<00:06, 521.91it/s]
Adding requests:  61%|██████    | 5015/8192 [00:09<00:06, 525.16it/s]
Adding requests:  62%|██████▏   | 5069/8192 [00:09<00:05, 527.49it/s]
Adding requests:  63%|██████▎   | 5123/8192 [00:09<00:05, 530.82it/s]
Adding requests:  63%|██████▎   | 5177/8192 [00:09<00:05, 529.19it/s]
Adding requests:  64%|██████▍   | 5230/8192 [00:10<00:05, 524.23it/s]
Adding requests:  64%|██████▍   | 5283/8192 [00:10<00:05, 521.68it/s]
Adding requests:  65%|██████▌   | 5337/8192 [00:10<00:05, 525.82it/s]
Adding requests:  66%|██████▌   | 5390/8192 [00:10<00:05, 526.74it/s]
Adding requests:  66%|██████▋   | 5443/8192 [00:10<00:05, 522.88it/s]
Adding requests:  67%|██████▋   | 5496/8192 [00:10<00:05, 519.89it/s]
Adding requests:  68%|██████▊   | 5548/8192 [00:10<00:05, 518.10it/s]
Adding requests:  68%|██████▊   | 5601/8192 [00:10<00:04, 519.09it/s]
Adding requests:  69%|██████▉   | 5653/8192 [00:10<00:04, 515.61it/s]
Adding requests:  70%|██████▉   | 5706/8192 [00:11<00:04, 519.24it/s]
Adding requests:  70%|███████   | 5758/8192 [00:11<00:04, 511.03it/s]
Adding requests:  71%|███████   | 5810/8192 [00:11<00:04, 511.00it/s]
Adding requests:  72%|███████▏  | 5863/8192 [00:11<00:04, 514.83it/s]
Adding requests:  72%|███████▏  | 5917/8192 [00:11<00:04, 520.46it/s]
Adding requests:  73%|███████▎  | 5970/8192 [00:11<00:04, 520.80it/s]
Adding requests:  74%|███████▎  | 6024/8192 [00:11<00:04, 524.97it/s]
Adding requests:  74%|███████▍  | 6077/8192 [00:11<00:04, 525.26it/s]
Adding requests:  75%|███████▍  | 6130/8192 [00:11<00:03, 526.03it/s]
Adding requests:  75%|███████▌  | 6183/8192 [00:11<00:03, 526.37it/s]
Adding requests:  76%|███████▌  | 6238/8192 [00:12<00:03, 531.56it/s]
Adding requests:  77%|███████▋  | 6293/8192 [00:12<00:03, 535.08it/s]
Adding requests:  77%|███████▋  | 6347/8192 [00:12<00:03, 534.26it/s]
Adding requests:  78%|███████▊  | 6401/8192 [00:12<00:03, 534.85it/s]
Adding requests:  79%|███████▉  | 6456/8192 [00:12<00:03, 538.45it/s]
Adding requests:  79%|███████▉  | 6511/8192 [00:12<00:03, 541.28it/s]
Adding requests:  80%|████████  | 6566/8192 [00:12<00:03, 537.05it/s]
Adding requests:  81%|████████  | 6620/8192 [00:12<00:02, 533.47it/s]
Adding requests:  81%|████████▏ | 6674/8192 [00:12<00:02, 531.05it/s]
Adding requests:  82%|████████▏ | 6728/8192 [00:12<00:02, 531.85it/s]
Adding requests:  83%|████████▎ | 6782/8192 [00:13<00:02, 531.53it/s]
Adding requests:  83%|████████▎ | 6836/8192 [00:13<00:02, 533.16it/s]
Adding requests:  84%|████████▍ | 6891/8192 [00:13<00:02, 534.91it/s]
Adding requests:  85%|████████▍ | 6947/8192 [00:13<00:02, 540.01it/s]
Adding requests:  85%|████████▌ | 7002/8192 [00:13<00:02, 533.46it/s]
Adding requests:  86%|████████▌ | 7056/8192 [00:13<00:02, 529.49it/s]
Adding requests:  87%|████████▋ | 7109/8192 [00:13<00:02, 519.74it/s]
Adding requests:  87%|████████▋ | 7162/8192 [00:13<00:01, 519.02it/s]
Adding requests:  88%|████████▊ | 7215/8192 [00:13<00:01, 521.33it/s]
Adding requests:  89%|████████▊ | 7269/8192 [00:13<00:01, 525.13it/s]
Adding requests:  89%|████████▉ | 7323/8192 [00:14<00:01, 527.81it/s]
Adding requests:  90%|█████████ | 7376/8192 [00:14<00:01, 525.10it/s]
Adding requests:  91%|█████████ | 7432/8192 [00:14<00:01, 533.53it/s]
Adding requests:  91%|█████████▏| 7486/8192 [00:14<00:01, 534.79it/s]
Adding requests:  92%|█████████▏| 7540/8192 [00:14<00:01, 533.28it/s]
Adding requests:  93%|█████████▎| 7594/8192 [00:14<00:01, 530.38it/s]
Adding requests:  93%|█████████▎| 7648/8192 [00:14<00:01, 531.31it/s]
Adding requests:  94%|█████████▍| 7702/8192 [00:14<00:00, 533.38it/s]
Adding requests:  95%|█████████▍| 7756/8192 [00:14<00:00, 529.16it/s]
Adding requests:  95%|█████████▌| 7809/8192 [00:14<00:00, 522.94it/s]
Adding requests:  96%|█████████▌| 7864/8192 [00:15<00:00, 528.61it/s]
Adding requests:  97%|█████████▋| 7917/8192 [00:15<00:00, 520.72it/s]
Adding requests:  97%|█████████▋| 7970/8192 [00:15<00:00, 521.28it/s]
Adding requests:  98%|█████████▊| 8023/8192 [00:15<00:00, 518.94it/s]
Adding requests:  99%|█████████▊| 8076/8192 [00:15<00:00, 521.86it/s]
Adding requests:  99%|█████████▉| 8129/8192 [00:15<00:00, 522.99it/s]
Adding requests: 100%|█████████▉| 8183/8192 [00:15<00:00, 527.18it/s]
Adding requests: 100%|██████████| 8192/8192 [00:15<00:00, 521.10it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 1305/8192 [00:00<00:02, 3266.93it/s, est. speed input: 3345539.17 toks/s, output: 3266.99 toks/s]
Processed prompts:  20%|█▉        | 1632/8192 [00:04<00:21, 306.60it/s, est. speed input: 401166.92 toks/s, output: 391.76 toks/s]   
Processed prompts:  22%|██▏       | 1772/8192 [00:05<00:27, 232.36it/s, est. speed input: 319838.12 toks/s, output: 312.34 toks/s]
Processed prompts:  23%|██▎       | 1853/8192 [00:06<00:30, 207.48it/s, est. speed input: 295194.95 toks/s, output: 288.28 toks/s]
Processed prompts:  23%|██▎       | 1906/8192 [00:07<00:35, 177.66it/s, est. speed input: 272141.05 toks/s, output: 265.76 toks/s]
Processed prompts:  24%|██▎       | 1945/8192 [00:07<00:42, 147.80it/s, est. speed input: 251594.78 toks/s, output: 245.70 toks/s]
Processed prompts:  25%|██▍       | 2009/8192 [00:08<00:46, 131.73it/s, est. speed input: 237313.74 toks/s, output: 231.75 toks/s]
Processed prompts:  25%|██▌       | 2073/8192 [00:09<00:51, 119.24it/s, est. speed input: 225318.40 toks/s, output: 220.04 toks/s]
Processed prompts:  26%|██▌       | 2137/8192 [00:10<00:55, 109.74it/s, est. speed input: 215073.33 toks/s, output: 210.03 toks/s]
Processed prompts:  27%|██▋       | 2201/8192 [00:10<00:57, 103.51it/s, est. speed input: 206630.71 toks/s, output: 201.79 toks/s]
Processed prompts:  28%|██▊       | 2265/8192 [00:11<01:00, 98.40it/s, est. speed input: 199025.36 toks/s, output: 194.36 toks/s] 
Processed prompts:  28%|██▊       | 2329/8192 [00:12<01:01, 94.77it/s, est. speed input: 192355.50 toks/s, output: 187.85 toks/s]
Processed prompts:  29%|██▉       | 2393/8192 [00:13<01:03, 91.84it/s, est. speed input: 186310.85 toks/s, output: 181.94 toks/s]
Processed prompts:  30%|██▉       | 2457/8192 [00:13<01:03, 90.08it/s, est. speed input: 181035.21 toks/s, output: 176.79 toks/s]
Processed prompts:  31%|███       | 2521/8192 [00:14<01:04, 88.45it/s, est. speed input: 176165.06 toks/s, output: 172.04 toks/s]
Processed prompts:  32%|███▏      | 2585/8192 [00:15<01:03, 87.67it/s, est. speed input: 171889.31 toks/s, output: 167.86 toks/s]
Processed prompts:  32%|███▏      | 2649/8192 [00:16<01:03, 86.83it/s, est. speed input: 167922.31 toks/s, output: 163.99 toks/s]
Processed prompts:  33%|███▎      | 2713/8192 [00:16<01:03, 86.23it/s, est. speed input: 164304.60 toks/s, output: 160.45 toks/s]
Processed prompts:  34%|███▍      | 2777/8192 [00:17<01:03, 85.86it/s, est. speed input: 161011.06 toks/s, output: 157.24 toks/s]
Processed prompts:  35%|███▍      | 2841/8192 [00:18<01:02, 85.56it/s, est. speed input: 157974.88 toks/s, output: 154.27 toks/s]
Processed prompts:  35%|███▌      | 2905/8192 [00:19<01:01, 85.34it/s, est. speed input: 155176.66 toks/s, output: 151.54 toks/s]
Processed prompts:  36%|███▌      | 2969/8192 [00:19<01:01, 85.11it/s, est. speed input: 152571.55 toks/s, output: 149.00 toks/s]
Processed prompts:  37%|███▋      | 3033/8192 [00:20<01:00, 85.01it/s, est. speed input: 150172.66 toks/s, output: 146.65 toks/s]
Processed prompts:  38%|███▊      | 3097/8192 [00:21<00:59, 85.24it/s, est. speed input: 148002.33 toks/s, output: 144.53 toks/s]
Processed prompts:  39%|███▊      | 3161/8192 [00:22<00:59, 85.12it/s, est. speed input: 145924.00 toks/s, output: 142.50 toks/s]
Processed prompts:  39%|███▉      | 3225/8192 [00:22<00:58, 85.06it/s, est. speed input: 143985.30 toks/s, output: 140.61 toks/s]
Processed prompts:  40%|████      | 3289/8192 [00:23<00:57, 84.83it/s, est. speed input: 142138.79 toks/s, output: 138.81 toks/s]
Processed prompts:  41%|████      | 3353/8192 [00:24<00:57, 84.85it/s, est. speed input: 140436.12 toks/s, output: 137.14 toks/s]
Processed prompts:  42%|████▏     | 3417/8192 [00:25<00:56, 84.72it/s, est. speed input: 138812.47 toks/s, output: 135.56 toks/s]
Processed prompts:  42%|████▏     | 3481/8192 [00:25<00:55, 84.77it/s, est. speed input: 137305.72 toks/s, output: 134.09 toks/s]
Processed prompts:  43%|████▎     | 3545/8192 [00:26<00:54, 84.78it/s, est. speed input: 135879.71 toks/s, output: 132.69 toks/s]
Processed prompts:  44%|████▍     | 3609/8192 [00:27<00:54, 84.65it/s, est. speed input: 134512.19 toks/s, output: 131.36 toks/s]
Processed prompts:  45%|████▍     | 3673/8192 [00:28<00:53, 84.66it/s, est. speed input: 133233.24 toks/s, output: 130.11 toks/s]
Processed prompts:  46%|████▌     | 3737/8192 [00:28<00:52, 84.91it/s, est. speed input: 132052.97 toks/s, output: 128.96 toks/s]
Processed prompts:  46%|████▋     | 3801/8192 [00:29<00:51, 84.83it/s, est. speed input: 130899.45 toks/s, output: 127.83 toks/s]
Processed prompts:  47%|████▋     | 3865/8192 [00:30<00:51, 84.63it/s, est. speed input: 129784.10 toks/s, output: 126.74 toks/s]
Processed prompts:  48%|████▊     | 3929/8192 [00:31<00:50, 84.65it/s, est. speed input: 128742.93 toks/s, output: 125.73 toks/s]
Processed prompts:  49%|████▊     | 3993/8192 [00:31<00:49, 84.88it/s, est. speed input: 127776.93 toks/s, output: 124.78 toks/s]
Processed prompts:  50%|████▉     | 4057/8192 [00:32<00:48, 84.83it/s, est. speed input: 126830.94 toks/s, output: 123.86 toks/s]
Processed prompts:  50%|█████     | 4121/8192 [00:33<00:48, 84.62it/s, est. speed input: 125907.13 toks/s, output: 122.96 toks/s]
Processed prompts:  51%|█████     | 4185/8192 [00:34<00:47, 84.88it/s, est. speed input: 125068.99 toks/s, output: 122.14 toks/s]
Processed prompts:  52%|█████▏    | 4249/8192 [00:35<00:46, 85.01it/s, est. speed input: 124261.02 toks/s, output: 121.35 toks/s]
Processed prompts:  53%|█████▎    | 4313/8192 [00:35<00:45, 85.13it/s, est. speed input: 123490.14 toks/s, output: 120.60 toks/s]
Processed prompts:  53%|█████▎    | 4377/8192 [00:36<00:44, 84.89it/s, est. speed input: 122718.51 toks/s, output: 119.84 toks/s]
Processed prompts:  54%|█████▍    | 4441/8192 [00:37<00:44, 84.69it/s, est. speed input: 121975.45 toks/s, output: 119.12 toks/s]
Processed prompts:  55%|█████▍    | 4505/8192 [00:38<00:43, 84.75it/s, est. speed input: 121280.55 toks/s, output: 118.44 toks/s]
Processed prompts:  56%|█████▌    | 4569/8192 [00:38<00:42, 84.63it/s, est. speed input: 120597.73 toks/s, output: 117.77 toks/s]
Processed prompts:  57%|█████▋    | 4633/8192 [00:39<00:42, 84.57it/s, est. speed input: 119943.65 toks/s, output: 117.13 toks/s]
Processed prompts:  57%|█████▋    | 4697/8192 [00:40<00:41, 84.35it/s, est. speed input: 119298.29 toks/s, output: 116.50 toks/s]
Processed prompts:  58%|█████▊    | 4761/8192 [00:41<00:40, 84.61it/s, est. speed input: 118712.73 toks/s, output: 115.93 toks/s]
Processed prompts:  59%|█████▉    | 4825/8192 [00:41<00:39, 84.82it/s, est. speed input: 118150.34 toks/s, output: 115.38 toks/s]
Processed prompts:  60%|█████▉    | 4889/8192 [00:42<00:38, 84.79it/s, est. speed input: 117593.29 toks/s, output: 114.84 toks/s]
Processed prompts:  60%|██████    | 4953/8192 [00:43<00:38, 84.82it/s, est. speed input: 117059.85 toks/s, output: 114.32 toks/s]
Processed prompts:  61%|██████    | 5017/8192 [00:44<00:37, 84.73it/s, est. speed input: 116535.71 toks/s, output: 113.80 toks/s]
Processed prompts:  62%|██████▏   | 5081/8192 [00:44<00:36, 84.63it/s, est. speed input: 116026.43 toks/s, output: 113.31 toks/s]
Processed prompts:  63%|██████▎   | 5145/8192 [00:45<00:36, 84.52it/s, est. speed input: 115530.74 toks/s, output: 112.82 toks/s]
Processed prompts:  64%|██████▎   | 5209/8192 [00:46<00:35, 84.42it/s, est. speed input: 115050.05 toks/s, output: 112.35 toks/s]
Processed prompts:  64%|██████▍   | 5273/8192 [00:47<00:34, 84.34it/s, est. speed input: 114584.30 toks/s, output: 111.90 toks/s]
Processed prompts:  65%|██████▌   | 5337/8192 [00:47<00:33, 84.35it/s, est. speed input: 114137.83 toks/s, output: 111.46 toks/s]
Processed prompts:  66%|██████▌   | 5401/8192 [00:48<00:33, 84.28it/s, est. speed input: 113699.51 toks/s, output: 111.03 toks/s]
Processed prompts:  67%|██████▋   | 5465/8192 [00:49<00:32, 84.25it/s, est. speed input: 113276.59 toks/s, output: 110.62 toks/s]
Processed prompts:  67%|██████▋   | 5529/8192 [00:50<00:31, 84.51it/s, est. speed input: 112885.32 toks/s, output: 110.24 toks/s]
Processed prompts:  68%|██████▊   | 5593/8192 [00:50<00:30, 84.35it/s, est. speed input: 112482.89 toks/s, output: 109.85 toks/s]
Processed prompts:  69%|██████▉   | 5657/8192 [00:51<00:30, 84.34it/s, est. speed input: 112098.87 toks/s, output: 109.47 toks/s]
Processed prompts:  70%|██████▉   | 5721/8192 [00:52<00:29, 84.23it/s, est. speed input: 111719.14 toks/s, output: 109.10 toks/s]
Processed prompts:  71%|███████   | 5785/8192 [00:53<00:28, 84.22it/s, est. speed input: 111354.76 toks/s, output: 108.74 toks/s]
Processed prompts:  71%|███████▏  | 5849/8192 [00:53<00:27, 84.26it/s, est. speed input: 111003.64 toks/s, output: 108.40 toks/s]
Processed prompts:  72%|███████▏  | 5913/8192 [00:54<00:27, 84.24it/s, est. speed input: 110659.20 toks/s, output: 108.07 toks/s]
Processed prompts:  73%|███████▎  | 5977/8192 [00:55<00:26, 84.17it/s, est. speed input: 110321.16 toks/s, output: 107.74 toks/s]
Processed prompts:  74%|███████▎  | 6041/8192 [00:56<00:25, 84.20it/s, est. speed input: 109996.26 toks/s, output: 107.42 toks/s]
Processed prompts:  75%|███████▍  | 6105/8192 [00:56<00:24, 84.23it/s, est. speed input: 109680.95 toks/s, output: 107.11 toks/s]
Processed prompts:  75%|███████▌  | 6169/8192 [00:57<00:24, 84.22it/s, est. speed input: 109372.39 toks/s, output: 106.81 toks/s]
Processed prompts:  76%|███████▌  | 6233/8192 [00:58<00:23, 84.16it/s, est. speed input: 109068.30 toks/s, output: 106.51 toks/s]
Processed prompts:  77%|███████▋  | 6297/8192 [00:59<00:22, 84.12it/s, est. speed input: 108772.50 toks/s, output: 106.22 toks/s]
Processed prompts:  78%|███████▊  | 6361/8192 [01:00<00:21, 84.11it/s, est. speed input: 108485.17 toks/s, output: 105.94 toks/s]
Processed prompts:  78%|███████▊  | 6425/8192 [01:00<00:21, 84.11it/s, est. speed input: 108205.41 toks/s, output: 105.67 toks/s]
Processed prompts:  79%|███████▉  | 6489/8192 [01:01<00:20, 84.08it/s, est. speed input: 107930.98 toks/s, output: 105.40 toks/s]
Processed prompts:  80%|███████▉  | 6553/8192 [01:02<00:19, 84.27it/s, est. speed input: 107674.44 toks/s, output: 105.15 toks/s]
Processed prompts:  81%|████████  | 6617/8192 [01:03<00:18, 84.27it/s, est. speed input: 107416.61 toks/s, output: 104.90 toks/s]
Processed prompts:  82%|████████▏ | 6681/8192 [01:03<00:17, 84.40it/s, est. speed input: 107172.10 toks/s, output: 104.66 toks/s]
Processed prompts:  82%|████████▏ | 6745/8192 [01:04<00:17, 84.30it/s, est. speed input: 106923.43 toks/s, output: 104.42 toks/s]
Processed prompts:  83%|████████▎ | 6809/8192 [01:05<00:16, 84.19it/s, est. speed input: 106678.57 toks/s, output: 104.18 toks/s]
Processed prompts:  84%|████████▍ | 6873/8192 [01:06<00:15, 84.04it/s, est. speed input: 106436.07 toks/s, output: 103.94 toks/s]
Processed prompts:  85%|████████▍ | 6937/8192 [01:06<00:14, 84.05it/s, est. speed input: 106204.33 toks/s, output: 103.72 toks/s]
Processed prompts:  85%|████████▌ | 7001/8192 [01:07<00:14, 83.94it/s, est. speed input: 105972.66 toks/s, output: 103.49 toks/s]
Processed prompts:  86%|████████▌ | 7065/8192 [01:08<00:13, 83.97it/s, est. speed input: 105750.97 toks/s, output: 103.27 toks/s]
Processed prompts:  87%|████████▋ | 7129/8192 [01:09<00:12, 84.14it/s, est. speed input: 105541.21 toks/s, output: 103.07 toks/s]
Processed prompts:  88%|████████▊ | 7193/8192 [01:09<00:11, 84.07it/s, est. speed input: 105327.07 toks/s, output: 102.86 toks/s]
Processed prompts:  89%|████████▊ | 7257/8192 [01:10<00:11, 84.20it/s, est. speed input: 105125.76 toks/s, output: 102.66 toks/s]
Processed prompts:  89%|████████▉ | 7321/8192 [01:11<00:10, 84.10it/s, est. speed input: 104920.32 toks/s, output: 102.46 toks/s]
Processed prompts:  90%|█████████ | 7385/8192 [01:12<00:09, 84.22it/s, est. speed input: 104727.53 toks/s, output: 102.27 toks/s]
Processed prompts:  91%|█████████ | 7449/8192 [01:12<00:08, 84.14it/s, est. speed input: 104531.23 toks/s, output: 102.08 toks/s]
Processed prompts:  92%|█████████▏| 7513/8192 [01:13<00:08, 83.96it/s, est. speed input: 104334.12 toks/s, output: 101.89 toks/s]
Processed prompts:  92%|█████████▏| 7577/8192 [01:14<00:07, 83.97it/s, est. speed input: 104146.54 toks/s, output: 101.71 toks/s]
Processed prompts:  93%|█████████▎| 7641/8192 [01:15<00:06, 83.89it/s, est. speed input: 103959.26 toks/s, output: 101.52 toks/s]
Processed prompts:  94%|█████████▍| 7705/8192 [01:16<00:05, 83.93it/s, est. speed input: 103779.86 toks/s, output: 101.35 toks/s]
Processed prompts:  95%|█████████▍| 7769/8192 [01:16<00:05, 83.86it/s, est. speed input: 103599.72 toks/s, output: 101.17 toks/s]
Processed prompts:  96%|█████████▌| 7833/8192 [01:17<00:04, 83.84it/s, est. speed input: 103424.67 toks/s, output: 101.00 toks/s]
Processed prompts:  96%|█████████▋| 7897/8192 [01:18<00:03, 83.80it/s, est. speed input: 103251.59 toks/s, output: 100.83 toks/s]
Processed prompts:  97%|█████████▋| 7961/8192 [01:19<00:02, 83.74it/s, est. speed input: 103080.92 toks/s, output: 100.66 toks/s]
Processed prompts:  98%|█████████▊| 8025/8192 [01:19<00:01, 83.81it/s, est. speed input: 102917.74 toks/s, output: 100.51 toks/s]
Processed prompts:  99%|█████████▊| 8089/8192 [01:20<00:01, 84.14it/s, est. speed input: 102768.52 toks/s, output: 100.36 toks/s]
Processed prompts: 100%|█████████▉| 8153/8192 [01:21<00:00, 95.27it/s, est. speed input: 102988.14 toks/s, output: 100.57 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:21<00:00, 95.27it/s, est. speed input: 103479.33 toks/s, output: 101.05 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:21<00:00, 101.05it/s, est. speed input: 103479.33 toks/s, output: 101.05 toks/s]
[rank0]:[W126 09:43:28.197892489 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:13:09
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:13:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1268068) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1268068) WARNING 01-26 11:13:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 36.23 requests/s, 18584.97 total tokens/s, 36.23 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:13:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:13:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:13:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:13:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:13:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:13:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:13:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:13:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:13:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:13:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:13:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:13:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1268068) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1268068) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.12it/s]
(EngineCore_DP0 pid=1268068) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.53it/s]
(EngineCore_DP0 pid=1268068) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.59it/s]
(EngineCore_DP0 pid=1268068) 
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1268068) [2026-01-26 11:13:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1268068) 2026-01-26 11:13:43,767 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1268068) 2026-01-26 11:13:43,796 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1268068) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
(EngineCore_DP0 pid=1268068) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.92it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  28%|██▊       | 36/128 [00:00<00:00, 356.43it/s]
Adding requests:  83%|████████▎ | 106/128 [00:00<00:00, 552.05it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 545.89it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:23,  5.33it/s, est. speed input: 2731.80 toks/s, output: 5.34 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 22.32it/s, est. speed input: 9858.15 toks/s, output: 19.25 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 29.85it/s, est. speed input: 12977.60 toks/s, output: 25.35 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 33.88it/s, est. speed input: 14721.28 toks/s, output: 28.75 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 36.28it/s, est. speed input: 15839.01 toks/s, output: 30.93 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 37.79it/s, est. speed input: 16614.12 toks/s, output: 32.45 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 38.77it/s, est. speed input: 17183.88 toks/s, output: 33.56 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 39.48it/s, est. speed input: 17630.40 toks/s, output: 34.43 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 39.96it/s, est. speed input: 17983.09 toks/s, output: 35.12 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 40.24it/s, est. speed input: 18261.63 toks/s, output: 35.67 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 40.37it/s, est. speed input: 18485.67 toks/s, output: 36.10 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 40.56it/s, est. speed input: 18684.46 toks/s, output: 36.49 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 40.72it/s, est. speed input: 18857.47 toks/s, output: 36.83 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 40.79it/s, est. speed input: 19001.69 toks/s, output: 37.11 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 40.84it/s, est. speed input: 19127.93 toks/s, output: 37.36 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 40.83it/s, est. speed input: 19235.36 toks/s, output: 37.57 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 40.89it/s, est. speed input: 19335.66 toks/s, output: 37.76 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 40.92it/s, est. speed input: 19424.84 toks/s, output: 37.94 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 40.89it/s, est. speed input: 19500.49 toks/s, output: 38.09 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 40.89it/s, est. speed input: 19570.65 toks/s, output: 38.22 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 40.89it/s, est. speed input: 19633.92 toks/s, output: 38.35 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 40.87it/s, est. speed input: 19690.46 toks/s, output: 38.46 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:02<00:00, 40.83it/s, est. speed input: 19739.76 toks/s, output: 38.55 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 40.77it/s, est. speed input: 19783.74 toks/s, output: 38.64 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 40.76it/s, est. speed input: 19825.55 toks/s, output: 38.72 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 40.72it/s, est. speed input: 19862.59 toks/s, output: 38.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 40.72it/s, est. speed input: 19878.54 toks/s, output: 38.82 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 38.82it/s, est. speed input: 19878.54 toks/s, output: 38.82 toks/s]
[rank0]:[W126 11:13:50.044504348 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:13:51
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:13:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1269216) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1269216) WARNING 01-26 11:14:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.07 requests/s, 33896.27 total tokens/s, 33.07 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 11:13:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:13:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:13:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:13:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:13:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:13:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:13:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:13:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:14:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:14:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:14:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:14:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:14:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:14:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1269216) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1269216) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.08it/s]
(EngineCore_DP0 pid=1269216) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.50it/s]
(EngineCore_DP0 pid=1269216) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]
(EngineCore_DP0 pid=1269216) 
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1269216) [2026-01-26 11:14:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1269216) 2026-01-26 11:14:27,157 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1269216) 2026-01-26 11:14:27,180 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1269216) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
(EngineCore_DP0 pid=1269216) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  15%|█▍        | 19/128 [00:00<00:00, 183.34it/s]
Adding requests:  45%|████▌     | 58/128 [00:00<00:00, 303.07it/s]
Adding requests:  75%|███████▌  | 96/128 [00:00<00:00, 334.42it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 327.40it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 24.01it/s, est. speed input: 24596.64 toks/s, output: 24.01 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:03, 31.83it/s, est. speed input: 31289.64 toks/s, output: 30.55 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 34.39it/s, est. speed input: 33583.48 toks/s, output: 32.79 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 35.60it/s, est. speed input: 34748.23 toks/s, output: 33.93 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:03, 36.29it/s, est. speed input: 35463.84 toks/s, output: 34.63 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:02, 36.69it/s, est. speed input: 35939.57 toks/s, output: 35.10 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 36.96it/s, est. speed input: 36285.48 toks/s, output: 35.43 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 37.06it/s, est. speed input: 36517.73 toks/s, output: 35.66 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:00<00:02, 37.10it/s, est. speed input: 36690.92 toks/s, output: 35.83 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 36.97it/s, est. speed input: 36777.01 toks/s, output: 35.91 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 37.06it/s, est. speed input: 36901.77 toks/s, output: 36.04 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 37.13it/s, est. speed input: 37006.64 toks/s, output: 36.14 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:02, 37.16it/s, est. speed input: 37091.75 toks/s, output: 36.22 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:01, 37.22it/s, est. speed input: 37173.99 toks/s, output: 36.30 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:01, 37.32it/s, est. speed input: 37258.88 toks/s, output: 36.38 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 37.38it/s, est. speed input: 37329.55 toks/s, output: 36.45 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 37.32it/s, est. speed input: 37374.37 toks/s, output: 36.50 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 37.33it/s, est. speed input: 37422.23 toks/s, output: 36.54 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 37.27it/s, est. speed input: 37453.13 toks/s, output: 36.57 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 37.19it/s, est. speed input: 37475.37 toks/s, output: 36.60 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 37.16it/s, est. speed input: 37498.89 toks/s, output: 36.62 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 37.19it/s, est. speed input: 37528.98 toks/s, output: 36.65 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 37.28it/s, est. speed input: 37565.73 toks/s, output: 36.68 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:00, 37.27it/s, est. speed input: 37590.31 toks/s, output: 36.71 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 37.27it/s, est. speed input: 37612.80 toks/s, output: 36.73 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:02<00:00, 37.25it/s, est. speed input: 37632.20 toks/s, output: 36.75 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:02<00:00, 37.23it/s, est. speed input: 37648.32 toks/s, output: 36.77 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:03<00:00, 37.20it/s, est. speed input: 37660.99 toks/s, output: 36.78 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 37.10it/s, est. speed input: 37664.67 toks/s, output: 36.78 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 37.10it/s, est. speed input: 37675.27 toks/s, output: 36.79 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 37.13it/s, est. speed input: 37689.28 toks/s, output: 36.81 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 36.97it/s, est. speed input: 37682.50 toks/s, output: 36.80 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.97it/s, est. speed input: 37686.82 toks/s, output: 36.80 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.80it/s, est. speed input: 37686.82 toks/s, output: 36.80 toks/s]
[rank0]:[W126 11:14:33.753652406 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 11:14:35
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:14:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1270321) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1270321) WARNING 01-26 11:15:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 38.95 requests/s, 39924.94 total tokens/s, 38.95 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 11:14:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:14:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:14:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:14:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:14:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:14:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:14:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:14:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:14:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:14:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:14:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:14:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:14:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:14:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1270321) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1270321) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.13it/s]
(EngineCore_DP0 pid=1270321) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.52it/s]
(EngineCore_DP0 pid=1270321) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.59it/s]
(EngineCore_DP0 pid=1270321) 
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1270321) [2026-01-26 11:14:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1270321) 2026-01-26 11:15:11,811 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1270321) 2026-01-26 11:15:11,856 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1270321) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 14.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.64it/s]
(EngineCore_DP0 pid=1270321) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.90it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.88it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 20/256 [00:00<00:01, 197.10it/s]
Adding requests:  23%|██▎       | 58/256 [00:00<00:00, 303.63it/s]
Adding requests:  37%|███▋      | 94/256 [00:00<00:00, 326.39it/s]
Adding requests:  52%|█████▏    | 132/256 [00:00<00:00, 345.61it/s]
Adding requests:  67%|██████▋   | 171/256 [00:00<00:00, 360.61it/s]
Adding requests:  82%|████████▏ | 211/256 [00:00<00:00, 372.80it/s]
Adding requests:  98%|█████████▊| 250/256 [00:00<00:00, 377.35it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 353.34it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 182.62it/s, est. speed input: 187033.41 toks/s, output: 182.63 toks/s]
Processed prompts:  16%|█▌        | 41/256 [00:00<00:03, 65.56it/s, est. speed input: 74859.28 toks/s, output: 73.10 toks/s]   
Processed prompts:  20%|██        | 52/256 [00:00<00:03, 53.26it/s, est. speed input: 62487.42 toks/s, output: 61.02 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:01<00:03, 49.36it/s, est. speed input: 58474.24 toks/s, output: 57.10 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:01<00:04, 47.18it/s, est. speed input: 56356.76 toks/s, output: 55.03 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:01<00:04, 45.66it/s, est. speed input: 54821.51 toks/s, output: 53.54 toks/s]
Processed prompts:  30%|███       | 78/256 [00:01<00:04, 44.19it/s, est. speed input: 53465.53 toks/s, output: 52.21 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:01<00:03, 43.10it/s, est. speed input: 52355.09 toks/s, output: 51.13 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:01<00:03, 42.40it/s, est. speed input: 51467.61 toks/s, output: 50.26 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:01<00:03, 43.97it/s, est. speed input: 51435.66 toks/s, output: 50.23 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:02<00:03, 40.98it/s, est. speed input: 50267.24 toks/s, output: 49.09 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:03, 40.68it/s, est. speed input: 49630.81 toks/s, output: 48.47 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:02<00:03, 40.65it/s, est. speed input: 49118.95 toks/s, output: 47.97 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:03, 40.60it/s, est. speed input: 48661.83 toks/s, output: 47.52 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:02<00:03, 40.55it/s, est. speed input: 48253.78 toks/s, output: 47.12 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:02<00:03, 40.50it/s, est. speed input: 47884.46 toks/s, output: 46.76 toks/s]
Processed prompts:  53%|█████▎    | 135/256 [00:02<00:02, 42.63it/s, est. speed input: 47996.46 toks/s, output: 46.87 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:03<00:02, 39.57it/s, est. speed input: 47305.29 toks/s, output: 46.20 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:03<00:02, 39.98it/s, est. speed input: 47054.42 toks/s, output: 45.95 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:03<00:02, 40.35it/s, est. speed input: 46839.10 toks/s, output: 45.74 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:03<00:02, 40.63it/s, est. speed input: 46647.49 toks/s, output: 45.55 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:03<00:02, 40.69it/s, est. speed input: 46451.69 toks/s, output: 45.36 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:03<00:02, 42.80it/s, est. speed input: 46575.24 toks/s, output: 45.48 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:03<00:02, 39.94it/s, est. speed input: 46127.51 toks/s, output: 45.05 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:04<00:01, 40.03it/s, est. speed input: 45943.95 toks/s, output: 44.87 toks/s]
Processed prompts:  72%|███████▏  | 185/256 [00:04<00:01, 42.31it/s, est. speed input: 46064.44 toks/s, output: 44.98 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:04<00:01, 39.45it/s, est. speed input: 45661.80 toks/s, output: 44.59 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:04<00:01, 40.01it/s, est. speed input: 45548.17 toks/s, output: 44.48 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:04<00:01, 41.39it/s, est. speed input: 45554.06 toks/s, output: 44.49 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:04<00:01, 41.43it/s, est. speed input: 45460.52 toks/s, output: 44.39 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:04<00:01, 41.37it/s, est. speed input: 45362.78 toks/s, output: 44.30 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:04<00:00, 41.39it/s, est. speed input: 45277.53 toks/s, output: 44.22 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:05<00:00, 41.10it/s, est. speed input: 45166.12 toks/s, output: 44.11 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:05<00:00, 40.87it/s, est. speed input: 45057.02 toks/s, output: 44.00 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:05<00:00, 40.69it/s, est. speed input: 44952.72 toks/s, output: 43.90 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:05<00:00, 40.56it/s, est. speed input: 44853.00 toks/s, output: 43.80 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:05<00:00, 40.59it/s, est. speed input: 44770.10 toks/s, output: 43.72 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 42.33it/s, est. speed input: 44843.48 toks/s, output: 43.79 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 42.33it/s, est. speed input: 44843.48 toks/s, output: 43.79 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 43.79it/s, est. speed input: 44843.48 toks/s, output: 43.79 toks/s]
[rank0]:[W126 11:15:20.527664910 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 11:15:22
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:15:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1271491) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1271491) WARNING 01-26 11:15:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.93 requests/s, 41951.45 total tokens/s, 40.93 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 11:15:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:15:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:15:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:15:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:15:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:15:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:15:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:15:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:15:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:15:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:15:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:15:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:15:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:15:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:15:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:15:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:15:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1271491) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1271491) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.08it/s]
(EngineCore_DP0 pid=1271491) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.52it/s]
(EngineCore_DP0 pid=1271491) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]
(EngineCore_DP0 pid=1271491) 
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1271491) [2026-01-26 11:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1271491) 2026-01-26 11:16:01,350 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1271491) 2026-01-26 11:16:01,383 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1271491) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.42it/s]
(EngineCore_DP0 pid=1271491) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  8.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 13.63it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▎         | 19/512 [00:00<00:02, 188.08it/s]
Adding requests:  12%|█▏        | 59/512 [00:00<00:01, 310.28it/s]
Adding requests:  19%|█▉        | 96/512 [00:00<00:01, 333.52it/s]
Adding requests:  26%|██▌       | 134/512 [00:00<00:01, 350.34it/s]
Adding requests:  34%|███▍      | 174/512 [00:00<00:00, 366.42it/s]
Adding requests:  42%|████▏     | 214/512 [00:00<00:00, 377.15it/s]
Adding requests:  49%|████▉     | 253/512 [00:00<00:00, 378.63it/s]
Adding requests:  57%|█████▋    | 292/512 [00:00<00:00, 381.58it/s]
Adding requests:  65%|██████▍   | 332/512 [00:00<00:00, 386.71it/s]
Adding requests:  73%|███████▎  | 373/512 [00:01<00:00, 392.91it/s]
Adding requests:  81%|████████  | 414/512 [00:01<00:00, 397.63it/s]
Adding requests:  89%|████████▊ | 454/512 [00:01<00:00, 395.19it/s]
Adding requests:  97%|█████████▋| 497/512 [00:01<00:00, 402.60it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 377.79it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 54/512 [00:00<00:00, 526.46it/s, est. speed input: 539215.00 toks/s, output: 526.49 toks/s]
Processed prompts:  21%|██        | 107/512 [00:01<00:05, 67.98it/s, est. speed input: 80188.43 toks/s, output: 78.31 toks/s]  
Processed prompts:  26%|██▌       | 132/512 [00:01<00:06, 58.22it/s, est. speed input: 69227.02 toks/s, output: 67.60 toks/s]
Processed prompts:  29%|██▉       | 148/512 [00:02<00:06, 53.64it/s, est. speed input: 64718.06 toks/s, output: 63.20 toks/s]
Processed prompts:  31%|███       | 159/512 [00:02<00:07, 50.15it/s, est. speed input: 61860.42 toks/s, output: 60.41 toks/s]
Processed prompts:  33%|███▎      | 168/512 [00:02<00:06, 49.38it/s, est. speed input: 60820.26 toks/s, output: 59.39 toks/s]
Processed prompts:  34%|███▍      | 175/512 [00:03<00:07, 46.58it/s, est. speed input: 59229.36 toks/s, output: 57.84 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:03<00:07, 44.24it/s, est. speed input: 57879.59 toks/s, output: 56.52 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:03<00:07, 43.57it/s, est. speed input: 57005.65 toks/s, output: 55.67 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:03<00:07, 42.91it/s, est. speed input: 56194.19 toks/s, output: 54.88 toks/s]
Processed prompts:  40%|████      | 206/512 [00:03<00:07, 43.29it/s, est. speed input: 55684.03 toks/s, output: 54.38 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:03<00:06, 42.58it/s, est. speed input: 54997.44 toks/s, output: 53.71 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:04<00:06, 42.12it/s, est. speed input: 54389.20 toks/s, output: 53.11 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:04<00:06, 41.89it/s, est. speed input: 53853.61 toks/s, output: 52.59 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:04<00:06, 41.66it/s, est. speed input: 53352.16 toks/s, output: 52.10 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:04<00:06, 41.42it/s, est. speed input: 52878.23 toks/s, output: 51.64 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:04<00:06, 41.15it/s, est. speed input: 52425.14 toks/s, output: 51.20 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:05<00:06, 41.15it/s, est. speed input: 52037.06 toks/s, output: 50.82 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:05<00:05, 41.18it/s, est. speed input: 51681.99 toks/s, output: 50.47 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:05<00:05, 41.15it/s, est. speed input: 51343.87 toks/s, output: 50.14 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:05<00:05, 41.03it/s, est. speed input: 51015.82 toks/s, output: 49.82 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:05<00:05, 41.00it/s, est. speed input: 50716.00 toks/s, output: 49.53 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:06<00:05, 40.94it/s, est. speed input: 50430.03 toks/s, output: 49.25 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:06<00:04, 42.26it/s, est. speed input: 50329.28 toks/s, output: 49.15 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:06<00:04, 41.89it/s, est. speed input: 50081.20 toks/s, output: 48.91 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:06<00:04, 41.54it/s, est. speed input: 49836.36 toks/s, output: 48.67 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:06<00:04, 41.39it/s, est. speed input: 49614.97 toks/s, output: 48.45 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:07<00:04, 41.16it/s, est. speed input: 49392.27 toks/s, output: 48.23 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:07<00:03, 41.12it/s, est. speed input: 49195.19 toks/s, output: 48.04 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:07<00:03, 41.10it/s, est. speed input: 49008.96 toks/s, output: 47.86 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:07<00:03, 41.10it/s, est. speed input: 48833.53 toks/s, output: 47.69 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:07<00:03, 41.05it/s, est. speed input: 48661.03 toks/s, output: 47.52 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:08<00:03, 40.90it/s, est. speed input: 48486.65 toks/s, output: 47.35 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:08<00:02, 40.96it/s, est. speed input: 48335.78 toks/s, output: 47.20 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:08<00:02, 41.04it/s, est. speed input: 48195.40 toks/s, output: 47.07 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:08<00:02, 41.02it/s, est. speed input: 48054.83 toks/s, output: 46.93 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:08<00:02, 40.96it/s, est. speed input: 47915.97 toks/s, output: 46.79 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:09<00:02, 40.85it/s, est. speed input: 47778.21 toks/s, output: 46.66 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:09<00:02, 40.85it/s, est. speed input: 47651.63 toks/s, output: 46.53 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:09<00:01, 42.20it/s, est. speed input: 47636.50 toks/s, output: 46.52 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:09<00:01, 41.90it/s, est. speed input: 47526.64 toks/s, output: 46.41 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:09<00:01, 41.54it/s, est. speed input: 47410.13 toks/s, output: 46.30 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:10<00:01, 41.26it/s, est. speed input: 47295.86 toks/s, output: 46.19 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:10<00:01, 41.11it/s, est. speed input: 47189.02 toks/s, output: 46.08 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:10<00:00, 41.15it/s, est. speed input: 47096.38 toks/s, output: 45.99 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:10<00:00, 41.15it/s, est. speed input: 47004.95 toks/s, output: 45.90 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:10<00:00, 41.02it/s, est. speed input: 46908.36 toks/s, output: 45.81 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:10<00:00, 40.89it/s, est. speed input: 46812.43 toks/s, output: 45.72 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:11<00:00, 42.47it/s, est. speed input: 46827.88 toks/s, output: 45.73 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:11<00:00, 42.47it/s, est. speed input: 47010.34 toks/s, output: 45.91 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:11<00:00, 45.91it/s, est. speed input: 47010.34 toks/s, output: 45.91 toks/s]
[rank0]:[W126 11:16:16.790752628 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 11:16:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:16:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1272805) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1272805) WARNING 01-26 11:16:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 42.48 requests/s, 43544.39 total tokens/s, 42.48 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 11:16:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:16:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:16:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:16:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:16:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:16:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:16:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:16:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:16:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:16:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:16:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:16:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:16:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:16:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:16:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:16:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:16:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1272805) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1272805) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=1272805) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.52it/s]
(EngineCore_DP0 pid=1272805) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]
(EngineCore_DP0 pid=1272805) 
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1272805) [2026-01-26 11:16:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1272805) 2026-01-26 11:16:59,525 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1272805) 2026-01-26 11:16:59,549 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1272805) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  3.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.27it/s]
(EngineCore_DP0 pid=1272805) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  9.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 17.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.30it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 20/1024 [00:00<00:05, 197.18it/s]
Adding requests:   6%|▌         | 61/1024 [00:00<00:03, 317.33it/s]
Adding requests:  10%|▉         | 98/1024 [00:00<00:02, 337.59it/s]
Adding requests:  13%|█▎        | 136/1024 [00:00<00:02, 352.08it/s]
Adding requests:  17%|█▋        | 176/1024 [00:00<00:02, 365.61it/s]
Adding requests:  21%|██        | 217/1024 [00:00<00:02, 379.07it/s]
Adding requests:  25%|██▍       | 255/1024 [00:00<00:02, 378.39it/s]
Adding requests:  29%|██▉       | 295/1024 [00:00<00:01, 383.12it/s]
Adding requests:  33%|███▎      | 337/1024 [00:00<00:01, 391.40it/s]
Adding requests:  37%|███▋      | 377/1024 [00:01<00:01, 393.58it/s]
Adding requests:  41%|████      | 419/1024 [00:01<00:01, 400.63it/s]
Adding requests:  45%|████▍     | 460/1024 [00:01<00:01, 395.68it/s]
Adding requests:  49%|████▉     | 503/1024 [00:01<00:01, 403.57it/s]
Adding requests:  53%|█████▎    | 544/1024 [00:01<00:01, 404.42it/s]
Adding requests:  57%|█████▋    | 585/1024 [00:01<00:01, 398.40it/s]
Adding requests:  61%|██████    | 625/1024 [00:01<00:01, 394.54it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:01<00:00, 387.98it/s]
Adding requests:  69%|██████▉   | 705/1024 [00:01<00:00, 390.62it/s]
Adding requests:  73%|███████▎  | 745/1024 [00:01<00:00, 384.80it/s]
Adding requests:  77%|███████▋  | 785/1024 [00:02<00:00, 387.58it/s]
Adding requests:  80%|████████  | 824/1024 [00:02<00:00, 387.19it/s]
Adding requests:  84%|████████▍ | 864/1024 [00:02<00:00, 389.72it/s]
Adding requests:  88%|████████▊ | 906/1024 [00:02<00:00, 396.78it/s]
Adding requests:  92%|█████████▏| 946/1024 [00:02<00:00, 385.50it/s]
Adding requests:  96%|█████████▋| 986/1024 [00:02<00:00, 387.11it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 383.17it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:00<00:01, 528.23it/s, est. speed input: 540969.71 toks/s, output: 528.25 toks/s]
Processed prompts:  16%|█▋        | 167/1024 [00:01<00:08, 103.71it/s, est. speed input: 127116.77 toks/s, output: 124.14 toks/s]
Processed prompts:  19%|█▉        | 192/1024 [00:01<00:10, 80.76it/s, est. speed input: 102965.82 toks/s, output: 100.55 toks/s] 
Processed prompts:  20%|██        | 208/1024 [00:02<00:11, 71.71it/s, est. speed input: 94171.99 toks/s, output: 91.96 toks/s]  
Processed prompts:  21%|██▏       | 220/1024 [00:02<00:13, 60.28it/s, est. speed input: 85227.30 toks/s, output: 83.23 toks/s]
Processed prompts:  22%|██▏       | 229/1024 [00:02<00:13, 58.27it/s, est. speed input: 82854.97 toks/s, output: 80.91 toks/s]
Processed prompts:  23%|██▎       | 237/1024 [00:03<00:14, 55.37it/s, est. speed input: 80469.67 toks/s, output: 78.58 toks/s]
Processed prompts:  24%|██▍       | 244/1024 [00:03<00:15, 51.46it/s, est. speed input: 77987.21 toks/s, output: 76.16 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:03<00:16, 46.80it/s, est. speed input: 75456.10 toks/s, output: 73.69 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:03<00:16, 45.50it/s, est. speed input: 73704.97 toks/s, output: 71.98 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:03<00:16, 44.64it/s, est. speed input: 72176.24 toks/s, output: 70.48 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:03<00:17, 44.06it/s, est. speed input: 70816.66 toks/s, output: 69.16 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:04<00:16, 43.74it/s, est. speed input: 69608.99 toks/s, output: 67.98 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:04<00:16, 43.39it/s, est. speed input: 68477.77 toks/s, output: 66.87 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:04<00:16, 42.97it/s, est. speed input: 67402.99 toks/s, output: 65.82 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:04<00:16, 44.32it/s, est. speed input: 66755.06 toks/s, output: 65.19 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:04<00:16, 43.80it/s, est. speed input: 65865.67 toks/s, output: 64.32 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:05<00:16, 43.49it/s, est. speed input: 65050.05 toks/s, output: 63.52 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:05<00:16, 43.14it/s, est. speed input: 64271.26 toks/s, output: 62.76 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:05<00:15, 42.92it/s, est. speed input: 63549.96 toks/s, output: 62.06 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:05<00:15, 42.63it/s, est. speed input: 62853.50 toks/s, output: 61.38 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:05<00:15, 42.65it/s, est. speed input: 62237.11 toks/s, output: 60.78 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:06<00:15, 42.76it/s, est. speed input: 61674.34 toks/s, output: 60.23 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:06<00:15, 42.78it/s, est. speed input: 61138.06 toks/s, output: 59.70 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:06<00:15, 42.70it/s, est. speed input: 60619.58 toks/s, output: 59.20 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:06<00:14, 42.64it/s, est. speed input: 60129.78 toks/s, output: 58.72 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:06<00:14, 42.53it/s, est. speed input: 59657.71 toks/s, output: 58.26 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:06<00:14, 42.60it/s, est. speed input: 59230.33 toks/s, output: 57.84 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:07<00:14, 42.72it/s, est. speed input: 58834.62 toks/s, output: 57.46 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:07<00:14, 42.69it/s, est. speed input: 58444.84 toks/s, output: 57.07 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:07<00:14, 42.50it/s, est. speed input: 58055.71 toks/s, output: 56.69 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:07<00:13, 43.93it/s, est. speed input: 57854.24 toks/s, output: 56.50 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:07<00:13, 43.42it/s, est. speed input: 57503.96 toks/s, output: 56.16 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:08<00:13, 43.28it/s, est. speed input: 57191.91 toks/s, output: 55.85 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:08<00:13, 43.06it/s, est. speed input: 56880.96 toks/s, output: 55.55 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:08<00:13, 42.80it/s, est. speed input: 56574.46 toks/s, output: 55.25 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:08<00:12, 42.59it/s, est. speed input: 56278.23 toks/s, output: 54.96 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:08<00:12, 42.49it/s, est. speed input: 55998.34 toks/s, output: 54.69 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:09<00:12, 42.63it/s, est. speed input: 55750.05 toks/s, output: 54.44 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:09<00:12, 42.51it/s, est. speed input: 55491.98 toks/s, output: 54.19 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:09<00:12, 42.53it/s, est. speed input: 55254.02 toks/s, output: 53.96 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:09<00:12, 42.37it/s, est. speed input: 55010.38 toks/s, output: 53.72 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:09<00:11, 42.31it/s, est. speed input: 54780.50 toks/s, output: 53.50 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:09<00:11, 42.39it/s, est. speed input: 54568.70 toks/s, output: 53.29 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:10<00:11, 42.43it/s, est. speed input: 54364.61 toks/s, output: 53.09 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:10<00:11, 42.31it/s, est. speed input: 54155.85 toks/s, output: 52.89 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:10<00:11, 42.41it/s, est. speed input: 53968.67 toks/s, output: 52.70 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:10<00:10, 42.27it/s, est. speed input: 53772.29 toks/s, output: 52.51 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:10<00:10, 42.32it/s, est. speed input: 53593.86 toks/s, output: 52.34 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:11<00:10, 42.42it/s, est. speed input: 53425.91 toks/s, output: 52.17 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:11<00:10, 42.39it/s, est. speed input: 53256.77 toks/s, output: 52.01 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:11<00:10, 42.35it/s, est. speed input: 53091.91 toks/s, output: 51.85 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:11<00:09, 42.40it/s, est. speed input: 52937.08 toks/s, output: 51.70 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:11<00:09, 42.37it/s, est. speed input: 52783.16 toks/s, output: 51.55 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:12<00:09, 42.36it/s, est. speed input: 52635.46 toks/s, output: 51.40 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:12<00:09, 42.37it/s, est. speed input: 52492.63 toks/s, output: 51.26 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:12<00:09, 42.40it/s, est. speed input: 52355.72 toks/s, output: 51.13 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:12<00:09, 42.31it/s, est. speed input: 52216.63 toks/s, output: 50.99 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:12<00:08, 42.38it/s, est. speed input: 52089.28 toks/s, output: 50.87 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:12<00:08, 42.36it/s, est. speed input: 51961.71 toks/s, output: 50.74 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:13<00:08, 42.33it/s, est. speed input: 51836.76 toks/s, output: 50.62 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:13<00:08, 42.35it/s, est. speed input: 51717.38 toks/s, output: 50.51 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:13<00:08, 42.26it/s, est. speed input: 51596.13 toks/s, output: 50.39 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:13<00:07, 42.24it/s, est. speed input: 51479.73 toks/s, output: 50.27 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:13<00:07, 42.32it/s, est. speed input: 51372.20 toks/s, output: 50.17 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:14<00:07, 42.17it/s, est. speed input: 51256.45 toks/s, output: 50.05 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:14<00:07, 42.27it/s, est. speed input: 51154.59 toks/s, output: 49.96 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:14<00:07, 42.25it/s, est. speed input: 51050.80 toks/s, output: 49.85 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:14<00:06, 42.25it/s, est. speed input: 50950.38 toks/s, output: 49.76 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:14<00:06, 42.47it/s, est. speed input: 50863.32 toks/s, output: 49.67 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:15<00:06, 42.35it/s, est. speed input: 50765.04 toks/s, output: 49.58 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:15<00:06, 42.32it/s, est. speed input: 50671.70 toks/s, output: 49.48 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:15<00:06, 42.30it/s, est. speed input: 50580.91 toks/s, output: 49.40 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:15<00:06, 42.20it/s, est. speed input: 50488.16 toks/s, output: 49.30 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:15<00:05, 42.21it/s, est. speed input: 50401.08 toks/s, output: 49.22 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:15<00:05, 43.80it/s, est. speed input: 50388.61 toks/s, output: 49.21 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:16<00:05, 43.18it/s, est. speed input: 50298.78 toks/s, output: 49.12 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:16<00:05, 42.85it/s, est. speed input: 50215.38 toks/s, output: 49.04 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:16<00:05, 42.60it/s, est. speed input: 50132.51 toks/s, output: 48.96 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:16<00:04, 42.49it/s, est. speed input: 50054.86 toks/s, output: 48.88 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:16<00:04, 42.47it/s, est. speed input: 49981.05 toks/s, output: 48.81 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:17<00:04, 42.49it/s, est. speed input: 49910.23 toks/s, output: 48.74 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:17<00:04, 42.48it/s, est. speed input: 49840.29 toks/s, output: 48.67 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:17<00:04, 42.34it/s, est. speed input: 49765.94 toks/s, output: 48.60 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:17<00:03, 42.38it/s, est. speed input: 49699.15 toks/s, output: 48.53 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:17<00:03, 42.45it/s, est. speed input: 49635.42 toks/s, output: 48.47 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:18<00:03, 42.54it/s, est. speed input: 49574.84 toks/s, output: 48.41 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:18<00:03, 42.38it/s, est. speed input: 49506.17 toks/s, output: 48.35 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:18<00:03, 42.42it/s, est. speed input: 49445.18 toks/s, output: 48.29 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:18<00:02, 42.37it/s, est. speed input: 49382.38 toks/s, output: 48.22 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:18<00:02, 42.38it/s, est. speed input: 49322.78 toks/s, output: 48.17 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:18<00:02, 42.47it/s, est. speed input: 49267.27 toks/s, output: 48.11 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:19<00:02, 42.45it/s, est. speed input: 49209.81 toks/s, output: 48.06 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:19<00:02, 42.47it/s, est. speed input: 49154.60 toks/s, output: 48.00 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:19<00:02, 42.38it/s, est. speed input: 49096.76 toks/s, output: 47.95 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:19<00:01, 42.45it/s, est. speed input: 49044.77 toks/s, output: 47.90 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:19<00:01, 42.41it/s, est. speed input: 48990.65 toks/s, output: 47.84 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:20<00:01, 42.43it/s, est. speed input: 48939.23 toks/s, output: 47.79 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:20<00:01, 42.43it/s, est. speed input: 48888.20 toks/s, output: 47.74 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:20<00:01, 42.47it/s, est. speed input: 48839.49 toks/s, output: 47.69 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:20<00:00, 42.43it/s, est. speed input: 48789.53 toks/s, output: 47.65 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:20<00:00, 42.40it/s, est. speed input: 48740.39 toks/s, output: 47.60 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:21<00:00, 42.33it/s, est. speed input: 48690.31 toks/s, output: 47.55 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:21<00:00, 42.32it/s, est. speed input: 48642.53 toks/s, output: 47.50 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:21<00:00, 43.85it/s, est. speed input: 48645.66 toks/s, output: 47.51 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:21<00:00, 43.85it/s, est. speed input: 48931.40 toks/s, output: 47.78 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:21<00:00, 47.78it/s, est. speed input: 48931.40 toks/s, output: 47.78 toks/s]
[rank0]:[W126 11:17:26.871452611 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 11:17:28
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:17:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1274311) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1274311) WARNING 01-26 11:18:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 43.42 requests/s, 44507.83 total tokens/s, 43.42 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 11:17:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:17:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:17:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:17:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:17:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:17:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:17:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:17:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:17:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:17:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:17:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:17:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:17:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:17:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:17:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:17:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:17:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1274311) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1274311) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.13it/s]
(EngineCore_DP0 pid=1274311) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.53it/s]
(EngineCore_DP0 pid=1274311) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.60it/s]
(EngineCore_DP0 pid=1274311) 
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1274311) [2026-01-26 11:17:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1274311) [rank0]:W0126 11:18:09.654000 1274311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1274311) [rank0]:W0126 11:18:09.731000 1274311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1274311) [rank0]:W0126 11:18:10.645000 1274311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1274311) [rank0]:W0126 11:18:10.768000 1274311 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1274311) 2026-01-26 11:18:14,651 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1274311) 2026-01-26 11:18:14,678 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1274311) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 13.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  5.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  6.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.52it/s]
(EngineCore_DP0 pid=1274311) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 19.06it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 11.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 13.15it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 19/2048 [00:00<00:11, 182.66it/s]
Adding requests:   3%|▎         | 57/2048 [00:00<00:06, 296.60it/s]
Adding requests:   5%|▍         | 95/2048 [00:00<00:05, 331.72it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:05, 348.70it/s]
Adding requests:   8%|▊         | 172/2048 [00:00<00:05, 362.47it/s]
Adding requests:  10%|█         | 213/2048 [00:00<00:04, 377.36it/s]
Adding requests:  12%|█▏        | 252/2048 [00:00<00:04, 378.43it/s]
Adding requests:  14%|█▍        | 290/2048 [00:00<00:04, 374.27it/s]
Adding requests:  16%|█▌        | 331/2048 [00:00<00:04, 382.84it/s]
Adding requests:  18%|█▊        | 372/2048 [00:01<00:04, 389.66it/s]
Adding requests:  20%|██        | 413/2048 [00:01<00:04, 394.71it/s]
Adding requests:  22%|██▏       | 453/2048 [00:01<00:04, 394.76it/s]
Adding requests:  24%|██▍       | 496/2048 [00:01<00:03, 403.58it/s]
Adding requests:  26%|██▋       | 538/2048 [00:01<00:03, 407.26it/s]
Adding requests:  28%|██▊       | 579/2048 [00:01<00:03, 404.16it/s]
Adding requests:  30%|███       | 620/2048 [00:01<00:03, 393.23it/s]
Adding requests:  32%|███▏      | 660/2048 [00:01<00:03, 387.58it/s]
Adding requests:  34%|███▍      | 700/2048 [00:01<00:03, 389.87it/s]
Adding requests:  36%|███▌      | 740/2048 [00:01<00:03, 384.91it/s]
Adding requests:  38%|███▊      | 779/2048 [00:02<00:03, 377.18it/s]
Adding requests:  40%|███▉      | 818/2048 [00:02<00:03, 379.13it/s]
Adding requests:  42%|████▏     | 859/2048 [00:02<00:03, 387.80it/s]
Adding requests:  44%|████▍     | 899/2048 [00:02<00:02, 390.79it/s]
Adding requests:  46%|████▌     | 939/2048 [00:02<00:02, 384.56it/s]
Adding requests:  48%|████▊     | 978/2048 [00:02<00:02, 385.52it/s]
Adding requests:  50%|████▉     | 1017/2048 [00:02<00:02, 381.25it/s]
Adding requests:  52%|█████▏    | 1056/2048 [00:02<00:02, 378.61it/s]
Adding requests:  53%|█████▎    | 1094/2048 [00:02<00:02, 378.60it/s]
Adding requests:  55%|█████▌    | 1135/2048 [00:02<00:02, 386.04it/s]
Adding requests:  57%|█████▋    | 1174/2048 [00:03<00:02, 383.52it/s]
Adding requests:  59%|█████▉    | 1214/2048 [00:03<00:02, 385.78it/s]
Adding requests:  61%|██████    | 1254/2048 [00:03<00:02, 388.63it/s]
Adding requests:  63%|██████▎   | 1293/2048 [00:03<00:01, 380.38it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:03<00:01, 382.98it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:03<00:01, 389.14it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:03<00:01, 385.53it/s]
Adding requests:  71%|███████   | 1452/2048 [00:03<00:01, 385.70it/s]
Adding requests:  73%|███████▎  | 1493/2048 [00:03<00:01, 391.87it/s]
Adding requests:  75%|███████▍  | 1533/2048 [00:04<00:01, 387.83it/s]
Adding requests:  77%|███████▋  | 1572/2048 [00:04<00:01, 381.41it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:04<00:01, 382.68it/s]
Adding requests:  81%|████████  | 1650/2048 [00:04<00:01, 372.95it/s]
Adding requests:  82%|████████▏ | 1688/2048 [00:04<00:00, 371.13it/s]
Adding requests:  84%|████████▍ | 1728/2048 [00:04<00:00, 378.16it/s]
Adding requests:  86%|████████▋ | 1769/2048 [00:04<00:00, 386.50it/s]
Adding requests:  88%|████████▊ | 1808/2048 [00:04<00:00, 380.70it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:04<00:00, 383.49it/s]
Adding requests:  92%|█████████▏| 1888/2048 [00:04<00:00, 387.31it/s]
Adding requests:  94%|█████████▍| 1927/2048 [00:05<00:00, 382.55it/s]
Adding requests:  96%|█████████▌| 1966/2048 [00:05<00:00, 384.72it/s]
Adding requests:  98%|█████████▊| 2005/2048 [00:05<00:00, 381.88it/s]
Adding requests: 100%|█████████▉| 2044/2048 [00:05<00:00, 377.11it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 381.22it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:00<00:02, 702.24it/s, est. speed input: 719196.33 toks/s, output: 702.27 toks/s]
Processed prompts:  15%|█▍        | 297/2048 [00:01<00:12, 135.33it/s, est. speed input: 169884.41 toks/s, output: 165.90 toks/s]
Processed prompts:  16%|█▌        | 329/2048 [00:02<00:16, 101.28it/s, est. speed input: 134505.85 toks/s, output: 131.35 toks/s]
Processed prompts:  17%|█▋        | 349/2048 [00:02<00:18, 91.07it/s, est. speed input: 124373.04 toks/s, output: 121.46 toks/s] 
Processed prompts:  18%|█▊        | 363/2048 [00:03<00:21, 78.48it/s, est. speed input: 114630.69 toks/s, output: 111.94 toks/s]
Processed prompts:  18%|█▊        | 374/2048 [00:03<00:25, 66.33it/s, est. speed input: 106139.24 toks/s, output: 103.65 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:03<00:28, 57.34it/s, est. speed input: 99379.68 toks/s, output: 97.05 toks/s]  
Processed prompts:  20%|█▉        | 402/2048 [00:04<00:30, 53.51it/s, est. speed input: 94718.12 toks/s, output: 92.50 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:04<00:32, 50.64it/s, est. speed input: 90779.12 toks/s, output: 88.65 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:05<00:32, 49.30it/s, est. speed input: 87752.61 toks/s, output: 85.70 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:05<00:33, 47.50it/s, est. speed input: 84784.30 toks/s, output: 82.80 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:05<00:34, 46.29it/s, est. speed input: 82223.97 toks/s, output: 80.30 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:06<00:34, 45.26it/s, est. speed input: 79904.18 toks/s, output: 78.03 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:06<00:34, 44.77it/s, est. speed input: 77928.37 toks/s, output: 76.10 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:06<00:34, 44.30it/s, est. speed input: 76124.91 toks/s, output: 74.34 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:07<00:34, 43.99it/s, est. speed input: 74509.38 toks/s, output: 72.76 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:07<00:34, 43.82it/s, est. speed input: 73060.71 toks/s, output: 71.35 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:08<00:34, 43.63it/s, est. speed input: 71728.34 toks/s, output: 70.05 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:08<00:33, 43.50it/s, est. speed input: 70515.84 toks/s, output: 68.86 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:08<00:33, 43.44it/s, est. speed input: 69410.93 toks/s, output: 67.78 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:09<00:33, 43.38it/s, est. speed input: 68392.92 toks/s, output: 66.79 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:09<00:32, 43.37it/s, est. speed input: 67460.53 toks/s, output: 65.88 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:09<00:32, 43.38it/s, est. speed input: 66600.81 toks/s, output: 65.04 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:10<00:32, 43.31it/s, est. speed input: 65788.64 toks/s, output: 64.25 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:10<00:31, 43.36it/s, est. speed input: 65052.16 toks/s, output: 63.53 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:10<00:31, 43.31it/s, est. speed input: 64349.26 toks/s, output: 62.84 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:11<00:30, 43.40it/s, est. speed input: 63712.09 toks/s, output: 62.22 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:11<00:30, 43.47it/s, est. speed input: 63116.42 toks/s, output: 61.64 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:12<00:30, 43.43it/s, est. speed input: 62544.36 toks/s, output: 61.08 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:12<00:29, 43.46it/s, est. speed input: 62013.10 toks/s, output: 60.56 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:12<00:29, 43.45it/s, est. speed input: 61509.25 toks/s, output: 60.07 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:13<00:28, 44.22it/s, est. speed input: 61133.03 toks/s, output: 59.70 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:13<00:28, 43.91it/s, est. speed input: 60671.05 toks/s, output: 59.25 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:13<00:28, 43.83it/s, est. speed input: 60249.29 toks/s, output: 58.84 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:14<00:27, 43.74it/s, est. speed input: 59845.49 toks/s, output: 58.44 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:14<00:27, 43.56it/s, est. speed input: 59449.14 toks/s, output: 58.06 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:15<00:27, 43.59it/s, est. speed input: 59089.45 toks/s, output: 57.70 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:15<00:26, 43.53it/s, est. speed input: 58737.73 toks/s, output: 57.36 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:15<00:26, 43.49it/s, est. speed input: 58403.13 toks/s, output: 57.03 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:16<00:26, 43.46it/s, est. speed input: 58082.74 toks/s, output: 56.72 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:16<00:25, 43.41it/s, est. speed input: 57774.87 toks/s, output: 56.42 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:16<00:25, 43.43it/s, est. speed input: 57485.18 toks/s, output: 56.14 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:17<00:24, 43.46it/s, est. speed input: 57209.39 toks/s, output: 55.87 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:17<00:24, 43.36it/s, est. speed input: 56934.63 toks/s, output: 55.60 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:17<00:24, 43.36it/s, est. speed input: 56677.27 toks/s, output: 55.35 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:18<00:23, 43.40it/s, est. speed input: 56433.27 toks/s, output: 55.11 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:18<00:23, 43.37it/s, est. speed input: 56194.08 toks/s, output: 54.88 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:19<00:23, 43.38it/s, est. speed input: 55966.91 toks/s, output: 54.66 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:19<00:22, 43.33it/s, est. speed input: 55743.87 toks/s, output: 54.44 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:19<00:22, 43.32it/s, est. speed input: 55531.09 toks/s, output: 54.23 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:20<00:22, 43.32it/s, est. speed input: 55326.41 toks/s, output: 54.03 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:20<00:21, 43.35it/s, est. speed input: 55131.24 toks/s, output: 53.84 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:20<00:21, 43.37it/s, est. speed input: 54943.03 toks/s, output: 53.66 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:21<00:21, 43.32it/s, est. speed input: 54757.09 toks/s, output: 53.47 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:21<00:20, 43.34it/s, est. speed input: 54581.29 toks/s, output: 53.30 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:22<00:20, 43.30it/s, est. speed input: 54407.53 toks/s, output: 53.13 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:22<00:19, 43.32it/s, est. speed input: 54242.65 toks/s, output: 52.97 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:22<00:19, 44.06it/s, est. speed input: 54131.62 toks/s, output: 52.86 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:23<00:18, 43.78it/s, est. speed input: 53971.79 toks/s, output: 52.71 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:23<00:18, 44.43it/s, est. speed input: 53870.11 toks/s, output: 52.61 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:23<00:18, 44.08it/s, est. speed input: 53722.42 toks/s, output: 52.46 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:24<00:17, 43.78it/s, est. speed input: 53574.92 toks/s, output: 52.32 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:24<00:17, 43.58it/s, est. speed input: 53432.75 toks/s, output: 52.18 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:24<00:17, 43.45it/s, est. speed input: 53295.36 toks/s, output: 52.05 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:25<00:16, 43.35it/s, est. speed input: 53161.08 toks/s, output: 51.92 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:25<00:16, 44.00it/s, est. speed input: 53072.72 toks/s, output: 51.83 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:26<00:16, 43.78it/s, est. speed input: 52948.33 toks/s, output: 51.71 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:26<00:15, 43.59it/s, est. speed input: 52825.08 toks/s, output: 51.59 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:26<00:15, 43.47it/s, est. speed input: 52706.16 toks/s, output: 51.47 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:27<00:15, 43.35it/s, est. speed input: 52588.58 toks/s, output: 51.36 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:27<00:14, 43.25it/s, est. speed input: 52473.28 toks/s, output: 51.24 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:27<00:14, 43.25it/s, est. speed input: 52364.80 toks/s, output: 51.14 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:28<00:14, 43.23it/s, est. speed input: 52257.86 toks/s, output: 51.03 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:28<00:13, 43.95it/s, est. speed input: 52191.54 toks/s, output: 50.97 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:28<00:13, 43.76it/s, est. speed input: 52091.45 toks/s, output: 50.87 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:29<00:12, 43.57it/s, est. speed input: 51991.61 toks/s, output: 50.77 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:29<00:12, 43.47it/s, est. speed input: 51895.76 toks/s, output: 50.68 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:30<00:11, 44.17it/s, est. speed input: 51838.73 toks/s, output: 50.62 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:30<00:11, 43.83it/s, est. speed input: 51744.13 toks/s, output: 50.53 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:30<00:11, 44.39it/s, est. speed input: 51688.49 toks/s, output: 50.48 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:31<00:10, 44.01it/s, est. speed input: 51599.24 toks/s, output: 50.39 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:31<00:10, 43.79it/s, est. speed input: 51513.98 toks/s, output: 50.31 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:31<00:10, 43.65it/s, est. speed input: 51431.06 toks/s, output: 50.23 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:32<00:09, 44.23it/s, est. speed input: 51380.35 toks/s, output: 50.18 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:32<00:09, 43.88it/s, est. speed input: 51297.68 toks/s, output: 50.10 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:32<00:09, 43.66it/s, est. speed input: 51217.66 toks/s, output: 50.02 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:33<00:08, 43.44it/s, est. speed input: 51136.58 toks/s, output: 49.94 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:33<00:08, 43.40it/s, est. speed input: 51062.20 toks/s, output: 49.87 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:34<00:08, 43.31it/s, est. speed input: 50986.66 toks/s, output: 49.79 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:34<00:07, 43.31it/s, est. speed input: 50915.54 toks/s, output: 49.72 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:34<00:07, 44.00it/s, est. speed input: 50874.12 toks/s, output: 49.68 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:35<00:06, 44.50it/s, est. speed input: 50833.70 toks/s, output: 49.64 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:35<00:06, 44.02it/s, est. speed input: 50761.81 toks/s, output: 49.57 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:35<00:06, 43.68it/s, est. speed input: 50690.97 toks/s, output: 49.50 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:36<00:05, 43.59it/s, est. speed input: 50627.10 toks/s, output: 49.44 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:36<00:05, 43.42it/s, est. speed input: 50560.58 toks/s, output: 49.38 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:37<00:05, 43.30it/s, est. speed input: 50495.06 toks/s, output: 49.31 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:37<00:04, 43.22it/s, est. speed input: 50431.13 toks/s, output: 49.25 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:37<00:04, 43.20it/s, est. speed input: 50369.85 toks/s, output: 49.19 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:38<00:04, 43.15it/s, est. speed input: 50308.46 toks/s, output: 49.13 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:38<00:03, 43.91it/s, est. speed input: 50277.52 toks/s, output: 49.10 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:38<00:03, 43.67it/s, est. speed input: 50219.18 toks/s, output: 49.04 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:39<00:02, 43.47it/s, est. speed input: 50160.36 toks/s, output: 48.98 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:39<00:02, 43.41it/s, est. speed input: 50105.96 toks/s, output: 48.93 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:39<00:02, 43.31it/s, est. speed input: 50050.15 toks/s, output: 48.88 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:40<00:01, 43.25it/s, est. speed input: 49995.69 toks/s, output: 48.82 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:40<00:01, 43.93it/s, est. speed input: 49967.40 toks/s, output: 48.80 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:41<00:01, 43.68it/s, est. speed input: 49914.83 toks/s, output: 48.74 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:41<00:00, 43.43it/s, est. speed input: 49860.52 toks/s, output: 48.69 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:41<00:00, 44.27it/s, est. speed input: 49840.93 toks/s, output: 48.67 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:41<00:00, 44.27it/s, est. speed input: 50183.23 toks/s, output: 49.01 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:41<00:00, 49.01it/s, est. speed input: 50183.23 toks/s, output: 49.01 toks/s]
[rank0]:[W126 11:19:05.350536051 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 11:19:07
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:19:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1276246) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1276246) WARNING 01-26 11:19:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 43.57 requests/s, 44654.70 total tokens/s, 43.57 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 11:19:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:19:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:19:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:19:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:19:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:19:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:19:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:19:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:19:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:19:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:19:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:19:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:19:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:19:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:19:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:19:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:19:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1276246) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1276246) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=1276246) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1276246) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1276246) 
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1276246) [2026-01-26 11:19:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1276246) [rank0]:W0126 11:19:57.811000 1276246 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1276246) [rank0]:W0126 11:19:57.889000 1276246 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1276246) [rank0]:W0126 11:19:59.226000 1276246 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1276246) [rank0]:W0126 11:19:59.352000 1276246 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1276246) 2026-01-26 11:20:03,416 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1276246) 2026-01-26 11:20:03,488 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1276246) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:03,  2.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  6.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 10.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  9.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 11.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 13.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.44it/s]
(EngineCore_DP0 pid=1276246) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:01,  5.48it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:01,  3.18it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:01,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:01<00:00,  5.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  8.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  6.23it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 247.99it/s]
Adding requests:   2%|▏         | 65/4096 [00:00<00:12, 335.32it/s]
Adding requests:   2%|▏         | 101/4096 [00:00<00:11, 344.78it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:11, 357.56it/s]
Adding requests:   4%|▍         | 178/4096 [00:00<00:10, 368.84it/s]
Adding requests:   5%|▌         | 220/4096 [00:00<00:10, 384.78it/s]
Adding requests:   6%|▋         | 259/4096 [00:00<00:10, 380.20it/s]
Adding requests:   7%|▋         | 299/4096 [00:00<00:09, 385.22it/s]
Adding requests:   8%|▊         | 340/4096 [00:00<00:09, 390.80it/s]
Adding requests:   9%|▉         | 380/4096 [00:01<00:09, 392.98it/s]
Adding requests:  10%|█         | 422/4096 [00:01<00:09, 400.07it/s]
Adding requests:  11%|█▏        | 463/4096 [00:01<00:09, 396.16it/s]
Adding requests:  12%|█▏        | 506/4096 [00:01<00:08, 404.60it/s]
Adding requests:  13%|█▎        | 548/4096 [00:01<00:08, 407.03it/s]
Adding requests:  14%|█▍        | 589/4096 [00:01<00:08, 402.81it/s]
Adding requests:  15%|█▌        | 630/4096 [00:01<00:08, 396.90it/s]
Adding requests:  16%|█▋        | 670/4096 [00:01<00:08, 386.74it/s]
Adding requests:  17%|█▋        | 711/4096 [00:01<00:08, 393.28it/s]
Adding requests:  18%|█▊        | 751/4096 [00:01<00:08, 384.90it/s]
Adding requests:  19%|█▉        | 791/4096 [00:02<00:08, 387.46it/s]
Adding requests:  20%|██        | 831/4096 [00:02<00:08, 390.91it/s]
Adding requests:  21%|██▏       | 872/4096 [00:02<00:08, 393.35it/s]
Adding requests:  22%|██▏       | 912/4096 [00:02<00:08, 391.05it/s]
Adding requests:  23%|██▎       | 952/4096 [00:02<00:08, 387.03it/s]
Adding requests:  24%|██▍       | 991/4096 [00:02<00:08, 385.95it/s]
Adding requests:  25%|██▌       | 1030/4096 [00:02<00:07, 383.58it/s]
Adding requests:  26%|██▌       | 1069/4096 [00:02<00:07, 383.11it/s]
Adding requests:  27%|██▋       | 1108/4096 [00:02<00:08, 370.79it/s]
Adding requests:  28%|██▊       | 1148/4096 [00:02<00:07, 377.61it/s]
Adding requests:  29%|██▉       | 1187/4096 [00:03<00:07, 378.44it/s]
Adding requests:  30%|██▉       | 1228/4096 [00:03<00:07, 385.05it/s]
Adding requests:  31%|███       | 1267/4096 [00:03<00:07, 384.85it/s]
Adding requests:  32%|███▏      | 1306/4096 [00:03<00:07, 381.71it/s]
Adding requests:  33%|███▎      | 1345/4096 [00:03<00:07, 383.39it/s]
Adding requests:  34%|███▍      | 1385/4096 [00:03<00:06, 387.30it/s]
Adding requests:  35%|███▍      | 1424/4096 [00:03<00:06, 383.16it/s]
Adding requests:  36%|███▌      | 1464/4096 [00:03<00:06, 386.90it/s]
Adding requests:  37%|███▋      | 1504/4096 [00:03<00:06, 390.33it/s]
Adding requests:  38%|███▊      | 1544/4096 [00:04<00:06, 389.86it/s]
Adding requests:  39%|███▊      | 1583/4096 [00:04<00:06, 381.60it/s]
Adding requests:  40%|███▉      | 1622/4096 [00:04<00:06, 376.02it/s]
Adding requests:  41%|████      | 1660/4096 [00:04<00:06, 369.71it/s]
Adding requests:  41%|████▏     | 1698/4096 [00:04<00:06, 372.29it/s]
Adding requests:  42%|████▏     | 1738/4096 [00:04<00:06, 378.24it/s]
Adding requests:  43%|████▎     | 1779/4096 [00:04<00:06, 385.76it/s]
Adding requests:  44%|████▍     | 1818/4096 [00:04<00:05, 380.84it/s]
Adding requests:  45%|████▌     | 1858/4096 [00:04<00:05, 385.88it/s]
Adding requests:  46%|████▋     | 1897/4096 [00:04<00:05, 384.26it/s]
Adding requests:  47%|████▋     | 1939/4096 [00:05<00:05, 391.49it/s]
Adding requests:  48%|████▊     | 1979/4096 [00:05<00:05, 392.16it/s]
Adding requests:  49%|████▉     | 2019/4096 [00:05<00:05, 381.71it/s]
Adding requests:  50%|█████     | 2058/4096 [00:05<00:05, 380.21it/s]
Adding requests:  51%|█████     | 2097/4096 [00:05<00:05, 377.27it/s]
Adding requests:  52%|█████▏    | 2136/4096 [00:05<00:05, 378.86it/s]
Adding requests:  53%|█████▎    | 2174/4096 [00:05<00:05, 373.46it/s]
Adding requests:  54%|█████▍    | 2212/4096 [00:05<00:05, 371.37it/s]
Adding requests:  55%|█████▍    | 2252/4096 [00:05<00:04, 378.28it/s]
Adding requests:  56%|█████▌    | 2293/4096 [00:05<00:04, 386.92it/s]
Adding requests:  57%|█████▋    | 2332/4096 [00:06<00:04, 376.08it/s]
Adding requests:  58%|█████▊    | 2373/4096 [00:06<00:04, 384.54it/s]
Adding requests:  59%|█████▉    | 2415/4096 [00:06<00:04, 391.86it/s]
Adding requests:  60%|█████▉    | 2455/4096 [00:06<00:04, 389.37it/s]
Adding requests:  61%|██████    | 2495/4096 [00:06<00:04, 391.43it/s]
Adding requests:  62%|██████▏   | 2536/4096 [00:06<00:03, 396.25it/s]
Adding requests:  63%|██████▎   | 2579/4096 [00:06<00:03, 406.02it/s]
Adding requests:  64%|██████▍   | 2620/4096 [00:06<00:03, 400.76it/s]
Adding requests:  65%|██████▍   | 2661/4096 [00:06<00:03, 390.98it/s]
Adding requests:  66%|██████▌   | 2701/4096 [00:07<00:03, 387.55it/s]
Adding requests:  67%|██████▋   | 2740/4096 [00:07<00:03, 387.68it/s]
Adding requests:  68%|██████▊   | 2782/4096 [00:07<00:03, 394.39it/s]
Adding requests:  69%|██████▉   | 2823/4096 [00:07<00:03, 398.00it/s]
Adding requests:  70%|██████▉   | 2863/4096 [00:07<00:03, 398.43it/s]
Adding requests:  71%|███████   | 2903/4096 [00:07<00:03, 396.85it/s]
Adding requests:  72%|███████▏  | 2944/4096 [00:07<00:02, 399.40it/s]
Adding requests:  73%|███████▎  | 2984/4096 [00:07<00:02, 394.78it/s]
Adding requests:  74%|███████▍  | 3026/4096 [00:07<00:02, 399.14it/s]
Adding requests:  75%|███████▍  | 3068/4096 [00:07<00:02, 402.15it/s]
Adding requests:  76%|███████▌  | 3109/4096 [00:08<00:02, 401.55it/s]
Adding requests:  77%|███████▋  | 3150/4096 [00:08<00:02, 402.70it/s]
Adding requests:  78%|███████▊  | 3191/4096 [00:08<00:02, 397.75it/s]
Adding requests:  79%|███████▉  | 3232/4096 [00:08<00:02, 398.42it/s]
Adding requests:  80%|███████▉  | 3272/4096 [00:08<00:02, 392.46it/s]
Adding requests:  81%|████████  | 3312/4096 [00:08<00:02, 381.76it/s]
Adding requests:  82%|████████▏ | 3352/4096 [00:08<00:01, 383.84it/s]
Adding requests:  83%|████████▎ | 3392/4096 [00:08<00:01, 388.06it/s]
Adding requests:  84%|████████▍ | 3432/4096 [00:08<00:01, 391.13it/s]
Adding requests:  85%|████████▍ | 3472/4096 [00:08<00:01, 393.26it/s]
Adding requests:  86%|████████▌ | 3512/4096 [00:09<00:01, 393.89it/s]
Adding requests:  87%|████████▋ | 3554/4096 [00:09<00:01, 399.75it/s]
Adding requests:  88%|████████▊ | 3594/4096 [00:09<00:01, 399.10it/s]
Adding requests:  89%|████████▊ | 3635/4096 [00:09<00:01, 399.73it/s]
Adding requests:  90%|████████▉ | 3675/4096 [00:09<00:01, 382.37it/s]
Adding requests:  91%|█████████ | 3714/4096 [00:09<00:00, 383.73it/s]
Adding requests:  92%|█████████▏| 3753/4096 [00:09<00:00, 380.75it/s]
Adding requests:  93%|█████████▎| 3792/4096 [00:09<00:00, 371.26it/s]
Adding requests:  94%|█████████▎| 3830/4096 [00:09<00:00, 369.48it/s]
Adding requests:  94%|█████████▍| 3870/4096 [00:10<00:00, 376.98it/s]
Adding requests:  95%|█████████▌| 3908/4096 [00:10<00:00, 372.60it/s]
Adding requests:  96%|█████████▋| 3946/4096 [00:10<00:00, 373.56it/s]
Adding requests:  97%|█████████▋| 3984/4096 [00:10<00:00, 373.07it/s]
Adding requests:  98%|█████████▊| 4022/4096 [00:10<00:00, 374.66it/s]
Adding requests:  99%|█████████▉| 4060/4096 [00:10<00:00, 375.42it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 385.66it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█▏        | 465/4096 [00:00<00:05, 614.20it/s, est. speed input: 628963.31 toks/s, output: 614.21 toks/s]
Processed prompts:  13%|█▎        | 527/4096 [00:01<00:11, 306.48it/s, est. speed input: 361824.38 toks/s, output: 353.34 toks/s]
Processed prompts:  14%|█▎        | 558/4096 [00:02<00:18, 186.53it/s, est. speed input: 256598.31 toks/s, output: 250.58 toks/s]
Processed prompts:  14%|█▍        | 577/4096 [00:02<00:28, 123.26it/s, est. speed input: 199398.02 toks/s, output: 194.72 toks/s]
Processed prompts:  14%|█▍        | 593/4096 [00:03<00:40, 86.93it/s, est. speed input: 164361.63 toks/s, output: 160.51 toks/s] 
Processed prompts:  15%|█▌        | 625/4096 [00:04<00:47, 72.35it/s, est. speed input: 144647.95 toks/s, output: 141.26 toks/s]
Processed prompts:  16%|█▌        | 657/4096 [00:05<00:54, 63.10it/s, est. speed input: 130548.59 toks/s, output: 127.49 toks/s]
Processed prompts:  17%|█▋        | 689/4096 [00:05<00:59, 56.87it/s, est. speed input: 119833.57 toks/s, output: 117.02 toks/s]
Processed prompts:  18%|█▊        | 721/4096 [00:06<01:04, 52.72it/s, est. speed input: 111501.45 toks/s, output: 108.89 toks/s]
Processed prompts:  18%|█▊        | 753/4096 [00:07<01:06, 49.98it/s, est. speed input: 104879.38 toks/s, output: 102.42 toks/s]
Processed prompts:  19%|█▉        | 785/4096 [00:08<01:08, 48.48it/s, est. speed input: 99689.27 toks/s, output: 97.35 toks/s]  
Processed prompts:  20%|█▉        | 817/4096 [00:08<01:09, 47.05it/s, est. speed input: 95134.20 toks/s, output: 92.90 toks/s]
Processed prompts:  21%|██        | 849/4096 [00:09<01:10, 46.03it/s, est. speed input: 91263.29 toks/s, output: 89.12 toks/s]
Processed prompts:  22%|██▏       | 881/4096 [00:10<01:10, 45.34it/s, est. speed input: 87946.94 toks/s, output: 85.89 toks/s]
Processed prompts:  22%|██▏       | 913/4096 [00:10<01:11, 44.81it/s, est. speed input: 85056.52 toks/s, output: 83.06 toks/s]
Processed prompts:  23%|██▎       | 945/4096 [00:11<01:10, 44.42it/s, est. speed input: 82518.32 toks/s, output: 80.58 toks/s]
Processed prompts:  24%|██▍       | 977/4096 [00:12<01:10, 44.21it/s, est. speed input: 80299.90 toks/s, output: 78.42 toks/s]
Processed prompts:  25%|██▍       | 1009/4096 [00:13<01:10, 43.99it/s, est. speed input: 78305.83 toks/s, output: 76.47 toks/s]
Processed prompts:  25%|██▌       | 1041/4096 [00:13<01:09, 43.86it/s, est. speed input: 76528.00 toks/s, output: 74.73 toks/s]
Processed prompts:  26%|██▌       | 1073/4096 [00:14<01:09, 43.76it/s, est. speed input: 74924.64 toks/s, output: 73.17 toks/s]
Processed prompts:  27%|██▋       | 1105/4096 [00:15<01:08, 43.76it/s, est. speed input: 73494.11 toks/s, output: 71.77 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:16<01:07, 43.69it/s, est. speed input: 72175.44 toks/s, output: 70.48 toks/s]
Processed prompts:  29%|██▊       | 1169/4096 [00:16<01:07, 43.60it/s, est. speed input: 70964.29 toks/s, output: 69.30 toks/s]
Processed prompts:  29%|██▉       | 1201/4096 [00:17<01:05, 43.99it/s, est. speed input: 69952.19 toks/s, output: 68.31 toks/s]
Processed prompts:  30%|███       | 1233/4096 [00:18<01:04, 44.27it/s, est. speed input: 69020.19 toks/s, output: 67.40 toks/s]
Processed prompts:  31%|███       | 1265/4096 [00:19<01:04, 44.00it/s, est. speed input: 68067.62 toks/s, output: 66.47 toks/s]
Processed prompts:  32%|███▏      | 1297/4096 [00:19<01:03, 43.78it/s, est. speed input: 67178.80 toks/s, output: 65.60 toks/s]
Processed prompts:  32%|███▏      | 1329/4096 [00:20<01:02, 44.12it/s, est. speed input: 66443.75 toks/s, output: 64.89 toks/s]
Processed prompts:  33%|███▎      | 1361/4096 [00:21<01:02, 43.92it/s, est. speed input: 65682.23 toks/s, output: 64.14 toks/s]
Processed prompts:  34%|███▍      | 1393/4096 [00:21<01:01, 43.77it/s, est. speed input: 64969.57 toks/s, output: 63.45 toks/s]
Processed prompts:  35%|███▍      | 1425/4096 [00:22<01:01, 43.64it/s, est. speed input: 64300.30 toks/s, output: 62.79 toks/s]
Processed prompts:  36%|███▌      | 1457/4096 [00:23<00:59, 44.00it/s, est. speed input: 63740.68 toks/s, output: 62.25 toks/s]
Processed prompts:  36%|███▋      | 1489/4096 [00:24<00:59, 43.85it/s, est. speed input: 63156.07 toks/s, output: 61.68 toks/s]
Processed prompts:  37%|███▋      | 1521/4096 [00:24<00:58, 44.11it/s, est. speed input: 62656.92 toks/s, output: 61.19 toks/s]
Processed prompts:  38%|███▊      | 1553/4096 [00:25<00:57, 44.30it/s, est. speed input: 62185.74 toks/s, output: 60.73 toks/s]
Processed prompts:  39%|███▊      | 1585/4096 [00:26<00:57, 44.00it/s, est. speed input: 61685.56 toks/s, output: 60.24 toks/s]
Processed prompts:  39%|███▉      | 1617/4096 [00:27<00:56, 44.20it/s, est. speed input: 61263.08 toks/s, output: 59.83 toks/s]
Processed prompts:  40%|████      | 1649/4096 [00:27<00:55, 43.97it/s, est. speed input: 60818.14 toks/s, output: 59.39 toks/s]
Processed prompts:  41%|████      | 1681/4096 [00:28<00:55, 43.78it/s, est. speed input: 60391.70 toks/s, output: 58.98 toks/s]
Processed prompts:  42%|████▏     | 1713/4096 [00:29<00:54, 44.06it/s, est. speed input: 60035.28 toks/s, output: 58.63 toks/s]
Processed prompts:  43%|████▎     | 1745/4096 [00:29<00:53, 44.28it/s, est. speed input: 59696.93 toks/s, output: 58.30 toks/s]
Processed prompts:  43%|████▎     | 1777/4096 [00:30<00:52, 43.96it/s, est. speed input: 59324.41 toks/s, output: 57.93 toks/s]
Processed prompts:  44%|████▍     | 1809/4096 [00:31<00:52, 43.75it/s, est. speed input: 58971.40 toks/s, output: 57.59 toks/s]
Processed prompts:  45%|████▍     | 1841/4096 [00:32<00:51, 43.59it/s, est. speed input: 58632.15 toks/s, output: 57.26 toks/s]
Processed prompts:  46%|████▌     | 1873/4096 [00:32<00:50, 43.89it/s, est. speed input: 58349.87 toks/s, output: 56.98 toks/s]
Processed prompts:  47%|████▋     | 1905/4096 [00:33<00:50, 43.74it/s, est. speed input: 58044.62 toks/s, output: 56.68 toks/s]
Processed prompts:  47%|████▋     | 1937/4096 [00:34<00:49, 43.63it/s, est. speed input: 57751.43 toks/s, output: 56.40 toks/s]
Processed prompts:  48%|████▊     | 1969/4096 [00:35<00:48, 43.93it/s, est. speed input: 57505.36 toks/s, output: 56.16 toks/s]
Processed prompts:  49%|████▉     | 2001/4096 [00:35<00:47, 43.72it/s, est. speed input: 57231.82 toks/s, output: 55.89 toks/s]
Processed prompts:  50%|████▉     | 2033/4096 [00:36<00:47, 43.57it/s, est. speed input: 56968.89 toks/s, output: 55.63 toks/s]
Processed prompts:  50%|█████     | 2065/4096 [00:37<00:46, 43.89it/s, est. speed input: 56752.54 toks/s, output: 55.42 toks/s]
Processed prompts:  51%|█████     | 2097/4096 [00:37<00:45, 43.68it/s, est. speed input: 56508.84 toks/s, output: 55.18 toks/s]
Processed prompts:  52%|█████▏    | 2129/4096 [00:38<00:45, 43.56it/s, est. speed input: 56276.26 toks/s, output: 54.96 toks/s]
Processed prompts:  53%|█████▎    | 2161/4096 [00:39<00:44, 43.47it/s, est. speed input: 56051.52 toks/s, output: 54.74 toks/s]
Processed prompts:  54%|█████▎    | 2193/4096 [00:40<00:43, 43.75it/s, est. speed input: 55862.19 toks/s, output: 54.55 toks/s]
Processed prompts:  54%|█████▍    | 2225/4096 [00:40<00:42, 43.59it/s, est. speed input: 55652.75 toks/s, output: 54.35 toks/s]
Processed prompts:  55%|█████▌    | 2257/4096 [00:41<00:42, 43.47it/s, est. speed input: 55449.41 toks/s, output: 54.15 toks/s]
Processed prompts:  56%|█████▌    | 2289/4096 [00:42<00:41, 43.40it/s, est. speed input: 55254.67 toks/s, output: 53.96 toks/s]
Processed prompts:  57%|█████▋    | 2321/4096 [00:43<00:40, 43.36it/s, est. speed input: 55066.75 toks/s, output: 53.78 toks/s]
Processed prompts:  57%|█████▋    | 2353/4096 [00:43<00:40, 43.30it/s, est. speed input: 54882.95 toks/s, output: 53.60 toks/s]
Processed prompts:  58%|█████▊    | 2385/4096 [00:44<00:39, 43.26it/s, est. speed input: 54706.04 toks/s, output: 53.42 toks/s]
Processed prompts:  59%|█████▉    | 2417/4096 [00:45<00:38, 43.26it/s, est. speed input: 54536.53 toks/s, output: 53.26 toks/s]
Processed prompts:  60%|█████▉    | 2449/4096 [00:46<00:38, 43.25it/s, est. speed input: 54371.58 toks/s, output: 53.10 toks/s]
Processed prompts:  61%|██████    | 2481/4096 [00:46<00:37, 43.22it/s, est. speed input: 54210.19 toks/s, output: 52.94 toks/s]
Processed prompts:  61%|██████▏   | 2513/4096 [00:47<00:36, 43.20it/s, est. speed input: 54053.97 toks/s, output: 52.79 toks/s]
Processed prompts:  62%|██████▏   | 2545/4096 [00:48<00:35, 43.59it/s, est. speed input: 53928.30 toks/s, output: 52.66 toks/s]
Processed prompts:  63%|██████▎   | 2577/4096 [00:49<00:34, 43.87it/s, est. speed input: 53806.30 toks/s, output: 52.55 toks/s]
Processed prompts:  64%|██████▎   | 2609/4096 [00:49<00:34, 43.62it/s, est. speed input: 53661.28 toks/s, output: 52.40 toks/s]
Processed prompts:  64%|██████▍   | 2641/4096 [00:50<00:33, 43.45it/s, est. speed input: 53520.33 toks/s, output: 52.27 toks/s]
Processed prompts:  65%|██████▌   | 2673/4096 [00:51<00:32, 43.34it/s, est. speed input: 53384.50 toks/s, output: 52.13 toks/s]
Processed prompts:  66%|██████▌   | 2705/4096 [00:52<00:32, 43.26it/s, est. speed input: 53251.65 toks/s, output: 52.00 toks/s]
Processed prompts:  67%|██████▋   | 2737/4096 [00:52<00:31, 43.56it/s, est. speed input: 53143.62 toks/s, output: 51.90 toks/s]
Processed prompts:  68%|██████▊   | 2769/4096 [00:53<00:30, 43.41it/s, est. speed input: 53017.85 toks/s, output: 51.78 toks/s]
Processed prompts:  68%|██████▊   | 2801/4096 [00:54<00:29, 43.30it/s, est. speed input: 52895.48 toks/s, output: 51.66 toks/s]
Processed prompts:  69%|██████▉   | 2833/4096 [00:54<00:29, 43.28it/s, est. speed input: 52779.02 toks/s, output: 51.54 toks/s]
Processed prompts:  70%|██████▉   | 2865/4096 [00:55<00:28, 43.20it/s, est. speed input: 52662.69 toks/s, output: 51.43 toks/s]
Processed prompts:  71%|███████   | 2897/4096 [00:56<00:26, 44.43it/s, est. speed input: 52615.81 toks/s, output: 51.38 toks/s]
Processed prompts:  72%|███████▏  | 2929/4096 [00:57<00:26, 44.07it/s, est. speed input: 52508.06 toks/s, output: 51.28 toks/s]
Processed prompts:  72%|███████▏  | 2961/4096 [00:57<00:25, 43.80it/s, est. speed input: 52401.75 toks/s, output: 51.17 toks/s]
Processed prompts:  73%|███████▎  | 2993/4096 [00:58<00:25, 43.60it/s, est. speed input: 52297.40 toks/s, output: 51.07 toks/s]
Processed prompts:  74%|███████▍  | 3025/4096 [00:59<00:24, 43.43it/s, est. speed input: 52194.47 toks/s, output: 50.97 toks/s]
Processed prompts:  75%|███████▍  | 3057/4096 [01:00<00:23, 43.30it/s, est. speed input: 52093.45 toks/s, output: 50.87 toks/s]
Processed prompts:  75%|███████▌  | 3089/4096 [01:00<00:23, 43.23it/s, est. speed input: 51995.62 toks/s, output: 50.78 toks/s]
Processed prompts:  76%|███████▌  | 3121/4096 [01:01<00:22, 43.17it/s, est. speed input: 51899.99 toks/s, output: 50.68 toks/s]
Processed prompts:  77%|███████▋  | 3153/4096 [01:02<00:21, 43.15it/s, est. speed input: 51807.34 toks/s, output: 50.59 toks/s]
Processed prompts:  78%|███████▊  | 3185/4096 [01:03<00:21, 43.10it/s, est. speed input: 51715.45 toks/s, output: 50.50 toks/s]
Processed prompts:  79%|███████▊  | 3217/4096 [01:03<00:20, 43.09it/s, est. speed input: 51626.92 toks/s, output: 50.42 toks/s]
Processed prompts:  79%|███████▉  | 3249/4096 [01:04<00:19, 43.04it/s, est. speed input: 51538.16 toks/s, output: 50.33 toks/s]
Processed prompts:  80%|████████  | 3281/4096 [01:05<00:18, 43.02it/s, est. speed input: 51452.35 toks/s, output: 50.25 toks/s]
Processed prompts:  81%|████████  | 3313/4096 [01:06<00:18, 43.03it/s, est. speed input: 51369.26 toks/s, output: 50.17 toks/s]
Processed prompts:  82%|████████▏ | 3345/4096 [01:06<00:17, 43.03it/s, est. speed input: 51288.08 toks/s, output: 50.09 toks/s]
Processed prompts:  82%|████████▏ | 3377/4096 [01:07<00:16, 42.99it/s, est. speed input: 51206.79 toks/s, output: 50.01 toks/s]
Processed prompts:  83%|████████▎ | 3409/4096 [01:08<00:15, 42.95it/s, est. speed input: 51126.84 toks/s, output: 49.93 toks/s]
Processed prompts:  84%|████████▍ | 3441/4096 [01:09<00:15, 42.99it/s, est. speed input: 51051.45 toks/s, output: 49.85 toks/s]
Processed prompts:  85%|████████▍ | 3473/4096 [01:09<00:14, 42.97it/s, est. speed input: 50975.39 toks/s, output: 49.78 toks/s]
Processed prompts:  86%|████████▌ | 3505/4096 [01:10<00:13, 42.99it/s, est. speed input: 50902.80 toks/s, output: 49.71 toks/s]
Processed prompts:  86%|████████▋ | 3537/4096 [01:11<00:12, 43.40it/s, est. speed input: 50847.37 toks/s, output: 49.66 toks/s]
Processed prompts:  87%|████████▋ | 3569/4096 [01:11<00:12, 43.23it/s, est. speed input: 50775.15 toks/s, output: 49.59 toks/s]
Processed prompts:  88%|████████▊ | 3601/4096 [01:12<00:11, 43.17it/s, est. speed input: 50706.31 toks/s, output: 49.52 toks/s]
Processed prompts:  89%|████████▊ | 3633/4096 [01:13<00:10, 43.13it/s, est. speed input: 50639.19 toks/s, output: 49.45 toks/s]
Processed prompts:  89%|████████▉ | 3665/4096 [01:14<00:09, 43.45it/s, est. speed input: 50587.07 toks/s, output: 49.40 toks/s]
Processed prompts:  90%|█████████ | 3697/4096 [01:14<00:09, 43.33it/s, est. speed input: 50522.34 toks/s, output: 49.34 toks/s]
Processed prompts:  91%|█████████ | 3729/4096 [01:15<00:08, 43.22it/s, est. speed input: 50458.30 toks/s, output: 49.28 toks/s]
Processed prompts:  92%|█████████▏| 3761/4096 [01:16<00:07, 43.14it/s, est. speed input: 50395.09 toks/s, output: 49.21 toks/s]
Processed prompts:  93%|█████████▎| 3793/4096 [01:17<00:07, 43.09it/s, est. speed input: 50333.35 toks/s, output: 49.15 toks/s]
Processed prompts:  93%|█████████▎| 3825/4096 [01:17<00:06, 43.05it/s, est. speed input: 50272.60 toks/s, output: 49.09 toks/s]
Processed prompts:  94%|█████████▍| 3857/4096 [01:18<00:05, 43.00it/s, est. speed input: 50212.47 toks/s, output: 49.04 toks/s]
Processed prompts:  95%|█████████▍| 3889/4096 [01:19<00:04, 42.97it/s, est. speed input: 50153.46 toks/s, output: 48.98 toks/s]
Processed prompts:  96%|█████████▌| 3921/4096 [01:20<00:04, 43.71it/s, est. speed input: 50122.54 toks/s, output: 48.95 toks/s]
Processed prompts:  97%|█████████▋| 3953/4096 [01:20<00:03, 43.50it/s, est. speed input: 50066.75 toks/s, output: 48.89 toks/s]
Processed prompts:  97%|█████████▋| 3985/4096 [01:21<00:02, 43.70it/s, est. speed input: 50023.95 toks/s, output: 48.85 toks/s]
Processed prompts:  98%|█████████▊| 4017/4096 [01:22<00:01, 43.44it/s, est. speed input: 49968.14 toks/s, output: 48.80 toks/s]
Processed prompts:  99%|█████████▉| 4049/4096 [01:23<00:01, 43.72it/s, est. speed input: 49928.95 toks/s, output: 48.76 toks/s]
Processed prompts: 100%|█████████▉| 4081/4096 [01:23<00:00, 51.77it/s, est. speed input: 50110.73 toks/s, output: 48.94 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:23<00:00, 51.77it/s, est. speed input: 50294.51 toks/s, output: 49.12 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:23<00:00, 49.12it/s, est. speed input: 50294.51 toks/s, output: 49.12 toks/s]
[rank0]:[W126 11:21:41.684421952 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 11:21:43
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:22:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1279105) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1279105) WARNING 01-26 11:22:50 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     def forward(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     raise e
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/tmp/torchinductor_root/k3/ck3k5ang27fzki3pw5tmgzjzcez3bhliyianmu36s25pdmllr5et.py", line 1093, in call
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 339, in quant_slide_int8_triton
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) ERROR 01-26 11:22:59 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered

STDERR:
[2026-01-26 11:22:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:22:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:22:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:22:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:22:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:22:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:22:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:22:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:22:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:22:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:22:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:22:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:22:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:22:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:22:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:22:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:22:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1279105) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1279105) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=1279105) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.53it/s]
(EngineCore_DP0 pid=1279105) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.60it/s]
(EngineCore_DP0 pid=1279105) 
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 13824000 bytes
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10752000 bytes
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 113664000 bytes
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1279105) [2026-01-26 11:22:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56627200 bytes
(EngineCore_DP0 pid=1279105) [rank0]:W0126 11:22:56.483000 1279105 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1279105) [rank0]:W0126 11:22:56.561000 1279105 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1279105) [rank0]:W0126 11:22:58.225000 1279105 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1279105) [rank0]:W0126 11:22:58.347000 1279105 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1279105) Process EngineCore_DP0:
(EngineCore_DP0 pid=1279105) Traceback (most recent call last):
(EngineCore_DP0 pid=1279105)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1279105)     self.run()
(EngineCore_DP0 pid=1279105)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1279105)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1279105)     raise e
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1279105)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1279105)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1279105)     super().__init__(
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1279105)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1279105)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1279105)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1279105)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1279105)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1279105)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1279105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1279105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1279105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1279105)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1279105)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1279105)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1279105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1279105)     outputs = self.model(
(EngineCore_DP0 pid=1279105)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1279105)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1279105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1279105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1279105)     hidden_states = self.model(
(EngineCore_DP0 pid=1279105)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1279105)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1279105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1279105)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1279105)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1279105)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1279105)     def forward(
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1279105)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1279105)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1279105)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1279105)     raise e
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1279105)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1279105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1279105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1279105)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1279105)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1279105)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1279105)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1279105)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1279105)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1279105)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1279105)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1279105)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1279105)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1279105)                             ^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1279105)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1279105)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1279105)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1279105)     out = model(new_inputs)
(EngineCore_DP0 pid=1279105)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/tmp/torchinductor_root/k3/ck3k5ang27fzki3pw5tmgzjzcez3bhliyianmu36s25pdmllr5et.py", line 1093, in call
(EngineCore_DP0 pid=1279105)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=1279105)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1279105)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1279105)     return fn(input, L)
(EngineCore_DP0 pid=1279105)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 339, in quant_slide_int8_triton
(EngineCore_DP0 pid=1279105)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1279105)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1279105)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1279105)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1279105)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1279105)     self._init_handles()
(EngineCore_DP0 pid=1279105)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1279105)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1279105)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1279105) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 11:23:00.439351913 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 13:13:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:13:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1405359) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1405359) WARNING 01-26 13:14:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.42 requests/s, 11499.67 total tokens/s, 22.42 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 13:13:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:13:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:13:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:13:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:13:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:13:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:13:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:13:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:13:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:13:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:13:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:13:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:13:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:13:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:13:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:13:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:13:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1405359) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1405359) 
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1405359) [2026-01-26 13:13:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1405359) 2026-01-26 13:14:20,076 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1405359) 2026-01-26 13:14:20,143 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1405359) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]
(EngineCore_DP0 pid=1405359) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  27%|██▋       | 35/128 [00:00<00:00, 345.43it/s]
Adding requests:  79%|███████▉  | 101/128 [00:00<00:00, 524.86it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 529.01it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:25,  5.07it/s, est. speed input: 2594.61 toks/s, output: 5.07 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:08, 14.08it/s, est. speed input: 6359.84 toks/s, output: 12.42 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 18.15it/s, est. speed input: 8035.97 toks/s, output: 15.69 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 20.36it/s, est. speed input: 8983.48 toks/s, output: 17.54 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 21.66it/s, est. speed input: 9589.29 toks/s, output: 18.73 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 22.51it/s, est. speed input: 10016.23 toks/s, output: 19.56 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 23.05it/s, est. speed input: 10328.33 toks/s, output: 20.17 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 23.40it/s, est. speed input: 10566.23 toks/s, output: 20.64 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 23.66it/s, est. speed input: 10758.34 toks/s, output: 21.01 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 23.82it/s, est. speed input: 10911.21 toks/s, output: 21.31 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.95it/s, est. speed input: 11040.88 toks/s, output: 21.56 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:03, 24.04it/s, est. speed input: 11149.41 toks/s, output: 21.78 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 24.09it/s, est. speed input: 11240.62 toks/s, output: 21.95 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 24.11it/s, est. speed input: 11318.19 toks/s, output: 22.11 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 24.11it/s, est. speed input: 11384.08 toks/s, output: 22.23 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 24.14it/s, est. speed input: 11444.91 toks/s, output: 22.35 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 24.13it/s, est. speed input: 11496.39 toks/s, output: 22.45 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 24.15it/s, est. speed input: 11544.53 toks/s, output: 22.55 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 24.16it/s, est. speed input: 11587.05 toks/s, output: 22.63 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 24.16it/s, est. speed input: 11624.99 toks/s, output: 22.70 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 24.18it/s, est. speed input: 11661.44 toks/s, output: 22.78 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 24.17it/s, est. speed input: 11692.30 toks/s, output: 22.84 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:02<00:02, 24.18it/s, est. speed input: 11721.63 toks/s, output: 22.89 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 24.16it/s, est. speed input: 11747.27 toks/s, output: 22.94 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 24.19it/s, est. speed input: 11773.42 toks/s, output: 22.99 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 24.19it/s, est. speed input: 11796.69 toks/s, output: 23.04 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 24.21it/s, est. speed input: 11818.81 toks/s, output: 23.08 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 24.17it/s, est. speed input: 11836.89 toks/s, output: 23.12 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 24.16it/s, est. speed input: 11854.29 toks/s, output: 23.15 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 24.15it/s, est. speed input: 11870.92 toks/s, output: 23.19 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:03<00:01, 24.14it/s, est. speed input: 11885.83 toks/s, output: 23.21 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 24.16it/s, est. speed input: 11901.52 toks/s, output: 23.24 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 24.18it/s, est. speed input: 11916.23 toks/s, output: 23.27 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 24.18it/s, est. speed input: 11929.83 toks/s, output: 23.30 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 24.12it/s, est. speed input: 11939.76 toks/s, output: 23.32 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 24.14it/s, est. speed input: 11951.64 toks/s, output: 23.34 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 24.15it/s, est. speed input: 11963.12 toks/s, output: 23.37 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 24.15it/s, est. speed input: 11973.65 toks/s, output: 23.39 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:04<00:00, 24.18it/s, est. speed input: 11984.64 toks/s, output: 23.41 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 24.19it/s, est. speed input: 11994.76 toks/s, output: 23.43 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 23.89it/s, est. speed input: 11992.22 toks/s, output: 23.42 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.72it/s, est. speed input: 11990.91 toks/s, output: 23.42 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.59it/s, est. speed input: 11989.49 toks/s, output: 23.42 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.59it/s, est. speed input: 11989.12 toks/s, output: 23.42 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.42it/s, est. speed input: 11989.12 toks/s, output: 23.42 toks/s]
[rank0]:[W126 13:14:29.081379752 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 13:14:30
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:14:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1406636) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1406636) WARNING 01-26 13:14:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.63 requests/s, 19100.03 total tokens/s, 18.63 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 13:14:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:14:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:14:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:14:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:14:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:14:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:14:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:14:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:14:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:14:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:14:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:14:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:14:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:14:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:14:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:14:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:14:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.77it/s]
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.59it/s]
(EngineCore_DP0 pid=1406636) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1406636) 
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1406636) [2026-01-26 13:14:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1406636) 2026-01-26 13:15:13,514 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1406636) 2026-01-26 13:15:13,553 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1406636) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.86it/s]
(EngineCore_DP0 pid=1406636) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  15%|█▍        | 19/128 [00:00<00:00, 188.53it/s]
Adding requests:  45%|████▌     | 58/128 [00:00<00:00, 304.43it/s]
Adding requests:  74%|███████▍  | 95/128 [00:00<00:00, 332.38it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 325.75it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 21.74it/s, est. speed input: 22263.48 toks/s, output: 21.74 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 20.89it/s, est. speed input: 21519.53 toks/s, output: 21.01 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 20.64it/s, est. speed input: 21290.54 toks/s, output: 20.79 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:05, 20.30it/s, est. speed input: 21028.76 toks/s, output: 20.53 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:05, 20.14it/s, est. speed input: 20886.91 toks/s, output: 20.40 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 20.02it/s, est. speed input: 20778.52 toks/s, output: 20.29 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:05, 19.80it/s, est. speed input: 20636.11 toks/s, output: 20.15 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 19.78it/s, est. speed input: 20596.93 toks/s, output: 20.11 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 19.81it/s, est. speed input: 20578.89 toks/s, output: 20.10 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 19.78it/s, est. speed input: 20549.80 toks/s, output: 20.07 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 19.80it/s, est. speed input: 20532.44 toks/s, output: 20.05 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 19.78it/s, est. speed input: 20511.32 toks/s, output: 20.03 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:04, 19.77it/s, est. speed input: 20493.64 toks/s, output: 20.01 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:04, 19.79it/s, est. speed input: 20483.24 toks/s, output: 20.00 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:04, 19.74it/s, est. speed input: 20461.89 toks/s, output: 19.98 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:04, 19.69it/s, est. speed input: 20440.13 toks/s, output: 19.96 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:04, 19.67it/s, est. speed input: 20423.21 toks/s, output: 19.94 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 19.66it/s, est. speed input: 20407.54 toks/s, output: 19.93 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 19.68it/s, est. speed input: 20397.91 toks/s, output: 19.92 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 19.69it/s, est. speed input: 20389.83 toks/s, output: 19.91 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 19.73it/s, est. speed input: 20385.46 toks/s, output: 19.91 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:03, 19.76it/s, est. speed input: 20382.34 toks/s, output: 19.90 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 19.76it/s, est. speed input: 20377.02 toks/s, output: 19.90 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 19.78it/s, est. speed input: 20373.88 toks/s, output: 19.90 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 19.71it/s, est. speed input: 20361.65 toks/s, output: 19.88 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:03, 19.69it/s, est. speed input: 20352.64 toks/s, output: 19.88 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 19.69it/s, est. speed input: 20346.68 toks/s, output: 19.87 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 19.69it/s, est. speed input: 20340.23 toks/s, output: 19.86 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 19.68it/s, est. speed input: 20333.98 toks/s, output: 19.86 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 19.72it/s, est. speed input: 20332.78 toks/s, output: 19.86 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:02, 19.74it/s, est. speed input: 20330.78 toks/s, output: 19.85 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:02, 19.73it/s, est. speed input: 20326.79 toks/s, output: 19.85 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 19.74it/s, est. speed input: 20324.24 toks/s, output: 19.85 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 19.73it/s, est. speed input: 20320.00 toks/s, output: 19.84 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 19.70it/s, est. speed input: 20314.57 toks/s, output: 19.84 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 19.67it/s, est. speed input: 20307.75 toks/s, output: 19.83 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 19.63it/s, est. speed input: 20300.91 toks/s, output: 19.82 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 19.62it/s, est. speed input: 20295.27 toks/s, output: 19.82 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 19.61it/s, est. speed input: 20289.73 toks/s, output: 19.81 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 19.65it/s, est. speed input: 20288.05 toks/s, output: 19.81 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:01, 19.68it/s, est. speed input: 20286.56 toks/s, output: 19.81 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 19.70it/s, est. speed input: 20284.79 toks/s, output: 19.81 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 19.70it/s, est. speed input: 20282.84 toks/s, output: 19.81 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:01, 19.68it/s, est. speed input: 20279.13 toks/s, output: 19.80 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 19.68it/s, est. speed input: 20276.20 toks/s, output: 19.80 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 19.64it/s, est. speed input: 20271.28 toks/s, output: 19.80 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 19.66it/s, est. speed input: 20269.31 toks/s, output: 19.79 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 19.65it/s, est. speed input: 20265.96 toks/s, output: 19.79 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 19.65it/s, est. speed input: 20263.43 toks/s, output: 19.79 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 19.65it/s, est. speed input: 20260.67 toks/s, output: 19.79 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:00, 19.64it/s, est. speed input: 20257.70 toks/s, output: 19.78 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:00, 19.68it/s, est. speed input: 20257.56 toks/s, output: 19.78 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:05<00:00, 19.71it/s, est. speed input: 20257.22 toks/s, output: 19.78 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 19.73it/s, est. speed input: 20256.95 toks/s, output: 19.78 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 19.71it/s, est. speed input: 20254.84 toks/s, output: 19.78 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 19.68it/s, est. speed input: 20251.95 toks/s, output: 19.78 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 19.67it/s, est. speed input: 20249.81 toks/s, output: 19.78 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 19.64it/s, est. speed input: 20246.58 toks/s, output: 19.77 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 19.67it/s, est. speed input: 20246.05 toks/s, output: 19.77 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 19.69it/s, est. speed input: 20245.41 toks/s, output: 19.77 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.69it/s, est. speed input: 20245.14 toks/s, output: 19.77 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.77it/s, est. speed input: 20245.14 toks/s, output: 19.77 toks/s]
[rank0]:[W126 13:15:22.750152531 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 13:15:24
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:15:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1407899) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1407899) WARNING 01-26 13:15:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.18 requests/s, 21704.92 total tokens/s, 21.18 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 13:15:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:15:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:15:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:15:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:15:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:15:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:15:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:15:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:15:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:15:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:15:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:15:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:15:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:15:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:15:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:15:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:15:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1407899) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1407899) 
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1407899) [2026-01-26 13:15:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1407899) 2026-01-26 13:16:07,670 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1407899) 2026-01-26 13:16:07,711 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1407899) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.47it/s]
(EngineCore_DP0 pid=1407899) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.24it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   7%|▋         | 19/256 [00:00<00:01, 184.99it/s]
Adding requests:  23%|██▎       | 59/256 [00:00<00:00, 308.21it/s]
Adding requests:  38%|███▊      | 96/256 [00:00<00:00, 333.56it/s]
Adding requests:  52%|█████▏    | 134/256 [00:00<00:00, 347.84it/s]
Adding requests:  68%|██████▊   | 173/256 [00:00<00:00, 361.50it/s]
Adding requests:  83%|████████▎ | 212/256 [00:00<00:00, 370.00it/s]
Adding requests:  98%|█████████▊| 250/256 [00:00<00:00, 373.23it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 351.81it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:00<00:03, 77.32it/s, est. speed input: 79191.92 toks/s, output: 77.33 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:06, 34.74it/s, est. speed input: 39492.75 toks/s, output: 38.56 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:00<00:07, 32.09it/s, est. speed input: 36485.46 toks/s, output: 35.63 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:00<00:08, 28.26it/s, est. speed input: 33290.64 toks/s, output: 32.51 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:01<00:08, 26.06it/s, est. speed input: 31345.87 toks/s, output: 30.61 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:09, 23.08it/s, est. speed input: 29266.08 toks/s, output: 28.58 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:09, 22.73it/s, est. speed input: 28409.22 toks/s, output: 27.74 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:09, 22.48it/s, est. speed input: 27737.89 toks/s, output: 27.09 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:09, 22.12it/s, est. speed input: 27125.08 toks/s, output: 26.49 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:09, 21.85it/s, est. speed input: 26621.49 toks/s, output: 26.00 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:09, 21.84it/s, est. speed input: 26262.33 toks/s, output: 25.65 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:08, 21.87it/s, est. speed input: 25968.98 toks/s, output: 25.36 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:08, 21.89it/s, est. speed input: 25717.07 toks/s, output: 25.11 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:08, 21.79it/s, est. speed input: 25471.67 toks/s, output: 24.87 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:08, 21.65it/s, est. speed input: 25239.20 toks/s, output: 24.65 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:08, 21.62it/s, est. speed input: 25048.56 toks/s, output: 24.46 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:08, 21.67it/s, est. speed input: 24895.42 toks/s, output: 24.31 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:07, 21.75it/s, est. speed input: 24767.72 toks/s, output: 24.19 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:07, 21.71it/s, est. speed input: 24634.46 toks/s, output: 24.06 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:07, 21.64it/s, est. speed input: 24506.16 toks/s, output: 23.93 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:07, 21.59it/s, est. speed input: 24389.98 toks/s, output: 23.82 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:07, 21.61it/s, est. speed input: 24293.49 toks/s, output: 23.72 toks/s]
Processed prompts:  41%|████      | 104/256 [00:04<00:07, 21.68it/s, est. speed input: 24213.76 toks/s, output: 23.65 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:06, 21.73it/s, est. speed input: 24140.03 toks/s, output: 23.57 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:06, 21.69it/s, est. speed input: 24061.75 toks/s, output: 23.50 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:04<00:06, 21.62it/s, est. speed input: 23982.96 toks/s, output: 23.42 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:06, 21.59it/s, est. speed input: 23912.35 toks/s, output: 23.35 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:06, 21.62it/s, est. speed input: 23853.27 toks/s, output: 23.29 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:05<00:05, 21.68it/s, est. speed input: 23803.06 toks/s, output: 23.25 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:05, 21.69it/s, est. speed input: 23752.28 toks/s, output: 23.20 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:05<00:05, 21.64it/s, est. speed input: 23698.75 toks/s, output: 23.14 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:06<00:05, 21.61it/s, est. speed input: 23648.19 toks/s, output: 23.09 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:05, 21.61it/s, est. speed input: 23602.63 toks/s, output: 23.05 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:06<00:04, 21.63it/s, est. speed input: 23562.92 toks/s, output: 23.01 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:06<00:04, 21.64it/s, est. speed input: 23524.47 toks/s, output: 22.97 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:06<00:04, 21.63it/s, est. speed input: 23486.22 toks/s, output: 22.94 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:06<00:04, 21.59it/s, est. speed input: 23447.01 toks/s, output: 22.90 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:07<00:04, 21.54it/s, est. speed input: 23407.53 toks/s, output: 22.86 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:07<00:04, 21.58it/s, est. speed input: 23376.78 toks/s, output: 22.83 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:07<00:03, 21.63it/s, est. speed input: 23350.19 toks/s, output: 22.80 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:07<00:03, 21.64it/s, est. speed input: 23321.85 toks/s, output: 22.78 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:07<00:03, 21.61it/s, est. speed input: 23292.14 toks/s, output: 22.75 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:08<00:03, 21.60it/s, est. speed input: 23265.09 toks/s, output: 22.72 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:08<00:03, 21.62it/s, est. speed input: 23240.62 toks/s, output: 22.70 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:08<00:02, 21.65it/s, est. speed input: 23218.77 toks/s, output: 22.67 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:08<00:02, 21.62it/s, est. speed input: 23194.57 toks/s, output: 22.65 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:08<00:02, 21.61it/s, est. speed input: 23171.88 toks/s, output: 22.63 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:08<00:02, 22.88it/s, est. speed input: 23238.33 toks/s, output: 22.69 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:09<00:02, 22.50it/s, est. speed input: 23216.94 toks/s, output: 22.67 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:09<00:01, 22.24it/s, est. speed input: 23196.79 toks/s, output: 22.65 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:09<00:01, 22.02it/s, est. speed input: 23173.93 toks/s, output: 22.63 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:09<00:01, 21.86it/s, est. speed input: 23151.89 toks/s, output: 22.61 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:09<00:01, 21.75it/s, est. speed input: 23130.44 toks/s, output: 22.59 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:10<00:01, 21.70it/s, est. speed input: 23111.41 toks/s, output: 22.57 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:10<00:01, 21.69it/s, est. speed input: 23094.79 toks/s, output: 22.55 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:10<00:00, 21.62it/s, est. speed input: 23075.16 toks/s, output: 22.53 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:10<00:00, 21.59it/s, est. speed input: 23057.15 toks/s, output: 22.52 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:10<00:00, 21.59it/s, est. speed input: 23040.65 toks/s, output: 22.50 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:11<00:00, 21.56it/s, est. speed input: 23023.29 toks/s, output: 22.48 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:11<00:00, 21.56it/s, est. speed input: 23007.84 toks/s, output: 22.47 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 23.11it/s, est. speed input: 23076.55 toks/s, output: 22.54 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 23.11it/s, est. speed input: 23076.55 toks/s, output: 22.54 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.53it/s, est. speed input: 23076.55 toks/s, output: 22.54 toks/s]
[rank0]:[W126 13:16:22.252153294 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 13:16:24
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:16:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1409240) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1409240) WARNING 01-26 13:16:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.12 requests/s, 22669.29 total tokens/s, 22.12 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 13:16:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:16:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:16:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:16:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:16:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:16:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:16:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:16:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:16:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:16:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:16:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:16:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:16:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:16:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:16:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:16:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:16:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.45it/s]
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.57it/s]
(EngineCore_DP0 pid=1409240) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1409240) 
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1409240) [2026-01-26 13:16:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1409240) 2026-01-26 13:17:09,499 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1409240) 2026-01-26 13:17:09,549 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1409240) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  6.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  6.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  6.69it/s]
(EngineCore_DP0 pid=1409240) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.29it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  3.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.12it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▎         | 19/512 [00:00<00:02, 188.61it/s]
Adding requests:  12%|█▏        | 59/512 [00:00<00:01, 310.51it/s]
Adding requests:  19%|█▉        | 96/512 [00:00<00:01, 334.70it/s]
Adding requests:  26%|██▌       | 134/512 [00:00<00:01, 351.08it/s]
Adding requests:  34%|███▎      | 172/512 [00:00<00:00, 360.91it/s]
Adding requests:  41%|████▏     | 212/512 [00:00<00:00, 373.02it/s]
Adding requests:  49%|████▉     | 251/512 [00:00<00:00, 378.44it/s]
Adding requests:  57%|█████▋    | 290/512 [00:00<00:00, 380.31it/s]
Adding requests:  65%|██████▍   | 331/512 [00:00<00:00, 388.75it/s]
Adding requests:  73%|███████▎  | 372/512 [00:01<00:00, 394.50it/s]
Adding requests:  81%|████████  | 413/512 [00:01<00:00, 397.10it/s]
Adding requests:  88%|████████▊ | 453/512 [00:01<00:00, 396.72it/s]
Adding requests:  97%|█████████▋| 496/512 [00:01<00:00, 405.45it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 378.28it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:00<00:02, 179.34it/s, est. speed input: 183708.06 toks/s, output: 179.35 toks/s]
Processed prompts:   9%|▊         | 44/512 [00:00<00:10, 44.61it/s, est. speed input: 52701.75 toks/s, output: 51.47 toks/s]   
Processed prompts:  10%|█         | 53/512 [00:01<00:12, 36.86it/s, est. speed input: 44535.89 toks/s, output: 43.49 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:01<00:15, 29.88it/s, est. speed input: 38439.96 toks/s, output: 37.54 toks/s]
Processed prompts:  12%|█▎        | 64/512 [00:01<00:15, 29.51it/s, est. speed input: 37451.76 toks/s, output: 36.57 toks/s]
Processed prompts:  13%|█▎        | 68/512 [00:01<00:15, 27.83it/s, est. speed input: 36059.49 toks/s, output: 35.21 toks/s]
Processed prompts:  14%|█▍        | 72/512 [00:02<00:16, 26.36it/s, est. speed input: 34877.34 toks/s, output: 34.06 toks/s]
Processed prompts:  15%|█▍        | 75/512 [00:02<00:18, 23.90it/s, est. speed input: 33493.52 toks/s, output: 32.71 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:19, 22.05it/s, est. speed input: 32336.77 toks/s, output: 31.58 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:19, 22.22it/s, est. speed input: 31728.09 toks/s, output: 30.98 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:02<00:19, 22.23it/s, est. speed input: 31161.25 toks/s, output: 30.43 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:19, 22.17it/s, est. speed input: 30640.38 toks/s, output: 29.92 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:18, 22.23it/s, est. speed input: 30206.11 toks/s, output: 29.50 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:18, 22.32it/s, est. speed input: 29831.02 toks/s, output: 29.13 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:18, 22.39it/s, est. speed input: 29493.10 toks/s, output: 28.80 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:18, 22.40it/s, est. speed input: 29181.34 toks/s, output: 28.50 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:18, 22.32it/s, est. speed input: 28877.99 toks/s, output: 28.20 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:17, 22.27it/s, est. speed input: 28604.72 toks/s, output: 27.93 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:17, 22.28it/s, est. speed input: 28361.65 toks/s, output: 27.70 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:17, 22.34it/s, est. speed input: 28147.06 toks/s, output: 27.49 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:17, 22.33it/s, est. speed input: 27941.59 toks/s, output: 27.29 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:17, 22.31it/s, est. speed input: 27749.54 toks/s, output: 27.10 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:16, 22.29it/s, est. speed input: 27569.06 toks/s, output: 26.92 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:16, 22.25it/s, est. speed input: 27397.88 toks/s, output: 26.76 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:16, 22.31it/s, est. speed input: 27251.13 toks/s, output: 26.61 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:16, 22.34it/s, est. speed input: 27111.63 toks/s, output: 26.48 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:16, 22.34it/s, est. speed input: 26978.06 toks/s, output: 26.35 toks/s]
Processed prompts:  30%|███       | 154/512 [00:05<00:16, 22.33it/s, est. speed input: 26852.03 toks/s, output: 26.22 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:15, 22.27it/s, est. speed input: 26727.08 toks/s, output: 26.10 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:15, 22.22it/s, est. speed input: 26608.17 toks/s, output: 25.98 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:15, 22.29it/s, est. speed input: 26507.91 toks/s, output: 25.89 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:15, 22.33it/s, est. speed input: 26411.39 toks/s, output: 25.79 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:06<00:15, 22.35it/s, est. speed input: 26320.39 toks/s, output: 25.70 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:06<00:14, 22.29it/s, est. speed input: 26225.23 toks/s, output: 25.61 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:14, 22.26it/s, est. speed input: 26137.25 toks/s, output: 25.52 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:07<00:14, 22.25it/s, est. speed input: 26053.73 toks/s, output: 25.44 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:14, 22.28it/s, est. speed input: 25978.56 toks/s, output: 25.37 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:07<00:14, 22.34it/s, est. speed input: 25909.76 toks/s, output: 25.30 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:07<00:14, 22.33it/s, est. speed input: 25839.67 toks/s, output: 25.23 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:07<00:13, 23.66it/s, est. speed input: 25881.30 toks/s, output: 25.27 toks/s]
Processed prompts:  40%|████      | 206/512 [00:08<00:13, 23.24it/s, est. speed input: 25814.85 toks/s, output: 25.21 toks/s]
Processed prompts:  41%|████      | 210/512 [00:08<00:13, 22.91it/s, est. speed input: 25747.98 toks/s, output: 25.14 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:13, 22.76it/s, est. speed input: 25689.37 toks/s, output: 25.09 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:08<00:13, 22.60it/s, est. speed input: 25628.77 toks/s, output: 25.03 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:08<00:12, 22.45it/s, est. speed input: 25568.35 toks/s, output: 24.97 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:09<00:12, 22.37it/s, est. speed input: 25511.33 toks/s, output: 24.91 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:09<00:12, 22.32it/s, est. speed input: 25457.75 toks/s, output: 24.86 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:12, 22.33it/s, est. speed input: 25408.78 toks/s, output: 24.81 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:09<00:12, 22.30it/s, est. speed input: 25359.25 toks/s, output: 24.76 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:09<00:12, 22.31it/s, est. speed input: 25313.42 toks/s, output: 24.72 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:09<00:11, 22.30it/s, est. speed input: 25268.47 toks/s, output: 24.68 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:10<00:11, 22.30it/s, est. speed input: 25225.70 toks/s, output: 24.63 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:10<00:11, 22.32it/s, est. speed input: 25185.52 toks/s, output: 24.60 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:10<00:11, 22.33it/s, est. speed input: 25146.05 toks/s, output: 24.56 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:10<00:11, 22.31it/s, est. speed input: 25106.89 toks/s, output: 24.52 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:10<00:11, 22.28it/s, est. speed input: 25067.62 toks/s, output: 24.48 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:11<00:10, 22.28it/s, est. speed input: 25031.12 toks/s, output: 24.44 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:11<00:10, 22.26it/s, est. speed input: 24994.12 toks/s, output: 24.41 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:11<00:10, 22.29it/s, est. speed input: 24961.59 toks/s, output: 24.38 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:11<00:10, 22.27it/s, est. speed input: 24927.43 toks/s, output: 24.34 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:11<00:10, 22.24it/s, est. speed input: 24893.25 toks/s, output: 24.31 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:11<00:09, 22.24it/s, est. speed input: 24861.53 toks/s, output: 24.28 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:12<00:09, 22.22it/s, est. speed input: 24829.23 toks/s, output: 24.25 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:12<00:09, 22.29it/s, est. speed input: 24802.54 toks/s, output: 24.22 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:12<00:09, 22.30it/s, est. speed input: 24774.65 toks/s, output: 24.19 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:12<00:09, 22.28it/s, est. speed input: 24746.44 toks/s, output: 24.17 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:12<00:09, 22.27it/s, est. speed input: 24719.05 toks/s, output: 24.14 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:13<00:08, 22.23it/s, est. speed input: 24690.18 toks/s, output: 24.11 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:13<00:08, 22.25it/s, est. speed input: 24664.98 toks/s, output: 24.09 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:13<00:08, 22.29it/s, est. speed input: 24641.71 toks/s, output: 24.06 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:13<00:08, 22.28it/s, est. speed input: 24617.19 toks/s, output: 24.04 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:13<00:08, 22.25it/s, est. speed input: 24592.41 toks/s, output: 24.02 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:13<00:08, 22.20it/s, est. speed input: 24566.29 toks/s, output: 23.99 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:14<00:07, 22.21it/s, est. speed input: 24543.46 toks/s, output: 23.97 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:14<00:07, 22.24it/s, est. speed input: 24522.28 toks/s, output: 23.95 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:14<00:07, 22.27it/s, est. speed input: 24501.96 toks/s, output: 23.93 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:14<00:07, 22.27it/s, est. speed input: 24481.21 toks/s, output: 23.91 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:14<00:07, 22.24it/s, est. speed input: 24459.36 toks/s, output: 23.89 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:15<00:06, 22.22it/s, est. speed input: 24438.38 toks/s, output: 23.87 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:15<00:06, 22.23it/s, est. speed input: 24419.00 toks/s, output: 23.85 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:15<00:06, 22.22it/s, est. speed input: 24399.23 toks/s, output: 23.83 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:15<00:06, 22.21it/s, est. speed input: 24379.75 toks/s, output: 23.81 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:15<00:06, 22.19it/s, est. speed input: 24359.85 toks/s, output: 23.79 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:15<00:06, 22.22it/s, est. speed input: 24342.53 toks/s, output: 23.77 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:16<00:05, 22.24it/s, est. speed input: 24325.68 toks/s, output: 23.76 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:16<00:05, 22.24it/s, est. speed input: 24308.61 toks/s, output: 23.74 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:16<00:05, 22.24it/s, est. speed input: 24291.90 toks/s, output: 23.72 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:16<00:05, 22.20it/s, est. speed input: 24273.63 toks/s, output: 23.70 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:16<00:05, 22.16it/s, est. speed input: 24255.52 toks/s, output: 23.69 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:16<00:04, 22.20it/s, est. speed input: 24240.44 toks/s, output: 23.67 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:17<00:04, 22.18it/s, est. speed input: 24224.07 toks/s, output: 23.66 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:17<00:04, 22.18it/s, est. speed input: 24208.07 toks/s, output: 23.64 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:17<00:04, 22.18it/s, est. speed input: 24192.79 toks/s, output: 23.63 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:17<00:04, 22.17it/s, est. speed input: 24177.43 toks/s, output: 23.61 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:17<00:04, 22.17it/s, est. speed input: 24162.47 toks/s, output: 23.60 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:18<00:03, 22.14it/s, est. speed input: 24146.86 toks/s, output: 23.58 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:18<00:03, 22.18it/s, est. speed input: 24133.51 toks/s, output: 23.57 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:18<00:03, 22.22it/s, est. speed input: 24121.26 toks/s, output: 23.56 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:18<00:03, 22.24it/s, est. speed input: 24108.56 toks/s, output: 23.54 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:18<00:03, 22.30it/s, est. speed input: 24097.92 toks/s, output: 23.53 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:18<00:02, 22.29it/s, est. speed input: 24085.76 toks/s, output: 23.52 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:19<00:02, 22.30it/s, est. speed input: 24074.15 toks/s, output: 23.51 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:19<00:02, 22.30it/s, est. speed input: 24062.64 toks/s, output: 23.50 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:19<00:02, 22.31it/s, est. speed input: 24051.80 toks/s, output: 23.49 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:19<00:02, 22.33it/s, est. speed input: 24041.28 toks/s, output: 23.48 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:19<00:02, 22.32it/s, est. speed input: 24030.43 toks/s, output: 23.47 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:20<00:01, 22.28it/s, est. speed input: 24018.55 toks/s, output: 23.46 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:20<00:01, 22.27it/s, est. speed input: 24007.67 toks/s, output: 23.44 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:20<00:01, 22.26it/s, est. speed input: 23996.82 toks/s, output: 23.43 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:20<00:01, 22.27it/s, est. speed input: 23986.68 toks/s, output: 23.42 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:20<00:01, 22.25it/s, est. speed input: 23975.67 toks/s, output: 23.41 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:20<00:00, 22.24it/s, est. speed input: 23965.22 toks/s, output: 23.40 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:21<00:00, 22.24it/s, est. speed input: 23955.11 toks/s, output: 23.39 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:21<00:00, 22.25it/s, est. speed input: 23945.31 toks/s, output: 23.38 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:21<00:00, 22.28it/s, est. speed input: 23936.66 toks/s, output: 23.38 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:21<00:00, 22.27it/s, est. speed input: 23926.95 toks/s, output: 23.37 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:21<00:00, 23.88it/s, est. speed input: 23961.94 toks/s, output: 23.40 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 23.88it/s, est. speed input: 24055.59 toks/s, output: 23.49 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:21<00:00, 23.49it/s, est. speed input: 24055.59 toks/s, output: 23.49 toks/s]
[rank0]:[W126 13:17:35.980721369 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 13:17:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:17:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1410752) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1410752) WARNING 01-26 13:18:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.77 requests/s, 23340.23 total tokens/s, 22.77 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 13:17:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:17:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:17:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:17:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:17:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:17:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:17:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:17:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:17:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:17:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:17:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:17:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:17:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:17:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:17:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:17:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:17:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1410752) [2026-01-26 13:17:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.45it/s]
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1410752) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1410752) 
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1410752) [2026-01-26 13:18:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1410752) 2026-01-26 13:18:26,202 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1410752) 2026-01-26 13:18:26,303 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1410752) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  4.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.17it/s]
(EngineCore_DP0 pid=1410752) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  6.86it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  7.65it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.22it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 219.82it/s]
Adding requests:   6%|▌         | 63/1024 [00:00<00:02, 328.88it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:02, 340.59it/s]
Adding requests:  13%|█▎        | 137/1024 [00:00<00:02, 353.86it/s]
Adding requests:  17%|█▋        | 176/1024 [00:00<00:02, 365.99it/s]
Adding requests:  21%|██        | 217/1024 [00:00<00:02, 378.58it/s]
Adding requests:  25%|██▍       | 255/1024 [00:00<00:02, 378.34it/s]
Adding requests:  29%|██▉       | 295/1024 [00:00<00:01, 382.34it/s]
Adding requests:  33%|███▎      | 336/1024 [00:00<00:01, 390.47it/s]
Adding requests:  37%|███▋      | 376/1024 [00:01<00:01, 392.38it/s]
Adding requests:  41%|████      | 418/1024 [00:01<00:01, 398.69it/s]
Adding requests:  45%|████▍     | 458/1024 [00:01<00:01, 393.62it/s]
Adding requests:  49%|████▉     | 500/1024 [00:01<00:01, 400.75it/s]
Adding requests:  53%|█████▎    | 541/1024 [00:01<00:01, 400.68it/s]
Adding requests:  57%|█████▋    | 582/1024 [00:01<00:01, 396.18it/s]
Adding requests:  61%|██████    | 622/1024 [00:01<00:01, 390.02it/s]
Adding requests:  65%|██████▍   | 662/1024 [00:01<00:00, 382.80it/s]
Adding requests:  69%|██████▊   | 702/1024 [00:01<00:00, 385.40it/s]
Adding requests:  72%|███████▏  | 741/1024 [00:01<00:00, 381.52it/s]
Adding requests:  76%|███████▌  | 780/1024 [00:02<00:00, 381.89it/s]
Adding requests:  80%|███████▉  | 819/1024 [00:02<00:00, 381.52it/s]
Adding requests:  84%|████████▍ | 860/1024 [00:02<00:00, 387.31it/s]
Adding requests:  88%|████████▊ | 900/1024 [00:02<00:00, 389.69it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:02<00:00, 384.11it/s]
Adding requests:  96%|█████████▌| 978/1024 [00:02<00:00, 385.01it/s]
Adding requests:  99%|█████████▉| 1017/1024 [00:02<00:00, 380.35it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 381.16it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:00<00:03, 281.68it/s, est. speed input: 288468.81 toks/s, output: 281.69 toks/s]
Processed prompts:   8%|▊         | 87/1024 [00:01<00:16, 58.18it/s, est. speed input: 70815.14 toks/s, output: 69.16 toks/s]   
Processed prompts:  10%|▉         | 101/1024 [00:01<00:22, 40.73it/s, est. speed input: 52754.11 toks/s, output: 51.52 toks/s]
Processed prompts:  11%|█         | 110/1024 [00:02<00:24, 37.12it/s, est. speed input: 48808.34 toks/s, output: 47.66 toks/s]
Processed prompts:  11%|█▏        | 116/1024 [00:02<00:28, 31.82it/s, est. speed input: 44611.09 toks/s, output: 43.56 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:03<00:32, 27.93it/s, est. speed input: 41512.89 toks/s, output: 40.54 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:33, 26.50it/s, est. speed input: 39621.66 toks/s, output: 38.69 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:03<00:34, 25.40it/s, est. speed input: 38059.05 toks/s, output: 37.17 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:04<00:35, 24.72it/s, est. speed input: 36820.92 toks/s, output: 35.96 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:36, 24.15it/s, est. speed input: 35743.96 toks/s, output: 34.91 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:04<00:36, 23.69it/s, est. speed input: 34808.14 toks/s, output: 33.99 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:05<00:36, 23.49it/s, est. speed input: 34044.56 toks/s, output: 33.25 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:36, 23.30it/s, est. speed input: 33362.85 toks/s, output: 32.58 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:05<00:36, 23.15it/s, est. speed input: 32756.58 toks/s, output: 31.99 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:06<00:35, 23.10it/s, est. speed input: 32236.32 toks/s, output: 31.48 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:34, 23.69it/s, est. speed input: 31922.77 toks/s, output: 31.17 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:06<00:34, 23.39it/s, est. speed input: 31475.73 toks/s, output: 30.74 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:34, 23.24it/s, est. speed input: 31085.77 toks/s, output: 30.36 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:34, 23.11it/s, est. speed input: 30726.14 toks/s, output: 30.01 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:07<00:34, 23.03it/s, est. speed input: 30400.27 toks/s, output: 29.69 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:34, 22.95it/s, est. speed input: 30097.22 toks/s, output: 29.39 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:08<00:33, 22.88it/s, est. speed input: 29817.45 toks/s, output: 29.12 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:08<00:33, 22.86it/s, est. speed input: 29563.12 toks/s, output: 28.87 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:33, 22.84it/s, est. speed input: 29328.49 toks/s, output: 28.64 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:09<00:32, 22.79it/s, est. speed input: 29105.31 toks/s, output: 28.42 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:09<00:32, 22.82it/s, est. speed input: 28907.34 toks/s, output: 28.23 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:10<00:32, 22.81it/s, est. speed input: 28717.96 toks/s, output: 28.04 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:10<00:31, 22.79it/s, est. speed input: 28539.21 toks/s, output: 27.87 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:31, 22.79it/s, est. speed input: 28374.31 toks/s, output: 27.71 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:11<00:31, 22.80it/s, est. speed input: 28219.95 toks/s, output: 27.56 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:11<00:30, 22.77it/s, est. speed input: 28070.27 toks/s, output: 27.41 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:30, 22.73it/s, est. speed input: 27927.90 toks/s, output: 27.27 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:12<00:30, 22.78it/s, est. speed input: 27801.86 toks/s, output: 27.15 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:12<00:29, 22.75it/s, est. speed input: 27675.57 toks/s, output: 27.03 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:13<00:29, 22.80it/s, est. speed input: 27563.84 toks/s, output: 26.92 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:13<00:29, 22.80it/s, est. speed input: 27454.10 toks/s, output: 26.81 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:13<00:28, 22.72it/s, est. speed input: 27342.32 toks/s, output: 26.70 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:14<00:28, 22.78it/s, est. speed input: 27247.00 toks/s, output: 26.61 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:14<00:28, 22.75it/s, est. speed input: 27149.85 toks/s, output: 26.51 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:14<00:27, 22.68it/s, est. speed input: 27051.83 toks/s, output: 26.42 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:15<00:27, 22.73it/s, est. speed input: 26968.27 toks/s, output: 26.34 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:15<00:26, 22.78it/s, est. speed input: 26889.13 toks/s, output: 26.26 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:15<00:26, 22.75it/s, est. speed input: 26808.31 toks/s, output: 26.18 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:16<00:26, 22.81it/s, est. speed input: 26737.75 toks/s, output: 26.11 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:16<00:25, 22.81it/s, est. speed input: 26666.75 toks/s, output: 26.04 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:17<00:25, 22.79it/s, est. speed input: 26596.96 toks/s, output: 25.97 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:17<00:25, 22.84it/s, est. speed input: 26534.86 toks/s, output: 25.91 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:17<00:24, 22.80it/s, est. speed input: 26469.54 toks/s, output: 25.85 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:18<00:24, 22.78it/s, est. speed input: 26407.16 toks/s, output: 25.79 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:18<00:24, 22.83it/s, est. speed input: 26351.97 toks/s, output: 25.73 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:18<00:23, 22.81it/s, est. speed input: 26294.91 toks/s, output: 25.68 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:19<00:23, 22.80it/s, est. speed input: 26240.69 toks/s, output: 25.63 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:19<00:23, 22.86it/s, est. speed input: 26192.29 toks/s, output: 25.58 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:19<00:22, 22.83it/s, est. speed input: 26141.21 toks/s, output: 25.53 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:20<00:22, 22.85it/s, est. speed input: 26094.93 toks/s, output: 25.48 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:20<00:21, 22.86it/s, est. speed input: 26049.63 toks/s, output: 25.44 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:20<00:21, 22.83it/s, est. speed input: 26003.39 toks/s, output: 25.39 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:21<00:21, 22.81it/s, est. speed input: 25958.84 toks/s, output: 25.35 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:21<00:20, 22.84it/s, est. speed input: 25918.35 toks/s, output: 25.31 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:21<00:20, 22.80it/s, est. speed input: 25875.69 toks/s, output: 25.27 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:22<00:20, 22.83it/s, est. speed input: 25837.58 toks/s, output: 25.23 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:22<00:19, 22.84it/s, est. speed input: 25799.84 toks/s, output: 25.20 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:22<00:19, 22.78it/s, est. speed input: 25759.75 toks/s, output: 25.16 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:23<00:19, 22.81it/s, est. speed input: 25724.51 toks/s, output: 25.12 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:23<00:18, 22.78it/s, est. speed input: 25687.85 toks/s, output: 25.09 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:24<00:18, 22.76it/s, est. speed input: 25652.15 toks/s, output: 25.05 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:24<00:18, 22.77it/s, est. speed input: 25619.10 toks/s, output: 25.02 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:24<00:17, 22.82it/s, est. speed input: 25588.88 toks/s, output: 24.99 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:25<00:17, 22.78it/s, est. speed input: 25555.88 toks/s, output: 24.96 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:25<00:17, 22.76it/s, est. speed input: 25524.25 toks/s, output: 24.93 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:25<00:16, 22.77it/s, est. speed input: 25494.19 toks/s, output: 24.90 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:26<00:16, 22.72it/s, est. speed input: 25462.59 toks/s, output: 24.87 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:26<00:16, 22.75it/s, est. speed input: 25434.72 toks/s, output: 24.84 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:26<00:15, 22.75it/s, est. speed input: 25407.00 toks/s, output: 24.81 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:27<00:15, 22.75it/s, est. speed input: 25379.49 toks/s, output: 24.78 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:27<00:15, 22.78it/s, est. speed input: 25354.30 toks/s, output: 24.76 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:27<00:14, 22.75it/s, est. speed input: 25327.47 toks/s, output: 24.73 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:28<00:14, 22.72it/s, est. speed input: 25300.65 toks/s, output: 24.71 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:28<00:13, 22.73it/s, est. speed input: 25276.10 toks/s, output: 24.68 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:28<00:13, 22.72it/s, est. speed input: 25251.52 toks/s, output: 24.66 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:29<00:13, 22.73it/s, est. speed input: 25227.98 toks/s, output: 24.64 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:29<00:12, 22.73it/s, est. speed input: 25204.91 toks/s, output: 24.61 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:30<00:12, 22.72it/s, est. speed input: 25181.80 toks/s, output: 24.59 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:30<00:12, 22.73it/s, est. speed input: 25159.98 toks/s, output: 24.57 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:30<00:11, 22.74it/s, est. speed input: 25138.65 toks/s, output: 24.55 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:31<00:11, 22.68it/s, est. speed input: 25115.17 toks/s, output: 24.53 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:31<00:11, 22.71it/s, est. speed input: 25095.25 toks/s, output: 24.51 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:31<00:10, 22.72it/s, est. speed input: 25075.09 toks/s, output: 24.49 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:32<00:10, 23.40it/s, est. speed input: 25082.10 toks/s, output: 24.49 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:32<00:09, 23.18it/s, est. speed input: 25061.81 toks/s, output: 24.47 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:32<00:09, 23.03it/s, est. speed input: 25042.34 toks/s, output: 24.46 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:33<00:09, 22.93it/s, est. speed input: 25023.11 toks/s, output: 24.44 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:33<00:08, 22.90it/s, est. speed input: 25005.80 toks/s, output: 24.42 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:33<00:08, 22.84it/s, est. speed input: 24987.63 toks/s, output: 24.40 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:34<00:08, 22.79it/s, est. speed input: 24969.50 toks/s, output: 24.38 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:34<00:07, 22.78it/s, est. speed input: 24952.46 toks/s, output: 24.37 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:34<00:07, 22.73it/s, est. speed input: 24934.18 toks/s, output: 24.35 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:35<00:07, 22.69it/s, est. speed input: 24916.30 toks/s, output: 24.33 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:35<00:06, 22.69it/s, est. speed input: 24899.64 toks/s, output: 24.32 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:35<00:06, 22.67it/s, est. speed input: 24882.64 toks/s, output: 24.30 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:36<00:06, 22.63it/s, est. speed input: 24864.91 toks/s, output: 24.28 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:36<00:05, 22.65it/s, est. speed input: 24849.48 toks/s, output: 24.27 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:37<00:05, 22.69it/s, est. speed input: 24835.02 toks/s, output: 24.25 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:37<00:05, 22.66it/s, est. speed input: 24819.02 toks/s, output: 24.24 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:37<00:04, 22.66it/s, est. speed input: 24803.77 toks/s, output: 24.22 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:38<00:04, 22.68it/s, est. speed input: 24789.46 toks/s, output: 24.21 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:38<00:04, 22.62it/s, est. speed input: 24773.32 toks/s, output: 24.19 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:38<00:03, 22.66it/s, est. speed input: 24759.95 toks/s, output: 24.18 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:39<00:03, 22.65it/s, est. speed input: 24745.55 toks/s, output: 24.17 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:39<00:03, 22.61it/s, est. speed input: 24730.45 toks/s, output: 24.15 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:39<00:02, 22.64it/s, est. speed input: 24717.35 toks/s, output: 24.14 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:40<00:02, 22.63it/s, est. speed input: 24703.54 toks/s, output: 24.12 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:40<00:02, 22.61it/s, est. speed input: 24689.55 toks/s, output: 24.11 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:40<00:01, 22.62it/s, est. speed input: 24676.49 toks/s, output: 24.10 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:41<00:01, 22.66it/s, est. speed input: 24664.88 toks/s, output: 24.09 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:41<00:00, 22.63it/s, est. speed input: 24651.62 toks/s, output: 24.07 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:41<00:00, 22.67it/s, est. speed input: 24640.25 toks/s, output: 24.06 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:42<00:00, 23.59it/s, est. speed input: 24655.16 toks/s, output: 24.08 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:42<00:00, 23.59it/s, est. speed input: 24800.23 toks/s, output: 24.22 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:42<00:00, 24.22it/s, est. speed input: 24800.23 toks/s, output: 24.22 toks/s]
[rank0]:[W126 13:19:14.927050138 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 13:19:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:19:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1412627) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1412627) WARNING 01-26 13:19:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.05 requests/s, 23628.50 total tokens/s, 23.05 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 13:19:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:19:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:19:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:19:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:19:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:19:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:19:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:19:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:19:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:19:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:19:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:19:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:19:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:19:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:19:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:19:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:19:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1412627) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1412627) 
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1412627) [2026-01-26 13:19:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1412627) [rank0]:W0126 13:20:05.866000 1412627 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1412627) [rank0]:W0126 13:20:05.919000 1412627 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1412627) [rank0]:W0126 13:20:06.670000 1412627 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1412627) [rank0]:W0126 13:20:06.753000 1412627 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1412627) 2026-01-26 13:20:11,391 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1412627) 2026-01-26 13:20:11,612 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1412627) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:04,  1.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  4.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  6.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.95it/s]
(EngineCore_DP0 pid=1412627) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  4.89it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  6.50it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  6.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.05it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.68it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/2048 [00:00<00:08, 236.71it/s]
Adding requests:   3%|▎         | 64/2048 [00:00<00:06, 329.84it/s]
Adding requests:   5%|▍         | 100/2048 [00:00<00:05, 342.02it/s]
Adding requests:   7%|▋         | 138/2048 [00:00<00:05, 355.46it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:05, 367.46it/s]
Adding requests:  11%|█         | 218/2048 [00:00<00:04, 381.24it/s]
Adding requests:  13%|█▎        | 257/2048 [00:00<00:04, 379.00it/s]
Adding requests:  15%|█▍        | 297/2048 [00:00<00:04, 384.97it/s]
Adding requests:  17%|█▋        | 338/2048 [00:00<00:04, 389.77it/s]
Adding requests:  18%|█▊        | 378/2048 [00:01<00:04, 391.93it/s]
Adding requests:  21%|██        | 420/2048 [00:01<00:04, 400.38it/s]
Adding requests:  23%|██▎       | 461/2048 [00:01<00:04, 395.13it/s]
Adding requests:  25%|██▍       | 504/2048 [00:01<00:03, 403.20it/s]
Adding requests:  27%|██▋       | 546/2048 [00:01<00:03, 407.96it/s]
Adding requests:  29%|██▊       | 587/2048 [00:01<00:03, 402.38it/s]
Adding requests:  31%|███       | 628/2048 [00:01<00:03, 397.56it/s]
Adding requests:  33%|███▎      | 668/2048 [00:01<00:03, 386.81it/s]
Adding requests:  35%|███▍      | 709/2048 [00:01<00:03, 391.81it/s]
Adding requests:  37%|███▋      | 749/2048 [00:01<00:03, 384.04it/s]
Adding requests:  38%|███▊      | 788/2048 [00:02<00:03, 377.82it/s]
Adding requests:  40%|████      | 827/2048 [00:02<00:03, 379.70it/s]
Adding requests:  42%|████▏     | 866/2048 [00:02<00:03, 381.78it/s]
Adding requests:  44%|████▍     | 907/2048 [00:02<00:02, 385.99it/s]
Adding requests:  46%|████▌     | 946/2048 [00:02<00:02, 376.94it/s]
Adding requests:  48%|████▊     | 985/2048 [00:02<00:02, 378.49it/s]
Adding requests:  50%|████▉     | 1023/2048 [00:02<00:02, 375.28it/s]
Adding requests:  52%|█████▏    | 1061/2048 [00:02<00:02, 371.92it/s]
Adding requests:  54%|█████▎    | 1099/2048 [00:02<00:02, 371.66it/s]
Adding requests:  56%|█████▌    | 1139/2048 [00:02<00:02, 379.30it/s]
Adding requests:  57%|█████▋    | 1177/2048 [00:03<00:02, 375.05it/s]
Adding requests:  59%|█████▉    | 1217/2048 [00:03<00:02, 381.12it/s]
Adding requests:  61%|██████▏   | 1256/2048 [00:03<00:02, 379.17it/s]
Adding requests:  63%|██████▎   | 1294/2048 [00:03<00:02, 373.64it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:03<00:01, 375.52it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:03<00:01, 383.59it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:03<00:01, 382.09it/s]
Adding requests:  71%|███████   | 1452/2048 [00:03<00:01, 383.92it/s]
Adding requests:  73%|███████▎  | 1493/2048 [00:03<00:01, 391.45it/s]
Adding requests:  75%|███████▍  | 1533/2048 [00:04<00:01, 388.65it/s]
Adding requests:  77%|███████▋  | 1572/2048 [00:04<00:01, 382.16it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:04<00:01, 383.99it/s]
Adding requests:  81%|████████  | 1650/2048 [00:04<00:01, 374.69it/s]
Adding requests:  82%|████████▏ | 1688/2048 [00:04<00:00, 372.24it/s]
Adding requests:  84%|████████▍ | 1728/2048 [00:04<00:00, 378.99it/s]
Adding requests:  86%|████████▋ | 1769/2048 [00:04<00:00, 386.76it/s]
Adding requests:  88%|████████▊ | 1808/2048 [00:04<00:00, 380.82it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:04<00:00, 383.26it/s]
Adding requests:  92%|█████████▏| 1888/2048 [00:04<00:00, 387.21it/s]
Adding requests:  94%|█████████▍| 1927/2048 [00:05<00:00, 381.78it/s]
Adding requests:  96%|█████████▌| 1966/2048 [00:05<00:00, 381.67it/s]
Adding requests:  98%|█████████▊| 2005/2048 [00:05<00:00, 380.69it/s]
Adding requests: 100%|█████████▉| 2044/2048 [00:05<00:00, 377.12it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 380.93it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:00<00:07, 261.16it/s, est. speed input: 267442.37 toks/s, output: 261.16 toks/s]
Processed prompts:   7%|▋         | 141/2048 [00:01<00:17, 107.59it/s, est. speed input: 128502.91 toks/s, output: 125.49 toks/s]
Processed prompts:   8%|▊         | 155/2048 [00:01<00:29, 64.32it/s, est. speed input: 87749.25 toks/s, output: 85.69 toks/s]   
Processed prompts:   8%|▊         | 164/2048 [00:02<00:43, 43.00it/s, est. speed input: 67251.99 toks/s, output: 65.68 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:03<00:54, 34.57it/s, est. speed input: 57241.77 toks/s, output: 55.90 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:03<00:59, 31.23it/s, est. speed input: 51801.94 toks/s, output: 50.59 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:04<01:04, 28.54it/s, est. speed input: 47534.62 toks/s, output: 46.42 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:05<01:07, 26.80it/s, est. speed input: 44390.31 toks/s, output: 43.35 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:05<01:10, 25.69it/s, est. speed input: 41993.53 toks/s, output: 41.01 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:06<01:11, 24.89it/s, est. speed input: 40075.89 toks/s, output: 39.14 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:07<01:12, 24.37it/s, est. speed input: 38531.46 toks/s, output: 37.63 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:07<01:13, 24.02it/s, est. speed input: 37253.11 toks/s, output: 36.38 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:08<01:13, 23.78it/s, est. speed input: 36184.32 toks/s, output: 35.34 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:09<01:13, 23.63it/s, est. speed input: 35276.25 toks/s, output: 34.45 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:10<01:12, 23.53it/s, est. speed input: 34494.66 toks/s, output: 33.69 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:10<01:12, 23.44it/s, est. speed input: 33808.59 toks/s, output: 33.02 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:11<01:11, 23.40it/s, est. speed input: 33210.40 toks/s, output: 32.43 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:12<01:11, 23.37it/s, est. speed input: 32679.80 toks/s, output: 31.91 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:12<01:10, 23.36it/s, est. speed input: 32208.66 toks/s, output: 31.45 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:13<01:09, 23.33it/s, est. speed input: 31780.02 toks/s, output: 31.04 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:14<01:09, 23.31it/s, est. speed input: 31392.80 toks/s, output: 30.66 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:14<01:08, 23.31it/s, est. speed input: 31045.15 toks/s, output: 30.32 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:15<01:07, 23.30it/s, est. speed input: 30725.51 toks/s, output: 30.01 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:16<01:07, 23.28it/s, est. speed input: 30431.46 toks/s, output: 29.72 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:16<01:06, 23.27it/s, est. speed input: 30161.14 toks/s, output: 29.45 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:17<01:05, 23.28it/s, est. speed input: 29915.47 toks/s, output: 29.21 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:18<01:05, 23.26it/s, est. speed input: 29684.40 toks/s, output: 28.99 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:18<01:04, 23.25it/s, est. speed input: 29470.01 toks/s, output: 28.78 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:19<01:03, 23.24it/s, est. speed input: 29270.86 toks/s, output: 28.58 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:20<01:03, 23.23it/s, est. speed input: 29083.65 toks/s, output: 28.40 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:21<01:02, 23.21it/s, est. speed input: 28907.88 toks/s, output: 28.23 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:21<01:01, 23.22it/s, est. speed input: 28746.13 toks/s, output: 28.07 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:22<01:01, 23.23it/s, est. speed input: 28594.03 toks/s, output: 27.92 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:23<01:00, 23.20it/s, est. speed input: 28447.66 toks/s, output: 27.78 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:23<00:59, 23.20it/s, est. speed input: 28311.69 toks/s, output: 27.65 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:24<00:59, 23.21it/s, est. speed input: 28184.36 toks/s, output: 27.52 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:25<00:58, 23.17it/s, est. speed input: 28059.61 toks/s, output: 27.40 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:25<00:57, 23.16it/s, est. speed input: 27942.45 toks/s, output: 27.29 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:26<00:57, 23.18it/s, est. speed input: 27834.46 toks/s, output: 27.18 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:27<00:56, 23.18it/s, est. speed input: 27730.67 toks/s, output: 27.08 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:27<00:55, 23.16it/s, est. speed input: 27630.18 toks/s, output: 26.98 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:28<00:55, 23.16it/s, est. speed input: 27535.70 toks/s, output: 26.89 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:29<00:53, 23.53it/s, est. speed input: 27479.53 toks/s, output: 26.84 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:29<00:53, 23.41it/s, est. speed input: 27392.43 toks/s, output: 26.75 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:30<00:52, 23.33it/s, est. speed input: 27309.41 toks/s, output: 26.67 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:31<00:52, 23.29it/s, est. speed input: 27230.65 toks/s, output: 26.59 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:32<00:51, 23.21it/s, est. speed input: 27151.63 toks/s, output: 26.52 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:32<00:50, 23.20it/s, est. speed input: 27079.64 toks/s, output: 26.44 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:33<00:50, 23.17it/s, est. speed input: 27008.83 toks/s, output: 26.38 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:34<00:49, 23.13it/s, est. speed input: 26939.55 toks/s, output: 26.31 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:34<00:49, 23.14it/s, est. speed input: 26875.39 toks/s, output: 26.25 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:35<00:48, 23.13it/s, est. speed input: 26812.66 toks/s, output: 26.18 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:36<00:47, 23.11it/s, est. speed input: 26751.31 toks/s, output: 26.12 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:36<00:46, 23.11it/s, est. speed input: 26693.29 toks/s, output: 26.07 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:37<00:46, 23.10it/s, est. speed input: 26637.08 toks/s, output: 26.01 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:38<00:45, 23.09it/s, est. speed input: 26582.65 toks/s, output: 25.96 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:38<00:44, 23.09it/s, est. speed input: 26530.53 toks/s, output: 25.91 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:39<00:44, 23.08it/s, est. speed input: 26479.37 toks/s, output: 25.86 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:40<00:43, 23.08it/s, est. speed input: 26430.55 toks/s, output: 25.81 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:41<00:42, 23.08it/s, est. speed input: 26383.16 toks/s, output: 25.76 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:41<00:42, 23.07it/s, est. speed input: 26336.90 toks/s, output: 25.72 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:42<00:41, 23.06it/s, est. speed input: 26292.24 toks/s, output: 25.68 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:43<00:40, 23.07it/s, est. speed input: 26249.40 toks/s, output: 25.63 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:43<00:40, 23.06it/s, est. speed input: 26207.59 toks/s, output: 25.59 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:44<00:39, 23.05it/s, est. speed input: 26166.23 toks/s, output: 25.55 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:45<00:38, 23.07it/s, est. speed input: 26127.97 toks/s, output: 25.52 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:45<00:38, 23.05it/s, est. speed input: 26088.93 toks/s, output: 25.48 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:46<00:37, 23.03it/s, est. speed input: 26050.78 toks/s, output: 25.44 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:47<00:36, 23.03it/s, est. speed input: 26014.90 toks/s, output: 25.41 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:48<00:36, 23.04it/s, est. speed input: 25980.00 toks/s, output: 25.37 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:48<00:35, 23.03it/s, est. speed input: 25945.62 toks/s, output: 25.34 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:49<00:34, 23.02it/s, est. speed input: 25911.70 toks/s, output: 25.30 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:50<00:33, 23.02it/s, est. speed input: 25879.22 toks/s, output: 25.27 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:50<00:33, 23.02it/s, est. speed input: 25847.61 toks/s, output: 25.24 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:51<00:32, 23.01it/s, est. speed input: 25816.64 toks/s, output: 25.21 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:52<00:31, 23.01it/s, est. speed input: 25786.35 toks/s, output: 25.18 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:52<00:31, 23.01it/s, est. speed input: 25757.39 toks/s, output: 25.15 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:53<00:30, 23.01it/s, est. speed input: 25728.53 toks/s, output: 25.13 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:54<00:29, 23.01it/s, est. speed input: 25700.82 toks/s, output: 25.10 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:54<00:29, 23.00it/s, est. speed input: 25673.26 toks/s, output: 25.07 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:55<00:28, 22.98it/s, est. speed input: 25645.81 toks/s, output: 25.04 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:56<00:27, 22.98it/s, est. speed input: 25619.78 toks/s, output: 25.02 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:57<00:27, 22.98it/s, est. speed input: 25594.23 toks/s, output: 24.99 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:57<00:26, 22.98it/s, est. speed input: 25569.57 toks/s, output: 24.97 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:58<00:25, 22.99it/s, est. speed input: 25545.44 toks/s, output: 24.95 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:59<00:24, 22.99it/s, est. speed input: 25521.99 toks/s, output: 24.92 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:59<00:24, 22.99it/s, est. speed input: 25499.10 toks/s, output: 24.90 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:00<00:23, 23.00it/s, est. speed input: 25476.75 toks/s, output: 24.88 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:01<00:22, 22.98it/s, est. speed input: 25454.20 toks/s, output: 24.86 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:01<00:22, 22.99it/s, est. speed input: 25432.81 toks/s, output: 24.84 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:02<00:21, 23.36it/s, est. speed input: 25426.66 toks/s, output: 24.83 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:03<00:20, 23.23it/s, est. speed input: 25405.31 toks/s, output: 24.81 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:03<00:19, 23.15it/s, est. speed input: 25384.62 toks/s, output: 24.79 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:04<00:19, 23.07it/s, est. speed input: 25363.81 toks/s, output: 24.77 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:05<00:18, 23.43it/s, est. speed input: 25358.94 toks/s, output: 24.76 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:06<00:17, 23.29it/s, est. speed input: 25339.62 toks/s, output: 24.75 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:06<00:17, 23.17it/s, est. speed input: 25319.88 toks/s, output: 24.73 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:07<00:16, 23.11it/s, est. speed input: 25301.19 toks/s, output: 24.71 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:08<00:15, 23.06it/s, est. speed input: 25282.69 toks/s, output: 24.69 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:08<00:15, 23.01it/s, est. speed input: 25264.03 toks/s, output: 24.67 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:09<00:14, 22.97it/s, est. speed input: 25245.70 toks/s, output: 24.65 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:10<00:13, 22.95it/s, est. speed input: 25227.77 toks/s, output: 24.64 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:10<00:13, 22.95it/s, est. speed input: 25210.66 toks/s, output: 24.62 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:11<00:12, 22.93it/s, est. speed input: 25193.37 toks/s, output: 24.60 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:12<00:11, 22.94it/s, est. speed input: 25177.11 toks/s, output: 24.59 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:13<00:11, 22.94it/s, est. speed input: 25160.99 toks/s, output: 24.57 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:13<00:10, 22.94it/s, est. speed input: 25145.33 toks/s, output: 24.56 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:14<00:09, 22.92it/s, est. speed input: 25129.03 toks/s, output: 24.54 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:15<00:08, 22.91it/s, est. speed input: 25113.21 toks/s, output: 24.52 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:15<00:08, 22.90it/s, est. speed input: 25097.84 toks/s, output: 24.51 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:16<00:07, 22.89it/s, est. speed input: 25082.34 toks/s, output: 24.49 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:17<00:06, 22.88it/s, est. speed input: 25067.29 toks/s, output: 24.48 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:17<00:06, 22.89it/s, est. speed input: 25052.86 toks/s, output: 24.47 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:18<00:05, 22.89it/s, est. speed input: 25038.43 toks/s, output: 24.45 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:19<00:04, 22.87it/s, est. speed input: 25023.72 toks/s, output: 24.44 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:20<00:04, 22.88it/s, est. speed input: 25009.91 toks/s, output: 24.42 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:20<00:03, 22.88it/s, est. speed input: 24996.16 toks/s, output: 24.41 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:21<00:02, 22.86it/s, est. speed input: 24982.05 toks/s, output: 24.40 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:22<00:02, 22.85it/s, est. speed input: 24968.54 toks/s, output: 24.38 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:22<00:01, 22.86it/s, est. speed input: 24955.34 toks/s, output: 24.37 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:23<00:00, 23.28it/s, est. speed input: 24955.13 toks/s, output: 24.37 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:23<00:00, 23.28it/s, est. speed input: 25126.70 toks/s, output: 24.54 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:23<00:00, 24.54it/s, est. speed input: 25126.70 toks/s, output: 24.54 toks/s]
[rank0]:[W126 13:21:44.980948332 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 13:21:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:22:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1415244) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1415244) WARNING 01-26 13:22:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.08 requests/s, 23658.09 total tokens/s, 23.08 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 13:22:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:22:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:22:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:22:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:22:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:22:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:22:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:22:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:22:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:22:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:22:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:22:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:22:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:22:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:22:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:22:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:22:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.77it/s]
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1415244) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1415244) 
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1415244) [2026-01-26 13:22:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1415244) [rank0]:W0126 13:22:47.161000 1415244 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1415244) [rank0]:W0126 13:22:47.216000 1415244 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1415244) [rank0]:W0126 13:22:47.850000 1415244 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1415244) [rank0]:W0126 13:22:47.934000 1415244 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1415244) 2026-01-26 13:22:52,645 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1415244) 2026-01-26 13:22:53,072 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1415244) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:01<00:10,  1.01s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  1.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  5.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  7.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  3.96it/s]
(EngineCore_DP0 pid=1415244) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:01,  5.06it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.80it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 10.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.05it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 34/4096 [00:00<00:12, 338.01it/s]
Adding requests:   2%|▏         | 72/4096 [00:00<00:11, 359.52it/s]
Adding requests:   3%|▎         | 109/4096 [00:00<00:10, 363.52it/s]
Adding requests:   4%|▎         | 146/4096 [00:00<00:10, 360.01it/s]
Adding requests:   5%|▍         | 185/4096 [00:00<00:10, 369.81it/s]
Adding requests:   5%|▌         | 224/4096 [00:00<00:10, 375.12it/s]
Adding requests:   6%|▋         | 262/4096 [00:00<00:10, 370.33it/s]
Adding requests:   7%|▋         | 301/4096 [00:00<00:10, 375.38it/s]
Adding requests:   8%|▊         | 341/4096 [00:00<00:09, 380.61it/s]
Adding requests:   9%|▉         | 380/4096 [00:01<00:10, 371.30it/s]
Adding requests:  10%|█         | 421/4096 [00:01<00:09, 381.56it/s]
Adding requests:  11%|█         | 460/4096 [00:01<00:09, 367.11it/s]
Adding requests:  12%|█▏        | 502/4096 [00:01<00:09, 380.64it/s]
Adding requests:  13%|█▎        | 544/4096 [00:01<00:09, 389.69it/s]
Adding requests:  14%|█▍        | 584/4096 [00:01<00:09, 388.52it/s]
Adding requests:  15%|█▌        | 623/4096 [00:01<00:09, 384.43it/s]
Adding requests:  16%|█▌        | 662/4096 [00:01<00:09, 378.13it/s]
Adding requests:  17%|█▋        | 701/4096 [00:01<00:08, 380.92it/s]
Adding requests:  18%|█▊        | 740/4096 [00:01<00:08, 374.52it/s]
Adding requests:  19%|█▉        | 778/4096 [00:02<00:08, 375.72it/s]
Adding requests:  20%|█▉        | 816/4096 [00:02<00:08, 375.11it/s]
Adding requests:  21%|██        | 857/4096 [00:02<00:08, 384.76it/s]
Adding requests:  22%|██▏       | 896/4096 [00:02<00:08, 385.71it/s]
Adding requests:  23%|██▎       | 935/4096 [00:02<00:08, 377.08it/s]
Adding requests:  24%|██▍       | 974/4096 [00:02<00:08, 380.49it/s]
Adding requests:  25%|██▍       | 1013/4096 [00:02<00:08, 373.72it/s]
Adding requests:  26%|██▌       | 1051/4096 [00:02<00:08, 374.10it/s]
Adding requests:  27%|██▋       | 1089/4096 [00:02<00:08, 372.08it/s]
Adding requests:  28%|██▊       | 1127/4096 [00:03<00:08, 366.88it/s]
Adding requests:  28%|██▊       | 1164/4096 [00:03<00:07, 366.76it/s]
Adding requests:  29%|██▉       | 1202/4096 [00:03<00:07, 368.67it/s]
Adding requests:  30%|███       | 1242/4096 [00:03<00:07, 377.36it/s]
Adding requests:  31%|███▏      | 1280/4096 [00:03<00:07, 373.41it/s]
Adding requests:  32%|███▏      | 1318/4096 [00:03<00:07, 374.55it/s]
Adding requests:  33%|███▎      | 1357/4096 [00:03<00:07, 378.60it/s]
Adding requests:  34%|███▍      | 1395/4096 [00:03<00:07, 378.36it/s]
Adding requests:  35%|███▍      | 1433/4096 [00:03<00:07, 377.56it/s]
Adding requests:  36%|███▌      | 1472/4096 [00:03<00:06, 378.78it/s]
Adding requests:  37%|███▋      | 1513/4096 [00:04<00:06, 385.09it/s]
Adding requests:  38%|███▊      | 1552/4096 [00:04<00:06, 382.17it/s]
Adding requests:  39%|███▉      | 1591/4096 [00:04<00:06, 376.17it/s]
Adding requests:  40%|███▉      | 1629/4096 [00:04<00:06, 369.71it/s]
Adding requests:  41%|████      | 1666/4096 [00:04<00:06, 362.15it/s]
Adding requests:  42%|████▏     | 1705/4096 [00:04<00:06, 368.71it/s]
Adding requests:  43%|████▎     | 1743/4096 [00:04<00:06, 371.56it/s]
Adding requests:  44%|████▎     | 1783/4096 [00:04<00:06, 378.91it/s]
Adding requests:  44%|████▍     | 1821/4096 [00:04<00:06, 375.79it/s]
Adding requests:  45%|████▌     | 1861/4096 [00:04<00:05, 379.99it/s]
Adding requests:  46%|████▋     | 1900/4096 [00:05<00:05, 378.36it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:05<00:05, 387.25it/s]
Adding requests:  48%|████▊     | 1981/4096 [00:05<00:05, 385.35it/s]
Adding requests:  49%|████▉     | 2020/4096 [00:05<00:05, 374.19it/s]
Adding requests:  50%|█████     | 2058/4096 [00:05<00:05, 373.20it/s]
Adding requests:  51%|█████     | 2096/4096 [00:05<00:05, 369.22it/s]
Adding requests:  52%|█████▏    | 2135/4096 [00:05<00:05, 373.37it/s]
Adding requests:  53%|█████▎    | 2173/4096 [00:05<00:05, 367.85it/s]
Adding requests:  54%|█████▍    | 2210/4096 [00:05<00:05, 365.41it/s]
Adding requests:  55%|█████▍    | 2248/4096 [00:05<00:04, 369.66it/s]
Adding requests:  56%|█████▌    | 2288/4096 [00:06<00:04, 378.05it/s]
Adding requests:  57%|█████▋    | 2326/4096 [00:06<00:04, 372.33it/s]
Adding requests:  58%|█████▊    | 2365/4096 [00:06<00:04, 376.86it/s]
Adding requests:  59%|█████▊    | 2405/4096 [00:06<00:04, 382.77it/s]
Adding requests:  60%|█████▉    | 2444/4096 [00:06<00:04, 384.88it/s]
Adding requests:  61%|██████    | 2483/4096 [00:06<00:04, 382.79it/s]
Adding requests:  62%|██████▏   | 2523/4096 [00:06<00:04, 386.67it/s]
Adding requests:  63%|██████▎   | 2566/4096 [00:06<00:03, 397.23it/s]
Adding requests:  64%|██████▎   | 2606/4096 [00:06<00:03, 394.84it/s]
Adding requests:  65%|██████▍   | 2646/4096 [00:07<00:03, 384.32it/s]
Adding requests:  66%|██████▌   | 2685/4096 [00:07<00:03, 382.58it/s]
Adding requests:  67%|██████▋   | 2724/4096 [00:07<00:03, 380.78it/s]
Adding requests:  67%|██████▋   | 2764/4096 [00:07<00:03, 385.27it/s]
Adding requests:  68%|██████▊   | 2805/4096 [00:07<00:03, 391.97it/s]
Adding requests:  69%|██████▉   | 2845/4096 [00:07<00:03, 389.83it/s]
Adding requests:  70%|███████   | 2885/4096 [00:07<00:03, 387.07it/s]
Adding requests:  71%|███████▏  | 2924/4096 [00:07<00:03, 386.85it/s]
Adding requests:  72%|███████▏  | 2965/4096 [00:07<00:02, 390.51it/s]
Adding requests:  73%|███████▎  | 3005/4096 [00:07<00:02, 391.63it/s]
Adding requests:  74%|███████▍  | 3045/4096 [00:08<00:02, 393.84it/s]
Adding requests:  75%|███████▌  | 3085/4096 [00:08<00:02, 393.23it/s]
Adding requests:  76%|███████▋  | 3126/4096 [00:08<00:02, 398.06it/s]
Adding requests:  77%|███████▋  | 3166/4096 [00:08<00:02, 392.23it/s]
Adding requests:  78%|███████▊  | 3206/4096 [00:08<00:02, 386.61it/s]
Adding requests:  79%|███████▉  | 3246/4096 [00:08<00:02, 387.80it/s]
Adding requests:  80%|████████  | 3285/4096 [00:08<00:02, 381.75it/s]
Adding requests:  81%|████████  | 3324/4096 [00:08<00:02, 376.40it/s]
Adding requests:  82%|████████▏ | 3363/4096 [00:08<00:01, 377.60it/s]
Adding requests:  83%|████████▎ | 3403/4096 [00:08<00:01, 384.08it/s]
Adding requests:  84%|████████▍ | 3442/4096 [00:09<00:01, 384.88it/s]
Adding requests:  85%|████████▍ | 3481/4096 [00:09<00:01, 384.29it/s]
Adding requests:  86%|████████▌ | 3521/4096 [00:09<00:01, 386.54it/s]
Adding requests:  87%|████████▋ | 3563/4096 [00:09<00:01, 395.68it/s]
Adding requests:  88%|████████▊ | 3603/4096 [00:09<00:01, 388.37it/s]
Adding requests:  89%|████████▉ | 3643/4096 [00:09<00:01, 391.34it/s]
Adding requests:  90%|████████▉ | 3683/4096 [00:09<00:01, 374.22it/s]
Adding requests:  91%|█████████ | 3722/4096 [00:09<00:00, 375.54it/s]
Adding requests:  92%|█████████▏| 3760/4096 [00:09<00:00, 369.63it/s]
Adding requests:  93%|█████████▎| 3798/4096 [00:10<00:00, 361.15it/s]
Adding requests:  94%|█████████▎| 3835/4096 [00:10<00:00, 362.55it/s]
Adding requests:  95%|█████████▍| 3874/4096 [00:10<00:00, 368.24it/s]
Adding requests:  95%|█████████▌| 3911/4096 [00:10<00:00, 364.52it/s]
Adding requests:  96%|█████████▋| 3949/4096 [00:10<00:00, 365.97it/s]
Adding requests:  97%|█████████▋| 3987/4096 [00:10<00:00, 367.67it/s]
Adding requests:  98%|█████████▊| 4025/4096 [00:10<00:00, 368.30it/s]
Adding requests:  99%|█████████▉| 4062/4096 [00:10<00:00, 368.11it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 377.99it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:00<00:03, 985.11it/s, est. speed input: 1008869.51 toks/s, output: 985.15 toks/s]
Processed prompts:   8%|▊         | 325/4096 [00:04<01:02, 60.50it/s, est. speed input: 77033.66 toks/s, output: 75.23 toks/s]    
Processed prompts:   9%|▉         | 367/4096 [00:05<01:12, 51.14it/s, est. speed input: 66091.69 toks/s, output: 64.54 toks/s]
Processed prompts:  10%|▉         | 392/4096 [00:07<01:30, 40.97it/s, est. speed input: 56935.51 toks/s, output: 55.60 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:08<01:47, 34.22it/s, est. speed input: 50844.31 toks/s, output: 49.65 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:09<01:57, 30.91it/s, est. speed input: 47081.74 toks/s, output: 45.98 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:11<02:06, 28.62it/s, est. speed input: 44242.52 toks/s, output: 43.21 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:12<02:12, 27.04it/s, est. speed input: 42025.88 toks/s, output: 41.04 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:13<02:16, 25.92it/s, est. speed input: 40236.81 toks/s, output: 39.29 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:15<02:19, 25.15it/s, est. speed input: 38772.07 toks/s, output: 37.86 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:16<02:21, 24.61it/s, est. speed input: 37547.30 toks/s, output: 36.67 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:18<02:22, 24.22it/s, est. speed input: 36505.83 toks/s, output: 35.65 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:19<02:22, 23.96it/s, est. speed input: 35614.78 toks/s, output: 34.78 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:20<02:22, 23.75it/s, est. speed input: 34833.63 toks/s, output: 34.02 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:22<02:22, 23.62it/s, est. speed input: 34153.89 toks/s, output: 33.35 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:23<02:20, 23.70it/s, est. speed input: 33601.03 toks/s, output: 32.81 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:24<02:19, 23.57it/s, est. speed input: 33060.83 toks/s, output: 32.29 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:26<02:18, 23.48it/s, est. speed input: 32575.86 toks/s, output: 31.81 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:27<02:17, 23.41it/s, est. speed input: 32139.06 toks/s, output: 31.39 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:28<02:16, 23.36it/s, est. speed input: 31742.61 toks/s, output: 31.00 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:30<02:15, 23.33it/s, est. speed input: 31383.42 toks/s, output: 30.65 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:31<02:14, 23.30it/s, est. speed input: 31053.28 toks/s, output: 30.33 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:33<02:13, 23.29it/s, est. speed input: 30752.25 toks/s, output: 30.03 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:34<02:12, 23.25it/s, est. speed input: 30470.95 toks/s, output: 29.76 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:35<02:10, 23.23it/s, est. speed input: 30212.11 toks/s, output: 29.50 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:37<02:09, 23.21it/s, est. speed input: 29970.50 toks/s, output: 29.27 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:38<02:08, 23.19it/s, est. speed input: 29746.63 toks/s, output: 29.05 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:40<02:06, 23.18it/s, est. speed input: 29538.59 toks/s, output: 28.85 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:41<02:05, 23.17it/s, est. speed input: 29343.73 toks/s, output: 28.66 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:42<02:04, 23.16it/s, est. speed input: 29160.85 toks/s, output: 28.48 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:44<02:02, 23.15it/s, est. speed input: 28989.62 toks/s, output: 28.31 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:45<02:01, 23.14it/s, est. speed input: 28827.55 toks/s, output: 28.15 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:46<02:00, 23.14it/s, est. speed input: 28676.19 toks/s, output: 28.00 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:48<01:58, 23.12it/s, est. speed input: 28531.53 toks/s, output: 27.86 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:49<01:57, 23.12it/s, est. speed input: 28396.28 toks/s, output: 27.73 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:51<01:56, 23.11it/s, est. speed input: 28267.41 toks/s, output: 27.60 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:52<01:54, 23.11it/s, est. speed input: 28146.20 toks/s, output: 27.49 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [00:53<01:53, 23.09it/s, est. speed input: 28028.94 toks/s, output: 27.37 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [00:55<01:52, 23.08it/s, est. speed input: 27917.89 toks/s, output: 27.26 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:56<01:50, 23.25it/s, est. speed input: 27829.83 toks/s, output: 27.18 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:57<01:48, 23.20it/s, est. speed input: 27729.56 toks/s, output: 27.08 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [00:59<01:46, 23.34it/s, est. speed input: 27649.74 toks/s, output: 27.00 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [01:00<01:45, 23.24it/s, est. speed input: 27555.89 toks/s, output: 26.91 toks/s]
Processed prompts:  41%|████      | 1666/4096 [01:02<01:44, 23.18it/s, est. speed input: 27467.47 toks/s, output: 26.82 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [01:03<01:43, 23.14it/s, est. speed input: 27382.93 toks/s, output: 26.74 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [01:04<01:42, 23.10it/s, est. speed input: 27301.39 toks/s, output: 26.66 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [01:06<01:41, 23.08it/s, est. speed input: 27223.22 toks/s, output: 26.59 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:07<01:39, 23.06it/s, est. speed input: 27148.15 toks/s, output: 26.51 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [01:09<01:38, 23.04it/s, est. speed input: 27075.38 toks/s, output: 26.44 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [01:10<01:37, 23.02it/s, est. speed input: 27005.30 toks/s, output: 26.37 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:11<01:35, 23.03it/s, est. speed input: 26939.59 toks/s, output: 26.31 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:13<01:34, 23.02it/s, est. speed input: 26875.00 toks/s, output: 26.25 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:14<01:33, 23.01it/s, est. speed input: 26813.04 toks/s, output: 26.18 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:16<01:31, 23.00it/s, est. speed input: 26752.80 toks/s, output: 26.13 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:17<01:30, 23.00it/s, est. speed input: 26694.89 toks/s, output: 26.07 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:18<01:28, 22.99it/s, est. speed input: 26639.01 toks/s, output: 26.01 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:20<01:27, 22.98it/s, est. speed input: 26584.43 toks/s, output: 25.96 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:21<01:26, 22.98it/s, est. speed input: 26532.67 toks/s, output: 25.91 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [01:22<01:24, 22.98it/s, est. speed input: 26481.85 toks/s, output: 25.86 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:24<01:22, 23.15it/s, est. speed input: 26443.93 toks/s, output: 25.82 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:25<01:21, 23.08it/s, est. speed input: 26395.29 toks/s, output: 25.78 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:27<01:20, 23.05it/s, est. speed input: 26349.60 toks/s, output: 25.73 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:28<01:19, 23.02it/s, est. speed input: 26304.53 toks/s, output: 25.69 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:29<01:17, 23.00it/s, est. speed input: 26261.27 toks/s, output: 25.65 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:31<01:16, 22.98it/s, est. speed input: 26218.81 toks/s, output: 25.60 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:32<01:15, 22.98it/s, est. speed input: 26178.60 toks/s, output: 25.57 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:34<01:13, 22.96it/s, est. speed input: 26138.40 toks/s, output: 25.53 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:35<01:12, 22.95it/s, est. speed input: 26099.24 toks/s, output: 25.49 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:36<01:11, 22.95it/s, est. speed input: 26061.87 toks/s, output: 25.45 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:38<01:09, 22.94it/s, est. speed input: 26025.17 toks/s, output: 25.42 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [01:39<01:08, 22.94it/s, est. speed input: 25989.66 toks/s, output: 25.38 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [01:41<01:06, 22.94it/s, est. speed input: 25954.95 toks/s, output: 25.35 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [01:42<01:05, 22.92it/s, est. speed input: 25920.66 toks/s, output: 25.31 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [01:43<01:04, 22.93it/s, est. speed input: 25888.12 toks/s, output: 25.28 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [01:45<01:02, 22.92it/s, est. speed input: 25855.95 toks/s, output: 25.25 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [01:46<01:01, 22.91it/s, est. speed input: 25824.16 toks/s, output: 25.22 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [01:48<00:59, 22.91it/s, est. speed input: 25793.66 toks/s, output: 25.19 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [01:49<00:58, 22.91it/s, est. speed input: 25763.71 toks/s, output: 25.16 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [01:50<00:57, 22.90it/s, est. speed input: 25734.15 toks/s, output: 25.13 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [01:52<00:55, 22.90it/s, est. speed input: 25705.68 toks/s, output: 25.10 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [01:53<00:54, 22.89it/s, est. speed input: 25677.78 toks/s, output: 25.08 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [01:55<00:52, 23.07it/s, est. speed input: 25658.73 toks/s, output: 25.06 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [01:56<00:51, 23.02it/s, est. speed input: 25632.29 toks/s, output: 25.03 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [01:57<00:50, 22.99it/s, est. speed input: 25606.51 toks/s, output: 25.01 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [01:59<00:48, 22.97it/s, est. speed input: 25581.36 toks/s, output: 24.98 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [02:00<00:47, 22.95it/s, est. speed input: 25556.69 toks/s, output: 24.96 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [02:02<00:45, 22.93it/s, est. speed input: 25532.43 toks/s, output: 24.93 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [02:03<00:44, 22.91it/s, est. speed input: 25508.59 toks/s, output: 24.91 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [02:04<00:43, 22.90it/s, est. speed input: 25485.08 toks/s, output: 24.89 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [02:06<00:41, 22.90it/s, est. speed input: 25462.64 toks/s, output: 24.87 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [02:07<00:40, 22.90it/s, est. speed input: 25440.39 toks/s, output: 24.84 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [02:08<00:39, 22.89it/s, est. speed input: 25418.66 toks/s, output: 24.82 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [02:10<00:37, 22.90it/s, est. speed input: 25397.72 toks/s, output: 24.80 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [02:11<00:36, 22.89it/s, est. speed input: 25376.71 toks/s, output: 24.78 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [02:13<00:34, 22.89it/s, est. speed input: 25356.42 toks/s, output: 24.76 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [02:14<00:33, 22.89it/s, est. speed input: 25336.51 toks/s, output: 24.74 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [02:15<00:32, 22.89it/s, est. speed input: 25317.10 toks/s, output: 24.72 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [02:17<00:30, 22.90it/s, est. speed input: 25298.11 toks/s, output: 24.71 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [02:18<00:29, 22.89it/s, est. speed input: 25279.23 toks/s, output: 24.69 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [02:20<00:27, 22.89it/s, est. speed input: 25260.81 toks/s, output: 24.67 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:21<00:26, 22.90it/s, est. speed input: 25243.25 toks/s, output: 24.65 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:22<00:25, 22.90it/s, est. speed input: 25225.63 toks/s, output: 24.63 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:24<00:23, 22.90it/s, est. speed input: 25208.35 toks/s, output: 24.62 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:25<00:22, 22.89it/s, est. speed input: 25191.40 toks/s, output: 24.60 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:27<00:20, 22.90it/s, est. speed input: 25174.88 toks/s, output: 24.58 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:28<00:19, 22.90it/s, est. speed input: 25158.66 toks/s, output: 24.57 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:29<00:17, 23.06it/s, est. speed input: 25148.05 toks/s, output: 24.56 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [02:31<00:16, 23.01it/s, est. speed input: 25132.37 toks/s, output: 24.54 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [02:32<00:15, 22.97it/s, est. speed input: 25116.79 toks/s, output: 24.53 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [02:34<00:13, 22.93it/s, est. speed input: 25101.10 toks/s, output: 24.51 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [02:35<00:12, 22.92it/s, est. speed input: 25086.32 toks/s, output: 24.50 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [02:36<00:11, 22.91it/s, est. speed input: 25071.61 toks/s, output: 24.48 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [02:38<00:09, 22.91it/s, est. speed input: 25057.25 toks/s, output: 24.47 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [02:39<00:08, 23.07it/s, est. speed input: 25048.56 toks/s, output: 24.46 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [02:41<00:06, 23.02it/s, est. speed input: 25034.57 toks/s, output: 24.45 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [02:42<00:05, 22.99it/s, est. speed input: 25021.05 toks/s, output: 24.43 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [02:43<00:04, 22.96it/s, est. speed input: 25007.61 toks/s, output: 24.42 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [02:45<00:02, 22.94it/s, est. speed input: 24994.35 toks/s, output: 24.41 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [02:46<00:01, 23.16it/s, est. speed input: 24988.30 toks/s, output: 24.40 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:46<00:00, 23.16it/s, est. speed input: 25172.53 toks/s, output: 24.58 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:46<00:00, 24.58it/s, est. speed input: 25172.53 toks/s, output: 24.58 toks/s]
[rank0]:[W126 13:25:56.057785343 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 13:25:58
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:26:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1419264) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1419264) WARNING 01-26 13:27:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.10 requests/s, 23678.67 total tokens/s, 23.10 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 13:26:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:26:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:26:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:26:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:26:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:26:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:26:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:26:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:26:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:26:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:26:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:26:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:26:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:26:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:26:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:26:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:26:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1419264) [2026-01-26 13:26:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.44it/s]
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1419264) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1419264) 
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30679040 bytes
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21913600 bytes
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 118333440 bytes
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1419264) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 58982400 bytes
(EngineCore_DP0 pid=1419264) [rank0]:W0126 13:27:19.561000 1419264 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1419264) [rank0]:W0126 13:27:19.615000 1419264 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1419264) [rank0]:W0126 13:27:20.234000 1419264 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1419264) [rank0]:W0126 13:27:20.318000 1419264 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1419264) 2026-01-26 13:27:25,092 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1419264) 2026-01-26 13:27:25,876 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1419264) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:25,  1.42s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:13,  1.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:10,  1.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:08,  1.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:02<00:02,  4.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:01,  5.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:03<00:01,  5.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:03<00:01,  5.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:04<00:01,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:04<00:01,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:04<00:00,  5.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  6.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  3.80it/s]
(EngineCore_DP0 pid=1419264) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  5.72it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00,  8.67it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:01,  5.95it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  6.42it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:01<00:01,  4.10it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  4.66it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  5.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.90it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  5.97it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 29/8192 [00:00<00:28, 288.08it/s]
Adding requests:   1%|          | 69/8192 [00:00<00:23, 352.71it/s]
Adding requests:   1%|▏         | 106/8192 [00:00<00:22, 357.23it/s]
Adding requests:   2%|▏         | 143/8192 [00:00<00:22, 361.97it/s]
Adding requests:   2%|▏         | 182/8192 [00:00<00:21, 371.03it/s]
Adding requests:   3%|▎         | 223/8192 [00:00<00:20, 382.00it/s]
Adding requests:   3%|▎         | 262/8192 [00:00<00:20, 378.52it/s]
Adding requests:   4%|▎         | 301/8192 [00:00<00:20, 382.10it/s]
Adding requests:   4%|▍         | 341/8192 [00:00<00:20, 387.56it/s]
Adding requests:   5%|▍         | 381/8192 [00:01<00:20, 389.37it/s]
Adding requests:   5%|▌         | 422/8192 [00:01<00:19, 395.47it/s]
Adding requests:   6%|▌         | 462/8192 [00:01<00:19, 391.59it/s]
Adding requests:   6%|▌         | 504/8192 [00:01<00:19, 399.09it/s]
Adding requests:   7%|▋         | 546/8192 [00:01<00:18, 403.37it/s]
Adding requests:   7%|▋         | 587/8192 [00:01<00:19, 398.79it/s]
Adding requests:   8%|▊         | 627/8192 [00:01<00:19, 391.35it/s]
Adding requests:   8%|▊         | 667/8192 [00:01<00:19, 380.43it/s]
Adding requests:   9%|▊         | 707/8192 [00:01<00:19, 385.85it/s]
Adding requests:   9%|▉         | 746/8192 [00:01<00:19, 380.49it/s]
Adding requests:  10%|▉         | 786/8192 [00:02<00:19, 384.71it/s]
Adding requests:  10%|█         | 825/8192 [00:02<00:19, 383.50it/s]
Adding requests:  11%|█         | 865/8192 [00:02<00:18, 388.12it/s]
Adding requests:  11%|█         | 906/8192 [00:02<00:18, 394.30it/s]
Adding requests:  12%|█▏        | 946/8192 [00:02<00:18, 383.18it/s]
Adding requests:  12%|█▏        | 985/8192 [00:02<00:18, 384.82it/s]
Adding requests:  12%|█▎        | 1024/8192 [00:02<00:18, 379.27it/s]
Adding requests:  13%|█▎        | 1062/8192 [00:02<00:18, 378.44it/s]
Adding requests:  13%|█▎        | 1100/8192 [00:02<00:18, 377.06it/s]
Adding requests:  14%|█▍        | 1141/8192 [00:02<00:18, 384.38it/s]
Adding requests:  14%|█▍        | 1180/8192 [00:03<00:18, 381.29it/s]
Adding requests:  15%|█▍        | 1220/8192 [00:03<00:18, 386.50it/s]
Adding requests:  15%|█▌        | 1259/8192 [00:03<00:18, 383.29it/s]
Adding requests:  16%|█▌        | 1298/8192 [00:03<00:18, 380.74it/s]
Adding requests:  16%|█▋        | 1337/8192 [00:03<00:17, 381.32it/s]
Adding requests:  17%|█▋        | 1378/8192 [00:03<00:17, 386.82it/s]
Adding requests:  17%|█▋        | 1417/8192 [00:03<00:17, 381.72it/s]
Adding requests:  18%|█▊        | 1457/8192 [00:03<00:17, 386.22it/s]
Adding requests:  18%|█▊        | 1497/8192 [00:03<00:17, 389.63it/s]
Adding requests:  19%|█▉        | 1536/8192 [00:04<00:17, 387.36it/s]
Adding requests:  19%|█▉        | 1575/8192 [00:04<00:17, 383.60it/s]
Adding requests:  20%|█▉        | 1614/8192 [00:04<00:17, 379.51it/s]
Adding requests:  20%|██        | 1652/8192 [00:04<00:17, 370.93it/s]
Adding requests:  21%|██        | 1690/8192 [00:04<00:17, 370.62it/s]
Adding requests:  21%|██        | 1729/8192 [00:04<00:17, 375.62it/s]
Adding requests:  22%|██▏       | 1770/8192 [00:04<00:16, 384.64it/s]
Adding requests:  22%|██▏       | 1809/8192 [00:04<00:17, 368.77it/s]
Adding requests:  23%|██▎       | 1848/8192 [00:04<00:17, 373.16it/s]
Adding requests:  23%|██▎       | 1888/8192 [00:04<00:16, 379.20it/s]
Adding requests:  24%|██▎       | 1928/8192 [00:05<00:16, 384.65it/s]
Adding requests:  24%|██▍       | 1967/8192 [00:05<00:16, 386.02it/s]
Adding requests:  24%|██▍       | 2006/8192 [00:05<00:16, 383.52it/s]
Adding requests:  25%|██▍       | 2045/8192 [00:05<00:16, 377.22it/s]
Adding requests:  25%|██▌       | 2083/8192 [00:05<00:16, 369.47it/s]
Adding requests:  26%|██▌       | 2124/8192 [00:05<00:16, 378.17it/s]
Adding requests:  26%|██▋       | 2162/8192 [00:05<00:16, 374.29it/s]
Adding requests:  27%|██▋       | 2200/8192 [00:05<00:16, 368.90it/s]
Adding requests:  27%|██▋       | 2239/8192 [00:05<00:15, 374.90it/s]
Adding requests:  28%|██▊       | 2279/8192 [00:05<00:15, 380.63it/s]
Adding requests:  28%|██▊       | 2319/8192 [00:06<00:15, 383.59it/s]
Adding requests:  29%|██▉       | 2360/8192 [00:06<00:14, 390.08it/s]
Adding requests:  29%|██▉       | 2401/8192 [00:06<00:14, 394.33it/s]
Adding requests:  30%|██▉       | 2441/8192 [00:06<00:14, 393.42it/s]
Adding requests:  30%|███       | 2481/8192 [00:06<00:14, 391.20it/s]
Adding requests:  31%|███       | 2521/8192 [00:06<00:14, 392.79it/s]
Adding requests:  31%|███▏      | 2564/8192 [00:06<00:14, 401.63it/s]
Adding requests:  32%|███▏      | 2605/8192 [00:06<00:13, 401.88it/s]
Adding requests:  32%|███▏      | 2646/8192 [00:06<00:14, 388.87it/s]
Adding requests:  33%|███▎      | 2685/8192 [00:07<00:14, 387.10it/s]
Adding requests:  33%|███▎      | 2724/8192 [00:07<00:14, 385.51it/s]
Adding requests:  34%|███▍      | 2765/8192 [00:07<00:13, 390.89it/s]
Adding requests:  34%|███▍      | 2806/8192 [00:07<00:13, 396.10it/s]
Adding requests:  35%|███▍      | 2846/8192 [00:07<00:13, 395.60it/s]
Adding requests:  35%|███▌      | 2886/8192 [00:07<00:13, 392.12it/s]
Adding requests:  36%|███▌      | 2926/8192 [00:07<00:13, 391.08it/s]
Adding requests:  36%|███▌      | 2966/8192 [00:07<00:13, 390.26it/s]
Adding requests:  37%|███▋      | 3006/8192 [00:07<00:13, 391.91it/s]
Adding requests:  37%|███▋      | 3046/8192 [00:07<00:13, 392.79it/s]
Adding requests:  38%|███▊      | 3086/8192 [00:08<00:13, 392.27it/s]
Adding requests:  38%|███▊      | 3126/8192 [00:08<00:13, 385.19it/s]
Adding requests:  39%|███▊      | 3165/8192 [00:08<00:13, 382.24it/s]
Adding requests:  39%|███▉      | 3204/8192 [00:08<00:13, 380.21it/s]
Adding requests:  40%|███▉      | 3244/8192 [00:08<00:12, 385.21it/s]
Adding requests:  40%|████      | 3283/8192 [00:08<00:12, 381.66it/s]
Adding requests:  41%|████      | 3322/8192 [00:08<00:12, 377.09it/s]
Adding requests:  41%|████      | 3361/8192 [00:08<00:12, 380.31it/s]
Adding requests:  42%|████▏     | 3402/8192 [00:08<00:12, 386.68it/s]
Adding requests:  42%|████▏     | 3442/8192 [00:08<00:12, 389.01it/s]
Adding requests:  43%|████▎     | 3482/8192 [00:09<00:12, 389.97it/s]
Adding requests:  43%|████▎     | 3522/8192 [00:09<00:11, 392.42it/s]
Adding requests:  44%|████▎     | 3565/8192 [00:09<00:11, 401.72it/s]
Adding requests:  44%|████▍     | 3606/8192 [00:09<00:11, 394.80it/s]
Adding requests:  45%|████▍     | 3647/8192 [00:09<00:11, 397.38it/s]
Adding requests:  45%|████▌     | 3687/8192 [00:09<00:11, 386.15it/s]
Adding requests:  45%|████▌     | 3727/8192 [00:09<00:11, 387.10it/s]
Adding requests:  46%|████▌     | 3766/8192 [00:09<00:11, 379.47it/s]
Adding requests:  46%|████▋     | 3804/8192 [00:09<00:11, 369.35it/s]
Adding requests:  47%|████▋     | 3843/8192 [00:10<00:11, 372.35it/s]
Adding requests:  47%|████▋     | 3882/8192 [00:10<00:11, 375.48it/s]
Adding requests:  48%|████▊     | 3920/8192 [00:10<00:11, 369.79it/s]
Adding requests:  48%|████▊     | 3959/8192 [00:10<00:11, 374.35it/s]
Adding requests:  49%|████▉     | 3997/8192 [00:10<00:11, 371.30it/s]
Adding requests:  49%|████▉     | 4036/8192 [00:10<00:11, 374.28it/s]
Adding requests:  50%|████▉     | 4074/8192 [00:10<00:11, 372.05it/s]
Adding requests:  50%|█████     | 4113/8192 [00:10<00:10, 376.86it/s]
Adding requests:  51%|█████     | 4151/8192 [00:10<00:10, 375.34it/s]
Adding requests:  51%|█████     | 4190/8192 [00:10<00:10, 377.59it/s]
Adding requests:  52%|█████▏    | 4228/8192 [00:11<00:10, 376.54it/s]
Adding requests:  52%|█████▏    | 4267/8192 [00:11<00:10, 379.02it/s]
Adding requests:  53%|█████▎    | 4306/8192 [00:11<00:10, 379.98it/s]
Adding requests:  53%|█████▎    | 4345/8192 [00:11<00:10, 381.77it/s]
Adding requests:  54%|█████▎    | 4384/8192 [00:11<00:09, 382.37it/s]
Adding requests:  54%|█████▍    | 4423/8192 [00:11<00:09, 382.71it/s]
Adding requests:  54%|█████▍    | 4462/8192 [00:11<00:09, 383.80it/s]
Adding requests:  55%|█████▍    | 4501/8192 [00:11<00:09, 373.22it/s]
Adding requests:  55%|█████▌    | 4541/8192 [00:11<00:09, 380.14it/s]
Adding requests:  56%|█████▌    | 4580/8192 [00:11<00:09, 380.15it/s]
Adding requests:  56%|█████▋    | 4619/8192 [00:12<00:09, 377.90it/s]
Adding requests:  57%|█████▋    | 4657/8192 [00:12<00:09, 375.93it/s]
Adding requests:  57%|█████▋    | 4695/8192 [00:12<00:09, 370.29it/s]
Adding requests:  58%|█████▊    | 4736/8192 [00:12<00:09, 381.59it/s]
Adding requests:  58%|█████▊    | 4775/8192 [00:12<00:08, 383.16it/s]
Adding requests:  59%|█████▉    | 4814/8192 [00:12<00:08, 379.60it/s]
Adding requests:  59%|█████▉    | 4852/8192 [00:12<00:08, 373.98it/s]
Adding requests:  60%|█████▉    | 4891/8192 [00:12<00:08, 377.58it/s]
Adding requests:  60%|██████    | 4931/8192 [00:12<00:08, 382.42it/s]
Adding requests:  61%|██████    | 4970/8192 [00:12<00:08, 384.49it/s]
Adding requests:  61%|██████    | 5009/8192 [00:13<00:08, 383.75it/s]
Adding requests:  62%|██████▏   | 5051/8192 [00:13<00:08, 390.97it/s]
Adding requests:  62%|██████▏   | 5091/8192 [00:13<00:07, 388.48it/s]
Adding requests:  63%|██████▎   | 5130/8192 [00:13<00:07, 387.57it/s]
Adding requests:  63%|██████▎   | 5169/8192 [00:13<00:07, 385.77it/s]
Adding requests:  64%|██████▎   | 5208/8192 [00:13<00:07, 382.68it/s]
Adding requests:  64%|██████▍   | 5247/8192 [00:13<00:07, 381.67it/s]
Adding requests:  65%|██████▍   | 5286/8192 [00:13<00:07, 380.39it/s]
Adding requests:  65%|██████▌   | 5325/8192 [00:13<00:07, 382.37it/s]
Adding requests:  65%|██████▌   | 5364/8192 [00:14<00:07, 382.51it/s]
Adding requests:  66%|██████▌   | 5403/8192 [00:14<00:07, 376.37it/s]
Adding requests:  66%|██████▋   | 5442/8192 [00:14<00:07, 378.61it/s]
Adding requests:  67%|██████▋   | 5482/8192 [00:14<00:07, 382.50it/s]
Adding requests:  67%|██████▋   | 5522/8192 [00:14<00:06, 385.95it/s]
Adding requests:  68%|██████▊   | 5561/8192 [00:14<00:06, 384.79it/s]
Adding requests:  68%|██████▊   | 5600/8192 [00:14<00:06, 380.25it/s]
Adding requests:  69%|██████▉   | 5640/8192 [00:14<00:06, 385.25it/s]
Adding requests:  69%|██████▉   | 5679/8192 [00:14<00:06, 382.90it/s]
Adding requests:  70%|██████▉   | 5718/8192 [00:14<00:06, 384.39it/s]
Adding requests:  70%|███████   | 5757/8192 [00:15<00:06, 382.85it/s]
Adding requests:  71%|███████   | 5798/8192 [00:15<00:06, 388.09it/s]
Adding requests:  71%|███████▏  | 5837/8192 [00:15<00:06, 386.22it/s]
Adding requests:  72%|███████▏  | 5876/8192 [00:15<00:06, 375.88it/s]
Adding requests:  72%|███████▏  | 5916/8192 [00:15<00:05, 382.07it/s]
Adding requests:  73%|███████▎  | 5957/8192 [00:15<00:05, 387.42it/s]
Adding requests:  73%|███████▎  | 5997/8192 [00:15<00:05, 388.67it/s]
Adding requests:  74%|███████▎  | 6036/8192 [00:15<00:05, 387.75it/s]
Adding requests:  74%|███████▍  | 6075/8192 [00:15<00:05, 387.62it/s]
Adding requests:  75%|███████▍  | 6114/8192 [00:15<00:05, 380.99it/s]
Adding requests:  75%|███████▌  | 6155/8192 [00:16<00:05, 389.07it/s]
Adding requests:  76%|███████▌  | 6194/8192 [00:16<00:05, 383.86it/s]
Adding requests:  76%|███████▌  | 6233/8192 [00:16<00:05, 382.94it/s]
Adding requests:  77%|███████▋  | 6273/8192 [00:16<00:04, 385.56it/s]
Adding requests:  77%|███████▋  | 6312/8192 [00:16<00:04, 386.60it/s]
Adding requests:  78%|███████▊  | 6353/8192 [00:16<00:04, 392.47it/s]
Adding requests:  78%|███████▊  | 6393/8192 [00:16<00:04, 390.22it/s]
Adding requests:  79%|███████▊  | 6433/8192 [00:16<00:04, 378.16it/s]
Adding requests:  79%|███████▉  | 6471/8192 [00:16<00:04, 377.74it/s]
Adding requests:  79%|███████▉  | 6510/8192 [00:16<00:04, 379.97it/s]
Adding requests:  80%|███████▉  | 6549/8192 [00:17<00:04, 380.48it/s]
Adding requests:  80%|████████  | 6588/8192 [00:17<00:04, 378.42it/s]
Adding requests:  81%|████████  | 6628/8192 [00:17<00:04, 382.85it/s]
Adding requests:  81%|████████▏ | 6667/8192 [00:17<00:03, 383.49it/s]
Adding requests:  82%|████████▏ | 6706/8192 [00:17<00:03, 382.00it/s]
Adding requests:  82%|████████▏ | 6747/8192 [00:17<00:03, 386.82it/s]
Adding requests:  83%|████████▎ | 6786/8192 [00:17<00:03, 387.40it/s]
Adding requests:  83%|████████▎ | 6825/8192 [00:17<00:03, 377.68it/s]
Adding requests:  84%|████████▍ | 6865/8192 [00:17<00:03, 381.01it/s]
Adding requests:  84%|████████▍ | 6904/8192 [00:18<00:03, 381.08it/s]
Adding requests:  85%|████████▍ | 6944/8192 [00:18<00:03, 385.85it/s]
Adding requests:  85%|████████▌ | 6983/8192 [00:18<00:03, 385.39it/s]
Adding requests:  86%|████████▌ | 7023/8192 [00:18<00:03, 387.89it/s]
Adding requests:  86%|████████▌ | 7062/8192 [00:18<00:02, 383.57it/s]
Adding requests:  87%|████████▋ | 7101/8192 [00:18<00:02, 378.89it/s]
Adding requests:  87%|████████▋ | 7142/8192 [00:18<00:02, 385.03it/s]
Adding requests:  88%|████████▊ | 7181/8192 [00:18<00:02, 386.18it/s]
Adding requests:  88%|████████▊ | 7220/8192 [00:18<00:02, 381.36it/s]
Adding requests:  89%|████████▊ | 7259/8192 [00:18<00:02, 383.72it/s]
Adding requests:  89%|████████▉ | 7298/8192 [00:19<00:02, 385.31it/s]
Adding requests:  90%|████████▉ | 7337/8192 [00:19<00:02, 383.21it/s]
Adding requests:  90%|█████████ | 7377/8192 [00:19<00:02, 387.01it/s]
Adding requests:  91%|█████████ | 7416/8192 [00:19<00:02, 384.32it/s]
Adding requests:  91%|█████████ | 7455/8192 [00:19<00:01, 382.32it/s]
Adding requests:  91%|█████████▏| 7494/8192 [00:19<00:01, 380.57it/s]
Adding requests:  92%|█████████▏| 7533/8192 [00:19<00:01, 382.29it/s]
Adding requests:  92%|█████████▏| 7572/8192 [00:19<00:01, 382.09it/s]
Adding requests:  93%|█████████▎| 7611/8192 [00:19<00:01, 381.45it/s]
Adding requests:  93%|█████████▎| 7651/8192 [00:19<00:01, 385.59it/s]
Adding requests:  94%|█████████▍| 7693/8192 [00:20<00:01, 394.27it/s]
Adding requests:  94%|█████████▍| 7733/8192 [00:20<00:01, 391.93it/s]
Adding requests:  95%|█████████▍| 7773/8192 [00:20<00:01, 388.86it/s]
Adding requests:  95%|█████████▌| 7812/8192 [00:20<00:00, 385.59it/s]
Adding requests:  96%|█████████▌| 7851/8192 [00:20<00:00, 382.71it/s]
Adding requests:  96%|█████████▋| 7890/8192 [00:20<00:00, 381.89it/s]
Adding requests:  97%|█████████▋| 7932/8192 [00:20<00:00, 390.49it/s]
Adding requests:  97%|█████████▋| 7973/8192 [00:20<00:00, 394.87it/s]
Adding requests:  98%|█████████▊| 8013/8192 [00:20<00:00, 394.84it/s]
Adding requests:  98%|█████████▊| 8053/8192 [00:20<00:00, 389.39it/s]
Adding requests:  99%|█████████▉| 8094/8192 [00:21<00:00, 393.78it/s]
Adding requests:  99%|█████████▉| 8134/8192 [00:21<00:00, 388.03it/s]
Adding requests: 100%|█████████▉| 8173/8192 [00:21<00:00, 382.23it/s]
Adding requests: 100%|██████████| 8192/8192 [00:21<00:00, 383.43it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 496/8192 [00:02<00:40, 192.16it/s, est. speed input: 196769.36 toks/s, output: 192.16 toks/s]
Processed prompts:   7%|▋         | 560/8192 [00:05<01:24, 90.65it/s, est. speed input: 107983.51 toks/s, output: 105.45 toks/s] 
Processed prompts:   8%|▊         | 624/8192 [00:08<02:07, 59.58it/s, est. speed input: 79473.68 toks/s, output: 77.61 toks/s]  
Processed prompts:   8%|▊         | 688/8192 [00:10<02:46, 45.19it/s, est. speed input: 65391.84 toks/s, output: 63.86 toks/s]
Processed prompts:   9%|▉         | 752/8192 [00:13<03:18, 37.49it/s, est. speed input: 57176.44 toks/s, output: 55.84 toks/s]
Processed prompts:  10%|▉         | 816/8192 [00:16<03:45, 32.64it/s, est. speed input: 51551.53 toks/s, output: 50.34 toks/s]
Processed prompts:  11%|█         | 880/8192 [00:18<04:07, 29.59it/s, est. speed input: 47557.05 toks/s, output: 46.44 toks/s]
Processed prompts:  12%|█▏        | 944/8192 [00:21<04:22, 27.58it/s, est. speed input: 44559.21 toks/s, output: 43.51 toks/s]
Processed prompts:  12%|█▏        | 1008/8192 [00:24<04:33, 26.25it/s, est. speed input: 42238.99 toks/s, output: 41.25 toks/s]
Processed prompts:  13%|█▎        | 1072/8192 [00:27<04:40, 25.34it/s, est. speed input: 40384.19 toks/s, output: 39.44 toks/s]
Processed prompts:  14%|█▍        | 1136/8192 [00:29<04:45, 24.72it/s, est. speed input: 38868.12 toks/s, output: 37.96 toks/s]
Processed prompts:  15%|█▍        | 1200/8192 [00:32<04:48, 24.28it/s, est. speed input: 37603.22 toks/s, output: 36.72 toks/s]
Processed prompts:  15%|█▌        | 1264/8192 [00:35<04:48, 23.97it/s, est. speed input: 36535.41 toks/s, output: 35.68 toks/s]
Processed prompts:  16%|█▌        | 1328/8192 [00:38<04:48, 23.76it/s, est. speed input: 35620.45 toks/s, output: 34.79 toks/s]
Processed prompts:  17%|█▋        | 1392/8192 [00:40<04:48, 23.61it/s, est. speed input: 34825.99 toks/s, output: 34.01 toks/s]
Processed prompts:  18%|█▊        | 1456/8192 [00:43<04:46, 23.49it/s, est. speed input: 34128.99 toks/s, output: 33.33 toks/s]
Processed prompts:  19%|█▊        | 1520/8192 [00:46<04:45, 23.41it/s, est. speed input: 33513.84 toks/s, output: 32.73 toks/s]
Processed prompts:  19%|█▉        | 1584/8192 [00:49<04:41, 23.45it/s, est. speed input: 32993.51 toks/s, output: 32.22 toks/s]
Processed prompts:  20%|██        | 1648/8192 [00:51<04:40, 23.36it/s, est. speed input: 32500.88 toks/s, output: 31.74 toks/s]
Processed prompts:  21%|██        | 1712/8192 [00:54<04:37, 23.31it/s, est. speed input: 32059.36 toks/s, output: 31.31 toks/s]
Processed prompts:  22%|██▏       | 1776/8192 [00:57<04:35, 23.29it/s, est. speed input: 31663.27 toks/s, output: 30.92 toks/s]
Processed prompts:  22%|██▏       | 1840/8192 [01:00<04:33, 23.24it/s, est. speed input: 31296.20 toks/s, output: 30.56 toks/s]
Processed prompts:  23%|██▎       | 1904/8192 [01:02<04:30, 23.21it/s, est. speed input: 30962.09 toks/s, output: 30.24 toks/s]
Processed prompts:  24%|██▍       | 1968/8192 [01:05<04:28, 23.17it/s, est. speed input: 30653.39 toks/s, output: 29.93 toks/s]
Processed prompts:  25%|██▍       | 2032/8192 [01:08<04:26, 23.15it/s, est. speed input: 30370.78 toks/s, output: 29.66 toks/s]
Processed prompts:  26%|██▌       | 2096/8192 [01:11<04:23, 23.12it/s, est. speed input: 30107.42 toks/s, output: 29.40 toks/s]
Processed prompts:  26%|██▋       | 2160/8192 [01:14<04:19, 23.23it/s, est. speed input: 29883.91 toks/s, output: 29.18 toks/s]
Processed prompts:  27%|██▋       | 2224/8192 [01:16<04:17, 23.18it/s, est. speed input: 29658.18 toks/s, output: 28.96 toks/s]
Processed prompts:  28%|██▊       | 2288/8192 [01:19<04:14, 23.15it/s, est. speed input: 29448.49 toks/s, output: 28.76 toks/s]
Processed prompts:  29%|██▊       | 2352/8192 [01:22<04:12, 23.12it/s, est. speed input: 29251.46 toks/s, output: 28.57 toks/s]
Processed prompts:  29%|██▉       | 2416/8192 [01:25<04:10, 23.10it/s, est. speed input: 29067.31 toks/s, output: 28.39 toks/s]
Processed prompts:  30%|███       | 2480/8192 [01:27<04:07, 23.09it/s, est. speed input: 28894.95 toks/s, output: 28.22 toks/s]
Processed prompts:  31%|███       | 2544/8192 [01:30<04:04, 23.07it/s, est. speed input: 28732.46 toks/s, output: 28.06 toks/s]
Processed prompts:  32%|███▏      | 2608/8192 [01:33<04:02, 23.07it/s, est. speed input: 28580.59 toks/s, output: 27.91 toks/s]
Processed prompts:  33%|███▎      | 2672/8192 [01:36<03:59, 23.07it/s, est. speed input: 28437.81 toks/s, output: 27.77 toks/s]
Processed prompts:  33%|███▎      | 2736/8192 [01:38<03:56, 23.06it/s, est. speed input: 28301.24 toks/s, output: 27.64 toks/s]
Processed prompts:  34%|███▍      | 2800/8192 [01:41<03:53, 23.05it/s, est. speed input: 28172.44 toks/s, output: 27.51 toks/s]
Processed prompts:  35%|███▍      | 2864/8192 [01:44<03:50, 23.14it/s, est. speed input: 28061.18 toks/s, output: 27.40 toks/s]
Processed prompts:  36%|███▌      | 2928/8192 [01:47<03:47, 23.10it/s, est. speed input: 27944.61 toks/s, output: 27.29 toks/s]
Processed prompts:  37%|███▋      | 2992/8192 [01:50<03:45, 23.08it/s, est. speed input: 27834.04 toks/s, output: 27.18 toks/s]
Processed prompts:  37%|███▋      | 3056/8192 [01:52<03:42, 23.05it/s, est. speed input: 27728.18 toks/s, output: 27.08 toks/s]
Processed prompts:  38%|███▊      | 3120/8192 [01:55<03:40, 23.03it/s, est. speed input: 27627.47 toks/s, output: 26.98 toks/s]
Processed prompts:  39%|███▉      | 3184/8192 [01:58<03:37, 23.03it/s, est. speed input: 27532.59 toks/s, output: 26.89 toks/s]
Processed prompts:  40%|███▉      | 3248/8192 [02:01<03:34, 23.03it/s, est. speed input: 27441.54 toks/s, output: 26.80 toks/s]
Processed prompts:  40%|████      | 3312/8192 [02:03<03:31, 23.02it/s, est. speed input: 27354.35 toks/s, output: 26.71 toks/s]
Processed prompts:  41%|████      | 3376/8192 [02:06<03:29, 23.02it/s, est. speed input: 27271.47 toks/s, output: 26.63 toks/s]
Processed prompts:  42%|████▏     | 3440/8192 [02:09<03:26, 23.01it/s, est. speed input: 27191.23 toks/s, output: 26.55 toks/s]
Processed prompts:  43%|████▎     | 3504/8192 [02:12<03:23, 23.01it/s, est. speed input: 27115.08 toks/s, output: 26.48 toks/s]
Processed prompts:  44%|████▎     | 3568/8192 [02:15<03:20, 23.03it/s, est. speed input: 27043.10 toks/s, output: 26.41 toks/s]
Processed prompts:  44%|████▍     | 3632/8192 [02:17<03:17, 23.13it/s, est. speed input: 26981.81 toks/s, output: 26.35 toks/s]
Processed prompts:  45%|████▌     | 3696/8192 [02:20<03:14, 23.10it/s, est. speed input: 26914.53 toks/s, output: 26.28 toks/s]
Processed prompts:  46%|████▌     | 3760/8192 [02:23<03:12, 23.08it/s, est. speed input: 26849.89 toks/s, output: 26.22 toks/s]
Processed prompts:  47%|████▋     | 3824/8192 [02:26<03:09, 23.05it/s, est. speed input: 26786.36 toks/s, output: 26.16 toks/s]
Processed prompts:  47%|████▋     | 3888/8192 [02:28<03:05, 23.14it/s, est. speed input: 26733.82 toks/s, output: 26.11 toks/s]
Processed prompts:  48%|████▊     | 3952/8192 [02:31<03:03, 23.10it/s, est. speed input: 26675.86 toks/s, output: 26.05 toks/s]
Processed prompts:  49%|████▉     | 4016/8192 [02:34<03:00, 23.07it/s, est. speed input: 26619.54 toks/s, output: 26.00 toks/s]
Processed prompts:  50%|████▉     | 4080/8192 [02:37<02:57, 23.16it/s, est. speed input: 26572.76 toks/s, output: 25.95 toks/s]
Processed prompts:  51%|█████     | 4144/8192 [02:40<02:55, 23.12it/s, est. speed input: 26520.99 toks/s, output: 25.90 toks/s]
Processed prompts:  51%|█████▏    | 4208/8192 [02:42<02:52, 23.08it/s, est. speed input: 26469.68 toks/s, output: 25.85 toks/s]
Processed prompts:  52%|█████▏    | 4272/8192 [02:45<02:49, 23.06it/s, est. speed input: 26421.00 toks/s, output: 25.80 toks/s]
Processed prompts:  53%|█████▎    | 4336/8192 [02:48<02:47, 23.04it/s, est. speed input: 26373.32 toks/s, output: 25.76 toks/s]
Processed prompts:  54%|█████▎    | 4400/8192 [02:51<02:44, 23.03it/s, est. speed input: 26327.69 toks/s, output: 25.71 toks/s]
Processed prompts:  54%|█████▍    | 4464/8192 [02:53<02:41, 23.03it/s, est. speed input: 26283.68 toks/s, output: 25.67 toks/s]
Processed prompts:  55%|█████▌    | 4528/8192 [02:56<02:39, 23.01it/s, est. speed input: 26240.33 toks/s, output: 25.63 toks/s]
Processed prompts:  56%|█████▌    | 4592/8192 [02:59<02:36, 23.00it/s, est. speed input: 26198.24 toks/s, output: 25.58 toks/s]
Processed prompts:  57%|█████▋    | 4656/8192 [03:02<02:33, 23.00it/s, est. speed input: 26157.60 toks/s, output: 25.54 toks/s]
Processed prompts:  58%|█████▊    | 4720/8192 [03:05<02:31, 22.99it/s, est. speed input: 26118.12 toks/s, output: 25.51 toks/s]
Processed prompts:  58%|█████▊    | 4784/8192 [03:07<02:28, 22.99it/s, est. speed input: 26079.97 toks/s, output: 25.47 toks/s]
Processed prompts:  59%|█████▉    | 4848/8192 [03:10<02:25, 23.00it/s, est. speed input: 26043.31 toks/s, output: 25.43 toks/s]
Processed prompts:  60%|█████▉    | 4912/8192 [03:13<02:22, 23.01it/s, est. speed input: 26008.02 toks/s, output: 25.40 toks/s]
Processed prompts:  61%|██████    | 4976/8192 [03:16<02:19, 23.10it/s, est. speed input: 25978.07 toks/s, output: 25.37 toks/s]
Processed prompts:  62%|██████▏   | 5040/8192 [03:18<02:16, 23.06it/s, est. speed input: 25943.49 toks/s, output: 25.34 toks/s]
Processed prompts:  62%|██████▏   | 5104/8192 [03:21<02:14, 23.02it/s, est. speed input: 25909.64 toks/s, output: 25.30 toks/s]
Processed prompts:  63%|██████▎   | 5168/8192 [03:24<02:11, 23.02it/s, est. speed input: 25877.64 toks/s, output: 25.27 toks/s]
Processed prompts:  64%|██████▍   | 5232/8192 [03:27<02:08, 23.00it/s, est. speed input: 25845.91 toks/s, output: 25.24 toks/s]
Processed prompts:  65%|██████▍   | 5296/8192 [03:30<02:05, 23.00it/s, est. speed input: 25815.34 toks/s, output: 25.21 toks/s]
Processed prompts:  65%|██████▌   | 5360/8192 [03:32<02:03, 22.99it/s, est. speed input: 25785.20 toks/s, output: 25.18 toks/s]
Processed prompts:  66%|██████▌   | 5424/8192 [03:35<02:00, 22.98it/s, est. speed input: 25755.64 toks/s, output: 25.15 toks/s]
Processed prompts:  67%|██████▋   | 5488/8192 [03:38<01:57, 22.97it/s, est. speed input: 25727.16 toks/s, output: 25.12 toks/s]
Processed prompts:  68%|██████▊   | 5552/8192 [03:41<01:54, 22.99it/s, est. speed input: 25700.00 toks/s, output: 25.10 toks/s]
Processed prompts:  69%|██████▊   | 5616/8192 [03:43<01:52, 22.99it/s, est. speed input: 25673.23 toks/s, output: 25.07 toks/s]
Processed prompts:  69%|██████▉   | 5680/8192 [03:46<01:49, 23.00it/s, est. speed input: 25647.36 toks/s, output: 25.05 toks/s]
Processed prompts:  70%|███████   | 5744/8192 [03:49<01:46, 23.00it/s, est. speed input: 25622.23 toks/s, output: 25.02 toks/s]
Processed prompts:  71%|███████   | 5808/8192 [03:52<01:43, 23.01it/s, est. speed input: 25597.89 toks/s, output: 25.00 toks/s]
Processed prompts:  72%|███████▏  | 5872/8192 [03:55<01:40, 23.11it/s, est. speed input: 25578.23 toks/s, output: 24.98 toks/s]
Processed prompts:  72%|███████▏  | 5936/8192 [03:57<01:37, 23.18it/s, est. speed input: 25558.69 toks/s, output: 24.96 toks/s]
Processed prompts:  73%|███████▎  | 6000/8192 [04:00<01:34, 23.12it/s, est. speed input: 25535.51 toks/s, output: 24.94 toks/s]
Processed prompts:  74%|███████▍  | 6064/8192 [04:03<01:32, 23.08it/s, est. speed input: 25512.49 toks/s, output: 24.91 toks/s]
Processed prompts:  75%|███████▍  | 6128/8192 [04:06<01:29, 23.05it/s, est. speed input: 25490.16 toks/s, output: 24.89 toks/s]
Processed prompts:  76%|███████▌  | 6192/8192 [04:08<01:26, 23.04it/s, est. speed input: 25468.55 toks/s, output: 24.87 toks/s]
Processed prompts:  76%|███████▋  | 6256/8192 [04:11<01:24, 23.03it/s, est. speed input: 25447.69 toks/s, output: 24.85 toks/s]
Processed prompts:  77%|███████▋  | 6320/8192 [04:14<01:21, 23.02it/s, est. speed input: 25426.89 toks/s, output: 24.83 toks/s]
Processed prompts:  78%|███████▊  | 6384/8192 [04:17<01:18, 23.01it/s, est. speed input: 25406.54 toks/s, output: 24.81 toks/s]
Processed prompts:  79%|███████▊  | 6448/8192 [04:20<01:15, 23.00it/s, est. speed input: 25386.18 toks/s, output: 24.79 toks/s]
Processed prompts:  79%|███████▉  | 6512/8192 [04:22<01:13, 22.99it/s, est. speed input: 25366.35 toks/s, output: 24.77 toks/s]
Processed prompts:  80%|████████  | 6576/8192 [04:25<01:10, 22.99it/s, est. speed input: 25347.33 toks/s, output: 24.75 toks/s]
Processed prompts:  81%|████████  | 6640/8192 [04:28<01:07, 22.99it/s, est. speed input: 25328.72 toks/s, output: 24.74 toks/s]
Processed prompts:  82%|████████▏ | 6704/8192 [04:31<01:04, 22.99it/s, est. speed input: 25310.30 toks/s, output: 24.72 toks/s]
Processed prompts:  83%|████████▎ | 6768/8192 [04:34<01:01, 22.98it/s, est. speed input: 25291.98 toks/s, output: 24.70 toks/s]
Processed prompts:  83%|████████▎ | 6832/8192 [04:36<00:59, 22.98it/s, est. speed input: 25274.08 toks/s, output: 24.68 toks/s]
Processed prompts:  84%|████████▍ | 6896/8192 [04:39<00:56, 22.97it/s, est. speed input: 25256.66 toks/s, output: 24.66 toks/s]
Processed prompts:  85%|████████▍ | 6960/8192 [04:42<00:53, 22.98it/s, est. speed input: 25239.63 toks/s, output: 24.65 toks/s]
Processed prompts:  86%|████████▌ | 7024/8192 [04:45<00:50, 22.98it/s, est. speed input: 25222.88 toks/s, output: 24.63 toks/s]
Processed prompts:  87%|████████▋ | 7088/8192 [04:47<00:48, 22.96it/s, est. speed input: 25206.09 toks/s, output: 24.62 toks/s]
Processed prompts:  87%|████████▋ | 7152/8192 [04:50<00:45, 22.97it/s, est. speed input: 25190.11 toks/s, output: 24.60 toks/s]
Processed prompts:  88%|████████▊ | 7216/8192 [04:53<00:42, 22.98it/s, est. speed input: 25174.51 toks/s, output: 24.58 toks/s]
Processed prompts:  89%|████████▉ | 7280/8192 [04:56<00:39, 22.98it/s, est. speed input: 25159.09 toks/s, output: 24.57 toks/s]
Processed prompts:  90%|████████▉ | 7344/8192 [04:59<00:36, 22.98it/s, est. speed input: 25143.88 toks/s, output: 24.55 toks/s]
Processed prompts:  90%|█████████ | 7408/8192 [05:01<00:34, 22.98it/s, est. speed input: 25128.95 toks/s, output: 24.54 toks/s]
Processed prompts:  91%|█████████ | 7472/8192 [05:04<00:31, 22.98it/s, est. speed input: 25114.57 toks/s, output: 24.53 toks/s]
Processed prompts:  92%|█████████▏| 7536/8192 [05:07<00:28, 22.98it/s, est. speed input: 25100.10 toks/s, output: 24.51 toks/s]
Processed prompts:  93%|█████████▎| 7600/8192 [05:10<00:25, 22.98it/s, est. speed input: 25085.88 toks/s, output: 24.50 toks/s]
Processed prompts:  94%|█████████▎| 7664/8192 [05:13<00:22, 22.98it/s, est. speed input: 25072.21 toks/s, output: 24.48 toks/s]
Processed prompts:  94%|█████████▍| 7728/8192 [05:15<00:20, 22.98it/s, est. speed input: 25058.56 toks/s, output: 24.47 toks/s]
Processed prompts:  95%|█████████▌| 7792/8192 [05:18<00:17, 22.98it/s, est. speed input: 25045.36 toks/s, output: 24.46 toks/s]
Processed prompts:  96%|█████████▌| 7856/8192 [05:21<00:14, 22.98it/s, est. speed input: 25032.23 toks/s, output: 24.45 toks/s]
Processed prompts:  97%|█████████▋| 7920/8192 [05:24<00:11, 22.99it/s, est. speed input: 25019.52 toks/s, output: 24.43 toks/s]
Processed prompts:  97%|█████████▋| 7984/8192 [05:26<00:09, 22.98it/s, est. speed input: 25006.82 toks/s, output: 24.42 toks/s]
Processed prompts:  98%|█████████▊| 8048/8192 [05:29<00:06, 22.99it/s, est. speed input: 24994.68 toks/s, output: 24.41 toks/s]
Processed prompts:  99%|█████████▉| 8112/8192 [05:32<00:03, 23.01it/s, est. speed input: 24982.93 toks/s, output: 24.40 toks/s]
Processed prompts: 100%|█████████▉| 8176/8192 [05:33<00:00, 29.46it/s, est. speed input: 25123.34 toks/s, output: 24.53 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [05:33<00:00, 29.46it/s, est. speed input: 25172.47 toks/s, output: 24.58 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [05:33<00:00, 24.58it/s, est. speed input: 25172.47 toks/s, output: 24.58 toks/s]
[rank0]:[W126 13:33:29.577676009 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 08:37:44
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:37:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3316751) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3316751) WARNING 01-28 08:38:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.51 requests/s, 17192.33 total tokens/s, 33.51 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 08:37:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:37:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:37:51] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:37:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:37:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:37:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:37:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:37:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:37:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:37:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:37:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:37:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:37:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:37:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:37:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:37:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:37:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3316751) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3316751) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=3316751) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=3316751) 
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3316751) [2026-01-28 08:37:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3316751) 2026-01-28 08:38:17,367 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3316751) 2026-01-28 08:38:17,398 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3316751) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]
(EngineCore_DP0 pid=3316751) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.22it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|████▍     | 57/128 [00:00<00:00, 566.09it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 725.39it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:28,  4.41it/s, est. speed input: 2258.08 toks/s, output: 4.41 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 17.60it/s, est. speed input: 7642.74 toks/s, output: 14.93 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 24.78it/s, est. speed input: 10418.86 toks/s, output: 20.35 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 29.08it/s, est. speed input: 12114.91 toks/s, output: 23.66 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 31.80it/s, est. speed input: 13259.37 toks/s, output: 25.90 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.47it/s, est. speed input: 14063.74 toks/s, output: 27.47 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.60it/s, est. speed input: 14670.79 toks/s, output: 28.65 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 35.34it/s, est. speed input: 15141.17 toks/s, output: 29.57 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 35.89it/s, est. speed input: 15524.51 toks/s, output: 30.32 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 36.30it/s, est. speed input: 15842.40 toks/s, output: 30.94 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 36.54it/s, est. speed input: 16102.73 toks/s, output: 31.45 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 36.69it/s, est. speed input: 16321.88 toks/s, output: 31.88 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 36.79it/s, est. speed input: 16508.52 toks/s, output: 32.24 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 36.86it/s, est. speed input: 16671.26 toks/s, output: 32.56 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 36.99it/s, est. speed input: 16820.86 toks/s, output: 32.85 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 37.06it/s, est. speed input: 16951.75 toks/s, output: 33.11 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 37.12it/s, est. speed input: 17068.53 toks/s, output: 33.34 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 37.07it/s, est. speed input: 17166.32 toks/s, output: 33.53 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 37.14it/s, est. speed input: 17261.87 toks/s, output: 33.71 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 37.22it/s, est. speed input: 17350.53 toks/s, output: 33.89 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 37.29it/s, est. speed input: 17432.70 toks/s, output: 34.05 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 37.30it/s, est. speed input: 17504.75 toks/s, output: 34.19 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 37.27it/s, est. speed input: 17568.98 toks/s, output: 34.31 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 37.25it/s, est. speed input: 17627.93 toks/s, output: 34.43 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 37.27it/s, est. speed input: 17684.19 toks/s, output: 34.54 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 37.25it/s, est. speed input: 17734.77 toks/s, output: 34.64 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 37.29it/s, est. speed input: 17784.56 toks/s, output: 34.74 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 37.24it/s, est. speed input: 17826.56 toks/s, output: 34.82 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 37.20it/s, est. speed input: 17865.27 toks/s, output: 34.89 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 37.23it/s, est. speed input: 17905.12 toks/s, output: 34.97 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 37.22it/s, est. speed input: 17940.70 toks/s, output: 35.04 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 37.23it/s, est. speed input: 17974.90 toks/s, output: 35.11 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.23it/s, est. speed input: 17999.38 toks/s, output: 35.15 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.15it/s, est. speed input: 17999.38 toks/s, output: 35.15 toks/s]
[rank0]:[W128 08:38:23.650026275 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 08:38:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:38:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3317879) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3317879) WARNING 01-28 08:38:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.95 requests/s, 34794.51 total tokens/s, 33.95 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 08:38:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:38:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:38:32] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:38:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:38:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:38:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:38:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:38:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:38:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:38:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:38:39] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:38:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:38:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:38:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:38:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:38:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:38:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3317879) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3317879) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.45it/s]
(EngineCore_DP0 pid=3317879) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.45it/s]
(EngineCore_DP0 pid=3317879) 
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3317879) [2026-01-28 08:38:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3317879) 2026-01-28 08:38:58,471 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3317879) 2026-01-28 08:38:58,498 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3317879) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.07it/s]
(EngineCore_DP0 pid=3317879) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 11.82it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|██▎       | 29/128 [00:00<00:00, 285.31it/s]
Adding requests:  63%|██████▎   | 81/128 [00:00<00:00, 420.41it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 430.03it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:03, 39.62it/s, est. speed input: 40580.20 toks/s, output: 39.63 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:03, 37.94it/s, est. speed input: 39134.18 toks/s, output: 38.21 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 37.39it/s, est. speed input: 38635.65 toks/s, output: 37.73 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:02, 37.15it/s, est. speed input: 38399.45 toks/s, output: 37.50 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 36.96it/s, est. speed input: 38228.04 toks/s, output: 37.33 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 36.85it/s, est. speed input: 38109.52 toks/s, output: 37.21 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 36.79it/s, est. speed input: 38030.04 toks/s, output: 37.14 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 36.73it/s, est. speed input: 37964.01 toks/s, output: 37.07 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:00<00:02, 36.75it/s, est. speed input: 37933.17 toks/s, output: 37.04 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 36.77it/s, est. speed input: 37909.75 toks/s, output: 37.02 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 36.78it/s, est. speed input: 37888.17 toks/s, output: 37.00 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 36.77it/s, est. speed input: 37866.03 toks/s, output: 36.98 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 36.68it/s, est. speed input: 37826.79 toks/s, output: 36.94 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 36.68it/s, est. speed input: 37809.45 toks/s, output: 36.92 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 36.70it/s, est. speed input: 37797.59 toks/s, output: 36.91 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 36.73it/s, est. speed input: 37790.39 toks/s, output: 36.90 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 36.70it/s, est. speed input: 37774.30 toks/s, output: 36.89 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:01<00:01, 36.67it/s, est. speed input: 37757.81 toks/s, output: 36.87 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 36.70it/s, est. speed input: 37751.35 toks/s, output: 36.87 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 36.75it/s, est. speed input: 37752.76 toks/s, output: 36.87 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 36.82it/s, est. speed input: 37757.04 toks/s, output: 36.87 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 36.87it/s, est. speed input: 37762.44 toks/s, output: 36.88 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 36.90it/s, est. speed input: 37766.35 toks/s, output: 36.88 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 36.91it/s, est. speed input: 37768.25 toks/s, output: 36.88 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 36.93it/s, est. speed input: 37772.20 toks/s, output: 36.89 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 36.86it/s, est. speed input: 37765.07 toks/s, output: 36.88 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:02<00:00, 36.87it/s, est. speed input: 37765.89 toks/s, output: 36.88 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 36.79it/s, est. speed input: 37755.67 toks/s, output: 36.87 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 36.84it/s, est. speed input: 37758.60 toks/s, output: 36.87 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 36.84it/s, est. speed input: 37757.56 toks/s, output: 36.87 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 36.86it/s, est. speed input: 37758.93 toks/s, output: 36.87 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.86it/s, est. speed input: 37759.48 toks/s, output: 36.87 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.87it/s, est. speed input: 37759.48 toks/s, output: 36.87 toks/s]
[rank0]:[W128 08:39:04.372404508 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 08:39:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:39:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3318963) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3318963) WARNING 01-28 08:39:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 62.12 requests/s, 63672.50 total tokens/s, 62.12 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 08:39:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:39:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:39:13] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:39:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:39:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:39:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:39:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:39:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:39:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:39:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:39:20] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:39:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:39:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:39:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:39:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:39:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3318963) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3318963) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.46it/s]
(EngineCore_DP0 pid=3318963) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.46it/s]
(EngineCore_DP0 pid=3318963) 
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3318963) [2026-01-28 08:39:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3318963) 2026-01-28 08:39:39,797 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3318963) 2026-01-28 08:39:39,834 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3318963) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 11.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 11.15it/s]
(EngineCore_DP0 pid=3318963) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 14.38it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 14.37it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█▏        | 29/256 [00:00<00:00, 286.69it/s]
Adding requests:  32%|███▏      | 81/256 [00:00<00:00, 421.25it/s]
Adding requests:  51%|█████     | 130/256 [00:00<00:00, 452.40it/s]
Adding requests:  70%|██████▉   | 178/256 [00:00<00:00, 462.26it/s]
Adding requests:  89%|████████▉ | 229/256 [00:00<00:00, 478.50it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 459.99it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:01, 130.48it/s, est. speed input: 133627.37 toks/s, output: 130.48 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:00<00:02, 88.79it/s, est. speed input: 95833.80 toks/s, output: 93.58 toks/s]   
Processed prompts:  16%|█▌        | 40/256 [00:00<00:02, 81.50it/s, est. speed input: 88844.54 toks/s, output: 86.76 toks/s]
Processed prompts:  19%|█▉        | 49/256 [00:00<00:02, 80.89it/s, est. speed input: 87400.78 toks/s, output: 85.35 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:00<00:02, 74.52it/s, est. speed input: 82968.22 toks/s, output: 81.02 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:00<00:02, 73.49it/s, est. speed input: 81574.75 toks/s, output: 79.66 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:00<00:02, 72.69it/s, est. speed input: 80486.48 toks/s, output: 78.60 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:02, 72.03it/s, est. speed input: 79590.66 toks/s, output: 77.72 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:01<00:02, 71.77it/s, est. speed input: 78941.09 toks/s, output: 77.09 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:01<00:02, 71.47it/s, est. speed input: 78369.08 toks/s, output: 76.53 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:01<00:02, 71.39it/s, est. speed input: 77928.56 toks/s, output: 76.10 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:01<00:01, 71.42it/s, est. speed input: 77578.19 toks/s, output: 75.76 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:01<00:01, 71.17it/s, est. speed input: 77207.02 toks/s, output: 75.40 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:01<00:01, 70.45it/s, est. speed input: 76755.96 toks/s, output: 74.96 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:01<00:01, 69.96it/s, est. speed input: 76362.85 toks/s, output: 74.57 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:01<00:01, 69.68it/s, est. speed input: 76027.18 toks/s, output: 74.24 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:02<00:01, 69.39it/s, est. speed input: 75711.47 toks/s, output: 73.94 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:02<00:01, 69.12it/s, est. speed input: 75415.70 toks/s, output: 73.65 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:02<00:01, 68.97it/s, est. speed input: 75156.46 toks/s, output: 73.39 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:02<00:01, 69.02it/s, est. speed input: 74948.84 toks/s, output: 73.19 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:02<00:01, 69.04it/s, est. speed input: 74758.18 toks/s, output: 73.01 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:02<00:00, 69.02it/s, est. speed input: 74578.39 toks/s, output: 72.83 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:02<00:00, 69.01it/s, est. speed input: 74413.48 toks/s, output: 72.67 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:02<00:00, 69.00it/s, est. speed input: 74262.76 toks/s, output: 72.52 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:03<00:00, 69.02it/s, est. speed input: 74125.87 toks/s, output: 72.39 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:03<00:00, 68.97it/s, est. speed input: 73991.22 toks/s, output: 72.26 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:03<00:00, 68.87it/s, est. speed input: 73858.32 toks/s, output: 72.13 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:03<00:00, 68.87it/s, est. speed input: 73743.22 toks/s, output: 72.01 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:03<00:00, 68.96it/s, est. speed input: 73646.73 toks/s, output: 71.92 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 68.96it/s, est. speed input: 73582.61 toks/s, output: 71.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.85it/s, est. speed input: 73582.61 toks/s, output: 71.86 toks/s]
[rank0]:[W128 08:39:46.255226997 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 08:39:48
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:39:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3320077) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3320077) WARNING 01-28 08:40:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 85.88 requests/s, 88024.83 total tokens/s, 85.88 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 08:39:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:39:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:39:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:39:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:39:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:39:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:39:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:39:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:39:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:40:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:40:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:40:04] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:40:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:40:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:40:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:40:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:40:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3320077) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3320077) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.45it/s]
(EngineCore_DP0 pid=3320077) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.45it/s]
(EngineCore_DP0 pid=3320077) 
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3320077) [2026-01-28 08:40:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3320077) 2026-01-28 08:40:23,037 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3320077) 2026-01-28 08:40:23,064 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3320077) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 14.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 13.63it/s]
(EngineCore_DP0 pid=3320077) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  3.98it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.49it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 285.43it/s]
Adding requests:  16%|█▌        | 82/512 [00:00<00:01, 425.33it/s]
Adding requests:  26%|██▌       | 133/512 [00:00<00:00, 463.14it/s]
Adding requests:  36%|███▌      | 182/512 [00:00<00:00, 473.10it/s]
Adding requests:  46%|████▌     | 234/512 [00:00<00:00, 486.36it/s]
Adding requests:  56%|█████▌    | 285/512 [00:00<00:00, 492.22it/s]
Adding requests:  65%|██████▌   | 335/512 [00:00<00:00, 490.77it/s]
Adding requests:  76%|███████▌  | 387/512 [00:00<00:00, 497.49it/s]
Adding requests:  86%|████████▌ | 438/512 [00:00<00:00, 500.27it/s]
Adding requests:  96%|█████████▌| 489/512 [00:01<00:00, 499.90it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 483.01it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:00<00:00, 511.61it/s, est. speed input: 523964.54 toks/s, output: 511.63 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:00<00:02, 153.92it/s, est. speed input: 179191.24 toks/s, output: 174.98 toks/s]
Processed prompts:  29%|██▉       | 149/512 [00:00<00:02, 135.36it/s, est. speed input: 158991.17 toks/s, output: 155.26 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:01<00:02, 122.21it/s, est. speed input: 146942.31 toks/s, output: 143.50 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:01<00:02, 114.52it/s, est. speed input: 140178.02 toks/s, output: 136.89 toks/s]
Processed prompts:  39%|███▉      | 199/512 [00:01<00:02, 105.55it/s, est. speed input: 133666.23 toks/s, output: 130.53 toks/s]
Processed prompts:  41%|████      | 211/512 [00:01<00:02, 102.51it/s, est. speed input: 130548.41 toks/s, output: 127.49 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:01<00:02, 98.33it/s, est. speed input: 127406.47 toks/s, output: 124.42 toks/s] 
Processed prompts:  46%|████▌     | 234/512 [00:01<00:02, 96.47it/s, est. speed input: 125062.88 toks/s, output: 122.13 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:02<00:02, 95.08it/s, est. speed input: 123036.82 toks/s, output: 120.15 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:02<00:02, 94.26it/s, est. speed input: 121319.02 toks/s, output: 118.47 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:02<00:02, 93.50it/s, est. speed input: 119757.40 toks/s, output: 116.95 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:02<00:02, 93.23it/s, est. speed input: 118429.11 toks/s, output: 115.65 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:02<00:02, 92.97it/s, est. speed input: 117220.96 toks/s, output: 114.47 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:02<00:02, 92.84it/s, est. speed input: 116140.42 toks/s, output: 113.42 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:02<00:02, 92.47it/s, est. speed input: 115105.86 toks/s, output: 112.41 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:02<00:01, 92.29it/s, est. speed input: 114176.27 toks/s, output: 111.50 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:03<00:01, 93.06it/s, est. speed input: 113482.20 toks/s, output: 110.82 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:03<00:01, 92.91it/s, est. speed input: 112727.78 toks/s, output: 110.08 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:03<00:01, 92.61it/s, est. speed input: 112002.87 toks/s, output: 109.38 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:03<00:01, 92.48it/s, est. speed input: 111342.23 toks/s, output: 108.73 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:03<00:01, 92.35it/s, est. speed input: 110725.03 toks/s, output: 108.13 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:03<00:01, 92.35it/s, est. speed input: 110162.26 toks/s, output: 107.58 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:03<00:01, 92.20it/s, est. speed input: 109618.56 toks/s, output: 107.05 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:03<00:00, 92.07it/s, est. speed input: 109106.75 toks/s, output: 106.55 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:04<00:00, 91.83it/s, est. speed input: 108608.11 toks/s, output: 106.06 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:04<00:00, 93.07it/s, est. speed input: 108309.12 toks/s, output: 105.77 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:04<00:00, 92.97it/s, est. speed input: 107914.71 toks/s, output: 105.38 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:04<00:00, 92.66it/s, est. speed input: 107517.51 toks/s, output: 105.00 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:04<00:00, 92.51it/s, est. speed input: 107148.90 toks/s, output: 104.64 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:04<00:00, 92.17it/s, est. speed input: 106775.80 toks/s, output: 104.27 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:04<00:00, 93.58it/s, est. speed input: 106589.29 toks/s, output: 104.09 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 93.58it/s, est. speed input: 107000.80 toks/s, output: 104.49 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 104.49it/s, est. speed input: 107000.80 toks/s, output: 104.49 toks/s]
[rank0]:[W128 08:40:31.535240741 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 08:40:33
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:40:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3321211) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3321211) WARNING 01-28 08:40:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 94.85 requests/s, 97225.84 total tokens/s, 94.85 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 08:40:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:40:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:40:44] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:40:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:40:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:40:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:40:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:40:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:40:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:40:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:40:50] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:40:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:40:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:40:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:40:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:40:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:40:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3321211) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3321211) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=3321211) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=3321211) 
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3321211) [2026-01-28 08:40:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3321211) 2026-01-28 08:41:09,904 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3321211) 2026-01-28 08:41:09,931 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3321211) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.31it/s]
(EngineCore_DP0 pid=3321211) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 17.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 17.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 17.72it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 28/1024 [00:00<00:03, 279.70it/s]
Adding requests:   8%|▊         | 80/1024 [00:00<00:02, 416.99it/s]
Adding requests:  13%|█▎        | 131/1024 [00:00<00:01, 456.59it/s]
Adding requests:  18%|█▊        | 180/1024 [00:00<00:01, 466.75it/s]
Adding requests:  23%|██▎       | 232/1024 [00:00<00:01, 482.15it/s]
Adding requests:  28%|██▊       | 283/1024 [00:00<00:01, 488.85it/s]
Adding requests:  33%|███▎      | 333/1024 [00:00<00:01, 489.79it/s]
Adding requests:  38%|███▊      | 384/1024 [00:00<00:01, 494.35it/s]
Adding requests:  42%|████▏     | 435/1024 [00:00<00:01, 496.96it/s]
Adding requests:  47%|████▋     | 486/1024 [00:01<00:01, 499.78it/s]
Adding requests:  52%|█████▏    | 536/1024 [00:01<00:01, 483.68it/s]
Adding requests:  58%|█████▊    | 589/1024 [00:01<00:00, 496.02it/s]
Adding requests:  62%|██████▎   | 640/1024 [00:01<00:00, 500.08it/s]
Adding requests:  68%|██████▊   | 693/1024 [00:01<00:00, 507.55it/s]
Adding requests:  73%|███████▎  | 744/1024 [00:01<00:00, 504.61it/s]
Adding requests:  78%|███████▊  | 795/1024 [00:01<00:00, 503.13it/s]
Adding requests:  83%|████████▎ | 846/1024 [00:01<00:00, 495.23it/s]
Adding requests:  88%|████████▊ | 899/1024 [00:01<00:00, 505.11it/s]
Adding requests:  93%|█████████▎| 950/1024 [00:01<00:00, 505.65it/s]
Adding requests:  98%|█████████▊| 1002/1024 [00:02<00:00, 508.04it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 492.00it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:00<00:00, 1845.72it/s, est. speed input: 1890463.45 toks/s, output: 1845.85 toks/s]
Processed prompts:  37%|███▋      | 379/1024 [00:02<00:04, 161.12it/s, est. speed input: 191877.55 toks/s, output: 187.38 toks/s]   
Processed prompts:  45%|████▌     | 461/1024 [00:02<00:04, 137.76it/s, est. speed input: 165391.06 toks/s, output: 161.51 toks/s]
Processed prompts:  50%|████▉     | 510/1024 [00:03<00:04, 127.83it/s, est. speed input: 155496.76 toks/s, output: 151.85 toks/s]
Processed prompts:  53%|█████▎    | 544/1024 [00:03<00:03, 122.91it/s, est. speed input: 150846.76 toks/s, output: 147.31 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:04<00:04, 113.26it/s, est. speed input: 144888.73 toks/s, output: 141.49 toks/s]
Processed prompts:  58%|█████▊    | 590/1024 [00:04<00:03, 113.98it/s, est. speed input: 143949.58 toks/s, output: 140.58 toks/s]
Processed prompts:  59%|█████▉    | 607/1024 [00:04<00:03, 111.87it/s, est. speed input: 142374.46 toks/s, output: 139.04 toks/s]
Processed prompts:  61%|██████    | 622/1024 [00:04<00:03, 107.67it/s, est. speed input: 140476.15 toks/s, output: 137.18 toks/s]
Processed prompts:  62%|██████▏   | 635/1024 [00:04<00:03, 101.52it/s, est. speed input: 138326.40 toks/s, output: 135.08 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:04<00:03, 98.67it/s, est. speed input: 136702.04 toks/s, output: 133.50 toks/s] 
Processed prompts:  65%|██████▌   | 666/1024 [00:05<00:03, 97.80it/s, est. speed input: 135390.44 toks/s, output: 132.22 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:05<00:03, 97.11it/s, est. speed input: 134164.97 toks/s, output: 131.02 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:05<00:03, 96.43it/s, est. speed input: 132992.16 toks/s, output: 129.87 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:05<00:03, 96.15it/s, est. speed input: 131924.80 toks/s, output: 128.83 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:05<00:03, 96.05it/s, est. speed input: 130935.51 toks/s, output: 127.87 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:05<00:02, 95.81it/s, est. speed input: 129979.00 toks/s, output: 126.93 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:06<00:02, 95.71it/s, est. speed input: 129086.18 toks/s, output: 126.06 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:06<00:02, 95.60it/s, est. speed input: 128235.52 toks/s, output: 125.23 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:06<00:02, 95.38it/s, est. speed input: 127414.30 toks/s, output: 124.43 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:06<00:02, 95.43it/s, est. speed input: 126658.23 toks/s, output: 123.69 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:06<00:02, 95.32it/s, est. speed input: 125923.02 toks/s, output: 122.97 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:06<00:01, 95.21it/s, est. speed input: 125221.53 toks/s, output: 122.29 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:07<00:01, 95.25it/s, est. speed input: 124564.83 toks/s, output: 121.64 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:07<00:01, 95.17it/s, est. speed input: 123927.54 toks/s, output: 121.02 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:07<00:01, 95.20it/s, est. speed input: 123328.62 toks/s, output: 120.44 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:07<00:01, 95.08it/s, est. speed input: 122742.65 toks/s, output: 119.87 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:07<00:01, 95.25it/s, est. speed input: 122205.89 toks/s, output: 119.34 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:07<00:00, 96.50it/s, est. speed input: 121792.79 toks/s, output: 118.94 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:08<00:00, 96.16it/s, est. speed input: 121289.55 toks/s, output: 118.45 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:08<00:00, 95.81it/s, est. speed input: 120797.87 toks/s, output: 117.97 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:08<00:00, 97.03it/s, est. speed input: 120446.69 toks/s, output: 117.62 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:08<00:00, 96.41it/s, est. speed input: 119990.19 toks/s, output: 117.18 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:08<00:00, 97.37it/s, est. speed input: 119660.15 toks/s, output: 116.86 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:08<00:00, 97.37it/s, est. speed input: 120360.09 toks/s, output: 117.54 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:08<00:00, 117.54it/s, est. speed input: 120360.09 toks/s, output: 117.54 toks/s]
[rank0]:[W128 08:41:23.470293093 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 08:41:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:41:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3322491) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3322491) WARNING 01-28 08:41:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 98.07 requests/s, 100521.36 total tokens/s, 98.07 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 08:41:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:41:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:41:40] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:41:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:41:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:41:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:41:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:41:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:41:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:41:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:41:47] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:41:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:41:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:41:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:41:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:41:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:41:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3322491) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3322491) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.48it/s]
(EngineCore_DP0 pid=3322491) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.48it/s]
(EngineCore_DP0 pid=3322491) 
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3322491) [2026-01-28 08:41:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3322491) 2026-01-28 08:42:06,060 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3322491) 2026-01-28 08:42:06,087 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3322491) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  9.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 13.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 15.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 15.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 14.80it/s]
(EngineCore_DP0 pid=3322491) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  7.05it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  7.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.68it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 33/2048 [00:00<00:06, 324.31it/s]
Adding requests:   4%|▍         | 85/2048 [00:00<00:04, 436.57it/s]
Adding requests:   7%|▋         | 135/2048 [00:00<00:04, 462.76it/s]
Adding requests:   9%|▉         | 184/2048 [00:00<00:03, 472.56it/s]
Adding requests:  11%|█▏        | 235/2048 [00:00<00:03, 485.71it/s]
Adding requests:  14%|█▍        | 285/2048 [00:00<00:03, 489.82it/s]
Adding requests:  16%|█▋        | 334/2048 [00:00<00:03, 485.65it/s]
Adding requests:  19%|█▉        | 385/2048 [00:00<00:03, 491.28it/s]
Adding requests:  21%|██▏       | 436/2048 [00:00<00:03, 497.02it/s]
Adding requests:  24%|██▍       | 487/2048 [00:01<00:03, 500.12it/s]
Adding requests:  26%|██▋       | 538/2048 [00:01<00:03, 489.68it/s]
Adding requests:  29%|██▉       | 590/2048 [00:01<00:02, 498.25it/s]
Adding requests:  31%|███▏      | 641/2048 [00:01<00:02, 500.08it/s]
Adding requests:  34%|███▍      | 694/2048 [00:01<00:02, 507.24it/s]
Adding requests:  36%|███▋      | 745/2048 [00:01<00:02, 496.36it/s]
Adding requests:  39%|███▉      | 795/2048 [00:01<00:02, 495.85it/s]
Adding requests:  41%|████▏     | 845/2048 [00:01<00:02, 490.16it/s]
Adding requests:  44%|████▍     | 899/2048 [00:01<00:02, 502.15it/s]
Adding requests:  46%|████▋     | 951/2048 [00:01<00:02, 505.23it/s]
Adding requests:  49%|████▉     | 1003/2048 [00:02<00:02, 509.57it/s]
Adding requests:  52%|█████▏    | 1055/2048 [00:02<00:01, 510.62it/s]
Adding requests:  54%|█████▍    | 1107/2048 [00:02<00:01, 508.91it/s]
Adding requests:  57%|█████▋    | 1159/2048 [00:02<00:01, 510.09it/s]
Adding requests:  59%|█████▉    | 1213/2048 [00:02<00:01, 518.51it/s]
Adding requests:  62%|██████▏   | 1265/2048 [00:02<00:01, 510.92it/s]
Adding requests:  64%|██████▍   | 1317/2048 [00:02<00:01, 510.22it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:02<00:01, 512.36it/s]
Adding requests:  69%|██████▉   | 1421/2048 [00:02<00:01, 511.84it/s]
Adding requests:  72%|███████▏  | 1473/2048 [00:02<00:01, 512.73it/s]
Adding requests:  75%|███████▍  | 1526/2048 [00:03<00:01, 517.15it/s]
Adding requests:  77%|███████▋  | 1579/2048 [00:03<00:00, 518.93it/s]
Adding requests:  80%|███████▉  | 1633/2048 [00:03<00:00, 523.03it/s]
Adding requests:  82%|████████▏ | 1686/2048 [00:03<00:00, 518.62it/s]
Adding requests:  85%|████████▍ | 1739/2048 [00:03<00:00, 520.75it/s]
Adding requests:  88%|████████▊ | 1792/2048 [00:03<00:00, 517.68it/s]
Adding requests:  90%|█████████ | 1845/2048 [00:03<00:00, 519.60it/s]
Adding requests:  93%|█████████▎| 1897/2048 [00:03<00:00, 503.20it/s]
Adding requests:  95%|█████████▌| 1948/2048 [00:03<00:00, 504.70it/s]
Adding requests:  98%|█████████▊| 2000/2048 [00:03<00:00, 508.40it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 502.83it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:00<00:01, 1598.22it/s, est. speed input: 1636869.84 toks/s, output: 1598.30 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:01<00:06, 246.64it/s, est. speed input: 308562.51 toks/s, output: 301.32 toks/s]   
Processed prompts:  31%|███       | 634/2048 [00:02<00:07, 199.68it/s, est. speed input: 257598.81 toks/s, output: 251.56 toks/s]
Processed prompts:  33%|███▎      | 678/2048 [00:03<00:08, 170.57it/s, est. speed input: 230949.63 toks/s, output: 225.54 toks/s]
Processed prompts:  35%|███▍      | 709/2048 [00:03<00:08, 154.95it/s, est. speed input: 217712.85 toks/s, output: 212.61 toks/s]
Processed prompts:  36%|███▌      | 732/2048 [00:03<00:08, 153.39it/s, est. speed input: 214398.68 toks/s, output: 209.37 toks/s]
Processed prompts:  37%|███▋      | 752/2048 [00:03<00:08, 148.87it/s, est. speed input: 210523.18 toks/s, output: 205.59 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:03<00:10, 120.84it/s, est. speed input: 198167.76 toks/s, output: 193.52 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:04<00:10, 116.70it/s, est. speed input: 194299.74 toks/s, output: 189.74 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:04<00:11, 112.80it/s, est. speed input: 190714.50 toks/s, output: 186.24 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:04<00:11, 109.41it/s, est. speed input: 187401.05 toks/s, output: 183.01 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:04<00:11, 106.76it/s, est. speed input: 184365.91 toks/s, output: 180.04 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:04<00:11, 104.86it/s, est. speed input: 181589.29 toks/s, output: 177.33 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:04<00:11, 103.24it/s, est. speed input: 178962.66 toks/s, output: 174.77 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:05<00:11, 101.93it/s, est. speed input: 176485.85 toks/s, output: 172.35 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:05<00:11, 100.87it/s, est. speed input: 174142.49 toks/s, output: 170.06 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:05<00:11, 100.02it/s, est. speed input: 171928.18 toks/s, output: 167.90 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:05<00:11, 100.60it/s, est. speed input: 170038.97 toks/s, output: 166.05 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:05<00:11, 100.12it/s, est. speed input: 168112.13 toks/s, output: 164.17 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:05<00:10, 99.53it/s, est. speed input: 166252.19 toks/s, output: 162.35 toks/s] 
Processed prompts:  48%|████▊     | 978/2048 [00:06<00:10, 100.43it/s, est. speed input: 164684.97 toks/s, output: 160.82 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:06<00:10, 99.61it/s, est. speed input: 162989.92 toks/s, output: 159.17 toks/s] 
Processed prompts:  49%|████▉     | 1010/2048 [00:06<00:10, 99.11it/s, est. speed input: 161392.13 toks/s, output: 157.61 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:06<00:10, 98.80it/s, est. speed input: 159879.24 toks/s, output: 156.13 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:06<00:10, 98.63it/s, est. speed input: 158445.57 toks/s, output: 154.73 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:06<00:10, 98.63it/s, est. speed input: 157093.60 toks/s, output: 153.41 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:07<00:09, 98.61it/s, est. speed input: 155802.41 toks/s, output: 152.15 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:07<00:09, 98.55it/s, est. speed input: 154563.52 toks/s, output: 150.94 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:07<00:09, 98.29it/s, est. speed input: 153353.55 toks/s, output: 149.76 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:07<00:09, 98.11it/s, est. speed input: 152197.38 toks/s, output: 148.63 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:07<00:09, 98.12it/s, est. speed input: 151104.03 toks/s, output: 147.56 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:07<00:08, 99.51it/s, est. speed input: 150200.39 toks/s, output: 146.68 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:08<00:08, 99.19it/s, est. speed input: 149200.73 toks/s, output: 145.70 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:08<00:08, 98.95it/s, est. speed input: 148239.00 toks/s, output: 144.76 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:08<00:08, 98.60it/s, est. speed input: 147297.39 toks/s, output: 143.84 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:08<00:08, 98.62it/s, est. speed input: 146416.45 toks/s, output: 142.98 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:08<00:08, 98.48it/s, est. speed input: 145554.53 toks/s, output: 142.14 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:08<00:08, 98.26it/s, est. speed input: 144713.82 toks/s, output: 141.32 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:09<00:07, 99.64it/s, est. speed input: 144036.84 toks/s, output: 140.66 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:09<00:07, 99.21it/s, est. speed input: 143263.69 toks/s, output: 139.91 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:09<00:07, 98.78it/s, est. speed input: 142507.29 toks/s, output: 139.17 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:09<00:07, 98.40it/s, est. speed input: 141770.66 toks/s, output: 138.45 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:09<00:07, 98.26it/s, est. speed input: 141068.72 toks/s, output: 137.76 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:09<00:07, 98.17it/s, est. speed input: 140390.50 toks/s, output: 137.10 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:09<00:06, 98.29it/s, est. speed input: 139748.39 toks/s, output: 136.47 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:10<00:06, 98.23it/s, est. speed input: 139116.86 toks/s, output: 135.86 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:10<00:06, 98.12it/s, est. speed input: 138499.82 toks/s, output: 135.25 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:10<00:06, 97.91it/s, est. speed input: 137892.29 toks/s, output: 134.66 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:10<00:06, 98.04it/s, est. speed input: 137322.88 toks/s, output: 134.10 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:10<00:06, 98.02it/s, est. speed input: 136763.56 toks/s, output: 133.56 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:10<00:06, 98.15it/s, est. speed input: 136230.49 toks/s, output: 133.04 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:11<00:05, 98.35it/s, est. speed input: 135720.04 toks/s, output: 132.54 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:11<00:05, 98.30it/s, est. speed input: 135212.31 toks/s, output: 132.04 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:11<00:05, 97.79it/s, est. speed input: 134687.61 toks/s, output: 131.53 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:11<00:05, 97.93it/s, est. speed input: 134209.74 toks/s, output: 131.06 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:11<00:05, 97.82it/s, est. speed input: 133732.06 toks/s, output: 130.60 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:11<00:05, 98.08it/s, est. speed input: 133288.56 toks/s, output: 130.16 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:12<00:04, 98.37it/s, est. speed input: 132862.98 toks/s, output: 129.75 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:12<00:04, 99.57it/s, est. speed input: 132507.49 toks/s, output: 129.40 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:12<00:04, 99.34it/s, est. speed input: 132098.93 toks/s, output: 129.00 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:12<00:04, 98.99it/s, est. speed input: 131690.48 toks/s, output: 128.60 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:12<00:04, 98.62it/s, est. speed input: 131284.84 toks/s, output: 128.21 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:12<00:04, 98.28it/s, est. speed input: 130884.93 toks/s, output: 127.82 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:13<00:03, 98.23it/s, est. speed input: 130505.36 toks/s, output: 127.45 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:13<00:03, 98.14it/s, est. speed input: 130132.19 toks/s, output: 127.08 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:13<00:03, 98.04it/s, est. speed input: 129766.27 toks/s, output: 126.72 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:13<00:03, 98.17it/s, est. speed input: 129419.91 toks/s, output: 126.39 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:13<00:03, 97.87it/s, est. speed input: 129061.12 toks/s, output: 126.04 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:13<00:03, 97.94it/s, est. speed input: 128725.25 toks/s, output: 125.71 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:14<00:02, 97.85it/s, est. speed input: 128389.81 toks/s, output: 125.38 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:14<00:02, 97.80it/s, est. speed input: 128063.36 toks/s, output: 125.06 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:14<00:02, 97.94it/s, est. speed input: 127752.81 toks/s, output: 124.76 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:14<00:02, 98.19it/s, est. speed input: 127456.48 toks/s, output: 124.47 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:14<00:02, 98.06it/s, est. speed input: 127151.77 toks/s, output: 124.17 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:14<00:02, 97.86it/s, est. speed input: 126849.07 toks/s, output: 123.88 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:15<00:01, 97.89it/s, est. speed input: 126560.42 toks/s, output: 123.59 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:15<00:01, 99.09it/s, est. speed input: 126332.38 toks/s, output: 123.37 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:15<00:01, 98.74it/s, est. speed input: 126055.24 toks/s, output: 123.10 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:15<00:01, 98.52it/s, est. speed input: 125785.06 toks/s, output: 122.84 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:15<00:01, 98.52it/s, est. speed input: 125526.80 toks/s, output: 122.58 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:15<00:01, 98.22it/s, est. speed input: 125261.06 toks/s, output: 122.32 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:16<00:00, 99.25it/s, est. speed input: 125054.02 toks/s, output: 122.12 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:16<00:00, 98.89it/s, est. speed input: 124805.31 toks/s, output: 121.88 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:16<00:00, 98.46it/s, est. speed input: 124553.95 toks/s, output: 121.63 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:16<00:00, 98.31it/s, est. speed input: 124313.72 toks/s, output: 121.40 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:16<00:00, 98.11it/s, est. speed input: 124074.64 toks/s, output: 121.17 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:16<00:00, 100.05it/s, est. speed input: 123922.94 toks/s, output: 121.02 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:16<00:00, 100.05it/s, est. speed input: 124772.87 toks/s, output: 121.85 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:16<00:00, 121.85it/s, est. speed input: 124772.87 toks/s, output: 121.85 toks/s]
[rank0]:[W128 08:42:29.859644004 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 08:42:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:42:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3323979) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3323979) WARNING 01-28 08:43:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 99.96 requests/s, 102454.71 total tokens/s, 99.96 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 08:42:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:42:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:42:55] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:42:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:42:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:42:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:42:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:42:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:42:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:43:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:43:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:43:02] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:43:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:43:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:43:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:43:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:43:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:43:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3323979) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3323979) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.46it/s]
(EngineCore_DP0 pid=3323979) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.46it/s]
(EngineCore_DP0 pid=3323979) 
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8232960 bytes
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5488640 bytes
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29638656 bytes
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3323979) [2026-01-28 08:43:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14745600 bytes
(EngineCore_DP0 pid=3323979) [rank0]:W0128 08:43:16.712000 3323979 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3323979) [rank0]:W0128 08:43:16.789000 3323979 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3323979) [rank0]:W0128 08:43:17.882000 3323979 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3323979) [rank0]:W0128 08:43:18.004000 3323979 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3323979) 2026-01-28 08:43:21,918 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3323979) 2026-01-28 08:43:21,947 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3323979) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  4.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  9.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 11.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 13.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 14.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 14.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 12.79it/s]
(EngineCore_DP0 pid=3323979) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 16.01it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 16.90it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 11.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 11.25it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 36/4096 [00:00<00:11, 354.15it/s]
Adding requests:   2%|▏         | 88/4096 [00:00<00:08, 445.95it/s]
Adding requests:   3%|▎         | 138/4096 [00:00<00:08, 469.61it/s]
Adding requests:   5%|▍         | 188/4096 [00:00<00:08, 476.09it/s]
Adding requests:   6%|▌         | 239/4096 [00:00<00:07, 488.17it/s]
Adding requests:   7%|▋         | 289/4096 [00:00<00:07, 491.24it/s]
Adding requests:   8%|▊         | 339/4096 [00:00<00:07, 490.54it/s]
Adding requests:  10%|▉         | 391/4096 [00:00<00:07, 498.87it/s]
Adding requests:  11%|█         | 441/4096 [00:00<00:07, 497.35it/s]
Adding requests:  12%|█▏        | 492/4096 [00:01<00:07, 500.44it/s]
Adding requests:  13%|█▎        | 543/4096 [00:01<00:07, 492.05it/s]
Adding requests:  15%|█▍        | 596/4096 [00:01<00:07, 499.60it/s]
Adding requests:  16%|█▌        | 648/4096 [00:01<00:06, 504.05it/s]
Adding requests:  17%|█▋        | 701/4096 [00:01<00:06, 510.87it/s]
Adding requests:  18%|█▊        | 753/4096 [00:01<00:06, 508.77it/s]
Adding requests:  20%|█▉        | 804/4096 [00:01<00:06, 502.89it/s]
Adding requests:  21%|██        | 855/4096 [00:01<00:06, 498.62it/s]
Adding requests:  22%|██▏       | 907/4096 [00:01<00:06, 504.57it/s]
Adding requests:  23%|██▎       | 959/4096 [00:01<00:06, 508.48it/s]
Adding requests:  25%|██▍       | 1011/4096 [00:02<00:06, 510.57it/s]
Adding requests:  26%|██▌       | 1063/4096 [00:02<00:05, 509.32it/s]
Adding requests:  27%|██▋       | 1114/4096 [00:02<00:05, 502.33it/s]
Adding requests:  28%|██▊       | 1167/4096 [00:02<00:05, 509.07it/s]
Adding requests:  30%|██▉       | 1218/4096 [00:02<00:05, 504.79it/s]
Adding requests:  31%|███       | 1269/4096 [00:02<00:05, 500.92it/s]
Adding requests:  32%|███▏      | 1321/4096 [00:02<00:05, 504.68it/s]
Adding requests:  34%|███▎      | 1374/4096 [00:02<00:05, 509.56it/s]
Adding requests:  35%|███▍      | 1426/4096 [00:02<00:05, 512.37it/s]
Adding requests:  36%|███▌      | 1478/4096 [00:02<00:05, 512.23it/s]
Adding requests:  37%|███▋      | 1531/4096 [00:03<00:04, 517.25it/s]
Adding requests:  39%|███▊      | 1583/4096 [00:03<00:04, 515.61it/s]
Adding requests:  40%|███▉      | 1637/4096 [00:03<00:04, 520.42it/s]
Adding requests:  41%|████▏     | 1690/4096 [00:03<00:04, 512.99it/s]
Adding requests:  43%|████▎     | 1743/4096 [00:03<00:04, 515.77it/s]
Adding requests:  44%|████▍     | 1795/4096 [00:03<00:04, 512.32it/s]
Adding requests:  45%|████▌     | 1847/4096 [00:03<00:04, 513.38it/s]
Adding requests:  46%|████▋     | 1899/4096 [00:03<00:04, 510.75it/s]
Adding requests:  48%|████▊     | 1951/4096 [00:03<00:04, 508.56it/s]
Adding requests:  49%|████▉     | 2004/4096 [00:03<00:04, 513.05it/s]
Adding requests:  50%|█████     | 2056/4096 [00:04<00:03, 513.05it/s]
Adding requests:  51%|█████▏    | 2109/4096 [00:04<00:03, 517.84it/s]
Adding requests:  53%|█████▎    | 2161/4096 [00:04<00:03, 507.59it/s]
Adding requests:  54%|█████▍    | 2212/4096 [00:04<00:03, 506.16it/s]
Adding requests:  55%|█████▌    | 2264/4096 [00:04<00:03, 510.13it/s]
Adding requests:  57%|█████▋    | 2317/4096 [00:04<00:03, 514.79it/s]
Adding requests:  58%|█████▊    | 2369/4096 [00:04<00:03, 511.90it/s]
Adding requests:  59%|█████▉    | 2421/4096 [00:04<00:03, 500.30it/s]
Adding requests:  60%|██████    | 2472/4096 [00:04<00:03, 502.80it/s]
Adding requests:  62%|██████▏   | 2523/4096 [00:05<00:03, 501.63it/s]
Adding requests:  63%|██████▎   | 2576/4096 [00:05<00:02, 509.40it/s]
Adding requests:  64%|██████▍   | 2627/4096 [00:05<00:02, 507.96it/s]
Adding requests:  65%|██████▌   | 2679/4096 [00:05<00:02, 509.78it/s]
Adding requests:  67%|██████▋   | 2730/4096 [00:05<00:02, 507.54it/s]
Adding requests:  68%|██████▊   | 2781/4096 [00:05<00:02, 507.97it/s]
Adding requests:  69%|██████▉   | 2832/4096 [00:05<00:02, 504.89it/s]
Adding requests:  70%|███████   | 2885/4096 [00:05<00:02, 510.03it/s]
Adding requests:  72%|███████▏  | 2937/4096 [00:05<00:02, 506.31it/s]
Adding requests:  73%|███████▎  | 2990/4096 [00:05<00:02, 511.83it/s]
Adding requests:  74%|███████▍  | 3042/4096 [00:06<00:02, 510.99it/s]
Adding requests:  76%|███████▌  | 3094/4096 [00:06<00:01, 507.68it/s]
Adding requests:  77%|███████▋  | 3145/4096 [00:06<00:01, 505.11it/s]
Adding requests:  78%|███████▊  | 3196/4096 [00:06<00:01, 505.83it/s]
Adding requests:  79%|███████▉  | 3249/4096 [00:06<00:01, 511.67it/s]
Adding requests:  81%|████████  | 3301/4096 [00:06<00:01, 510.39it/s]
Adding requests:  82%|████████▏ | 3353/4096 [00:06<00:01, 512.74it/s]
Adding requests:  83%|████████▎ | 3405/4096 [00:06<00:01, 510.86it/s]
Adding requests:  84%|████████▍ | 3457/4096 [00:06<00:01, 507.96it/s]
Adding requests:  86%|████████▌ | 3508/4096 [00:06<00:01, 502.87it/s]
Adding requests:  87%|████████▋ | 3559/4096 [00:07<00:01, 501.24it/s]
Adding requests:  88%|████████▊ | 3610/4096 [00:07<00:00, 495.71it/s]
Adding requests:  89%|████████▉ | 3660/4096 [00:07<00:00, 492.12it/s]
Adding requests:  91%|█████████ | 3712/4096 [00:07<00:00, 498.42it/s]
Adding requests:  92%|█████████▏| 3762/4096 [00:07<00:00, 482.53it/s]
Adding requests:  93%|█████████▎| 3814/4096 [00:07<00:00, 491.51it/s]
Adding requests:  94%|█████████▍| 3867/4096 [00:07<00:00, 501.82it/s]
Adding requests:  96%|█████████▌| 3919/4096 [00:07<00:00, 505.52it/s]
Adding requests:  97%|█████████▋| 3971/4096 [00:07<00:00, 507.85it/s]
Adding requests:  98%|█████████▊| 4023/4096 [00:07<00:00, 510.08it/s]
Adding requests:  99%|█████████▉| 4075/4096 [00:08<00:00, 503.06it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 504.56it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▉        | 796/4096 [00:00<00:00, 3406.18it/s, est. speed input: 3488262.72 toks/s, output: 3406.28 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:03<00:11, 268.59it/s, est. speed input: 341016.53 toks/s, output: 333.02 toks/s]  
Processed prompts:  31%|███▏      | 1284/4096 [00:04<00:14, 197.66it/s, est. speed input: 263075.91 toks/s, output: 256.91 toks/s]
Processed prompts:  33%|███▎      | 1368/4096 [00:05<00:14, 184.92it/s, est. speed input: 248310.32 toks/s, output: 242.49 toks/s]
Processed prompts:  35%|███▍      | 1424/4096 [00:06<00:16, 164.20it/s, est. speed input: 232121.84 toks/s, output: 226.68 toks/s]
Processed prompts:  36%|███▌      | 1463/4096 [00:06<00:16, 158.55it/s, est. speed input: 226879.08 toks/s, output: 221.56 toks/s]
Processed prompts:  36%|███▋      | 1493/4096 [00:06<00:17, 148.15it/s, est. speed input: 220765.62 toks/s, output: 215.59 toks/s]
Processed prompts:  37%|███▋      | 1517/4096 [00:07<00:19, 134.59it/s, est. speed input: 214375.26 toks/s, output: 209.35 toks/s]
Processed prompts:  38%|███▊      | 1536/4096 [00:07<00:21, 118.88it/s, est. speed input: 207867.03 toks/s, output: 202.99 toks/s]
Processed prompts:  38%|███▊      | 1564/4096 [00:07<00:22, 111.70it/s, est. speed input: 203073.27 toks/s, output: 198.31 toks/s]
Processed prompts:  39%|███▉      | 1596/4096 [00:08<00:22, 109.70it/s, est. speed input: 199403.40 toks/s, output: 194.73 toks/s]
Processed prompts:  40%|███▉      | 1628/4096 [00:08<00:23, 107.01it/s, est. speed input: 195719.71 toks/s, output: 191.13 toks/s]
Processed prompts:  41%|████      | 1660/4096 [00:08<00:23, 104.90it/s, est. speed input: 192290.24 toks/s, output: 187.78 toks/s]
Processed prompts:  41%|████▏     | 1692/4096 [00:09<00:23, 103.31it/s, est. speed input: 189099.93 toks/s, output: 184.67 toks/s]
Processed prompts:  42%|████▏     | 1724/4096 [00:09<00:23, 102.20it/s, est. speed input: 186137.84 toks/s, output: 181.77 toks/s]
Processed prompts:  43%|████▎     | 1756/4096 [00:09<00:23, 101.38it/s, est. speed input: 183368.38 toks/s, output: 179.07 toks/s]
Processed prompts:  44%|████▎     | 1788/4096 [00:10<00:22, 101.01it/s, est. speed input: 180815.05 toks/s, output: 176.58 toks/s]
Processed prompts:  44%|████▍     | 1820/4096 [00:10<00:22, 100.57it/s, est. speed input: 178385.96 toks/s, output: 174.20 toks/s]
Processed prompts:  45%|████▌     | 1852/4096 [00:10<00:22, 101.23it/s, est. speed input: 176274.12 toks/s, output: 172.14 toks/s]
Processed prompts:  46%|████▌     | 1884/4096 [00:11<00:21, 100.63it/s, est. speed input: 174100.35 toks/s, output: 170.02 toks/s]
Processed prompts:  47%|████▋     | 1916/4096 [00:11<00:21, 100.12it/s, est. speed input: 172036.35 toks/s, output: 168.00 toks/s]
Processed prompts:  48%|████▊     | 1948/4096 [00:11<00:21, 100.83it/s, est. speed input: 170250.90 toks/s, output: 166.26 toks/s]
Processed prompts:  48%|████▊     | 1980/4096 [00:12<00:21, 100.57it/s, est. speed input: 168445.11 toks/s, output: 164.50 toks/s]
Processed prompts:  49%|████▉     | 2012/4096 [00:12<00:20, 100.42it/s, est. speed input: 166736.95 toks/s, output: 162.83 toks/s]
Processed prompts:  50%|████▉     | 2044/4096 [00:12<00:20, 100.23it/s, est. speed input: 165104.65 toks/s, output: 161.23 toks/s]
Processed prompts:  51%|█████     | 2076/4096 [00:12<00:20, 100.19it/s, est. speed input: 163564.44 toks/s, output: 159.73 toks/s]
Processed prompts:  51%|█████▏    | 2108/4096 [00:13<00:19, 100.37it/s, est. speed input: 162126.03 toks/s, output: 158.33 toks/s]
Processed prompts:  52%|█████▏    | 2140/4096 [00:13<00:19, 100.03it/s, est. speed input: 160695.31 toks/s, output: 156.93 toks/s]
Processed prompts:  53%|█████▎    | 2172/4096 [00:13<00:19, 100.08it/s, est. speed input: 159365.71 toks/s, output: 155.63 toks/s]
Processed prompts:  54%|█████▍    | 2204/4096 [00:14<00:18, 99.96it/s, est. speed input: 158077.35 toks/s, output: 154.37 toks/s] 
Processed prompts:  55%|█████▍    | 2236/4096 [00:14<00:18, 101.38it/s, est. speed input: 157016.08 toks/s, output: 153.34 toks/s]
Processed prompts:  55%|█████▌    | 2268/4096 [00:14<00:18, 101.05it/s, est. speed input: 155853.59 toks/s, output: 152.20 toks/s]
Processed prompts:  56%|█████▌    | 2300/4096 [00:15<00:17, 101.53it/s, est. speed input: 154814.12 toks/s, output: 151.19 toks/s]
Processed prompts:  57%|█████▋    | 2332/4096 [00:15<00:17, 101.90it/s, est. speed input: 153820.02 toks/s, output: 150.21 toks/s]
Processed prompts:  58%|█████▊    | 2364/4096 [00:15<00:16, 102.99it/s, est. speed input: 152945.96 toks/s, output: 149.36 toks/s]
Processed prompts:  58%|█████▊    | 2396/4096 [00:16<00:16, 102.14it/s, est. speed input: 151950.70 toks/s, output: 148.39 toks/s]
Processed prompts:  59%|█████▉    | 2428/4096 [00:16<00:16, 101.49it/s, est. speed input: 150987.77 toks/s, output: 147.45 toks/s]
Processed prompts:  60%|██████    | 2460/4096 [00:16<00:16, 101.03it/s, est. speed input: 150060.88 toks/s, output: 146.54 toks/s]
Processed prompts:  61%|██████    | 2492/4096 [00:17<00:15, 101.64it/s, est. speed input: 149252.91 toks/s, output: 145.75 toks/s]
Processed prompts:  62%|██████▏   | 2524/4096 [00:17<00:15, 101.00it/s, est. speed input: 148379.53 toks/s, output: 144.90 toks/s]
Processed prompts:  62%|██████▏   | 2556/4096 [00:17<00:15, 100.47it/s, est. speed input: 147530.19 toks/s, output: 144.07 toks/s]
Processed prompts:  63%|██████▎   | 2588/4096 [00:18<00:14, 101.00it/s, est. speed input: 146788.15 toks/s, output: 143.35 toks/s]
Processed prompts:  64%|██████▍   | 2620/4096 [00:18<00:14, 100.52it/s, est. speed input: 146000.17 toks/s, output: 142.58 toks/s]
Processed prompts:  65%|██████▍   | 2652/4096 [00:18<00:14, 100.34it/s, est. speed input: 145252.05 toks/s, output: 141.85 toks/s]
Processed prompts:  66%|██████▌   | 2684/4096 [00:19<00:14, 100.16it/s, est. speed input: 144524.76 toks/s, output: 141.14 toks/s]
Processed prompts:  66%|██████▋   | 2716/4096 [00:19<00:13, 100.17it/s, est. speed input: 143832.52 toks/s, output: 140.46 toks/s]
Processed prompts:  67%|██████▋   | 2748/4096 [00:19<00:13, 100.04it/s, est. speed input: 143151.54 toks/s, output: 139.80 toks/s]
Processed prompts:  68%|██████▊   | 2780/4096 [00:19<00:13, 99.84it/s, est. speed input: 142484.27 toks/s, output: 139.14 toks/s] 
Processed prompts:  69%|██████▊   | 2812/4096 [00:20<00:12, 99.67it/s, est. speed input: 141836.40 toks/s, output: 138.51 toks/s]
Processed prompts:  69%|██████▉   | 2844/4096 [00:20<00:12, 99.62it/s, est. speed input: 141213.06 toks/s, output: 137.90 toks/s]
Processed prompts:  70%|███████   | 2876/4096 [00:20<00:12, 99.66it/s, est. speed input: 140615.16 toks/s, output: 137.32 toks/s]
Processed prompts:  71%|███████   | 2908/4096 [00:21<00:11, 99.77it/s, est. speed input: 140040.14 toks/s, output: 136.76 toks/s]
Processed prompts:  72%|███████▏  | 2940/4096 [00:21<00:11, 99.67it/s, est. speed input: 139470.40 toks/s, output: 136.20 toks/s]
Processed prompts:  73%|███████▎  | 2972/4096 [00:21<00:11, 99.88it/s, est. speed input: 138936.20 toks/s, output: 135.68 toks/s]
Processed prompts:  73%|███████▎  | 3004/4096 [00:22<00:10, 99.76it/s, est. speed input: 138399.94 toks/s, output: 135.16 toks/s]
Processed prompts:  74%|███████▍  | 3036/4096 [00:22<00:10, 99.70it/s, est. speed input: 137880.47 toks/s, output: 134.65 toks/s]
Processed prompts:  75%|███████▍  | 3068/4096 [00:22<00:10, 99.67it/s, est. speed input: 137376.29 toks/s, output: 134.16 toks/s]
Processed prompts:  76%|███████▌  | 3100/4096 [00:23<00:09, 99.69it/s, est. speed input: 136888.45 toks/s, output: 133.68 toks/s]
Processed prompts:  76%|███████▋  | 3132/4096 [00:23<00:09, 100.45it/s, est. speed input: 136460.40 toks/s, output: 133.26 toks/s]
Processed prompts:  77%|███████▋  | 3164/4096 [00:23<00:09, 100.06it/s, est. speed input: 135987.47 toks/s, output: 132.80 toks/s]
Processed prompts:  78%|███████▊  | 3196/4096 [00:24<00:09, 99.80it/s, est. speed input: 135527.95 toks/s, output: 132.35 toks/s] 
Processed prompts:  79%|███████▉  | 3228/4096 [00:24<00:08, 99.75it/s, est. speed input: 135088.03 toks/s, output: 131.92 toks/s]
Processed prompts:  80%|███████▉  | 3260/4096 [00:24<00:08, 99.02it/s, est. speed input: 134618.64 toks/s, output: 131.46 toks/s]
Processed prompts:  80%|████████  | 3292/4096 [00:25<00:08, 99.50it/s, est. speed input: 134219.37 toks/s, output: 131.07 toks/s]
Processed prompts:  81%|████████  | 3324/4096 [00:25<00:07, 99.48it/s, est. speed input: 133809.59 toks/s, output: 130.67 toks/s]
Processed prompts:  82%|████████▏ | 3356/4096 [00:25<00:07, 99.42it/s, est. speed input: 133406.84 toks/s, output: 130.28 toks/s]
Processed prompts:  83%|████████▎ | 3388/4096 [00:26<00:07, 99.46it/s, est. speed input: 133019.34 toks/s, output: 129.90 toks/s]
Processed prompts:  83%|████████▎ | 3420/4096 [00:26<00:06, 99.33it/s, est. speed input: 132632.53 toks/s, output: 129.52 toks/s]
Processed prompts:  84%|████████▍ | 3452/4096 [00:26<00:06, 99.44it/s, est. speed input: 132265.49 toks/s, output: 129.17 toks/s]
Processed prompts:  85%|████████▌ | 3484/4096 [00:27<00:06, 100.95it/s, est. speed input: 131981.89 toks/s, output: 128.89 toks/s]
Processed prompts:  86%|████████▌ | 3516/4096 [00:27<00:05, 100.49it/s, est. speed input: 131627.04 toks/s, output: 128.54 toks/s]
Processed prompts:  87%|████████▋ | 3548/4096 [00:27<00:05, 100.20it/s, est. speed input: 131281.66 toks/s, output: 128.20 toks/s]
Processed prompts:  87%|████████▋ | 3580/4096 [00:27<00:05, 100.01it/s, est. speed input: 130945.02 toks/s, output: 127.88 toks/s]
Processed prompts:  88%|████████▊ | 3612/4096 [00:28<00:04, 99.83it/s, est. speed input: 130613.78 toks/s, output: 127.55 toks/s] 
Processed prompts:  89%|████████▉ | 3644/4096 [00:28<00:04, 99.61it/s, est. speed input: 130285.43 toks/s, output: 127.23 toks/s]
Processed prompts:  90%|████████▉ | 3676/4096 [00:28<00:04, 99.52it/s, est. speed input: 129967.03 toks/s, output: 126.92 toks/s]
Processed prompts:  91%|█████████ | 3708/4096 [00:29<00:03, 99.46it/s, est. speed input: 129656.05 toks/s, output: 126.62 toks/s]
Processed prompts:  91%|█████████▏| 3740/4096 [00:29<00:03, 100.25it/s, est. speed input: 129390.70 toks/s, output: 126.36 toks/s]
Processed prompts:  92%|█████████▏| 3772/4096 [00:29<00:03, 99.90it/s, est. speed input: 129089.55 toks/s, output: 126.06 toks/s] 
Processed prompts:  93%|█████████▎| 3804/4096 [00:30<00:02, 99.77it/s, est. speed input: 128799.97 toks/s, output: 125.78 toks/s]
Processed prompts:  94%|█████████▎| 3836/4096 [00:30<00:02, 100.50it/s, est. speed input: 128552.95 toks/s, output: 125.54 toks/s]
Processed prompts:  94%|█████████▍| 3868/4096 [00:30<00:02, 100.13it/s, est. speed input: 128272.33 toks/s, output: 125.27 toks/s]
Processed prompts:  95%|█████████▌| 3900/4096 [00:31<00:01, 99.96it/s, est. speed input: 128001.26 toks/s, output: 125.00 toks/s] 
Processed prompts:  96%|█████████▌| 3932/4096 [00:31<00:01, 99.77it/s, est. speed input: 127732.51 toks/s, output: 124.74 toks/s]
Processed prompts:  97%|█████████▋| 3964/4096 [00:31<00:01, 99.56it/s, est. speed input: 127466.07 toks/s, output: 124.48 toks/s]
Processed prompts:  98%|█████████▊| 3996/4096 [00:32<00:01, 99.42it/s, est. speed input: 127205.26 toks/s, output: 124.22 toks/s]
Processed prompts:  98%|█████████▊| 4028/4096 [00:32<00:00, 100.44it/s, est. speed input: 126996.22 toks/s, output: 124.02 toks/s]
Processed prompts:  99%|█████████▉| 4060/4096 [00:32<00:00, 100.21it/s, est. speed input: 126752.28 toks/s, output: 123.78 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:32<00:00, 100.21it/s, est. speed input: 127653.86 toks/s, output: 124.66 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:32<00:00, 124.66it/s, est. speed input: 127653.86 toks/s, output: 124.66 toks/s]
[rank0]:[W128 08:44:06.374930994 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

