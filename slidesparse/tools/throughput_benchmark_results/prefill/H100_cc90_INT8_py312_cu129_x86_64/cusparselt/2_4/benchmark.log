
========== M=512 ==========
Time: 2026-01-25 15:58:12
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 15:58:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=157791) [INFO] Compress extension not found, building...
(EngineCore_DP0 pid=157791) ============================================================
(EngineCore_DP0 pid=157791) cuSPARSELt Compress Extension Builder
(EngineCore_DP0 pid=157791) ============================================================
(EngineCore_DP0 pid=157791) Extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64
(EngineCore_DP0 pid=157791) Source: cusparselt_compress.cu
(EngineCore_DP0 pid=157791) Build dir: /root/vllmbench/slidesparse/weight_convert/build
(EngineCore_DP0 pid=157791) ------------------------------------------------------------
(EngineCore_DP0 pid=157791) GPU: H100 (NVIDIA H100 PCIe)
(EngineCore_DP0 pid=157791) CC: cc90 (sm_90)
(EngineCore_DP0 pid=157791) Python: py312
(EngineCore_DP0 pid=157791) CUDA: cu129
(EngineCore_DP0 pid=157791) Arch: x86_64
(EngineCore_DP0 pid=157791) ============================================================
(EngineCore_DP0 pid=157791) ðŸ”¨ Building cusparselt_compress_H100_cc90_py312_cu129_x86_64...
(EngineCore_DP0 pid=157791) Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/weight_convert/cusparselt_compress.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcuda -o /root/vllmbench/slidesparse/weight_convert/build/cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=157791) âœ“ Built: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=157791) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=157791) WARNING 01-25 15:58:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.86 requests/s, 17369.61 total tokens/s, 33.86 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-25 15:58:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 15:58:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 15:58:19] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:19] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 15:58:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:19] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:19] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 15:58:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:19] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:19] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:19] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 15:58:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:19] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 15:58:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 15:58:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 15:58:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 15:58:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 15:58:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 15:58:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 15:58:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 15:58:26] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:26] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 15:58:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:26] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:26] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 15:58:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:26] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:26] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:26] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 15:58:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:26] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:58:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:58:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 15:58:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 15:58:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 15:58:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 15:58:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 15:58:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:28] INFO gemm_wrapper.py:85: Auto-building cusparselt GEMM library from /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py...
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO gemm_wrapper.py:95: cusparselt GEMM library build completed
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=157791) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=157791) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.60it/s]
(EngineCore_DP0 pid=157791) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.60it/s]
(EngineCore_DP0 pid=157791) 
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=157791) [2026-01-25 15:58:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=157791) [2026-01-25 15:59:00] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=157791) 2026-01-25 15:59:06,369 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=157791) 2026-01-25 15:59:06,418 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=157791) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  2.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=157791) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.84it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:00<00:00, 534.55it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 708.59it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:28,  4.48it/s, est. speed input: 2295.89 toks/s, output: 4.48 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:07, 17.24it/s, est. speed input: 7538.72 toks/s, output: 14.72 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:04, 24.52it/s, est. speed input: 10331.32 toks/s, output: 20.18 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:03, 28.93it/s, est. speed input: 12047.12 toks/s, output: 23.53 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:03, 31.75it/s, est. speed input: 13207.99 toks/s, output: 25.80 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:00<00:03, 33.56it/s, est. speed input: 14038.98 toks/s, output: 27.42 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:00<00:02, 34.82it/s, est. speed input: 14674.73 toks/s, output: 28.66 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:00<00:02, 35.70it/s, est. speed input: 15176.52 toks/s, output: 29.64 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:02, 36.29it/s, est. speed input: 15577.21 toks/s, output: 30.42 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 36.70it/s, est. speed input: 15906.63 toks/s, output: 31.07 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 37.01it/s, est. speed input: 16184.97 toks/s, output: 31.61 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 37.23it/s, est. speed input: 16422.84 toks/s, output: 32.07 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 37.33it/s, est. speed input: 16620.99 toks/s, output: 32.46 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:02, 37.47it/s, est. speed input: 16799.81 toks/s, output: 32.81 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:01<00:01, 37.58it/s, est. speed input: 16957.80 toks/s, output: 33.12 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:01<00:01, 37.60it/s, est. speed input: 17092.30 toks/s, output: 33.38 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:01<00:01, 37.63it/s, est. speed input: 17214.23 toks/s, output: 33.62 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 37.69it/s, est. speed input: 17325.31 toks/s, output: 33.84 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 37.67it/s, est. speed input: 17421.63 toks/s, output: 34.03 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 37.68it/s, est. speed input: 17509.97 toks/s, output: 34.20 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 37.74it/s, est. speed input: 17594.80 toks/s, output: 34.36 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 37.78it/s, est. speed input: 17671.30 toks/s, output: 34.51 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:02<00:01, 37.84it/s, est. speed input: 17744.47 toks/s, output: 34.66 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:02<00:00, 37.90it/s, est. speed input: 17812.33 toks/s, output: 34.79 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:02<00:00, 37.91it/s, est. speed input: 17873.38 toks/s, output: 34.91 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:02<00:00, 37.89it/s, est. speed input: 17928.64 toks/s, output: 35.02 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:02<00:00, 37.87it/s, est. speed input: 17979.52 toks/s, output: 35.12 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 37.86it/s, est. speed input: 18026.93 toks/s, output: 35.21 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 37.84it/s, est. speed input: 18070.89 toks/s, output: 35.29 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 37.85it/s, est. speed input: 18113.14 toks/s, output: 35.38 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 37.83it/s, est. speed input: 18151.25 toks/s, output: 35.45 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:03<00:00, 37.82it/s, est. speed input: 18187.46 toks/s, output: 35.52 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 37.82it/s, est. speed input: 18214.03 toks/s, output: 35.57 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 35.57it/s, est. speed input: 18214.03 toks/s, output: 35.57 toks/s]
[rank0]:[W125 15:59:13.519654195 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-25 15:59:15
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 15:59:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=159648) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=159648) WARNING 01-25 15:59:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.21 requests/s, 36092.39 total tokens/s, 35.21 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-25 15:59:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 15:59:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 15:59:22] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:22] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 15:59:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:22] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:22] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 15:59:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:22] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:22] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:22] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 15:59:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:22] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 15:59:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 15:59:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 15:59:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 15:59:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 15:59:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 15:59:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 15:59:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 15:59:29] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:29] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 15:59:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:29] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:29] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 15:59:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:29] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:29] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:29] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 15:59:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:29] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 15:59:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 15:59:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 15:59:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 15:59:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 15:59:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 15:59:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 15:59:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=159648) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=159648) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.58it/s]
(EngineCore_DP0 pid=159648) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.58it/s]
(EngineCore_DP0 pid=159648) 
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=159648) [2026-01-25 15:59:44] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=159648) 2026-01-25 15:59:50,133 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=159648) 2026-01-25 15:59:50,182 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=159648) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.62it/s]
(EngineCore_DP0 pid=159648) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.44it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 27/128 [00:00<00:00, 265.02it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 80/128 [00:00<00:00, 418.81it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 431.98it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:01, 72.46it/s, est. speed input: 74210.81 toks/s, output: 72.46 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:02, 47.23it/s, est. speed input: 51203.93 toks/s, output: 50.00 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 23/128 [00:00<00:02, 42.85it/s, est. speed input: 46949.10 toks/s, output: 45.85 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 28/128 [00:00<00:02, 40.92it/s, est. speed input: 45066.56 toks/s, output: 44.01 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:00<00:02, 39.70it/s, est. speed input: 43848.99 toks/s, output: 42.82 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 38/128 [00:00<00:02, 38.92it/s, est. speed input: 42999.67 toks/s, output: 41.99 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:01<00:02, 38.48it/s, est. speed input: 42488.37 toks/s, output: 41.49 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:02, 38.05it/s, est. speed input: 42034.71 toks/s, output: 41.05 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [00:01<00:02, 37.70it/s, est. speed input: 41652.61 toks/s, output: 40.68 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:01<00:01, 37.53it/s, est. speed input: 41356.93 toks/s, output: 40.39 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [00:01<00:01, 37.40it/s, est. speed input: 41106.04 toks/s, output: 40.14 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [00:01<00:01, 37.32it/s, est. speed input: 40892.28 toks/s, output: 39.93 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:01<00:01, 37.23it/s, est. speed input: 40697.89 toks/s, output: 39.74 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [00:01<00:01, 37.19it/s, est. speed input: 40532.78 toks/s, output: 39.58 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [00:01<00:01, 37.17it/s, est. speed input: 40387.93 toks/s, output: 39.44 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:01<00:01, 37.17it/s, est. speed input: 40262.13 toks/s, output: 39.32 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:02<00:01, 37.13it/s, est. speed input: 40142.33 toks/s, output: 39.20 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [00:02<00:01, 37.10it/s, est. speed input: 40033.42 toks/s, output: 39.09 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:02<00:01, 37.11it/s, est. speed input: 39937.82 toks/s, output: 39.00 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [00:02<00:00, 37.16it/s, est. speed input: 39860.09 toks/s, output: 38.93 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [00:02<00:00, 37.22it/s, est. speed input: 39791.52 toks/s, output: 38.86 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:02<00:00, 37.18it/s, est. speed input: 39717.93 toks/s, output: 38.79 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:02<00:00, 37.20it/s, est. speed input: 39656.13 toks/s, output: 38.73 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [00:02<00:00, 36.74it/s, est. speed input: 39533.87 toks/s, output: 38.61 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [00:02<00:00, 36.75it/s, est. speed input: 39465.69 toks/s, output: 38.54 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [00:03<00:00, 36.76it/s, est. speed input: 39401.19 toks/s, output: 38.48 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:03<00:00, 36.81it/s, est. speed input: 39346.70 toks/s, output: 38.42 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:03<00:00, 36.87it/s, est. speed input: 39299.47 toks/s, output: 38.38 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 36.87it/s, est. speed input: 39277.76 toks/s, output: 38.36 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 38.35it/s, est. speed input: 39277.76 toks/s, output: 38.36 toks/s]
[rank0]:[W125 15:59:55.977038661 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-25 15:59:57
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:00:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=160820) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=160820) WARNING 01-25 16:00:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 65.90 requests/s, 67545.63 total tokens/s, 65.90 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-25 16:00:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:00:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:05] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:05] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:00:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:05] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:05] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:00:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:05] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:05] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:05] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:00:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:05] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:00:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:00:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:00:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:00:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:00:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:00:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:12] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:12] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:00:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:12] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:12] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:00:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:12] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:12] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:12] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:00:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:12] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:00:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:00:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:00:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:00:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=160820) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=160820) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=160820) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=160820) 
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=160820) [2026-01-25 16:00:26] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=160820) 2026-01-25 16:00:31,347 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=160820) 2026-01-25 16:00:31,379 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=160820) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  8.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 13.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 12.78it/s]
(EngineCore_DP0 pid=160820) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.04it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|â–‰         | 25/256 [00:00<00:00, 244.63it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 73/256 [00:00<00:00, 379.51it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 124/256 [00:00<00:00, 437.64it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 174/256 [00:00<00:00, 459.91it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 222/256 [00:00<00:00, 466.58it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 449.02it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|â–‰         | 24/256 [00:00<00:01, 221.24it/s, est. speed input: 226589.56 toks/s, output: 221.25 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 47/256 [00:00<00:01, 106.34it/s, est. speed input: 118310.20 toks/s, output: 115.53 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 61/256 [00:00<00:02, 92.60it/s, est. speed input: 104659.97 toks/s, output: 102.20 toks/s] 
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 72/256 [00:00<00:02, 84.16it/s, est. speed input: 97102.28 toks/s, output: 94.82 toks/s]  
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 82/256 [00:00<00:02, 81.14it/s, est. speed input: 93819.97 toks/s, output: 91.62 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 91/256 [00:01<00:02, 81.58it/s, est. speed input: 92852.18 toks/s, output: 90.68 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 100/256 [00:01<00:02, 76.94it/s, est. speed input: 89901.10 toks/s, output: 87.79 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 108/256 [00:01<00:01, 75.82it/s, est. speed input: 88536.94 toks/s, output: 86.46 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 116/256 [00:01<00:01, 74.65it/s, est. speed input: 87288.37 toks/s, output: 85.24 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 124/256 [00:01<00:01, 73.78it/s, est. speed input: 86224.09 toks/s, output: 84.20 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 132/256 [00:01<00:01, 73.19it/s, est. speed input: 85323.21 toks/s, output: 83.32 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 140/256 [00:01<00:01, 72.78it/s, est. speed input: 84547.94 toks/s, output: 82.56 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 148/256 [00:01<00:01, 72.46it/s, est. speed input: 83859.49 toks/s, output: 81.89 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 156/256 [00:01<00:01, 72.21it/s, est. speed input: 83245.67 toks/s, output: 81.29 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 164/256 [00:02<00:01, 72.06it/s, est. speed input: 82706.24 toks/s, output: 80.77 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 172/256 [00:02<00:01, 72.02it/s, est. speed input: 82235.32 toks/s, output: 80.31 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 180/256 [00:02<00:01, 71.94it/s, est. speed input: 81802.93 toks/s, output: 79.88 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 188/256 [00:02<00:00, 71.89it/s, est. speed input: 81410.66 toks/s, output: 79.50 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 196/256 [00:02<00:00, 71.82it/s, est. speed input: 81047.96 toks/s, output: 79.15 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 204/256 [00:02<00:00, 71.77it/s, est. speed input: 80717.28 toks/s, output: 78.82 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 212/256 [00:02<00:00, 71.74it/s, est. speed input: 80414.15 toks/s, output: 78.53 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 220/256 [00:02<00:00, 71.68it/s, est. speed input: 80129.83 toks/s, output: 78.25 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 228/256 [00:02<00:00, 71.74it/s, est. speed input: 79880.45 toks/s, output: 78.01 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 236/256 [00:03<00:00, 71.72it/s, est. speed input: 79642.40 toks/s, output: 77.77 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 244/256 [00:03<00:00, 71.75it/s, est. speed input: 79425.05 toks/s, output: 77.56 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 252/256 [00:03<00:00, 71.65it/s, est. speed input: 79209.66 toks/s, output: 77.35 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 71.65it/s, est. speed input: 79127.52 toks/s, output: 77.27 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 77.27it/s, est. speed input: 79127.52 toks/s, output: 77.27 toks/s]
[rank0]:[W125 16:00:37.430297344 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-25 16:00:39
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:00:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=161973) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=161973) WARNING 01-25 16:01:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 80.62 requests/s, 82633.65 total tokens/s, 80.62 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-25 16:00:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:00:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:48] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:48] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:00:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:48] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:48] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:00:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:48] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:48] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:48] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:00:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:48] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:00:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:00:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:00:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:00:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:00:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:00:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:54] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:54] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:00:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:54] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:54] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:00:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:54] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:54] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:54] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:00:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:54] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:00:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:00:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:00:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:00:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:00:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:00:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:00:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=161973) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=161973) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.51it/s]
(EngineCore_DP0 pid=161973) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.51it/s]
(EngineCore_DP0 pid=161973) 
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=161973) [2026-01-25 16:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=161973) [2026-01-25 16:01:09] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=161973) 2026-01-25 16:01:15,326 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=161973) 2026-01-25 16:01:15,364 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=161973) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 12.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.00it/s]
(EngineCore_DP0 pid=161973) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 18.81it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 19.37it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|â–Œ         | 30/512 [00:00<00:01, 296.94it/s]
Adding requests:  16%|â–ˆâ–Œ        | 82/512 [00:00<00:01, 426.32it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 134/512 [00:00<00:00, 465.57it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 184/512 [00:00<00:00, 477.22it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 236/512 [00:00<00:00, 492.13it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 287/512 [00:00<00:00, 496.63it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 338/512 [00:00<00:00, 498.64it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 391/512 [00:00<00:00, 506.65it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 442/512 [00:00<00:00, 507.47it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 494/512 [00:01<00:00, 509.32it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:01<00:00, 489.66it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|â–ˆâ–        | 74/512 [00:00<00:00, 561.50it/s, est. speed input: 575066.19 toks/s, output: 561.53 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 131/512 [00:00<00:02, 144.11it/s, est. speed input: 168838.58 toks/s, output: 164.88 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 160/512 [00:01<00:02, 121.53it/s, est. speed input: 144825.85 toks/s, output: 141.43 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/512 [00:01<00:02, 111.31it/s, est. speed input: 134874.04 toks/s, output: 131.71 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 196/512 [00:01<00:03, 104.86it/s, est. speed input: 129034.86 toks/s, output: 126.01 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 209/512 [00:01<00:02, 101.78it/s, est. speed input: 125922.77 toks/s, output: 122.97 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 221/512 [00:01<00:02, 97.48it/s, est. speed input: 122728.58 toks/s, output: 119.85 toks/s] 
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 232/512 [00:01<00:03, 92.17it/s, est. speed input: 119468.77 toks/s, output: 116.67 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 242/512 [00:02<00:03, 86.50it/s, est. speed input: 116294.04 toks/s, output: 113.57 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 254/512 [00:02<00:03, 85.99it/s, est. speed input: 114444.94 toks/s, output: 111.76 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/512 [00:02<00:02, 85.69it/s, est. speed input: 112833.10 toks/s, output: 110.19 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 278/512 [00:02<00:02, 85.39it/s, est. speed input: 111382.35 toks/s, output: 108.77 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 290/512 [00:02<00:02, 84.93it/s, est. speed input: 110026.07 toks/s, output: 107.45 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 302/512 [00:02<00:02, 84.34it/s, est. speed input: 108750.70 toks/s, output: 106.20 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/512 [00:02<00:02, 83.72it/s, est. speed input: 107553.24 toks/s, output: 105.03 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 326/512 [00:03<00:02, 83.90it/s, est. speed input: 106590.16 toks/s, output: 104.09 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 338/512 [00:03<00:02, 84.10it/s, est. speed input: 105724.02 toks/s, output: 103.25 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 350/512 [00:03<00:01, 85.57it/s, est. speed input: 105158.74 toks/s, output: 102.69 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 362/512 [00:03<00:01, 85.38it/s, est. speed input: 104435.37 toks/s, output: 101.99 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 374/512 [00:03<00:01, 84.98it/s, est. speed input: 103725.41 toks/s, output: 101.29 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 386/512 [00:03<00:01, 84.44it/s, est. speed input: 103029.22 toks/s, output: 100.61 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 398/512 [00:03<00:01, 84.30it/s, est. speed input: 102416.52 toks/s, output: 100.02 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 410/512 [00:04<00:01, 84.36it/s, est. speed input: 101868.94 toks/s, output: 99.48 toks/s] 
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/512 [00:04<00:01, 83.99it/s, est. speed input: 101303.97 toks/s, output: 98.93 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 434/512 [00:04<00:00, 84.22it/s, est. speed input: 100837.07 toks/s, output: 98.47 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 446/512 [00:04<00:00, 84.34it/s, est. speed input: 100395.02 toks/s, output: 98.04 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 458/512 [00:04<00:00, 85.80it/s, est. speed input: 100141.74 toks/s, output: 97.79 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/512 [00:04<00:00, 84.76it/s, est. speed input: 99667.69 toks/s, output: 97.33 toks/s] 
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482/512 [00:04<00:00, 84.25it/s, est. speed input: 99243.66 toks/s, output: 96.92 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 494/512 [00:05<00:00, 83.85it/s, est. speed input: 98838.48 toks/s, output: 96.52 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 506/512 [00:05<00:00, 83.34it/s, est. speed input: 98430.54 toks/s, output: 96.12 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:05<00:00, 83.34it/s, est. speed input: 98860.40 toks/s, output: 96.54 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:05<00:00, 96.54it/s, est. speed input: 98860.40 toks/s, output: 96.54 toks/s]
[rank0]:[W125 16:01:24.022361961 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-25 16:01:25
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:01:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=163192) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=163192) WARNING 01-25 16:01:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 87.04 requests/s, 89217.44 total tokens/s, 87.04 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-25 16:01:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:01:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:01:36] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:36] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:01:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:36] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:36] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:01:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:36] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:36] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:36] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:01:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:36] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:01:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:01:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:01:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:01:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:01:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:01:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:01:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:01:44] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:44] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:01:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:44] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:44] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:01:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:44] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:44] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:44] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:01:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:44] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:01:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:01:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:01:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:01:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:01:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:01:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:01:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:45] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=163192) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=163192) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=163192) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=163192) 
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=163192) [2026-01-25 16:01:58] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=163192) 2026-01-25 16:02:03,574 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=163192) 2026-01-25 16:02:03,598 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=163192) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:01,  2.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:00,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  5.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.80it/s]
(EngineCore_DP0 pid=163192) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 18.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.53it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 25/1024 [00:00<00:04, 246.32it/s]
Adding requests:   7%|â–‹         | 72/1024 [00:00<00:02, 374.68it/s]
Adding requests:  12%|â–ˆâ–        | 120/1024 [00:00<00:02, 420.02it/s]
Adding requests:  16%|â–ˆâ–‹        | 167/1024 [00:00<00:01, 437.09it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 214/1024 [00:00<00:01, 447.35it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 263/1024 [00:00<00:01, 459.95it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:01, 463.43it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 358/1024 [00:00<00:01, 464.95it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:01, 466.03it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 453/1024 [00:01<00:01, 467.87it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 500/1024 [00:01<00:01, 468.32it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 547/1024 [00:01<00:01, 459.97it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:01<00:00, 467.72it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 645/1024 [00:01<00:00, 473.07it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 695/1024 [00:01<00:00, 479.00it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 743/1024 [00:01<00:00, 478.43it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 791/1024 [00:01<00:00, 478.50it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839/1024 [00:01<00:00, 466.44it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 889/1024 [00:01<00:00, 474.79it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 938/1024 [00:02<00:00, 477.48it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 987/1024 [00:02<00:00, 480.51it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 463.34it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 194/1024 [00:00<00:00, 1263.75it/s, est. speed input: 1294285.79 toks/s, output: 1263.81 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 321/1024 [00:01<00:03, 177.85it/s, est. speed input: 215725.18 toks/s, output: 210.67 toks/s]   
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 379/1024 [00:02<00:04, 137.57it/s, est. speed input: 172633.05 toks/s, output: 168.59 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 414/1024 [00:02<00:04, 128.02it/s, est. speed input: 162216.26 toks/s, output: 158.41 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 439/1024 [00:02<00:04, 120.60it/s, est. speed input: 155582.15 toks/s, output: 151.94 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 459/1024 [00:03<00:05, 110.87it/s, est. speed input: 148954.89 toks/s, output: 145.46 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 475/1024 [00:03<00:05, 106.77it/s, est. speed input: 145688.84 toks/s, output: 142.27 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 490/1024 [00:03<00:05, 101.87it/s, est. speed input: 142494.78 toks/s, output: 139.15 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 506/1024 [00:03<00:05, 98.62it/s, est. speed input: 139860.04 toks/s, output: 136.58 toks/s] 
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 522/1024 [00:03<00:05, 95.81it/s, est. speed input: 137456.75 toks/s, output: 134.23 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 538/1024 [00:04<00:05, 93.54it/s, est. speed input: 135270.05 toks/s, output: 132.10 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 554/1024 [00:04<00:05, 91.85it/s, est. speed input: 133287.18 toks/s, output: 130.16 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 570/1024 [00:04<00:05, 90.65it/s, est. speed input: 131487.81 toks/s, output: 128.40 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 586/1024 [00:04<00:04, 89.58it/s, est. speed input: 129794.39 toks/s, output: 126.75 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 602/1024 [00:04<00:04, 88.85it/s, est. speed input: 128239.95 toks/s, output: 125.23 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 618/1024 [00:04<00:04, 88.35it/s, est. speed input: 126804.13 toks/s, output: 123.83 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 634/1024 [00:05<00:04, 88.05it/s, est. speed input: 125480.19 toks/s, output: 122.54 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 650/1024 [00:05<00:04, 87.89it/s, est. speed input: 124255.84 toks/s, output: 121.34 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 666/1024 [00:05<00:04, 87.69it/s, est. speed input: 123098.11 toks/s, output: 120.21 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:05<00:03, 87.53it/s, est. speed input: 122013.04 toks/s, output: 119.15 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 698/1024 [00:05<00:03, 87.28it/s, est. speed input: 120975.16 toks/s, output: 118.14 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 714/1024 [00:06<00:03, 87.06it/s, est. speed input: 119993.20 toks/s, output: 117.18 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 730/1024 [00:06<00:03, 87.22it/s, est. speed input: 119110.91 toks/s, output: 116.32 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 746/1024 [00:06<00:03, 87.27it/s, est. speed input: 118271.06 toks/s, output: 115.50 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 762/1024 [00:06<00:03, 87.16it/s, est. speed input: 117459.85 toks/s, output: 114.71 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 778/1024 [00:06<00:02, 87.11it/s, est. speed input: 116695.60 toks/s, output: 113.96 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 794/1024 [00:07<00:02, 87.04it/s, est. speed input: 115967.42 toks/s, output: 113.25 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 810/1024 [00:07<00:02, 86.97it/s, est. speed input: 115273.85 toks/s, output: 112.57 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 826/1024 [00:07<00:02, 87.14it/s, est. speed input: 114638.21 toks/s, output: 111.95 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842/1024 [00:07<00:02, 87.01it/s, est. speed input: 114007.71 toks/s, output: 111.34 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:07<00:01, 87.20it/s, est. speed input: 113436.27 toks/s, output: 110.78 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 874/1024 [00:07<00:01, 87.11it/s, est. speed input: 112869.26 toks/s, output: 110.22 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 890/1024 [00:08<00:01, 87.11it/s, est. speed input: 112332.53 toks/s, output: 109.70 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 906/1024 [00:08<00:01, 87.12it/s, est. speed input: 111821.75 toks/s, output: 109.20 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 922/1024 [00:08<00:01, 87.05it/s, est. speed input: 111325.34 toks/s, output: 108.72 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 938/1024 [00:08<00:00, 88.51it/s, est. speed input: 110984.52 toks/s, output: 108.38 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 954/1024 [00:08<00:00, 88.15it/s, est. speed input: 110537.16 toks/s, output: 107.95 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:09<00:00, 87.74it/s, est. speed input: 110094.58 toks/s, output: 107.51 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 986/1024 [00:09<00:00, 89.06it/s, est. speed input: 109801.29 toks/s, output: 107.23 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1002/1024 [00:09<00:00, 88.50it/s, est. speed input: 109400.36 toks/s, output: 106.84 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:09<00:00, 89.65it/s, est. speed input: 109133.28 toks/s, output: 106.58 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:09<00:00, 89.65it/s, est. speed input: 109772.13 toks/s, output: 107.20 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:09<00:00, 107.20it/s, est. speed input: 109772.13 toks/s, output: 107.20 toks/s]
[rank0]:[W125 16:02:18.688068259 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-25 16:02:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:02:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=164555) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=164555) WARNING 01-25 16:02:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 89.46 requests/s, 91697.40 total tokens/s, 89.46 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-25 16:02:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:02:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:02:35] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:35] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:02:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:35] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:35] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:02:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:35] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:35] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:35] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:02:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:35] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:02:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:02:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:02:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:02:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:02:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:02:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:02:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:02:42] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:42] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:02:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:42] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:42] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:02:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:42] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:42] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:42] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:02:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:42] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:02:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:02:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:02:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:02:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:02:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:02:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:02:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=164555) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=164555) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=164555) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=164555) 
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=164555) [2026-01-25 16:02:57] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=164555) 2026-01-25 16:03:01,892 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=164555) 2026-01-25 16:03:01,921 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=164555) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00,  9.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00,  6.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:01<00:00,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:01<00:00,  5.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.71it/s]
(EngineCore_DP0 pid=164555) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 17.70it/s]
Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 11.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.77it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 33/2048 [00:00<00:06, 329.75it/s]
Adding requests:   4%|â–         | 85/2048 [00:00<00:04, 441.12it/s]
Adding requests:   7%|â–‹         | 136/2048 [00:00<00:04, 469.41it/s]
Adding requests:   9%|â–‰         | 185/2048 [00:00<00:03, 477.10it/s]
Adding requests:  12%|â–ˆâ–        | 237/2048 [00:00<00:03, 490.37it/s]
Adding requests:  14%|â–ˆâ–        | 288/2048 [00:00<00:03, 494.17it/s]
Adding requests:  17%|â–ˆâ–‹        | 338/2048 [00:00<00:03, 495.96it/s]
Adding requests:  19%|â–ˆâ–‰        | 390/2048 [00:00<00:03, 501.39it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 441/2048 [00:00<00:03, 502.24it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 492/2048 [00:01<00:03, 502.86it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 543/2048 [00:01<00:03, 495.18it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 596/2048 [00:01<00:02, 501.64it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 648/2048 [00:01<00:02, 506.79it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 702/2048 [00:01<00:02, 513.55it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 754/2048 [00:01<00:02, 504.61it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 805/2048 [00:01<00:02, 498.50it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 855/2048 [00:01<00:02, 495.18it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 908/2048 [00:01<00:02, 504.10it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 960/2048 [00:01<00:02, 507.31it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1013/2048 [00:02<00:02, 512.21it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1065/2048 [00:02<00:01, 513.97it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1117/2048 [00:02<00:01, 506.86it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:02<00:01, 512.78it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1224/2048 [00:02<00:01, 519.03it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1276/2048 [00:02<00:01, 509.56it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1329/2048 [00:02<00:01, 513.81it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1382/2048 [00:02<00:01, 515.77it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1434/2048 [00:02<00:01, 516.66it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1487/2048 [00:02<00:01, 519.29it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1540/2048 [00:03<00:00, 520.87it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1594/2048 [00:03<00:00, 525.64it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1647/2048 [00:03<00:00, 525.95it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1700/2048 [00:03<00:00, 516.99it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1753/2048 [00:03<00:00, 517.99it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1805/2048 [00:03<00:00, 514.59it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1858/2048 [00:03<00:00, 516.89it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1910/2048 [00:03<00:00, 502.06it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1962/2048 [00:03<00:00, 506.97it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2015/2048 [00:03<00:00, 511.21it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:04<00:00, 506.04it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 354/2048 [00:00<00:00, 2524.61it/s, est. speed input: 2585644.48 toks/s, output: 2524.75 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 607/2048 [00:02<00:07, 181.03it/s, est. speed input: 221320.85 toks/s, output: 216.13 toks/s]   
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 717/2048 [00:04<00:09, 144.59it/s, est. speed input: 180964.19 toks/s, output: 176.72 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 781/2048 [00:04<00:09, 131.26it/s, est. speed input: 167613.83 toks/s, output: 163.68 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 823/2048 [00:05<00:10, 120.22it/s, est. speed input: 158711.22 toks/s, output: 154.99 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 853/2048 [00:05<00:10, 114.31it/s, est. speed input: 154149.40 toks/s, output: 150.54 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 876/2048 [00:05<00:10, 115.87it/s, est. speed input: 153486.13 toks/s, output: 149.89 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 896/2048 [00:06<00:09, 115.42it/s, est. speed input: 152349.72 toks/s, output: 148.78 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 913/2048 [00:06<00:10, 112.18it/s, est. speed input: 150754.19 toks/s, output: 147.22 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 928/2048 [00:06<00:10, 106.97it/s, est. speed input: 148932.58 toks/s, output: 145.44 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 941/2048 [00:06<00:10, 101.14it/s, est. speed input: 147147.98 toks/s, output: 143.70 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 953/2048 [00:06<00:11, 93.27it/s, est. speed input: 145061.77 toks/s, output: 141.66 toks/s] 
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 963/2048 [00:06<00:12, 84.02it/s, est. speed input: 142791.37 toks/s, output: 139.44 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 978/2048 [00:07<00:12, 85.30it/s, est. speed input: 141566.58 toks/s, output: 138.25 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 994/2048 [00:07<00:12, 86.30it/s, est. speed input: 140313.52 toks/s, output: 137.02 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1010/2048 [00:07<00:11, 87.15it/s, est. speed input: 139135.30 toks/s, output: 135.87 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1026/2048 [00:07<00:11, 87.79it/s, est. speed input: 138015.63 toks/s, output: 134.78 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1042/2048 [00:07<00:11, 88.40it/s, est. speed input: 136965.86 toks/s, output: 133.76 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1058/2048 [00:07<00:11, 88.72it/s, est. speed input: 135949.14 toks/s, output: 132.76 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1074/2048 [00:08<00:10, 88.70it/s, est. speed input: 134949.02 toks/s, output: 131.79 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1090/2048 [00:08<00:10, 88.74it/s, est. speed input: 133997.92 toks/s, output: 130.86 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1106/2048 [00:08<00:10, 88.91it/s, est. speed input: 133102.01 toks/s, output: 129.98 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1122/2048 [00:08<00:10, 89.06it/s, est. speed input: 132246.14 toks/s, output: 129.15 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1138/2048 [00:08<00:10, 89.19it/s, est. speed input: 131427.91 toks/s, output: 128.35 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1154/2048 [00:09<00:09, 90.64it/s, est. speed input: 130770.79 toks/s, output: 127.71 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:09<00:09, 90.08it/s, est. speed input: 129992.38 toks/s, output: 126.95 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1186/2048 [00:09<00:09, 89.95it/s, est. speed input: 129266.84 toks/s, output: 126.24 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1202/2048 [00:09<00:09, 89.80it/s, est. speed input: 128562.78 toks/s, output: 125.55 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1218/2048 [00:09<00:09, 89.85it/s, est. speed input: 127898.64 toks/s, output: 124.90 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1234/2048 [00:09<00:09, 89.64it/s, est. speed input: 127237.41 toks/s, output: 124.25 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1250/2048 [00:10<00:08, 89.40it/s, est. speed input: 126591.02 toks/s, output: 123.62 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1266/2048 [00:10<00:08, 89.27it/s, est. speed input: 125971.19 toks/s, output: 123.02 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1282/2048 [00:10<00:08, 89.32it/s, est. speed input: 125383.37 toks/s, output: 122.44 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1298/2048 [00:10<00:08, 89.36it/s, est. speed input: 124815.85 toks/s, output: 121.89 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1314/2048 [00:10<00:08, 89.23it/s, est. speed input: 124255.49 toks/s, output: 121.34 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1330/2048 [00:11<00:08, 89.07it/s, est. speed input: 123707.60 toks/s, output: 120.81 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1346/2048 [00:11<00:07, 89.02it/s, est. speed input: 123181.87 toks/s, output: 120.29 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1362/2048 [00:11<00:07, 89.02it/s, est. speed input: 122675.89 toks/s, output: 119.80 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1378/2048 [00:11<00:07, 89.16it/s, est. speed input: 122195.83 toks/s, output: 119.33 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1394/2048 [00:11<00:07, 89.21it/s, est. speed input: 121726.11 toks/s, output: 118.87 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1410/2048 [00:11<00:07, 89.11it/s, est. speed input: 121261.92 toks/s, output: 118.42 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1426/2048 [00:12<00:06, 89.20it/s, est. speed input: 120821.95 toks/s, output: 117.99 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1442/2048 [00:12<00:06, 89.25it/s, est. speed input: 120393.71 toks/s, output: 117.57 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1458/2048 [00:12<00:06, 89.36it/s, est. speed input: 119983.35 toks/s, output: 117.17 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1474/2048 [00:12<00:06, 89.47it/s, est. speed input: 119586.90 toks/s, output: 116.78 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1490/2048 [00:12<00:06, 89.54it/s, est. speed input: 119199.77 toks/s, output: 116.41 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1506/2048 [00:12<00:06, 89.50it/s, est. speed input: 118818.82 toks/s, output: 116.03 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1522/2048 [00:13<00:05, 89.55it/s, est. speed input: 118452.77 toks/s, output: 115.68 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1538/2048 [00:13<00:05, 89.34it/s, est. speed input: 118081.95 toks/s, output: 115.31 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1554/2048 [00:13<00:05, 89.37it/s, est. speed input: 117731.13 toks/s, output: 114.97 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1570/2048 [00:13<00:05, 89.36it/s, est. speed input: 117388.11 toks/s, output: 114.64 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1586/2048 [00:13<00:05, 90.75it/s, est. speed input: 117131.37 toks/s, output: 114.39 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1602/2048 [00:14<00:04, 90.39it/s, est. speed input: 116807.66 toks/s, output: 114.07 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1618/2048 [00:14<00:04, 90.04it/s, est. speed input: 116487.33 toks/s, output: 113.76 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1634/2048 [00:14<00:04, 89.90it/s, est. speed input: 116179.88 toks/s, output: 113.46 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1650/2048 [00:14<00:04, 89.90it/s, est. speed input: 115885.61 toks/s, output: 113.17 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1666/2048 [00:14<00:04, 89.71it/s, est. speed input: 115588.46 toks/s, output: 112.88 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1682/2048 [00:14<00:04, 89.59it/s, est. speed input: 115298.72 toks/s, output: 112.60 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1698/2048 [00:15<00:03, 89.45it/s, est. speed input: 115013.64 toks/s, output: 112.32 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1714/2048 [00:15<00:03, 89.39it/s, est. speed input: 114736.91 toks/s, output: 112.05 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1730/2048 [00:15<00:03, 89.34it/s, est. speed input: 114466.00 toks/s, output: 111.78 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1746/2048 [00:15<00:03, 89.29it/s, est. speed input: 114200.66 toks/s, output: 111.52 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1762/2048 [00:15<00:03, 89.37it/s, est. speed input: 113946.83 toks/s, output: 111.28 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1778/2048 [00:16<00:03, 89.27it/s, est. speed input: 113691.02 toks/s, output: 111.03 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1794/2048 [00:16<00:02, 89.20it/s, est. speed input: 113441.23 toks/s, output: 110.78 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1810/2048 [00:16<00:02, 89.21it/s, est. speed input: 113199.54 toks/s, output: 110.55 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1826/2048 [00:16<00:02, 89.17it/s, est. speed input: 112960.96 toks/s, output: 110.31 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1842/2048 [00:16<00:02, 89.30it/s, est. speed input: 112734.82 toks/s, output: 110.09 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1858/2048 [00:16<00:02, 89.19it/s, est. speed input: 112504.13 toks/s, output: 109.87 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1874/2048 [00:17<00:01, 90.77it/s, est. speed input: 112350.37 toks/s, output: 109.72 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1890/2048 [00:17<00:01, 90.43it/s, est. speed input: 112138.03 toks/s, output: 109.51 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1906/2048 [00:17<00:01, 90.25it/s, est. speed input: 111932.30 toks/s, output: 109.31 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1922/2048 [00:17<00:01, 89.95it/s, est. speed input: 111723.13 toks/s, output: 109.10 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1938/2048 [00:17<00:01, 89.81it/s, est. speed input: 111521.46 toks/s, output: 108.91 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1954/2048 [00:17<00:01, 91.15it/s, est. speed input: 111381.70 toks/s, output: 108.77 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1970/2048 [00:18<00:00, 90.77it/s, est. speed input: 111192.19 toks/s, output: 108.59 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1986/2048 [00:18<00:00, 90.55it/s, est. speed input: 111007.93 toks/s, output: 108.41 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2002/2048 [00:18<00:00, 90.25it/s, est. speed input: 110821.89 toks/s, output: 108.22 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [00:18<00:00, 90.04it/s, est. speed input: 110638.60 toks/s, output: 108.05 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2034/2048 [00:18<00:00, 92.02it/s, est. speed input: 110539.49 toks/s, output: 107.95 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:18<00:00, 92.02it/s, est. speed input: 111296.28 toks/s, output: 108.69 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:18<00:00, 108.69it/s, est. speed input: 111296.28 toks/s, output: 108.69 toks/s]
[rank0]:[W125 16:03:28.277395840 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-25 16:03:30
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:03:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=166168) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=166168) WARNING 01-25 16:04:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 90.41 requests/s, 92670.95 total tokens/s, 90.41 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-25 16:03:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:03:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:03:53] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:03:53] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:03:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:03:53] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:03:53] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:03:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:03:53] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:03:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:03:53] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:03:53] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:03:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:03:53] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:03:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:03:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:03:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:03:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:03:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:03:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:03:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:04:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:04:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:04:00] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:04:00] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:04:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:04:00] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:04:00] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:04:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:04:00] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:04:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:04:00] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:04:00] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:04:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:04:00] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:04:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:04:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:04:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:04:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:04:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:04:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:04:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=166168) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=166168) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=166168) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=166168) 
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=166168) [rank0]:W0125 16:04:15.357000 166168 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166168) [rank0]:W0125 16:04:15.441000 166168 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166168) [2026-01-25 16:04:15] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=166168) [rank0]:W0125 16:04:16.372000 166168 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166168) [rank0]:W0125 16:04:16.493000 166168 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166168) 2026-01-25 16:04:20,439 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=166168) 2026-01-25 16:04:20,466 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=166168) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 2/11 [00:00<00:00, 16.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:00<00:00, 11.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:00<00:00, 11.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:00<00:00,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00,  5.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  7.79it/s]
(EngineCore_DP0 pid=166168) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 1/7 [00:00<00:00,  6.49it/s]
Capturing CUDA graphs (decode, FULL):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00,  8.10it/s]
Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00, 11.91it/s]
Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:00<00:00, 10.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 10.62it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 34/4096 [00:00<00:12, 336.49it/s]
Adding requests:   2%|â–         | 86/4096 [00:00<00:09, 441.27it/s]
Adding requests:   3%|â–Ž         | 137/4096 [00:00<00:08, 470.86it/s]
Adding requests:   5%|â–         | 188/4096 [00:00<00:08, 475.97it/s]
Adding requests:   6%|â–Œ         | 240/4096 [00:00<00:07, 488.86it/s]
Adding requests:   7%|â–‹         | 292/4096 [00:00<00:07, 496.70it/s]
Adding requests:   8%|â–Š         | 343/4096 [00:00<00:07, 498.72it/s]
Adding requests:  10%|â–‰         | 396/4096 [00:00<00:07, 508.39it/s]
Adding requests:  11%|â–ˆ         | 448/4096 [00:00<00:07, 509.97it/s]
Adding requests:  12%|â–ˆâ–        | 500/4096 [00:01<00:07, 508.34it/s]
Adding requests:  13%|â–ˆâ–Ž        | 551/4096 [00:01<00:07, 504.79it/s]
Adding requests:  15%|â–ˆâ–        | 603/4096 [00:01<00:06, 507.98it/s]
Adding requests:  16%|â–ˆâ–Œ        | 657/4096 [00:01<00:06, 516.38it/s]
Adding requests:  17%|â–ˆâ–‹        | 711/4096 [00:01<00:06, 522.57it/s]
Adding requests:  19%|â–ˆâ–Š        | 764/4096 [00:01<00:06, 520.45it/s]
Adding requests:  20%|â–ˆâ–‰        | 817/4096 [00:01<00:06, 511.09it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 869/4096 [00:01<00:06, 511.89it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 922/4096 [00:01<00:06, 517.00it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 975/4096 [00:01<00:06, 519.34it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 1028/4096 [00:02<00:05, 521.87it/s]
Adding requests:  26%|â–ˆâ–ˆâ–‹       | 1081/4096 [00:02<00:05, 519.61it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 1133/4096 [00:02<00:05, 517.20it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 1185/4096 [00:02<00:05, 511.95it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 1238/4096 [00:02<00:05, 515.87it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆâ–      | 1290/4096 [00:02<00:05, 514.26it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1344/4096 [00:02<00:05, 521.56it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 1398/4096 [00:02<00:05, 526.28it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1451/4096 [00:02<00:05, 525.29it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1506/4096 [00:02<00:04, 528.73it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1560/4096 [00:03<00:04, 530.69it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1615/4096 [00:03<00:04, 533.62it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1669/4096 [00:03<00:04, 529.30it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1723/4096 [00:03<00:04, 531.87it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1777/4096 [00:03<00:04, 528.17it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1830/4096 [00:03<00:04, 527.63it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1883/4096 [00:03<00:04, 527.33it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1936/4096 [00:03<00:04, 526.52it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1989/4096 [00:03<00:04, 524.73it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2043/4096 [00:03<00:03, 527.45it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2097/4096 [00:04<00:03, 529.25it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2150/4096 [00:04<00:03, 523.54it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2203/4096 [00:04<00:03, 518.60it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2258/4096 [00:04<00:03, 525.89it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2311/4096 [00:04<00:03, 523.08it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2364/4096 [00:04<00:03, 519.77it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2416/4096 [00:04<00:03, 505.78it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2468/4096 [00:04<00:03, 509.51it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2520/4096 [00:04<00:03, 512.54it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2575/4096 [00:04<00:02, 520.75it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2628/4096 [00:05<00:02, 522.13it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2682/4096 [00:05<00:02, 525.61it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2735/4096 [00:05<00:02, 521.37it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2788/4096 [00:05<00:02, 522.32it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2841/4096 [00:05<00:02, 521.10it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2895/4096 [00:05<00:02, 525.41it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2948/4096 [00:05<00:02, 519.49it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3001/4096 [00:05<00:02, 520.94it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3054/4096 [00:05<00:01, 522.21it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3107/4096 [00:06<00:01, 519.27it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3160/4096 [00:06<00:01, 521.28it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3213/4096 [00:06<00:01, 521.73it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3267/4096 [00:06<00:01, 525.68it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3320/4096 [00:06<00:01, 525.93it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3373/4096 [00:06<00:01, 526.41it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3427/4096 [00:06<00:01, 528.46it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3480/4096 [00:06<00:01, 518.52it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3532/4096 [00:06<00:01, 518.45it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3585/4096 [00:06<00:00, 519.47it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3637/4096 [00:07<00:00, 519.53it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3690/4096 [00:07<00:00, 521.87it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3743/4096 [00:07<00:00, 506.05it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3799/4096 [00:07<00:00, 518.77it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3853/4096 [00:07<00:00, 523.10it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3906/4096 [00:07<00:00, 523.85it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3960/4096 [00:07<00:00, 526.52it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4013/4096 [00:07<00:00, 526.92it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4066/4096 [00:07<00:00, 520.73it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:07<00:00, 517.84it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 691/4096 [00:00<00:00, 5921.57it/s, est. speed input: 6064937.13 toks/s, output: 5921.92 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 1284/4096 [00:06<00:16, 167.60it/s, est. speed input: 203561.43 toks/s, output: 198.79 toks/s]  
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1534/4096 [00:09<00:18, 136.78it/s, est. speed input: 168903.18 toks/s, output: 164.94 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1674/4096 [00:10<00:18, 128.51it/s, est. speed input: 159898.84 toks/s, output: 156.15 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1763/4096 [00:11<00:19, 120.02it/s, est. speed input: 153167.18 toks/s, output: 149.58 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1823/4096 [00:12<00:19, 114.63it/s, est. speed input: 149385.72 toks/s, output: 145.88 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1866/4096 [00:12<00:19, 115.27it/s, est. speed input: 148687.11 toks/s, output: 145.20 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1899/4096 [00:13<00:19, 112.97it/s, est. speed input: 147375.79 toks/s, output: 143.92 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1925/4096 [00:13<00:20, 107.10it/s, est. speed input: 145497.04 toks/s, output: 142.09 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1945/4096 [00:13<00:21, 98.70it/s, est. speed input: 143370.39 toks/s, output: 140.01 toks/s] 
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1971/4096 [00:14<00:22, 93.65it/s, est. speed input: 141686.38 toks/s, output: 138.37 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2003/4096 [00:14<00:22, 93.02it/s, est. speed input: 140510.25 toks/s, output: 137.22 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2035/4096 [00:14<00:22, 92.29it/s, est. speed input: 139360.78 toks/s, output: 136.09 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2067/4096 [00:15<00:22, 91.79it/s, est. speed input: 138277.80 toks/s, output: 135.04 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2099/4096 [00:15<00:21, 91.52it/s, est. speed input: 137257.64 toks/s, output: 134.04 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2131/4096 [00:16<00:21, 91.10it/s, est. speed input: 136257.02 toks/s, output: 133.06 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2163/4096 [00:16<00:21, 90.84it/s, est. speed input: 135304.63 toks/s, output: 132.13 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2195/4096 [00:16<00:20, 90.78it/s, est. speed input: 134408.07 toks/s, output: 131.26 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2227/4096 [00:17<00:20, 92.24it/s, est. speed input: 133701.82 toks/s, output: 130.57 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2259/4096 [00:17<00:20, 91.63it/s, est. speed input: 132859.33 toks/s, output: 129.75 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2291/4096 [00:17<00:19, 92.04it/s, est. speed input: 132131.56 toks/s, output: 129.03 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2323/4096 [00:18<00:19, 92.20it/s, est. speed input: 131418.59 toks/s, output: 128.34 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2355/4096 [00:18<00:18, 91.65it/s, est. speed input: 130672.34 toks/s, output: 127.61 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2387/4096 [00:18<00:18, 91.15it/s, est. speed input: 129944.23 toks/s, output: 126.90 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2419/4096 [00:19<00:18, 90.93it/s, est. speed input: 129254.22 toks/s, output: 126.22 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2451/4096 [00:19<00:18, 90.79it/s, est. speed input: 128590.95 toks/s, output: 125.58 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2483/4096 [00:19<00:17, 91.39it/s, est. speed input: 128008.88 toks/s, output: 125.01 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2515/4096 [00:20<00:17, 91.04it/s, est. speed input: 127383.83 toks/s, output: 124.40 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2547/4096 [00:20<00:17, 90.88it/s, est. speed input: 126787.43 toks/s, output: 123.82 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2579/4096 [00:20<00:16, 91.37it/s, est. speed input: 126257.78 toks/s, output: 123.30 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2611/4096 [00:21<00:16, 91.09it/s, est. speed input: 125698.27 toks/s, output: 122.75 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2643/4096 [00:21<00:15, 90.91it/s, est. speed input: 125158.23 toks/s, output: 122.22 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2675/4096 [00:21<00:15, 90.74it/s, est. speed input: 124632.24 toks/s, output: 121.71 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2707/4096 [00:22<00:15, 90.51it/s, est. speed input: 124114.47 toks/s, output: 121.21 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2739/4096 [00:22<00:15, 90.40it/s, est. speed input: 123617.16 toks/s, output: 120.72 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2771/4096 [00:23<00:14, 90.42it/s, est. speed input: 123141.10 toks/s, output: 120.25 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2803/4096 [00:23<00:14, 90.37it/s, est. speed input: 122676.09 toks/s, output: 119.80 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2835/4096 [00:23<00:13, 90.26it/s, est. speed input: 122218.87 toks/s, output: 119.35 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2867/4096 [00:24<00:13, 90.20it/s, est. speed input: 121776.65 toks/s, output: 118.92 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2899/4096 [00:24<00:13, 90.18it/s, est. speed input: 121348.95 toks/s, output: 118.50 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2931/4096 [00:24<00:12, 90.20it/s, est. speed input: 120935.37 toks/s, output: 118.10 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2963/4096 [00:25<00:12, 90.17it/s, est. speed input: 120531.26 toks/s, output: 117.71 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2995/4096 [00:25<00:12, 90.11it/s, est. speed input: 120135.67 toks/s, output: 117.32 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3027/4096 [00:25<00:11, 90.21it/s, est. speed input: 119759.07 toks/s, output: 116.95 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3059/4096 [00:26<00:11, 90.20it/s, est. speed input: 119388.12 toks/s, output: 116.59 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3091/4096 [00:26<00:11, 90.08it/s, est. speed input: 119020.49 toks/s, output: 116.23 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3123/4096 [00:26<00:10, 90.84it/s, est. speed input: 118711.03 toks/s, output: 115.93 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3155/4096 [00:27<00:10, 90.60it/s, est. speed input: 118365.94 toks/s, output: 115.59 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3187/4096 [00:27<00:10, 90.29it/s, est. speed input: 118021.92 toks/s, output: 115.26 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3219/4096 [00:28<00:09, 90.20it/s, est. speed input: 117693.20 toks/s, output: 114.93 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3251/4096 [00:28<00:09, 90.32it/s, est. speed input: 117382.87 toks/s, output: 114.63 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3283/4096 [00:28<00:09, 90.09it/s, est. speed input: 117063.50 toks/s, output: 114.32 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3315/4096 [00:29<00:08, 90.10it/s, est. speed input: 116760.73 toks/s, output: 114.02 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3347/4096 [00:29<00:08, 90.14it/s, est. speed input: 116467.45 toks/s, output: 113.74 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3379/4096 [00:29<00:07, 90.03it/s, est. speed input: 116173.86 toks/s, output: 113.45 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3411/4096 [00:30<00:07, 90.13it/s, est. speed input: 115895.96 toks/s, output: 113.18 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3443/4096 [00:30<00:07, 90.09it/s, est. speed input: 115618.96 toks/s, output: 112.91 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3475/4096 [00:30<00:06, 89.90it/s, est. speed input: 115340.89 toks/s, output: 112.64 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3507/4096 [00:31<00:06, 90.04it/s, est. speed input: 115082.02 toks/s, output: 112.38 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3539/4096 [00:31<00:06, 90.04it/s, est. speed input: 114824.23 toks/s, output: 112.13 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3571/4096 [00:31<00:05, 89.93it/s, est. speed input: 114566.96 toks/s, output: 111.88 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3603/4096 [00:32<00:05, 90.09it/s, est. speed input: 114326.80 toks/s, output: 111.65 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3635/4096 [00:32<00:05, 89.97it/s, est. speed input: 114080.76 toks/s, output: 111.41 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3667/4096 [00:32<00:04, 90.01it/s, est. speed input: 113845.81 toks/s, output: 111.18 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3699/4096 [00:33<00:04, 90.12it/s, est. speed input: 113619.81 toks/s, output: 110.96 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3731/4096 [00:33<00:04, 90.70it/s, est. speed input: 113420.30 toks/s, output: 110.76 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3763/4096 [00:34<00:03, 90.55it/s, est. speed input: 113201.03 toks/s, output: 110.55 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3795/4096 [00:34<00:03, 90.35it/s, est. speed input: 112981.97 toks/s, output: 110.33 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3827/4096 [00:34<00:02, 89.97it/s, est. speed input: 112757.40 toks/s, output: 110.11 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3859/4096 [00:35<00:02, 89.98it/s, est. speed input: 112548.80 toks/s, output: 109.91 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3891/4096 [00:35<00:02, 90.06it/s, est. speed input: 112347.35 toks/s, output: 109.71 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3923/4096 [00:35<00:01, 89.93it/s, est. speed input: 112142.47 toks/s, output: 109.51 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3955/4096 [00:36<00:01, 90.09it/s, est. speed input: 111951.48 toks/s, output: 109.33 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3987/4096 [00:36<00:01, 89.92it/s, est. speed input: 111753.45 toks/s, output: 109.13 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4019/4096 [00:36<00:00, 90.59it/s, est. speed input: 111589.99 toks/s, output: 108.97 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4051/4096 [00:37<00:00, 90.60it/s, est. speed input: 111411.93 toks/s, output: 108.80 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4083/4096 [00:37<00:00, 108.67it/s, est. speed input: 111819.04 toks/s, output: 109.20 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:37<00:00, 108.67it/s, est. speed input: 112173.46 toks/s, output: 109.54 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:37<00:00, 109.54it/s, est. speed input: 112173.46 toks/s, output: 109.54 toks/s]
[rank0]:[W125 16:05:09.758097722 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-25 16:05:11
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 16:05:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=168312) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=168312) WARNING 01-25 16:06:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 90.46 requests/s, 92717.30 total tokens/s, 90.46 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-25 16:05:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:05:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:05:52] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:52] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:05:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:52] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:52] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:05:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:52] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:52] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:52] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:05:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:52] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:05:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:05:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:05:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:05:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:05:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 16:05:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 16:05:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 16:05:59] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:59] INFO kernels.py:78: Using basic kernel: basic_dequant_bias_triton.py
[2026-01-25 16:05:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:59] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:59] INFO kernels.py:78: Using basic kernel: basic_quant_only_triton.py
[2026-01-25 16:05:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:59] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:59] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:59] INFO kernels.py:78: Using basic kernel: basic_quant_slide_triton.py
[2026-01-25 16:05:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:59] WARNING kernels.py:115: Tuned kernel not found for Llama3.2-3B-INT8, using basic kernel
[2026-01-25 16:05:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 16:05:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 16:05:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=0, cuSPARSELt=0 models
[2026-01-25 16:05:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 16:05:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 16:05:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 16:05:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=168312) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=168312) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=168312) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=168312) 
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=168312) [rank0]:W0125 16:06:14.372000 168312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=168312) [rank0]:W0125 16:06:14.454000 168312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=168312) [2026-01-25 16:06:14] WARNING gemm_wrapper.py:391: No cuSPARSELt config for model 'Llama3.2-3B-INT8', using default algorithm
(EngineCore_DP0 pid=168312) [rank0]:W0125 16:06:15.694000 168312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=168312) [rank0]:W0125 16:06:15.815000 168312 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=168312) 2026-01-25 16:06:20,530 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=168312) 2026-01-25 16:06:20,595 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=168312) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|â–Œ         | 1/19 [00:00<00:03,  4.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:03,  4.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  7.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 12.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 13.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:02<00:00, 15.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.81it/s]
(EngineCore_DP0 pid=168312) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 1/11 [00:00<00:02,  4.04it/s]
Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 2/11 [00:00<00:02,  4.24it/s]
Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 3/11 [00:00<00:02,  3.12it/s]
Capturing CUDA graphs (decode, FULL):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [00:01<00:01,  5.53it/s]
Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 7/11 [00:01<00:00,  8.17it/s]
Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [00:01<00:00,  8.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00, 10.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  7.44it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 50/8192 [00:00<00:16, 494.04it/s]
Adding requests:   1%|          | 102/8192 [00:00<00:16, 503.90it/s]
Adding requests:   2%|â–         | 153/8192 [00:00<00:16, 498.88it/s]
Adding requests:   2%|â–         | 204/8192 [00:00<00:15, 499.75it/s]
Adding requests:   3%|â–Ž         | 257/8192 [00:00<00:15, 507.36it/s]
Adding requests:   4%|â–         | 308/8192 [00:00<00:15, 502.70it/s]
Adding requests:   4%|â–         | 359/8192 [00:00<00:15, 504.11it/s]
Adding requests:   5%|â–Œ         | 411/8192 [00:00<00:15, 506.90it/s]
Adding requests:   6%|â–Œ         | 462/8192 [00:00<00:15, 507.40it/s]
Adding requests:   6%|â–‹         | 513/8192 [00:01<00:15, 501.84it/s]
Adding requests:   7%|â–‹         | 564/8192 [00:01<00:15, 501.07it/s]
Adding requests:   8%|â–Š         | 615/8192 [00:01<00:15, 503.42it/s]
Adding requests:   8%|â–Š         | 668/8192 [00:01<00:14, 511.34it/s]
Adding requests:   9%|â–‰         | 722/8192 [00:01<00:14, 517.22it/s]
Adding requests:   9%|â–‰         | 774/8192 [00:01<00:14, 513.60it/s]
Adding requests:  10%|â–ˆ         | 826/8192 [00:01<00:14, 496.64it/s]
Adding requests:  11%|â–ˆ         | 878/8192 [00:01<00:14, 502.70it/s]
Adding requests:  11%|â–ˆâ–        | 931/8192 [00:01<00:14, 510.20it/s]
Adding requests:  12%|â–ˆâ–        | 983/8192 [00:01<00:14, 512.85it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1036/8192 [00:02<00:13, 516.95it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1088/8192 [00:02<00:13, 513.79it/s]
Adding requests:  14%|â–ˆâ–        | 1140/8192 [00:02<00:13, 511.62it/s]
Adding requests:  15%|â–ˆâ–        | 1196/8192 [00:02<00:13, 523.19it/s]
Adding requests:  15%|â–ˆâ–Œ        | 1249/8192 [00:02<00:13, 522.26it/s]
Adding requests:  16%|â–ˆâ–Œ        | 1302/8192 [00:02<00:13, 518.62it/s]
Adding requests:  17%|â–ˆâ–‹        | 1356/8192 [00:02<00:13, 521.96it/s]
Adding requests:  17%|â–ˆâ–‹        | 1410/8192 [00:02<00:12, 526.38it/s]
Adding requests:  18%|â–ˆâ–Š        | 1463/8192 [00:02<00:12, 524.84it/s]
Adding requests:  19%|â–ˆâ–Š        | 1516/8192 [00:02<00:12, 524.54it/s]
Adding requests:  19%|â–ˆâ–‰        | 1569/8192 [00:03<00:12, 525.05it/s]
Adding requests:  20%|â–ˆâ–‰        | 1623/8192 [00:03<00:12, 528.99it/s]
Adding requests:  20%|â–ˆâ–ˆ        | 1676/8192 [00:03<00:12, 521.78it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 1730/8192 [00:03<00:12, 524.30it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1783/8192 [00:03<00:12, 519.16it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1836/8192 [00:03<00:12, 520.73it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1889/8192 [00:03<00:12, 520.65it/s]
Adding requests:  24%|â–ˆâ–ˆâ–Ž       | 1942/8192 [00:03<00:12, 519.26it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 1994/8192 [00:03<00:12, 503.09it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 2048/8192 [00:03<00:11, 512.28it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 2101/8192 [00:04<00:11, 517.40it/s]
Adding requests:  26%|â–ˆâ–ˆâ–‹       | 2153/8192 [00:04<00:11, 513.79it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2205/8192 [00:04<00:11, 510.61it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2260/8192 [00:04<00:11, 517.41it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2314/8192 [00:04<00:11, 521.65it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 2367/8192 [00:04<00:11, 518.24it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 2420/8192 [00:04<00:11, 519.86it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 2473/8192 [00:04<00:11, 519.62it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2525/8192 [00:04<00:10, 517.83it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆâ–      | 2580/8192 [00:05<00:10, 525.28it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2633/8192 [00:05<00:10, 521.01it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2686/8192 [00:05<00:10, 521.99it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2739/8192 [00:05<00:10, 517.31it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 2791/8192 [00:05<00:10, 515.35it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 2844/8192 [00:05<00:10, 517.27it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2897/8192 [00:05<00:10, 520.97it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2950/8192 [00:05<00:10, 515.82it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3003/8192 [00:05<00:10, 517.41it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3056/8192 [00:05<00:09, 518.74it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3108/8192 [00:06<00:09, 514.49it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3160/8192 [00:06<00:09, 515.76it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3212/8192 [00:06<00:09, 516.30it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3265/8192 [00:06<00:09, 520.21it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3318/8192 [00:06<00:09, 508.76it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3371/8192 [00:06<00:09, 514.25it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3425/8192 [00:06<00:09, 518.87it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3477/8192 [00:06<00:09, 506.81it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3528/8192 [00:06<00:09, 507.06it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3580/8192 [00:06<00:09, 509.84it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3632/8192 [00:07<00:08, 510.43it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3685/8192 [00:07<00:08, 513.83it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3737/8192 [00:07<00:08, 512.60it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3792/8192 [00:07<00:08, 522.53it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3846/8192 [00:07<00:08, 525.23it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3899/8192 [00:07<00:08, 523.06it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3952/8192 [00:07<00:08, 522.65it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4005/8192 [00:07<00:08, 521.76it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4058/8192 [00:07<00:07, 518.55it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4111/8192 [00:07<00:07, 519.27it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4164/8192 [00:08<00:07, 521.17it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4217/8192 [00:08<00:07, 522.27it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4270/8192 [00:08<00:07, 521.95it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4323/8192 [00:08<00:07, 524.08it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4377/8192 [00:08<00:07, 528.66it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4430/8192 [00:08<00:07, 525.49it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4483/8192 [00:08<00:07, 522.49it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4536/8192 [00:08<00:07, 518.70it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4589/8192 [00:08<00:06, 519.91it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4642/8192 [00:08<00:06, 513.45it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4694/8192 [00:09<00:06, 511.07it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4747/8192 [00:09<00:06, 516.11it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4799/8192 [00:09<00:06, 515.20it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4851/8192 [00:09<00:06, 516.16it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4903/8192 [00:09<00:06, 512.52it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4956/8192 [00:09<00:06, 516.99it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 5008/8192 [00:09<00:06, 517.68it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5062/8192 [00:09<00:05, 521.69it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5116/8192 [00:09<00:05, 526.50it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5169/8192 [00:10<00:05, 525.83it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5222/8192 [00:10<00:05, 523.06it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5275/8192 [00:10<00:05, 518.25it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5329/8192 [00:10<00:05, 523.76it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5382/8192 [00:10<00:05, 523.24it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5435/8192 [00:10<00:05, 524.00it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5488/8192 [00:10<00:05, 517.13it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5540/8192 [00:10<00:05, 516.29it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5592/8192 [00:10<00:05, 516.59it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5644/8192 [00:10<00:04, 517.05it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5696/8192 [00:11<00:04, 515.20it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5749/8192 [00:11<00:04, 517.12it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5802/8192 [00:11<00:04, 518.19it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5854/8192 [00:11<00:04, 516.47it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5908/8192 [00:11<00:04, 522.59it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5961/8192 [00:11<00:04, 521.71it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6014/8192 [00:11<00:04, 513.21it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6067/8192 [00:11<00:04, 517.04it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6119/8192 [00:11<00:04, 513.63it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6171/8192 [00:11<00:03, 512.79it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6225/8192 [00:12<00:03, 519.12it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6279/8192 [00:12<00:03, 522.94it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6333/8192 [00:12<00:03, 526.39it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6386/8192 [00:12<00:03, 527.44it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6441/8192 [00:12<00:03, 532.23it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6496/8192 [00:12<00:03, 535.10it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6550/8192 [00:12<00:03, 534.16it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6604/8192 [00:12<00:02, 531.62it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6658/8192 [00:12<00:02, 532.23it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6712/8192 [00:12<00:02, 529.25it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6765/8192 [00:13<00:02, 527.42it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6819/8192 [00:13<00:02, 531.07it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6874/8192 [00:13<00:02, 534.05it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6928/8192 [00:13<00:02, 535.61it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6982/8192 [00:13<00:02, 532.21it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7036/8192 [00:13<00:02, 529.94it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7090/8192 [00:13<00:02, 528.05it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7143/8192 [00:13<00:01, 526.96it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7196/8192 [00:13<00:01, 525.27it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7250/8192 [00:13<00:01, 528.04it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7304/8192 [00:14<00:01, 529.57it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7357/8192 [00:14<00:01, 512.70it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7412/8192 [00:14<00:01, 522.31it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7467/8192 [00:14<00:01, 527.75it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7521/8192 [00:14<00:01, 529.12it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7574/8192 [00:14<00:01, 527.48it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7627/8192 [00:14<00:01, 524.95it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7682/8192 [00:14<00:00, 531.26it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7736/8192 [00:14<00:00, 529.68it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7789/8192 [00:15<00:00, 524.04it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7843/8192 [00:15<00:00, 527.61it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7896/8192 [00:15<00:00, 526.94it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7949/8192 [00:15<00:00, 520.78it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8002/8192 [00:15<00:00, 519.49it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8054/8192 [00:15<00:00, 517.91it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8108/8192 [00:15<00:00, 521.90it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8161/8192 [00:15<00:00, 523.64it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:15<00:00, 519.33it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 1386/8192 [00:00<00:01, 6567.46it/s, est. speed input: 6725831.18 toks/s, output: 6567.68 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–       | 2043/8192 [00:07<00:27, 227.10it/s, est. speed input: 289420.23 toks/s, output: 282.64 toks/s]   
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 2319/8192 [00:10<00:32, 181.60it/s, est. speed input: 237350.83 toks/s, output: 231.79 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 2474/8192 [00:12<00:37, 151.61it/s, est. speed input: 209267.73 toks/s, output: 204.36 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 2571/8192 [00:12<00:37, 150.23it/s, est. speed input: 205676.33 toks/s, output: 200.86 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 2638/8192 [00:13<00:39, 142.25it/s, est. speed input: 200002.07 toks/s, output: 195.31 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2686/8192 [00:14<00:42, 129.53it/s, est. speed input: 193511.97 toks/s, output: 188.98 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2730/8192 [00:14<00:46, 116.35it/s, est. speed input: 187377.09 toks/s, output: 182.98 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 2794/8192 [00:15<00:48, 110.68it/s, est. speed input: 183090.99 toks/s, output: 178.80 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 2858/8192 [00:16<00:50, 105.90it/s, est. speed input: 179185.31 toks/s, output: 174.99 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2922/8192 [00:17<00:51, 102.01it/s, est. speed input: 175600.68 toks/s, output: 171.48 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 2986/8192 [00:17<00:52, 98.93it/s, est. speed input: 172293.02 toks/s, output: 168.25 toks/s] 
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3050/8192 [00:18<00:53, 96.62it/s, est. speed input: 169245.97 toks/s, output: 165.28 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3114/8192 [00:19<00:53, 95.34it/s, est. speed input: 166521.66 toks/s, output: 162.62 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3178/8192 [00:19<00:53, 93.93it/s, est. speed input: 163888.02 toks/s, output: 160.05 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3242/8192 [00:20<00:53, 92.91it/s, est. speed input: 161435.50 toks/s, output: 157.65 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3306/8192 [00:21<00:53, 92.16it/s, est. speed input: 159140.48 toks/s, output: 155.41 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3370/8192 [00:21<00:52, 91.66it/s, est. speed input: 157000.14 toks/s, output: 153.32 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3434/8192 [00:22<00:52, 91.29it/s, est. speed input: 154990.32 toks/s, output: 151.36 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3498/8192 [00:23<00:51, 91.04it/s, est. speed input: 153105.08 toks/s, output: 149.52 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3562/8192 [00:24<00:50, 90.82it/s, est. speed input: 151321.13 toks/s, output: 147.77 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3626/8192 [00:24<00:50, 90.61it/s, est. speed input: 149631.96 toks/s, output: 146.12 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3690/8192 [00:25<00:49, 91.02it/s, est. speed input: 148119.98 toks/s, output: 144.65 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3754/8192 [00:26<00:48, 90.76it/s, est. speed input: 146609.35 toks/s, output: 143.17 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3818/8192 [00:26<00:48, 90.58it/s, est. speed input: 145178.80 toks/s, output: 141.78 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3882/8192 [00:27<00:47, 90.47it/s, est. speed input: 143823.94 toks/s, output: 140.45 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3946/8192 [00:28<00:46, 90.37it/s, est. speed input: 142532.68 toks/s, output: 139.19 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4010/8192 [00:29<00:46, 90.81it/s, est. speed input: 141370.09 toks/s, output: 138.06 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4074/8192 [00:29<00:45, 90.63it/s, est. speed input: 140201.61 toks/s, output: 136.92 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4138/8192 [00:30<00:44, 90.52it/s, est. speed input: 139089.79 toks/s, output: 135.83 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4202/8192 [00:31<00:43, 90.81it/s, est. speed input: 138071.30 toks/s, output: 134.84 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4266/8192 [00:31<00:43, 91.06it/s, est. speed input: 137102.38 toks/s, output: 133.89 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4330/8192 [00:32<00:42, 91.22it/s, est. speed input: 136172.96 toks/s, output: 132.98 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4394/8192 [00:33<00:41, 90.92it/s, est. speed input: 135239.18 toks/s, output: 132.07 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4458/8192 [00:33<00:41, 90.65it/s, est. speed input: 134339.05 toks/s, output: 131.19 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4522/8192 [00:34<00:40, 90.51it/s, est. speed input: 133480.12 toks/s, output: 130.35 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4586/8192 [00:35<00:39, 90.43it/s, est. speed input: 132657.16 toks/s, output: 129.55 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4650/8192 [00:36<00:39, 90.27it/s, est. speed input: 131856.58 toks/s, output: 128.77 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4714/8192 [00:36<00:38, 90.23it/s, est. speed input: 131093.74 toks/s, output: 128.02 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4778/8192 [00:37<00:37, 90.65it/s, est. speed input: 130400.71 toks/s, output: 127.34 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4842/8192 [00:38<00:36, 90.82it/s, est. speed input: 129721.78 toks/s, output: 126.68 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4906/8192 [00:38<00:36, 90.58it/s, est. speed input: 129036.13 toks/s, output: 126.01 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4970/8192 [00:39<00:35, 90.94it/s, est. speed input: 128419.56 toks/s, output: 125.41 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5034/8192 [00:40<00:34, 90.63it/s, est. speed input: 127778.71 toks/s, output: 124.78 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5098/8192 [00:41<00:34, 90.52it/s, est. speed input: 127167.91 toks/s, output: 124.19 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5162/8192 [00:41<00:33, 90.37it/s, est. speed input: 126571.96 toks/s, output: 123.61 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5226/8192 [00:42<00:32, 90.21it/s, est. speed input: 125992.13 toks/s, output: 123.04 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5290/8192 [00:43<00:32, 90.09it/s, est. speed input: 125430.70 toks/s, output: 122.49 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5354/8192 [00:43<00:31, 90.07it/s, est. speed input: 124892.15 toks/s, output: 121.96 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5418/8192 [00:44<00:30, 90.01it/s, est. speed input: 124367.72 toks/s, output: 121.45 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5482/8192 [00:45<00:30, 89.83it/s, est. speed input: 123849.88 toks/s, output: 120.95 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5546/8192 [00:46<00:29, 90.31it/s, est. speed input: 123390.40 toks/s, output: 120.50 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5610/8192 [00:46<00:28, 90.23it/s, est. speed input: 122916.12 toks/s, output: 120.04 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5674/8192 [00:47<00:27, 90.07it/s, est. speed input: 122449.27 toks/s, output: 119.58 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5738/8192 [00:48<00:27, 90.02it/s, est. speed input: 121999.97 toks/s, output: 119.14 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5802/8192 [00:48<00:26, 89.86it/s, est. speed input: 121555.33 toks/s, output: 118.71 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5866/8192 [00:49<00:25, 89.93it/s, est. speed input: 121135.55 toks/s, output: 118.30 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5930/8192 [00:50<00:25, 89.70it/s, est. speed input: 120710.24 toks/s, output: 117.88 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5994/8192 [00:51<00:24, 89.70it/s, est. speed input: 120306.82 toks/s, output: 117.49 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6058/8192 [00:51<00:23, 89.73it/s, est. speed input: 119916.29 toks/s, output: 117.11 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6122/8192 [00:52<00:23, 89.70it/s, est. speed input: 119532.78 toks/s, output: 116.73 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6186/8192 [00:53<00:22, 89.66it/s, est. speed input: 119159.22 toks/s, output: 116.37 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6250/8192 [00:53<00:21, 89.66it/s, est. speed input: 118796.87 toks/s, output: 116.01 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6314/8192 [00:54<00:20, 89.71it/s, est. speed input: 118446.56 toks/s, output: 115.67 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6378/8192 [00:55<00:20, 89.67it/s, est. speed input: 118101.49 toks/s, output: 115.33 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6442/8192 [00:56<00:19, 89.59it/s, est. speed input: 117762.35 toks/s, output: 115.00 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6506/8192 [00:56<00:18, 89.59it/s, est. speed input: 117434.70 toks/s, output: 114.68 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6570/8192 [00:57<00:18, 90.04it/s, est. speed input: 117139.24 toks/s, output: 114.39 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6634/8192 [00:58<00:17, 90.23it/s, est. speed input: 116844.45 toks/s, output: 114.11 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6698/8192 [00:58<00:16, 90.00it/s, est. speed input: 116538.02 toks/s, output: 113.81 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6762/8192 [00:59<00:15, 89.94it/s, est. speed input: 116243.54 toks/s, output: 113.52 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6826/8192 [01:00<00:15, 89.89it/s, est. speed input: 115956.04 toks/s, output: 113.24 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6890/8192 [01:00<00:14, 89.69it/s, est. speed input: 115666.90 toks/s, output: 112.96 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6954/8192 [01:01<00:13, 89.69it/s, est. speed input: 115391.55 toks/s, output: 112.69 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7018/8192 [01:02<00:13, 89.65it/s, est. speed input: 115120.14 toks/s, output: 112.42 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7082/8192 [01:03<00:12, 89.62it/s, est. speed input: 114855.17 toks/s, output: 112.16 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7146/8192 [01:03<00:11, 90.02it/s, est. speed input: 114615.75 toks/s, output: 111.93 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7210/8192 [01:04<00:10, 89.87it/s, est. speed input: 114361.97 toks/s, output: 111.68 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7274/8192 [01:05<00:10, 90.18it/s, est. speed input: 114132.31 toks/s, output: 111.46 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7338/8192 [01:05<00:09, 89.93it/s, est. speed input: 113886.45 toks/s, output: 111.22 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7402/8192 [01:06<00:08, 90.29it/s, est. speed input: 113670.27 toks/s, output: 111.01 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7466/8192 [01:07<00:08, 90.06it/s, est. speed input: 113436.87 toks/s, output: 110.78 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7530/8192 [01:08<00:07, 89.79it/s, est. speed input: 113203.68 toks/s, output: 110.55 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7594/8192 [01:08<00:06, 89.76it/s, est. speed input: 112982.04 toks/s, output: 110.33 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7658/8192 [01:09<00:05, 89.69it/s, est. speed input: 112763.07 toks/s, output: 110.12 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7722/8192 [01:10<00:05, 89.65it/s, est. speed input: 112549.01 toks/s, output: 109.91 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7786/8192 [01:10<00:04, 89.54it/s, est. speed input: 112335.72 toks/s, output: 109.70 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7850/8192 [01:11<00:03, 89.60it/s, est. speed input: 112132.31 toks/s, output: 109.50 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7914/8192 [01:12<00:03, 89.55it/s, est. speed input: 111929.34 toks/s, output: 109.31 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7978/8192 [01:13<00:02, 89.51it/s, est. speed input: 111729.80 toks/s, output: 109.11 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8042/8192 [01:13<00:01, 89.39it/s, est. speed input: 111530.66 toks/s, output: 108.92 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8106/8192 [01:14<00:00, 90.03it/s, est. speed input: 111363.89 toks/s, output: 108.75 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8170/8192 [01:14<00:00, 111.83it/s, est. speed input: 111869.55 toks/s, output: 109.25 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [01:14<00:00, 111.83it/s, est. speed input: 112169.69 toks/s, output: 109.54 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [01:14<00:00, 109.54it/s, est. speed input: 112169.69 toks/s, output: 109.54 toks/s]
[rank0]:[W125 16:07:56.840251659 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16 ==========
Time: 2026-01-25 21:52:46
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:52:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=467806) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467806) WARNING 01-25 21:53:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.96 requests/s, 475.31 total tokens/s, 27.96 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-25 21:52:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:52:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:52:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:52:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:52:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:52:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:52:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:52:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:52:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:53:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:53:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:53:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:53:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:53:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:53:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=467806) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=467806) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.66it/s]
(EngineCore_DP0 pid=467806) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.65it/s]
(EngineCore_DP0 pid=467806) 
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=467806) [2026-01-25 21:53:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=467806) 2026-01-25 21:53:16,070 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=467806) 2026-01-25 21:53:16,109 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=467806) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]
(EngineCore_DP0 pid=467806) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.83it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 2544.69it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:23,  1.53it/s, est. speed input: 24.48 toks/s, output: 1.53 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:15,  8.12it/s, est. speed input: 103.26 toks/s, output: 6.45 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:08, 13.85it/s, est. speed input: 160.69 toks/s, output: 10.04 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:01<00:06, 18.56it/s, est. speed input: 204.29 toks/s, output: 12.77 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:01<00:04, 22.27it/s, est. speed input: 238.48 toks/s, output: 14.90 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:04, 25.28it/s, est. speed input: 266.68 toks/s, output: 16.67 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 27.50it/s, est. speed input: 289.82 toks/s, output: 18.11 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:03, 29.06it/s, est. speed input: 309.01 toks/s, output: 19.31 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:03, 30.14it/s, est. speed input: 325.18 toks/s, output: 20.32 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 31.03it/s, est. speed input: 339.41 toks/s, output: 21.21 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 31.56it/s, est. speed input: 351.54 toks/s, output: 21.97 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 31.94it/s, est. speed input: 362.20 toks/s, output: 22.64 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:02<00:02, 32.21it/s, est. speed input: 371.62 toks/s, output: 23.23 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:02<00:02, 32.40it/s, est. speed input: 380.02 toks/s, output: 23.75 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:02, 32.69it/s, est. speed input: 387.87 toks/s, output: 24.24 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:02, 31.97it/s, est. speed input: 393.11 toks/s, output: 24.57 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 32.32it/s, est. speed input: 399.48 toks/s, output: 24.97 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 32.52it/s, est. speed input: 405.20 toks/s, output: 25.32 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 32.44it/s, est. speed input: 410.02 toks/s, output: 25.63 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 32.46it/s, est. speed input: 414.59 toks/s, output: 25.91 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:03<00:01, 32.53it/s, est. speed input: 418.88 toks/s, output: 26.18 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:03<00:01, 32.57it/s, est. speed input: 422.83 toks/s, output: 26.43 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:03<00:01, 32.62it/s, est. speed input: 426.52 toks/s, output: 26.66 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 32.56it/s, est. speed input: 429.81 toks/s, output: 26.86 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 32.71it/s, est. speed input: 433.15 toks/s, output: 27.07 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 32.69it/s, est. speed input: 436.10 toks/s, output: 27.26 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 32.70it/s, est. speed input: 438.90 toks/s, output: 27.43 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 32.77it/s, est. speed input: 441.60 toks/s, output: 27.60 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:04<00:00, 32.77it/s, est. speed input: 444.08 toks/s, output: 27.75 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:04<00:00, 32.79it/s, est. speed input: 446.45 toks/s, output: 27.90 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:04<00:00, 32.79it/s, est. speed input: 448.65 toks/s, output: 28.04 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:04<00:00, 32.86it/s, est. speed input: 450.83 toks/s, output: 28.18 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 32.86it/s, est. speed input: 452.53 toks/s, output: 28.28 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 28.28it/s, est. speed input: 452.53 toks/s, output: 28.28 toks/s]
[rank0]:[W125 21:53:23.692566969 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 21:53:25
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:53:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=468974) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468974) WARNING 01-25 21:53:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.21 requests/s, 3639.23 total tokens/s, 28.21 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-25 21:53:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:53:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:53:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:53:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:53:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:53:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:53:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:53:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:53:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:53:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:53:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:53:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:53:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:53:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=468974) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=468974) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.61it/s]
(EngineCore_DP0 pid=468974) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.60it/s]
(EngineCore_DP0 pid=468974) 
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=468974) [2026-01-25 21:53:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=468974) 2026-01-25 21:53:53,076 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=468974) 2026-01-25 21:53:53,123 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=468974) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.01it/s]
(EngineCore_DP0 pid=468974) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.15it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 1392.97it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:00,  2.11it/s, est. speed input: 269.63 toks/s, output: 2.11 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:11, 10.31it/s, est. speed input: 1070.15 toks/s, output: 8.36 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:07, 16.50it/s, est. speed input: 1597.86 toks/s, output: 12.48 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:05, 21.08it/s, est. speed input: 1972.77 toks/s, output: 15.41 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:04, 24.40it/s, est. speed input: 2251.94 toks/s, output: 17.59 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:04, 26.74it/s, est. speed input: 2466.59 toks/s, output: 19.27 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 28.31it/s, est. speed input: 2634.12 toks/s, output: 20.58 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:03, 29.23it/s, est. speed input: 2765.13 toks/s, output: 21.60 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:03, 30.20it/s, est. speed input: 2882.45 toks/s, output: 22.52 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 30.91it/s, est. speed input: 2982.33 toks/s, output: 23.30 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 31.43it/s, est. speed input: 3068.13 toks/s, output: 23.97 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 31.52it/s, est. speed input: 3136.31 toks/s, output: 24.50 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 31.55it/s, est. speed input: 3195.02 toks/s, output: 24.96 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:02<00:02, 31.61it/s, est. speed input: 3247.46 toks/s, output: 25.37 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:02, 31.62it/s, est. speed input: 3293.30 toks/s, output: 25.73 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:02, 31.67it/s, est. speed input: 3334.83 toks/s, output: 26.05 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 31.68it/s, est. speed input: 3371.79 toks/s, output: 26.34 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 31.69it/s, est. speed input: 3405.35 toks/s, output: 26.60 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 31.72it/s, est. speed input: 3436.08 toks/s, output: 26.84 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 31.76it/s, est. speed input: 3464.34 toks/s, output: 27.06 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 31.88it/s, est. speed input: 3491.63 toks/s, output: 27.28 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:03<00:01, 31.92it/s, est. speed input: 3516.16 toks/s, output: 27.47 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:03<00:01, 31.92it/s, est. speed input: 3538.30 toks/s, output: 27.64 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 31.94it/s, est. speed input: 3559.02 toks/s, output: 27.80 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 31.95it/s, est. speed input: 3578.30 toks/s, output: 27.96 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 31.95it/s, est. speed input: 3596.05 toks/s, output: 28.09 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 32.00it/s, est. speed input: 3613.30 toks/s, output: 28.23 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 31.95it/s, est. speed input: 3628.43 toks/s, output: 28.35 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 31.93it/s, est. speed input: 3642.74 toks/s, output: 28.46 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:04<00:00, 31.93it/s, est. speed input: 3656.31 toks/s, output: 28.56 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:04<00:00, 31.69it/s, est. speed input: 3666.31 toks/s, output: 28.64 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:04<00:00, 31.77it/s, est. speed input: 3678.49 toks/s, output: 28.74 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 31.77it/s, est. speed input: 3687.20 toks/s, output: 28.81 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 28.80it/s, est. speed input: 3687.20 toks/s, output: 28.81 toks/s]
[rank0]:[W125 21:53:59.573343086 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 21:54:01
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:54:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=470020) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=470020) WARNING 01-25 21:54:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.63 requests/s, 8129.45 total tokens/s, 31.63 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-25 21:54:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:54:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:54:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:54:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:54:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:54:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:54:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:54:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:54:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 21:54:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 21:54:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 21:54:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 21:54:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:54:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:54:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:54:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:54:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=470020) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=470020) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.66it/s]
(EngineCore_DP0 pid=470020) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.65it/s]
(EngineCore_DP0 pid=470020) 
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=470020) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=470020) 2026-01-25 21:54:29,638 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=470020) 2026-01-25 21:54:29,668 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=470020) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.75it/s]
(EngineCore_DP0 pid=470020) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.41it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:00<00:00, 807.42it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 993.25it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|â–         | 2/128 [00:00<00:07, 16.70it/s, est. speed input: 4275.62 toks/s, output: 16.70 toks/s]
Processed prompts:   5%|â–         | 6/128 [00:00<00:04, 26.60it/s, est. speed input: 6430.36 toks/s, output: 25.11 toks/s]
Processed prompts:   8%|â–Š         | 10/128 [00:00<00:03, 29.86it/s, est. speed input: 7164.97 toks/s, output: 27.99 toks/s]
Processed prompts:  11%|â–ˆ         | 14/128 [00:00<00:03, 31.42it/s, est. speed input: 7536.58 toks/s, output: 29.44 toks/s]
Processed prompts:  14%|â–ˆâ–        | 18/128 [00:00<00:03, 32.25it/s, est. speed input: 7754.97 toks/s, output: 30.29 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 22/128 [00:00<00:03, 32.43it/s, est. speed input: 7863.51 toks/s, output: 30.72 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 26/128 [00:00<00:03, 32.64it/s, est. speed input: 7949.93 toks/s, output: 31.05 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:00<00:02, 32.75it/s, est. speed input: 8012.16 toks/s, output: 31.30 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 34/128 [00:01<00:02, 32.79it/s, est. speed input: 8057.49 toks/s, output: 31.47 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 38/128 [00:01<00:02, 32.88it/s, est. speed input: 8099.55 toks/s, output: 31.64 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:01<00:02, 32.91it/s, est. speed input: 8130.39 toks/s, output: 31.76 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:02, 32.91it/s, est. speed input: 8155.15 toks/s, output: 31.86 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [00:01<00:02, 33.03it/s, est. speed input: 8183.91 toks/s, output: 31.97 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:01<00:02, 33.21it/s, est. speed input: 8213.99 toks/s, output: 32.09 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [00:01<00:02, 33.37it/s, est. speed input: 8241.91 toks/s, output: 32.19 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [00:01<00:01, 33.31it/s, est. speed input: 8257.76 toks/s, output: 32.26 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:02<00:01, 33.24it/s, est. speed input: 8270.01 toks/s, output: 32.30 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [00:02<00:01, 33.27it/s, est. speed input: 8284.64 toks/s, output: 32.36 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [00:02<00:01, 33.23it/s, est. speed input: 8295.36 toks/s, output: 32.40 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:02<00:01, 33.11it/s, est. speed input: 8300.98 toks/s, output: 32.43 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:02<00:01, 33.16it/s, est. speed input: 8311.14 toks/s, output: 32.47 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [00:02<00:01, 33.26it/s, est. speed input: 8323.19 toks/s, output: 32.51 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:02<00:01, 33.19it/s, est. speed input: 8328.98 toks/s, output: 32.53 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [00:02<00:01, 33.15it/s, est. speed input: 8334.56 toks/s, output: 32.56 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [00:03<00:00, 33.18it/s, est. speed input: 8341.80 toks/s, output: 32.58 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:03<00:00, 33.08it/s, est. speed input: 8344.20 toks/s, output: 32.59 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:03<00:00, 33.26it/s, est. speed input: 8354.51 toks/s, output: 32.63 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [00:03<00:00, 33.40it/s, est. speed input: 8364.43 toks/s, output: 32.67 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [00:03<00:00, 33.21it/s, est. speed input: 8365.30 toks/s, output: 32.68 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [00:03<00:00, 33.06it/s, est. speed input: 8365.76 toks/s, output: 32.68 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:03<00:00, 32.93it/s, est. speed input: 8365.23 toks/s, output: 32.68 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:03<00:00, 32.83it/s, est. speed input: 8364.58 toks/s, output: 32.67 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 32.83it/s, est. speed input: 8368.34 toks/s, output: 32.69 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 32.69it/s, est. speed input: 8368.34 toks/s, output: 32.69 toks/s]
[rank0]:[W125 21:54:35.746670211 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16 ==========
Time: 2026-01-26 07:35:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:35:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=973561) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=973561) WARNING 01-26 07:35:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.69 requests/s, 504.80 total tokens/s, 29.69 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:35:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:35:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:35:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:35:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=973561) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=973561) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.66it/s]
(EngineCore_DP0 pid=973561) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.65it/s]
(EngineCore_DP0 pid=973561) 
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=973561) [2026-01-26 07:35:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=973561) 2026-01-26 07:35:46,240 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=973561) 2026-01-26 07:35:46,275 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=973561) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=973561) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.03it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 2785.19it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:03,  2.00it/s, est. speed input: 32.00 toks/s, output: 2.00 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:12, 10.02it/s, est. speed input: 129.27 toks/s, output: 8.08 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:07, 16.26it/s, est. speed input: 194.85 toks/s, output: 12.18 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:05, 20.95it/s, est. speed input: 241.97 toks/s, output: 15.12 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:04, 24.47it/s, est. speed input: 277.72 toks/s, output: 17.36 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:03, 27.01it/s, est. speed input: 305.56 toks/s, output: 19.10 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 28.85it/s, est. speed input: 327.96 toks/s, output: 20.50 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:03, 30.16it/s, est. speed input: 346.35 toks/s, output: 21.65 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:03, 31.08it/s, est. speed input: 361.66 toks/s, output: 22.60 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 31.73it/s, est. speed input: 374.64 toks/s, output: 23.41 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 32.22it/s, est. speed input: 385.87 toks/s, output: 24.12 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 32.47it/s, est. speed input: 395.38 toks/s, output: 24.71 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 33.08it/s, est. speed input: 404.81 toks/s, output: 25.30 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:02<00:02, 33.29it/s, est. speed input: 412.62 toks/s, output: 25.79 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:02, 33.29it/s, est. speed input: 419.25 toks/s, output: 26.20 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:02, 33.32it/s, est. speed input: 425.24 toks/s, output: 26.58 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 33.34it/s, est. speed input: 430.66 toks/s, output: 26.92 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 33.42it/s, est. speed input: 435.68 toks/s, output: 27.23 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 33.47it/s, est. speed input: 440.24 toks/s, output: 27.51 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 33.52it/s, est. speed input: 444.45 toks/s, output: 27.78 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 33.45it/s, est. speed input: 448.11 toks/s, output: 28.01 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:03<00:01, 33.42it/s, est. speed input: 451.52 toks/s, output: 28.22 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:03<00:01, 33.74it/s, est. speed input: 455.25 toks/s, output: 28.45 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 33.93it/s, est. speed input: 458.66 toks/s, output: 28.67 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 34.05it/s, est. speed input: 461.79 toks/s, output: 28.86 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 34.17it/s, est. speed input: 464.78 toks/s, output: 29.05 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 34.24it/s, est. speed input: 467.55 toks/s, output: 29.22 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 34.30it/s, est. speed input: 470.17 toks/s, output: 29.39 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 34.27it/s, est. speed input: 472.52 toks/s, output: 29.53 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 34.31it/s, est. speed input: 474.82 toks/s, output: 29.68 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:04<00:00, 34.28it/s, est. speed input: 476.91 toks/s, output: 29.81 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:04<00:00, 34.36it/s, est. speed input: 479.02 toks/s, output: 29.94 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 34.36it/s, est. speed input: 480.45 toks/s, output: 30.03 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 30.03it/s, est. speed input: 480.45 toks/s, output: 30.03 toks/s]
[rank0]:[W126 07:35:53.290606919 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 07:35:55
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:36:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=974639) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=974639) WARNING 01-26 07:36:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.44 requests/s, 3926.12 total tokens/s, 30.44 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 07:36:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:36:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:36:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:36:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=974639) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=974639) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.62it/s]
(EngineCore_DP0 pid=974639) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.61it/s]
(EngineCore_DP0 pid=974639) 
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=974639) [2026-01-26 07:36:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=974639) 2026-01-26 07:36:20,461 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=974639) 2026-01-26 07:36:20,554 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=974639) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  2.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.46it/s]
(EngineCore_DP0 pid=974639) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.35it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 1376.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.77it/s, est. speed input: 354.85 toks/s, output: 2.77 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:09, 12.70it/s, est. speed input: 1338.27 toks/s, output: 10.45 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:06, 19.29it/s, est. speed input: 1928.99 toks/s, output: 15.07 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:04, 23.61it/s, est. speed input: 2317.08 toks/s, output: 18.10 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:04, 26.69it/s, est. speed input: 2600.20 toks/s, output: 20.31 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:00<00:03, 28.69it/s, est. speed input: 2807.98 toks/s, output: 21.94 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 30.18it/s, est. speed input: 2973.30 toks/s, output: 23.23 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:03, 31.21it/s, est. speed input: 3105.29 toks/s, output: 24.26 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:02, 31.95it/s, est. speed input: 3214.22 toks/s, output: 25.11 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 32.73it/s, est. speed input: 3312.39 toks/s, output: 25.88 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 33.25it/s, est. speed input: 3395.16 toks/s, output: 26.52 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 33.63it/s, est. speed input: 3466.58 toks/s, output: 27.08 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 33.62it/s, est. speed input: 3522.17 toks/s, output: 27.52 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:02, 33.67it/s, est. speed input: 3572.17 toks/s, output: 27.91 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:02, 33.72it/s, est. speed input: 3616.78 toks/s, output: 28.26 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:01, 33.95it/s, est. speed input: 3660.12 toks/s, output: 28.59 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 34.08it/s, est. speed input: 3698.36 toks/s, output: 28.89 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 34.03it/s, est. speed input: 3730.52 toks/s, output: 29.14 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 33.97it/s, est. speed input: 3759.01 toks/s, output: 29.37 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 33.94it/s, est. speed input: 3785.12 toks/s, output: 29.57 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 33.98it/s, est. speed input: 3810.05 toks/s, output: 29.77 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 34.25it/s, est. speed input: 3836.50 toks/s, output: 29.97 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:02<00:01, 34.11it/s, est. speed input: 3856.17 toks/s, output: 30.13 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 34.03it/s, est. speed input: 3874.48 toks/s, output: 30.27 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 33.94it/s, est. speed input: 3890.89 toks/s, output: 30.40 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 33.91it/s, est. speed input: 3906.71 toks/s, output: 30.52 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 33.90it/s, est. speed input: 3921.51 toks/s, output: 30.64 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 33.81it/s, est. speed input: 3934.24 toks/s, output: 30.74 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 33.74it/s, est. speed input: 3946.04 toks/s, output: 30.83 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 33.73it/s, est. speed input: 3957.55 toks/s, output: 30.92 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 33.71it/s, est. speed input: 3968.23 toks/s, output: 31.00 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:04<00:00, 33.71it/s, est. speed input: 3978.45 toks/s, output: 31.08 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 33.71it/s, est. speed input: 3985.55 toks/s, output: 31.14 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 31.13it/s, est. speed input: 3985.55 toks/s, output: 31.14 toks/s]
[rank0]:[W126 07:36:26.969544625 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 07:36:28
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:36:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=975712) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=975712) WARNING 01-26 07:36:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.73 requests/s, 7641.02 total tokens/s, 29.73 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 07:36:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:36:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:36:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:36:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=975712) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=975712) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.64it/s]
(EngineCore_DP0 pid=975712) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.64it/s]
(EngineCore_DP0 pid=975712) 
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=975712) [2026-01-26 07:36:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=975712) 2026-01-26 07:36:54,603 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=975712) 2026-01-26 07:36:54,642 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=975712) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.84it/s]
(EngineCore_DP0 pid=975712) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.75it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:00<00:00, 886.71it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 1025.79it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:52,  2.42it/s, est. speed input: 618.66 toks/s, output: 2.42 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:10, 11.56it/s, est. speed input: 2411.93 toks/s, output: 9.42 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:06, 18.06it/s, est. speed input: 3545.51 toks/s, output: 13.85 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:05, 22.64it/s, est. speed input: 4326.57 toks/s, output: 16.90 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:04, 25.91it/s, est. speed input: 4900.17 toks/s, output: 19.14 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:03, 28.19it/s, est. speed input: 5337.05 toks/s, output: 20.85 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 29.83it/s, est. speed input: 5683.60 toks/s, output: 22.20 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:03, 30.95it/s, est. speed input: 5961.98 toks/s, output: 23.29 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:02, 31.70it/s, est. speed input: 6189.88 toks/s, output: 24.18 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 32.36it/s, est. speed input: 6388.20 toks/s, output: 24.95 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 32.66it/s, est. speed input: 6549.05 toks/s, output: 25.58 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 32.95it/s, est. speed input: 6691.37 toks/s, output: 26.14 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 33.22it/s, est. speed input: 6818.40 toks/s, output: 26.63 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:02, 33.31it/s, est. speed input: 6925.87 toks/s, output: 27.05 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:02, 33.66it/s, est. speed input: 7032.07 toks/s, output: 27.47 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:01, 33.87it/s, est. speed input: 7125.87 toks/s, output: 27.84 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 34.03it/s, est. speed input: 7210.60 toks/s, output: 28.17 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 34.08it/s, est. speed input: 7285.02 toks/s, output: 28.46 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 34.05it/s, est. speed input: 7350.53 toks/s, output: 28.71 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 33.97it/s, est. speed input: 7408.35 toks/s, output: 28.94 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 33.93it/s, est. speed input: 7461.62 toks/s, output: 29.15 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 33.82it/s, est. speed input: 7508.28 toks/s, output: 29.33 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:03<00:01, 33.79it/s, est. speed input: 7552.41 toks/s, output: 29.50 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 33.79it/s, est. speed input: 7593.77 toks/s, output: 29.66 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 33.83it/s, est. speed input: 7633.29 toks/s, output: 29.82 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 33.88it/s, est. speed input: 7670.57 toks/s, output: 29.96 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 33.80it/s, est. speed input: 7702.55 toks/s, output: 30.09 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 33.77it/s, est. speed input: 7732.89 toks/s, output: 30.21 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 33.67it/s, est. speed input: 7759.39 toks/s, output: 30.31 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 33.55it/s, est. speed input: 7783.16 toks/s, output: 30.40 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 33.20it/s, est. speed input: 7799.03 toks/s, output: 30.46 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:04<00:00, 33.28it/s, est. speed input: 7821.63 toks/s, output: 30.55 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 33.28it/s, est. speed input: 7841.25 toks/s, output: 30.63 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:04<00:00, 30.63it/s, est. speed input: 7841.25 toks/s, output: 30.63 toks/s]
[rank0]:[W126 07:37:00.710974413 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:10:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:10:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1032400) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1032400) WARNING 01-26 08:11:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.01 requests/s, 15910.31 total tokens/s, 31.01 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:10:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:10:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:10:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:10:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:10:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:10:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:10:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:10:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:10:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:11:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:11:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:11:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:11:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:11:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:11:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1032400) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1032400) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.68it/s]
(EngineCore_DP0 pid=1032400) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.67it/s]
(EngineCore_DP0 pid=1032400) 
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1032400) [2026-01-26 08:11:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1032400) 2026-01-26 08:11:17,486 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1032400) 2026-01-26 08:11:17,517 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1032400) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  2.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.25it/s]
(EngineCore_DP0 pid=1032400) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.03it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:00<00:00, 535.34it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 709.68it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|â–         | 2/128 [00:00<00:06, 18.19it/s, est. speed input: 9317.28 toks/s, output: 18.20 toks/s]
Processed prompts:   5%|â–         | 6/128 [00:00<00:04, 26.87it/s, est. speed input: 13132.15 toks/s, output: 25.65 toks/s]
Processed prompts:   8%|â–Š         | 10/128 [00:00<00:04, 29.45it/s, est. speed input: 14324.85 toks/s, output: 27.98 toks/s]
Processed prompts:  11%|â–ˆ         | 14/128 [00:00<00:03, 30.78it/s, est. speed input: 14953.20 toks/s, output: 29.20 toks/s]
Processed prompts:  14%|â–ˆâ–        | 18/128 [00:00<00:03, 31.39it/s, est. speed input: 15294.44 toks/s, output: 29.87 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 22/128 [00:00<00:03, 31.87it/s, est. speed input: 15545.38 toks/s, output: 30.36 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 26/128 [00:00<00:03, 32.13it/s, est. speed input: 15716.82 toks/s, output: 30.70 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:00<00:03, 32.18it/s, est. speed input: 15820.94 toks/s, output: 30.90 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 34/128 [00:01<00:02, 32.59it/s, est. speed input: 15966.29 toks/s, output: 31.18 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 38/128 [00:01<00:02, 32.67it/s, est. speed input: 16051.62 toks/s, output: 31.35 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:01<00:02, 32.67it/s, est. speed input: 16113.79 toks/s, output: 31.47 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:02, 32.64it/s, est. speed input: 16161.51 toks/s, output: 31.56 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [00:01<00:02, 32.66it/s, est. speed input: 16206.91 toks/s, output: 31.65 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:01<00:02, 32.65it/s, est. speed input: 16242.82 toks/s, output: 31.72 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [00:01<00:02, 32.66it/s, est. speed input: 16275.26 toks/s, output: 31.79 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [00:01<00:02, 32.69it/s, est. speed input: 16306.62 toks/s, output: 31.85 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:02<00:01, 32.84it/s, est. speed input: 16346.56 toks/s, output: 31.93 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [00:02<00:01, 33.07it/s, est. speed input: 16394.26 toks/s, output: 32.02 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [00:02<00:01, 33.22it/s, est. speed input: 16434.90 toks/s, output: 32.10 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:02<00:01, 33.17it/s, est. speed input: 16459.39 toks/s, output: 32.15 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:02<00:01, 33.11it/s, est. speed input: 16479.61 toks/s, output: 32.19 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [00:02<00:01, 33.06it/s, est. speed input: 16497.30 toks/s, output: 32.22 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:02<00:01, 33.07it/s, est. speed input: 16516.40 toks/s, output: 32.26 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [00:02<00:01, 32.99it/s, est. speed input: 16528.38 toks/s, output: 32.28 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [00:03<00:00, 32.98it/s, est. speed input: 16541.90 toks/s, output: 32.31 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:03<00:00, 33.00it/s, est. speed input: 16556.30 toks/s, output: 32.34 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:03<00:00, 32.99it/s, est. speed input: 16568.32 toks/s, output: 32.36 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [00:03<00:00, 32.92it/s, est. speed input: 16575.80 toks/s, output: 32.37 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [00:03<00:00, 32.95it/s, est. speed input: 16586.86 toks/s, output: 32.40 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [00:03<00:00, 32.91it/s, est. speed input: 16594.26 toks/s, output: 32.41 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:03<00:00, 32.92it/s, est. speed input: 16603.26 toks/s, output: 32.43 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:03<00:00, 32.91it/s, est. speed input: 16610.52 toks/s, output: 32.44 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 32.91it/s, est. speed input: 16612.23 toks/s, output: 32.45 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 32.44it/s, est. speed input: 16612.23 toks/s, output: 32.45 toks/s]
[rank0]:[W126 08:11:24.996594494 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:11:26
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:11:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1033419) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1033419) WARNING 01-26 08:11:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.71 requests/s, 31481.61 total tokens/s, 30.71 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:11:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:11:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:11:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:11:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:11:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:11:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:11:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:11:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:11:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:11:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:11:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:11:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:11:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:11:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1033419) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1033419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.67it/s]
(EngineCore_DP0 pid=1033419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.67it/s]
(EngineCore_DP0 pid=1033419) 
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1033419) [2026-01-26 08:11:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1033419) 2026-01-26 08:11:54,505 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1033419) 2026-01-26 08:11:54,536 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1033419) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.57it/s]
(EngineCore_DP0 pid=1033419) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.41it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|â–ˆâ–ˆ        | 26/128 [00:00<00:00, 256.02it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:00<00:00, 407.32it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 448.44it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 421.93it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:03, 39.09it/s, est. speed input: 40037.95 toks/s, output: 39.10 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:03, 35.52it/s, est. speed input: 36934.98 toks/s, output: 36.07 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:03, 34.36it/s, est. speed input: 35893.23 toks/s, output: 35.05 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:03, 33.83it/s, est. speed input: 35379.60 toks/s, output: 34.55 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:00<00:03, 33.50it/s, est. speed input: 35047.81 toks/s, output: 34.22 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:00<00:03, 33.34it/s, est. speed input: 34844.63 toks/s, output: 34.03 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:00<00:02, 33.25it/s, est. speed input: 34704.84 toks/s, output: 33.89 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:00<00:02, 33.31it/s, est. speed input: 34647.15 toks/s, output: 33.83 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 33.36it/s, est. speed input: 34605.99 toks/s, output: 33.79 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 33.43it/s, est. speed input: 34586.50 toks/s, output: 33.78 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 33.42it/s, est. speed input: 34552.23 toks/s, output: 33.74 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 33.41it/s, est. speed input: 34521.09 toks/s, output: 33.71 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:02, 33.27it/s, est. speed input: 34460.20 toks/s, output: 33.65 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:01<00:02, 33.20it/s, est. speed input: 34417.07 toks/s, output: 33.61 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:01<00:02, 33.21it/s, est. speed input: 34391.53 toks/s, output: 33.58 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:01<00:01, 33.13it/s, est. speed input: 34349.78 toks/s, output: 33.54 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 33.01it/s, est. speed input: 34300.06 toks/s, output: 33.50 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 32.92it/s, est. speed input: 34256.37 toks/s, output: 33.45 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 32.86it/s, est. speed input: 34216.56 toks/s, output: 33.41 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 32.81it/s, est. speed input: 34179.81 toks/s, output: 33.38 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 32.83it/s, est. speed input: 34154.08 toks/s, output: 33.35 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:02<00:01, 32.83it/s, est. speed input: 34130.00 toks/s, output: 33.33 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:02<00:01, 32.85it/s, est. speed input: 34110.38 toks/s, output: 33.31 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:02<00:00, 32.74it/s, est. speed input: 34075.30 toks/s, output: 33.28 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 32.72it/s, est. speed input: 34050.61 toks/s, output: 33.25 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 32.71it/s, est. speed input: 34028.30 toks/s, output: 33.23 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 32.71it/s, est. speed input: 34007.86 toks/s, output: 33.21 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 32.68it/s, est. speed input: 33985.88 toks/s, output: 33.19 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 32.73it/s, est. speed input: 33973.24 toks/s, output: 33.18 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 32.72it/s, est. speed input: 33957.16 toks/s, output: 33.16 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:03<00:00, 32.71it/s, est. speed input: 33941.04 toks/s, output: 33.15 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 32.71it/s, est. speed input: 33934.79 toks/s, output: 33.14 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 33.14it/s, est. speed input: 33934.79 toks/s, output: 33.14 toks/s]
[rank0]:[W126 08:12:00.959642908 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:12:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:12:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1034443) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1034443) WARNING 01-26 08:12:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 61.83 requests/s, 63373.35 total tokens/s, 61.83 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:12:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:12:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1034443) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1034443) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.63it/s]
(EngineCore_DP0 pid=1034443) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.62it/s]
(EngineCore_DP0 pid=1034443) 
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1034443) [2026-01-26 08:12:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1034443) 2026-01-26 08:12:31,897 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1034443) 2026-01-26 08:12:31,956 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1034443) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 15.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 15.56it/s]
(EngineCore_DP0 pid=1034443) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.14it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  12%|â–ˆâ–        | 31/256 [00:00<00:00, 306.72it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 84/256 [00:00<00:00, 437.13it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 135/256 [00:00<00:00, 469.31it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 185/256 [00:00<00:00, 480.83it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 238/256 [00:00<00:00, 495.71it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 475.31it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|â–ˆ         | 28/256 [00:00<00:01, 216.25it/s, est. speed input: 221466.31 toks/s, output: 216.25 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 50/256 [00:00<00:02, 97.47it/s, est. speed input: 109966.59 toks/s, output: 107.38 toks/s] 
Processed prompts:  25%|â–ˆâ–ˆâ–       | 63/256 [00:00<00:02, 87.34it/s, est. speed input: 99387.31 toks/s, output: 97.06 toks/s]  
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 74/256 [00:00<00:02, 77.89it/s, est. speed input: 91160.12 toks/s, output: 89.02 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 83/256 [00:00<00:02, 77.03it/s, est. speed input: 89257.81 toks/s, output: 87.16 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 92/256 [00:01<00:02, 71.64it/s, est. speed input: 85386.21 toks/s, output: 83.38 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 100/256 [00:01<00:02, 70.15it/s, est. speed input: 83615.91 toks/s, output: 81.65 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 108/256 [00:01<00:02, 69.13it/s, est. speed input: 82215.03 toks/s, output: 80.29 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 116/256 [00:01<00:02, 68.42it/s, est. speed input: 81062.54 toks/s, output: 79.16 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 124/256 [00:01<00:01, 67.08it/s, est. speed input: 79827.80 toks/s, output: 77.96 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 132/256 [00:01<00:01, 66.80it/s, est. speed input: 78968.00 toks/s, output: 77.12 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 140/256 [00:01<00:01, 66.24it/s, est. speed input: 78129.34 toks/s, output: 76.30 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 148/256 [00:01<00:01, 65.88it/s, est. speed input: 77403.60 toks/s, output: 75.59 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 156/256 [00:02<00:01, 66.07it/s, est. speed input: 76866.67 toks/s, output: 75.06 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 164/256 [00:02<00:01, 66.02it/s, est. speed input: 76347.89 toks/s, output: 74.56 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 172/256 [00:02<00:01, 65.70it/s, est. speed input: 75827.39 toks/s, output: 74.05 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 180/256 [00:02<00:01, 65.52it/s, est. speed input: 75366.99 toks/s, output: 73.60 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 188/256 [00:02<00:01, 65.28it/s, est. speed input: 74929.03 toks/s, output: 73.17 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 196/256 [00:02<00:00, 65.78it/s, est. speed input: 74647.25 toks/s, output: 72.90 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 204/256 [00:02<00:00, 66.02it/s, est. speed input: 74370.50 toks/s, output: 72.63 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 212/256 [00:02<00:00, 66.18it/s, est. speed input: 74115.22 toks/s, output: 72.38 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 220/256 [00:03<00:00, 66.25it/s, est. speed input: 73875.09 toks/s, output: 72.14 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 228/256 [00:03<00:00, 65.99it/s, est. speed input: 73607.31 toks/s, output: 71.88 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 236/256 [00:03<00:00, 65.80it/s, est. speed input: 73359.38 toks/s, output: 71.64 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 244/256 [00:03<00:00, 65.67it/s, est. speed input: 73128.75 toks/s, output: 71.41 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 252/256 [00:03<00:00, 65.56it/s, est. speed input: 72912.05 toks/s, output: 71.20 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 65.56it/s, est. speed input: 72817.29 toks/s, output: 71.11 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 71.10it/s, est. speed input: 72817.29 toks/s, output: 71.11 toks/s]
[rank0]:[W126 08:12:38.100473794 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:12:40
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:12:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1035483) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1035483) WARNING 01-26 08:13:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 111.61 requests/s, 114401.70 total tokens/s, 111.61 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:12:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:12:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:12:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:12:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:12:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:12:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:12:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:12:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:12:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1035483) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1035483) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.61it/s]
(EngineCore_DP0 pid=1035483) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.60it/s]
(EngineCore_DP0 pid=1035483) 
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1035483) [2026-01-26 08:12:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1035483) 2026-01-26 08:13:09,064 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1035483) 2026-01-26 08:13:09,094 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1035483) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 13.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.51it/s]
(EngineCore_DP0 pid=1035483) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 15.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.29it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|â–Œ         | 31/512 [00:00<00:01, 305.78it/s]
Adding requests:  16%|â–ˆâ–‹        | 84/512 [00:00<00:00, 434.61it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 136/512 [00:00<00:00, 469.77it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 186/512 [00:00<00:00, 481.55it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 238/512 [00:00<00:00, 494.57it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 289/512 [00:00<00:00, 497.97it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 339/512 [00:00<00:00, 498.48it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 392/512 [00:00<00:00, 505.36it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 443/512 [00:00<00:00, 506.41it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 495/512 [00:01<00:00, 507.75it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:01<00:00, 490.43it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|â–ˆâ–Ž        | 70/512 [00:00<00:00, 552.47it/s, est. speed input: 565905.93 toks/s, output: 552.49 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–       | 126/512 [00:00<00:01, 202.05it/s, est. speed input: 231378.31 toks/s, output: 225.94 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 157/512 [00:00<00:01, 179.74it/s, est. speed input: 207366.64 toks/s, output: 202.50 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/512 [00:00<00:02, 163.13it/s, est. speed input: 192292.53 toks/s, output: 187.78 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 200/512 [00:01<00:02, 151.53it/s, est. speed input: 182666.24 toks/s, output: 178.38 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/512 [00:01<00:01, 147.55it/s, est. speed input: 178163.65 toks/s, output: 173.99 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 233/512 [00:01<00:01, 142.45it/s, est. speed input: 173801.24 toks/s, output: 169.73 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 248/512 [00:01<00:01, 136.23it/s, est. speed input: 169449.09 toks/s, output: 165.48 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 262/512 [00:01<00:01, 129.47it/s, est. speed input: 165195.12 toks/s, output: 161.32 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 278/512 [00:01<00:01, 129.03it/s, est. speed input: 162747.67 toks/s, output: 158.93 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 294/512 [00:01<00:01, 129.03it/s, est. speed input: 160720.30 toks/s, output: 156.95 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 310/512 [00:01<00:01, 129.52it/s, est. speed input: 159072.58 toks/s, output: 155.34 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 326/512 [00:02<00:01, 129.78it/s, est. speed input: 157593.91 toks/s, output: 153.90 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 342/512 [00:02<00:01, 128.93it/s, est. speed input: 156043.93 toks/s, output: 152.39 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 358/512 [00:02<00:01, 129.23it/s, est. speed input: 154850.58 toks/s, output: 151.22 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 374/512 [00:02<00:01, 129.47it/s, est. speed input: 153778.50 toks/s, output: 150.17 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 390/512 [00:02<00:00, 129.65it/s, est. speed input: 152810.13 toks/s, output: 149.23 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 406/512 [00:02<00:00, 129.69it/s, est. speed input: 151912.69 toks/s, output: 148.35 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/512 [00:02<00:00, 129.73it/s, est. speed input: 151095.94 toks/s, output: 147.55 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 438/512 [00:02<00:00, 129.55it/s, est. speed input: 150312.23 toks/s, output: 146.79 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 454/512 [00:03<00:00, 128.92it/s, est. speed input: 149514.09 toks/s, output: 146.01 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/512 [00:03<00:00, 129.15it/s, est. speed input: 148876.09 toks/s, output: 145.39 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 486/512 [00:03<00:00, 129.45it/s, est. speed input: 148304.19 toks/s, output: 144.83 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 502/512 [00:03<00:00, 129.63it/s, est. speed input: 147771.65 toks/s, output: 144.31 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:03<00:00, 129.63it/s, est. speed input: 148049.00 toks/s, output: 144.58 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:03<00:00, 144.57it/s, est. speed input: 148049.00 toks/s, output: 144.58 toks/s]
[rank0]:[W126 08:13:16.258653774 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:13:18
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:13:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1036537) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1036537) WARNING 01-26 08:13:42 [backends.py:609] Failed to read file <frozen os>
Throughput: 169.96 requests/s, 174210.23 total tokens/s, 169.96 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:13:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:13:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:13:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:13:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:13:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:13:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:13:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:13:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:13:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:13:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:13:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:13:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:13:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:13:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:13:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:13:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:13:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1036537) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1036537) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.68it/s]
(EngineCore_DP0 pid=1036537) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.67it/s]
(EngineCore_DP0 pid=1036537) 
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1036537) [2026-01-26 08:13:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1036537) 2026-01-26 08:13:49,835 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1036537) 2026-01-26 08:13:50,166 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1036537) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 14.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 16.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 16.52it/s]
(EngineCore_DP0 pid=1036537) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.22it/s]
Capturing CUDA graphs (decode, FULL):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.71it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.23it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|â–Ž         | 32/1024 [00:00<00:03, 315.87it/s]
Adding requests:   8%|â–Š         | 84/1024 [00:00<00:02, 434.88it/s]
Adding requests:  13%|â–ˆâ–Ž        | 135/1024 [00:00<00:01, 468.17it/s]
Adding requests:  18%|â–ˆâ–Š        | 185/1024 [00:00<00:01, 477.33it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 237/1024 [00:00<00:01, 490.56it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 288/1024 [00:00<00:01, 494.78it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 338/1024 [00:00<00:01, 495.48it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 391/1024 [00:00<00:01, 504.12it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 442/1024 [00:00<00:01, 503.95it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:01<00:01, 506.57it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 545/1024 [00:01<00:00, 493.41it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 598/1024 [00:01<00:00, 502.53it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 650/1024 [00:01<00:00, 507.60it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:01<00:00, 515.82it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 756/1024 [00:01<00:00, 513.48it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 808/1024 [00:01<00:00, 507.52it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 859/1024 [00:01<00:00, 505.94it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 912/1024 [00:01<00:00, 511.77it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 965/1024 [00:01<00:00, 515.58it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:02<00:00, 516.81it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 500.22it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–Ž       | 242/1024 [00:00<00:00, 2313.93it/s, est. speed input: 2369891.07 toks/s, output: 2314.05 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 474/1024 [00:01<00:01, 310.56it/s, est. speed input: 366635.13 toks/s, output: 358.04 toks/s]   
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 581/1024 [00:01<00:01, 274.59it/s, est. speed input: 324739.47 toks/s, output: 317.13 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 649/1024 [00:02<00:01, 260.60it/s, est. speed input: 309665.18 toks/s, output: 302.41 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 699/1024 [00:02<00:01, 242.55it/s, est. speed input: 295762.35 toks/s, output: 288.83 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 738/1024 [00:02<00:01, 234.31it/s, est. speed input: 288909.97 toks/s, output: 282.13 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:02<00:01, 228.99it/s, est. speed input: 284426.75 toks/s, output: 277.76 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 799/1024 [00:02<00:00, 231.79it/s, est. speed input: 283115.54 toks/s, output: 276.48 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 827/1024 [00:03<00:00, 219.27it/s, est. speed input: 277949.14 toks/s, output: 271.43 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 852/1024 [00:03<00:00, 217.83it/s, est. speed input: 275685.51 toks/s, output: 269.22 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:03<00:00, 214.64it/s, est. speed input: 273270.17 toks/s, output: 266.86 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 899/1024 [00:03<00:00, 210.19it/s, est. speed input: 270773.15 toks/s, output: 264.43 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 922/1024 [00:03<00:00, 206.42it/s, est. speed input: 268415.88 toks/s, output: 262.12 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 946/1024 [00:03<00:00, 207.73it/s, est. speed input: 266792.05 toks/s, output: 260.54 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:03<00:00, 206.72it/s, est. speed input: 264979.81 toks/s, output: 258.77 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 994/1024 [00:03<00:00, 207.91it/s, est. speed input: 263538.89 toks/s, output: 257.36 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:03<00:00, 209.15it/s, est. speed input: 262226.34 toks/s, output: 256.08 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:03<00:00, 209.15it/s, est. speed input: 263743.26 toks/s, output: 257.56 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:03<00:00, 257.55it/s, est. speed input: 263743.26 toks/s, output: 257.56 toks/s]
[rank0]:[W126 08:13:58.585499834 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:14:00
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:14:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1037701) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1037701) WARNING 01-26 08:14:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 197.44 requests/s, 202371.28 total tokens/s, 197.44 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:14:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:14:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:14:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:14:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:14:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:14:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:14:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:14:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:14:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1037701) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1037701) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.63it/s]
(EngineCore_DP0 pid=1037701) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.62it/s]
(EngineCore_DP0 pid=1037701) 
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1037701) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1037701) 2026-01-26 08:14:36,013 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1037701) 2026-01-26 08:14:36,047 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1037701) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00, 14.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00, 12.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.43it/s]
(EngineCore_DP0 pid=1037701) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.71it/s]
Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  7.32it/s]
Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00,  6.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.01it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 34/2048 [00:00<00:05, 337.71it/s]
Adding requests:   4%|â–         | 87/2048 [00:00<00:04, 448.00it/s]
Adding requests:   7%|â–‹         | 138/2048 [00:00<00:04, 474.59it/s]
Adding requests:   9%|â–‰         | 188/2048 [00:00<00:03, 483.55it/s]
Adding requests:  12%|â–ˆâ–        | 241/2048 [00:00<00:03, 498.71it/s]
Adding requests:  14%|â–ˆâ–        | 292/2048 [00:00<00:03, 500.68it/s]
Adding requests:  17%|â–ˆâ–‹        | 343/2048 [00:00<00:03, 501.46it/s]
Adding requests:  19%|â–ˆâ–‰        | 395/2048 [00:00<00:03, 507.27it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 446/2048 [00:00<00:03, 507.23it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 497/2048 [00:01<00:03, 507.48it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 548/2048 [00:01<00:02, 501.21it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 600/2048 [00:01<00:02, 506.33it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 653/2048 [00:01<00:02, 512.76it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 707/2048 [00:01<00:02, 519.40it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 759/2048 [00:01<00:02, 511.60it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 811/2048 [00:01<00:02, 506.95it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 862/2048 [00:01<00:02, 507.47it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 916/2048 [00:01<00:02, 514.80it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 969/2048 [00:01<00:02, 516.35it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1022/2048 [00:02<00:01, 519.68it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1074/2048 [00:02<00:01, 516.22it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1126/2048 [00:02<00:01, 516.31it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1180/2048 [00:02<00:01, 523.06it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1234/2048 [00:02<00:01, 527.19it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1287/2048 [00:02<00:01, 521.55it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1341/2048 [00:02<00:01, 526.24it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1395/2048 [00:02<00:01, 528.42it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1448/2048 [00:02<00:01, 525.80it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1503/2048 [00:02<00:01, 530.60it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1557/2048 [00:03<00:00, 523.85it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1611/2048 [00:03<00:00, 525.84it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1664/2048 [00:03<00:00, 524.92it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1717/2048 [00:03<00:00, 526.03it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1770/2048 [00:03<00:00, 524.04it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1823/2048 [00:03<00:00, 523.52it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1876/2048 [00:03<00:00, 508.99it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1929/2048 [00:03<00:00, 512.62it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1982/2048 [00:03<00:00, 514.97it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2036/2048 [00:03<00:00, 519.31it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:03<00:00, 512.80it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 674/2048 [00:00<00:00, 5622.01it/s, est. speed input: 5758027.38 toks/s, output: 5622.31 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1237/2048 [00:02<00:02, 387.87it/s, est. speed input: 468473.66 toks/s, output: 457.49 toks/s]  
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1482/2048 [00:03<00:01, 326.05it/s, est. speed input: 398376.71 toks/s, output: 389.04 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1625/2048 [00:04<00:01, 299.28it/s, est. speed input: 371985.15 toks/s, output: 363.27 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1720/2048 [00:04<00:01, 283.61it/s, est. speed input: 358385.50 toks/s, output: 349.99 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1789/2048 [00:05<00:00, 275.71it/s, est. speed input: 351475.21 toks/s, output: 343.24 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1843/2048 [00:05<00:00, 258.98it/s, est. speed input: 342581.57 toks/s, output: 334.55 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1885/2048 [00:05<00:00, 262.45it/s, est. speed input: 341423.27 toks/s, output: 333.42 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1923/2048 [00:05<00:00, 244.40it/s, est. speed input: 335081.80 toks/s, output: 327.23 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1955/2048 [00:06<00:00, 240.82it/s, est. speed input: 332468.01 toks/s, output: 324.68 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1986/2048 [00:06<00:00, 236.11it/s, est. speed input: 329831.01 toks/s, output: 322.10 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [00:06<00:00, 234.02it/s, est. speed input: 327611.38 toks/s, output: 319.93 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:06<00:00, 234.02it/s, est. speed input: 328877.04 toks/s, output: 321.17 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:06<00:00, 321.16it/s, est. speed input: 328877.04 toks/s, output: 321.17 toks/s]
[rank0]:[W126 08:14:49.556533962 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:14:51
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:15:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1039000) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1039000) WARNING 01-26 08:15:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 220.97 requests/s, 226490.27 total tokens/s, 220.97 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:15:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:15:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:15:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:15:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:15:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:15:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:15:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:15:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:15:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:15:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:15:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:15:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:15:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:15:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:15:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:15:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:15:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1039000) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1039000) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.62it/s]
(EngineCore_DP0 pid=1039000) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.61it/s]
(EngineCore_DP0 pid=1039000) 
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1039000) [2026-01-26 08:15:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1039000) [rank0]:W0126 08:15:32.564000 1039000 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1039000) [rank0]:W0126 08:15:32.618000 1039000 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1039000) [rank0]:W0126 08:15:33.277000 1039000 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1039000) [rank0]:W0126 08:15:33.352000 1039000 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1039000) 2026-01-26 08:15:36,158 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1039000) 2026-01-26 08:15:36,211 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1039000) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 2/11 [00:00<00:00, 14.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:00<00:00, 13.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:00<00:00, 10.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:00<00:00, 10.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00,  5.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  7.69it/s]
(EngineCore_DP0 pid=1039000) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 1/7 [00:00<00:00,  6.25it/s]
Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00, 10.27it/s]
Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:00<00:00, 12.36it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 12.25it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 36/4096 [00:00<00:11, 355.81it/s]
Adding requests:   2%|â–         | 88/4096 [00:00<00:08, 448.29it/s]
Adding requests:   3%|â–Ž         | 139/4096 [00:00<00:08, 474.09it/s]
Adding requests:   5%|â–         | 189/4096 [00:00<00:08, 482.42it/s]
Adding requests:   6%|â–Œ         | 241/4096 [00:00<00:07, 494.49it/s]
Adding requests:   7%|â–‹         | 292/4096 [00:00<00:07, 497.14it/s]
Adding requests:   8%|â–Š         | 342/4096 [00:00<00:07, 496.13it/s]
Adding requests:  10%|â–‰         | 394/4096 [00:00<00:07, 502.43it/s]
Adding requests:  11%|â–ˆ         | 445/4096 [00:00<00:07, 502.18it/s]
Adding requests:  12%|â–ˆâ–        | 496/4096 [00:01<00:07, 503.74it/s]
Adding requests:  13%|â–ˆâ–Ž        | 547/4096 [00:01<00:07, 497.81it/s]
Adding requests:  15%|â–ˆâ–        | 599/4096 [00:01<00:06, 503.62it/s]
Adding requests:  16%|â–ˆâ–Œ        | 652/4096 [00:01<00:06, 508.55it/s]
Adding requests:  17%|â–ˆâ–‹        | 705/4096 [00:01<00:06, 514.63it/s]
Adding requests:  18%|â–ˆâ–Š        | 757/4096 [00:01<00:06, 511.83it/s]
Adding requests:  20%|â–ˆâ–‰        | 809/4096 [00:01<00:06, 503.39it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 860/4096 [00:01<00:06, 502.29it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 913/4096 [00:01<00:06, 509.56it/s]
Adding requests:  24%|â–ˆâ–ˆâ–Ž       | 966/4096 [00:01<00:06, 513.54it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 1019/4096 [00:02<00:05, 516.87it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 1071/4096 [00:02<00:06, 503.75it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 1122/4096 [00:02<00:05, 504.81it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 1175/4096 [00:02<00:05, 511.57it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 1228/4096 [00:02<00:05, 516.73it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆâ–      | 1280/4096 [00:02<00:05, 511.64it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1333/4096 [00:02<00:05, 514.76it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 1385/4096 [00:02<00:05, 515.36it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1437/4096 [00:02<00:05, 514.58it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1490/4096 [00:02<00:05, 519.08it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1543/4096 [00:03<00:04, 520.08it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1597/4096 [00:03<00:04, 524.37it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1650/4096 [00:03<00:04, 524.04it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1703/4096 [00:03<00:04, 519.82it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1755/4096 [00:03<00:04, 519.15it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1807/4096 [00:03<00:04, 518.31it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1859/4096 [00:03<00:04, 518.29it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1911/4096 [00:03<00:04, 514.32it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1963/4096 [00:03<00:04, 514.27it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2016/4096 [00:03<00:04, 516.96it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2070/4096 [00:04<00:03, 523.45it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2123/4096 [00:04<00:03, 520.69it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2176/4096 [00:04<00:03, 516.84it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2228/4096 [00:04<00:03, 505.96it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2280/4096 [00:04<00:03, 508.26it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2332/4096 [00:04<00:03, 510.01it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2384/4096 [00:04<00:03, 511.52it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2436/4096 [00:04<00:03, 511.82it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2488/4096 [00:04<00:03, 512.21it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2540/4096 [00:04<00:03, 511.91it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2593/4096 [00:05<00:02, 513.32it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2645/4096 [00:05<00:02, 508.34it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2696/4096 [00:05<00:02, 500.39it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2747/4096 [00:05<00:02, 499.70it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2798/4096 [00:05<00:02, 500.15it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2850/4096 [00:05<00:02, 503.61it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2902/4096 [00:05<00:02, 507.23it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2953/4096 [00:05<00:02, 505.17it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3004/4096 [00:05<00:02, 506.57it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3056/4096 [00:06<00:02, 509.40it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3107/4096 [00:06<00:01, 507.24it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3159/4096 [00:06<00:01, 509.62it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3211/4096 [00:06<00:01, 511.38it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3264/4096 [00:06<00:01, 515.52it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3316/4096 [00:06<00:01, 514.81it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3369/4096 [00:06<00:01, 516.39it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3422/4096 [00:06<00:01, 519.00it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3474/4096 [00:06<00:01, 497.13it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3526/4096 [00:06<00:01, 502.99it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3578/4096 [00:07<00:01, 505.92it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3629/4096 [00:07<00:00, 505.58it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3681/4096 [00:07<00:00, 509.83it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3733/4096 [00:07<00:00, 511.51it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3787/4096 [00:07<00:00, 518.66it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3840/4096 [00:07<00:00, 520.57it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3893/4096 [00:07<00:00, 521.75it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3946/4096 [00:07<00:00, 521.95it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3999/4096 [00:07<00:00, 518.53it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4051/4096 [00:07<00:00, 516.29it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:08<00:00, 509.74it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1750/4096 [00:00<00:00, 13398.01it/s, est. speed input: 13722040.45 toks/s, output: 13398.74 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3090/4096 [00:05<00:02, 433.28it/s, est. speed input: 530976.17 toks/s, output: 518.53 toks/s]      
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3656/4096 [00:08<00:01, 351.76it/s, est. speed input: 438966.08 toks/s, output: 428.68 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3974/4096 [00:09<00:00, 321.00it/s, est. speed input: 408179.65 toks/s, output: 398.61 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:10<00:00, 321.00it/s, est. speed input: 399553.14 toks/s, output: 390.19 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:10<00:00, 390.18it/s, est. speed input: 399553.14 toks/s, output: 390.19 toks/s]
[rank0]:[W126 08:15:58.648246156 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:16:00
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:16:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1040636) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1040636) WARNING 01-26 08:16:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 223.88 requests/s, 229477.93 total tokens/s, 223.88 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:16:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:16:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:16:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:16:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:16:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:16:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:16:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:16:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:16:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:16:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:16:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:16:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:16:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:16:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:16:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:16:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:16:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1040636) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1040636) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.65it/s]
(EngineCore_DP0 pid=1040636) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.64it/s]
(EngineCore_DP0 pid=1040636) 
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3932160 bytes
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 2621440 bytes
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20971520 bytes
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1040636) [2026-01-26 08:16:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10485760 bytes
(EngineCore_DP0 pid=1040636) [rank0]:W0126 08:16:58.849000 1040636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1040636) [rank0]:W0126 08:16:58.903000 1040636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1040636) [rank0]:W0126 08:16:59.960000 1040636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1040636) [rank0]:W0126 08:17:00.036000 1040636 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1040636) 2026-01-26 08:17:03,483 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1040636) 2026-01-26 08:17:03,566 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1040636) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|â–Œ         | 1/19 [00:00<00:03,  5.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 13.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  6.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00,  8.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.90it/s]
(EngineCore_DP0 pid=1040636) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 1/11 [00:00<00:01,  9.26it/s]
Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:00<00:00, 11.24it/s]
Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:00<00:00, 13.77it/s]
Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [00:00<00:00, 16.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 15.61it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 50/8192 [00:00<00:16, 492.07it/s]
Adding requests:   1%|          | 101/8192 [00:00<00:16, 499.78it/s]
Adding requests:   2%|â–         | 151/8192 [00:00<00:16, 494.63it/s]
Adding requests:   2%|â–         | 201/8192 [00:00<00:16, 494.62it/s]
Adding requests:   3%|â–Ž         | 253/8192 [00:00<00:15, 502.95it/s]
Adding requests:   4%|â–Ž         | 304/8192 [00:00<00:15, 497.45it/s]
Adding requests:   4%|â–         | 356/8192 [00:00<00:15, 501.53it/s]
Adding requests:   5%|â–         | 407/8192 [00:00<00:15, 501.49it/s]
Adding requests:   6%|â–Œ         | 458/8192 [00:00<00:15, 500.80it/s]
Adding requests:   6%|â–Œ         | 509/8192 [00:01<00:15, 497.83it/s]
Adding requests:   7%|â–‹         | 559/8192 [00:01<00:15, 495.42it/s]
Adding requests:   7%|â–‹         | 609/8192 [00:01<00:15, 491.31it/s]
Adding requests:   8%|â–Š         | 662/8192 [00:01<00:15, 500.33it/s]
Adding requests:   9%|â–Š         | 715/8192 [00:01<00:14, 508.53it/s]
Adding requests:   9%|â–‰         | 766/8192 [00:01<00:14, 507.36it/s]
Adding requests:  10%|â–‰         | 817/8192 [00:01<00:14, 498.36it/s]
Adding requests:  11%|â–ˆ         | 867/8192 [00:01<00:14, 498.59it/s]
Adding requests:  11%|â–ˆ         | 920/8192 [00:01<00:14, 506.53it/s]
Adding requests:  12%|â–ˆâ–        | 971/8192 [00:01<00:14, 507.36it/s]
Adding requests:  12%|â–ˆâ–Ž        | 1024/8192 [00:02<00:14, 511.95it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1076/8192 [00:02<00:14, 506.31it/s]
Adding requests:  14%|â–ˆâ–        | 1127/8192 [00:02<00:13, 505.42it/s]
Adding requests:  14%|â–ˆâ–        | 1180/8192 [00:02<00:13, 510.74it/s]
Adding requests:  15%|â–ˆâ–Œ        | 1233/8192 [00:02<00:13, 515.67it/s]
Adding requests:  16%|â–ˆâ–Œ        | 1285/8192 [00:02<00:13, 511.08it/s]
Adding requests:  16%|â–ˆâ–‹        | 1338/8192 [00:02<00:13, 513.48it/s]
Adding requests:  17%|â–ˆâ–‹        | 1391/8192 [00:02<00:13, 516.95it/s]
Adding requests:  18%|â–ˆâ–Š        | 1443/8192 [00:02<00:13, 515.03it/s]
Adding requests:  18%|â–ˆâ–Š        | 1496/8192 [00:02<00:12, 517.48it/s]
Adding requests:  19%|â–ˆâ–‰        | 1548/8192 [00:03<00:12, 517.65it/s]
Adding requests:  20%|â–ˆâ–‰        | 1602/8192 [00:03<00:12, 523.46it/s]
Adding requests:  20%|â–ˆâ–ˆ        | 1655/8192 [00:03<00:12, 520.36it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 1708/8192 [00:03<00:12, 508.20it/s]
Adding requests:  21%|â–ˆâ–ˆâ–       | 1760/8192 [00:03<00:12, 509.51it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1812/8192 [00:03<00:12, 511.84it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1864/8192 [00:03<00:12, 509.38it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1917/8192 [00:03<00:12, 513.09it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 1969/8192 [00:03<00:12, 510.81it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 2022/8192 [00:03<00:11, 514.86it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 2075/8192 [00:04<00:11, 518.76it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 2127/8192 [00:04<00:11, 513.47it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2179/8192 [00:04<00:11, 507.85it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2231/8192 [00:04<00:11, 511.12it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2283/8192 [00:04<00:11, 512.47it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 2335/8192 [00:04<00:11, 511.67it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 2387/8192 [00:04<00:11, 513.76it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 2439/8192 [00:04<00:11, 513.35it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 2492/8192 [00:04<00:11, 515.91it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2544/8192 [00:05<00:11, 512.27it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2597/8192 [00:05<00:10, 515.84it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2649/8192 [00:05<00:10, 515.28it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2701/8192 [00:05<00:10, 513.89it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2753/8192 [00:05<00:10, 511.56it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 2805/8192 [00:05<00:10, 509.75it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 2857/8192 [00:05<00:10, 510.84it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2910/8192 [00:05<00:10, 514.69it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2962/8192 [00:05<00:10, 497.44it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3014/8192 [00:05<00:10, 503.10it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3065/8192 [00:06<00:10, 503.40it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3118/8192 [00:06<00:09, 508.76it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3169/8192 [00:06<00:09, 507.31it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3221/8192 [00:06<00:09, 508.31it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3274/8192 [00:06<00:09, 512.87it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3326/8192 [00:06<00:09, 513.91it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3380/8192 [00:06<00:09, 518.61it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3433/8192 [00:06<00:09, 520.47it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3486/8192 [00:06<00:09, 509.46it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3538/8192 [00:06<00:09, 510.67it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3590/8192 [00:07<00:09, 510.49it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3642/8192 [00:07<00:08, 507.23it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3694/8192 [00:07<00:08, 510.96it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3746/8192 [00:07<00:08, 508.59it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3800/8192 [00:07<00:08, 517.30it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3853/8192 [00:07<00:08, 520.05it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3906/8192 [00:07<00:08, 516.65it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3959/8192 [00:07<00:08, 518.57it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4011/8192 [00:07<00:08, 516.72it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4063/8192 [00:07<00:08, 510.85it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4116/8192 [00:08<00:07, 513.54it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4169/8192 [00:08<00:07, 516.13it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4222/8192 [00:08<00:07, 518.04it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4274/8192 [00:08<00:07, 503.48it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4327/8192 [00:08<00:07, 508.81it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4381/8192 [00:08<00:07, 515.37it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4433/8192 [00:08<00:07, 514.97it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4485/8192 [00:08<00:07, 512.88it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4537/8192 [00:08<00:07, 509.97it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4589/8192 [00:08<00:07, 512.22it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4643/8192 [00:09<00:06, 518.79it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4695/8192 [00:09<00:06, 512.85it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4748/8192 [00:09<00:06, 517.75it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4800/8192 [00:09<00:06, 514.52it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4852/8192 [00:09<00:06, 515.50it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4904/8192 [00:09<00:06, 510.34it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4957/8192 [00:09<00:06, 514.43it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 5009/8192 [00:09<00:06, 515.04it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5063/8192 [00:09<00:06, 520.08it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5117/8192 [00:10<00:05, 523.40it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5170/8192 [00:10<00:05, 522.33it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5223/8192 [00:10<00:05, 516.73it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5275/8192 [00:10<00:05, 513.75it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5329/8192 [00:10<00:05, 519.40it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5381/8192 [00:10<00:05, 517.60it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5434/8192 [00:10<00:05, 519.67it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5486/8192 [00:10<00:05, 513.30it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5538/8192 [00:10<00:05, 500.14it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5590/8192 [00:10<00:05, 503.18it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5642/8192 [00:11<00:05, 505.79it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5693/8192 [00:11<00:04, 504.50it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5746/8192 [00:11<00:04, 509.38it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5798/8192 [00:11<00:04, 509.88it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5850/8192 [00:11<00:04, 508.45it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5904/8192 [00:11<00:04, 515.40it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5956/8192 [00:11<00:04, 513.57it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6010/8192 [00:11<00:04, 519.31it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6064/8192 [00:11<00:04, 522.90it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6117/8192 [00:11<00:04, 517.67it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6169/8192 [00:12<00:03, 515.98it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6224/8192 [00:12<00:03, 524.85it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6277/8192 [00:12<00:03, 526.33it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6331/8192 [00:12<00:03, 528.25it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6384/8192 [00:12<00:03, 524.80it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6439/8192 [00:12<00:03, 530.51it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6493/8192 [00:12<00:03, 530.66it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6547/8192 [00:12<00:03, 529.31it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6600/8192 [00:12<00:03, 527.00it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6653/8192 [00:12<00:02, 527.63it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6706/8192 [00:13<00:02, 525.62it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6759/8192 [00:13<00:02, 523.30it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6812/8192 [00:13<00:02, 514.27it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6866/8192 [00:13<00:02, 520.98it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6919/8192 [00:13<00:02, 522.88it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6973/8192 [00:13<00:02, 526.31it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7026/8192 [00:13<00:02, 519.06it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7078/8192 [00:13<00:02, 517.91it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7131/8192 [00:13<00:02, 521.07it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7184/8192 [00:14<00:01, 515.52it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7237/8192 [00:14<00:01, 516.69it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7292/8192 [00:14<00:01, 524.06it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7345/8192 [00:14<00:01, 522.75it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7398/8192 [00:14<00:01, 523.13it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7453/8192 [00:14<00:01, 529.81it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7506/8192 [00:14<00:01, 527.73it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7559/8192 [00:14<00:01, 525.33it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7612/8192 [00:14<00:01, 520.50it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7666/8192 [00:14<00:00, 526.18it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7719/8192 [00:15<00:00, 524.07it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7772/8192 [00:15<00:00, 519.45it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7824/8192 [00:15<00:00, 518.22it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7876/8192 [00:15<00:00, 517.06it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7928/8192 [00:15<00:00, 515.52it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7980/8192 [00:15<00:00, 513.39it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8032/8192 [00:15<00:00, 507.90it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8083/8192 [00:15<00:00, 505.22it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8135/8192 [00:15<00:00, 509.00it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8189/8192 [00:15<00:00, 515.87it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:15<00:00, 513.77it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3522/8192 [00:00<00:00, 11733.35it/s, est. speed input: 12015917.68 toks/s, output: 11733.63 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4696/8192 [00:05<00:05, 685.70it/s, est. speed input: 890894.27 toks/s, output: 870.01 toks/s]      
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5193/8192 [00:07<00:05, 509.75it/s, est. speed input: 694659.47 toks/s, output: 678.38 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5473/8192 [00:08<00:05, 455.13it/s, est. speed input: 638891.38 toks/s, output: 623.92 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5653/8192 [00:09<00:06, 410.39it/s, est. speed input: 602054.39 toks/s, output: 587.94 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5776/8192 [00:10<00:06, 381.23it/s, est. speed input: 580936.33 toks/s, output: 567.32 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5865/8192 [00:10<00:06, 374.28it/s, est. speed input: 573736.70 toks/s, output: 560.29 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5935/8192 [00:10<00:06, 359.63it/s, est. speed input: 565579.94 toks/s, output: 552.32 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5991/8192 [00:11<00:06, 335.12it/s, est. speed input: 556128.83 toks/s, output: 543.09 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6036/8192 [00:11<00:07, 304.53it/s, est. speed input: 546344.72 toks/s, output: 533.54 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6082/8192 [00:11<00:07, 275.68it/s, est. speed input: 536968.34 toks/s, output: 524.38 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6146/8192 [00:11<00:07, 266.18it/s, est. speed input: 530012.60 toks/s, output: 517.59 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6210/8192 [00:12<00:07, 256.54it/s, est. speed input: 523072.85 toks/s, output: 510.81 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6274/8192 [00:12<00:07, 248.19it/s, est. speed input: 516340.64 toks/s, output: 504.24 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6338/8192 [00:12<00:07, 241.69it/s, est. speed input: 509904.09 toks/s, output: 497.95 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6402/8192 [00:13<00:07, 237.16it/s, est. speed input: 503810.76 toks/s, output: 492.00 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6466/8192 [00:13<00:07, 233.65it/s, est. speed input: 497952.76 toks/s, output: 486.28 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6530/8192 [00:13<00:07, 231.80it/s, est. speed input: 492447.64 toks/s, output: 480.90 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6594/8192 [00:13<00:06, 230.25it/s, est. speed input: 487136.50 toks/s, output: 475.72 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6658/8192 [00:14<00:06, 229.13it/s, est. speed input: 482035.26 toks/s, output: 470.74 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6722/8192 [00:14<00:06, 227.67it/s, est. speed input: 477041.69 toks/s, output: 465.86 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6786/8192 [00:14<00:06, 227.20it/s, est. speed input: 472317.89 toks/s, output: 461.25 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6850/8192 [00:14<00:05, 226.82it/s, est. speed input: 467765.67 toks/s, output: 456.80 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6914/8192 [00:15<00:05, 226.35it/s, est. speed input: 463356.36 toks/s, output: 452.50 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6978/8192 [00:15<00:05, 226.34it/s, est. speed input: 459148.35 toks/s, output: 448.39 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7042/8192 [00:15<00:05, 226.10it/s, est. speed input: 455062.40 toks/s, output: 444.40 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7106/8192 [00:16<00:04, 227.76it/s, est. speed input: 451331.29 toks/s, output: 440.75 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7170/8192 [00:16<00:04, 226.46it/s, est. speed input: 447448.01 toks/s, output: 436.96 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7234/8192 [00:16<00:04, 227.83it/s, est. speed input: 443949.44 toks/s, output: 433.54 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7298/8192 [00:16<00:03, 227.07it/s, est. speed input: 440380.59 toks/s, output: 430.06 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7362/8192 [00:17<00:03, 226.75it/s, est. speed input: 436950.64 toks/s, output: 426.71 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7426/8192 [00:17<00:03, 226.59it/s, est. speed input: 433638.86 toks/s, output: 423.47 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7490/8192 [00:17<00:03, 226.65it/s, est. speed input: 430448.92 toks/s, output: 420.36 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7554/8192 [00:18<00:02, 227.95it/s, est. speed input: 427480.76 toks/s, output: 417.46 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7618/8192 [00:18<00:02, 227.26it/s, est. speed input: 424449.84 toks/s, output: 414.50 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7682/8192 [00:18<00:02, 227.06it/s, est. speed input: 421537.67 toks/s, output: 411.66 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7746/8192 [00:18<00:01, 225.87it/s, est. speed input: 418616.12 toks/s, output: 408.80 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7810/8192 [00:19<00:01, 224.95it/s, est. speed input: 415772.08 toks/s, output: 406.03 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7874/8192 [00:19<00:01, 224.74it/s, est. speed input: 413050.95 toks/s, output: 403.37 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7938/8192 [00:19<00:01, 225.35it/s, est. speed input: 410473.70 toks/s, output: 400.85 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8002/8192 [00:20<00:00, 225.10it/s, est. speed input: 407911.58 toks/s, output: 398.35 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8066/8192 [00:20<00:00, 226.50it/s, est. speed input: 405552.56 toks/s, output: 396.05 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8130/8192 [00:20<00:00, 228.83it/s, est. speed input: 403363.53 toks/s, output: 393.91 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:20<00:00, 228.83it/s, est. speed input: 406402.54 toks/s, output: 396.88 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:20<00:00, 396.87it/s, est. speed input: 406402.54 toks/s, output: 396.88 toks/s]
[rank0]:[W126 08:17:45.164898535 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 09:25:06
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:25:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1135320) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1135320) WARNING 01-26 09:25:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.93 requests/s, 16382.61 total tokens/s, 31.93 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 09:25:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:25:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:25:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:25:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:25:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:25:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:25:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:25:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:25:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:25:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:25:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:25:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1135320) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1135320) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1135320) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1135320) 
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1135320) [2026-01-26 09:25:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1135320) 2026-01-26 09:25:36,785 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1135320) 2026-01-26 09:25:36,809 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1135320) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.05s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.20it/s]
(EngineCore_DP0 pid=1135320) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 55/128 [00:00<00:00, 546.42it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 709.98it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:00,  2.09it/s, est. speed input: 1072.33 toks/s, output: 2.09 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:11, 10.35it/s, est. speed input: 4286.90 toks/s, output: 8.37 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:06, 17.21it/s, est. speed input: 6555.91 toks/s, output: 12.80 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:05, 22.67it/s, est. speed input: 8238.47 toks/s, output: 16.09 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:04, 26.86it/s, est. speed input: 9532.90 toks/s, output: 18.62 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:03, 29.96it/s, est. speed input: 10556.42 toks/s, output: 20.62 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:03, 32.29it/s, est. speed input: 11393.36 toks/s, output: 22.25 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:01<00:02, 33.98it/s, est. speed input: 12088.00 toks/s, output: 23.61 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:02, 35.17it/s, est. speed input: 12670.03 toks/s, output: 24.75 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 36.05it/s, est. speed input: 13170.98 toks/s, output: 25.72 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 36.70it/s, est. speed input: 13605.68 toks/s, output: 26.57 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 37.16it/s, est. speed input: 13984.63 toks/s, output: 27.31 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 37.43it/s, est. speed input: 14315.13 toks/s, output: 27.96 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:01, 37.64it/s, est. speed input: 14608.84 toks/s, output: 28.53 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:01<00:01, 37.78it/s, est. speed input: 14871.24 toks/s, output: 29.04 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:01, 37.85it/s, est. speed input: 15105.13 toks/s, output: 29.50 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:02<00:01, 37.92it/s, est. speed input: 15317.60 toks/s, output: 29.92 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:01, 38.01it/s, est. speed input: 15512.58 toks/s, output: 30.30 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 38.09it/s, est. speed input: 15691.93 toks/s, output: 30.65 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 38.12it/s, est. speed input: 15854.47 toks/s, output: 30.97 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 38.13it/s, est. speed input: 16003.47 toks/s, output: 31.26 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 38.13it/s, est. speed input: 16140.53 toks/s, output: 31.52 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:02<00:01, 38.09it/s, est. speed input: 16265.17 toks/s, output: 31.77 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:02<00:00, 38.13it/s, est. speed input: 16384.11 toks/s, output: 32.00 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:00, 38.15it/s, est. speed input: 16494.35 toks/s, output: 32.22 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 38.14it/s, est. speed input: 16595.90 toks/s, output: 32.41 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:03<00:00, 38.14it/s, est. speed input: 16691.71 toks/s, output: 32.60 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:03<00:00, 38.17it/s, est. speed input: 16782.21 toks/s, output: 32.78 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 38.14it/s, est. speed input: 16865.54 toks/s, output: 32.94 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 38.16it/s, est. speed input: 16945.22 toks/s, output: 33.10 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 37.76it/s, est. speed input: 17002.42 toks/s, output: 33.21 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:03<00:00, 37.92it/s, est. speed input: 17075.13 toks/s, output: 33.35 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 37.92it/s, est. speed input: 17127.27 toks/s, output: 33.45 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 33.45it/s, est. speed input: 17127.27 toks/s, output: 33.45 toks/s]
[rank0]:[W126 09:25:44.240229641 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 09:25:46
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:25:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1136500) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1136500) WARNING 01-26 09:26:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.48 requests/s, 34316.01 total tokens/s, 33.48 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 09:25:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:25:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:25:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:25:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:25:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:25:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:26:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:26:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:26:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:26:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:26:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:26:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1136500) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1136500) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1136500) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1136500) 
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1136500) [2026-01-26 09:26:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1136500) 2026-01-26 09:26:16,391 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1136500) 2026-01-26 09:26:16,414 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1136500) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.44it/s]
(EngineCore_DP0 pid=1136500) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.88it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|â–ˆâ–‰        | 25/128 [00:00<00:00, 247.33it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [00:00<00:00, 373.75it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:00<00:00, 430.28it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 406.23it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:17,  7.27it/s, est. speed input: 7447.13 toks/s, output: 7.27 toks/s]
Processed prompts:   4%|â–         | 5/128 [00:00<00:05, 23.21it/s, est. speed input: 21003.39 toks/s, output: 20.51 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:04, 29.42it/s, est. speed input: 26349.71 toks/s, output: 25.73 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:03, 32.60it/s, est. speed input: 29221.72 toks/s, output: 28.53 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:03, 34.41it/s, est. speed input: 31002.17 toks/s, output: 30.27 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:00<00:03, 35.52it/s, est. speed input: 32215.57 toks/s, output: 31.46 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:00<00:02, 36.28it/s, est. speed input: 33110.51 toks/s, output: 32.33 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:00<00:02, 36.77it/s, est. speed input: 33789.52 toks/s, output: 33.00 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:00<00:02, 37.08it/s, est. speed input: 34313.94 toks/s, output: 33.51 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:02, 37.34it/s, est. speed input: 34751.29 toks/s, output: 33.94 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 37.51it/s, est. speed input: 35110.47 toks/s, output: 34.29 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:02, 37.61it/s, est. speed input: 35404.61 toks/s, output: 34.57 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:02, 37.68it/s, est. speed input: 35656.40 toks/s, output: 34.82 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [00:01<00:01, 37.76it/s, est. speed input: 35879.23 toks/s, output: 35.04 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:01<00:01, 37.85it/s, est. speed input: 36080.58 toks/s, output: 35.23 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:01<00:01, 37.89it/s, est. speed input: 36253.09 toks/s, output: 35.40 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [00:01<00:01, 37.89it/s, est. speed input: 36399.95 toks/s, output: 35.55 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:01<00:01, 37.90it/s, est. speed input: 36533.06 toks/s, output: 35.68 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:01, 37.94it/s, est. speed input: 36657.52 toks/s, output: 35.80 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:02<00:01, 37.97it/s, est. speed input: 36770.11 toks/s, output: 35.91 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 37.92it/s, est. speed input: 36861.13 toks/s, output: 36.00 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:02<00:01, 37.94it/s, est. speed input: 36951.55 toks/s, output: 36.09 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [00:02<00:01, 37.96it/s, est. speed input: 37036.08 toks/s, output: 36.17 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:02<00:00, 38.00it/s, est. speed input: 37116.70 toks/s, output: 36.25 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:02<00:00, 38.00it/s, est. speed input: 37187.61 toks/s, output: 36.32 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:02<00:00, 38.00it/s, est. speed input: 37253.29 toks/s, output: 36.38 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:02<00:00, 37.99it/s, est. speed input: 37312.02 toks/s, output: 36.44 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:02<00:00, 37.83it/s, est. speed input: 37350.15 toks/s, output: 36.47 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [00:03<00:00, 37.57it/s, est. speed input: 37368.31 toks/s, output: 36.49 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:03<00:00, 37.40it/s, est. speed input: 37386.36 toks/s, output: 36.51 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 37.30it/s, est. speed input: 37405.07 toks/s, output: 36.53 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [00:03<00:00, 36.75it/s, est. speed input: 37371.21 toks/s, output: 36.49 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 36.75it/s, est. speed input: 37379.32 toks/s, output: 36.50 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 36.50it/s, est. speed input: 37379.32 toks/s, output: 36.50 toks/s]
[rank0]:[W126 09:26:22.103844527 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 09:26:23
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:26:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1137563) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1137563) WARNING 01-26 09:26:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 65.48 requests/s, 67117.81 total tokens/s, 65.48 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 09:26:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:26:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:26:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:26:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:26:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:26:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:26:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:26:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:26:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:26:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:26:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:26:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1137563) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1137563) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1137563) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1137563) 
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1137563) [2026-01-26 09:26:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1137563) 2026-01-26 09:26:54,307 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1137563) 2026-01-26 09:26:54,331 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1137563) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 15.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 14.90it/s]
(EngineCore_DP0 pid=1137563) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.16it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|â–ˆ         | 27/256 [00:00<00:00, 266.79it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆâ–      | 80/256 [00:00<00:00, 418.81it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 130/256 [00:00<00:00, 454.87it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 179/256 [00:00<00:00, 468.46it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 230/256 [00:00<00:00, 480.20it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 461.47it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|â–‰         | 24/256 [00:00<00:01, 195.05it/s, est. speed input: 199765.15 toks/s, output: 195.06 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 44/256 [00:00<00:02, 103.51it/s, est. speed input: 114816.51 toks/s, output: 112.12 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 57/256 [00:00<00:02, 94.55it/s, est. speed input: 105448.27 toks/s, output: 102.98 toks/s] 
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 68/256 [00:00<00:02, 84.85it/s, est. speed input: 97257.25 toks/s, output: 94.98 toks/s]  
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 77/256 [00:00<00:02, 84.39it/s, est. speed input: 95653.71 toks/s, output: 93.41 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 86/256 [00:00<00:02, 77.78it/s, est. speed input: 91240.70 toks/s, output: 89.10 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 94/256 [00:01<00:02, 75.96it/s, est. speed input: 89304.96 toks/s, output: 87.21 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 102/256 [00:01<00:02, 74.56it/s, est. speed input: 87724.09 toks/s, output: 85.67 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 110/256 [00:01<00:01, 73.59it/s, est. speed input: 86441.40 toks/s, output: 84.41 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 118/256 [00:01<00:01, 72.81it/s, est. speed input: 85337.78 toks/s, output: 83.34 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 126/256 [00:01<00:01, 72.40it/s, est. speed input: 84441.80 toks/s, output: 82.46 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/256 [00:01<00:01, 72.09it/s, est. speed input: 83662.19 toks/s, output: 81.70 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 142/256 [00:01<00:01, 71.82it/s, est. speed input: 82972.58 toks/s, output: 81.03 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 150/256 [00:01<00:01, 71.65it/s, est. speed input: 82368.96 toks/s, output: 80.44 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 158/256 [00:01<00:01, 71.60it/s, est. speed input: 81848.87 toks/s, output: 79.93 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 166/256 [00:02<00:01, 71.55it/s, est. speed input: 81383.54 toks/s, output: 79.48 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 174/256 [00:02<00:01, 71.51it/s, est. speed input: 80962.60 toks/s, output: 79.06 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 182/256 [00:02<00:01, 71.40it/s, est. speed input: 80569.31 toks/s, output: 78.68 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 190/256 [00:02<00:00, 71.37it/s, est. speed input: 80218.53 toks/s, output: 78.34 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 198/256 [00:02<00:00, 71.37it/s, est. speed input: 79903.80 toks/s, output: 78.03 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 206/256 [00:02<00:00, 71.27it/s, est. speed input: 79598.63 toks/s, output: 77.73 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 214/256 [00:02<00:00, 71.20it/s, est. speed input: 79319.94 toks/s, output: 77.46 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 222/256 [00:02<00:00, 71.20it/s, est. speed input: 79069.66 toks/s, output: 77.22 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 230/256 [00:02<00:00, 71.10it/s, est. speed input: 78824.12 toks/s, output: 76.98 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 238/256 [00:03<00:00, 71.10it/s, est. speed input: 78605.35 toks/s, output: 76.76 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 246/256 [00:03<00:00, 71.06it/s, est. speed input: 78398.23 toks/s, output: 76.56 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 254/256 [00:03<00:00, 71.13it/s, est. speed input: 78217.00 toks/s, output: 76.38 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 71.13it/s, est. speed input: 78184.71 toks/s, output: 76.35 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:03<00:00, 76.35it/s, est. speed input: 78184.71 toks/s, output: 76.35 toks/s]
[rank0]:[W126 09:27:00.256821469 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 09:27:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:27:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1138625) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1138625) WARNING 01-26 09:27:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 83.70 requests/s, 85797.62 total tokens/s, 83.70 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 09:27:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:27:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:27:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:27:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:27:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:27:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:27:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:27:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:27:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:27:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:27:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:27:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1138625) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1138625) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1138625) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1138625) 
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1138625) [2026-01-26 09:27:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1138625) 2026-01-26 09:27:34,114 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1138625) 2026-01-26 09:27:34,166 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1138625) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  6.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.60it/s]
(EngineCore_DP0 pid=1138625) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 18.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 18.90it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|â–Œ         | 27/512 [00:00<00:01, 269.68it/s]
Adding requests:  15%|â–ˆâ–Œ        | 78/512 [00:00<00:01, 410.23it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 129/512 [00:00<00:00, 454.86it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 179/512 [00:00<00:00, 469.98it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/512 [00:00<00:00, 487.70it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 282/512 [00:00<00:00, 494.96it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 333/512 [00:00<00:00, 496.80it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 385/512 [00:00<00:00, 501.75it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 436/512 [00:00<00:00, 498.11it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 487/512 [00:01<00:00, 501.13it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:01<00:00, 482.43it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|â–ˆâ–Ž        | 70/512 [00:00<00:00, 559.80it/s, est. speed input: 573318.62 toks/s, output: 559.82 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–       | 126/512 [00:00<00:02, 147.37it/s, est. speed input: 172038.18 toks/s, output: 168.00 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 155/512 [00:01<00:02, 125.26it/s, est. speed input: 148401.47 toks/s, output: 144.92 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 175/512 [00:01<00:02, 115.11it/s, est. speed input: 138503.62 toks/s, output: 135.26 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 191/512 [00:01<00:02, 108.91it/s, est. speed input: 132825.97 toks/s, output: 129.71 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/512 [00:01<00:02, 108.08it/s, est. speed input: 130710.52 toks/s, output: 127.65 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 218/512 [00:01<00:02, 98.12it/s, est. speed input: 125091.48 toks/s, output: 122.16 toks/s] 
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 230/512 [00:01<00:02, 95.83it/s, est. speed input: 122643.12 toks/s, output: 119.77 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 242/512 [00:02<00:02, 93.97it/s, est. speed input: 120523.30 toks/s, output: 117.70 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 254/512 [00:02<00:02, 92.50it/s, est. speed input: 118665.84 toks/s, output: 115.88 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/512 [00:02<00:02, 91.39it/s, est. speed input: 117026.41 toks/s, output: 114.28 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 278/512 [00:02<00:02, 90.60it/s, est. speed input: 115579.06 toks/s, output: 112.87 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 290/512 [00:02<00:02, 90.22it/s, est. speed input: 114327.61 toks/s, output: 111.65 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 302/512 [00:02<00:02, 90.02it/s, est. speed input: 113216.44 toks/s, output: 110.56 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/512 [00:02<00:02, 89.68it/s, est. speed input: 112168.84 toks/s, output: 109.54 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 326/512 [00:03<00:02, 89.37it/s, est. speed input: 111203.08 toks/s, output: 108.60 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 338/512 [00:03<00:01, 88.99it/s, est. speed input: 110291.47 toks/s, output: 107.71 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 350/512 [00:03<00:01, 90.12it/s, est. speed input: 109693.33 toks/s, output: 107.12 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 362/512 [00:03<00:01, 89.60it/s, est. speed input: 108929.18 toks/s, output: 106.38 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 374/512 [00:03<00:01, 89.41it/s, est. speed input: 108248.99 toks/s, output: 105.71 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 386/512 [00:03<00:01, 89.43it/s, est. speed input: 107641.74 toks/s, output: 105.12 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 398/512 [00:03<00:01, 89.43it/s, est. speed input: 107076.00 toks/s, output: 104.56 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 410/512 [00:03<00:01, 89.33it/s, est. speed input: 106534.29 toks/s, output: 104.04 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/512 [00:04<00:01, 89.11it/s, est. speed input: 106008.76 toks/s, output: 103.52 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 434/512 [00:04<00:00, 88.80it/s, est. speed input: 105498.04 toks/s, output: 103.02 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 446/512 [00:04<00:00, 88.65it/s, est. speed input: 105026.84 toks/s, output: 102.56 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 458/512 [00:04<00:00, 90.28it/s, est. speed input: 104786.24 toks/s, output: 102.33 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/512 [00:04<00:00, 89.74it/s, est. speed input: 104370.39 toks/s, output: 101.92 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482/512 [00:04<00:00, 89.47it/s, est. speed input: 103989.72 toks/s, output: 101.55 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 494/512 [00:04<00:00, 89.30it/s, est. speed input: 103631.81 toks/s, output: 101.20 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 506/512 [00:05<00:00, 89.13it/s, est. speed input: 103286.48 toks/s, output: 100.87 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:05<00:00, 89.13it/s, est. speed input: 103746.62 toks/s, output: 101.31 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:05<00:00, 101.31it/s, est. speed input: 103746.62 toks/s, output: 101.31 toks/s]
[rank0]:[W126 09:27:42.393547077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 09:27:44
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:27:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1139744) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1139744) WARNING 01-26 09:28:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 90.34 requests/s, 92594.56 total tokens/s, 90.34 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 09:27:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:27:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:27:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:27:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:27:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:27:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:28:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:28:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:28:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:28:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:28:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:28:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1139744) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1139744) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1139744) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1139744) 
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1139744) [2026-01-26 09:28:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1139744) 2026-01-26 09:28:18,183 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1139744) 2026-01-26 09:28:18,226 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1139744) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:00,  3.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:01<00:00,  2.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.13it/s]
(EngineCore_DP0 pid=1139744) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 19.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.85it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|â–Ž         | 29/1024 [00:00<00:03, 287.96it/s]
Adding requests:   8%|â–Š         | 82/1024 [00:00<00:02, 428.35it/s]
Adding requests:  13%|â–ˆâ–Ž        | 134/1024 [00:00<00:01, 467.86it/s]
Adding requests:  18%|â–ˆâ–Š        | 184/1024 [00:00<00:01, 479.48it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 237/1024 [00:00<00:01, 494.42it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 288/1024 [00:00<00:01, 499.35it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 339/1024 [00:00<00:01, 500.43it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:01, 508.99it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 443/1024 [00:00<00:01, 508.95it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:01<00:01, 511.20it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 547/1024 [00:01<00:00, 503.62it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 600/1024 [00:01<00:00, 508.92it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 651/1024 [00:01<00:00, 508.42it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:01<00:00, 516.32it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:01<00:00, 514.22it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 809/1024 [00:01<00:00, 507.64it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 860/1024 [00:01<00:00, 505.85it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 913/1024 [00:01<00:00, 511.81it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 966/1024 [00:01<00:00, 514.63it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:02<00:00, 515.91it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 501.74it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 162/1024 [00:00<00:00, 1142.46it/s, est. speed input: 1170255.39 toks/s, output: 1142.56 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 277/1024 [00:01<00:04, 176.11it/s, est. speed input: 211760.74 toks/s, output: 206.80 toks/s]   
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 330/1024 [00:01<00:04, 140.83it/s, est. speed input: 173901.17 toks/s, output: 169.82 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 363/1024 [00:02<00:05, 130.61it/s, est. speed input: 163125.88 toks/s, output: 159.30 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 387/1024 [00:02<00:05, 122.92it/s, est. speed input: 156329.61 toks/s, output: 152.66 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 406/1024 [00:02<00:05, 120.83it/s, est. speed input: 153574.51 toks/s, output: 149.97 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 422/1024 [00:02<00:05, 115.39it/s, est. speed input: 150047.03 toks/s, output: 146.53 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 436/1024 [00:03<00:05, 108.08it/s, est. speed input: 146289.69 toks/s, output: 142.86 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 450/1024 [00:03<00:05, 102.90it/s, est. speed input: 143279.60 toks/s, output: 139.92 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 466/1024 [00:03<00:05, 100.79it/s, est. speed input: 140951.15 toks/s, output: 137.65 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 482/1024 [00:03<00:05, 98.76it/s, est. speed input: 138752.19 toks/s, output: 135.50 toks/s] 
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:03<00:05, 97.10it/s, est. speed input: 136728.19 toks/s, output: 133.52 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 514/1024 [00:03<00:05, 95.97it/s, est. speed input: 134902.76 toks/s, output: 131.74 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 530/1024 [00:04<00:05, 95.16it/s, est. speed input: 133236.15 toks/s, output: 130.11 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 546/1024 [00:04<00:05, 94.62it/s, est. speed input: 131714.34 toks/s, output: 128.63 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 562/1024 [00:04<00:04, 94.32it/s, est. speed input: 130324.71 toks/s, output: 127.27 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 578/1024 [00:04<00:04, 93.95it/s, est. speed input: 129013.79 toks/s, output: 125.99 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:04<00:04, 93.58it/s, est. speed input: 127777.69 toks/s, output: 124.78 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 610/1024 [00:04<00:04, 93.27it/s, est. speed input: 126620.23 toks/s, output: 123.65 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 626/1024 [00:05<00:04, 93.22it/s, est. speed input: 125567.88 toks/s, output: 122.62 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 642/1024 [00:05<00:04, 93.28it/s, est. speed input: 124597.50 toks/s, output: 121.68 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 658/1024 [00:05<00:03, 93.32it/s, est. speed input: 123687.11 toks/s, output: 120.79 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 674/1024 [00:05<00:03, 93.11it/s, est. speed input: 122800.08 toks/s, output: 119.92 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:05<00:03, 92.85it/s, est. speed input: 121951.97 toks/s, output: 119.09 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 706/1024 [00:05<00:03, 92.87it/s, est. speed input: 121178.81 toks/s, output: 118.34 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 722/1024 [00:06<00:03, 92.98it/s, est. speed input: 120460.32 toks/s, output: 117.64 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 738/1024 [00:06<00:03, 93.04it/s, est. speed input: 119777.86 toks/s, output: 116.97 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 754/1024 [00:06<00:02, 93.21it/s, est. speed input: 119146.88 toks/s, output: 116.35 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:06<00:02, 93.01it/s, est. speed input: 118513.45 toks/s, output: 115.74 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:06<00:02, 92.97it/s, est. speed input: 117922.80 toks/s, output: 115.16 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 802/1024 [00:06<00:02, 92.99it/s, est. speed input: 117366.46 toks/s, output: 114.62 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 818/1024 [00:07<00:02, 93.04it/s, est. speed input: 116839.34 toks/s, output: 114.10 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 834/1024 [00:07<00:02, 93.23it/s, est. speed input: 116352.57 toks/s, output: 113.63 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 850/1024 [00:07<00:01, 93.23it/s, est. speed input: 115875.82 toks/s, output: 113.16 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:07<00:01, 93.17it/s, est. speed input: 115414.29 toks/s, output: 112.71 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 882/1024 [00:07<00:01, 93.04it/s, est. speed input: 114964.79 toks/s, output: 112.27 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 898/1024 [00:08<00:01, 93.01it/s, est. speed input: 114540.57 toks/s, output: 111.86 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 914/1024 [00:08<00:01, 93.15it/s, est. speed input: 114147.39 toks/s, output: 111.47 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 930/1024 [00:08<00:01, 93.06it/s, est. speed input: 113755.47 toks/s, output: 111.09 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 946/1024 [00:08<00:00, 94.25it/s, est. speed input: 113479.93 toks/s, output: 110.82 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:08<00:00, 93.91it/s, est. speed input: 113122.43 toks/s, output: 110.47 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 978/1024 [00:08<00:00, 93.75it/s, est. speed input: 112784.87 toks/s, output: 110.14 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 994/1024 [00:09<00:00, 94.66it/s, est. speed input: 112536.33 toks/s, output: 109.90 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1010/1024 [00:09<00:00, 94.19it/s, est. speed input: 112215.92 toks/s, output: 109.59 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:09<00:00, 94.19it/s, est. speed input: 112843.88 toks/s, output: 110.20 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:09<00:00, 110.20it/s, est. speed input: 112843.88 toks/s, output: 110.20 toks/s]
[rank0]:[W126 09:28:33.173162193 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 09:28:35
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:28:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1140998) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1140998) WARNING 01-26 09:29:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 93.67 requests/s, 96011.60 total tokens/s, 93.67 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 09:28:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:28:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:28:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:28:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:28:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:28:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:28:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:28:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:28:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:28:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:28:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:28:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:28:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:28:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1140998) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1140998) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1140998) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1140998) 
(EngineCore_DP0 pid=1140998) [2026-01-26 09:28:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1140998) [2026-01-26 09:29:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1140998) 2026-01-26 09:29:12,924 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1140998) 2026-01-26 09:29:12,948 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1140998) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00, 14.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00, 12.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.50it/s]
(EngineCore_DP0 pid=1140998) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.44it/s]
Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 16.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 16.04it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 31/2048 [00:00<00:06, 305.93it/s]
Adding requests:   4%|â–         | 84/2048 [00:00<00:04, 434.70it/s]
Adding requests:   7%|â–‹         | 135/2048 [00:00<00:04, 468.03it/s]
Adding requests:   9%|â–‰         | 185/2048 [00:00<00:03, 479.02it/s]
Adding requests:  12%|â–ˆâ–        | 237/2048 [00:00<00:03, 493.57it/s]
Adding requests:  14%|â–ˆâ–        | 288/2048 [00:00<00:03, 495.95it/s]
Adding requests:  17%|â–ˆâ–‹        | 338/2048 [00:00<00:03, 496.84it/s]
Adding requests:  19%|â–ˆâ–‰        | 390/2048 [00:00<00:03, 503.76it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 441/2048 [00:00<00:03, 504.72it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 492/2048 [00:01<00:03, 505.45it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 543/2048 [00:01<00:03, 497.20it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 596/2048 [00:01<00:02, 504.90it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 649/2048 [00:01<00:02, 511.54it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 703/2048 [00:01<00:02, 519.83it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 756/2048 [00:01<00:02, 509.48it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 808/2048 [00:01<00:02, 506.12it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 859/2048 [00:01<00:02, 505.82it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 913/2048 [00:01<00:02, 514.22it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 966/2048 [00:01<00:02, 517.21it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1019/2048 [00:02<00:01, 519.74it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1071/2048 [00:02<00:01, 515.79it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1123/2048 [00:02<00:01, 516.32it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1177/2048 [00:02<00:01, 521.71it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1231/2048 [00:02<00:01, 526.31it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1284/2048 [00:02<00:01, 521.06it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1338/2048 [00:02<00:01, 522.81it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1392/2048 [00:02<00:01, 525.68it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1445/2048 [00:02<00:01, 522.24it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1500/2048 [00:02<00:01, 528.33it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1553/2048 [00:03<00:00, 525.85it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1608/2048 [00:03<00:00, 531.78it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1662/2048 [00:03<00:00, 528.09it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1715/2048 [00:03<00:00, 527.73it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1768/2048 [00:03<00:00, 525.24it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1821/2048 [00:03<00:00, 524.36it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1874/2048 [00:03<00:00, 522.84it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1927/2048 [00:03<00:00, 512.09it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1980/2048 [00:03<00:00, 516.12it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2034/2048 [00:03<00:00, 520.44it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:04<00:00, 511.92it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 354/2048 [00:00<00:00, 1705.92it/s, est. speed input: 1747057.16 toks/s, output: 1705.98 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 525/2048 [00:01<00:06, 230.22it/s, est. speed input: 285743.66 toks/s, output: 279.04 toks/s]   
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 602/2048 [00:02<00:08, 174.83it/s, est. speed input: 226199.43 toks/s, output: 220.90 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 648/2048 [00:03<00:09, 153.60it/s, est. speed input: 205462.43 toks/s, output: 200.65 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 680/2048 [00:03<00:09, 141.96it/s, est. speed input: 195103.86 toks/s, output: 190.53 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 704/2048 [00:03<00:09, 141.98it/s, est. speed input: 192864.63 toks/s, output: 188.34 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 725/2048 [00:04<00:10, 121.43it/s, est. speed input: 182215.50 toks/s, output: 177.94 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 741/2048 [00:04<00:11, 117.26it/s, est. speed input: 178827.60 toks/s, output: 174.64 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 755/2048 [00:04<00:11, 110.94it/s, est. speed input: 175214.59 toks/s, output: 171.11 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 770/2048 [00:04<00:12, 106.36it/s, est. speed input: 172108.36 toks/s, output: 168.07 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 786/2048 [00:04<00:12, 103.76it/s, est. speed input: 169452.15 toks/s, output: 165.48 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 802/2048 [00:04<00:12, 101.70it/s, est. speed input: 167002.24 toks/s, output: 163.09 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 818/2048 [00:05<00:12, 99.90it/s, est. speed input: 164680.08 toks/s, output: 160.82 toks/s] 
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 834/2048 [00:05<00:12, 98.73it/s, est. speed input: 162549.57 toks/s, output: 158.74 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 850/2048 [00:05<00:12, 97.59it/s, est. speed input: 160504.01 toks/s, output: 156.74 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 866/2048 [00:05<00:12, 96.78it/s, est. speed input: 158586.18 toks/s, output: 154.87 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 882/2048 [00:05<00:12, 96.06it/s, est. speed input: 156760.43 toks/s, output: 153.09 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 898/2048 [00:05<00:11, 95.99it/s, est. speed input: 155108.49 toks/s, output: 151.47 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 914/2048 [00:06<00:11, 95.61it/s, est. speed input: 153497.67 toks/s, output: 149.90 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 930/2048 [00:06<00:11, 97.22it/s, est. speed input: 152241.37 toks/s, output: 148.67 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 946/2048 [00:06<00:11, 96.40it/s, est. speed input: 150781.09 toks/s, output: 147.25 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 962/2048 [00:06<00:11, 96.08it/s, est. speed input: 149426.72 toks/s, output: 145.92 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 978/2048 [00:06<00:10, 97.40it/s, est. speed input: 148335.37 toks/s, output: 144.86 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 994/2048 [00:06<00:10, 96.59it/s, est. speed input: 147083.01 toks/s, output: 143.63 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1010/2048 [00:07<00:10, 95.92it/s, est. speed input: 145877.48 toks/s, output: 142.46 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1026/2048 [00:07<00:10, 95.75it/s, est. speed input: 144762.25 toks/s, output: 141.37 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1042/2048 [00:07<00:10, 95.41it/s, est. speed input: 143672.08 toks/s, output: 140.30 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1058/2048 [00:07<00:10, 95.26it/s, est. speed input: 142640.08 toks/s, output: 139.30 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1074/2048 [00:07<00:10, 95.09it/s, est. speed input: 141646.27 toks/s, output: 138.33 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1090/2048 [00:07<00:10, 95.27it/s, est. speed input: 140726.47 toks/s, output: 137.43 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1106/2048 [00:08<00:09, 94.99it/s, est. speed input: 139802.67 toks/s, output: 136.53 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1122/2048 [00:08<00:09, 94.90it/s, est. speed input: 138926.85 toks/s, output: 135.67 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1138/2048 [00:08<00:09, 94.88it/s, est. speed input: 138091.32 toks/s, output: 134.85 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1154/2048 [00:08<00:09, 96.55it/s, est. speed input: 137445.16 toks/s, output: 134.22 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:08<00:09, 95.97it/s, est. speed input: 136663.32 toks/s, output: 133.46 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1186/2048 [00:08<00:09, 95.62it/s, est. speed input: 135915.77 toks/s, output: 132.73 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1202/2048 [00:09<00:08, 95.36it/s, est. speed input: 135194.61 toks/s, output: 132.03 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1218/2048 [00:09<00:08, 95.33it/s, est. speed input: 134512.90 toks/s, output: 131.36 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1234/2048 [00:09<00:08, 95.05it/s, est. speed input: 133833.04 toks/s, output: 130.70 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1250/2048 [00:09<00:08, 95.00it/s, est. speed input: 133190.11 toks/s, output: 130.07 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1266/2048 [00:09<00:08, 94.90it/s, est. speed input: 132563.48 toks/s, output: 129.46 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1282/2048 [00:09<00:08, 94.71it/s, est. speed input: 131948.42 toks/s, output: 128.86 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1298/2048 [00:10<00:07, 94.70it/s, est. speed input: 131364.05 toks/s, output: 128.28 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1314/2048 [00:10<00:07, 94.76it/s, est. speed input: 130803.38 toks/s, output: 127.74 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1330/2048 [00:10<00:07, 94.80it/s, est. speed input: 130261.54 toks/s, output: 127.21 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1346/2048 [00:10<00:07, 94.80it/s, est. speed input: 129734.04 toks/s, output: 126.69 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1362/2048 [00:10<00:07, 94.73it/s, est. speed input: 129217.98 toks/s, output: 126.19 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1378/2048 [00:10<00:07, 94.48it/s, est. speed input: 128704.25 toks/s, output: 125.69 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1394/2048 [00:11<00:06, 94.60it/s, est. speed input: 128226.72 toks/s, output: 125.22 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1410/2048 [00:11<00:06, 94.54it/s, est. speed input: 127753.19 toks/s, output: 124.76 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1426/2048 [00:11<00:06, 94.61it/s, est. speed input: 127301.11 toks/s, output: 124.32 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1442/2048 [00:11<00:06, 94.63it/s, est. speed input: 126861.17 toks/s, output: 123.89 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1458/2048 [00:11<00:06, 94.46it/s, est. speed input: 126421.08 toks/s, output: 123.46 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1474/2048 [00:11<00:06, 94.42it/s, est. speed input: 125998.19 toks/s, output: 123.04 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1490/2048 [00:12<00:05, 94.23it/s, est. speed input: 125577.75 toks/s, output: 122.63 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1506/2048 [00:12<00:05, 94.38it/s, est. speed input: 125185.83 toks/s, output: 122.25 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1522/2048 [00:12<00:05, 94.49it/s, est. speed input: 124804.83 toks/s, output: 121.88 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1538/2048 [00:12<00:05, 94.51it/s, est. speed input: 124430.86 toks/s, output: 121.51 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1554/2048 [00:12<00:05, 94.51it/s, est. speed input: 124066.02 toks/s, output: 121.16 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1570/2048 [00:12<00:05, 94.55it/s, est. speed input: 123712.64 toks/s, output: 120.81 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1586/2048 [00:13<00:04, 96.37it/s, est. speed input: 123467.14 toks/s, output: 120.57 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1602/2048 [00:13<00:04, 95.74it/s, est. speed input: 123124.65 toks/s, output: 120.24 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1618/2048 [00:13<00:04, 95.43it/s, est. speed input: 122796.99 toks/s, output: 119.92 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1634/2048 [00:13<00:04, 95.12it/s, est. speed input: 122472.77 toks/s, output: 119.60 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1650/2048 [00:13<00:04, 94.94it/s, est. speed input: 122158.48 toks/s, output: 119.30 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1666/2048 [00:14<00:04, 94.72it/s, est. speed input: 121846.84 toks/s, output: 118.99 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1682/2048 [00:14<00:03, 94.75it/s, est. speed input: 121552.17 toks/s, output: 118.70 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1698/2048 [00:14<00:03, 94.65it/s, est. speed input: 121258.29 toks/s, output: 118.42 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1714/2048 [00:14<00:03, 94.57it/s, est. speed input: 120970.79 toks/s, output: 118.14 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1730/2048 [00:14<00:03, 94.56it/s, est. speed input: 120691.91 toks/s, output: 117.86 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1746/2048 [00:14<00:03, 94.60it/s, est. speed input: 120421.85 toks/s, output: 117.60 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1762/2048 [00:15<00:03, 94.59it/s, est. speed input: 120156.45 toks/s, output: 117.34 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1778/2048 [00:15<00:02, 94.54it/s, est. speed input: 119894.70 toks/s, output: 117.08 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1794/2048 [00:15<00:02, 94.74it/s, est. speed input: 119649.18 toks/s, output: 116.84 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1810/2048 [00:15<00:02, 94.51it/s, est. speed input: 119392.40 toks/s, output: 116.59 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1826/2048 [00:15<00:02, 94.50it/s, est. speed input: 119148.19 toks/s, output: 116.36 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1842/2048 [00:15<00:02, 94.45it/s, est. speed input: 118906.97 toks/s, output: 116.12 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1858/2048 [00:16<00:02, 94.56it/s, est. speed input: 118677.18 toks/s, output: 115.90 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1874/2048 [00:16<00:01, 96.19it/s, est. speed input: 118518.97 toks/s, output: 115.74 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1890/2048 [00:16<00:01, 95.50it/s, est. speed input: 118286.34 toks/s, output: 115.51 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1906/2048 [00:16<00:01, 95.19it/s, est. speed input: 118065.83 toks/s, output: 115.30 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1922/2048 [00:16<00:01, 94.89it/s, est. speed input: 117845.79 toks/s, output: 115.08 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1938/2048 [00:16<00:01, 94.84it/s, est. speed input: 117637.26 toks/s, output: 114.88 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1954/2048 [00:17<00:00, 96.56it/s, est. speed input: 117503.10 toks/s, output: 114.75 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1970/2048 [00:17<00:00, 95.89it/s, est. speed input: 117297.36 toks/s, output: 114.55 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1986/2048 [00:17<00:00, 95.33it/s, est. speed input: 117091.60 toks/s, output: 114.35 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2002/2048 [00:17<00:00, 95.20it/s, est. speed input: 116900.21 toks/s, output: 114.16 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [00:17<00:00, 95.04it/s, est. speed input: 116709.59 toks/s, output: 113.97 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2034/2048 [00:17<00:00, 97.51it/s, est. speed input: 116619.57 toks/s, output: 113.89 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:17<00:00, 97.51it/s, est. speed input: 117418.52 toks/s, output: 114.67 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:17<00:00, 114.67it/s, est. speed input: 117418.52 toks/s, output: 114.67 toks/s]
[rank0]:[W126 09:29:37.877122916 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 09:29:40
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:30:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1142489) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1142489) WARNING 01-26 09:30:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 97.00 requests/s, 99429.37 total tokens/s, 97.00 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 09:30:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:30:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:30:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:30:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:30:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:30:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:30:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:30:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:30:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:30:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:30:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:30:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:30:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:30:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:30:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:30:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:30:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1142489) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1142489) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1142489) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1142489) 
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1142489) [2026-01-26 09:30:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1142489) 2026-01-26 09:30:28,571 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1142489) 2026-01-26 09:30:28,620 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1142489) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 1/11 [00:00<00:01,  9.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 3/11 [00:00<00:00, 14.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [00:00<00:00, 16.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 7/11 [00:00<00:00, 17.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [00:00<00:00, 17.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 11.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 13.08it/s]
(EngineCore_DP0 pid=1142489) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 1/7 [00:00<00:00,  8.03it/s]
Capturing CUDA graphs (decode, FULL):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:01,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00,  5.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  7.73it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 34/4096 [00:00<00:12, 333.45it/s]
Adding requests:   2%|â–         | 86/4096 [00:00<00:09, 441.39it/s]
Adding requests:   3%|â–Ž         | 137/4096 [00:00<00:08, 471.91it/s]
Adding requests:   5%|â–         | 188/4096 [00:00<00:08, 481.94it/s]
Adding requests:   6%|â–Œ         | 240/4096 [00:00<00:07, 495.49it/s]
Adding requests:   7%|â–‹         | 291/4096 [00:00<00:07, 499.74it/s]
Adding requests:   8%|â–Š         | 342/4096 [00:00<00:07, 500.82it/s]
Adding requests:  10%|â–‰         | 395/4096 [00:00<00:07, 509.33it/s]
Adding requests:  11%|â–ˆ         | 446/4096 [00:00<00:07, 508.61it/s]
Adding requests:  12%|â–ˆâ–        | 498/4096 [00:01<00:07, 509.53it/s]
Adding requests:  13%|â–ˆâ–Ž        | 549/4096 [00:01<00:07, 503.35it/s]
Adding requests:  15%|â–ˆâ–        | 601/4096 [00:01<00:06, 507.06it/s]
Adding requests:  16%|â–ˆâ–Œ        | 655/4096 [00:01<00:06, 515.57it/s]
Adding requests:  17%|â–ˆâ–‹        | 709/4096 [00:01<00:06, 520.93it/s]
Adding requests:  19%|â–ˆâ–Š        | 762/4096 [00:01<00:06, 519.95it/s]
Adding requests:  20%|â–ˆâ–‰        | 815/4096 [00:01<00:06, 511.35it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 867/4096 [00:01<00:06, 512.62it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 921/4096 [00:01<00:06, 518.73it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 974/4096 [00:01<00:06, 519.75it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 1027/4096 [00:02<00:05, 522.29it/s]
Adding requests:  26%|â–ˆâ–ˆâ–‹       | 1080/4096 [00:02<00:05, 508.39it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 1131/4096 [00:02<00:05, 507.21it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 1186/4096 [00:02<00:05, 517.39it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 1240/4096 [00:02<00:05, 521.94it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 1293/4096 [00:02<00:05, 519.18it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1347/4096 [00:02<00:05, 522.56it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 1401/4096 [00:02<00:05, 526.21it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1454/4096 [00:02<00:05, 525.06it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1509/4096 [00:02<00:04, 530.43it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1563/4096 [00:03<00:04, 529.35it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1617/4096 [00:03<00:04, 532.49it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1671/4096 [00:03<00:04, 528.25it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1726/4096 [00:03<00:04, 532.67it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1780/4096 [00:03<00:04, 526.19it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1834/4096 [00:03<00:04, 527.40it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1887/4096 [00:03<00:04, 526.69it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1940/4096 [00:03<00:04, 524.29it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1993/4096 [00:03<00:04, 522.77it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2047/4096 [00:03<00:03, 526.88it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2101/4096 [00:04<00:03, 529.00it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2154/4096 [00:04<00:03, 522.29it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2207/4096 [00:04<00:03, 518.24it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2261/4096 [00:04<00:03, 523.04it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2314/4096 [00:04<00:03, 516.09it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2366/4096 [00:04<00:03, 514.92it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2419/4096 [00:04<00:03, 517.41it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2472/4096 [00:04<00:03, 519.08it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2524/4096 [00:04<00:03, 518.51it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2579/4096 [00:04<00:02, 525.86it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2632/4096 [00:05<00:02, 522.97it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2686/4096 [00:05<00:02, 525.16it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2739/4096 [00:05<00:02, 520.57it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2792/4096 [00:05<00:02, 519.33it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2845/4096 [00:05<00:02, 520.43it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2899/4096 [00:05<00:02, 522.78it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2952/4096 [00:05<00:02, 519.15it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3005/4096 [00:05<00:02, 519.96it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3058/4096 [00:05<00:01, 521.35it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3111/4096 [00:06<00:01, 518.83it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3164/4096 [00:06<00:01, 519.78it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3217/4096 [00:06<00:01, 521.96it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3270/4096 [00:06<00:01, 523.63it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3323/4096 [00:06<00:01, 523.74it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3377/4096 [00:06<00:01, 526.40it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3430/4096 [00:06<00:01, 526.96it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3483/4096 [00:06<00:01, 516.90it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3535/4096 [00:06<00:01, 517.24it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3588/4096 [00:06<00:00, 517.90it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3640/4096 [00:07<00:00, 504.39it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3694/4096 [00:07<00:00, 511.94it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3746/4096 [00:07<00:00, 513.11it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3801/4096 [00:07<00:00, 523.85it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3855/4096 [00:07<00:00, 526.82it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3908/4096 [00:07<00:00, 527.01it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3961/4096 [00:07<00:00, 527.87it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4014/4096 [00:07<00:00, 527.06it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4067/4096 [00:07<00:00, 521.55it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:07<00:00, 517.79it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|â–ˆâ–Š        | 760/4096 [00:00<00:01, 1792.79it/s, est. speed input: 1835919.63 toks/s, output: 1792.82 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 940/4096 [00:02<00:08, 368.43it/s, est. speed input: 467331.11 toks/s, output: 456.38 toks/s]   
Processed prompts:  25%|â–ˆâ–ˆâ–       | 1021/4096 [00:03<00:12, 248.72it/s, est. speed input: 344314.34 toks/s, output: 336.24 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 1069/4096 [00:03<00:13, 231.66it/s, est. speed input: 325424.90 toks/s, output: 317.80 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 1104/4096 [00:03<00:14, 207.30it/s, est. speed input: 306067.48 toks/s, output: 298.89 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 1130/4096 [00:04<00:16, 179.54it/s, est. speed input: 287661.42 toks/s, output: 280.92 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 1150/4096 [00:04<00:19, 152.52it/s, est. speed input: 271209.43 toks/s, output: 264.85 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–Š       | 1176/4096 [00:04<00:21, 133.77it/s, est. speed input: 257749.63 toks/s, output: 251.71 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 1208/4096 [00:05<00:23, 124.15it/s, est. speed input: 247386.76 toks/s, output: 241.59 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 1240/4096 [00:05<00:24, 116.89it/s, est. speed input: 238327.58 toks/s, output: 232.74 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 1272/4096 [00:05<00:25, 111.21it/s, est. speed input: 230203.10 toks/s, output: 224.81 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 1304/4096 [00:05<00:26, 107.18it/s, est. speed input: 223018.20 toks/s, output: 217.79 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1336/4096 [00:06<00:26, 104.40it/s, est. speed input: 216626.78 toks/s, output: 211.55 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1368/4096 [00:06<00:26, 102.19it/s, est. speed input: 210794.94 toks/s, output: 205.85 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 1400/4096 [00:06<00:26, 100.73it/s, est. speed input: 205547.71 toks/s, output: 200.73 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 1432/4096 [00:07<00:26, 99.87it/s, est. speed input: 200825.54 toks/s, output: 196.12 toks/s] 
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1464/4096 [00:07<00:26, 98.90it/s, est. speed input: 196406.16 toks/s, output: 191.80 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1496/4096 [00:07<00:26, 98.47it/s, est. speed input: 192421.47 toks/s, output: 187.91 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1528/4096 [00:08<00:26, 98.23it/s, est. speed input: 188768.34 toks/s, output: 184.34 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1560/4096 [00:08<00:25, 97.80it/s, est. speed input: 185329.12 toks/s, output: 180.98 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1592/4096 [00:08<00:25, 97.67it/s, est. speed input: 182184.31 toks/s, output: 177.91 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1624/4096 [00:09<00:25, 97.64it/s, est. speed input: 179276.74 toks/s, output: 175.07 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1656/4096 [00:09<00:25, 97.47it/s, est. speed input: 176533.95 toks/s, output: 172.40 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1688/4096 [00:09<00:24, 97.28it/s, est. speed input: 173961.64 toks/s, output: 169.88 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1720/4096 [00:10<00:24, 97.34it/s, est. speed input: 171590.24 toks/s, output: 167.57 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1752/4096 [00:10<00:24, 97.28it/s, est. speed input: 169347.17 toks/s, output: 165.38 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1784/4096 [00:10<00:23, 97.21it/s, est. speed input: 167235.36 toks/s, output: 163.32 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1816/4096 [00:11<00:23, 97.22it/s, est. speed input: 165257.08 toks/s, output: 161.38 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1848/4096 [00:11<00:23, 97.18it/s, est. speed input: 163383.06 toks/s, output: 159.55 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1880/4096 [00:11<00:22, 97.90it/s, est. speed input: 161727.80 toks/s, output: 157.94 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1912/4096 [00:12<00:22, 97.28it/s, est. speed input: 159993.68 toks/s, output: 156.24 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1944/4096 [00:12<00:21, 98.28it/s, est. speed input: 158553.24 toks/s, output: 154.84 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1976/4096 [00:12<00:21, 98.14it/s, est. speed input: 157070.92 toks/s, output: 153.39 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2008/4096 [00:13<00:21, 97.86it/s, est. speed input: 155637.04 toks/s, output: 151.99 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2040/4096 [00:13<00:21, 97.84it/s, est. speed input: 154295.81 toks/s, output: 150.68 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2072/4096 [00:13<00:20, 97.75it/s, est. speed input: 153009.02 toks/s, output: 149.42 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2104/4096 [00:14<00:20, 97.56it/s, est. speed input: 151765.78 toks/s, output: 148.21 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2136/4096 [00:14<00:20, 97.54it/s, est. speed input: 150592.58 toks/s, output: 147.06 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2168/4096 [00:14<00:19, 97.53it/s, est. speed input: 149470.94 toks/s, output: 145.97 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2200/4096 [00:15<00:19, 97.57it/s, est. speed input: 148402.93 toks/s, output: 144.92 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2232/4096 [00:15<00:18, 99.13it/s, est. speed input: 147541.67 toks/s, output: 144.08 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2264/4096 [00:15<00:18, 98.72it/s, est. speed input: 146560.68 toks/s, output: 143.13 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2296/4096 [00:16<00:18, 99.13it/s, est. speed input: 145687.23 toks/s, output: 142.27 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2328/4096 [00:16<00:17, 99.29it/s, est. speed input: 144836.76 toks/s, output: 141.44 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2360/4096 [00:16<00:17, 98.76it/s, est. speed input: 143958.53 toks/s, output: 140.58 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2392/4096 [00:17<00:17, 98.41it/s, est. speed input: 143115.16 toks/s, output: 139.76 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2424/4096 [00:17<00:17, 98.00it/s, est. speed input: 142288.23 toks/s, output: 138.95 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2456/4096 [00:17<00:16, 97.83it/s, est. speed input: 141502.78 toks/s, output: 138.19 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2488/4096 [00:18<00:16, 98.48it/s, est. speed input: 140811.77 toks/s, output: 137.51 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2520/4096 [00:18<00:16, 98.17it/s, est. speed input: 140081.16 toks/s, output: 136.80 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2552/4096 [00:18<00:15, 97.85it/s, est. speed input: 139366.72 toks/s, output: 136.10 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2584/4096 [00:19<00:15, 98.49it/s, est. speed input: 138746.71 toks/s, output: 135.49 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2616/4096 [00:19<00:15, 98.23it/s, est. speed input: 138091.24 toks/s, output: 134.85 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2648/4096 [00:19<00:14, 97.86it/s, est. speed input: 137443.67 toks/s, output: 134.22 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2680/4096 [00:20<00:14, 97.63it/s, est. speed input: 136818.71 toks/s, output: 133.61 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2712/4096 [00:20<00:14, 97.64it/s, est. speed input: 136227.23 toks/s, output: 133.03 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2744/4096 [00:20<00:13, 97.55it/s, est. speed input: 135646.78 toks/s, output: 132.47 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2776/4096 [00:21<00:13, 97.42it/s, est. speed input: 135080.51 toks/s, output: 131.91 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2808/4096 [00:21<00:13, 97.41it/s, est. speed input: 134536.84 toks/s, output: 131.38 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2840/4096 [00:21<00:12, 97.35it/s, est. speed input: 134005.93 toks/s, output: 130.86 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2872/4096 [00:22<00:12, 97.31it/s, est. speed input: 133491.42 toks/s, output: 130.36 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2904/4096 [00:22<00:12, 97.29it/s, est. speed input: 132991.84 toks/s, output: 129.87 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2936/4096 [00:22<00:11, 97.21it/s, est. speed input: 132503.23 toks/s, output: 129.40 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2968/4096 [00:23<00:11, 97.27it/s, est. speed input: 132035.88 toks/s, output: 128.94 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3000/4096 [00:23<00:11, 97.22it/s, est. speed input: 131575.71 toks/s, output: 128.49 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3032/4096 [00:23<00:10, 97.14it/s, est. speed input: 131125.55 toks/s, output: 128.05 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3064/4096 [00:24<00:10, 97.21it/s, est. speed input: 130695.38 toks/s, output: 127.63 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3096/4096 [00:24<00:10, 97.12it/s, est. speed input: 130268.37 toks/s, output: 127.21 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3128/4096 [00:24<00:09, 97.85it/s, est. speed input: 129899.71 toks/s, output: 126.85 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3160/4096 [00:24<00:09, 97.75it/s, est. speed input: 129505.18 toks/s, output: 126.47 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3192/4096 [00:25<00:09, 97.55it/s, est. speed input: 129113.84 toks/s, output: 126.09 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3224/4096 [00:25<00:08, 97.39it/s, est. speed input: 128730.69 toks/s, output: 125.71 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3256/4096 [00:25<00:08, 97.32it/s, est. speed input: 128360.32 toks/s, output: 125.35 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3288/4096 [00:26<00:08, 97.34it/s, est. speed input: 128002.44 toks/s, output: 125.00 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3320/4096 [00:26<00:07, 97.09it/s, est. speed input: 127639.42 toks/s, output: 124.65 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3352/4096 [00:26<00:07, 97.11it/s, est. speed input: 127295.33 toks/s, output: 124.31 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3384/4096 [00:27<00:07, 97.26it/s, est. speed input: 126967.00 toks/s, output: 123.99 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3416/4096 [00:27<00:07, 97.08it/s, est. speed input: 126631.60 toks/s, output: 123.66 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3448/4096 [00:27<00:06, 97.07it/s, est. speed input: 126309.95 toks/s, output: 123.35 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3480/4096 [00:28<00:06, 97.13it/s, est. speed input: 125999.57 toks/s, output: 123.05 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3512/4096 [00:28<00:06, 97.02it/s, est. speed input: 125688.60 toks/s, output: 122.74 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3544/4096 [00:28<00:05, 97.04it/s, est. speed input: 125389.26 toks/s, output: 122.45 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3576/4096 [00:29<00:05, 97.13it/s, est. speed input: 125100.47 toks/s, output: 122.17 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3608/4096 [00:29<00:05, 96.95it/s, est. speed input: 124806.65 toks/s, output: 121.88 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3640/4096 [00:29<00:04, 96.90it/s, est. speed input: 124522.72 toks/s, output: 121.60 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3672/4096 [00:30<00:04, 96.92it/s, est. speed input: 124247.64 toks/s, output: 121.34 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3704/4096 [00:30<00:04, 96.85it/s, est. speed input: 123974.36 toks/s, output: 121.07 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3736/4096 [00:30<00:03, 97.51it/s, est. speed input: 123739.59 toks/s, output: 120.84 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3768/4096 [00:31<00:03, 97.42it/s, est. speed input: 123484.53 toks/s, output: 120.59 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3800/4096 [00:31<00:03, 97.27it/s, est. speed input: 123231.01 toks/s, output: 120.34 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3832/4096 [00:31<00:02, 97.09it/s, est. speed input: 122979.72 toks/s, output: 120.10 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3864/4096 [00:32<00:02, 97.09it/s, est. speed input: 122738.89 toks/s, output: 119.86 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3896/4096 [00:32<00:02, 97.01it/s, est. speed input: 122499.19 toks/s, output: 119.63 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3928/4096 [00:32<00:01, 96.94it/s, est. speed input: 122264.10 toks/s, output: 119.40 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3960/4096 [00:33<00:01, 96.96it/s, est. speed input: 122036.41 toks/s, output: 119.18 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3992/4096 [00:33<00:01, 96.87it/s, est. speed input: 121808.87 toks/s, output: 118.95 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4024/4096 [00:33<00:00, 97.62it/s, est. speed input: 121619.07 toks/s, output: 118.77 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4056/4096 [00:34<00:00, 97.55it/s, est. speed input: 121408.82 toks/s, output: 118.56 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4088/4096 [00:34<00:00, 123.12it/s, est. speed input: 122006.63 toks/s, output: 119.15 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:34<00:00, 123.12it/s, est. speed input: 122243.60 toks/s, output: 119.38 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:34<00:00, 119.38it/s, est. speed input: 122243.60 toks/s, output: 119.38 toks/s]
[rank0]:[W126 09:31:14.354184688 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 09:31:17
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:31:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1144492) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1144492) WARNING 01-26 09:32:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 97.72 requests/s, 100164.08 total tokens/s, 97.72 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 09:31:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:31:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:31:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:31:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:31:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:31:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:31:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:31:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:31:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:32:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:32:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:32:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:32:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:32:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:32:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:32:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:32:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:32:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1144492) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1144492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1144492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1144492) 
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5898240 bytes
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1144492) [2026-01-26 09:32:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1144492) 2026-01-26 09:32:20,584 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1144492) 2026-01-26 09:32:20,690 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1144492) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|â–Œ         | 1/19 [00:00<00:13,  1.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|â–ˆ         | 2/19 [00:01<00:09,  1.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:03,  4.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  6.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  8.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  8.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  7.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00,  9.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 10.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  6.60it/s]
(EngineCore_DP0 pid=1144492) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 2/11 [00:00<00:00, 18.83it/s]
Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:00<00:00, 11.37it/s]
Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:00<00:00, 10.95it/s]
Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:01<00:00,  5.88it/s]
Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [00:01<00:00,  6.26it/s]
Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00,  6.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  7.60it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 41/8192 [00:00<00:20, 407.16it/s]
Adding requests:   1%|          | 93/8192 [00:00<00:17, 471.93it/s]
Adding requests:   2%|â–         | 143/8192 [00:00<00:16, 484.58it/s]
Adding requests:   2%|â–         | 193/8192 [00:00<00:16, 487.68it/s]
Adding requests:   3%|â–Ž         | 245/8192 [00:00<00:16, 495.75it/s]
Adding requests:   4%|â–Ž         | 295/8192 [00:00<00:15, 496.74it/s]
Adding requests:   4%|â–         | 345/8192 [00:00<00:16, 488.96it/s]
Adding requests:   5%|â–         | 398/8192 [00:00<00:15, 499.86it/s]
Adding requests:   5%|â–Œ         | 449/8192 [00:00<00:15, 501.62it/s]
Adding requests:   6%|â–Œ         | 500/8192 [00:01<00:15, 499.78it/s]
Adding requests:   7%|â–‹         | 550/8192 [00:01<00:15, 495.59it/s]
Adding requests:   7%|â–‹         | 600/8192 [00:01<00:15, 493.77it/s]
Adding requests:   8%|â–Š         | 653/8192 [00:01<00:14, 502.62it/s]
Adding requests:   9%|â–Š         | 706/8192 [00:01<00:14, 509.90it/s]
Adding requests:   9%|â–‰         | 758/8192 [00:01<00:14, 510.63it/s]
Adding requests:  10%|â–‰         | 810/8192 [00:01<00:14, 503.16it/s]
Adding requests:  11%|â–ˆ         | 861/8192 [00:01<00:14, 502.60it/s]
Adding requests:  11%|â–ˆ         | 914/8192 [00:01<00:14, 507.62it/s]
Adding requests:  12%|â–ˆâ–        | 967/8192 [00:01<00:14, 511.91it/s]
Adding requests:  12%|â–ˆâ–        | 1019/8192 [00:02<00:13, 513.93it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1071/8192 [00:02<00:13, 511.01it/s]
Adding requests:  14%|â–ˆâ–Ž        | 1123/8192 [00:02<00:13, 511.42it/s]
Adding requests:  14%|â–ˆâ–        | 1177/8192 [00:02<00:13, 518.96it/s]
Adding requests:  15%|â–ˆâ–Œ        | 1231/8192 [00:02<00:13, 524.38it/s]
Adding requests:  16%|â–ˆâ–Œ        | 1284/8192 [00:02<00:13, 519.34it/s]
Adding requests:  16%|â–ˆâ–‹        | 1338/8192 [00:02<00:13, 522.07it/s]
Adding requests:  17%|â–ˆâ–‹        | 1392/8192 [00:02<00:12, 524.54it/s]
Adding requests:  18%|â–ˆâ–Š        | 1445/8192 [00:02<00:12, 523.13it/s]
Adding requests:  18%|â–ˆâ–Š        | 1498/8192 [00:02<00:12, 523.66it/s]
Adding requests:  19%|â–ˆâ–‰        | 1551/8192 [00:03<00:12, 523.70it/s]
Adding requests:  20%|â–ˆâ–‰        | 1605/8192 [00:03<00:12, 527.77it/s]
Adding requests:  20%|â–ˆâ–ˆ        | 1658/8192 [00:03<00:12, 523.28it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 1711/8192 [00:03<00:12, 521.39it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1764/8192 [00:03<00:12, 512.09it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1817/8192 [00:03<00:12, 514.51it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1869/8192 [00:03<00:12, 511.89it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1922/8192 [00:03<00:12, 517.17it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 1974/8192 [00:03<00:12, 515.82it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 2027/8192 [00:03<00:11, 519.19it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 2080/8192 [00:04<00:11, 521.14it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 2133/8192 [00:04<00:11, 517.58it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2185/8192 [00:04<00:11, 509.83it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2239/8192 [00:04<00:11, 517.37it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2291/8192 [00:04<00:11, 517.40it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 2344/8192 [00:04<00:11, 519.33it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 2396/8192 [00:04<00:11, 518.98it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 2449/8192 [00:04<00:11, 519.24it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2502/8192 [00:04<00:10, 519.04it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2556/8192 [00:04<00:10, 524.02it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2609/8192 [00:05<00:10, 523.15it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2663/8192 [00:05<00:10, 526.68it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2716/8192 [00:05<00:10, 520.45it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 2769/8192 [00:05<00:10, 521.46it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 2822/8192 [00:05<00:10, 516.01it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2875/8192 [00:05<00:10, 517.99it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2927/8192 [00:05<00:10, 517.35it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 2980/8192 [00:05<00:10, 519.56it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3032/8192 [00:05<00:09, 517.35it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3084/8192 [00:06<00:10, 503.27it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3136/8192 [00:06<00:09, 507.21it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3188/8192 [00:06<00:09, 510.81it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3241/8192 [00:06<00:09, 515.80it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3294/8192 [00:06<00:09, 518.52it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3348/8192 [00:06<00:09, 523.38it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3401/8192 [00:06<00:09, 520.99it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3454/8192 [00:06<00:09, 520.79it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3507/8192 [00:06<00:09, 517.74it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3559/8192 [00:06<00:08, 517.96it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3611/8192 [00:07<00:08, 516.25it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3663/8192 [00:07<00:08, 513.13it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3716/8192 [00:07<00:08, 515.91it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3769/8192 [00:07<00:08, 519.19it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3823/8192 [00:07<00:08, 524.27it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3877/8192 [00:07<00:08, 526.89it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3930/8192 [00:07<00:08, 523.04it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3983/8192 [00:07<00:08, 522.46it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4036/8192 [00:07<00:07, 520.15it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4089/8192 [00:07<00:07, 519.98it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4142/8192 [00:08<00:07, 521.30it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4196/8192 [00:08<00:07, 525.18it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4249/8192 [00:08<00:07, 526.06it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4302/8192 [00:08<00:07, 523.82it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4356/8192 [00:08<00:07, 527.37it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4411/8192 [00:08<00:07, 532.09it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4465/8192 [00:08<00:07, 517.70it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4517/8192 [00:08<00:07, 511.76it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4570/8192 [00:08<00:07, 516.43it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4623/8192 [00:08<00:06, 518.54it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4675/8192 [00:09<00:06, 518.87it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4728/8192 [00:09<00:06, 521.42it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4781/8192 [00:09<00:06, 521.92it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4834/8192 [00:09<00:06, 523.56it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4887/8192 [00:09<00:06, 520.63it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4940/8192 [00:09<00:06, 522.22it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4993/8192 [00:09<00:06, 522.11it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5047/8192 [00:09<00:05, 526.30it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5102/8192 [00:09<00:05, 530.75it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5156/8192 [00:09<00:05, 529.39it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5210/8192 [00:10<00:05, 529.74it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5263/8192 [00:10<00:05, 522.20it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5317/8192 [00:10<00:05, 524.81it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5371/8192 [00:10<00:05, 527.06it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5424/8192 [00:10<00:05, 526.28it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5477/8192 [00:10<00:05, 522.39it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5530/8192 [00:10<00:05, 519.31it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5582/8192 [00:10<00:05, 517.64it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5635/8192 [00:10<00:04, 518.73it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5687/8192 [00:11<00:04, 514.65it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5741/8192 [00:11<00:04, 519.39it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5793/8192 [00:11<00:04, 507.72it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5844/8192 [00:11<00:04, 504.63it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5898/8192 [00:11<00:04, 513.80it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5951/8192 [00:11<00:04, 517.60it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6004/8192 [00:11<00:04, 520.12it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6059/8192 [00:11<00:04, 526.97it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6112/8192 [00:11<00:03, 523.83it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6165/8192 [00:11<00:03, 523.35it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6221/8192 [00:12<00:03, 533.50it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6275/8192 [00:12<00:03, 534.30it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6329/8192 [00:12<00:03, 535.30it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6383/8192 [00:12<00:03, 531.84it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6439/8192 [00:12<00:03, 537.54it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6493/8192 [00:12<00:03, 537.26it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6547/8192 [00:12<00:03, 536.85it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6601/8192 [00:12<00:02, 534.10it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6655/8192 [00:12<00:02, 533.54it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6709/8192 [00:12<00:02, 530.35it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6763/8192 [00:13<00:02, 529.87it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6817/8192 [00:13<00:02, 532.20it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6872/8192 [00:13<00:02, 537.44it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6926/8192 [00:13<00:02, 537.64it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6980/8192 [00:13<00:02, 536.16it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7034/8192 [00:13<00:02, 532.12it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7088/8192 [00:13<00:02, 530.27it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7142/8192 [00:13<00:02, 518.10it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7195/8192 [00:13<00:01, 520.28it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7249/8192 [00:13<00:01, 524.62it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7303/8192 [00:14<00:01, 529.07it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7356/8192 [00:14<00:01, 527.85it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7411/8192 [00:14<00:01, 533.60it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7465/8192 [00:14<00:01, 535.42it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7519/8192 [00:14<00:01, 534.16it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7573/8192 [00:14<00:01, 531.02it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7627/8192 [00:14<00:01, 527.08it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7682/8192 [00:14<00:00, 533.71it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7736/8192 [00:14<00:00, 530.33it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7790/8192 [00:14<00:00, 523.01it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7845/8192 [00:15<00:00, 527.77it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7899/8192 [00:15<00:00, 528.67it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7952/8192 [00:15<00:00, 522.09it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8005/8192 [00:15<00:00, 522.73it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8058/8192 [00:15<00:00, 520.58it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8112/8192 [00:15<00:00, 526.10it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8165/8192 [00:15<00:00, 524.52it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:15<00:00, 520.02it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 1502/8192 [00:00<00:01, 3572.35it/s, est. speed input: 3658294.90 toks/s, output: 3572.41 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 1860/8192 [00:03<00:15, 397.04it/s, est. speed input: 518139.14 toks/s, output: 505.99 toks/s]   
Processed prompts:  25%|â–ˆâ–ˆâ–       | 2014/8192 [00:05<00:23, 257.53it/s, est. speed input: 366971.69 toks/s, output: 358.37 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 2102/8192 [00:06<00:25, 236.40it/s, est. speed input: 343326.09 toks/s, output: 335.28 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–‹       | 2161/8192 [00:06<00:29, 207.41it/s, est. speed input: 319744.93 toks/s, output: 312.25 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 2206/8192 [00:07<00:33, 178.13it/s, est. speed input: 299188.64 toks/s, output: 292.17 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 2270/8192 [00:08<00:37, 159.30it/s, est. speed input: 283688.63 toks/s, output: 277.04 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 2334/8192 [00:08<00:40, 144.11it/s, est. speed input: 270475.68 toks/s, output: 264.14 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 2398/8192 [00:09<00:43, 131.84it/s, est. speed input: 258851.44 toks/s, output: 252.78 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 2462/8192 [00:10<00:46, 122.97it/s, est. speed input: 248902.01 toks/s, output: 243.07 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 2526/8192 [00:10<00:48, 115.94it/s, est. speed input: 239947.52 toks/s, output: 234.32 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 2590/8192 [00:11<00:50, 111.21it/s, est. speed input: 232165.24 toks/s, output: 226.72 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 2654/8192 [00:12<00:51, 107.37it/s, est. speed input: 225054.14 toks/s, output: 219.78 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2718/8192 [00:12<00:52, 104.66it/s, est. speed input: 218679.21 toks/s, output: 213.55 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 2782/8192 [00:13<00:52, 102.91it/s, est. speed input: 212981.67 toks/s, output: 207.99 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 2846/8192 [00:14<00:52, 101.37it/s, est. speed input: 207715.39 toks/s, output: 202.85 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2910/8192 [00:14<00:52, 100.39it/s, est. speed input: 202946.12 toks/s, output: 198.19 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 2974/8192 [00:15<00:52, 99.71it/s, est. speed input: 198587.51 toks/s, output: 193.93 toks/s] 
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3038/8192 [00:15<00:51, 99.27it/s, est. speed input: 194593.39 toks/s, output: 190.03 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3102/8192 [00:16<00:51, 99.26it/s, est. speed input: 190989.04 toks/s, output: 186.51 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3166/8192 [00:17<00:50, 98.93it/s, est. speed input: 187575.71 toks/s, output: 183.18 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3230/8192 [00:17<00:50, 98.72it/s, est. speed input: 184416.32 toks/s, output: 180.09 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3294/8192 [00:18<00:49, 98.42it/s, est. speed input: 181444.97 toks/s, output: 177.19 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3358/8192 [00:19<00:49, 98.28it/s, est. speed input: 178690.78 toks/s, output: 174.50 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3422/8192 [00:19<00:48, 98.18it/s, est. speed input: 176115.21 toks/s, output: 171.99 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3486/8192 [00:20<00:47, 98.13it/s, est. speed input: 173708.89 toks/s, output: 169.64 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3550/8192 [00:21<00:47, 98.09it/s, est. speed input: 171449.84 toks/s, output: 167.43 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3614/8192 [00:21<00:46, 98.00it/s, est. speed input: 169313.99 toks/s, output: 165.35 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3678/8192 [00:22<00:46, 97.93it/s, est. speed input: 167302.01 toks/s, output: 163.38 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3742/8192 [00:23<00:45, 98.27it/s, est. speed input: 165464.94 toks/s, output: 161.59 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3806/8192 [00:23<00:44, 98.14it/s, est. speed input: 163671.86 toks/s, output: 159.84 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3870/8192 [00:24<00:44, 98.03it/s, est. speed input: 161971.82 toks/s, output: 158.18 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3934/8192 [00:25<00:43, 98.05it/s, est. speed input: 160373.60 toks/s, output: 156.61 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 3998/8192 [00:25<00:42, 98.36it/s, est. speed input: 158896.65 toks/s, output: 155.17 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4062/8192 [00:26<00:42, 98.25it/s, est. speed input: 157449.11 toks/s, output: 153.76 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4126/8192 [00:27<00:41, 98.10it/s, est. speed input: 156062.70 toks/s, output: 152.40 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4190/8192 [00:27<00:40, 98.34it/s, est. speed input: 154783.66 toks/s, output: 151.16 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4254/8192 [00:28<00:39, 98.60it/s, est. speed input: 153573.75 toks/s, output: 149.97 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4318/8192 [00:29<00:39, 98.77it/s, est. speed input: 152416.25 toks/s, output: 148.84 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4382/8192 [00:29<00:38, 98.45it/s, est. speed input: 151260.41 toks/s, output: 147.72 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4446/8192 [00:30<00:38, 98.28it/s, est. speed input: 150160.03 toks/s, output: 146.64 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4510/8192 [00:30<00:37, 98.11it/s, est. speed input: 149100.16 toks/s, output: 145.61 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4574/8192 [00:31<00:36, 98.02it/s, est. speed input: 148087.78 toks/s, output: 144.62 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4638/8192 [00:32<00:36, 97.97it/s, est. speed input: 147117.24 toks/s, output: 143.67 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4702/8192 [00:32<00:35, 97.86it/s, est. speed input: 146178.10 toks/s, output: 142.75 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4766/8192 [00:33<00:34, 98.17it/s, est. speed input: 145313.58 toks/s, output: 141.91 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4830/8192 [00:34<00:34, 98.44it/s, est. speed input: 144485.22 toks/s, output: 141.10 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4894/8192 [00:34<00:33, 98.26it/s, est. speed input: 143654.92 toks/s, output: 140.29 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4958/8192 [00:35<00:32, 98.30it/s, est. speed input: 142869.70 toks/s, output: 139.52 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5022/8192 [00:36<00:32, 98.13it/s, est. speed input: 142095.46 toks/s, output: 138.76 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5086/8192 [00:36<00:31, 97.97it/s, est. speed input: 141345.31 toks/s, output: 138.03 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5150/8192 [00:37<00:31, 97.84it/s, est. speed input: 140619.74 toks/s, output: 137.32 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5214/8192 [00:38<00:30, 97.73it/s, est. speed input: 139917.96 toks/s, output: 136.64 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5278/8192 [00:38<00:29, 97.61it/s, est. speed input: 139236.25 toks/s, output: 135.97 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5342/8192 [00:39<00:29, 97.58it/s, est. speed input: 138580.87 toks/s, output: 135.33 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5406/8192 [00:40<00:28, 97.66it/s, est. speed input: 137955.24 toks/s, output: 134.72 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5470/8192 [00:40<00:27, 97.56it/s, est. speed input: 137338.12 toks/s, output: 134.12 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5534/8192 [00:41<00:27, 97.87it/s, est. speed input: 136768.05 toks/s, output: 133.56 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5598/8192 [00:42<00:26, 97.78it/s, est. speed input: 136193.85 toks/s, output: 133.00 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5662/8192 [00:42<00:25, 97.64it/s, est. speed input: 135631.90 toks/s, output: 132.45 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5726/8192 [00:43<00:25, 97.65it/s, est. speed input: 135094.01 toks/s, output: 131.93 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5790/8192 [00:44<00:24, 97.45it/s, est. speed input: 134558.31 toks/s, output: 131.40 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5854/8192 [00:44<00:24, 97.38it/s, est. speed input: 134043.18 toks/s, output: 130.90 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5918/8192 [00:45<00:23, 97.36it/s, est. speed input: 133544.72 toks/s, output: 130.41 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5982/8192 [00:46<00:22, 97.35it/s, est. speed input: 133060.61 toks/s, output: 129.94 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6046/8192 [00:46<00:22, 97.36it/s, est. speed input: 132591.19 toks/s, output: 129.48 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6110/8192 [00:47<00:21, 97.37it/s, est. speed input: 132135.14 toks/s, output: 129.04 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6174/8192 [00:48<00:20, 97.38it/s, est. speed input: 131692.18 toks/s, output: 128.61 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6238/8192 [00:48<00:20, 97.35it/s, est. speed input: 131258.53 toks/s, output: 128.18 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6302/8192 [00:49<00:19, 97.31it/s, est. speed input: 130835.16 toks/s, output: 127.77 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6366/8192 [00:49<00:18, 97.33it/s, est. speed input: 130425.91 toks/s, output: 127.37 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6430/8192 [00:50<00:18, 97.29it/s, est. speed input: 130024.44 toks/s, output: 126.98 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6494/8192 [00:51<00:17, 97.23it/s, est. speed input: 129630.89 toks/s, output: 126.59 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6558/8192 [00:51<00:16, 97.62it/s, est. speed input: 129272.11 toks/s, output: 126.24 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6622/8192 [00:52<00:16, 97.86it/s, est. speed input: 128919.98 toks/s, output: 125.90 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6686/8192 [00:53<00:15, 97.65it/s, est. speed input: 128555.88 toks/s, output: 125.54 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6750/8192 [00:53<00:14, 97.51it/s, est. speed input: 128201.42 toks/s, output: 125.20 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6814/8192 [00:54<00:14, 97.45it/s, est. speed input: 127856.94 toks/s, output: 124.86 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6878/8192 [00:55<00:13, 97.35it/s, est. speed input: 127518.31 toks/s, output: 124.53 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6942/8192 [00:55<00:12, 97.30it/s, est. speed input: 127188.09 toks/s, output: 124.21 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7006/8192 [00:56<00:12, 97.22it/s, est. speed input: 126863.84 toks/s, output: 123.89 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7070/8192 [00:57<00:11, 97.16it/s, est. speed input: 126546.50 toks/s, output: 123.58 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7134/8192 [00:57<00:10, 97.55it/s, est. speed input: 126257.44 toks/s, output: 123.30 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7198/8192 [00:58<00:10, 97.39it/s, est. speed input: 125954.26 toks/s, output: 123.00 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7262/8192 [00:59<00:09, 97.66it/s, est. speed input: 125675.90 toks/s, output: 122.73 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7326/8192 [00:59<00:08, 97.57it/s, est. speed input: 125390.31 toks/s, output: 122.45 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7390/8192 [01:00<00:08, 97.72it/s, est. speed input: 125120.83 toks/s, output: 122.19 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7454/8192 [01:01<00:07, 97.62it/s, est. speed input: 124847.97 toks/s, output: 121.92 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7518/8192 [01:01<00:06, 97.36it/s, est. speed input: 124571.96 toks/s, output: 121.65 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7582/8192 [01:02<00:06, 97.27it/s, est. speed input: 124306.24 toks/s, output: 121.39 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7646/8192 [01:03<00:05, 97.21it/s, est. speed input: 124046.07 toks/s, output: 121.14 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7710/8192 [01:03<00:04, 97.20it/s, est. speed input: 123792.71 toks/s, output: 120.89 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7774/8192 [01:04<00:04, 97.20it/s, est. speed input: 123544.75 toks/s, output: 120.65 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7838/8192 [01:05<00:03, 97.16it/s, est. speed input: 123300.10 toks/s, output: 120.41 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7902/8192 [01:05<00:02, 97.14it/s, est. speed input: 123060.91 toks/s, output: 120.18 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7966/8192 [01:06<00:02, 97.14it/s, est. speed input: 122826.63 toks/s, output: 119.95 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8030/8192 [01:07<00:01, 97.08it/s, est. speed input: 122594.77 toks/s, output: 119.72 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8094/8192 [01:07<00:01, 97.58it/s, est. speed input: 122389.67 toks/s, output: 119.52 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8158/8192 [01:08<00:00, 113.42it/s, est. speed input: 122721.96 toks/s, output: 119.85 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [01:08<00:00, 113.42it/s, est. speed input: 123231.32 toks/s, output: 120.34 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [01:08<00:00, 120.34it/s, est. speed input: 123231.32 toks/s, output: 120.34 toks/s]
[rank0]:[W126 09:33:50.771249567 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:03:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:03:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1256353) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1256353) WARNING 01-26 11:04:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.63 requests/s, 16740.05 total tokens/s, 32.63 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:03:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:03:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:03:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:03:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:03:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:03:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:03:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:03:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:03:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:04:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:04:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:04:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:04:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:04:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:04:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1256353) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1256353) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1256353) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.89it/s]
(EngineCore_DP0 pid=1256353) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]
(EngineCore_DP0 pid=1256353) 
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1256353) [2026-01-26 11:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1256353) 2026-01-26 11:04:24,545 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1256353) 2026-01-26 11:04:24,588 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1256353) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]
(EngineCore_DP0 pid=1256353) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.77it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 39/128 [00:00<00:00, 389.93it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [00:00<00:00, 580.05it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 566.60it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<01:20,  1.58it/s, est. speed input: 806.72 toks/s, output: 1.58 toks/s]
Processed prompts:   5%|â–         | 6/128 [00:00<00:12, 10.08it/s, est. speed input: 4063.68 toks/s, output: 7.94 toks/s]
Processed prompts:   9%|â–Š         | 11/128 [00:00<00:06, 17.39it/s, est. speed input: 6420.99 toks/s, output: 12.54 toks/s]
Processed prompts:  12%|â–ˆâ–Ž        | 16/128 [00:00<00:04, 23.39it/s, est. speed input: 8208.54 toks/s, output: 16.03 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:01<00:03, 28.15it/s, est. speed input: 9613.08 toks/s, output: 18.78 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 26/128 [00:01<00:03, 31.83it/s, est. speed input: 10748.44 toks/s, output: 20.99 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 31/128 [00:01<00:02, 34.58it/s, est. speed input: 11682.76 toks/s, output: 22.82 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 36/128 [00:01<00:02, 36.61it/s, est. speed input: 12467.23 toks/s, output: 24.35 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:01<00:02, 38.05it/s, est. speed input: 13130.43 toks/s, output: 25.64 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:02, 39.09it/s, est. speed input: 13701.60 toks/s, output: 26.76 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 51/128 [00:01<00:01, 39.81it/s, est. speed input: 14196.56 toks/s, output: 27.73 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/128 [00:01<00:01, 40.33it/s, est. speed input: 14631.06 toks/s, output: 28.58 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:01, 40.68it/s, est. speed input: 15014.39 toks/s, output: 29.32 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:02<00:01, 40.93it/s, est. speed input: 15356.27 toks/s, output: 29.99 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 71/128 [00:02<00:01, 41.14it/s, est. speed input: 15664.77 toks/s, output: 30.59 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 76/128 [00:02<00:01, 41.29it/s, est. speed input: 15943.09 toks/s, output: 31.14 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:02<00:01, 41.41it/s, est. speed input: 16196.09 toks/s, output: 31.63 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [00:02<00:01, 41.44it/s, est. speed input: 16423.24 toks/s, output: 32.08 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 91/128 [00:02<00:00, 41.50it/s, est. speed input: 16633.26 toks/s, output: 32.49 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 96/128 [00:02<00:00, 41.56it/s, est. speed input: 16826.58 toks/s, output: 32.86 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [00:03<00:00, 41.59it/s, est. speed input: 17004.93 toks/s, output: 33.21 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:03<00:00, 41.62it/s, est. speed input: 17169.40 toks/s, output: 33.53 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [00:03<00:00, 41.64it/s, est. speed input: 17321.85 toks/s, output: 33.83 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 116/128 [00:03<00:00, 41.60it/s, est. speed input: 17461.05 toks/s, output: 34.10 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:03<00:00, 41.02it/s, est. speed input: 17563.63 toks/s, output: 34.30 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:03<00:00, 41.23it/s, est. speed input: 17688.36 toks/s, output: 34.55 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 41.23it/s, est. speed input: 17736.65 toks/s, output: 34.64 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 34.64it/s, est. speed input: 17736.65 toks/s, output: 34.64 toks/s]
[rank0]:[W126 11:04:31.858279574 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:04:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:04:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1257628) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1257628) WARNING 01-26 11:04:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.39 requests/s, 35246.97 total tokens/s, 34.39 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 11:04:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:04:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:04:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:04:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:04:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:04:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:04:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:04:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:04:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:04:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:04:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:04:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:04:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:04:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1257628) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1257628) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1257628) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.88it/s]
(EngineCore_DP0 pid=1257628) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.96it/s]
(EngineCore_DP0 pid=1257628) 
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1257628) [2026-01-26 11:04:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1257628) 2026-01-26 11:05:08,354 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1257628) 2026-01-26 11:05:08,378 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1257628) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.53it/s]
(EngineCore_DP0 pid=1257628) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.71it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  14%|â–ˆâ–        | 18/128 [00:00<00:00, 179.93it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:00<00:00, 301.53it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 95/128 [00:00<00:00, 334.96it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 327.66it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|â–         | 2/128 [00:00<00:07, 17.16it/s, est. speed input: 17575.03 toks/s, output: 17.16 toks/s]
Processed prompts:   5%|â–         | 6/128 [00:00<00:04, 29.61it/s, est. speed input: 28274.13 toks/s, output: 27.61 toks/s]
Processed prompts:   8%|â–Š         | 10/128 [00:00<00:03, 33.90it/s, est. speed input: 32086.28 toks/s, output: 31.33 toks/s]
Processed prompts:  11%|â–ˆ         | 14/128 [00:00<00:03, 35.98it/s, est. speed input: 34051.79 toks/s, output: 33.25 toks/s]
Processed prompts:  14%|â–ˆâ–        | 18/128 [00:00<00:02, 37.16it/s, est. speed input: 35252.92 toks/s, output: 34.42 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 22/128 [00:00<00:02, 37.87it/s, est. speed input: 36060.29 toks/s, output: 35.21 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 26/128 [00:00<00:02, 38.27it/s, est. speed input: 36621.01 toks/s, output: 35.76 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:00<00:02, 38.54it/s, est. speed input: 37045.25 toks/s, output: 36.18 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 34/128 [00:00<00:02, 38.78it/s, est. speed input: 37394.25 toks/s, output: 36.52 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 38/128 [00:01<00:02, 38.93it/s, est. speed input: 37672.58 toks/s, output: 36.79 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:01<00:02, 39.07it/s, est. speed input: 37909.43 toks/s, output: 37.02 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:02, 39.11it/s, est. speed input: 38093.78 toks/s, output: 37.20 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [00:01<00:01, 39.05it/s, est. speed input: 38229.52 toks/s, output: 37.33 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:01<00:01, 39.10it/s, est. speed input: 38365.34 toks/s, output: 37.47 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [00:01<00:01, 39.06it/s, est. speed input: 38467.92 toks/s, output: 37.57 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [00:01<00:01, 39.06it/s, est. speed input: 38562.50 toks/s, output: 37.66 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:01<00:01, 39.05it/s, est. speed input: 38645.08 toks/s, output: 37.74 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [00:01<00:01, 39.06it/s, est. speed input: 38720.17 toks/s, output: 37.81 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [00:01<00:01, 39.06it/s, est. speed input: 38787.28 toks/s, output: 37.88 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:02<00:01, 39.10it/s, est. speed input: 38854.46 toks/s, output: 37.94 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:02<00:01, 39.13it/s, est. speed input: 38915.87 toks/s, output: 38.00 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [00:02<00:01, 39.18it/s, est. speed input: 38974.82 toks/s, output: 38.06 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:02<00:00, 39.19it/s, est. speed input: 39025.31 toks/s, output: 38.11 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [00:02<00:00, 39.21it/s, est. speed input: 39073.90 toks/s, output: 38.16 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [00:02<00:00, 39.25it/s, est. speed input: 39122.10 toks/s, output: 38.20 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:02<00:00, 39.26it/s, est. speed input: 39164.20 toks/s, output: 38.25 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:02<00:00, 39.19it/s, est. speed input: 39194.43 toks/s, output: 38.28 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [00:02<00:00, 39.19it/s, est. speed input: 39227.90 toks/s, output: 38.31 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [00:02<00:00, 39.21it/s, est. speed input: 39260.58 toks/s, output: 38.34 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [00:03<00:00, 39.23it/s, est. speed input: 39292.10 toks/s, output: 38.37 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:03<00:00, 39.21it/s, est. speed input: 39318.46 toks/s, output: 38.40 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:03<00:00, 39.26it/s, est. speed input: 39349.44 toks/s, output: 38.43 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 39.26it/s, est. speed input: 39364.52 toks/s, output: 38.44 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:03<00:00, 38.44it/s, est. speed input: 39364.52 toks/s, output: 38.44 toks/s]
[rank0]:[W126 11:05:14.745741148 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 11:05:16
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:05:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1258754) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1258754) WARNING 01-26 11:05:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 46.28 requests/s, 47438.43 total tokens/s, 46.28 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 11:05:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:05:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:05:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:05:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:05:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:05:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:05:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:05:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:05:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:05:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:05:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:05:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:05:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:05:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:05:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:05:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:05:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1258754) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1258754) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1258754) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.89it/s]
(EngineCore_DP0 pid=1258754) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]
(EngineCore_DP0 pid=1258754) 
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1258754) [2026-01-26 11:05:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1258754) 2026-01-26 11:05:51,736 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1258754) 2026-01-26 11:05:51,759 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1258754) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.09it/s]
(EngineCore_DP0 pid=1258754) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.19it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   7%|â–‹         | 19/256 [00:00<00:01, 185.45it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 59/256 [00:00<00:00, 308.42it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 96/256 [00:00<00:00, 333.99it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/256 [00:00<00:00, 350.69it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 174/256 [00:00<00:00, 366.86it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 214/256 [00:00<00:00, 377.93it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 253/256 [00:00<00:00, 379.06it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 356.39it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|â–ˆâ–        | 30/256 [00:00<00:00, 283.86it/s, est. speed input: 290721.04 toks/s, output: 283.87 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 59/256 [00:00<00:02, 76.18it/s, est. speed input: 87805.74 toks/s, output: 85.75 toks/s]   
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 74/256 [00:01<00:02, 62.62it/s, est. speed input: 73779.88 toks/s, output: 72.05 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 84/256 [00:01<00:02, 58.69it/s, est. speed input: 69655.42 toks/s, output: 68.02 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 92/256 [00:01<00:02, 56.12it/s, est. speed input: 67197.20 toks/s, output: 65.62 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 99/256 [00:01<00:02, 56.12it/s, est. speed input: 66401.25 toks/s, output: 64.84 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 106/256 [00:01<00:02, 52.18it/s, est. speed input: 64093.11 toks/s, output: 62.59 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 112/256 [00:01<00:02, 51.07it/s, est. speed input: 63010.86 toks/s, output: 61.53 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 118/256 [00:01<00:02, 50.05it/s, est. speed input: 62035.02 toks/s, output: 60.58 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 124/256 [00:02<00:02, 49.49it/s, est. speed input: 61249.06 toks/s, output: 59.81 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 130/256 [00:02<00:02, 49.01it/s, est. speed input: 60541.81 toks/s, output: 59.12 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 136/256 [00:02<00:02, 48.68it/s, est. speed input: 59917.37 toks/s, output: 58.51 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 142/256 [00:02<00:02, 48.50it/s, est. speed input: 59371.38 toks/s, output: 57.98 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 148/256 [00:02<00:02, 48.46it/s, est. speed input: 58895.19 toks/s, output: 57.51 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 154/256 [00:02<00:02, 48.21it/s, est. speed input: 58422.57 toks/s, output: 57.05 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 160/256 [00:02<00:02, 47.97it/s, est. speed input: 57979.94 toks/s, output: 56.62 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 166/256 [00:02<00:01, 47.79it/s, est. speed input: 57572.36 toks/s, output: 56.22 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 172/256 [00:03<00:01, 47.70it/s, est. speed input: 57206.57 toks/s, output: 55.87 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 178/256 [00:03<00:01, 47.64it/s, est. speed input: 56868.16 toks/s, output: 55.53 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 184/256 [00:03<00:01, 47.76it/s, est. speed input: 56580.25 toks/s, output: 55.25 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 190/256 [00:03<00:01, 47.83it/s, est. speed input: 56311.47 toks/s, output: 54.99 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 196/256 [00:03<00:01, 47.86it/s, est. speed input: 56058.62 toks/s, output: 54.74 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 202/256 [00:03<00:01, 49.15it/s, est. speed input: 55985.91 toks/s, output: 54.67 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 208/256 [00:03<00:00, 48.73it/s, est. speed input: 55754.40 toks/s, output: 54.45 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 214/256 [00:03<00:00, 48.27it/s, est. speed input: 55516.07 toks/s, output: 54.21 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 220/256 [00:04<00:00, 48.18it/s, est. speed input: 55319.86 toks/s, output: 54.02 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 226/256 [00:04<00:00, 47.93it/s, est. speed input: 55113.60 toks/s, output: 53.82 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 232/256 [00:04<00:00, 47.80it/s, est. speed input: 54924.42 toks/s, output: 53.64 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 238/256 [00:04<00:00, 47.86it/s, est. speed input: 54762.40 toks/s, output: 53.48 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 244/256 [00:04<00:00, 47.93it/s, est. speed input: 54611.71 toks/s, output: 53.33 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 250/256 [00:04<00:00, 47.75it/s, est. speed input: 54445.94 toks/s, output: 53.17 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:04<00:00, 49.71it/s, est. speed input: 54488.44 toks/s, output: 53.21 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:04<00:00, 49.71it/s, est. speed input: 54488.44 toks/s, output: 53.21 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:04<00:00, 53.21it/s, est. speed input: 54488.44 toks/s, output: 53.21 toks/s]
[rank0]:[W126 11:06:00.168787220 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 11:06:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:06:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1259902) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1259902) WARNING 01-26 11:06:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 49.12 requests/s, 50347.01 total tokens/s, 49.12 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 11:06:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:06:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:06:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:06:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:06:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:06:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:06:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:06:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:06:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:06:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:06:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:06:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:06:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:06:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:06:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:06:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:06:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1259902) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1259902) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1259902) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.88it/s]
(EngineCore_DP0 pid=1259902) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.96it/s]
(EngineCore_DP0 pid=1259902) 
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1259902) [2026-01-26 11:06:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1259902) 2026-01-26 11:06:39,926 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1259902) 2026-01-26 11:06:39,949 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1259902) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.21it/s]
(EngineCore_DP0 pid=1259902) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  7.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.25it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|â–         | 20/512 [00:00<00:02, 194.57it/s]
Adding requests:  12%|â–ˆâ–        | 61/512 [00:00<00:01, 316.90it/s]
Adding requests:  19%|â–ˆâ–‰        | 98/512 [00:00<00:01, 337.08it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 136/512 [00:00<00:01, 353.78it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 176/512 [00:00<00:00, 367.61it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/512 [00:00<00:00, 380.75it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/512 [00:00<00:00, 380.95it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 296/512 [00:00<00:00, 385.36it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 337/512 [00:00<00:00, 391.57it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 377/512 [00:01<00:00, 393.67it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/512 [00:01<00:00, 401.04it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 460/512 [00:01<00:00, 397.22it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 503/512 [00:01<00:00, 404.96it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:01<00:00, 380.81it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|â–ˆâ–        | 62/512 [00:00<00:00, 569.79it/s, est. speed input: 583588.59 toks/s, output: 569.83 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 119/512 [00:01<00:04, 83.27it/s, est. speed input: 98404.75 toks/s, output: 96.10 toks/s]  
Processed prompts:  29%|â–ˆâ–ˆâ–Š       | 146/512 [00:01<00:05, 69.17it/s, est. speed input: 83021.40 toks/s, output: 81.07 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 163/512 [00:02<00:05, 65.03it/s, est. speed input: 78550.86 toks/s, output: 76.71 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 176/512 [00:02<00:05, 62.87it/s, est. speed input: 76264.53 toks/s, output: 74.48 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 186/512 [00:02<00:05, 58.08it/s, est. speed input: 73202.86 toks/s, output: 71.49 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 194/512 [00:02<00:05, 56.50it/s, est. speed input: 71873.68 toks/s, output: 70.19 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 202/512 [00:02<00:05, 55.71it/s, est. speed input: 70924.08 toks/s, output: 69.26 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 210/512 [00:03<00:05, 54.32it/s, est. speed input: 69870.24 toks/s, output: 68.23 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 218/512 [00:03<00:05, 53.17it/s, est. speed input: 68923.52 toks/s, output: 67.31 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 226/512 [00:03<00:05, 52.36it/s, est. speed input: 68092.21 toks/s, output: 66.49 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 234/512 [00:03<00:05, 51.75it/s, est. speed input: 67336.75 toks/s, output: 65.76 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 242/512 [00:03<00:05, 51.06it/s, est. speed input: 66602.78 toks/s, output: 65.04 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 250/512 [00:03<00:05, 50.52it/s, est. speed input: 65921.22 toks/s, output: 64.38 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 258/512 [00:04<00:05, 50.16it/s, est. speed input: 65301.74 toks/s, output: 63.77 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/512 [00:04<00:04, 50.11it/s, est. speed input: 64763.48 toks/s, output: 63.24 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 274/512 [00:04<00:04, 50.08it/s, est. speed input: 64266.51 toks/s, output: 62.76 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 282/512 [00:04<00:04, 50.15it/s, est. speed input: 63819.37 toks/s, output: 62.32 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 290/512 [00:04<00:04, 50.08it/s, est. speed input: 63385.03 toks/s, output: 61.90 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 298/512 [00:04<00:04, 49.91it/s, est. speed input: 62962.14 toks/s, output: 61.49 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 306/512 [00:04<00:04, 51.01it/s, est. speed input: 62727.66 toks/s, output: 61.26 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/512 [00:05<00:03, 50.57it/s, est. speed input: 62353.14 toks/s, output: 60.89 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 322/512 [00:05<00:03, 50.29it/s, est. speed input: 62004.48 toks/s, output: 60.55 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 330/512 [00:05<00:03, 50.14it/s, est. speed input: 61680.46 toks/s, output: 60.23 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 338/512 [00:05<00:03, 49.97it/s, est. speed input: 61368.14 toks/s, output: 59.93 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346/512 [00:05<00:03, 49.82it/s, est. speed input: 61069.71 toks/s, output: 59.64 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 354/512 [00:05<00:03, 49.68it/s, est. speed input: 60783.23 toks/s, output: 59.36 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 362/512 [00:06<00:03, 49.64it/s, est. speed input: 60519.13 toks/s, output: 59.10 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/512 [00:06<00:02, 49.79it/s, est. speed input: 60286.15 toks/s, output: 58.87 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 378/512 [00:06<00:02, 49.86it/s, est. speed input: 60061.30 toks/s, output: 58.65 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 386/512 [00:06<00:02, 49.87it/s, est. speed input: 59843.09 toks/s, output: 58.44 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 394/512 [00:06<00:02, 49.83it/s, est. speed input: 59631.84 toks/s, output: 58.23 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 402/512 [00:06<00:02, 49.77it/s, est. speed input: 59426.79 toks/s, output: 58.03 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 410/512 [00:07<00:02, 49.65it/s, est. speed input: 59223.90 toks/s, output: 57.84 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/512 [00:07<00:01, 49.54it/s, est. speed input: 59027.71 toks/s, output: 57.64 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 426/512 [00:07<00:01, 49.55it/s, est. speed input: 58848.17 toks/s, output: 57.47 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 434/512 [00:07<00:01, 50.85it/s, est. speed input: 58782.03 toks/s, output: 57.40 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 442/512 [00:07<00:01, 50.48it/s, est. speed input: 58616.01 toks/s, output: 57.24 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 450/512 [00:07<00:01, 50.17it/s, est. speed input: 58452.32 toks/s, output: 57.08 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 458/512 [00:08<00:01, 50.00it/s, est. speed input: 58298.73 toks/s, output: 56.93 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 466/512 [00:08<00:00, 49.98it/s, est. speed input: 58158.93 toks/s, output: 56.80 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 474/512 [00:08<00:00, 49.93it/s, est. speed input: 58021.34 toks/s, output: 56.66 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482/512 [00:08<00:00, 49.83it/s, est. speed input: 57885.07 toks/s, output: 56.53 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 490/512 [00:08<00:00, 49.74it/s, est. speed input: 57751.87 toks/s, output: 56.40 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 498/512 [00:08<00:00, 49.57it/s, est. speed input: 57616.05 toks/s, output: 56.27 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 506/512 [00:09<00:00, 49.45it/s, est. speed input: 57484.40 toks/s, output: 56.14 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:09<00:00, 49.45it/s, est. speed input: 57759.13 toks/s, output: 56.41 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:09<00:00, 56.40it/s, est. speed input: 57759.13 toks/s, output: 56.41 toks/s]
[rank0]:[W126 11:06:52.985309752 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 11:06:54
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:07:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1261159) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1261159) WARNING 01-26 11:07:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 50.53 requests/s, 51796.96 total tokens/s, 50.53 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 11:07:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:07:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:07:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:07:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:07:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:07:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:07:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:07:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:07:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:07:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:07:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:07:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:07:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:07:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:07:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:07:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:07:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1261159) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1261159) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1261159) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.89it/s]
(EngineCore_DP0 pid=1261159) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]
(EngineCore_DP0 pid=1261159) 
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1261159) [2026-01-26 11:07:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1261159) 2026-01-26 11:07:33,718 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1261159) 2026-01-26 11:07:33,751 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1261159) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00,  5.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.26it/s]
(EngineCore_DP0 pid=1261159) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 19.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.93it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 22/1024 [00:00<00:04, 216.81it/s]
Adding requests:   6%|â–Œ         | 60/1024 [00:00<00:03, 310.39it/s]
Adding requests:   9%|â–‰         | 97/1024 [00:00<00:02, 334.52it/s]
Adding requests:  13%|â–ˆâ–Ž        | 135/1024 [00:00<00:02, 350.72it/s]
Adding requests:  17%|â–ˆâ–‹        | 175/1024 [00:00<00:02, 364.77it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 216/1024 [00:00<00:02, 377.17it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 255/1024 [00:00<00:02, 378.61it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:01, 383.30it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 337/1024 [00:00<00:01, 391.86it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 378/1024 [00:01<00:01, 393.75it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 420/1024 [00:01<00:01, 401.27it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 461/1024 [00:01<00:01, 395.75it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:01<00:01, 403.94it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 546/1024 [00:01<00:01, 408.41it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:01<00:01, 402.28it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 628/1024 [00:01<00:01, 393.75it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 668/1024 [00:01<00:00, 384.39it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 709/1024 [00:01<00:00, 390.54it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 749/1024 [00:01<00:00, 382.93it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 789/1024 [00:02<00:00, 385.97it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 829/1024 [00:02<00:00, 388.78it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:02<00:00, 388.85it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 909/1024 [00:02<00:00, 393.12it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 949/1024 [00:02<00:00, 384.50it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 989/1024 [00:02<00:00, 386.87it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 383.00it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 130/1024 [00:00<00:00, 1270.10it/s, est. speed input: 1300886.64 toks/s, output: 1270.18 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 258/1024 [00:02<00:09, 84.67it/s, est. speed input: 100950.27 toks/s, output: 98.58 toks/s]     
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 314/1024 [00:03<00:09, 72.22it/s, est. speed input: 86795.97 toks/s, output: 84.76 toks/s] 
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 347/1024 [00:04<00:10, 67.49it/s, est. speed input: 81950.91 toks/s, output: 80.03 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 369/1024 [00:04<00:09, 67.73it/s, est. speed input: 81190.13 toks/s, output: 79.29 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 386/1024 [00:05<00:10, 60.25it/s, est. speed input: 77114.49 toks/s, output: 75.31 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:05<00:10, 62.45it/s, est. speed input: 77315.51 toks/s, output: 75.50 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 410/1024 [00:05<00:10, 56.18it/s, est. speed input: 74945.86 toks/s, output: 73.19 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 419/1024 [00:05<00:10, 56.25it/s, est. speed input: 74478.57 toks/s, output: 72.73 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 427/1024 [00:05<00:10, 55.34it/s, est. speed input: 73878.27 toks/s, output: 72.15 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 434/1024 [00:06<00:10, 54.31it/s, est. speed input: 73335.48 toks/s, output: 71.62 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 442/1024 [00:06<00:10, 53.52it/s, est. speed input: 72790.43 toks/s, output: 71.08 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 450/1024 [00:06<00:10, 52.76it/s, est. speed input: 72259.99 toks/s, output: 70.57 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 458/1024 [00:06<00:10, 52.09it/s, est. speed input: 71749.43 toks/s, output: 70.07 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 466/1024 [00:06<00:10, 51.67it/s, est. speed input: 71276.03 toks/s, output: 69.61 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 474/1024 [00:06<00:10, 51.43it/s, est. speed input: 70832.47 toks/s, output: 69.17 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 482/1024 [00:07<00:10, 51.32it/s, est. speed input: 70417.70 toks/s, output: 68.77 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 490/1024 [00:07<00:10, 51.14it/s, est. speed input: 70009.62 toks/s, output: 68.37 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:07<00:10, 50.94it/s, est. speed input: 69612.55 toks/s, output: 67.98 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 506/1024 [00:07<00:10, 50.78it/s, est. speed input: 69230.97 toks/s, output: 67.61 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 514/1024 [00:07<00:10, 50.64it/s, est. speed input: 68862.20 toks/s, output: 67.25 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 522/1024 [00:07<00:09, 50.53it/s, est. speed input: 68507.29 toks/s, output: 66.90 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 530/1024 [00:07<00:09, 50.59it/s, est. speed input: 68179.86 toks/s, output: 66.58 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 538/1024 [00:08<00:09, 50.55it/s, est. speed input: 67856.75 toks/s, output: 66.27 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 546/1024 [00:08<00:09, 50.55it/s, est. speed input: 67549.19 toks/s, output: 65.97 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 554/1024 [00:08<00:09, 50.49it/s, est. speed input: 67247.96 toks/s, output: 65.67 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 562/1024 [00:08<00:09, 50.50it/s, est. speed input: 66962.33 toks/s, output: 65.39 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 570/1024 [00:08<00:08, 50.60it/s, est. speed input: 66693.82 toks/s, output: 65.13 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 578/1024 [00:08<00:08, 50.69it/s, est. speed input: 66436.76 toks/s, output: 64.88 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 586/1024 [00:09<00:08, 50.72it/s, est. speed input: 66186.57 toks/s, output: 64.64 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:09<00:08, 50.56it/s, est. speed input: 65930.70 toks/s, output: 64.39 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 602/1024 [00:09<00:08, 50.47it/s, est. speed input: 65685.67 toks/s, output: 64.15 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 610/1024 [00:09<00:08, 50.38it/s, est. speed input: 65446.56 toks/s, output: 63.91 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 618/1024 [00:09<00:08, 50.40it/s, est. speed input: 65221.26 toks/s, output: 63.69 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 626/1024 [00:09<00:07, 50.48it/s, est. speed input: 65007.62 toks/s, output: 63.48 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 634/1024 [00:10<00:07, 50.48it/s, est. speed input: 64796.97 toks/s, output: 63.28 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 642/1024 [00:10<00:07, 50.47it/s, est. speed input: 64592.51 toks/s, output: 63.08 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 650/1024 [00:10<00:07, 50.39it/s, est. speed input: 64389.26 toks/s, output: 62.88 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 658/1024 [00:10<00:07, 50.30it/s, est. speed input: 64189.58 toks/s, output: 62.68 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 666/1024 [00:10<00:07, 50.26it/s, est. speed input: 63998.33 toks/s, output: 62.50 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 674/1024 [00:10<00:06, 50.40it/s, est. speed input: 63822.03 toks/s, output: 62.33 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:10<00:06, 50.46it/s, est. speed input: 63649.46 toks/s, output: 62.16 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:11<00:06, 50.48it/s, est. speed input: 63479.87 toks/s, output: 61.99 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 698/1024 [00:11<00:06, 50.50it/s, est. speed input: 63315.64 toks/s, output: 61.83 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 706/1024 [00:11<00:06, 50.41it/s, est. speed input: 63149.74 toks/s, output: 61.67 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 714/1024 [00:11<00:06, 50.38it/s, est. speed input: 62990.57 toks/s, output: 61.51 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 722/1024 [00:11<00:05, 50.46it/s, est. speed input: 62840.98 toks/s, output: 61.37 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 730/1024 [00:11<00:05, 50.43it/s, est. speed input: 62691.07 toks/s, output: 61.22 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 738/1024 [00:12<00:05, 50.45it/s, est. speed input: 62547.14 toks/s, output: 61.08 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 746/1024 [00:12<00:05, 50.46it/s, est. speed input: 62406.44 toks/s, output: 60.94 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 754/1024 [00:12<00:05, 50.44it/s, est. speed input: 62268.19 toks/s, output: 60.81 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 762/1024 [00:12<00:05, 50.32it/s, est. speed input: 62127.72 toks/s, output: 60.67 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:12<00:05, 50.45it/s, est. speed input: 62002.14 toks/s, output: 60.55 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 778/1024 [00:12<00:04, 50.34it/s, est. speed input: 61868.99 toks/s, output: 60.42 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:13<00:04, 51.94it/s, est. speed input: 61820.44 toks/s, output: 60.37 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 794/1024 [00:13<00:04, 51.51it/s, est. speed input: 61699.73 toks/s, output: 60.25 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 802/1024 [00:13<00:04, 51.16it/s, est. speed input: 61578.97 toks/s, output: 60.14 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 810/1024 [00:13<00:04, 50.88it/s, est. speed input: 61459.19 toks/s, output: 60.02 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 818/1024 [00:13<00:04, 50.78it/s, est. speed input: 61347.08 toks/s, output: 59.91 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 826/1024 [00:13<00:03, 50.85it/s, est. speed input: 61243.61 toks/s, output: 59.81 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 834/1024 [00:13<00:03, 50.75it/s, est. speed input: 61135.67 toks/s, output: 59.70 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842/1024 [00:14<00:03, 50.83it/s, est. speed input: 61037.05 toks/s, output: 59.61 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 850/1024 [00:14<00:03, 50.73it/s, est. speed input: 60933.68 toks/s, output: 59.51 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:14<00:03, 50.72it/s, est. speed input: 60834.93 toks/s, output: 59.41 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:14<00:03, 50.64it/s, est. speed input: 60735.27 toks/s, output: 59.31 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 874/1024 [00:14<00:02, 50.55it/s, est. speed input: 60636.59 toks/s, output: 59.22 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 882/1024 [00:14<00:02, 50.48it/s, est. speed input: 60539.30 toks/s, output: 59.12 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 890/1024 [00:15<00:02, 50.56it/s, est. speed input: 60449.66 toks/s, output: 59.03 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 898/1024 [00:15<00:02, 50.60it/s, est. speed input: 60361.16 toks/s, output: 58.95 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 906/1024 [00:15<00:02, 50.61it/s, est. speed input: 60273.66 toks/s, output: 58.86 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 914/1024 [00:15<00:02, 50.64it/s, est. speed input: 60189.04 toks/s, output: 58.78 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 922/1024 [00:15<00:02, 50.69it/s, est. speed input: 60107.18 toks/s, output: 58.70 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 930/1024 [00:15<00:01, 50.66it/s, est. speed input: 60024.50 toks/s, output: 58.62 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 938/1024 [00:16<00:01, 50.54it/s, est. speed input: 59939.62 toks/s, output: 58.53 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 946/1024 [00:16<00:01, 50.59it/s, est. speed input: 59861.50 toks/s, output: 58.46 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 954/1024 [00:16<00:01, 50.48it/s, est. speed input: 59779.22 toks/s, output: 58.38 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:16<00:01, 50.53it/s, est. speed input: 59703.58 toks/s, output: 58.30 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:16<00:01, 50.54it/s, est. speed input: 59628.21 toks/s, output: 58.23 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 978/1024 [00:16<00:00, 50.50it/s, est. speed input: 59552.43 toks/s, output: 58.16 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 986/1024 [00:16<00:00, 50.54it/s, est. speed input: 59480.83 toks/s, output: 58.09 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 994/1024 [00:17<00:00, 50.68it/s, est. speed input: 59414.52 toks/s, output: 58.02 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1002/1024 [00:17<00:00, 50.58it/s, est. speed input: 59342.31 toks/s, output: 57.95 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1010/1024 [00:17<00:00, 50.56it/s, est. speed input: 59273.26 toks/s, output: 57.88 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:17<00:00, 52.48it/s, est. speed input: 59270.69 toks/s, output: 57.88 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:17<00:00, 52.48it/s, est. speed input: 59618.75 toks/s, output: 58.22 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:17<00:00, 58.22it/s, est. speed input: 59618.75 toks/s, output: 58.22 toks/s]
[rank0]:[W126 11:07:56.981400208 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 11:07:58
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:08:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1262609) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1262609) WARNING 01-26 11:08:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 51.67 requests/s, 52963.66 total tokens/s, 51.67 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 11:08:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:08:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:08:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:08:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:08:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:08:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:08:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:08:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:08:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:08:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:08:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:08:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:08:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:08:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:08:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:08:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:08:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1262609) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1262609) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1262609) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.89it/s]
(EngineCore_DP0 pid=1262609) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]
(EngineCore_DP0 pid=1262609) 
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1262609) [2026-01-26 11:08:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1262609) [rank0]:W0126 11:08:37.847000 1262609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1262609) [rank0]:W0126 11:08:37.925000 1262609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1262609) [rank0]:W0126 11:08:38.985000 1262609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1262609) [rank0]:W0126 11:08:39.111000 1262609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1262609) 2026-01-26 11:08:43,076 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1262609) 2026-01-26 11:08:43,102 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1262609) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–        | 1/7 [00:00<00:04,  1.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:01,  2.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  9.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.33it/s]
(EngineCore_DP0 pid=1262609) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 19.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.18it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 243.51it/s]
Adding requests:   3%|â–Ž         | 65/2048 [00:00<00:05, 332.01it/s]
Adding requests:   5%|â–         | 101/2048 [00:00<00:05, 342.21it/s]
Adding requests:   7%|â–‹         | 140/2048 [00:00<00:05, 356.91it/s]
Adding requests:   9%|â–Š         | 179/2048 [00:00<00:05, 367.80it/s]
Adding requests:  11%|â–ˆ         | 221/2048 [00:00<00:04, 383.80it/s]
Adding requests:  13%|â–ˆâ–Ž        | 260/2048 [00:00<00:04, 379.77it/s]
Adding requests:  15%|â–ˆâ–        | 301/2048 [00:00<00:04, 385.77it/s]
Adding requests:  17%|â–ˆâ–‹        | 342/2048 [00:00<00:04, 391.69it/s]
Adding requests:  19%|â–ˆâ–Š        | 382/2048 [00:01<00:04, 393.54it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 424/2048 [00:01<00:04, 400.96it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 465/2048 [00:01<00:04, 395.63it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 508/2048 [00:01<00:03, 405.39it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 549/2048 [00:01<00:03, 406.63it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 590/2048 [00:01<00:03, 400.81it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 631/2048 [00:01<00:03, 396.96it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 671/2048 [00:01<00:03, 386.50it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 712/2048 [00:01<00:03, 392.30it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 752/2048 [00:01<00:03, 380.13it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 792/2048 [00:02<00:03, 381.66it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 833/2048 [00:02<00:03, 388.37it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 873/2048 [00:02<00:03, 391.27it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 913/2048 [00:02<00:02, 390.57it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 953/2048 [00:02<00:02, 386.56it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 992/2048 [00:02<00:02, 384.34it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1031/2048 [00:02<00:02, 382.46it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1070/2048 [00:02<00:02, 382.43it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1109/2048 [00:02<00:02, 378.07it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1149/2048 [00:02<00:02, 383.62it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1188/2048 [00:03<00:02, 382.69it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1229/2048 [00:03<00:02, 388.09it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1268/2048 [00:03<00:02, 386.09it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1307/2048 [00:03<00:01, 384.76it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1347/2048 [00:03<00:01, 385.90it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1387/2048 [00:03<00:01, 388.39it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1426/2048 [00:03<00:01, 384.93it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1466/2048 [00:03<00:01, 389.11it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1506/2048 [00:03<00:01, 391.67it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1546/2048 [00:04<00:01, 388.59it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1585/2048 [00:04<00:01, 381.90it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1624/2048 [00:04<00:01, 375.98it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1662/2048 [00:04<00:01, 371.05it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1701/2048 [00:04<00:00, 375.00it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1741/2048 [00:04<00:00, 379.13it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1782/2048 [00:04<00:00, 386.50it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1821/2048 [00:04<00:00, 382.34it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1861/2048 [00:04<00:00, 386.67it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1900/2048 [00:04<00:00, 385.76it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1939/2048 [00:05<00:00, 385.09it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1979/2048 [00:05<00:00, 388.44it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [00:05<00:00, 379.03it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:05<00:00, 383.74it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 274/2048 [00:00<00:02, 814.10it/s, est. speed input: 833694.78 toks/s, output: 814.11 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 356/2048 [00:01<00:10, 154.89it/s, est. speed input: 195082.49 toks/s, output: 190.51 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 393/2048 [00:02<00:13, 123.09it/s, est. speed input: 161692.37 toks/s, output: 157.90 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 416/2048 [00:02<00:14, 113.57it/s, est. speed input: 152115.92 toks/s, output: 148.55 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 433/2048 [00:03<00:16, 100.84it/s, est. speed input: 142501.34 toks/s, output: 139.16 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 446/2048 [00:03<00:18, 88.30it/s, est. speed input: 134252.82 toks/s, output: 131.11 toks/s] 
Processed prompts:  22%|â–ˆâ–ˆâ–       | 456/2048 [00:03<00:21, 74.04it/s, est. speed input: 125799.41 toks/s, output: 122.85 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 466/2048 [00:04<00:25, 62.82it/s, est. speed input: 118602.55 toks/s, output: 115.82 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–Ž       | 482/2048 [00:04<00:26, 59.71it/s, est. speed input: 113887.65 toks/s, output: 111.22 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 498/2048 [00:04<00:26, 57.50it/s, est. speed input: 109846.06 toks/s, output: 107.27 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 514/2048 [00:04<00:27, 55.71it/s, est. speed input: 106241.23 toks/s, output: 103.75 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 530/2048 [00:05<00:27, 54.36it/s, est. speed input: 103036.78 toks/s, output: 100.62 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 546/2048 [00:05<00:28, 53.61it/s, est. speed input: 100265.93 toks/s, output: 97.92 toks/s] 
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 562/2048 [00:05<00:28, 52.93it/s, est. speed input: 97738.93 toks/s, output: 95.45 toks/s] 
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 578/2048 [00:06<00:28, 52.46it/s, est. speed input: 95469.69 toks/s, output: 93.23 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 594/2048 [00:06<00:27, 52.22it/s, est. speed input: 93444.49 toks/s, output: 91.25 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 610/2048 [00:06<00:27, 52.00it/s, est. speed input: 91587.91 toks/s, output: 89.44 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 626/2048 [00:07<00:27, 51.84it/s, est. speed input: 89894.10 toks/s, output: 87.79 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 642/2048 [00:07<00:27, 51.76it/s, est. speed input: 88347.31 toks/s, output: 86.28 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 658/2048 [00:07<00:26, 51.72it/s, est. speed input: 86927.57 toks/s, output: 84.89 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 674/2048 [00:08<00:26, 51.65it/s, est. speed input: 85610.21 toks/s, output: 83.60 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 690/2048 [00:08<00:26, 51.62it/s, est. speed input: 84393.75 toks/s, output: 82.42 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 706/2048 [00:08<00:25, 51.63it/s, est. speed input: 83269.24 toks/s, output: 81.32 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 722/2048 [00:08<00:25, 51.55it/s, est. speed input: 82207.69 toks/s, output: 80.28 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 738/2048 [00:09<00:25, 51.61it/s, est. speed input: 81235.71 toks/s, output: 79.33 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 754/2048 [00:09<00:25, 51.59it/s, est. speed input: 80316.74 toks/s, output: 78.43 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 770/2048 [00:09<00:24, 51.56it/s, est. speed input: 79453.49 toks/s, output: 77.59 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 786/2048 [00:10<00:23, 52.59it/s, est. speed input: 78801.22 toks/s, output: 76.95 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 802/2048 [00:10<00:23, 52.26it/s, est. speed input: 78031.17 toks/s, output: 76.20 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 818/2048 [00:10<00:23, 52.04it/s, est. speed input: 77307.54 toks/s, output: 75.50 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 834/2048 [00:11<00:23, 51.86it/s, est. speed input: 76620.94 toks/s, output: 74.82 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 850/2048 [00:11<00:23, 51.78it/s, est. speed input: 75976.52 toks/s, output: 74.20 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 866/2048 [00:11<00:22, 51.73it/s, est. speed input: 75367.65 toks/s, output: 73.60 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 882/2048 [00:12<00:22, 51.65it/s, est. speed input: 74784.28 toks/s, output: 73.03 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 898/2048 [00:12<00:22, 51.69it/s, est. speed input: 74241.27 toks/s, output: 72.50 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 914/2048 [00:12<00:21, 51.63it/s, est. speed input: 73714.29 toks/s, output: 71.99 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 930/2048 [00:13<00:21, 51.60it/s, est. speed input: 73214.14 toks/s, output: 71.50 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 946/2048 [00:13<00:21, 51.54it/s, est. speed input: 72733.11 toks/s, output: 71.03 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 962/2048 [00:13<00:21, 51.59it/s, est. speed input: 72283.71 toks/s, output: 70.59 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 978/2048 [00:13<00:20, 51.49it/s, est. speed input: 71840.89 toks/s, output: 70.16 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 994/2048 [00:14<00:20, 51.49it/s, est. speed input: 71423.51 toks/s, output: 69.75 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1010/2048 [00:14<00:20, 51.50it/s, est. speed input: 71025.55 toks/s, output: 69.36 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1026/2048 [00:14<00:19, 51.45it/s, est. speed input: 70639.09 toks/s, output: 68.98 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1042/2048 [00:15<00:19, 51.42it/s, est. speed input: 70268.66 toks/s, output: 68.62 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1058/2048 [00:15<00:19, 51.47it/s, est. speed input: 69919.72 toks/s, output: 68.28 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1074/2048 [00:15<00:18, 51.53it/s, est. speed input: 69585.77 toks/s, output: 67.95 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1090/2048 [00:16<00:18, 51.46it/s, est. speed input: 69255.62 toks/s, output: 67.63 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1106/2048 [00:16<00:18, 51.51it/s, est. speed input: 68946.67 toks/s, output: 67.33 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1122/2048 [00:16<00:17, 51.47it/s, est. speed input: 68642.57 toks/s, output: 67.03 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1138/2048 [00:17<00:17, 51.40it/s, est. speed input: 68346.68 toks/s, output: 66.74 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1154/2048 [00:17<00:17, 51.38it/s, est. speed input: 68062.87 toks/s, output: 66.47 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:17<00:17, 51.38it/s, est. speed input: 67790.94 toks/s, output: 66.20 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1186/2048 [00:17<00:16, 51.40it/s, est. speed input: 67529.44 toks/s, output: 65.95 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1202/2048 [00:18<00:16, 52.40it/s, est. speed input: 67348.95 toks/s, output: 65.77 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1218/2048 [00:18<00:15, 52.11it/s, est. speed input: 67103.67 toks/s, output: 65.53 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1234/2048 [00:18<00:15, 52.87it/s, est. speed input: 66932.48 toks/s, output: 65.36 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1250/2048 [00:19<00:15, 52.43it/s, est. speed input: 66701.22 toks/s, output: 65.14 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1266/2048 [00:19<00:15, 52.09it/s, est. speed input: 66474.96 toks/s, output: 64.92 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1282/2048 [00:19<00:14, 51.77it/s, est. speed input: 66250.35 toks/s, output: 64.70 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1298/2048 [00:20<00:14, 51.72it/s, est. speed input: 66043.55 toks/s, output: 64.50 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1314/2048 [00:20<00:14, 51.60it/s, est. speed input: 65838.00 toks/s, output: 64.29 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1330/2048 [00:20<00:13, 52.49it/s, est. speed input: 65699.00 toks/s, output: 64.16 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1346/2048 [00:21<00:13, 52.12it/s, est. speed input: 65503.44 toks/s, output: 63.97 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1362/2048 [00:21<00:13, 51.91it/s, est. speed input: 65316.56 toks/s, output: 63.79 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1378/2048 [00:21<00:12, 51.72it/s, est. speed input: 65131.89 toks/s, output: 63.61 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1394/2048 [00:21<00:12, 51.62it/s, est. speed input: 64954.58 toks/s, output: 63.43 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1410/2048 [00:22<00:12, 51.61it/s, est. speed input: 64785.75 toks/s, output: 63.27 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1426/2048 [00:22<00:12, 51.50it/s, est. speed input: 64615.46 toks/s, output: 63.10 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1442/2048 [00:22<00:11, 51.44it/s, est. speed input: 64451.24 toks/s, output: 62.94 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1458/2048 [00:23<00:11, 52.42it/s, est. speed input: 64347.23 toks/s, output: 62.84 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1474/2048 [00:23<00:11, 52.09it/s, est. speed input: 64191.28 toks/s, output: 62.69 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1490/2048 [00:23<00:10, 51.85it/s, est. speed input: 64038.36 toks/s, output: 62.54 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1506/2048 [00:24<00:10, 51.69it/s, est. speed input: 63889.84 toks/s, output: 62.39 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1522/2048 [00:24<00:09, 52.61it/s, est. speed input: 63798.26 toks/s, output: 62.30 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1538/2048 [00:24<00:09, 52.13it/s, est. speed input: 63652.41 toks/s, output: 62.16 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1554/2048 [00:25<00:09, 52.85it/s, est. speed input: 63561.98 toks/s, output: 62.07 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1570/2048 [00:25<00:09, 52.43it/s, est. speed input: 63428.58 toks/s, output: 61.94 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1586/2048 [00:25<00:08, 51.99it/s, est. speed input: 63291.52 toks/s, output: 61.81 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1602/2048 [00:25<00:08, 51.77it/s, est. speed input: 63161.97 toks/s, output: 61.68 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1618/2048 [00:26<00:08, 52.65it/s, est. speed input: 63083.86 toks/s, output: 61.61 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1634/2048 [00:26<00:07, 52.16it/s, est. speed input: 62956.34 toks/s, output: 61.48 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1650/2048 [00:26<00:07, 51.93it/s, est. speed input: 62836.76 toks/s, output: 61.36 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1666/2048 [00:27<00:07, 51.70it/s, est. speed input: 62716.86 toks/s, output: 61.25 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1682/2048 [00:27<00:07, 51.51it/s, est. speed input: 62598.11 toks/s, output: 61.13 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1698/2048 [00:27<00:06, 51.43it/s, est. speed input: 62484.79 toks/s, output: 61.02 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1714/2048 [00:28<00:06, 51.34it/s, est. speed input: 62372.09 toks/s, output: 60.91 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1730/2048 [00:28<00:06, 52.31it/s, est. speed input: 62307.05 toks/s, output: 60.85 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1746/2048 [00:28<00:05, 52.95it/s, est. speed input: 62240.56 toks/s, output: 60.78 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1762/2048 [00:29<00:05, 52.41it/s, est. speed input: 62134.99 toks/s, output: 60.68 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1778/2048 [00:29<00:05, 52.09it/s, est. speed input: 62033.57 toks/s, output: 60.58 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1794/2048 [00:29<00:04, 51.77it/s, est. speed input: 61930.49 toks/s, output: 60.48 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1810/2048 [00:29<00:04, 51.54it/s, est. speed input: 61828.97 toks/s, output: 60.38 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1826/2048 [00:30<00:04, 51.51it/s, est. speed input: 61734.92 toks/s, output: 60.29 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1842/2048 [00:30<00:04, 51.36it/s, est. speed input: 61637.67 toks/s, output: 60.19 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1858/2048 [00:30<00:03, 51.26it/s, est. speed input: 61542.40 toks/s, output: 60.10 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1874/2048 [00:31<00:03, 51.27it/s, est. speed input: 61452.48 toks/s, output: 60.01 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1890/2048 [00:31<00:03, 52.21it/s, est. speed input: 61400.21 toks/s, output: 59.96 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1906/2048 [00:31<00:02, 51.89it/s, est. speed input: 61311.67 toks/s, output: 59.87 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1922/2048 [00:32<00:02, 51.68it/s, est. speed input: 61225.42 toks/s, output: 59.79 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1938/2048 [00:32<00:02, 51.51it/s, est. speed input: 61139.80 toks/s, output: 59.71 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1954/2048 [00:32<00:01, 51.41it/s, est. speed input: 61056.34 toks/s, output: 59.63 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1970/2048 [00:33<00:01, 51.28it/s, est. speed input: 60972.34 toks/s, output: 59.54 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1986/2048 [00:33<00:01, 52.30it/s, est. speed input: 60930.17 toks/s, output: 59.50 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2002/2048 [00:33<00:00, 51.99it/s, est. speed input: 60852.21 toks/s, output: 59.43 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [00:34<00:00, 51.67it/s, est. speed input: 60772.01 toks/s, output: 59.35 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2034/2048 [00:34<00:00, 52.58it/s, est. speed input: 60732.76 toks/s, output: 59.31 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:34<00:00, 52.58it/s, est. speed input: 61149.71 toks/s, output: 59.72 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:34<00:00, 59.72it/s, est. speed input: 61149.71 toks/s, output: 59.72 toks/s]
[rank0]:[W126 11:09:25.952147331 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 11:09:28
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:09:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1264432) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1264432) WARNING 01-26 11:10:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 52.35 requests/s, 53656.89 total tokens/s, 52.35 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 11:09:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:09:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:09:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:09:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:09:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:09:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:09:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:09:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:09:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:10:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:10:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:10:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:10:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:10:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:10:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:10:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:10:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:10:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1264432) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1264432) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=1264432) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.90it/s]
(EngineCore_DP0 pid=1264432) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.98it/s]
(EngineCore_DP0 pid=1264432) 
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1264432) [2026-01-26 11:10:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1264432) [rank0]:W0126 11:10:18.885000 1264432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1264432) [rank0]:W0126 11:10:18.961000 1264432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1264432) [rank0]:W0126 11:10:19.867000 1264432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1264432) [rank0]:W0126 11:10:19.988000 1264432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1264432) 2026-01-26 11:10:23,968 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1264432) 2026-01-26 11:10:23,995 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1264432) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 1/11 [00:00<00:05,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 2/11 [00:00<00:02,  3.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 3/11 [00:01<00:02,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [00:01<00:01,  5.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:01<00:00,  5.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:01<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00, 10.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.62it/s]
(EngineCore_DP0 pid=1264432) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 1/7 [00:00<00:00,  7.14it/s]
Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00, 12.04it/s]
Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:00<00:00, 11.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.60it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/4096 [00:00<00:17, 228.02it/s]
Adding requests:   2%|â–         | 63/4096 [00:00<00:12, 326.90it/s]
Adding requests:   2%|â–         | 99/4096 [00:00<00:11, 337.53it/s]
Adding requests:   3%|â–Ž         | 137/4096 [00:00<00:11, 351.16it/s]
Adding requests:   4%|â–         | 176/4096 [00:00<00:10, 363.82it/s]
Adding requests:   5%|â–Œ         | 216/4096 [00:00<00:10, 375.06it/s]
Adding requests:   6%|â–Œ         | 254/4096 [00:00<00:10, 376.03it/s]
Adding requests:   7%|â–‹         | 293/4096 [00:00<00:10, 379.60it/s]
Adding requests:   8%|â–Š         | 334/4096 [00:00<00:09, 387.29it/s]
Adding requests:   9%|â–‰         | 374/4096 [00:01<00:09, 390.62it/s]
Adding requests:  10%|â–ˆ         | 415/4096 [00:01<00:09, 395.77it/s]
Adding requests:  11%|â–ˆ         | 455/4096 [00:01<00:09, 393.32it/s]
Adding requests:  12%|â–ˆâ–        | 498/4096 [00:01<00:08, 401.56it/s]
Adding requests:  13%|â–ˆâ–Ž        | 540/4096 [00:01<00:08, 406.03it/s]
Adding requests:  14%|â–ˆâ–        | 581/4096 [00:01<00:08, 401.87it/s]
Adding requests:  15%|â–ˆâ–Œ        | 622/4096 [00:01<00:08, 394.93it/s]
Adding requests:  16%|â–ˆâ–Œ        | 662/4096 [00:01<00:08, 386.97it/s]
Adding requests:  17%|â–ˆâ–‹        | 702/4096 [00:01<00:08, 388.58it/s]
Adding requests:  18%|â–ˆâ–Š        | 741/4096 [00:01<00:08, 383.77it/s]
Adding requests:  19%|â–ˆâ–‰        | 780/4096 [00:02<00:08, 384.00it/s]
Adding requests:  20%|â–ˆâ–‰        | 819/4096 [00:02<00:08, 382.54it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 860/4096 [00:02<00:08, 390.20it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 900/4096 [00:02<00:08, 391.23it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 940/4096 [00:02<00:08, 384.93it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 979/4096 [00:02<00:08, 384.73it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 1018/4096 [00:02<00:08, 379.36it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 1056/4096 [00:02<00:08, 377.21it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 1094/4096 [00:02<00:08, 369.37it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 1134/4096 [00:02<00:07, 375.78it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 1172/4096 [00:03<00:07, 372.79it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 1212/4096 [00:03<00:07, 378.96it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 1252/4096 [00:03<00:07, 382.50it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 1291/4096 [00:03<00:07, 375.72it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 1331/4096 [00:03<00:07, 379.93it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1371/4096 [00:03<00:07, 385.16it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 1410/4096 [00:03<00:07, 382.28it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1449/4096 [00:03<00:06, 381.32it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1490/4096 [00:03<00:06, 387.50it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1530/4096 [00:04<00:06, 388.24it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1569/4096 [00:04<00:06, 381.88it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1608/4096 [00:04<00:06, 380.02it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1647/4096 [00:04<00:06, 371.27it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1685/4096 [00:04<00:06, 371.35it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1724/4096 [00:04<00:06, 375.27it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1764/4096 [00:04<00:06, 381.50it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1803/4096 [00:04<00:05, 382.78it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1842/4096 [00:04<00:05, 382.44it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1881/4096 [00:04<00:05, 384.01it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1921/4096 [00:05<00:05, 388.18it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1962/4096 [00:05<00:05, 391.06it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2002/4096 [00:05<00:05, 384.73it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2041/4096 [00:05<00:05, 379.38it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2079/4096 [00:05<00:05, 371.16it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2119/4096 [00:05<00:05, 378.59it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2157/4096 [00:05<00:05, 376.71it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2195/4096 [00:05<00:05, 371.41it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2233/4096 [00:05<00:04, 373.29it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2273/4096 [00:05<00:04, 380.99it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2312/4096 [00:06<00:04, 371.41it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2353/4096 [00:06<00:04, 382.12it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2394/4096 [00:06<00:04, 387.27it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2434/4096 [00:06<00:04, 390.10it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2474/4096 [00:06<00:04, 390.55it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2515/4096 [00:06<00:04, 393.49it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2557/4096 [00:06<00:03, 400.20it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2599/4096 [00:06<00:03, 405.07it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2640/4096 [00:06<00:03, 389.62it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2680/4096 [00:07<00:03, 389.49it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2720/4096 [00:07<00:03, 386.32it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2761/4096 [00:07<00:03, 390.89it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2804/4096 [00:07<00:03, 398.89it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2844/4096 [00:07<00:03, 396.17it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2884/4096 [00:07<00:03, 391.86it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2924/4096 [00:07<00:02, 393.04it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2965/4096 [00:07<00:02, 396.96it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3006/4096 [00:07<00:02, 398.11it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3047/4096 [00:07<00:02, 399.60it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3088/4096 [00:08<00:02, 400.30it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3130/4096 [00:08<00:02, 403.03it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3171/4096 [00:08<00:02, 396.48it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3211/4096 [00:08<00:02, 392.80it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3253/4096 [00:08<00:02, 399.61it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3293/4096 [00:08<00:02, 384.06it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3332/4096 [00:08<00:02, 379.76it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3374/4096 [00:08<00:01, 388.66it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3414/4096 [00:08<00:01, 390.60it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3454/4096 [00:08<00:01, 390.36it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3494/4096 [00:09<00:01, 388.10it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3537/4096 [00:09<00:01, 400.00it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3578/4096 [00:09<00:01, 397.32it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3618/4096 [00:09<00:01, 396.47it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3658/4096 [00:09<00:01, 381.23it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3697/4096 [00:09<00:01, 376.71it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3737/4096 [00:09<00:00, 383.39it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3776/4096 [00:09<00:00, 374.30it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3814/4096 [00:09<00:00, 365.99it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3853/4096 [00:10<00:00, 371.85it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3892/4096 [00:10<00:00, 374.48it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3930/4096 [00:10<00:00, 370.67it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3969/4096 [00:10<00:00, 374.19it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4007/4096 [00:10<00:00, 374.68it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4045/4096 [00:10<00:00, 373.83it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4083/4096 [00:10<00:00, 374.40it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:10<00:00, 383.46it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 546/4096 [00:00<00:03, 984.74it/s, est. speed input: 1008412.92 toks/s, output: 984.75 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 645/4096 [00:02<00:15, 217.69it/s, est. speed input: 277885.53 toks/s, output: 271.37 toks/s] 
Processed prompts:  17%|â–ˆâ–‹        | 689/4096 [00:02<00:19, 176.39it/s, est. speed input: 236077.52 toks/s, output: 230.54 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 717/4096 [00:03<00:24, 139.08it/s, est. speed input: 204209.72 toks/s, output: 199.42 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 738/4096 [00:04<00:30, 108.61it/s, est. speed input: 179734.38 toks/s, output: 175.52 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 770/4096 [00:04<00:35, 93.00it/s, est. speed input: 164459.20 toks/s, output: 160.60 toks/s] 
Processed prompts:  20%|â–ˆâ–‰        | 802/4096 [00:05<00:40, 81.03it/s, est. speed input: 152035.51 toks/s, output: 148.47 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 834/4096 [00:06<00:45, 72.40it/s, est. speed input: 141992.31 toks/s, output: 138.66 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 866/4096 [00:06<00:48, 66.57it/s, est. speed input: 133943.33 toks/s, output: 130.80 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 898/4096 [00:07<00:51, 62.30it/s, est. speed input: 127149.83 toks/s, output: 124.17 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 930/4096 [00:07<00:53, 59.36it/s, est. speed input: 121446.17 toks/s, output: 118.60 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 962/4096 [00:08<00:54, 57.30it/s, est. speed input: 116560.58 toks/s, output: 113.83 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 994/4096 [00:09<00:55, 55.85it/s, est. speed input: 112328.84 toks/s, output: 109.70 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 1026/4096 [00:09<00:56, 54.81it/s, est. speed input: 108621.58 toks/s, output: 106.08 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 1058/4096 [00:10<00:56, 54.12it/s, est. speed input: 105370.53 toks/s, output: 102.90 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 1090/4096 [00:10<00:56, 53.58it/s, est. speed input: 102464.00 toks/s, output: 100.06 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 1122/4096 [00:11<00:55, 53.30it/s, est. speed input: 99897.66 toks/s, output: 97.56 toks/s]  
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 1154/4096 [00:12<00:55, 52.94it/s, est. speed input: 97538.24 toks/s, output: 95.25 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 1186/4096 [00:12<00:54, 53.35it/s, est. speed input: 95596.88 toks/s, output: 93.36 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 1218/4096 [00:13<00:53, 53.55it/s, est. speed input: 93802.89 toks/s, output: 91.60 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 1250/4096 [00:13<00:53, 53.19it/s, est. speed input: 92036.22 toks/s, output: 89.88 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 1282/4096 [00:14<00:53, 52.95it/s, est. speed input: 90421.41 toks/s, output: 88.30 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 1314/4096 [00:15<00:52, 53.17it/s, est. speed input: 89024.08 toks/s, output: 86.94 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1346/4096 [00:15<00:51, 52.99it/s, est. speed input: 87662.76 toks/s, output: 85.61 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1378/4096 [00:16<00:51, 52.73it/s, est. speed input: 86373.82 toks/s, output: 84.35 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 1410/4096 [00:16<00:51, 52.65it/s, est. speed input: 85199.21 toks/s, output: 83.20 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1442/4096 [00:17<00:50, 53.05it/s, est. speed input: 84189.69 toks/s, output: 82.22 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1474/4096 [00:18<00:49, 52.80it/s, est. speed input: 83152.02 toks/s, output: 81.20 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1506/4096 [00:18<00:48, 53.24it/s, est. speed input: 82285.22 toks/s, output: 80.36 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1538/4096 [00:19<00:47, 53.41it/s, est. speed input: 81449.97 toks/s, output: 79.54 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1570/4096 [00:19<00:47, 53.08it/s, est. speed input: 80595.72 toks/s, output: 78.71 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1602/4096 [00:20<00:46, 53.37it/s, est. speed input: 79868.42 toks/s, output: 78.00 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1634/4096 [00:21<00:46, 53.01it/s, est. speed input: 79102.48 toks/s, output: 77.25 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1666/4096 [00:21<00:45, 52.83it/s, est. speed input: 78389.05 toks/s, output: 76.55 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1698/4096 [00:22<00:45, 52.66it/s, est. speed input: 77708.12 toks/s, output: 75.89 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1730/4096 [00:22<00:44, 53.63it/s, est. speed input: 77202.12 toks/s, output: 75.39 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1762/4096 [00:23<00:43, 53.21it/s, est. speed input: 76586.18 toks/s, output: 74.79 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1794/4096 [00:24<00:43, 52.85it/s, est. speed input: 75993.55 toks/s, output: 74.21 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1826/4096 [00:24<00:43, 52.75it/s, est. speed input: 75447.04 toks/s, output: 73.68 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1858/4096 [00:25<00:42, 52.54it/s, est. speed input: 74911.03 toks/s, output: 73.16 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1890/4096 [00:25<00:41, 52.89it/s, est. speed input: 74455.62 toks/s, output: 72.71 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1922/4096 [00:26<00:41, 52.71it/s, est. speed input: 73974.09 toks/s, output: 72.24 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1954/4096 [00:27<00:40, 52.55it/s, est. speed input: 73511.94 toks/s, output: 71.79 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1986/4096 [00:27<00:39, 52.90it/s, est. speed input: 73115.43 toks/s, output: 71.40 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2018/4096 [00:28<00:39, 52.66it/s, est. speed input: 72689.17 toks/s, output: 70.99 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2050/4096 [00:29<00:38, 53.01it/s, est. speed input: 72329.90 toks/s, output: 70.63 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2082/4096 [00:29<00:38, 52.75it/s, est. speed input: 71937.43 toks/s, output: 70.25 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2114/4096 [00:30<00:37, 52.56it/s, est. speed input: 71560.92 toks/s, output: 69.88 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2146/4096 [00:30<00:37, 52.43it/s, est. speed input: 71199.04 toks/s, output: 69.53 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2178/4096 [00:31<00:36, 52.85it/s, est. speed input: 70895.97 toks/s, output: 69.23 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2210/4096 [00:32<00:35, 52.58it/s, est. speed input: 70556.11 toks/s, output: 68.90 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2242/4096 [00:32<00:35, 52.46it/s, est. speed input: 70235.11 toks/s, output: 68.59 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2274/4096 [00:33<00:34, 52.36it/s, est. speed input: 69924.35 toks/s, output: 68.29 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2306/4096 [00:33<00:34, 52.25it/s, est. speed input: 69621.81 toks/s, output: 67.99 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2338/4096 [00:34<00:33, 52.21it/s, est. speed input: 69332.66 toks/s, output: 67.71 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2370/4096 [00:35<00:33, 52.19it/s, est. speed input: 69054.27 toks/s, output: 67.44 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2402/4096 [00:35<00:32, 52.13it/s, est. speed input: 68782.26 toks/s, output: 67.17 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2434/4096 [00:36<00:31, 52.09it/s, est. speed input: 68519.20 toks/s, output: 66.91 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2466/4096 [00:36<00:31, 52.06it/s, est. speed input: 68265.35 toks/s, output: 66.67 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2498/4096 [00:37<00:30, 52.03it/s, est. speed input: 68018.85 toks/s, output: 66.42 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2530/4096 [00:38<00:29, 52.62it/s, est. speed input: 67822.49 toks/s, output: 66.23 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2562/4096 [00:38<00:29, 52.35it/s, est. speed input: 67585.52 toks/s, output: 66.00 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2594/4096 [00:39<00:28, 52.72it/s, est. speed input: 67393.19 toks/s, output: 65.81 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2626/4096 [00:40<00:27, 52.55it/s, est. speed input: 67179.13 toks/s, output: 65.60 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2658/4096 [00:40<00:27, 52.91it/s, est. speed input: 67001.30 toks/s, output: 65.43 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2690/4096 [00:41<00:26, 52.68it/s, est. speed input: 66799.09 toks/s, output: 65.23 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2722/4096 [00:41<00:25, 52.90it/s, est. speed input: 66625.57 toks/s, output: 65.06 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2754/4096 [00:42<00:25, 52.59it/s, est. speed input: 66429.38 toks/s, output: 64.87 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2786/4096 [00:43<00:24, 52.47it/s, est. speed input: 66244.94 toks/s, output: 64.69 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2818/4096 [00:43<00:24, 52.30it/s, est. speed input: 66060.13 toks/s, output: 64.51 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2850/4096 [00:44<00:23, 52.22it/s, est. speed input: 65882.75 toks/s, output: 64.34 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2882/4096 [00:44<00:22, 53.07it/s, est. speed input: 65761.48 toks/s, output: 64.22 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2914/4096 [00:45<00:22, 53.17it/s, est. speed input: 65615.34 toks/s, output: 64.08 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2946/4096 [00:46<00:21, 52.81it/s, est. speed input: 65449.93 toks/s, output: 63.92 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2978/4096 [00:46<00:21, 52.55it/s, est. speed input: 65288.53 toks/s, output: 63.76 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3010/4096 [00:47<00:20, 52.40it/s, est. speed input: 65132.93 toks/s, output: 63.61 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3042/4096 [00:47<00:20, 52.25it/s, est. speed input: 64978.88 toks/s, output: 63.46 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3074/4096 [00:48<00:19, 52.08it/s, est. speed input: 64825.11 toks/s, output: 63.31 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3106/4096 [00:49<00:19, 52.02it/s, est. speed input: 64678.39 toks/s, output: 63.16 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3138/4096 [00:49<00:18, 51.96it/s, est. speed input: 64534.63 toks/s, output: 63.02 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3170/4096 [00:50<00:17, 51.97it/s, est. speed input: 64396.68 toks/s, output: 62.89 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3202/4096 [00:51<00:17, 52.01it/s, est. speed input: 64263.47 toks/s, output: 62.76 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3234/4096 [00:51<00:16, 51.92it/s, est. speed input: 64127.93 toks/s, output: 62.62 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3266/4096 [00:52<00:15, 51.91it/s, est. speed input: 63998.30 toks/s, output: 62.50 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3298/4096 [00:52<00:15, 51.86it/s, est. speed input: 63869.63 toks/s, output: 62.37 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3330/4096 [00:53<00:14, 51.80it/s, est. speed input: 63742.56 toks/s, output: 62.25 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3362/4096 [00:54<00:14, 51.84it/s, est. speed input: 63622.36 toks/s, output: 62.13 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3394/4096 [00:54<00:13, 51.87it/s, est. speed input: 63504.66 toks/s, output: 62.02 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3426/4096 [00:55<00:12, 51.87it/s, est. speed input: 63389.12 toks/s, output: 61.90 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3458/4096 [00:55<00:12, 51.87it/s, est. speed input: 63275.75 toks/s, output: 61.79 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3490/4096 [00:56<00:11, 51.81it/s, est. speed input: 63162.41 toks/s, output: 61.68 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3522/4096 [00:57<00:11, 51.80it/s, est. speed input: 63052.75 toks/s, output: 61.57 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3554/4096 [00:57<00:10, 52.26it/s, est. speed input: 62965.73 toks/s, output: 61.49 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3586/4096 [00:58<00:09, 52.08it/s, est. speed input: 62858.90 toks/s, output: 61.39 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3618/4096 [00:59<00:09, 51.98it/s, est. speed input: 62755.65 toks/s, output: 61.28 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3650/4096 [00:59<00:08, 51.86it/s, est. speed input: 62652.09 toks/s, output: 61.18 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3682/4096 [01:00<00:07, 52.32it/s, est. speed input: 62573.05 toks/s, output: 61.11 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3714/4096 [01:00<00:07, 52.12it/s, est. speed input: 62474.90 toks/s, output: 61.01 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3746/4096 [01:01<00:06, 52.01it/s, est. speed input: 62379.64 toks/s, output: 60.92 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3778/4096 [01:02<00:06, 52.00it/s, est. speed input: 62288.90 toks/s, output: 60.83 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3810/4096 [01:02<00:05, 51.93it/s, est. speed input: 62197.44 toks/s, output: 60.74 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3842/4096 [01:03<00:04, 51.91it/s, est. speed input: 62108.78 toks/s, output: 60.65 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3874/4096 [01:03<00:04, 51.86it/s, est. speed input: 62020.77 toks/s, output: 60.57 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3906/4096 [01:04<00:03, 52.37it/s, est. speed input: 61954.58 toks/s, output: 60.50 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3938/4096 [01:05<00:03, 52.63it/s, est. speed input: 61886.13 toks/s, output: 60.44 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3970/4096 [01:05<00:02, 52.32it/s, est. speed input: 61800.76 toks/s, output: 60.35 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4002/4096 [01:06<00:01, 52.66it/s, est. speed input: 61737.32 toks/s, output: 60.29 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4034/4096 [01:06<00:01, 52.80it/s, est. speed input: 61671.46 toks/s, output: 60.23 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4066/4096 [01:07<00:00, 53.55it/s, est. speed input: 61628.93 toks/s, output: 60.18 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [01:07<00:00, 53.55it/s, est. speed input: 62082.74 toks/s, output: 60.63 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [01:07<00:00, 60.63it/s, est. speed input: 62082.74 toks/s, output: 60.63 toks/s]
[rank0]:[W126 11:11:46.601725945 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 11:11:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:12:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1267043) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1267043) WARNING 01-26 11:12:57 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     def forward(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     raise e
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/tmp/torchinductor_root/kh/ckhj7zmb322mko3v5rzl4ng6llpwtacrpf3ftoyspbamrbf3bcif.py", line 1090, in call
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1267043) ERROR 01-26 11:13:05 [core.py:866] 

STDERR:
[2026-01-26 11:12:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:12:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:12:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:12:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:12:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:12:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:12:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:12:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:12:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:12:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:12:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:12:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:12:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:12:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:12:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:12:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:12:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1267043) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1267043) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1267043) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.88it/s]
(EngineCore_DP0 pid=1267043) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.96it/s]
(EngineCore_DP0 pid=1267043) 
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10321920 bytes
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 8028160 bytes
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 84869120 bytes
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1267043) [2026-01-26 11:12:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42434560 bytes
(EngineCore_DP0 pid=1267043) [rank0]:W0126 11:13:02.936000 1267043 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1267043) [rank0]:W0126 11:13:03.016000 1267043 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1267043) [rank0]:W0126 11:13:04.459000 1267043 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1267043) [rank0]:W0126 11:13:04.583000 1267043 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1267043) Process EngineCore_DP0:
(EngineCore_DP0 pid=1267043) Traceback (most recent call last):
(EngineCore_DP0 pid=1267043)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1267043)     self.run()
(EngineCore_DP0 pid=1267043)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1267043)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1267043)     raise e
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1267043)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1267043)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1267043)     super().__init__(
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1267043)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1267043)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1267043)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1267043)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1267043)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1267043)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1267043)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1267043)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1267043)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1267043)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1267043)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1267043)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1267043)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1267043)     outputs = self.model(
(EngineCore_DP0 pid=1267043)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1267043)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1267043)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1267043)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1267043)     hidden_states = self.model(
(EngineCore_DP0 pid=1267043)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1267043)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1267043)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1267043)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1267043)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1267043)     def forward(
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1267043)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1267043)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1267043)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1267043)     raise e
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1267043)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1267043)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1267043)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1267043)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1267043)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1267043)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1267043)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1267043)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1267043)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1267043)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1267043)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1267043)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1267043)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1267043)                             ^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1267043)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1267043)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1267043)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1267043)     out = model(new_inputs)
(EngineCore_DP0 pid=1267043)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/tmp/torchinductor_root/kh/ckhj7zmb322mko3v5rzl4ng6llpwtacrpf3ftoyspbamrbf3bcif.py", line 1090, in call
(EngineCore_DP0 pid=1267043)     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=1267043)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=1267043)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=1267043)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=1267043)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=1267043)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=1267043)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=1267043)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=1267043)     torch.cuda.synchronize()
(EngineCore_DP0 pid=1267043)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=1267043)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=1267043)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1267043) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1267043) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1267043) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1267043) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1267043) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1267043) 
[rank0]:[W126 11:13:06.457235302 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 12:55:43
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:55:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1387196) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1387196) WARNING 01-26 12:56:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.36 requests/s, 11984.03 total tokens/s, 23.36 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 12:55:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:55:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:55:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:55:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:55:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:55:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:55:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:55:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:55:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:55:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:55:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:55:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:55:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:55:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:55:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:55:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:55:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1387196) [2026-01-26 12:55:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.94it/s]
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.15it/s]
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.99it/s]
(EngineCore_DP0 pid=1387196) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.96it/s]
(EngineCore_DP0 pid=1387196) 
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1387196) [2026-01-26 12:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1387196) 2026-01-26 12:56:27,930 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1387196) 2026-01-26 12:56:27,970 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1387196) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  1.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.12it/s]
(EngineCore_DP0 pid=1387196) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.83it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 38/128 [00:00<00:00, 379.21it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:00<00:00, 573.44it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 561.96it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|â–Ž         | 4/128 [00:00<00:04, 28.96it/s, est. speed input: 14828.41 toks/s, output: 28.96 toks/s]
Processed prompts:   5%|â–Œ         | 7/128 [00:00<00:04, 26.29it/s, est. speed input: 13678.54 toks/s, output: 26.71 toks/s]
Processed prompts:   8%|â–Š         | 10/128 [00:00<00:04, 25.38it/s, est. speed input: 13271.19 toks/s, output: 25.92 toks/s]
Processed prompts:  10%|â–ˆ         | 13/128 [00:00<00:04, 24.93it/s, est. speed input: 13061.62 toks/s, output: 25.51 toks/s]
Processed prompts:  12%|â–ˆâ–Ž        | 16/128 [00:00<00:04, 24.73it/s, est. speed input: 12946.43 toks/s, output: 25.28 toks/s]
Processed prompts:  15%|â–ˆâ–        | 19/128 [00:00<00:04, 24.55it/s, est. speed input: 12854.65 toks/s, output: 25.11 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 22/128 [00:00<00:04, 24.46it/s, est. speed input: 12795.30 toks/s, output: 24.99 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 25/128 [00:01<00:04, 24.36it/s, est. speed input: 12742.11 toks/s, output: 24.89 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 28/128 [00:01<00:04, 24.36it/s, est. speed input: 12711.77 toks/s, output: 24.83 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 31/128 [00:01<00:03, 24.32it/s, est. speed input: 12682.13 toks/s, output: 24.77 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 34/128 [00:01<00:03, 24.30it/s, est. speed input: 12657.81 toks/s, output: 24.72 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:01<00:03, 24.29it/s, est. speed input: 12638.42 toks/s, output: 24.68 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 40/128 [00:01<00:03, 24.24it/s, est. speed input: 12616.31 toks/s, output: 24.64 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 43/128 [00:01<00:03, 24.22it/s, est. speed input: 12599.62 toks/s, output: 24.61 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [00:01<00:03, 24.24it/s, est. speed input: 12588.90 toks/s, output: 24.59 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [00:01<00:03, 24.23it/s, est. speed input: 12576.31 toks/s, output: 24.56 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [00:02<00:03, 24.25it/s, est. speed input: 12568.29 toks/s, output: 24.55 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 55/128 [00:02<00:03, 24.27it/s, est. speed input: 12562.08 toks/s, output: 24.53 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [00:02<00:02, 24.28it/s, est. speed input: 12555.67 toks/s, output: 24.52 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [00:02<00:02, 24.27it/s, est. speed input: 12548.40 toks/s, output: 24.51 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [00:02<00:02, 24.30it/s, est. speed input: 12545.09 toks/s, output: 24.50 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/128 [00:02<00:02, 24.29it/s, est. speed input: 12539.79 toks/s, output: 24.49 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [00:02<00:02, 24.29it/s, est. speed input: 12534.92 toks/s, output: 24.48 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [00:02<00:02, 24.33it/s, est. speed input: 12534.01 toks/s, output: 24.48 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 76/128 [00:03<00:02, 24.30it/s, est. speed input: 12529.00 toks/s, output: 24.47 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/128 [00:03<00:02, 24.31it/s, est. speed input: 12526.08 toks/s, output: 24.46 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:03<00:01, 24.29it/s, est. speed input: 12521.86 toks/s, output: 24.46 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [00:03<00:01, 24.31it/s, est. speed input: 12519.99 toks/s, output: 24.45 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 88/128 [00:03<00:01, 24.32it/s, est. speed input: 12518.07 toks/s, output: 24.45 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 91/128 [00:03<00:01, 24.32it/s, est. speed input: 12515.71 toks/s, output: 24.44 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [00:03<00:01, 24.27it/s, est. speed input: 12510.82 toks/s, output: 24.43 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:03<00:01, 24.25it/s, est. speed input: 12507.33 toks/s, output: 24.43 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 100/128 [00:04<00:01, 24.24it/s, est. speed input: 12503.93 toks/s, output: 24.42 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 103/128 [00:04<00:01, 24.25it/s, est. speed input: 12501.60 toks/s, output: 24.42 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [00:04<00:00, 24.26it/s, est. speed input: 12499.81 toks/s, output: 24.41 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [00:04<00:00, 24.27it/s, est. speed input: 12497.83 toks/s, output: 24.41 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 112/128 [00:04<00:00, 24.25it/s, est. speed input: 12495.17 toks/s, output: 24.40 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 115/128 [00:04<00:00, 24.25it/s, est. speed input: 12493.26 toks/s, output: 24.40 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [00:04<00:00, 24.26it/s, est. speed input: 12491.59 toks/s, output: 24.40 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:04<00:00, 24.24it/s, est. speed input: 12489.16 toks/s, output: 24.39 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 124/128 [00:05<00:00, 24.22it/s, est. speed input: 12486.30 toks/s, output: 24.39 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 127/128 [00:05<00:00, 24.22it/s, est. speed input: 12484.22 toks/s, output: 24.38 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:05<00:00, 24.22it/s, est. speed input: 12483.95 toks/s, output: 24.38 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:05<00:00, 24.38it/s, est. speed input: 12483.95 toks/s, output: 24.38 toks/s]
[rank0]:[W126 12:56:36.474662292 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 12:56:38
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:56:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1388528) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1388528) WARNING 01-26 12:57:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.99 requests/s, 22541.01 total tokens/s, 21.99 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:56:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:56:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:56:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:56:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:56:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:56:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:56:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:56:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:56:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:56:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:56:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:56:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:56:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:56:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:56:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:56:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:56:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.97it/s]
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=1388528) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1388528) 
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1388528) [2026-01-26 12:56:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1388528) 2026-01-26 12:57:21,948 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1388528) 2026-01-26 12:57:21,987 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1388528) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  9.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.35it/s]
(EngineCore_DP0 pid=1388528) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.99it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  14%|â–ˆâ–        | 18/128 [00:00<00:00, 175.91it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [00:00<00:00, 269.26it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [00:00<00:00, 304.36it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [00:00<00:00, 315.21it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 299.06it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|â–         | 3/128 [00:00<00:04, 27.19it/s, est. speed input: 27847.51 toks/s, output: 27.19 toks/s]
Processed prompts:   5%|â–         | 6/128 [00:00<00:04, 25.04it/s, est. speed input: 25951.80 toks/s, output: 25.34 toks/s]
Processed prompts:   7%|â–‹         | 9/128 [00:00<00:04, 24.44it/s, est. speed input: 25389.30 toks/s, output: 24.79 toks/s]
Processed prompts:   9%|â–‰         | 12/128 [00:00<00:04, 24.04it/s, est. speed input: 25031.72 toks/s, output: 24.44 toks/s]
Processed prompts:  12%|â–ˆâ–        | 15/128 [00:00<00:04, 23.91it/s, est. speed input: 24873.61 toks/s, output: 24.29 toks/s]
Processed prompts:  14%|â–ˆâ–        | 18/128 [00:00<00:04, 23.88it/s, est. speed input: 24791.55 toks/s, output: 24.21 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 21/128 [00:00<00:04, 23.73it/s, est. speed input: 24672.55 toks/s, output: 24.09 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 24/128 [00:00<00:04, 23.71it/s, est. speed input: 24617.58 toks/s, output: 24.04 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 27/128 [00:01<00:04, 23.72it/s, est. speed input: 24583.34 toks/s, output: 24.01 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:01<00:04, 23.68it/s, est. speed input: 24540.87 toks/s, output: 23.97 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:01<00:04, 23.67it/s, est. speed input: 24511.06 toks/s, output: 23.94 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 36/128 [00:01<00:03, 23.76it/s, est. speed input: 24513.28 toks/s, output: 23.94 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 39/128 [00:01<00:03, 23.69it/s, est. speed input: 24481.63 toks/s, output: 23.91 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:01<00:03, 23.69it/s, est. speed input: 24463.96 toks/s, output: 23.89 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:01<00:03, 23.75it/s, est. speed input: 24464.51 toks/s, output: 23.89 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/128 [00:02<00:03, 23.77it/s, est. speed input: 24459.15 toks/s, output: 23.89 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 51/128 [00:02<00:03, 23.69it/s, est. speed input: 24436.47 toks/s, output: 23.86 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:02<00:03, 23.68it/s, est. speed input: 24424.59 toks/s, output: 23.85 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:02<00:03, 23.55it/s, est. speed input: 24392.00 toks/s, output: 23.82 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 60/128 [00:02<00:02, 23.57it/s, est. speed input: 24381.31 toks/s, output: 23.81 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 63/128 [00:02<00:02, 23.65it/s, est. speed input: 24382.86 toks/s, output: 23.81 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [00:02<00:02, 23.61it/s, est. speed input: 24369.43 toks/s, output: 23.80 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [00:02<00:02, 23.58it/s, est. speed input: 24355.64 toks/s, output: 23.78 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [00:03<00:02, 23.59it/s, est. speed input: 24348.02 toks/s, output: 23.78 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 75/128 [00:03<00:02, 23.44it/s, est. speed input: 24320.33 toks/s, output: 23.75 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [00:03<00:02, 23.53it/s, est. speed input: 24319.19 toks/s, output: 23.75 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:03<00:01, 23.55it/s, est. speed input: 24314.23 toks/s, output: 23.74 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 84/128 [00:03<00:01, 23.60it/s, est. speed input: 24313.20 toks/s, output: 23.74 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [00:03<00:01, 23.68it/s, est. speed input: 24317.99 toks/s, output: 23.75 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:03<00:01, 23.71it/s, est. speed input: 24318.02 toks/s, output: 23.75 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [00:03<00:01, 23.68it/s, est. speed input: 24313.64 toks/s, output: 23.74 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 96/128 [00:04<00:01, 23.69it/s, est. speed input: 24312.33 toks/s, output: 23.74 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 99/128 [00:04<00:01, 23.61it/s, est. speed input: 24302.81 toks/s, output: 23.73 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:04<00:01, 23.58it/s, est. speed input: 24295.73 toks/s, output: 23.73 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [00:04<00:00, 23.57it/s, est. speed input: 24291.02 toks/s, output: 23.72 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 108/128 [00:04<00:00, 23.65it/s, est. speed input: 24294.24 toks/s, output: 23.72 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [00:04<00:00, 23.73it/s, est. speed input: 24299.17 toks/s, output: 23.73 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [00:04<00:00, 23.83it/s, est. speed input: 24308.68 toks/s, output: 23.74 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:04<00:00, 23.79it/s, est. speed input: 24307.13 toks/s, output: 23.74 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 120/128 [00:05<00:00, 23.79it/s, est. speed input: 24308.41 toks/s, output: 23.74 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 123/128 [00:05<00:00, 23.76it/s, est. speed input: 24307.52 toks/s, output: 23.74 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:05<00:00, 23.82it/s, est. speed input: 24312.54 toks/s, output: 23.74 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:05<00:00, 23.82it/s, est. speed input: 24313.78 toks/s, output: 23.74 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:05<00:00, 23.74it/s, est. speed input: 24313.78 toks/s, output: 23.74 toks/s]
[rank0]:[W126 12:57:30.266834523 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:57:32
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:57:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1389785) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1389785) WARNING 01-26 12:58:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.64 requests/s, 25252.51 total tokens/s, 24.64 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:57:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:57:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:57:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:57:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:57:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:57:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:57:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:57:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:57:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:57:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:57:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:57:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:57:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:57:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:57:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:57:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:57:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.95it/s]
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.66it/s]
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.14it/s]
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.98it/s]
(EngineCore_DP0 pid=1389785) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.95it/s]
(EngineCore_DP0 pid=1389785) 
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1389785) [2026-01-26 12:57:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1389785) 2026-01-26 12:58:16,244 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1389785) 2026-01-26 12:58:16,310 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1389785) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  4.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  6.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  8.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.40it/s]
(EngineCore_DP0 pid=1389785) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.52it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|â–Š         | 21/256 [00:00<00:01, 204.71it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 62/256 [00:00<00:00, 322.38it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 98/256 [00:00<00:00, 338.36it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 136/256 [00:00<00:00, 354.14it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 176/256 [00:00<00:00, 368.06it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 216/256 [00:00<00:00, 376.88it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 255/256 [00:00<00:00, 378.35it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 358.89it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|â–         | 12/256 [00:00<00:02, 105.37it/s, est. speed input: 107941.10 toks/s, output: 105.40 toks/s]
Processed prompts:   9%|â–‰         | 23/256 [00:00<00:05, 41.32it/s, est. speed input: 46759.89 toks/s, output: 45.66 toks/s]   
Processed prompts:  11%|â–ˆâ–        | 29/256 [00:00<00:06, 34.53it/s, est. speed input: 40014.61 toks/s, output: 39.08 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 34/256 [00:00<00:07, 29.36it/s, est. speed input: 35445.10 toks/s, output: 34.61 toks/s]
Processed prompts:  15%|â–ˆâ–        | 38/256 [00:01<00:07, 28.42it/s, est. speed input: 34202.90 toks/s, output: 33.40 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 42/256 [00:01<00:07, 27.66it/s, est. speed input: 33235.68 toks/s, output: 32.46 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 46/256 [00:01<00:07, 27.05it/s, est. speed input: 32463.16 toks/s, output: 31.70 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 50/256 [00:01<00:07, 26.59it/s, est. speed input: 31838.10 toks/s, output: 31.09 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 54/256 [00:01<00:07, 26.11it/s, est. speed input: 31268.21 toks/s, output: 30.53 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 58/256 [00:01<00:07, 25.66it/s, est. speed input: 30756.80 toks/s, output: 30.04 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 62/256 [00:02<00:07, 25.60it/s, est. speed input: 30404.44 toks/s, output: 29.69 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 66/256 [00:02<00:07, 25.61it/s, est. speed input: 30113.96 toks/s, output: 29.41 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 70/256 [00:02<00:07, 25.58it/s, est. speed input: 29855.10 toks/s, output: 29.15 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 74/256 [00:02<00:07, 25.62it/s, est. speed input: 29638.77 toks/s, output: 28.94 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 78/256 [00:02<00:06, 25.47it/s, est. speed input: 29409.79 toks/s, output: 28.72 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 82/256 [00:02<00:06, 25.35it/s, est. speed input: 29203.33 toks/s, output: 28.52 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 86/256 [00:03<00:06, 25.26it/s, est. speed input: 29015.23 toks/s, output: 28.33 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 90/256 [00:03<00:06, 25.31it/s, est. speed input: 28869.58 toks/s, output: 28.19 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 94/256 [00:03<00:06, 25.37it/s, est. speed input: 28740.10 toks/s, output: 28.07 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 98/256 [00:03<00:06, 25.40it/s, est. speed input: 28621.05 toks/s, output: 27.95 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 102/256 [00:03<00:06, 25.43it/s, est. speed input: 28513.07 toks/s, output: 27.84 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 106/256 [00:03<00:05, 25.36it/s, est. speed input: 28400.49 toks/s, output: 27.73 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 110/256 [00:03<00:05, 25.39it/s, est. speed input: 28308.93 toks/s, output: 27.65 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 114/256 [00:04<00:05, 25.34it/s, est. speed input: 28213.36 toks/s, output: 27.55 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 118/256 [00:04<00:05, 25.35it/s, est. speed input: 28132.01 toks/s, output: 27.47 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 122/256 [00:04<00:05, 25.35it/s, est. speed input: 28054.28 toks/s, output: 27.40 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 126/256 [00:04<00:05, 25.39it/s, est. speed input: 27988.33 toks/s, output: 27.33 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 130/256 [00:04<00:04, 25.30it/s, est. speed input: 27911.88 toks/s, output: 27.26 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/256 [00:04<00:04, 25.33it/s, est. speed input: 27851.06 toks/s, output: 27.20 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 138/256 [00:05<00:04, 25.31it/s, est. speed input: 27789.78 toks/s, output: 27.14 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 142/256 [00:05<00:04, 25.39it/s, est. speed input: 27741.27 toks/s, output: 27.09 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 146/256 [00:05<00:04, 25.40it/s, est. speed input: 27692.24 toks/s, output: 27.04 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 150/256 [00:05<00:04, 25.45it/s, est. speed input: 27649.31 toks/s, output: 27.00 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 154/256 [00:05<00:04, 25.37it/s, est. speed input: 27597.54 toks/s, output: 26.95 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 158/256 [00:05<00:03, 25.30it/s, est. speed input: 27547.03 toks/s, output: 26.90 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 162/256 [00:06<00:03, 25.26it/s, est. speed input: 27500.05 toks/s, output: 26.86 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 166/256 [00:06<00:03, 25.33it/s, est. speed input: 27465.27 toks/s, output: 26.82 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 170/256 [00:06<00:03, 25.37it/s, est. speed input: 27430.93 toks/s, output: 26.79 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 174/256 [00:06<00:03, 25.41it/s, est. speed input: 27398.96 toks/s, output: 26.76 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 178/256 [00:06<00:03, 25.40it/s, est. speed input: 27365.51 toks/s, output: 26.72 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 182/256 [00:06<00:02, 25.40it/s, est. speed input: 27334.10 toks/s, output: 26.69 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 186/256 [00:06<00:02, 25.32it/s, est. speed input: 27297.99 toks/s, output: 26.66 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 190/256 [00:07<00:02, 25.34it/s, est. speed input: 27269.05 toks/s, output: 26.63 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 194/256 [00:07<00:02, 25.33it/s, est. speed input: 27239.35 toks/s, output: 26.60 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 198/256 [00:07<00:02, 25.30it/s, est. speed input: 27209.82 toks/s, output: 26.57 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 202/256 [00:07<00:02, 26.58it/s, est. speed input: 27273.55 toks/s, output: 26.63 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 206/256 [00:07<00:01, 26.33it/s, est. speed input: 27255.63 toks/s, output: 26.62 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 210/256 [00:07<00:01, 26.06it/s, est. speed input: 27232.29 toks/s, output: 26.59 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 214/256 [00:08<00:01, 25.79it/s, est. speed input: 27203.38 toks/s, output: 26.57 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 218/256 [00:08<00:01, 25.69it/s, est. speed input: 27181.57 toks/s, output: 26.54 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 222/256 [00:08<00:01, 25.53it/s, est. speed input: 27154.70 toks/s, output: 26.52 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 226/256 [00:08<00:01, 25.43it/s, est. speed input: 27129.81 toks/s, output: 26.49 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 230/256 [00:08<00:01, 25.43it/s, est. speed input: 27109.91 toks/s, output: 26.47 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 234/256 [00:08<00:00, 25.46it/s, est. speed input: 27092.64 toks/s, output: 26.46 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 238/256 [00:09<00:00, 25.38it/s, est. speed input: 27070.14 toks/s, output: 26.44 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 242/256 [00:09<00:00, 25.38it/s, est. speed input: 27051.28 toks/s, output: 26.42 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 246/256 [00:09<00:00, 25.42it/s, est. speed input: 27035.96 toks/s, output: 26.40 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 250/256 [00:09<00:00, 25.36it/s, est. speed input: 27015.72 toks/s, output: 26.38 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 254/256 [00:09<00:00, 25.40it/s, est. speed input: 27000.94 toks/s, output: 26.37 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:09<00:00, 25.40it/s, est. speed input: 27092.34 toks/s, output: 26.46 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:09<00:00, 26.46it/s, est. speed input: 27092.34 toks/s, output: 26.46 toks/s]
[rank0]:[W126 12:58:29.290214538 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:58:31
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:58:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1391100) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1391100) WARNING 01-26 12:59:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.35 requests/s, 25984.44 total tokens/s, 25.35 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:58:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:58:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:58:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:58:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:58:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:58:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:58:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:58:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:58:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:58:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:58:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:58:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:58:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:58:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:58:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:58:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:58:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.96it/s]
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=1391100) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1391100) 
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1391100) [2026-01-26 12:58:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1391100) 2026-01-26 12:59:15,851 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1391100) 2026-01-26 12:59:15,937 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1391100) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  9.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 11.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.75it/s]
(EngineCore_DP0 pid=1391100) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  6.25it/s]
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  4.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.57it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|â–         | 22/512 [00:00<00:02, 217.30it/s]
Adding requests:  12%|â–ˆâ–        | 63/512 [00:00<00:01, 327.91it/s]
Adding requests:  19%|â–ˆâ–‰        | 99/512 [00:00<00:01, 339.26it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 137/512 [00:00<00:01, 355.06it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 177/512 [00:00<00:00, 367.90it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/512 [00:00<00:00, 377.99it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 255/512 [00:00<00:00, 377.13it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 294/512 [00:00<00:00, 380.51it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 335/512 [00:00<00:00, 388.77it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 375/512 [00:01<00:00, 389.58it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/512 [00:01<00:00, 395.21it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 456/512 [00:01<00:00, 391.52it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 498/512 [00:01<00:00, 398.85it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:01<00:00, 378.24it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|â–         | 22/512 [00:00<00:04, 107.27it/s, est. speed input: 109856.18 toks/s, output: 107.27 toks/s]
Processed prompts:   6%|â–‹         | 33/512 [00:00<00:08, 57.58it/s, est. speed input: 64980.80 toks/s, output: 63.46 toks/s]   
Processed prompts:   8%|â–Š         | 40/512 [00:00<00:11, 40.84it/s, est. speed input: 49769.07 toks/s, output: 48.60 toks/s]
Processed prompts:   9%|â–‰         | 45/512 [00:00<00:12, 38.87it/s, est. speed input: 47319.27 toks/s, output: 46.21 toks/s]
Processed prompts:  10%|â–‰         | 50/512 [00:01<00:15, 29.29it/s, est. speed input: 40033.92 toks/s, output: 39.09 toks/s]
Processed prompts:  11%|â–ˆ         | 54/512 [00:01<00:16, 28.42it/s, est. speed input: 38530.59 toks/s, output: 37.63 toks/s]
Processed prompts:  11%|â–ˆâ–        | 58/512 [00:01<00:16, 27.81it/s, est. speed input: 37377.01 toks/s, output: 36.50 toks/s]
Processed prompts:  12%|â–ˆâ–        | 62/512 [00:01<00:16, 27.41it/s, est. speed input: 36460.74 toks/s, output: 35.61 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 66/512 [00:01<00:16, 27.14it/s, est. speed input: 35707.33 toks/s, output: 34.87 toks/s]
Processed prompts:  14%|â–ˆâ–Ž        | 70/512 [00:02<00:16, 26.96it/s, est. speed input: 35075.79 toks/s, output: 34.25 toks/s]
Processed prompts:  14%|â–ˆâ–        | 74/512 [00:02<00:16, 26.76it/s, est. speed input: 34508.61 toks/s, output: 33.70 toks/s]
Processed prompts:  15%|â–ˆâ–Œ        | 78/512 [00:02<00:16, 26.45it/s, est. speed input: 33965.42 toks/s, output: 33.17 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 82/512 [00:02<00:16, 26.24it/s, est. speed input: 33493.24 toks/s, output: 32.71 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 86/512 [00:02<00:16, 26.22it/s, est. speed input: 33109.23 toks/s, output: 32.33 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 90/512 [00:02<00:16, 26.23it/s, est. speed input: 32773.00 toks/s, output: 32.00 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 94/512 [00:02<00:15, 26.27it/s, est. speed input: 32477.37 toks/s, output: 31.72 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 98/512 [00:03<00:15, 26.30it/s, est. speed input: 32210.88 toks/s, output: 31.46 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 102/512 [00:03<00:15, 26.19it/s, est. speed input: 31943.66 toks/s, output: 31.19 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 106/512 [00:03<00:15, 26.02it/s, est. speed input: 31683.64 toks/s, output: 30.94 toks/s]
Processed prompts:  21%|â–ˆâ–ˆâ–       | 110/512 [00:03<00:15, 26.03it/s, est. speed input: 31469.85 toks/s, output: 30.73 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 114/512 [00:03<00:15, 26.07it/s, est. speed input: 31278.35 toks/s, output: 30.54 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 118/512 [00:03<00:15, 26.12it/s, est. speed input: 31104.19 toks/s, output: 30.37 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 122/512 [00:04<00:14, 26.21it/s, est. speed input: 30952.82 toks/s, output: 30.23 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–       | 126/512 [00:04<00:14, 26.15it/s, est. speed input: 30794.82 toks/s, output: 30.07 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 130/512 [00:04<00:14, 26.03it/s, est. speed input: 30636.22 toks/s, output: 29.92 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 134/512 [00:04<00:14, 26.04it/s, est. speed input: 30501.42 toks/s, output: 29.79 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 138/512 [00:04<00:14, 26.05it/s, est. speed input: 30376.28 toks/s, output: 29.66 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 142/512 [00:04<00:14, 26.07it/s, est. speed input: 30260.78 toks/s, output: 29.55 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–Š       | 146/512 [00:04<00:13, 26.19it/s, est. speed input: 30164.84 toks/s, output: 29.46 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 150/512 [00:05<00:13, 26.21it/s, est. speed input: 30066.48 toks/s, output: 29.36 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 154/512 [00:05<00:13, 26.07it/s, est. speed input: 29957.27 toks/s, output: 29.25 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 158/512 [00:05<00:13, 26.05it/s, est. speed input: 29862.80 toks/s, output: 29.16 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 162/512 [00:05<00:13, 26.02it/s, est. speed input: 29771.94 toks/s, output: 29.07 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 166/512 [00:05<00:13, 26.04it/s, est. speed input: 29690.37 toks/s, output: 28.99 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 170/512 [00:05<00:13, 26.14it/s, est. speed input: 29620.56 toks/s, output: 28.93 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 174/512 [00:06<00:12, 26.17it/s, est. speed input: 29550.81 toks/s, output: 28.86 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 178/512 [00:06<00:12, 26.11it/s, est. speed input: 29477.92 toks/s, output: 28.79 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 182/512 [00:06<00:12, 26.06it/s, est. speed input: 29406.41 toks/s, output: 28.72 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 186/512 [00:06<00:12, 26.03it/s, est. speed input: 29339.93 toks/s, output: 28.65 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 190/512 [00:06<00:12, 26.02it/s, est. speed input: 29276.61 toks/s, output: 28.59 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 194/512 [00:06<00:12, 26.09it/s, est. speed input: 29223.21 toks/s, output: 28.54 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 198/512 [00:06<00:12, 26.14it/s, est. speed input: 29172.35 toks/s, output: 28.49 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 202/512 [00:07<00:11, 27.17it/s, est. speed input: 29199.74 toks/s, output: 28.52 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/512 [00:07<00:11, 26.88it/s, est. speed input: 29150.07 toks/s, output: 28.47 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 210/512 [00:07<00:11, 26.59it/s, est. speed input: 29095.93 toks/s, output: 28.41 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/512 [00:07<00:11, 26.39it/s, est. speed input: 29044.29 toks/s, output: 28.36 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 218/512 [00:07<00:11, 26.33it/s, est. speed input: 29000.32 toks/s, output: 28.32 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 222/512 [00:07<00:11, 26.26it/s, est. speed input: 28955.67 toks/s, output: 28.28 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 226/512 [00:08<00:10, 26.15it/s, est. speed input: 28908.39 toks/s, output: 28.23 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 230/512 [00:08<00:10, 26.16it/s, est. speed input: 28869.33 toks/s, output: 28.19 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 234/512 [00:08<00:10, 26.12it/s, est. speed input: 28828.09 toks/s, output: 28.15 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 238/512 [00:08<00:10, 26.02it/s, est. speed input: 28783.91 toks/s, output: 28.11 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 242/512 [00:08<00:10, 26.02it/s, est. speed input: 28746.05 toks/s, output: 28.07 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 246/512 [00:08<00:10, 26.06it/s, est. speed input: 28711.43 toks/s, output: 28.04 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 250/512 [00:08<00:10, 26.00it/s, est. speed input: 28672.83 toks/s, output: 28.00 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 254/512 [00:09<00:09, 26.01it/s, est. speed input: 28638.64 toks/s, output: 27.97 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 258/512 [00:09<00:09, 26.04it/s, est. speed input: 28607.33 toks/s, output: 27.94 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 262/512 [00:09<00:09, 26.02it/s, est. speed input: 28574.26 toks/s, output: 27.90 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/512 [00:09<00:09, 25.98it/s, est. speed input: 28541.00 toks/s, output: 27.87 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 270/512 [00:09<00:09, 26.08it/s, est. speed input: 28515.93 toks/s, output: 27.85 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 274/512 [00:09<00:09, 26.06it/s, est. speed input: 28486.88 toks/s, output: 27.82 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 278/512 [00:10<00:08, 26.01it/s, est. speed input: 28456.47 toks/s, output: 27.79 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 282/512 [00:10<00:08, 26.07it/s, est. speed input: 28431.89 toks/s, output: 27.77 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 286/512 [00:10<00:08, 26.06it/s, est. speed input: 28405.82 toks/s, output: 27.74 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 290/512 [00:10<00:08, 26.04it/s, est. speed input: 28379.46 toks/s, output: 27.71 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 294/512 [00:10<00:08, 26.12it/s, est. speed input: 28358.91 toks/s, output: 27.69 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 298/512 [00:10<00:08, 26.13it/s, est. speed input: 28336.44 toks/s, output: 27.67 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 302/512 [00:10<00:08, 26.10it/s, est. speed input: 28312.94 toks/s, output: 27.65 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 306/512 [00:11<00:07, 27.26it/s, est. speed input: 28346.39 toks/s, output: 27.68 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 310/512 [00:11<00:07, 26.95it/s, est. speed input: 28326.61 toks/s, output: 27.66 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/512 [00:11<00:07, 26.67it/s, est. speed input: 28304.04 toks/s, output: 27.64 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/512 [00:11<00:07, 26.51it/s, est. speed input: 28283.52 toks/s, output: 27.62 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 322/512 [00:11<00:07, 26.43it/s, est. speed input: 28265.43 toks/s, output: 27.60 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 326/512 [00:11<00:07, 26.39it/s, est. speed input: 28248.32 toks/s, output: 27.59 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 330/512 [00:11<00:06, 26.28it/s, est. speed input: 28227.88 toks/s, output: 27.57 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 334/512 [00:12<00:06, 26.24it/s, est. speed input: 28209.43 toks/s, output: 27.55 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 338/512 [00:12<00:06, 26.19it/s, est. speed input: 28190.47 toks/s, output: 27.53 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 342/512 [00:12<00:06, 26.18it/s, est. speed input: 28173.29 toks/s, output: 27.51 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346/512 [00:12<00:06, 26.16it/s, est. speed input: 28155.87 toks/s, output: 27.50 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 350/512 [00:12<00:06, 26.18it/s, est. speed input: 28140.32 toks/s, output: 27.48 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 354/512 [00:12<00:06, 26.17it/s, est. speed input: 28124.11 toks/s, output: 27.46 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 358/512 [00:13<00:05, 26.14it/s, est. speed input: 28107.26 toks/s, output: 27.45 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 362/512 [00:13<00:05, 26.11it/s, est. speed input: 28090.38 toks/s, output: 27.43 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/512 [00:13<00:05, 26.11it/s, est. speed input: 28074.88 toks/s, output: 27.42 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/512 [00:13<00:05, 26.09it/s, est. speed input: 28058.95 toks/s, output: 27.40 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 374/512 [00:13<00:05, 26.11it/s, est. speed input: 28044.61 toks/s, output: 27.39 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 378/512 [00:13<00:05, 26.15it/s, est. speed input: 28031.86 toks/s, output: 27.37 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 382/512 [00:13<00:04, 26.10it/s, est. speed input: 28016.07 toks/s, output: 27.36 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 386/512 [00:14<00:04, 26.14it/s, est. speed input: 28003.57 toks/s, output: 27.35 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 390/512 [00:14<00:04, 26.12it/s, est. speed input: 27989.68 toks/s, output: 27.33 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 394/512 [00:14<00:04, 26.11it/s, est. speed input: 27976.10 toks/s, output: 27.32 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 398/512 [00:14<00:04, 26.12it/s, est. speed input: 27963.36 toks/s, output: 27.31 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 402/512 [00:14<00:04, 26.15it/s, est. speed input: 27951.91 toks/s, output: 27.30 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 406/512 [00:14<00:04, 26.14it/s, est. speed input: 27939.27 toks/s, output: 27.28 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 410/512 [00:15<00:03, 26.08it/s, est. speed input: 27925.24 toks/s, output: 27.27 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 414/512 [00:15<00:03, 26.11it/s, est. speed input: 27914.08 toks/s, output: 27.26 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/512 [00:15<00:03, 26.12it/s, est. speed input: 27902.65 toks/s, output: 27.25 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/512 [00:15<00:03, 26.09it/s, est. speed input: 27890.20 toks/s, output: 27.24 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 426/512 [00:15<00:03, 26.08it/s, est. speed input: 27878.40 toks/s, output: 27.22 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 430/512 [00:15<00:03, 26.10it/s, est. speed input: 27867.51 toks/s, output: 27.21 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 434/512 [00:15<00:02, 26.08it/s, est. speed input: 27855.95 toks/s, output: 27.20 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 438/512 [00:16<00:02, 26.03it/s, est. speed input: 27843.46 toks/s, output: 27.19 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 442/512 [00:16<00:02, 26.04it/s, est. speed input: 27832.48 toks/s, output: 27.18 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 446/512 [00:16<00:02, 26.01it/s, est. speed input: 27820.55 toks/s, output: 27.17 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 450/512 [00:16<00:02, 26.05it/s, est. speed input: 27810.76 toks/s, output: 27.16 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 454/512 [00:16<00:02, 26.04it/s, est. speed input: 27800.00 toks/s, output: 27.15 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 458/512 [00:16<00:02, 26.10it/s, est. speed input: 27791.72 toks/s, output: 27.14 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 462/512 [00:17<00:01, 26.05it/s, est. speed input: 27780.42 toks/s, output: 27.13 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 466/512 [00:17<00:01, 26.03it/s, est. speed input: 27769.87 toks/s, output: 27.12 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/512 [00:17<00:01, 26.06it/s, est. speed input: 27761.01 toks/s, output: 27.11 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 474/512 [00:17<00:01, 26.06it/s, est. speed input: 27751.39 toks/s, output: 27.10 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 478/512 [00:17<00:01, 26.04it/s, est. speed input: 27741.57 toks/s, output: 27.09 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482/512 [00:17<00:01, 26.07it/s, est. speed input: 27733.12 toks/s, output: 27.08 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 486/512 [00:17<00:00, 26.10it/s, est. speed input: 27725.33 toks/s, output: 27.08 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 490/512 [00:18<00:00, 26.06it/s, est. speed input: 27715.60 toks/s, output: 27.07 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 494/512 [00:18<00:00, 26.09it/s, est. speed input: 27707.80 toks/s, output: 27.06 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 498/512 [00:18<00:00, 26.10it/s, est. speed input: 27699.81 toks/s, output: 27.05 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 502/512 [00:18<00:00, 26.06it/s, est. speed input: 27690.75 toks/s, output: 27.04 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 506/512 [00:18<00:00, 26.04it/s, est. speed input: 27681.90 toks/s, output: 27.03 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 510/512 [00:18<00:00, 27.69it/s, est. speed input: 27718.34 toks/s, output: 27.07 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:18<00:00, 27.69it/s, est. speed input: 27826.62 toks/s, output: 27.17 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:18<00:00, 27.17it/s, est. speed input: 27826.62 toks/s, output: 27.17 toks/s]
[rank0]:[W126 12:59:38.980943080 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:59:41
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:59:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1392567) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1392567) WARNING 01-26 13:00:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.49 requests/s, 28178.11 total tokens/s, 27.49 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:59:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:59:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:59:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 12:59:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 12:59:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:59:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:59:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:59:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:59:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:00:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:00:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:00:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:00:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:00:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:00:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:00:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:00:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:00:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.96it/s]
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=1392567) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1392567) 
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1392567) [2026-01-26 13:00:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1392567) 2026-01-26 13:00:29,074 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1392567) 2026-01-26 13:00:29,152 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1392567) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  4.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  4.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:01<00:00,  3.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.25it/s]
(EngineCore_DP0 pid=1392567) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.76it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|â–         | 22/1024 [00:00<00:04, 217.57it/s]
Adding requests:   6%|â–Œ         | 63/1024 [00:00<00:02, 327.14it/s]
Adding requests:  10%|â–‰         | 99/1024 [00:00<00:02, 339.57it/s]
Adding requests:  13%|â–ˆâ–Ž        | 137/1024 [00:00<00:02, 353.78it/s]
Adding requests:  17%|â–ˆâ–‹        | 177/1024 [00:00<00:02, 366.37it/s]
Adding requests:  21%|â–ˆâ–ˆâ–       | 218/1024 [00:00<00:02, 380.65it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 257/1024 [00:00<00:02, 378.74it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 298/1024 [00:00<00:01, 385.74it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 339/1024 [00:00<00:01, 390.62it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 380/1024 [00:01<00:01, 393.65it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 422/1024 [00:01<00:01, 400.78it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 463/1024 [00:01<00:01, 396.31it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 506/1024 [00:01<00:01, 404.49it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 548/1024 [00:01<00:01, 407.29it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:01<00:01, 401.60it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 630/1024 [00:01<00:01, 390.86it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 670/1024 [00:01<00:00, 381.76it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 712/1024 [00:01<00:00, 389.74it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 752/1024 [00:01<00:00, 383.34it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 792/1024 [00:02<00:00, 384.38it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 833/1024 [00:02<00:00, 389.63it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 873/1024 [00:02<00:00, 391.46it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 913/1024 [00:02<00:00, 390.54it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 953/1024 [00:02<00:00, 386.66it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 992/1024 [00:02<00:00, 384.62it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 383.39it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|â–‹         | 74/1024 [00:00<00:04, 226.86it/s, est. speed input: 232320.59 toks/s, output: 226.86 toks/s]
Processed prompts:   9%|â–‰         | 97/1024 [00:00<00:10, 92.02it/s, est. speed input: 109060.26 toks/s, output: 106.50 toks/s] 
Processed prompts:  11%|â–ˆ         | 109/1024 [00:01<00:16, 55.98it/s, est. speed input: 74839.44 toks/s, output: 73.08 toks/s] 
Processed prompts:  11%|â–ˆâ–        | 117/1024 [00:01<00:18, 48.41it/s, est. speed input: 67211.08 toks/s, output: 65.64 toks/s]
Processed prompts:  12%|â–ˆâ–        | 123/1024 [00:02<00:21, 40.97it/s, est. speed input: 60894.11 toks/s, output: 59.47 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 130/1024 [00:02<00:24, 36.20it/s, est. speed input: 56433.98 toks/s, output: 55.11 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 138/1024 [00:02<00:26, 33.56it/s, est. speed input: 53247.09 toks/s, output: 52.00 toks/s]
Processed prompts:  14%|â–ˆâ–        | 146/1024 [00:02<00:27, 31.92it/s, est. speed input: 50834.83 toks/s, output: 49.64 toks/s]
Processed prompts:  15%|â–ˆâ–Œ        | 154/1024 [00:03<00:28, 30.69it/s, est. speed input: 48827.51 toks/s, output: 47.68 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 162/1024 [00:03<00:29, 29.65it/s, est. speed input: 47078.82 toks/s, output: 45.97 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 170/1024 [00:03<00:29, 29.01it/s, est. speed input: 45635.67 toks/s, output: 44.57 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 178/1024 [00:04<00:29, 28.64it/s, est. speed input: 44428.07 toks/s, output: 43.39 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 186/1024 [00:04<00:29, 28.28it/s, est. speed input: 43341.87 toks/s, output: 42.33 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 194/1024 [00:04<00:29, 27.96it/s, est. speed input: 42371.53 toks/s, output: 41.38 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 202/1024 [00:04<00:28, 28.72it/s, est. speed input: 41796.98 toks/s, output: 40.82 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 210/1024 [00:05<00:28, 28.41it/s, est. speed input: 41055.88 toks/s, output: 40.09 toks/s]
Processed prompts:  21%|â–ˆâ–ˆâ–       | 218/1024 [00:05<00:28, 28.02it/s, est. speed input: 40350.53 toks/s, output: 39.40 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 226/1024 [00:05<00:28, 27.87it/s, est. speed input: 39741.95 toks/s, output: 38.81 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 234/1024 [00:06<00:28, 27.82it/s, est. speed input: 39205.26 toks/s, output: 38.29 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–Ž       | 242/1024 [00:06<00:28, 27.77it/s, est. speed input: 38712.12 toks/s, output: 37.80 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 250/1024 [00:06<00:27, 27.67it/s, est. speed input: 38249.91 toks/s, output: 37.35 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 258/1024 [00:06<00:27, 27.72it/s, est. speed input: 37848.50 toks/s, output: 36.96 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 266/1024 [00:07<00:27, 27.70it/s, est. speed input: 37468.71 toks/s, output: 36.59 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 274/1024 [00:07<00:27, 27.62it/s, est. speed input: 37108.47 toks/s, output: 36.24 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 282/1024 [00:07<00:26, 27.62it/s, est. speed input: 36782.84 toks/s, output: 35.92 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 290/1024 [00:08<00:26, 27.65it/s, est. speed input: 36485.19 toks/s, output: 35.63 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 298/1024 [00:08<00:26, 27.56it/s, est. speed input: 36190.16 toks/s, output: 35.34 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 306/1024 [00:08<00:25, 28.36it/s, est. speed input: 36038.31 toks/s, output: 35.19 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 314/1024 [00:08<00:25, 28.15it/s, est. speed input: 35790.81 toks/s, output: 34.95 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 322/1024 [00:09<00:25, 27.97it/s, est. speed input: 35553.99 toks/s, output: 34.72 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 330/1024 [00:09<00:24, 27.82it/s, est. speed input: 35327.67 toks/s, output: 34.50 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 338/1024 [00:09<00:24, 27.76it/s, est. speed input: 35121.31 toks/s, output: 34.30 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 346/1024 [00:10<00:24, 27.75it/s, est. speed input: 34929.54 toks/s, output: 34.11 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 354/1024 [00:10<00:24, 27.65it/s, est. speed input: 34737.66 toks/s, output: 33.92 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 362/1024 [00:10<00:23, 27.63it/s, est. speed input: 34562.30 toks/s, output: 33.75 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 370/1024 [00:11<00:23, 27.62it/s, est. speed input: 34396.03 toks/s, output: 33.59 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 378/1024 [00:11<00:23, 27.56it/s, est. speed input: 34233.43 toks/s, output: 33.43 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 386/1024 [00:11<00:23, 27.56it/s, est. speed input: 34082.50 toks/s, output: 33.28 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:11<00:22, 27.57it/s, est. speed input: 33940.85 toks/s, output: 33.15 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 402/1024 [00:12<00:22, 27.57it/s, est. speed input: 33804.29 toks/s, output: 33.01 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 410/1024 [00:12<00:22, 27.52it/s, est. speed input: 33669.67 toks/s, output: 32.88 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 418/1024 [00:12<00:22, 27.54it/s, est. speed input: 33546.81 toks/s, output: 32.76 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 426/1024 [00:13<00:21, 27.54it/s, est. speed input: 33427.39 toks/s, output: 32.64 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 434/1024 [00:13<00:21, 27.54it/s, est. speed input: 33313.84 toks/s, output: 32.53 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 442/1024 [00:13<00:21, 27.51it/s, est. speed input: 33202.05 toks/s, output: 32.42 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 450/1024 [00:13<00:20, 27.56it/s, est. speed input: 33101.67 toks/s, output: 32.33 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 458/1024 [00:14<00:20, 27.55it/s, est. speed input: 33000.54 toks/s, output: 32.23 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 466/1024 [00:14<00:20, 27.56it/s, est. speed input: 32905.33 toks/s, output: 32.13 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 474/1024 [00:14<00:19, 27.53it/s, est. speed input: 32811.17 toks/s, output: 32.04 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 482/1024 [00:15<00:19, 27.56it/s, est. speed input: 32724.78 toks/s, output: 31.96 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 490/1024 [00:15<00:19, 27.52it/s, est. speed input: 32636.46 toks/s, output: 31.87 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:15<00:19, 27.51it/s, est. speed input: 32553.00 toks/s, output: 31.79 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 506/1024 [00:15<00:18, 27.52it/s, est. speed input: 32474.00 toks/s, output: 31.71 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 514/1024 [00:16<00:18, 27.50it/s, est. speed input: 32395.99 toks/s, output: 31.64 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 522/1024 [00:16<00:18, 27.50it/s, est. speed input: 32321.40 toks/s, output: 31.56 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 530/1024 [00:16<00:17, 27.49it/s, est. speed input: 32248.74 toks/s, output: 31.49 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 538/1024 [00:17<00:17, 27.50it/s, est. speed input: 32179.87 toks/s, output: 31.43 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 546/1024 [00:17<00:17, 27.48it/s, est. speed input: 32111.16 toks/s, output: 31.36 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 554/1024 [00:17<00:17, 27.50it/s, est. speed input: 32047.39 toks/s, output: 31.30 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 562/1024 [00:17<00:16, 27.48it/s, est. speed input: 31982.99 toks/s, output: 31.23 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 570/1024 [00:18<00:16, 27.48it/s, est. speed input: 31922.19 toks/s, output: 31.17 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 578/1024 [00:18<00:16, 27.46it/s, est. speed input: 31861.47 toks/s, output: 31.11 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 586/1024 [00:18<00:15, 27.45it/s, est. speed input: 31803.27 toks/s, output: 31.06 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:19<00:15, 27.45it/s, est. speed input: 31747.07 toks/s, output: 31.00 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 602/1024 [00:19<00:15, 27.44it/s, est. speed input: 31692.13 toks/s, output: 30.95 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 610/1024 [00:19<00:15, 27.48it/s, est. speed input: 31641.08 toks/s, output: 30.90 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 618/1024 [00:20<00:14, 27.46it/s, est. speed input: 31589.18 toks/s, output: 30.85 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 626/1024 [00:20<00:14, 27.49it/s, est. speed input: 31540.92 toks/s, output: 30.80 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 634/1024 [00:20<00:14, 27.46it/s, est. speed input: 31491.44 toks/s, output: 30.75 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 642/1024 [00:20<00:13, 27.45it/s, est. speed input: 31444.02 toks/s, output: 30.71 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 650/1024 [00:21<00:13, 27.46it/s, est. speed input: 31398.47 toks/s, output: 30.66 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 658/1024 [00:21<00:13, 27.43it/s, est. speed input: 31352.69 toks/s, output: 30.62 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 666/1024 [00:21<00:13, 27.45it/s, est. speed input: 31310.07 toks/s, output: 30.58 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 674/1024 [00:22<00:12, 27.45it/s, est. speed input: 31267.49 toks/s, output: 30.53 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:22<00:12, 27.46it/s, est. speed input: 31227.14 toks/s, output: 30.50 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:22<00:12, 27.44it/s, est. speed input: 31186.14 toks/s, output: 30.46 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 698/1024 [00:22<00:11, 27.44it/s, est. speed input: 31146.83 toks/s, output: 30.42 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 706/1024 [00:23<00:11, 27.42it/s, est. speed input: 31107.76 toks/s, output: 30.38 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 714/1024 [00:23<00:11, 27.43it/s, est. speed input: 31070.44 toks/s, output: 30.34 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 722/1024 [00:23<00:11, 27.43it/s, est. speed input: 31034.27 toks/s, output: 30.31 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 730/1024 [00:24<00:10, 27.44it/s, est. speed input: 30998.77 toks/s, output: 30.27 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 738/1024 [00:24<00:10, 27.44it/s, est. speed input: 30964.39 toks/s, output: 30.24 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 746/1024 [00:24<00:10, 27.43it/s, est. speed input: 30930.19 toks/s, output: 30.21 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 754/1024 [00:24<00:09, 27.42it/s, est. speed input: 30896.48 toks/s, output: 30.17 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 762/1024 [00:25<00:09, 27.41it/s, est. speed input: 30863.66 toks/s, output: 30.14 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:25<00:09, 27.42it/s, est. speed input: 30831.97 toks/s, output: 30.11 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 778/1024 [00:25<00:08, 27.43it/s, est. speed input: 30801.55 toks/s, output: 30.08 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:26<00:08, 28.22it/s, est. speed input: 30803.10 toks/s, output: 30.08 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 794/1024 [00:26<00:08, 27.97it/s, est. speed input: 30773.05 toks/s, output: 30.05 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 802/1024 [00:26<00:07, 27.82it/s, est. speed input: 30744.15 toks/s, output: 30.02 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 810/1024 [00:27<00:07, 27.71it/s, est. speed input: 30715.70 toks/s, output: 30.00 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 818/1024 [00:27<00:07, 27.61it/s, est. speed input: 30687.00 toks/s, output: 29.97 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 826/1024 [00:27<00:07, 27.54it/s, est. speed input: 30658.82 toks/s, output: 29.94 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 834/1024 [00:27<00:06, 27.51it/s, est. speed input: 30632.34 toks/s, output: 29.91 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842/1024 [00:28<00:06, 27.47it/s, est. speed input: 30605.40 toks/s, output: 29.89 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 850/1024 [00:28<00:06, 27.43it/s, est. speed input: 30578.34 toks/s, output: 29.86 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:28<00:06, 27.42it/s, est. speed input: 30552.66 toks/s, output: 29.84 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:29<00:05, 27.40it/s, est. speed input: 30527.24 toks/s, output: 29.81 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 874/1024 [00:29<00:05, 27.39it/s, est. speed input: 30502.10 toks/s, output: 29.79 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 882/1024 [00:29<00:05, 27.36it/s, est. speed input: 30476.78 toks/s, output: 29.76 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 890/1024 [00:29<00:04, 27.38it/s, est. speed input: 30453.73 toks/s, output: 29.74 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 898/1024 [00:30<00:04, 27.39it/s, est. speed input: 30430.43 toks/s, output: 29.72 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 906/1024 [00:30<00:04, 27.34it/s, est. speed input: 30405.97 toks/s, output: 29.69 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 914/1024 [00:30<00:04, 27.38it/s, est. speed input: 30384.56 toks/s, output: 29.67 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 922/1024 [00:31<00:03, 27.38it/s, est. speed input: 30362.40 toks/s, output: 29.65 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 930/1024 [00:31<00:03, 27.37it/s, est. speed input: 30340.50 toks/s, output: 29.63 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 938/1024 [00:31<00:03, 27.37it/s, est. speed input: 30319.20 toks/s, output: 29.61 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 946/1024 [00:31<00:02, 27.37it/s, est. speed input: 30298.25 toks/s, output: 29.59 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 954/1024 [00:32<00:02, 27.40it/s, est. speed input: 30278.50 toks/s, output: 29.57 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:32<00:02, 27.37it/s, est. speed input: 30257.52 toks/s, output: 29.55 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:32<00:01, 27.33it/s, est. speed input: 30236.54 toks/s, output: 29.53 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 978/1024 [00:33<00:01, 27.37it/s, est. speed input: 30217.96 toks/s, output: 29.51 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 986/1024 [00:33<00:01, 27.32it/s, est. speed input: 30197.28 toks/s, output: 29.49 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 994/1024 [00:33<00:01, 27.29it/s, est. speed input: 30176.82 toks/s, output: 29.47 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1002/1024 [00:34<00:00, 27.33it/s, est. speed input: 30158.94 toks/s, output: 29.45 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1010/1024 [00:34<00:00, 27.31it/s, est. speed input: 30139.85 toks/s, output: 29.43 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1018/1024 [00:34<00:00, 28.25it/s, est. speed input: 30149.58 toks/s, output: 29.44 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:34<00:00, 28.25it/s, est. speed input: 30326.90 toks/s, output: 29.62 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:34<00:00, 29.62it/s, est. speed input: 30326.90 toks/s, output: 29.62 toks/s]
[rank0]:[W126 13:01:10.043482625 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 13:01:12
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:01:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1394347) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1394347) WARNING 01-26 13:01:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.67 requests/s, 28363.70 total tokens/s, 27.67 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 13:01:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:01:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:01:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:01:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:01:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:01:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:01:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:01:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:01:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:01:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:01:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:01:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:01:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:01:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:01:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:01:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:01:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.96it/s]
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.17it/s]
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=1394347) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1394347) 
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1394347) [2026-01-26 13:01:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1394347) [rank0]:W0126 13:01:59.684000 1394347 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1394347) [rank0]:W0126 13:01:59.738000 1394347 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1394347) [rank0]:W0126 13:02:00.481000 1394347 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1394347) [rank0]:W0126 13:02:00.564000 1394347 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1394347) 2026-01-26 13:02:05,333 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1394347) 2026-01-26 13:02:05,534 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1394347) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–        | 1/7 [00:00<00:01,  4.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00,  5.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00,  4.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00,  7.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  7.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.58it/s]
(EngineCore_DP0 pid=1394347) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.19it/s]
Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.61it/s]
Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.11it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/2048 [00:00<00:09, 208.96it/s]
Adding requests:   3%|â–Ž         | 59/2048 [00:00<00:06, 308.21it/s]
Adding requests:   5%|â–         | 94/2048 [00:00<00:05, 326.47it/s]
Adding requests:   6%|â–‹         | 131/2048 [00:00<00:05, 339.99it/s]
Adding requests:   8%|â–Š         | 169/2048 [00:00<00:05, 353.41it/s]
Adding requests:  10%|â–ˆ         | 206/2048 [00:00<00:05, 358.62it/s]
Adding requests:  12%|â–ˆâ–        | 244/2048 [00:00<00:04, 363.86it/s]
Adding requests:  14%|â–ˆâ–        | 282/2048 [00:00<00:04, 365.46it/s]
Adding requests:  16%|â–ˆâ–Œ        | 321/2048 [00:00<00:04, 372.75it/s]
Adding requests:  18%|â–ˆâ–Š        | 360/2048 [00:01<00:04, 377.02it/s]
Adding requests:  19%|â–ˆâ–‰        | 399/2048 [00:01<00:04, 380.09it/s]
Adding requests:  21%|â–ˆâ–ˆâ–       | 438/2048 [00:01<00:04, 381.09it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 477/2048 [00:01<00:04, 383.61it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 518/2048 [00:01<00:03, 390.22it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 558/2048 [00:01<00:03, 391.87it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 598/2048 [00:01<00:03, 381.80it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 637/2048 [00:01<00:03, 378.20it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 675/2048 [00:01<00:03, 369.97it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 714/2048 [00:01<00:03, 375.56it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 752/2048 [00:02<00:03, 362.66it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 789/2048 [00:02<00:03, 364.14it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 826/2048 [00:02<00:03, 364.38it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 864/2048 [00:02<00:03, 368.68it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 904/2048 [00:02<00:03, 377.28it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 942/2048 [00:02<00:02, 370.39it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 980/2048 [00:02<00:02, 370.14it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1018/2048 [00:02<00:02, 367.64it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1055/2048 [00:02<00:02, 365.79it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1092/2048 [00:02<00:02, 366.28it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1132/2048 [00:03<00:02, 373.92it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:03<00:02, 367.85it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1209/2048 [00:03<00:02, 373.58it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1247/2048 [00:03<00:02, 372.43it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1285/2048 [00:03<00:02, 368.53it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1324/2048 [00:03<00:01, 372.34it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1363/2048 [00:03<00:01, 375.88it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1401/2048 [00:03<00:01, 372.94it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1440/2048 [00:03<00:01, 374.78it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1478/2048 [00:04<00:01, 372.56it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1517/2048 [00:04<00:01, 377.27it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1555/2048 [00:04<00:01, 372.75it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1593/2048 [00:04<00:01, 368.85it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1630/2048 [00:04<00:01, 362.83it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1667/2048 [00:04<00:01, 355.07it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1706/2048 [00:04<00:00, 363.27it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1744/2048 [00:04<00:00, 365.79it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1783/2048 [00:04<00:00, 372.61it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1821/2048 [00:04<00:00, 368.84it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1860/2048 [00:05<00:00, 373.06it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1898/2048 [00:05<00:00, 372.65it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1936/2048 [00:05<00:00, 371.03it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1975/2048 [00:05<00:00, 374.23it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2013/2048 [00:05<00:00, 370.59it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:05<00:00, 368.54it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|â–‹         | 146/2048 [00:00<00:04, 444.34it/s, est. speed input: 455034.45 toks/s, output: 444.35 toks/s]
Processed prompts:   9%|â–‰         | 191/2048 [00:01<00:17, 106.50it/s, est. speed input: 132082.64 toks/s, output: 128.99 toks/s]
Processed prompts:  10%|â–ˆ         | 212/2048 [00:02<00:30, 59.39it/s, est. speed input: 83439.16 toks/s, output: 81.48 toks/s]   
Processed prompts:  11%|â–ˆ         | 226/2048 [00:03<00:36, 49.58it/s, est. speed input: 72929.99 toks/s, output: 71.22 toks/s]
Processed prompts:  12%|â–ˆâ–        | 242/2048 [00:03<00:41, 43.31it/s, est. speed input: 66102.29 toks/s, output: 64.55 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 258/2048 [00:04<00:46, 38.83it/s, est. speed input: 61124.94 toks/s, output: 59.69 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 274/2048 [00:04<00:49, 35.60it/s, est. speed input: 57293.60 toks/s, output: 55.95 toks/s]
Processed prompts:  14%|â–ˆâ–        | 290/2048 [00:05<00:52, 33.32it/s, est. speed input: 54278.01 toks/s, output: 53.01 toks/s]
Processed prompts:  15%|â–ˆâ–        | 306/2048 [00:06<00:54, 32.22it/s, est. speed input: 52104.37 toks/s, output: 50.88 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 322/2048 [00:06<00:55, 30.90it/s, est. speed input: 50043.28 toks/s, output: 48.87 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 338/2048 [00:07<00:57, 29.96it/s, est. speed input: 48310.47 toks/s, output: 47.18 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 354/2048 [00:07<00:57, 29.29it/s, est. speed input: 46826.02 toks/s, output: 45.73 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 370/2048 [00:08<00:58, 28.86it/s, est. speed input: 45561.18 toks/s, output: 44.49 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 386/2048 [00:08<00:58, 28.50it/s, est. speed input: 44442.05 toks/s, output: 43.40 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 402/2048 [00:09<00:58, 28.30it/s, est. speed input: 43474.94 toks/s, output: 42.46 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 418/2048 [00:10<00:57, 28.14it/s, est. speed input: 42612.63 toks/s, output: 41.61 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 434/2048 [00:10<00:57, 28.01it/s, est. speed input: 41838.16 toks/s, output: 40.86 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 450/2048 [00:11<00:57, 27.95it/s, est. speed input: 41151.17 toks/s, output: 40.19 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 466/2048 [00:11<00:56, 27.90it/s, est. speed input: 40530.75 toks/s, output: 39.58 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–Ž       | 482/2048 [00:12<00:56, 27.87it/s, est. speed input: 39967.53 toks/s, output: 39.03 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 498/2048 [00:12<00:55, 27.81it/s, est. speed input: 39448.43 toks/s, output: 38.52 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 514/2048 [00:13<00:55, 27.79it/s, est. speed input: 38976.82 toks/s, output: 38.06 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 530/2048 [00:14<00:54, 27.76it/s, est. speed input: 38541.32 toks/s, output: 37.64 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 546/2048 [00:14<00:54, 27.78it/s, est. speed input: 38146.62 toks/s, output: 37.25 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 562/2048 [00:15<00:53, 27.76it/s, est. speed input: 37777.27 toks/s, output: 36.89 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 578/2048 [00:15<00:52, 27.77it/s, est. speed input: 37437.00 toks/s, output: 36.56 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 594/2048 [00:16<00:52, 27.74it/s, est. speed input: 37116.23 toks/s, output: 36.25 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 610/2048 [00:16<00:51, 27.74it/s, est. speed input: 36819.88 toks/s, output: 35.96 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 626/2048 [00:17<00:51, 27.74it/s, est. speed input: 36542.88 toks/s, output: 35.69 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 642/2048 [00:18<00:50, 27.74it/s, est. speed input: 36284.54 toks/s, output: 35.43 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 658/2048 [00:18<00:50, 27.77it/s, est. speed input: 36044.84 toks/s, output: 35.20 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 674/2048 [00:19<00:49, 27.76it/s, est. speed input: 35816.86 toks/s, output: 34.98 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 690/2048 [00:19<00:48, 27.77it/s, est. speed input: 35602.61 toks/s, output: 34.77 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 706/2048 [00:20<00:48, 27.74it/s, est. speed input: 35396.66 toks/s, output: 34.57 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 722/2048 [00:21<00:47, 27.73it/s, est. speed input: 35203.77 toks/s, output: 34.38 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 738/2048 [00:21<00:47, 27.74it/s, est. speed input: 35022.65 toks/s, output: 34.20 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 754/2048 [00:22<00:46, 27.76it/s, est. speed input: 34852.39 toks/s, output: 34.04 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 770/2048 [00:22<00:46, 27.76it/s, est. speed input: 34689.70 toks/s, output: 33.88 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 786/2048 [00:23<00:44, 28.21it/s, est. speed input: 34580.29 toks/s, output: 33.77 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 802/2048 [00:23<00:44, 28.06it/s, est. speed input: 34430.30 toks/s, output: 33.62 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 818/2048 [00:24<00:43, 27.97it/s, est. speed input: 34288.75 toks/s, output: 33.49 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 834/2048 [00:25<00:43, 27.90it/s, est. speed input: 34152.77 toks/s, output: 33.35 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 850/2048 [00:25<00:43, 27.82it/s, est. speed input: 34020.48 toks/s, output: 33.22 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 866/2048 [00:26<00:42, 27.76it/s, est. speed input: 33893.41 toks/s, output: 33.10 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 882/2048 [00:26<00:42, 27.73it/s, est. speed input: 33773.32 toks/s, output: 32.98 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 898/2048 [00:27<00:41, 27.74it/s, est. speed input: 33660.45 toks/s, output: 32.87 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 914/2048 [00:27<00:40, 27.70it/s, est. speed input: 33548.68 toks/s, output: 32.76 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 930/2048 [00:28<00:40, 27.72it/s, est. speed input: 33444.73 toks/s, output: 32.66 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 946/2048 [00:29<00:39, 27.69it/s, est. speed input: 33342.10 toks/s, output: 32.56 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 962/2048 [00:29<00:39, 27.68it/s, est. speed input: 33243.95 toks/s, output: 32.46 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 978/2048 [00:30<00:38, 27.68it/s, est. speed input: 33150.37 toks/s, output: 32.37 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 994/2048 [00:30<00:38, 27.66it/s, est. speed input: 33058.47 toks/s, output: 32.28 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1010/2048 [00:31<00:37, 27.64it/s, est. speed input: 32969.85 toks/s, output: 32.20 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1026/2048 [00:31<00:36, 27.64it/s, est. speed input: 32885.17 toks/s, output: 32.11 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1042/2048 [00:32<00:36, 27.63it/s, est. speed input: 32802.84 toks/s, output: 32.03 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1058/2048 [00:33<00:35, 27.61it/s, est. speed input: 32722.97 toks/s, output: 31.96 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1074/2048 [00:33<00:35, 27.62it/s, est. speed input: 32646.59 toks/s, output: 31.88 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1090/2048 [00:34<00:34, 27.62it/s, est. speed input: 32573.13 toks/s, output: 31.81 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1106/2048 [00:34<00:34, 27.61it/s, est. speed input: 32500.82 toks/s, output: 31.74 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1122/2048 [00:35<00:33, 27.60it/s, est. speed input: 32431.42 toks/s, output: 31.67 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1138/2048 [00:36<00:32, 27.60it/s, est. speed input: 32363.98 toks/s, output: 31.61 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1154/2048 [00:36<00:32, 27.59it/s, est. speed input: 32298.49 toks/s, output: 31.54 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1170/2048 [00:37<00:31, 27.59it/s, est. speed input: 32235.59 toks/s, output: 31.48 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1186/2048 [00:37<00:31, 27.59it/s, est. speed input: 32174.16 toks/s, output: 31.42 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1202/2048 [00:38<00:30, 27.60it/s, est. speed input: 32115.27 toks/s, output: 31.36 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1218/2048 [00:38<00:30, 27.56it/s, est. speed input: 32055.96 toks/s, output: 31.30 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1234/2048 [00:39<00:29, 27.57it/s, est. speed input: 31999.98 toks/s, output: 31.25 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1250/2048 [00:40<00:28, 27.57it/s, est. speed input: 31945.55 toks/s, output: 31.20 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1266/2048 [00:40<00:28, 27.58it/s, est. speed input: 31892.81 toks/s, output: 31.15 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1282/2048 [00:41<00:27, 27.58it/s, est. speed input: 31841.30 toks/s, output: 31.09 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1298/2048 [00:41<00:27, 27.56it/s, est. speed input: 31790.37 toks/s, output: 31.05 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1314/2048 [00:42<00:26, 27.58it/s, est. speed input: 31742.48 toks/s, output: 31.00 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1330/2048 [00:42<00:26, 27.56it/s, est. speed input: 31694.31 toks/s, output: 30.95 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1346/2048 [00:43<00:25, 27.58it/s, est. speed input: 31648.81 toks/s, output: 30.91 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1362/2048 [00:44<00:24, 27.57it/s, est. speed input: 31603.70 toks/s, output: 30.86 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1378/2048 [00:44<00:24, 27.57it/s, est. speed input: 31559.79 toks/s, output: 30.82 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1394/2048 [00:45<00:23, 27.58it/s, est. speed input: 31517.69 toks/s, output: 30.78 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1410/2048 [00:45<00:23, 27.58it/s, est. speed input: 31476.42 toks/s, output: 30.74 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1426/2048 [00:46<00:22, 27.59it/s, est. speed input: 31436.25 toks/s, output: 30.70 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1442/2048 [00:47<00:21, 27.59it/s, est. speed input: 31396.99 toks/s, output: 30.66 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1458/2048 [00:47<00:21, 27.58it/s, est. speed input: 31358.17 toks/s, output: 30.62 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1474/2048 [00:48<00:20, 27.57it/s, est. speed input: 31320.40 toks/s, output: 30.59 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1490/2048 [00:48<00:20, 27.58it/s, est. speed input: 31284.07 toks/s, output: 30.55 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1506/2048 [00:49<00:19, 27.58it/s, est. speed input: 31248.27 toks/s, output: 30.52 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1522/2048 [00:49<00:19, 27.59it/s, est. speed input: 31213.60 toks/s, output: 30.48 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1538/2048 [00:50<00:18, 27.59it/s, est. speed input: 31179.74 toks/s, output: 30.45 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1554/2048 [00:51<00:17, 28.05it/s, est. speed input: 31165.76 toks/s, output: 30.44 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1570/2048 [00:51<00:17, 27.92it/s, est. speed input: 31133.65 toks/s, output: 30.40 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1586/2048 [00:52<00:16, 27.81it/s, est. speed input: 31101.18 toks/s, output: 30.37 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1602/2048 [00:52<00:16, 27.74it/s, est. speed input: 31069.79 toks/s, output: 30.34 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1618/2048 [00:53<00:15, 28.13it/s, est. speed input: 31056.58 toks/s, output: 30.33 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1634/2048 [00:53<00:14, 27.93it/s, est. speed input: 31025.09 toks/s, output: 30.30 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1650/2048 [00:54<00:14, 27.83it/s, est. speed input: 30995.46 toks/s, output: 30.27 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1666/2048 [00:55<00:13, 27.73it/s, est. speed input: 30965.54 toks/s, output: 30.24 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1682/2048 [00:55<00:13, 27.65it/s, est. speed input: 30935.99 toks/s, output: 30.21 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1698/2048 [00:56<00:12, 27.64it/s, est. speed input: 30908.40 toks/s, output: 30.18 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1714/2048 [00:56<00:12, 27.58it/s, est. speed input: 30879.61 toks/s, output: 30.16 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1730/2048 [00:57<00:11, 27.58it/s, est. speed input: 30852.92 toks/s, output: 30.13 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1746/2048 [00:57<00:10, 27.57it/s, est. speed input: 30826.48 toks/s, output: 30.10 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1762/2048 [00:58<00:10, 27.56it/s, est. speed input: 30800.29 toks/s, output: 30.08 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1778/2048 [00:59<00:09, 27.54it/s, est. speed input: 30774.54 toks/s, output: 30.05 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1794/2048 [00:59<00:09, 27.53it/s, est. speed input: 30749.06 toks/s, output: 30.03 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1810/2048 [01:00<00:08, 27.51it/s, est. speed input: 30723.58 toks/s, output: 30.00 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1826/2048 [01:00<00:08, 27.49it/s, est. speed input: 30698.63 toks/s, output: 29.98 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1842/2048 [01:01<00:07, 27.48it/s, est. speed input: 30674.02 toks/s, output: 29.96 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1858/2048 [01:02<00:06, 27.46it/s, est. speed input: 30649.47 toks/s, output: 29.93 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1874/2048 [01:02<00:06, 27.46it/s, est. speed input: 30625.97 toks/s, output: 29.91 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1890/2048 [01:03<00:05, 27.48it/s, est. speed input: 30603.44 toks/s, output: 29.89 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1906/2048 [01:03<00:05, 27.48it/s, est. speed input: 30581.02 toks/s, output: 29.86 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1922/2048 [01:04<00:04, 27.48it/s, est. speed input: 30558.88 toks/s, output: 29.84 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1938/2048 [01:04<00:04, 27.46it/s, est. speed input: 30536.65 toks/s, output: 29.82 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1954/2048 [01:05<00:03, 27.45it/s, est. speed input: 30514.86 toks/s, output: 29.80 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1970/2048 [01:06<00:02, 27.44it/s, est. speed input: 30493.19 toks/s, output: 29.78 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1986/2048 [01:06<00:02, 27.45it/s, est. speed input: 30472.62 toks/s, output: 29.76 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2002/2048 [01:07<00:01, 27.45it/s, est. speed input: 30452.31 toks/s, output: 29.74 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2018/2048 [01:07<00:01, 27.48it/s, est. speed input: 30433.03 toks/s, output: 29.72 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2034/2048 [01:08<00:00, 27.96it/s, est. speed input: 30428.34 toks/s, output: 29.72 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [01:08<00:00, 27.96it/s, est. speed input: 30637.50 toks/s, output: 29.92 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [01:08<00:00, 29.92it/s, est. speed input: 30637.50 toks/s, output: 29.92 toks/s]
[rank0]:[W126 13:03:23.655333518 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 13:03:25
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:03:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1396735) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1396735) WARNING 01-26 13:04:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.87 requests/s, 28562.17 total tokens/s, 27.87 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 13:03:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:03:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:03:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:03:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:03:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:03:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:03:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:03:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:03:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:04:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:04:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:04:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:04:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:04:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:04:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:04:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:04:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:04:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.95it/s]
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.66it/s]
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.14it/s]
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.98it/s]
(EngineCore_DP0 pid=1396735) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.95it/s]
(EngineCore_DP0 pid=1396735) 
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1396735) [2026-01-26 13:04:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1396735) [rank0]:W0126 13:04:23.708000 1396735 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1396735) [rank0]:W0126 13:04:23.762000 1396735 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1396735) [rank0]:W0126 13:04:24.720000 1396735 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1396735) [rank0]:W0126 13:04:24.803000 1396735 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1396735) 2026-01-26 13:04:29,546 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1396735) 2026-01-26 13:04:29,927 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1396735) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 1/11 [00:00<00:06,  1.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 2/11 [00:01<00:04,  1.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:01<00:01,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [00:01<00:00,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:01<00:00,  7.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00,  6.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.73it/s]
(EngineCore_DP0 pid=1396735) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 1/7 [00:00<00:02,  2.49it/s]
Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00,  5.95it/s]
Capturing CUDA graphs (decode, FULL):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00,  6.98it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  7.14it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 247.08it/s]
Adding requests:   2%|â–         | 65/4096 [00:00<00:12, 333.57it/s]
Adding requests:   2%|â–         | 100/4096 [00:00<00:11, 340.78it/s]
Adding requests:   3%|â–Ž         | 137/4096 [00:00<00:11, 350.53it/s]
Adding requests:   4%|â–         | 176/4096 [00:00<00:10, 361.51it/s]
Adding requests:   5%|â–Œ         | 216/4096 [00:00<00:10, 372.18it/s]
Adding requests:   6%|â–Œ         | 254/4096 [00:00<00:10, 371.70it/s]
Adding requests:   7%|â–‹         | 293/4096 [00:00<00:10, 374.70it/s]
Adding requests:   8%|â–Š         | 333/4096 [00:00<00:09, 381.55it/s]
Adding requests:   9%|â–‰         | 373/4096 [00:01<00:09, 385.80it/s]
Adding requests:  10%|â–ˆ         | 413/4096 [00:01<00:09, 388.28it/s]
Adding requests:  11%|â–ˆ         | 452/4096 [00:01<00:09, 385.07it/s]
Adding requests:  12%|â–ˆâ–        | 494/4096 [00:01<00:09, 395.42it/s]
Adding requests:  13%|â–ˆâ–Ž        | 535/4096 [00:01<00:08, 398.07it/s]
Adding requests:  14%|â–ˆâ–        | 575/4096 [00:01<00:08, 394.63it/s]
Adding requests:  15%|â–ˆâ–Œ        | 615/4096 [00:01<00:09, 382.16it/s]
Adding requests:  16%|â–ˆâ–Œ        | 654/4096 [00:01<00:09, 375.89it/s]
Adding requests:  17%|â–ˆâ–‹        | 694/4096 [00:01<00:08, 382.78it/s]
Adding requests:  18%|â–ˆâ–Š        | 733/4096 [00:01<00:08, 378.05it/s]
Adding requests:  19%|â–ˆâ–‰        | 771/4096 [00:02<00:08, 377.37it/s]
Adding requests:  20%|â–ˆâ–‰        | 809/4096 [00:02<00:08, 378.01it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 850/4096 [00:02<00:08, 384.00it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 891/4096 [00:02<00:08, 388.57it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 930/4096 [00:02<00:08, 382.20it/s]
Adding requests:  24%|â–ˆâ–ˆâ–Ž       | 970/4096 [00:02<00:08, 384.13it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 1009/4096 [00:02<00:08, 378.43it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 1047/4096 [00:02<00:08, 376.85it/s]
Adding requests:  26%|â–ˆâ–ˆâ–‹       | 1085/4096 [00:02<00:07, 376.77it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 1124/4096 [00:02<00:07, 377.71it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 1162/4096 [00:03<00:07, 375.69it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 1200/4096 [00:03<00:07, 368.68it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 1240/4096 [00:03<00:07, 377.49it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 1278/4096 [00:03<00:07, 372.13it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 1317/4096 [00:03<00:07, 375.49it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1356/4096 [00:03<00:07, 379.30it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 1394/4096 [00:03<00:07, 378.73it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 1432/4096 [00:03<00:07, 378.59it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1471/4096 [00:03<00:06, 380.38it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1511/4096 [00:04<00:06, 386.18it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1550/4096 [00:04<00:06, 383.70it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1589/4096 [00:04<00:06, 377.84it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1627/4096 [00:04<00:06, 371.78it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1665/4096 [00:04<00:06, 365.41it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1705/4096 [00:04<00:06, 372.08it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1744/4096 [00:04<00:06, 376.23it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1784/4096 [00:04<00:06, 380.68it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1823/4096 [00:04<00:05, 378.90it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1862/4096 [00:04<00:05, 381.94it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1901/4096 [00:05<00:05, 381.90it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1943/4096 [00:05<00:05, 391.84it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1983/4096 [00:05<00:05, 391.46it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2023/4096 [00:05<00:05, 379.62it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2062/4096 [00:05<00:05, 378.04it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2100/4096 [00:05<00:05, 374.53it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2139/4096 [00:05<00:05, 377.83it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2177/4096 [00:05<00:05, 370.61it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2215/4096 [00:05<00:05, 369.43it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2255/4096 [00:05<00:04, 376.81it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2295/4096 [00:06<00:04, 381.81it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2334/4096 [00:06<00:04, 382.67it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2374/4096 [00:06<00:04, 386.78it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2416/4096 [00:06<00:04, 394.62it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2456/4096 [00:06<00:04, 379.99it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2495/4096 [00:06<00:04, 380.38it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2536/4096 [00:06<00:04, 387.85it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2577/4096 [00:06<00:03, 393.79it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2617/4096 [00:06<00:03, 388.49it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2656/4096 [00:07<00:03, 383.28it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2695/4096 [00:07<00:03, 379.11it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2734/4096 [00:07<00:03, 379.08it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2775/4096 [00:07<00:03, 385.17it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2816/4096 [00:07<00:03, 392.41it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2856/4096 [00:07<00:03, 390.64it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2896/4096 [00:07<00:03, 388.68it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2937/4096 [00:07<00:02, 393.57it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2977/4096 [00:07<00:02, 390.89it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3017/4096 [00:07<00:02, 391.90it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3057/4096 [00:08<00:02, 390.95it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3097/4096 [00:08<00:02, 391.50it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3137/4096 [00:08<00:02, 392.52it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3177/4096 [00:08<00:02, 382.67it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3216/4096 [00:08<00:02, 379.87it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3256/4096 [00:08<00:02, 384.77it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3295/4096 [00:08<00:02, 370.54it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3333/4096 [00:08<00:02, 369.37it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3374/4096 [00:08<00:01, 379.83it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3414/4096 [00:08<00:01, 383.31it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3453/4096 [00:09<00:01, 381.07it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3492/4096 [00:09<00:01, 379.28it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3534/4096 [00:09<00:01, 390.99it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3574/4096 [00:09<00:01, 392.31it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3615/4096 [00:09<00:01, 395.31it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3655/4096 [00:09<00:01, 392.50it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3695/4096 [00:09<00:01, 384.72it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3735/4096 [00:09<00:00, 387.16it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3774/4096 [00:09<00:00, 378.03it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3812/4096 [00:10<00:00, 356.53it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3851/4096 [00:10<00:00, 363.81it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3889/4096 [00:10<00:00, 365.75it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3926/4096 [00:10<00:00, 362.37it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3964/4096 [00:10<00:00, 366.37it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4001/4096 [00:10<00:00, 365.74it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4039/4096 [00:10<00:00, 369.89it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4077/4096 [00:10<00:00, 368.10it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:10<00:00, 379.13it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|â–‹         | 290/4096 [00:00<00:08, 427.78it/s, est. speed input: 438071.45 toks/s, output: 427.79 toks/s]
Processed prompts:   8%|â–Š         | 333/4096 [00:01<00:24, 152.69it/s, est. speed input: 187925.03 toks/s, output: 183.52 toks/s]
Processed prompts:   9%|â–Š         | 354/4096 [00:02<00:43, 85.38it/s, est. speed input: 122901.21 toks/s, output: 120.02 toks/s] 
Processed prompts:   9%|â–‰         | 386/4096 [00:04<01:00, 61.50it/s, est. speed input: 96762.11 toks/s, output: 94.49 toks/s]  
Processed prompts:  10%|â–ˆ         | 418/4096 [00:05<01:15, 49.04it/s, est. speed input: 81979.51 toks/s, output: 80.06 toks/s]
Processed prompts:  11%|â–ˆ         | 450/4096 [00:06<01:27, 41.76it/s, est. speed input: 72475.40 toks/s, output: 70.78 toks/s]
Processed prompts:  12%|â–ˆâ–        | 482/4096 [00:07<01:37, 37.20it/s, est. speed input: 65818.70 toks/s, output: 64.28 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 514/4096 [00:08<01:44, 34.26it/s, est. speed input: 60927.09 toks/s, output: 59.50 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 546/4096 [00:09<01:49, 32.34it/s, est. speed input: 57199.78 toks/s, output: 55.86 toks/s]
Processed prompts:  14%|â–ˆâ–        | 578/4096 [00:10<01:53, 31.03it/s, est. speed input: 54238.24 toks/s, output: 52.97 toks/s]
Processed prompts:  15%|â–ˆâ–        | 610/4096 [00:12<01:55, 30.14it/s, est. speed input: 51838.13 toks/s, output: 50.62 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 642/4096 [00:13<01:57, 29.51it/s, est. speed input: 49840.38 toks/s, output: 48.67 toks/s]
Processed prompts:  16%|â–ˆâ–‹        | 674/4096 [00:14<01:57, 29.07it/s, est. speed input: 48163.04 toks/s, output: 47.03 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 706/4096 [00:15<01:57, 28.77it/s, est. speed input: 46731.91 toks/s, output: 45.64 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 738/4096 [00:16<01:57, 28.55it/s, est. speed input: 45496.03 toks/s, output: 44.43 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 770/4096 [00:17<01:56, 28.63it/s, est. speed input: 44493.93 toks/s, output: 43.45 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 802/4096 [00:18<01:55, 28.47it/s, est. speed input: 43544.59 toks/s, output: 42.52 toks/s]
Processed prompts:  20%|â–ˆâ–ˆ        | 834/4096 [00:20<01:55, 28.34it/s, est. speed input: 42697.87 toks/s, output: 41.70 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 866/4096 [00:21<01:54, 28.24it/s, est. speed input: 41941.84 toks/s, output: 40.96 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 898/4096 [00:22<01:53, 28.17it/s, est. speed input: 41261.53 toks/s, output: 40.29 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 930/4096 [00:23<01:52, 28.12it/s, est. speed input: 40646.66 toks/s, output: 39.69 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 962/4096 [00:24<01:51, 28.08it/s, est. speed input: 40089.17 toks/s, output: 39.15 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 994/4096 [00:25<01:50, 28.05it/s, est. speed input: 39581.41 toks/s, output: 38.65 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 1026/4096 [00:26<01:49, 28.03it/s, est. speed input: 39115.50 toks/s, output: 38.20 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 1058/4096 [00:28<01:48, 28.01it/s, est. speed input: 38686.87 toks/s, output: 37.78 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 1090/4096 [00:29<01:47, 28.00it/s, est. speed input: 38293.49 toks/s, output: 37.40 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 1122/4096 [00:30<01:46, 27.99it/s, est. speed input: 37928.00 toks/s, output: 37.04 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 1154/4096 [00:31<01:45, 27.98it/s, est. speed input: 37589.15 toks/s, output: 36.71 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 1186/4096 [00:32<01:44, 27.97it/s, est. speed input: 37273.96 toks/s, output: 36.40 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 1218/4096 [00:33<01:42, 27.96it/s, est. speed input: 36980.17 toks/s, output: 36.11 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 1250/4096 [00:34<01:41, 27.96it/s, est. speed input: 36705.23 toks/s, output: 35.84 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆâ–      | 1282/4096 [00:36<01:40, 27.97it/s, est. speed input: 36450.35 toks/s, output: 35.60 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 1314/4096 [00:37<01:39, 27.95it/s, est. speed input: 36206.71 toks/s, output: 35.36 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1346/4096 [00:38<01:38, 27.94it/s, est. speed input: 35978.74 toks/s, output: 35.14 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1378/4096 [00:39<01:37, 27.92it/s, est. speed input: 35762.81 toks/s, output: 34.92 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 1410/4096 [00:40<01:36, 27.91it/s, est. speed input: 35559.49 toks/s, output: 34.73 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1442/4096 [00:41<01:35, 27.92it/s, est. speed input: 35368.98 toks/s, output: 34.54 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1474/4096 [00:42<01:33, 27.89it/s, est. speed input: 35184.78 toks/s, output: 34.36 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1506/4096 [00:44<01:32, 27.89it/s, est. speed input: 35011.32 toks/s, output: 34.19 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1538/4096 [00:45<01:31, 28.10it/s, est. speed input: 34870.12 toks/s, output: 34.05 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1570/4096 [00:46<01:30, 28.03it/s, est. speed input: 34713.16 toks/s, output: 33.90 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1602/4096 [00:47<01:28, 28.20it/s, est. speed input: 34585.00 toks/s, output: 33.77 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1634/4096 [00:48<01:27, 28.08it/s, est. speed input: 34440.12 toks/s, output: 33.63 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1666/4096 [00:49<01:26, 28.01it/s, est. speed input: 34303.36 toks/s, output: 33.50 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1698/4096 [00:50<01:25, 27.95it/s, est. speed input: 34171.77 toks/s, output: 33.37 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1730/4096 [00:52<01:24, 27.93it/s, est. speed input: 34048.04 toks/s, output: 33.25 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1762/4096 [00:53<01:23, 27.88it/s, est. speed input: 33926.21 toks/s, output: 33.13 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1794/4096 [00:54<01:22, 27.87it/s, est. speed input: 33811.62 toks/s, output: 33.02 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1826/4096 [00:55<01:21, 27.85it/s, est. speed input: 33700.86 toks/s, output: 32.91 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1858/4096 [00:56<01:20, 27.85it/s, est. speed input: 33595.32 toks/s, output: 32.81 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1890/4096 [00:57<01:19, 27.84it/s, est. speed input: 33493.92 toks/s, output: 32.71 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1922/4096 [00:58<01:18, 27.82it/s, est. speed input: 33395.31 toks/s, output: 32.61 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1954/4096 [01:00<01:17, 27.81it/s, est. speed input: 33300.31 toks/s, output: 32.52 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1986/4096 [01:01<01:15, 27.81it/s, est. speed input: 33209.47 toks/s, output: 32.43 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2018/4096 [01:02<01:14, 27.80it/s, est. speed input: 33121.79 toks/s, output: 32.35 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2050/4096 [01:03<01:13, 27.79it/s, est. speed input: 33036.76 toks/s, output: 32.26 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2082/4096 [01:04<01:12, 27.79it/s, est. speed input: 32954.87 toks/s, output: 32.18 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2114/4096 [01:05<01:11, 27.77it/s, est. speed input: 32875.33 toks/s, output: 32.10 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2146/4096 [01:06<01:10, 27.78it/s, est. speed input: 32799.47 toks/s, output: 32.03 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2178/4096 [01:08<01:08, 27.99it/s, est. speed input: 32739.93 toks/s, output: 31.97 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2210/4096 [01:09<01:07, 27.92it/s, est. speed input: 32667.80 toks/s, output: 31.90 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2242/4096 [01:10<01:06, 27.88it/s, est. speed input: 32598.73 toks/s, output: 31.83 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2274/4096 [01:11<01:05, 27.84it/s, est. speed input: 32531.70 toks/s, output: 31.77 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2306/4096 [01:12<01:04, 27.80it/s, est. speed input: 32465.35 toks/s, output: 31.70 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2338/4096 [01:13<01:03, 27.79it/s, est. speed input: 32402.33 toks/s, output: 31.64 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2370/4096 [01:15<01:02, 27.76it/s, est. speed input: 32339.90 toks/s, output: 31.58 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2402/4096 [01:16<01:01, 27.76it/s, est. speed input: 32280.61 toks/s, output: 31.52 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2434/4096 [01:17<00:59, 27.74it/s, est. speed input: 32222.20 toks/s, output: 31.47 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2466/4096 [01:18<00:58, 27.72it/s, est. speed input: 32164.90 toks/s, output: 31.41 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2498/4096 [01:19<00:57, 27.71it/s, est. speed input: 32109.84 toks/s, output: 31.36 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2530/4096 [01:20<00:56, 27.71it/s, est. speed input: 32056.30 toks/s, output: 31.30 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2562/4096 [01:21<00:55, 27.73it/s, est. speed input: 32005.40 toks/s, output: 31.26 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2594/4096 [01:23<00:54, 27.74it/s, est. speed input: 31956.05 toks/s, output: 31.21 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2626/4096 [01:24<00:52, 27.74it/s, est. speed input: 31907.61 toks/s, output: 31.16 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2658/4096 [01:25<00:51, 27.74it/s, est. speed input: 31860.04 toks/s, output: 31.11 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2690/4096 [01:26<00:50, 27.73it/s, est. speed input: 31813.79 toks/s, output: 31.07 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2722/4096 [01:27<00:49, 27.72it/s, est. speed input: 31768.25 toks/s, output: 31.02 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2754/4096 [01:28<00:48, 27.71it/s, est. speed input: 31723.65 toks/s, output: 30.98 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2786/4096 [01:30<00:47, 27.71it/s, est. speed input: 31680.65 toks/s, output: 30.94 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2818/4096 [01:31<00:46, 27.70it/s, est. speed input: 31638.25 toks/s, output: 30.90 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2850/4096 [01:32<00:45, 27.69it/s, est. speed input: 31596.75 toks/s, output: 30.86 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2882/4096 [01:33<00:43, 27.90it/s, est. speed input: 31566.82 toks/s, output: 30.83 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2914/4096 [01:34<00:42, 27.83it/s, est. speed input: 31526.96 toks/s, output: 30.79 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2946/4096 [01:35<00:41, 27.78it/s, est. speed input: 31488.55 toks/s, output: 30.75 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2978/4096 [01:36<00:40, 27.75it/s, est. speed input: 31451.00 toks/s, output: 30.71 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3010/4096 [01:38<00:39, 27.73it/s, est. speed input: 31414.24 toks/s, output: 30.68 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3042/4096 [01:39<00:38, 27.72it/s, est. speed input: 31378.74 toks/s, output: 30.64 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3074/4096 [01:40<00:36, 27.70it/s, est. speed input: 31343.57 toks/s, output: 30.61 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3106/4096 [01:41<00:35, 27.70it/s, est. speed input: 31309.59 toks/s, output: 30.58 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3138/4096 [01:42<00:34, 27.69it/s, est. speed input: 31276.25 toks/s, output: 30.54 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3170/4096 [01:43<00:33, 27.69it/s, est. speed input: 31243.73 toks/s, output: 30.51 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3202/4096 [01:45<00:32, 27.68it/s, est. speed input: 31211.67 toks/s, output: 30.48 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3234/4096 [01:46<00:31, 27.68it/s, est. speed input: 31180.39 toks/s, output: 30.45 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3266/4096 [01:47<00:29, 27.68it/s, est. speed input: 31149.76 toks/s, output: 30.42 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3298/4096 [01:48<00:28, 27.68it/s, est. speed input: 31119.96 toks/s, output: 30.39 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3330/4096 [01:49<00:27, 27.68it/s, est. speed input: 31090.67 toks/s, output: 30.36 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3362/4096 [01:50<00:26, 27.69it/s, est. speed input: 31062.27 toks/s, output: 30.33 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3394/4096 [01:51<00:25, 27.68it/s, est. speed input: 31034.04 toks/s, output: 30.31 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3426/4096 [01:53<00:24, 27.68it/s, est. speed input: 31006.67 toks/s, output: 30.28 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3458/4096 [01:54<00:23, 27.68it/s, est. speed input: 30979.79 toks/s, output: 30.25 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3490/4096 [01:55<00:21, 27.68it/s, est. speed input: 30953.31 toks/s, output: 30.23 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3522/4096 [01:56<00:20, 27.68it/s, est. speed input: 30927.59 toks/s, output: 30.20 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3554/4096 [01:57<00:19, 27.68it/s, est. speed input: 30902.15 toks/s, output: 30.18 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3586/4096 [01:58<00:18, 27.67it/s, est. speed input: 30876.92 toks/s, output: 30.15 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3618/4096 [02:00<00:17, 27.65it/s, est. speed input: 30851.79 toks/s, output: 30.13 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3650/4096 [02:01<00:16, 27.64it/s, est. speed input: 30827.13 toks/s, output: 30.10 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3682/4096 [02:02<00:14, 27.86it/s, est. speed input: 30810.80 toks/s, output: 30.09 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3714/4096 [02:03<00:13, 27.79it/s, est. speed input: 30787.37 toks/s, output: 30.07 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3746/4096 [02:04<00:12, 27.76it/s, est. speed input: 30764.66 toks/s, output: 30.04 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3778/4096 [02:05<00:11, 27.74it/s, est. speed input: 30742.57 toks/s, output: 30.02 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3810/4096 [02:06<00:10, 27.73it/s, est. speed input: 30720.90 toks/s, output: 30.00 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3842/4096 [02:08<00:09, 27.71it/s, est. speed input: 30699.42 toks/s, output: 29.98 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3874/4096 [02:09<00:08, 27.67it/s, est. speed input: 30677.44 toks/s, output: 29.96 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3906/4096 [02:10<00:06, 27.88it/s, est. speed input: 30663.47 toks/s, output: 29.94 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3938/4096 [02:11<00:05, 27.82it/s, est. speed input: 30642.96 toks/s, output: 29.92 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3970/4096 [02:12<00:04, 27.77it/s, est. speed input: 30622.90 toks/s, output: 29.91 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4002/4096 [02:13<00:03, 27.74it/s, est. speed input: 30603.17 toks/s, output: 29.89 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4034/4096 [02:15<00:02, 27.73it/s, est. speed input: 30583.98 toks/s, output: 29.87 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4066/4096 [02:16<00:01, 27.99it/s, est. speed input: 30573.32 toks/s, output: 29.86 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [02:16<00:00, 27.99it/s, est. speed input: 30798.69 toks/s, output: 30.08 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [02:16<00:00, 30.08it/s, est. speed input: 30798.69 toks/s, output: 30.08 toks/s]
[rank0]:[W126 13:07:02.442169859 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 13:07:04
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:07:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1400341) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1400341) WARNING 01-26 13:08:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.85 requests/s, 28547.13 total tokens/s, 27.85 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 13:07:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:07:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:07:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:07:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:07:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:07:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:07:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:07:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:07:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:08:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:08:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:08:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:08:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:08:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:08:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:08:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:08:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:08:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.95it/s]
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
(EngineCore_DP0 pid=1400341) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1400341) 
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 22937600 bytes
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16384000 bytes
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 88473600 bytes
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1400341) [2026-01-26 13:08:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44236800 bytes
(EngineCore_DP0 pid=1400341) [rank0]:W0126 13:08:25.883000 1400341 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1400341) [rank0]:W0126 13:08:25.937000 1400341 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1400341) [rank0]:W0126 13:08:26.782000 1400341 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1400341) [rank0]:W0126 13:08:26.865000 1400341 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1400341) 2026-01-26 13:08:31,658 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1400341) 2026-01-26 13:08:32,321 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1400341) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|â–Œ         | 1/19 [00:00<00:15,  1.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  4.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  4.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:02,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  4.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:03<00:01,  4.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  6.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  4.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.38it/s]
(EngineCore_DP0 pid=1400341) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 1/11 [00:00<00:01,  9.99it/s]
Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 3/11 [00:00<00:00, 11.63it/s]
Capturing CUDA graphs (decode, FULL):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [00:00<00:00, 11.88it/s]
Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 7/11 [00:00<00:00, 12.08it/s]
Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [00:01<00:00,  4.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  5.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.69it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 31/8192 [00:00<00:26, 303.69it/s]
Adding requests:   1%|          | 70/8192 [00:00<00:23, 352.68it/s]
Adding requests:   1%|â–         | 107/8192 [00:00<00:22, 359.01it/s]
Adding requests:   2%|â–         | 144/8192 [00:00<00:22, 361.71it/s]
Adding requests:   2%|â–         | 184/8192 [00:00<00:21, 374.44it/s]
Adding requests:   3%|â–Ž         | 224/8192 [00:00<00:21, 378.74it/s]
Adding requests:   3%|â–Ž         | 262/8192 [00:00<00:21, 376.98it/s]
Adding requests:   4%|â–Ž         | 301/8192 [00:00<00:20, 380.23it/s]
Adding requests:   4%|â–         | 341/8192 [00:00<00:20, 385.55it/s]
Adding requests:   5%|â–         | 380/8192 [00:01<00:20, 386.69it/s]
Adding requests:   5%|â–Œ         | 421/8192 [00:01<00:19, 393.35it/s]
Adding requests:   6%|â–Œ         | 461/8192 [00:01<00:19, 388.57it/s]
Adding requests:   6%|â–Œ         | 503/8192 [00:01<00:19, 397.41it/s]
Adding requests:   7%|â–‹         | 545/8192 [00:01<00:19, 401.58it/s]
Adding requests:   7%|â–‹         | 586/8192 [00:01<00:19, 395.70it/s]
Adding requests:   8%|â–Š         | 626/8192 [00:01<00:19, 386.63it/s]
Adding requests:   8%|â–Š         | 665/8192 [00:01<00:19, 379.45it/s]
Adding requests:   9%|â–Š         | 705/8192 [00:01<00:19, 383.61it/s]
Adding requests:   9%|â–‰         | 744/8192 [00:01<00:19, 378.70it/s]
Adding requests:  10%|â–‰         | 783/8192 [00:02<00:19, 381.44it/s]
Adding requests:  10%|â–ˆ         | 822/8192 [00:02<00:19, 381.88it/s]
Adding requests:  11%|â–ˆ         | 862/8192 [00:02<00:18, 386.65it/s]
Adding requests:  11%|â–ˆ         | 902/8192 [00:02<00:18, 389.32it/s]
Adding requests:  11%|â–ˆâ–        | 941/8192 [00:02<00:18, 383.98it/s]
Adding requests:  12%|â–ˆâ–        | 980/8192 [00:02<00:18, 382.40it/s]
Adding requests:  12%|â–ˆâ–        | 1019/8192 [00:02<00:19, 376.47it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1057/8192 [00:02<00:18, 376.25it/s]
Adding requests:  13%|â–ˆâ–Ž        | 1095/8192 [00:02<00:18, 374.68it/s]
Adding requests:  14%|â–ˆâ–        | 1136/8192 [00:02<00:18, 382.80it/s]
Adding requests:  14%|â–ˆâ–        | 1175/8192 [00:03<00:18, 379.60it/s]
Adding requests:  15%|â–ˆâ–        | 1214/8192 [00:03<00:18, 380.99it/s]
Adding requests:  15%|â–ˆâ–Œ        | 1254/8192 [00:03<00:18, 385.02it/s]
Adding requests:  16%|â–ˆâ–Œ        | 1293/8192 [00:03<00:18, 377.63it/s]
Adding requests:  16%|â–ˆâ–‹        | 1333/8192 [00:03<00:18, 381.00it/s]
Adding requests:  17%|â–ˆâ–‹        | 1374/8192 [00:03<00:17, 387.80it/s]
Adding requests:  17%|â–ˆâ–‹        | 1413/8192 [00:03<00:17, 383.78it/s]
Adding requests:  18%|â–ˆâ–Š        | 1452/8192 [00:03<00:17, 383.83it/s]
Adding requests:  18%|â–ˆâ–Š        | 1493/8192 [00:03<00:17, 389.32it/s]
Adding requests:  19%|â–ˆâ–Š        | 1532/8192 [00:04<00:17, 386.74it/s]
Adding requests:  19%|â–ˆâ–‰        | 1571/8192 [00:04<00:17, 379.78it/s]
Adding requests:  20%|â–ˆâ–‰        | 1610/8192 [00:04<00:17, 378.86it/s]
Adding requests:  20%|â–ˆâ–ˆ        | 1648/8192 [00:04<00:17, 368.70it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 1685/8192 [00:04<00:17, 368.51it/s]
Adding requests:  21%|â–ˆâ–ˆ        | 1723/8192 [00:04<00:17, 371.84it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1763/8192 [00:04<00:16, 379.06it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1801/8192 [00:04<00:17, 371.97it/s]
Adding requests:  22%|â–ˆâ–ˆâ–       | 1840/8192 [00:04<00:16, 376.32it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1879/8192 [00:04<00:16, 378.98it/s]
Adding requests:  23%|â–ˆâ–ˆâ–Ž       | 1919/8192 [00:05<00:16, 383.81it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 1960/8192 [00:05<00:16, 388.24it/s]
Adding requests:  24%|â–ˆâ–ˆâ–       | 1999/8192 [00:05<00:16, 382.13it/s]
Adding requests:  25%|â–ˆâ–ˆâ–       | 2038/8192 [00:05<00:16, 377.37it/s]
Adding requests:  25%|â–ˆâ–ˆâ–Œ       | 2076/8192 [00:05<00:16, 369.73it/s]
Adding requests:  26%|â–ˆâ–ˆâ–Œ       | 2116/8192 [00:05<00:16, 377.45it/s]
Adding requests:  26%|â–ˆâ–ˆâ–‹       | 2154/8192 [00:05<00:16, 375.54it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2192/8192 [00:05<00:16, 369.85it/s]
Adding requests:  27%|â–ˆâ–ˆâ–‹       | 2230/8192 [00:05<00:16, 369.93it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2271/8192 [00:05<00:15, 379.39it/s]
Adding requests:  28%|â–ˆâ–ˆâ–Š       | 2310/8192 [00:06<00:15, 380.19it/s]
Adding requests:  29%|â–ˆâ–ˆâ–Š       | 2352/8192 [00:06<00:15, 388.92it/s]
Adding requests:  29%|â–ˆâ–ˆâ–‰       | 2392/8192 [00:06<00:14, 391.85it/s]
Adding requests:  30%|â–ˆâ–ˆâ–‰       | 2432/8192 [00:06<00:14, 391.75it/s]
Adding requests:  30%|â–ˆâ–ˆâ–ˆ       | 2472/8192 [00:06<00:14, 390.03it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2512/8192 [00:06<00:14, 391.01it/s]
Adding requests:  31%|â–ˆâ–ˆâ–ˆ       | 2554/8192 [00:06<00:14, 397.89it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2596/8192 [00:06<00:13, 404.24it/s]
Adding requests:  32%|â–ˆâ–ˆâ–ˆâ–      | 2637/8192 [00:06<00:14, 390.31it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2677/8192 [00:07<00:14, 388.91it/s]
Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2716/8192 [00:07<00:14, 382.60it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2757/8192 [00:07<00:13, 388.28it/s]
Adding requests:  34%|â–ˆâ–ˆâ–ˆâ–      | 2799/8192 [00:07<00:13, 395.54it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–      | 2839/8192 [00:07<00:13, 393.82it/s]
Adding requests:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2879/8192 [00:07<00:13, 391.59it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2919/8192 [00:07<00:13, 389.64it/s]
Adding requests:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2961/8192 [00:07<00:13, 395.27it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3001/8192 [00:07<00:13, 393.97it/s]
Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3043/8192 [00:07<00:12, 398.37it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3083/8192 [00:08<00:12, 397.90it/s]
Adding requests:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3123/8192 [00:08<00:12, 390.18it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3163/8192 [00:08<00:13, 386.36it/s]
Adding requests:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3202/8192 [00:08<00:13, 382.40it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3243/8192 [00:08<00:12, 387.71it/s]
Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3282/8192 [00:08<00:12, 382.95it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3321/8192 [00:08<00:12, 378.02it/s]
Adding requests:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3360/8192 [00:08<00:12, 379.01it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3401/8192 [00:08<00:12, 385.92it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3441/8192 [00:08<00:12, 388.01it/s]
Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3481/8192 [00:09<00:12, 389.60it/s]
Adding requests:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3521/8192 [00:09<00:11, 391.01it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3564/8192 [00:09<00:11, 400.52it/s]
Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3605/8192 [00:09<00:11, 392.28it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3646/8192 [00:09<00:11, 395.86it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3686/8192 [00:09<00:11, 384.07it/s]
Adding requests:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3726/8192 [00:09<00:11, 386.04it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3765/8192 [00:09<00:11, 377.96it/s]
Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3803/8192 [00:09<00:11, 367.25it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3842/8192 [00:10<00:11, 371.30it/s]
Adding requests:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3881/8192 [00:10<00:11, 373.57it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3919/8192 [00:10<00:11, 367.21it/s]
Adding requests:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3958/8192 [00:10<00:11, 371.81it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 3996/8192 [00:10<00:11, 371.17it/s]
Adding requests:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4034/8192 [00:10<00:11, 371.38it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4072/8192 [00:10<00:11, 371.84it/s]
Adding requests:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4111/8192 [00:10<00:10, 375.71it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4149/8192 [00:10<00:10, 374.11it/s]
Adding requests:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4188/8192 [00:10<00:10, 377.25it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4226/8192 [00:11<00:10, 375.13it/s]
Adding requests:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4265/8192 [00:11<00:10, 378.17it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4303/8192 [00:11<00:10, 378.15it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4341/8192 [00:11<00:10, 376.54it/s]
Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4381/8192 [00:11<00:09, 383.14it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4420/8192 [00:11<00:09, 382.85it/s]
Adding requests:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4459/8192 [00:11<00:09, 383.07it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4498/8192 [00:11<00:09, 369.86it/s]
Adding requests:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4538/8192 [00:11<00:09, 377.83it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4576/8192 [00:11<00:09, 377.48it/s]
Adding requests:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4614/8192 [00:12<00:09, 377.44it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4652/8192 [00:12<00:09, 373.83it/s]
Adding requests:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4690/8192 [00:12<00:09, 368.58it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4731/8192 [00:12<00:09, 377.97it/s]
Adding requests:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4771/8192 [00:12<00:08, 381.97it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4810/8192 [00:12<00:08, 378.60it/s]
Adding requests:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4848/8192 [00:12<00:08, 373.25it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4886/8192 [00:12<00:08, 374.27it/s]
Adding requests:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4925/8192 [00:12<00:08, 378.41it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4965/8192 [00:13<00:08, 382.60it/s]
Adding requests:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 5004/8192 [00:13<00:08, 381.55it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5045/8192 [00:13<00:08, 388.61it/s]
Adding requests:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5084/8192 [00:13<00:08, 385.98it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5123/8192 [00:13<00:07, 386.50it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5162/8192 [00:13<00:07, 386.71it/s]
Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5201/8192 [00:13<00:07, 378.39it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5240/8192 [00:13<00:07, 381.58it/s]
Adding requests:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5279/8192 [00:13<00:07, 380.44it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5318/8192 [00:13<00:07, 378.07it/s]
Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5358/8192 [00:14<00:07, 382.96it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5397/8192 [00:14<00:07, 377.96it/s]
Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5435/8192 [00:14<00:07, 374.16it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5476/8192 [00:14<00:07, 381.71it/s]
Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5517/8192 [00:14<00:06, 386.67it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5556/8192 [00:14<00:06, 384.38it/s]
Adding requests:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5595/8192 [00:14<00:06, 379.85it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5635/8192 [00:14<00:06, 382.91it/s]
Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5674/8192 [00:14<00:06, 384.06it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5713/8192 [00:14<00:06, 383.15it/s]
Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5752/8192 [00:15<00:06, 381.49it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5791/8192 [00:15<00:06, 381.97it/s]
Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5831/8192 [00:15<00:06, 378.17it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5870/8192 [00:15<00:06, 379.22it/s]
Adding requests:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5909/8192 [00:15<00:05, 380.70it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5949/8192 [00:15<00:05, 384.95it/s]
Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5990/8192 [00:15<00:05, 390.27it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6030/8192 [00:15<00:05, 389.63it/s]
Adding requests:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6069/8192 [00:15<00:05, 386.22it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6108/8192 [00:15<00:05, 379.53it/s]
Adding requests:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6149/8192 [00:16<00:05, 386.35it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6188/8192 [00:16<00:05, 384.36it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6227/8192 [00:16<00:05, 381.28it/s]
Adding requests:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6266/8192 [00:16<00:05, 382.79it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6305/8192 [00:16<00:04, 384.07it/s]
Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6347/8192 [00:16<00:04, 393.23it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6387/8192 [00:16<00:04, 390.07it/s]
Adding requests:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6427/8192 [00:16<00:04, 378.23it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6465/8192 [00:16<00:04, 374.31it/s]
Adding requests:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6503/8192 [00:17<00:04, 373.50it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6542/8192 [00:17<00:04, 376.43it/s]
Adding requests:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6582/8192 [00:17<00:04, 379.95it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6621/8192 [00:17<00:04, 379.88it/s]
Adding requests:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6660/8192 [00:17<00:04, 382.84it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6699/8192 [00:17<00:03, 380.08it/s]
Adding requests:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6739/8192 [00:17<00:03, 383.98it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6780/8192 [00:17<00:03, 389.63it/s]
Adding requests:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6819/8192 [00:17<00:03, 379.17it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6857/8192 [00:17<00:03, 378.03it/s]
Adding requests:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6896/8192 [00:18<00:03, 381.45it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6936/8192 [00:18<00:03, 385.61it/s]
Adding requests:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6975/8192 [00:18<00:03, 378.27it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7016/8192 [00:18<00:03, 385.97it/s]
Adding requests:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7055/8192 [00:18<00:02, 382.04it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7094/8192 [00:18<00:02, 378.73it/s]
Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7133/8192 [00:18<00:02, 381.21it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7172/8192 [00:18<00:02, 381.83it/s]
Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7211/8192 [00:18<00:02, 376.36it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7250/8192 [00:18<00:02, 380.25it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7291/8192 [00:19<00:02, 387.28it/s]
Adding requests:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7330/8192 [00:19<00:02, 382.29it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7370/8192 [00:19<00:02, 385.07it/s]
Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7409/8192 [00:19<00:02, 383.23it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7448/8192 [00:19<00:01, 381.71it/s]
Adding requests:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7487/8192 [00:19<00:01, 378.51it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7527/8192 [00:19<00:01, 382.54it/s]
Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7566/8192 [00:19<00:01, 383.84it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7605/8192 [00:19<00:01, 380.07it/s]
Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7645/8192 [00:20<00:01, 383.21it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7687/8192 [00:20<00:01, 393.33it/s]
Adding requests:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7727/8192 [00:20<00:01, 389.66it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7766/8192 [00:20<00:01, 386.35it/s]
Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7805/8192 [00:20<00:01, 384.97it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7844/8192 [00:20<00:00, 377.32it/s]
Adding requests:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7882/8192 [00:20<00:00, 376.43it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7924/8192 [00:20<00:00, 387.75it/s]
Adding requests:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7964/8192 [00:20<00:00, 390.13it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8004/8192 [00:20<00:00, 392.91it/s]
Adding requests:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8044/8192 [00:21<00:00, 386.01it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8084/8192 [00:21<00:00, 388.88it/s]
Adding requests:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8123/8192 [00:21<00:00, 380.55it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8162/8192 [00:21<00:00, 380.68it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [00:21<00:00, 382.08it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|â–‹         | 546/8192 [00:00<00:03, 1918.41it/s, est. speed input: 1964616.04 toks/s, output: 1918.46 toks/s]
Processed prompts:   9%|â–‰         | 738/8192 [00:07<01:30, 82.55it/s, est. speed input: 107332.43 toks/s, output: 104.82 toks/s]    
Processed prompts:  10%|â–‰         | 819/8192 [00:09<01:48, 67.67it/s, est. speed input: 90094.81 toks/s, output: 87.98 toks/s]  
Processed prompts:  11%|â–ˆ         | 866/8192 [00:11<02:18, 53.01it/s, est. speed input: 76599.53 toks/s, output: 74.80 toks/s]
Processed prompts:  11%|â–ˆâ–        | 930/8192 [00:13<02:40, 45.36it/s, est. speed input: 68784.17 toks/s, output: 67.17 toks/s]
Processed prompts:  12%|â–ˆâ–        | 994/8192 [00:16<02:59, 40.09it/s, est. speed input: 63147.81 toks/s, output: 61.67 toks/s]
Processed prompts:  13%|â–ˆâ–Ž        | 1058/8192 [00:18<03:15, 36.46it/s, est. speed input: 58906.37 toks/s, output: 57.53 toks/s]
Processed prompts:  14%|â–ˆâ–Ž        | 1122/8192 [00:20<03:28, 33.93it/s, est. speed input: 55591.21 toks/s, output: 54.29 toks/s]
Processed prompts:  14%|â–ˆâ–        | 1186/8192 [00:22<03:37, 32.18it/s, est. speed input: 52935.74 toks/s, output: 51.69 toks/s]
Processed prompts:  15%|â–ˆâ–Œ        | 1250/8192 [00:25<03:44, 30.94it/s, est. speed input: 50751.02 toks/s, output: 49.56 toks/s]
Processed prompts:  16%|â–ˆâ–Œ        | 1314/8192 [00:27<03:48, 30.09it/s, est. speed input: 48931.74 toks/s, output: 47.78 toks/s]
Processed prompts:  17%|â–ˆâ–‹        | 1378/8192 [00:29<03:51, 29.47it/s, est. speed input: 47380.45 toks/s, output: 46.27 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 1442/8192 [00:32<03:52, 29.04it/s, est. speed input: 46053.71 toks/s, output: 44.97 toks/s]
Processed prompts:  18%|â–ˆâ–Š        | 1506/8192 [00:34<03:51, 28.87it/s, est. speed input: 44944.36 toks/s, output: 43.89 toks/s]
Processed prompts:  19%|â–ˆâ–‰        | 1570/8192 [00:36<03:50, 28.72it/s, est. speed input: 43963.86 toks/s, output: 42.93 toks/s]
Processed prompts:  20%|â–ˆâ–‰        | 1634/8192 [00:38<03:50, 28.49it/s, est. speed input: 43061.50 toks/s, output: 42.05 toks/s]
Processed prompts:  21%|â–ˆâ–ˆ        | 1698/8192 [00:41<03:49, 28.32it/s, est. speed input: 42256.02 toks/s, output: 41.27 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 1762/8192 [00:43<03:48, 28.20it/s, est. speed input: 41533.47 toks/s, output: 40.56 toks/s]
Processed prompts:  22%|â–ˆâ–ˆâ–       | 1826/8192 [00:45<03:46, 28.11it/s, est. speed input: 40884.27 toks/s, output: 39.93 toks/s]
Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 1890/8192 [00:48<03:44, 28.06it/s, est. speed input: 40299.15 toks/s, output: 39.35 toks/s]
Processed prompts:  24%|â–ˆâ–ˆâ–       | 1954/8192 [00:50<03:42, 28.01it/s, est. speed input: 39764.20 toks/s, output: 38.83 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–       | 2018/8192 [00:52<03:40, 27.98it/s, est. speed input: 39275.81 toks/s, output: 38.36 toks/s]
Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 2082/8192 [00:54<03:38, 27.94it/s, est. speed input: 38826.44 toks/s, output: 37.92 toks/s]
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 2146/8192 [00:57<03:35, 28.03it/s, est. speed input: 38433.59 toks/s, output: 37.53 toks/s]
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 2210/8192 [00:59<03:33, 27.98it/s, est. speed input: 38051.69 toks/s, output: 37.16 toks/s]
Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 2274/8192 [01:01<03:31, 27.94it/s, est. speed input: 37696.33 toks/s, output: 36.81 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–Š       | 2338/8192 [01:04<03:29, 27.90it/s, est. speed input: 37365.44 toks/s, output: 36.49 toks/s]
Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 2402/8192 [01:06<03:27, 27.87it/s, est. speed input: 37056.32 toks/s, output: 36.19 toks/s]
Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 2466/8192 [01:08<03:25, 27.86it/s, est. speed input: 36770.25 toks/s, output: 35.91 toks/s]
Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 2530/8192 [01:10<03:23, 27.83it/s, est. speed input: 36499.38 toks/s, output: 35.64 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 2594/8192 [01:13<03:21, 27.83it/s, est. speed input: 36248.53 toks/s, output: 35.40 toks/s]
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 2658/8192 [01:15<03:18, 27.84it/s, est. speed input: 36013.94 toks/s, output: 35.17 toks/s]
Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2722/8192 [01:17<03:16, 27.84it/s, est. speed input: 35791.71 toks/s, output: 34.95 toks/s]
Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 2786/8192 [01:20<03:14, 27.82it/s, est. speed input: 35580.95 toks/s, output: 34.75 toks/s]
Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 2850/8192 [01:22<03:11, 27.94it/s, est. speed input: 35396.87 toks/s, output: 34.57 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2914/8192 [01:24<03:09, 27.88it/s, est. speed input: 35206.92 toks/s, output: 34.38 toks/s]
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 2978/8192 [01:27<03:07, 27.86it/s, est. speed input: 35028.93 toks/s, output: 34.21 toks/s]
Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3042/8192 [01:29<03:05, 27.84it/s, est. speed input: 34859.28 toks/s, output: 34.04 toks/s]
Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3106/8192 [01:31<03:02, 27.82it/s, est. speed input: 34698.17 toks/s, output: 33.88 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3170/8192 [01:33<03:00, 27.82it/s, est. speed input: 34545.87 toks/s, output: 33.74 toks/s]
Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3234/8192 [01:36<02:58, 27.81it/s, est. speed input: 34400.33 toks/s, output: 33.59 toks/s]
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3298/8192 [01:38<02:56, 27.79it/s, est. speed input: 34259.76 toks/s, output: 33.46 toks/s]
Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3362/8192 [01:40<02:53, 27.78it/s, est. speed input: 34126.31 toks/s, output: 33.33 toks/s]
Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3426/8192 [01:43<02:51, 27.78it/s, est. speed input: 33999.38 toks/s, output: 33.20 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3490/8192 [01:45<02:49, 27.77it/s, est. speed input: 33877.16 toks/s, output: 33.08 toks/s]
Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3554/8192 [01:47<02:47, 27.76it/s, est. speed input: 33759.81 toks/s, output: 32.97 toks/s]
Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3618/8192 [01:50<02:44, 27.75it/s, est. speed input: 33647.20 toks/s, output: 32.86 toks/s]
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3682/8192 [01:52<02:41, 27.84it/s, est. speed input: 33547.61 toks/s, output: 32.76 toks/s]
Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3746/8192 [01:54<02:40, 27.78it/s, est. speed input: 33441.66 toks/s, output: 32.66 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3810/8192 [01:57<02:37, 27.75it/s, est. speed input: 33341.00 toks/s, output: 32.56 toks/s]
Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3874/8192 [01:59<02:35, 27.85it/s, est. speed input: 33253.67 toks/s, output: 32.47 toks/s]
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 3938/8192 [02:01<02:32, 27.82it/s, est. speed input: 33161.77 toks/s, output: 32.38 toks/s]
Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4002/8192 [02:03<02:30, 27.78it/s, est. speed input: 33072.40 toks/s, output: 32.30 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4066/8192 [02:06<02:28, 27.87it/s, est. speed input: 32994.06 toks/s, output: 32.22 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4130/8192 [02:08<02:26, 27.82it/s, est. speed input: 32910.94 toks/s, output: 32.14 toks/s]
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4194/8192 [02:10<02:23, 27.79it/s, est. speed input: 32831.33 toks/s, output: 32.06 toks/s]
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4258/8192 [02:13<02:21, 27.77it/s, est. speed input: 32754.04 toks/s, output: 31.99 toks/s]
Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4322/8192 [02:15<02:19, 27.76it/s, est. speed input: 32679.81 toks/s, output: 31.91 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4386/8192 [02:17<02:17, 27.74it/s, est. speed input: 32607.72 toks/s, output: 31.84 toks/s]
Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4450/8192 [02:20<02:14, 27.73it/s, est. speed input: 32537.39 toks/s, output: 31.77 toks/s]
Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4514/8192 [02:22<02:12, 27.72it/s, est. speed input: 32469.85 toks/s, output: 31.71 toks/s]
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 4578/8192 [02:24<02:10, 27.71it/s, est. speed input: 32404.00 toks/s, output: 31.64 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4642/8192 [02:26<02:08, 27.70it/s, est. speed input: 32340.07 toks/s, output: 31.58 toks/s]
Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4706/8192 [02:29<02:05, 27.71it/s, est. speed input: 32279.32 toks/s, output: 31.52 toks/s]
Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4770/8192 [02:31<02:03, 27.73it/s, est. speed input: 32220.66 toks/s, output: 31.47 toks/s]
Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4834/8192 [02:33<02:01, 27.74it/s, est. speed input: 32164.01 toks/s, output: 31.41 toks/s]
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4898/8192 [02:36<01:58, 27.73it/s, est. speed input: 32107.73 toks/s, output: 31.36 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 4962/8192 [02:38<01:56, 27.83it/s, est. speed input: 32059.39 toks/s, output: 31.31 toks/s]
Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5026/8192 [02:40<01:53, 27.80it/s, est. speed input: 32006.82 toks/s, output: 31.26 toks/s]
Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5090/8192 [02:43<01:51, 27.77it/s, est. speed input: 31955.49 toks/s, output: 31.21 toks/s]
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5154/8192 [02:45<01:49, 27.76it/s, est. speed input: 31905.54 toks/s, output: 31.16 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5218/8192 [02:47<01:47, 27.75it/s, est. speed input: 31857.36 toks/s, output: 31.11 toks/s]
Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5282/8192 [02:50<01:44, 27.74it/s, est. speed input: 31810.34 toks/s, output: 31.06 toks/s]
Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5346/8192 [02:52<01:42, 27.72it/s, est. speed input: 31763.53 toks/s, output: 31.02 toks/s]
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5410/8192 [02:54<01:40, 27.71it/s, est. speed input: 31718.32 toks/s, output: 30.97 toks/s]
Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5474/8192 [02:56<01:38, 27.72it/s, est. speed input: 31675.21 toks/s, output: 30.93 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5538/8192 [02:59<01:35, 27.73it/s, est. speed input: 31633.20 toks/s, output: 30.89 toks/s]
Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 5602/8192 [03:01<01:33, 27.72it/s, est. speed input: 31591.49 toks/s, output: 30.85 toks/s]
Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5666/8192 [03:03<01:31, 27.73it/s, est. speed input: 31551.84 toks/s, output: 30.81 toks/s]
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 5730/8192 [03:06<01:28, 27.72it/s, est. speed input: 31512.28 toks/s, output: 30.77 toks/s]
Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5794/8192 [03:08<01:26, 27.74it/s, est. speed input: 31474.96 toks/s, output: 30.74 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5858/8192 [03:10<01:24, 27.74it/s, est. speed input: 31437.57 toks/s, output: 30.70 toks/s]
Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5922/8192 [03:13<01:21, 27.83it/s, est. speed input: 31405.74 toks/s, output: 30.67 toks/s]
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5986/8192 [03:15<01:19, 27.91it/s, est. speed input: 31374.79 toks/s, output: 30.64 toks/s]
Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6050/8192 [03:17<01:16, 27.83it/s, est. speed input: 31339.05 toks/s, output: 30.60 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6114/8192 [03:19<01:14, 27.79it/s, est. speed input: 31304.78 toks/s, output: 30.57 toks/s]
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6178/8192 [03:22<01:12, 27.76it/s, est. speed input: 31270.99 toks/s, output: 30.54 toks/s]
Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6242/8192 [03:24<01:10, 27.73it/s, est. speed input: 31237.82 toks/s, output: 30.51 toks/s]
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6306/8192 [03:26<01:08, 27.72it/s, est. speed input: 31205.72 toks/s, output: 30.47 toks/s]
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6370/8192 [03:29<01:05, 27.71it/s, est. speed input: 31174.16 toks/s, output: 30.44 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6434/8192 [03:31<01:03, 27.70it/s, est. speed input: 31142.98 toks/s, output: 30.41 toks/s]
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6498/8192 [03:33<01:01, 27.71it/s, est. speed input: 31113.59 toks/s, output: 30.38 toks/s]
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6562/8192 [03:36<00:58, 27.73it/s, est. speed input: 31085.14 toks/s, output: 30.36 toks/s]
Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6626/8192 [03:38<00:56, 27.73it/s, est. speed input: 31056.64 toks/s, output: 30.33 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6690/8192 [03:40<00:54, 27.73it/s, est. speed input: 31028.75 toks/s, output: 30.30 toks/s]
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6754/8192 [03:43<00:51, 27.75it/s, est. speed input: 31002.22 toks/s, output: 30.28 toks/s]
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6818/8192 [03:45<00:49, 27.75it/s, est. speed input: 30975.86 toks/s, output: 30.25 toks/s]
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6882/8192 [03:47<00:47, 27.75it/s, est. speed input: 30949.81 toks/s, output: 30.22 toks/s]
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6946/8192 [03:50<00:44, 27.75it/s, est. speed input: 30924.49 toks/s, output: 30.20 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7010/8192 [03:52<00:42, 27.75it/s, est. speed input: 30899.69 toks/s, output: 30.18 toks/s]
Processed prompts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7074/8192 [03:54<00:40, 27.74it/s, est. speed input: 30874.74 toks/s, output: 30.15 toks/s]
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7138/8192 [03:56<00:38, 27.74it/s, est. speed input: 30850.64 toks/s, output: 30.13 toks/s]
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7202/8192 [03:59<00:35, 27.72it/s, est. speed input: 30826.48 toks/s, output: 30.10 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7266/8192 [04:01<00:33, 27.72it/s, est. speed input: 30803.11 toks/s, output: 30.08 toks/s]
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7330/8192 [04:03<00:31, 27.72it/s, est. speed input: 30780.13 toks/s, output: 30.06 toks/s]
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7394/8192 [04:06<00:28, 27.72it/s, est. speed input: 30757.89 toks/s, output: 30.04 toks/s]
Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7458/8192 [04:08<00:26, 27.72it/s, est. speed input: 30735.68 toks/s, output: 30.02 toks/s]
Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7522/8192 [04:10<00:24, 27.71it/s, est. speed input: 30713.65 toks/s, output: 29.99 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7586/8192 [04:13<00:21, 27.71it/s, est. speed input: 30692.40 toks/s, output: 29.97 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7650/8192 [04:15<00:19, 27.70it/s, est. speed input: 30671.07 toks/s, output: 29.95 toks/s]
Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7714/8192 [04:17<00:17, 27.70it/s, est. speed input: 30650.34 toks/s, output: 29.93 toks/s]
Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 7778/8192 [04:20<00:14, 27.69it/s, est. speed input: 30629.86 toks/s, output: 29.91 toks/s]
Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7842/8192 [04:22<00:12, 27.69it/s, est. speed input: 30609.62 toks/s, output: 29.89 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7906/8192 [04:24<00:10, 27.71it/s, est. speed input: 30590.70 toks/s, output: 29.87 toks/s]
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7970/8192 [04:26<00:08, 27.71it/s, est. speed input: 30571.59 toks/s, output: 29.86 toks/s]
Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8034/8192 [04:29<00:05, 27.71it/s, est. speed input: 30552.76 toks/s, output: 29.84 toks/s]
Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8098/8192 [04:31<00:03, 27.73it/s, est. speed input: 30534.69 toks/s, output: 29.82 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8162/8192 [04:32<00:00, 32.79it/s, est. speed input: 30649.67 toks/s, output: 29.93 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [04:32<00:00, 32.79it/s, est. speed input: 30762.20 toks/s, output: 30.04 toks/s]
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8192/8192 [04:32<00:00, 30.04it/s, est. speed input: 30762.20 toks/s, output: 30.04 toks/s]
[rank0]:[W126 13:13:34.700383760 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

