
========== M=16 ==========
Time: 2026-01-25 22:00:05
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:00:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=480290) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=480290) WARNING 01-25 22:00:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.06 requests/s, 510.96 total tokens/s, 30.06 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-25 22:00:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:00:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:00:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:00:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:00:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:00:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:00:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:00:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:00:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:00:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:00:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:00:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=480290) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=480290) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.42it/s]
(EngineCore_DP0 pid=480290) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.41it/s]
(EngineCore_DP0 pid=480290) 
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=480290) [2026-01-25 22:00:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=480290) 2026-01-25 22:00:33,518 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=480290) 2026-01-25 22:00:33,585 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=480290) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.49it/s]
(EngineCore_DP0 pid=480290) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.02it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2917.22it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.80it/s, est. speed input: 44.76 toks/s, output: 2.80 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.61it/s, est. speed input: 166.71 toks/s, output: 10.42 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 19.14it/s, est. speed input: 240.03 toks/s, output: 15.00 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 23.35it/s, est. speed input: 287.62 toks/s, output: 17.98 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 26.36it/s, est. speed input: 322.40 toks/s, output: 20.15 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.37it/s, est. speed input: 348.10 toks/s, output: 21.76 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 29.87it/s, est. speed input: 368.62 toks/s, output: 23.04 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 30.75it/s, est. speed input: 384.34 toks/s, output: 24.02 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 31.35it/s, est. speed input: 397.13 toks/s, output: 24.82 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 31.79it/s, est. speed input: 407.86 toks/s, output: 25.49 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.26it/s, est. speed input: 417.48 toks/s, output: 26.09 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.38it/s, est. speed input: 425.07 toks/s, output: 26.57 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.58it/s, est. speed input: 431.98 toks/s, output: 27.00 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.63it/s, est. speed input: 437.78 toks/s, output: 27.36 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 32.73it/s, est. speed input: 443.07 toks/s, output: 27.69 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.76it/s, est. speed input: 447.67 toks/s, output: 27.98 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.83it/s, est. speed input: 451.90 toks/s, output: 28.24 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.92it/s, est. speed input: 455.79 toks/s, output: 28.49 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.91it/s, est. speed input: 459.16 toks/s, output: 28.70 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.92it/s, est. speed input: 462.25 toks/s, output: 28.89 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.92it/s, est. speed input: 465.05 toks/s, output: 29.07 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.87it/s, est. speed input: 467.54 toks/s, output: 29.22 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 32.86it/s, est. speed input: 469.86 toks/s, output: 29.37 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.89it/s, est. speed input: 472.08 toks/s, output: 29.51 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.99it/s, est. speed input: 474.27 toks/s, output: 29.64 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.90it/s, est. speed input: 476.04 toks/s, output: 29.75 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.82it/s, est. speed input: 477.64 toks/s, output: 29.85 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.85it/s, est. speed input: 479.28 toks/s, output: 29.95 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.84it/s, est. speed input: 480.77 toks/s, output: 30.05 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.86it/s, est. speed input: 482.20 toks/s, output: 30.14 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:04<00:00, 32.83it/s, est. speed input: 483.48 toks/s, output: 30.22 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.03it/s, est. speed input: 484.99 toks/s, output: 30.31 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.03it/s, est. speed input: 486.14 toks/s, output: 30.38 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.38it/s, est. speed input: 486.14 toks/s, output: 30.38 toks/s]
[rank0]:[W125 22:00:40.208385746 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 22:00:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:00:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=481345) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=481345) WARNING 01-25 22:01:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.32 requests/s, 3782.18 total tokens/s, 29.32 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-25 22:00:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:00:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:00:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:00:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:00:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:00:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:00:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:00:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:00:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:00:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:00:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:00:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:00:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:00:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=481345) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=481345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.35it/s]
(EngineCore_DP0 pid=481345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.34it/s]
(EngineCore_DP0 pid=481345) 
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=481345) [2026-01-25 22:00:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=481345) 2026-01-25 22:01:10,070 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=481345) 2026-01-25 22:01:10,108 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=481345) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 12.37it/s]
(EngineCore_DP0 pid=481345) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1391.92it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:40,  3.15it/s, est. speed input: 403.34 toks/s, output: 3.15 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 13.65it/s, est. speed input: 1455.90 toks/s, output: 11.37 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 20.03it/s, est. speed input: 2048.12 toks/s, output: 16.00 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 24.10it/s, est. speed input: 2427.90 toks/s, output: 18.97 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 26.78it/s, est. speed input: 2691.90 toks/s, output: 21.03 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.57it/s, est. speed input: 2886.37 toks/s, output: 22.55 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 29.77it/s, est. speed input: 3034.27 toks/s, output: 23.70 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 30.68it/s, est. speed input: 3154.58 toks/s, output: 24.64 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 31.23it/s, est. speed input: 3249.81 toks/s, output: 25.39 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 31.44it/s, est. speed input: 3323.05 toks/s, output: 25.96 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 31.69it/s, est. speed input: 3387.61 toks/s, output: 26.47 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 31.85it/s, est. speed input: 3442.23 toks/s, output: 26.89 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 31.86it/s, est. speed input: 3486.96 toks/s, output: 27.24 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 31.90it/s, est. speed input: 3526.54 toks/s, output: 27.55 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 31.90it/s, est. speed input: 3560.38 toks/s, output: 27.81 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 31.88it/s, est. speed input: 3590.08 toks/s, output: 28.05 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 31.88it/s, est. speed input: 3616.93 toks/s, output: 28.26 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 31.89it/s, est. speed input: 3641.05 toks/s, output: 28.44 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 31.93it/s, est. speed input: 3663.41 toks/s, output: 28.62 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 31.88it/s, est. speed input: 3682.46 toks/s, output: 28.77 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 31.91it/s, est. speed input: 3700.81 toks/s, output: 28.91 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 31.93it/s, est. speed input: 3717.58 toks/s, output: 29.04 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 31.98it/s, est. speed input: 3733.49 toks/s, output: 29.17 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 31.99it/s, est. speed input: 3747.76 toks/s, output: 29.28 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.01it/s, est. speed input: 3761.26 toks/s, output: 29.38 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 31.94it/s, est. speed input: 3772.50 toks/s, output: 29.47 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 31.92it/s, est. speed input: 3783.35 toks/s, output: 29.56 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 31.90it/s, est. speed input: 3793.35 toks/s, output: 29.64 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 31.91it/s, est. speed input: 3803.12 toks/s, output: 29.71 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 31.95it/s, est. speed input: 3812.51 toks/s, output: 29.78 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:04<00:00, 31.91it/s, est. speed input: 3820.64 toks/s, output: 29.85 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 31.91it/s, est. speed input: 3828.55 toks/s, output: 29.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.91it/s, est. speed input: 3835.26 toks/s, output: 29.96 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 29.96it/s, est. speed input: 3835.26 toks/s, output: 29.96 toks/s]
[rank0]:[W125 22:01:16.381624867 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 22:01:18
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:01:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=482373) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482373) WARNING 01-25 22:01:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.13 requests/s, 8256.68 total tokens/s, 32.13 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-25 22:01:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:01:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:01:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:01:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:01:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:01:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:01:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:01:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:01:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:01:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:01:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:01:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:01:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:01:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:01:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:01:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:01:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=482373) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=482373) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.40it/s]
(EngineCore_DP0 pid=482373) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=482373) 
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=482373) [2026-01-25 22:01:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=482373) 2026-01-25 22:01:46,106 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=482373) 2026-01-25 22:01:46,137 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=482373) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 12.47it/s]
(EngineCore_DP0 pid=482373) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.50it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 816.61it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 997.19it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 42.14it/s, est. speed input: 10791.38 toks/s, output: 42.15 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:03, 35.92it/s, est. speed input: 9406.39 toks/s, output: 36.74 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:03, 34.56it/s, est. speed input: 9086.54 toks/s, output: 35.49 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:03, 33.62it/s, est. speed input: 8878.13 toks/s, output: 34.68 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:03, 33.38it/s, est. speed input: 8792.30 toks/s, output: 34.34 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:03, 33.17it/s, est. speed input: 8727.06 toks/s, output: 34.09 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 33.04it/s, est. speed input: 8680.84 toks/s, output: 33.91 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:02, 33.03it/s, est. speed input: 8652.85 toks/s, output: 33.80 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 32.97it/s, est. speed input: 8625.93 toks/s, output: 33.69 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 32.95it/s, est. speed input: 8605.99 toks/s, output: 33.62 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 32.83it/s, est. speed input: 8581.66 toks/s, output: 33.52 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 32.82it/s, est. speed input: 8566.75 toks/s, output: 33.46 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 32.77it/s, est. speed input: 8551.31 toks/s, output: 33.40 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:02, 32.80it/s, est. speed input: 8541.36 toks/s, output: 33.36 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:02, 32.84it/s, est. speed input: 8534.17 toks/s, output: 33.34 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 32.87it/s, est. speed input: 8528.13 toks/s, output: 33.31 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:02<00:01, 32.92it/s, est. speed input: 8524.03 toks/s, output: 33.30 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 32.89it/s, est. speed input: 8517.52 toks/s, output: 33.27 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 32.92it/s, est. speed input: 8513.57 toks/s, output: 33.26 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 33.05it/s, est. speed input: 8514.69 toks/s, output: 33.26 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 33.14it/s, est. speed input: 8515.97 toks/s, output: 33.27 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 33.23it/s, est. speed input: 8517.88 toks/s, output: 33.27 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:01, 33.07it/s, est. speed input: 8511.40 toks/s, output: 33.25 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 33.21it/s, est. speed input: 8514.60 toks/s, output: 33.26 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:03<00:00, 33.30it/s, est. speed input: 8517.03 toks/s, output: 33.27 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:03<00:00, 33.44it/s, est. speed input: 8521.72 toks/s, output: 33.29 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 33.39it/s, est. speed input: 8521.53 toks/s, output: 33.29 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 33.16it/s, est. speed input: 8515.79 toks/s, output: 33.26 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 32.99it/s, est. speed input: 8509.81 toks/s, output: 33.24 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 32.98it/s, est. speed input: 8507.37 toks/s, output: 33.23 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 32.90it/s, est. speed input: 8503.25 toks/s, output: 33.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.90it/s, est. speed input: 8502.53 toks/s, output: 33.21 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.21it/s, est. speed input: 8502.53 toks/s, output: 33.21 toks/s]
[rank0]:[W125 22:01:52.185275566 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16 ==========
Time: 2026-01-26 07:42:15
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:42:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=985718) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=985718) WARNING 01-26 07:42:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.79 requests/s, 523.45 total tokens/s, 30.79 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:42:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:42:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:42:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:42:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:42:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:42:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:42:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:42:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:42:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:42:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:42:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:42:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=985718) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=985718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.38it/s]
(EngineCore_DP0 pid=985718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=985718) 
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=985718) [2026-01-26 07:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=985718) 2026-01-26 07:42:41,836 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=985718) 2026-01-26 07:42:41,897 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=985718) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.73it/s]
(EngineCore_DP0 pid=985718) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 19.34it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2562.16it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.81it/s, est. speed input: 44.94 toks/s, output: 2.81 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.88it/s, est. speed input: 169.58 toks/s, output: 10.60 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 19.56it/s, est. speed input: 244.47 toks/s, output: 15.28 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 24.03it/s, est. speed input: 294.27 toks/s, output: 18.39 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 27.11it/s, est. speed input: 329.99 toks/s, output: 20.62 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.17it/s, est. speed input: 356.51 toks/s, output: 22.28 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 30.67it/s, est. speed input: 377.46 toks/s, output: 23.59 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.62it/s, est. speed input: 393.87 toks/s, output: 24.62 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.32it/s, est. speed input: 407.42 toks/s, output: 25.46 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.79it/s, est. speed input: 418.67 toks/s, output: 26.17 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.10it/s, est. speed input: 428.11 toks/s, output: 26.76 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.32it/s, est. speed input: 436.24 toks/s, output: 27.26 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.46it/s, est. speed input: 443.21 toks/s, output: 27.70 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.57it/s, est. speed input: 449.36 toks/s, output: 28.08 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 33.60it/s, est. speed input: 454.65 toks/s, output: 28.42 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:01, 33.66it/s, est. speed input: 459.46 toks/s, output: 28.72 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.71it/s, est. speed input: 463.76 toks/s, output: 28.98 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.76it/s, est. speed input: 467.68 toks/s, output: 29.23 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.78it/s, est. speed input: 471.19 toks/s, output: 29.45 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.79it/s, est. speed input: 474.36 toks/s, output: 29.65 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.77it/s, est. speed input: 477.22 toks/s, output: 29.83 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.77it/s, est. speed input: 479.86 toks/s, output: 29.99 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.78it/s, est. speed input: 482.30 toks/s, output: 30.14 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.81it/s, est. speed input: 484.59 toks/s, output: 30.29 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.77it/s, est. speed input: 486.61 toks/s, output: 30.41 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.76it/s, est. speed input: 488.52 toks/s, output: 30.53 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.78it/s, est. speed input: 490.34 toks/s, output: 30.65 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.78it/s, est. speed input: 492.02 toks/s, output: 30.75 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.79it/s, est. speed input: 493.59 toks/s, output: 30.85 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.67it/s, est. speed input: 494.88 toks/s, output: 30.93 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.58it/s, est. speed input: 496.08 toks/s, output: 31.00 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.89it/s, est. speed input: 497.76 toks/s, output: 31.11 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.89it/s, est. speed input: 498.92 toks/s, output: 31.18 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.18it/s, est. speed input: 498.92 toks/s, output: 31.18 toks/s]
[rank0]:[W126 07:42:48.212998650 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 07:42:50
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:42:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=986734) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=986734) WARNING 01-26 07:43:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.66 requests/s, 4083.89 total tokens/s, 31.66 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 07:42:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:42:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:42:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:42:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:42:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:42:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:42:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:42:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:43:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=986734) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=986734) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.36it/s]
(EngineCore_DP0 pid=986734) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.36it/s]
(EngineCore_DP0 pid=986734) 
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=986734) [2026-01-26 07:43:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=986734) 2026-01-26 07:43:17,107 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=986734) 2026-01-26 07:43:17,147 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=986734) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.70it/s]
(EngineCore_DP0 pid=986734) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.94it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1384.22it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:23,  5.38it/s, est. speed input: 688.60 toks/s, output: 5.38 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 19.09it/s, est. speed input: 2119.57 toks/s, output: 16.56 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.15it/s, est. speed input: 2746.26 toks/s, output: 21.45 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 28.23it/s, est. speed input: 3087.01 toks/s, output: 24.12 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 30.08it/s, est. speed input: 3306.16 toks/s, output: 25.83 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 31.22it/s, est. speed input: 3457.58 toks/s, output: 27.01 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.99it/s, est. speed input: 3570.02 toks/s, output: 27.89 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.49it/s, est. speed input: 3655.37 toks/s, output: 28.56 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.78it/s, est. speed input: 3720.84 toks/s, output: 29.07 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.99it/s, est. speed input: 3774.39 toks/s, output: 29.49 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.13it/s, est. speed input: 3818.53 toks/s, output: 29.83 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.24it/s, est. speed input: 3856.17 toks/s, output: 30.13 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.33it/s, est. speed input: 3888.50 toks/s, output: 30.38 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.40it/s, est. speed input: 3916.55 toks/s, output: 30.60 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.46it/s, est. speed input: 3941.16 toks/s, output: 30.79 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 33.58it/s, est. speed input: 3964.80 toks/s, output: 30.97 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.64it/s, est. speed input: 3985.13 toks/s, output: 31.13 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.63it/s, est. speed input: 4002.18 toks/s, output: 31.27 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.60it/s, est. speed input: 4016.99 toks/s, output: 31.38 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.60it/s, est. speed input: 4030.85 toks/s, output: 31.49 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.64it/s, est. speed input: 4044.11 toks/s, output: 31.59 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.60it/s, est. speed input: 4055.09 toks/s, output: 31.68 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.56it/s, est. speed input: 4064.84 toks/s, output: 31.76 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.76it/s, est. speed input: 4077.57 toks/s, output: 31.86 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.94it/s, est. speed input: 4089.85 toks/s, output: 31.95 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.87it/s, est. speed input: 4098.30 toks/s, output: 32.02 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.69it/s, est. speed input: 4104.26 toks/s, output: 32.06 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.83it/s, est. speed input: 4113.47 toks/s, output: 32.14 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.94it/s, est. speed input: 4122.22 toks/s, output: 32.20 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 34.08it/s, est. speed input: 4131.32 toks/s, output: 32.28 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 34.14it/s, est. speed input: 4139.33 toks/s, output: 32.34 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 34.06it/s, est. speed input: 4145.34 toks/s, output: 32.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.06it/s, est. speed input: 4149.00 toks/s, output: 32.41 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.41it/s, est. speed input: 4149.00 toks/s, output: 32.41 toks/s]
[rank0]:[W126 07:43:22.988902661 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 07:43:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:43:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=987743) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=987743) WARNING 01-26 07:43:45 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.35 requests/s, 7800.12 total tokens/s, 30.35 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 07:43:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:43:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=987743) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=987743) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=987743) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=987743) 
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=987743) [2026-01-26 07:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=987743) 2026-01-26 07:43:49,747 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=987743) 2026-01-26 07:43:49,792 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=987743) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.21it/s]
(EngineCore_DP0 pid=987743) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.85it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1549.23it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.78it/s, est. speed input: 711.17 toks/s, output: 2.78 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.67it/s, est. speed input: 2672.64 toks/s, output: 10.44 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 19.25it/s, est. speed input: 3853.46 toks/s, output: 15.05 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 23.71it/s, est. speed input: 4643.20 toks/s, output: 18.14 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 26.73it/s, est. speed input: 5205.47 toks/s, output: 20.33 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.79it/s, est. speed input: 5626.09 toks/s, output: 21.98 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 30.29it/s, est. speed input: 5958.54 toks/s, output: 23.27 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.33it/s, est. speed input: 6224.89 toks/s, output: 24.32 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 31.98it/s, est. speed input: 6438.26 toks/s, output: 25.15 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.49it/s, est. speed input: 6619.92 toks/s, output: 25.86 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.79it/s, est. speed input: 6770.38 toks/s, output: 26.45 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.02it/s, est. speed input: 6900.32 toks/s, output: 26.95 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.13it/s, est. speed input: 7010.55 toks/s, output: 27.38 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.22it/s, est. speed input: 7107.34 toks/s, output: 27.76 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 33.34it/s, est. speed input: 7195.56 toks/s, output: 28.11 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 33.44it/s, est. speed input: 7274.22 toks/s, output: 28.41 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.47it/s, est. speed input: 7343.37 toks/s, output: 28.68 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.51it/s, est. speed input: 7406.17 toks/s, output: 28.93 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.50it/s, est. speed input: 7461.60 toks/s, output: 29.15 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.74it/s, est. speed input: 7520.46 toks/s, output: 29.38 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.65it/s, est. speed input: 7565.87 toks/s, output: 29.55 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.68it/s, est. speed input: 7610.29 toks/s, output: 29.73 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.79it/s, est. speed input: 7653.99 toks/s, output: 29.90 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.76it/s, est. speed input: 7691.11 toks/s, output: 30.04 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.62it/s, est. speed input: 7722.37 toks/s, output: 30.17 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.82it/s, est. speed input: 7759.22 toks/s, output: 30.31 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.69it/s, est. speed input: 7786.66 toks/s, output: 30.42 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.56it/s, est. speed input: 7811.24 toks/s, output: 30.51 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.49it/s, est. speed input: 7834.73 toks/s, output: 30.60 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.56it/s, est. speed input: 7859.59 toks/s, output: 30.70 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.65it/s, est. speed input: 7883.82 toks/s, output: 30.80 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.82it/s, est. speed input: 7909.35 toks/s, output: 30.90 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.82it/s, est. speed input: 7927.71 toks/s, output: 30.97 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.97it/s, est. speed input: 7927.71 toks/s, output: 30.97 toks/s]
[rank0]:[W126 07:43:55.819685601 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:32:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:32:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1062152) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1062152) WARNING 01-26 08:32:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.13 requests/s, 16481.71 total tokens/s, 32.13 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:32:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:32:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:32:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:32:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:32:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:32:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:32:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:32:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:32:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:32:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:32:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:32:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1062152) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1062152) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.36it/s]
(EngineCore_DP0 pid=1062152) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.36it/s]
(EngineCore_DP0 pid=1062152) 
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1062152) [2026-01-26 08:32:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1062152) 2026-01-26 08:32:33,892 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1062152) 2026-01-26 08:32:33,923 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1062152) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
(EngineCore_DP0 pid=1062152) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.38it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  37%|███▋      | 47/128 [00:00<00:00, 467.81it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 681.89it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 50.85it/s, est. speed input: 26037.57 toks/s, output: 50.85 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:02, 38.72it/s, est. speed input: 20562.10 toks/s, output: 40.15 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 36.42it/s, est. speed input: 19440.21 toks/s, output: 37.97 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 35.40it/s, est. speed input: 18949.48 toks/s, output: 37.01 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.63it/s, est. speed input: 18592.75 toks/s, output: 36.31 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.11it/s, est. speed input: 18340.12 toks/s, output: 35.82 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 33.79it/s, est. speed input: 18158.21 toks/s, output: 35.46 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.60it/s, est. speed input: 18023.80 toks/s, output: 35.20 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.57it/s, est. speed input: 17934.18 toks/s, output: 35.03 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.48it/s, est. speed input: 17850.48 toks/s, output: 34.86 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.35it/s, est. speed input: 17770.60 toks/s, output: 34.71 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.17it/s, est. speed input: 17691.74 toks/s, output: 34.55 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.92it/s, est. speed input: 17607.52 toks/s, output: 34.39 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 33.08it/s, est. speed input: 17575.54 toks/s, output: 34.33 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 33.25it/s, est. speed input: 17554.68 toks/s, output: 34.29 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.43it/s, est. speed input: 17541.50 toks/s, output: 34.26 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.49it/s, est. speed input: 17523.07 toks/s, output: 34.22 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.58it/s, est. speed input: 17511.20 toks/s, output: 34.20 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.53it/s, est. speed input: 17491.32 toks/s, output: 34.16 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.27it/s, est. speed input: 17453.87 toks/s, output: 34.09 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.09it/s, est. speed input: 17419.69 toks/s, output: 34.02 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.01it/s, est. speed input: 17392.70 toks/s, output: 33.97 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 33.11it/s, est. speed input: 17378.95 toks/s, output: 33.94 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 33.23it/s, est. speed input: 17370.10 toks/s, output: 33.93 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.23it/s, est. speed input: 17356.43 toks/s, output: 33.90 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.13it/s, est. speed input: 17336.72 toks/s, output: 33.86 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.10it/s, est. speed input: 17321.31 toks/s, output: 33.83 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.08it/s, est. speed input: 17306.95 toks/s, output: 33.80 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.08it/s, est. speed input: 17294.59 toks/s, output: 33.78 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.05it/s, est. speed input: 17281.23 toks/s, output: 33.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.05it/s, est. speed input: 17271.72 toks/s, output: 33.73 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.73it/s, est. speed input: 17271.72 toks/s, output: 33.73 toks/s]
[rank0]:[W126 08:32:40.210110366 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:32:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:32:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1063217) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1063217) WARNING 01-26 08:33:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.39 requests/s, 32172.26 total tokens/s, 31.39 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:32:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:32:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:32:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:32:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:32:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:32:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:32:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:32:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:32:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:32:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:32:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:32:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:32:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:32:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1063217) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1063217) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.40it/s]
(EngineCore_DP0 pid=1063217) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=1063217) 
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1063217) [2026-01-26 08:32:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1063217) 2026-01-26 08:33:10,653 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1063217) 2026-01-26 08:33:10,708 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1063217) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.36it/s]
(EngineCore_DP0 pid=1063217) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.58it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 236.63it/s]
Adding requests:  55%|█████▌    | 71/128 [00:00<00:00, 371.53it/s]
Adding requests:  96%|█████████▌| 123/128 [00:00<00:00, 435.88it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 407.92it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 71.74it/s, est. speed input: 73475.08 toks/s, output: 71.74 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:02, 42.24it/s, est. speed input: 46099.42 toks/s, output: 45.01 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 38.49it/s, est. speed input: 42389.74 toks/s, output: 41.39 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 36.62it/s, est. speed input: 40502.91 toks/s, output: 39.55 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 35.45it/s, est. speed input: 39402.30 toks/s, output: 38.48 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 34.73it/s, est. speed input: 38646.21 toks/s, output: 37.74 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 34.23it/s, est. speed input: 38075.82 toks/s, output: 37.18 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 33.73it/s, est. speed input: 37571.01 toks/s, output: 36.69 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 33.41it/s, est. speed input: 37173.54 toks/s, output: 36.30 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 33.16it/s, est. speed input: 36836.73 toks/s, output: 35.97 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 33.10it/s, est. speed input: 36587.19 toks/s, output: 35.73 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:02, 33.12it/s, est. speed input: 36392.86 toks/s, output: 35.54 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 33.20it/s, est. speed input: 36242.89 toks/s, output: 35.39 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 33.22it/s, est. speed input: 36102.22 toks/s, output: 35.26 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 32.96it/s, est. speed input: 35918.47 toks/s, output: 35.08 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 32.93it/s, est. speed input: 35788.94 toks/s, output: 34.95 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 32.90it/s, est. speed input: 35671.47 toks/s, output: 34.83 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 32.92it/s, est. speed input: 35571.97 toks/s, output: 34.74 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 32.86it/s, est. speed input: 35470.31 toks/s, output: 34.64 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 32.90it/s, est. speed input: 35391.61 toks/s, output: 34.56 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:01, 32.87it/s, est. speed input: 35311.25 toks/s, output: 34.48 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 32.86it/s, est. speed input: 35239.24 toks/s, output: 34.41 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 32.82it/s, est. speed input: 35167.32 toks/s, output: 34.34 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:03<00:00, 32.82it/s, est. speed input: 35106.08 toks/s, output: 34.28 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 32.81it/s, est. speed input: 35048.62 toks/s, output: 34.23 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 32.78it/s, est. speed input: 34991.65 toks/s, output: 34.17 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 32.78it/s, est. speed input: 34941.67 toks/s, output: 34.12 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 32.82it/s, est. speed input: 34898.79 toks/s, output: 34.08 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 32.84it/s, est. speed input: 34858.90 toks/s, output: 34.04 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.84it/s, est. speed input: 34836.94 toks/s, output: 34.02 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.02it/s, est. speed input: 34836.94 toks/s, output: 34.02 toks/s]
[rank0]:[W126 08:33:16.777747067 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:33:18
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:33:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1064263) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1064263) WARNING 01-26 08:33:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 61.88 requests/s, 63425.63 total tokens/s, 61.88 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:33:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:33:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:33:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:33:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:33:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:33:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:33:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:33:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:33:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:33:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:33:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:33:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:33:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:33:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1064263) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1064263) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.74it/s]
(EngineCore_DP0 pid=1064263) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.73it/s]
(EngineCore_DP0 pid=1064263) 
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1064263) [2026-01-26 08:33:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1064263) 2026-01-26 08:33:47,494 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1064263) 2026-01-26 08:33:47,528 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1064263) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.84it/s]
(EngineCore_DP0 pid=1064263) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.31it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█▏        | 29/256 [00:00<00:00, 284.15it/s]
Adding requests:  31%|███       | 79/256 [00:00<00:00, 405.09it/s]
Adding requests:  49%|████▉     | 126/256 [00:00<00:00, 434.10it/s]
Adding requests:  68%|██████▊   | 173/256 [00:00<00:00, 445.33it/s]
Adding requests:  87%|████████▋ | 223/256 [00:00<00:00, 462.84it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 448.57it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:00<00:00, 263.67it/s, est. speed input: 270039.38 toks/s, output: 263.68 toks/s]
Processed prompts:  22%|██▏       | 57/256 [00:00<00:02, 99.40it/s, est. speed input: 112890.73 toks/s, output: 110.24 toks/s] 
Processed prompts:  28%|██▊       | 72/256 [00:00<00:02, 83.42it/s, est. speed input: 96812.51 toks/s, output: 94.54 toks/s]  
Processed prompts:  32%|███▏      | 83/256 [00:00<00:02, 80.22it/s, est. speed input: 92886.78 toks/s, output: 90.71 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:01<00:02, 75.89it/s, est. speed input: 89068.98 toks/s, output: 86.98 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:01<00:02, 71.20it/s, est. speed input: 85559.57 toks/s, output: 83.55 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:01<00:02, 70.09it/s, est. speed input: 84005.20 toks/s, output: 82.03 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:01<00:02, 68.90it/s, est. speed input: 82597.46 toks/s, output: 80.66 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:01<00:01, 67.88it/s, est. speed input: 81368.59 toks/s, output: 79.46 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:01<00:01, 67.17it/s, est. speed input: 80331.70 toks/s, output: 78.45 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:01<00:01, 66.58it/s, est. speed input: 79414.71 toks/s, output: 77.55 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:01<00:01, 66.09it/s, est. speed input: 78595.61 toks/s, output: 76.75 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:02<00:01, 66.09it/s, est. speed input: 77958.75 toks/s, output: 76.13 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:02<00:01, 65.77it/s, est. speed input: 77321.58 toks/s, output: 75.51 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:02<00:01, 65.53it/s, est. speed input: 76749.78 toks/s, output: 74.95 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:02<00:01, 65.73it/s, est. speed input: 76306.48 toks/s, output: 74.52 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:02<00:01, 65.91it/s, est. speed input: 75911.58 toks/s, output: 74.13 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:02<00:00, 66.07it/s, est. speed input: 75558.50 toks/s, output: 73.79 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:02<00:00, 66.04it/s, est. speed input: 75213.76 toks/s, output: 73.45 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:02<00:00, 66.05it/s, est. speed input: 74900.93 toks/s, output: 73.14 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:03<00:00, 66.01it/s, est. speed input: 74605.45 toks/s, output: 72.86 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:03<00:00, 66.06it/s, est. speed input: 74345.17 toks/s, output: 72.60 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:03<00:00, 65.94it/s, est. speed input: 74082.26 toks/s, output: 72.35 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:03<00:00, 65.93it/s, est. speed input: 73847.53 toks/s, output: 72.12 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:03<00:00, 65.62it/s, est. speed input: 73590.20 toks/s, output: 71.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.62it/s, est. speed input: 73536.07 toks/s, output: 71.81 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.81it/s, est. speed input: 73536.07 toks/s, output: 71.81 toks/s]
[rank0]:[W126 08:33:54.250205201 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:33:56
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:34:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1065335) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1065335) WARNING 01-26 08:34:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 109.98 requests/s, 112725.01 total tokens/s, 109.98 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:34:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:34:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:34:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:34:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:34:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:34:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:34:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:34:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:34:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:34:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:34:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:34:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1065335) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1065335) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1065335) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1065335) 
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1065335) [2026-01-26 08:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1065335) 2026-01-26 08:34:25,095 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1065335) 2026-01-26 08:34:25,151 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1065335) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  3.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  5.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.86it/s]
(EngineCore_DP0 pid=1065335) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 17.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 18.26it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 30/512 [00:00<00:01, 297.97it/s]
Adding requests:  16%|█▌        | 83/512 [00:00<00:00, 431.20it/s]
Adding requests:  26%|██▋       | 135/512 [00:00<00:00, 468.22it/s]
Adding requests:  36%|███▌      | 185/512 [00:00<00:00, 478.13it/s]
Adding requests:  46%|████▋     | 238/512 [00:00<00:00, 494.04it/s]
Adding requests:  56%|█████▋    | 289/512 [00:00<00:00, 496.98it/s]
Adding requests:  66%|██████▋   | 340/512 [00:00<00:00, 499.28it/s]
Adding requests:  77%|███████▋  | 393/512 [00:00<00:00, 506.57it/s]
Adding requests:  87%|████████▋ | 445/512 [00:00<00:00, 508.20it/s]
Adding requests:  97%|█████████▋| 497/512 [00:01<00:00, 509.15it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 490.65it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:00<00:00, 532.33it/s, est. speed input: 545185.97 toks/s, output: 532.36 toks/s]
Processed prompts:  24%|██▍       | 124/512 [00:00<00:01, 206.26it/s, est. speed input: 235663.40 toks/s, output: 230.13 toks/s]
Processed prompts:  30%|███       | 154/512 [00:00<00:02, 170.19it/s, est. speed input: 199835.63 toks/s, output: 195.14 toks/s]
Processed prompts:  34%|███▍      | 176/512 [00:00<00:02, 161.57it/s, est. speed input: 190164.33 toks/s, output: 185.71 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:01<00:02, 149.87it/s, est. speed input: 180521.10 toks/s, output: 176.29 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:01<00:02, 146.16it/s, est. speed input: 176144.13 toks/s, output: 172.01 toks/s]
Processed prompts:  45%|████▍     | 228/512 [00:01<00:02, 140.86it/s, est. speed input: 171704.71 toks/s, output: 167.68 toks/s]
Processed prompts:  47%|████▋     | 243/512 [00:01<00:01, 134.88it/s, est. speed input: 167426.37 toks/s, output: 163.50 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:01<00:01, 130.34it/s, est. speed input: 163812.90 toks/s, output: 159.97 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:01<00:01, 129.21it/s, est. speed input: 161307.13 toks/s, output: 157.52 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:01<00:01, 128.36it/s, est. speed input: 159133.85 toks/s, output: 155.40 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:01<00:01, 127.70it/s, est. speed input: 157225.00 toks/s, output: 153.54 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:02<00:01, 127.22it/s, est. speed input: 155541.16 toks/s, output: 151.89 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:02<00:01, 127.10it/s, est. speed input: 154096.67 toks/s, output: 150.48 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:02<00:01, 126.00it/s, est. speed input: 152590.57 toks/s, output: 149.01 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:02<00:01, 126.21it/s, est. speed input: 151435.71 toks/s, output: 147.88 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:02<00:00, 126.35it/s, est. speed input: 150392.69 toks/s, output: 146.87 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:02<00:00, 126.42it/s, est. speed input: 149439.61 toks/s, output: 145.93 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:02<00:00, 126.45it/s, est. speed input: 148567.07 toks/s, output: 145.08 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:03<00:00, 126.65it/s, est. speed input: 147796.14 toks/s, output: 144.33 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:03<00:00, 126.41it/s, est. speed input: 147027.87 toks/s, output: 143.58 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:03<00:00, 126.32it/s, est. speed input: 146331.74 toks/s, output: 142.90 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:03<00:00, 126.23it/s, est. speed input: 145684.12 toks/s, output: 142.27 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:03<00:00, 126.33it/s, est. speed input: 145106.13 toks/s, output: 141.70 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 126.33it/s, est. speed input: 145224.41 toks/s, output: 141.82 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 141.81it/s, est. speed input: 145224.41 toks/s, output: 141.82 toks/s]
[rank0]:[W126 08:34:32.545488320 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:34:34
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:34:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1066420) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1066420) WARNING 01-26 08:34:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 148.46 requests/s, 152173.57 total tokens/s, 148.46 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:34:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:34:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:34:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:34:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:34:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:34:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:34:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:34:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:34:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:34:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:34:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:34:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:34:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:34:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1066420) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1066420) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1066420) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.36it/s]
(EngineCore_DP0 pid=1066420) 
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1066420) [2026-01-26 08:34:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1066420) 2026-01-26 08:35:06,360 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1066420) 2026-01-26 08:35:06,435 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1066420) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 14.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 16.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 16.27it/s]
(EngineCore_DP0 pid=1066420) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 19.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 20.07it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 40/1024 [00:00<00:02, 395.72it/s]
Adding requests:   9%|▉         | 92/1024 [00:00<00:01, 466.48it/s]
Adding requests:  14%|█▍        | 144/1024 [00:00<00:01, 486.52it/s]
Adding requests:  19%|█▉        | 194/1024 [00:00<00:01, 490.62it/s]
Adding requests:  24%|██▍       | 246/1024 [00:00<00:01, 500.94it/s]
Adding requests:  29%|██▉       | 298/1024 [00:00<00:01, 504.08it/s]
Adding requests:  34%|███▍      | 349/1024 [00:00<00:01, 501.63it/s]
Adding requests:  39%|███▉      | 401/1024 [00:00<00:01, 506.64it/s]
Adding requests:  44%|████▍     | 453/1024 [00:00<00:01, 507.06it/s]
Adding requests:  49%|████▉     | 504/1024 [00:01<00:01, 507.83it/s]
Adding requests:  54%|█████▍    | 555/1024 [00:01<00:00, 503.53it/s]
Adding requests:  59%|█████▉    | 606/1024 [00:01<00:00, 505.08it/s]
Adding requests:  64%|██████▍   | 658/1024 [00:01<00:00, 506.85it/s]
Adding requests:  70%|██████▉   | 712/1024 [00:01<00:00, 515.12it/s]
Adding requests:  75%|███████▍  | 764/1024 [00:01<00:00, 514.44it/s]
Adding requests:  80%|███████▉  | 816/1024 [00:01<00:00, 506.09it/s]
Adding requests:  85%|████████▍ | 868/1024 [00:01<00:00, 507.99it/s]
Adding requests:  90%|█████████ | 922/1024 [00:01<00:00, 514.64it/s]
Adding requests:  95%|█████████▌| 975/1024 [00:01<00:00, 517.27it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 505.99it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:00<00:00, 1793.97it/s, est. speed input: 1837305.48 toks/s, output: 1794.05 toks/s]
Processed prompts:  41%|████      | 422/1024 [00:01<00:01, 306.01it/s, est. speed input: 365518.44 toks/s, output: 356.95 toks/s]   
Processed prompts:  49%|████▉     | 506/1024 [00:01<00:02, 249.31it/s, est. speed input: 304624.52 toks/s, output: 297.48 toks/s]
Processed prompts:  55%|█████▍    | 560/1024 [00:01<00:01, 234.38it/s, est. speed input: 288146.17 toks/s, output: 281.39 toks/s]
Processed prompts:  59%|█████▊    | 600/1024 [00:02<00:01, 219.40it/s, est. speed input: 275473.31 toks/s, output: 269.02 toks/s]
Processed prompts:  62%|██████▏   | 632/1024 [00:02<00:01, 208.97it/s, est. speed input: 267258.72 toks/s, output: 260.99 toks/s]
Processed prompts:  64%|██████▍   | 659/1024 [00:02<00:01, 194.28it/s, est. speed input: 258458.29 toks/s, output: 252.40 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:02<00:01, 187.99it/s, est. speed input: 253648.40 toks/s, output: 247.70 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:02<00:01, 183.39it/s, est. speed input: 249530.88 toks/s, output: 243.68 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:03<00:01, 179.54it/s, est. speed input: 245828.32 toks/s, output: 240.06 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:03<00:01, 176.25it/s, est. speed input: 242420.05 toks/s, output: 236.74 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:03<00:01, 173.88it/s, est. speed input: 239353.85 toks/s, output: 233.74 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:03<00:01, 172.40it/s, est. speed input: 236610.43 toks/s, output: 231.06 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:03<00:01, 171.14it/s, est. speed input: 234052.06 toks/s, output: 228.56 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:03<00:01, 170.33it/s, est. speed input: 231710.99 toks/s, output: 226.28 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:03<00:00, 169.14it/s, est. speed input: 229436.23 toks/s, output: 224.06 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:04<00:00, 168.52it/s, est. speed input: 227361.52 toks/s, output: 222.03 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:04<00:00, 167.74it/s, est. speed input: 225376.83 toks/s, output: 220.09 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:04<00:00, 169.07it/s, est. speed input: 223801.74 toks/s, output: 218.55 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:04<00:00, 168.80it/s, est. speed input: 222154.73 toks/s, output: 216.95 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:04<00:00, 170.03it/s, est. speed input: 220801.18 toks/s, output: 215.62 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:04<00:00, 135.48it/s, est. speed input: 213981.37 toks/s, output: 208.96 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 135.48it/s, est. speed input: 215226.47 toks/s, output: 210.18 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 210.17it/s, est. speed input: 215226.47 toks/s, output: 210.18 toks/s]
[rank0]:[W126 08:35:15.600715413 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:35:17
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:35:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1067652) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1067652) WARNING 01-26 08:35:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 167.55 requests/s, 171739.90 total tokens/s, 167.55 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:35:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:35:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:35:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:35:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:35:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:35:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:35:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:35:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:35:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:35:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:35:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:35:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:35:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:35:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:35:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:35:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:35:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1067652) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1067652) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.43it/s]
(EngineCore_DP0 pid=1067652) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.42it/s]
(EngineCore_DP0 pid=1067652) 
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1067652) [2026-01-26 08:35:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1067652) 2026-01-26 08:35:54,120 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1067652) 2026-01-26 08:35:54,153 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1067652) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 14.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 15.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  9.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.63it/s]
(EngineCore_DP0 pid=1067652) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.92it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  7.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  7.43it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 41/2048 [00:00<00:04, 404.82it/s]
Adding requests:   5%|▍         | 93/2048 [00:00<00:04, 470.78it/s]
Adding requests:   7%|▋         | 144/2048 [00:00<00:03, 488.36it/s]
Adding requests:   9%|▉         | 194/2048 [00:00<00:03, 490.77it/s]
Adding requests:  12%|█▏        | 246/2048 [00:00<00:03, 500.66it/s]
Adding requests:  15%|█▍        | 297/2048 [00:00<00:03, 501.95it/s]
Adding requests:  17%|█▋        | 348/2048 [00:00<00:03, 500.95it/s]
Adding requests:  20%|█▉        | 400/2048 [00:00<00:03, 506.44it/s]
Adding requests:  22%|██▏       | 451/2048 [00:00<00:03, 506.07it/s]
Adding requests:  25%|██▍       | 502/2048 [00:01<00:03, 504.51it/s]
Adding requests:  27%|██▋       | 553/2048 [00:01<00:02, 498.74it/s]
Adding requests:  30%|██▉       | 605/2048 [00:01<00:02, 502.01it/s]
Adding requests:  32%|███▏      | 658/2048 [00:01<00:02, 509.51it/s]
Adding requests:  35%|███▍      | 712/2048 [00:01<00:02, 516.87it/s]
Adding requests:  37%|███▋      | 764/2048 [00:01<00:02, 515.81it/s]
Adding requests:  40%|███▉      | 816/2048 [00:01<00:02, 508.21it/s]
Adding requests:  42%|████▏     | 867/2048 [00:01<00:02, 499.51it/s]
Adding requests:  45%|████▍     | 921/2048 [00:01<00:02, 509.10it/s]
Adding requests:  48%|████▊     | 974/2048 [00:01<00:02, 512.75it/s]
Adding requests:  50%|█████     | 1027/2048 [00:02<00:01, 516.67it/s]
Adding requests:  53%|█████▎    | 1079/2048 [00:02<00:01, 514.85it/s]
Adding requests:  55%|█████▌    | 1131/2048 [00:02<00:01, 512.45it/s]
Adding requests:  58%|█████▊    | 1186/2048 [00:02<00:01, 521.22it/s]
Adding requests:  61%|██████    | 1240/2048 [00:02<00:01, 523.99it/s]
Adding requests:  63%|██████▎   | 1293/2048 [00:02<00:01, 520.92it/s]
Adding requests:  66%|██████▌   | 1347/2048 [00:02<00:01, 523.28it/s]
Adding requests:  68%|██████▊   | 1401/2048 [00:02<00:01, 526.47it/s]
Adding requests:  71%|███████   | 1454/2048 [00:02<00:01, 525.04it/s]
Adding requests:  74%|███████▎  | 1508/2048 [00:02<00:01, 528.28it/s]
Adding requests:  76%|███████▌  | 1561/2048 [00:03<00:00, 520.39it/s]
Adding requests:  79%|███████▉  | 1615/2048 [00:03<00:00, 524.64it/s]
Adding requests:  81%|████████▏ | 1668/2048 [00:03<00:00, 521.65it/s]
Adding requests:  84%|████████▍ | 1722/2048 [00:03<00:00, 526.22it/s]
Adding requests:  87%|████████▋ | 1775/2048 [00:03<00:00, 522.22it/s]
Adding requests:  89%|████████▉ | 1828/2048 [00:03<00:00, 524.27it/s]
Adding requests:  92%|█████████▏| 1881/2048 [00:03<00:00, 523.72it/s]
Adding requests:  94%|█████████▍| 1934/2048 [00:03<00:00, 524.24it/s]
Adding requests:  97%|█████████▋| 1987/2048 [00:03<00:00, 510.30it/s]
Adding requests: 100%|█████████▉| 2041/2048 [00:03<00:00, 516.80it/s]
Adding requests: 100%|██████████| 2048/2048 [00:03<00:00, 512.96it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:00<00:00, 4177.34it/s, est. speed input: 4278529.81 toks/s, output: 4177.79 toks/s]
Processed prompts:  51%|█████     | 1044/2048 [00:02<00:02, 342.81it/s, est. speed input: 420472.87 toks/s, output: 410.62 toks/s]  
Processed prompts:  60%|█████▉    | 1227/2048 [00:03<00:02, 283.35it/s, est. speed input: 353410.34 toks/s, output: 345.12 toks/s]
Processed prompts:  65%|██████▌   | 1335/2048 [00:04<00:02, 255.06it/s, est. speed input: 326026.27 toks/s, output: 318.38 toks/s]
Processed prompts:  69%|██████▊   | 1407/2048 [00:04<00:02, 244.80it/s, est. speed input: 315776.91 toks/s, output: 308.38 toks/s]
Processed prompts:  71%|███████▏  | 1460/2048 [00:04<00:02, 224.91it/s, est. speed input: 303102.27 toks/s, output: 296.00 toks/s]
Processed prompts:  73%|███████▎  | 1500/2048 [00:05<00:02, 223.83it/s, est. speed input: 300143.64 toks/s, output: 293.11 toks/s]
Processed prompts:  75%|███████▍  | 1534/2048 [00:05<00:02, 217.94it/s, est. speed input: 296263.46 toks/s, output: 289.32 toks/s]
Processed prompts:  76%|███████▋  | 1563/2048 [00:05<00:02, 207.33it/s, est. speed input: 291725.53 toks/s, output: 284.89 toks/s]
Processed prompts:  78%|███████▊  | 1588/2048 [00:05<00:02, 193.99it/s, est. speed input: 287002.89 toks/s, output: 280.28 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:05<00:02, 186.84it/s, est. speed input: 283174.54 toks/s, output: 276.54 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:06<00:02, 184.32it/s, est. speed input: 280086.44 toks/s, output: 273.52 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:06<00:02, 181.49it/s, est. speed input: 277039.52 toks/s, output: 270.54 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:06<00:01, 179.21it/s, est. speed input: 274155.48 toks/s, output: 267.73 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:06<00:01, 177.62it/s, est. speed input: 271451.95 toks/s, output: 265.09 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:06<00:01, 176.48it/s, est. speed input: 268900.98 toks/s, output: 262.60 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:06<00:01, 175.17it/s, est. speed input: 266419.51 toks/s, output: 260.17 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:07<00:01, 174.35it/s, est. speed input: 264082.49 toks/s, output: 257.89 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:07<00:00, 175.29it/s, est. speed input: 262059.47 toks/s, output: 255.92 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:07<00:00, 174.57it/s, est. speed input: 259962.64 toks/s, output: 253.87 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:07<00:00, 174.02it/s, est. speed input: 257961.75 toks/s, output: 251.91 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:07<00:00, 175.03it/s, est. speed input: 256215.44 toks/s, output: 250.21 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:08<00:00, 177.14it/s, est. speed input: 254699.92 toks/s, output: 248.73 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:08<00:00, 177.67it/s, est. speed input: 253145.72 toks/s, output: 247.21 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:08<00:00, 177.67it/s, est. speed input: 254867.90 toks/s, output: 248.89 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:08<00:00, 248.89it/s, est. speed input: 254867.90 toks/s, output: 248.89 toks/s]
[rank0]:[W126 08:36:09.454648511 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:36:12
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:36:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1069034) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1069034) WARNING 01-26 08:36:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 176.86 requests/s, 181281.58 total tokens/s, 176.86 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:36:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:36:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:36:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:36:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:36:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:36:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:36:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:36:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:36:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:36:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:36:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:36:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:36:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:36:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:36:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:36:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:36:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1069034) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1069034) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1069034) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1069034) 
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1069034) [2026-01-26 08:36:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1069034) [rank0]:W0126 08:36:52.014000 1069034 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1069034) [rank0]:W0126 08:36:52.068000 1069034 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1069034) [rank0]:W0126 08:36:52.983000 1069034 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1069034) [rank0]:W0126 08:36:53.058000 1069034 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1069034) 2026-01-26 08:36:56,106 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1069034) 2026-01-26 08:36:56,197 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1069034) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 14.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 16.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00, 10.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  6.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  5.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.96it/s]
(EngineCore_DP0 pid=1069034) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.99it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 12.40it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 16.40it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 15.38it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 33/4096 [00:00<00:12, 325.24it/s]
Adding requests:   2%|▏         | 85/4096 [00:00<00:09, 437.15it/s]
Adding requests:   3%|▎         | 136/4096 [00:00<00:08, 469.16it/s]
Adding requests:   5%|▍         | 186/4096 [00:00<00:08, 481.14it/s]
Adding requests:   6%|▌         | 238/4096 [00:00<00:07, 492.46it/s]
Adding requests:   7%|▋         | 289/4096 [00:00<00:07, 497.00it/s]
Adding requests:   8%|▊         | 339/4096 [00:00<00:07, 497.68it/s]
Adding requests:  10%|▉         | 392/4096 [00:00<00:07, 505.89it/s]
Adding requests:  11%|█         | 443/4096 [00:00<00:07, 506.24it/s]
Adding requests:  12%|█▏        | 495/4096 [00:01<00:07, 508.38it/s]
Adding requests:  13%|█▎        | 546/4096 [00:01<00:07, 501.09it/s]
Adding requests:  15%|█▍        | 599/4096 [00:01<00:06, 508.01it/s]
Adding requests:  16%|█▌        | 652/4096 [00:01<00:06, 513.04it/s]
Adding requests:  17%|█▋        | 706/4096 [00:01<00:06, 519.71it/s]
Adding requests:  19%|█▊        | 758/4096 [00:01<00:06, 518.71it/s]
Adding requests:  20%|█▉        | 810/4096 [00:01<00:06, 510.74it/s]
Adding requests:  21%|██        | 862/4096 [00:01<00:06, 510.56it/s]
Adding requests:  22%|██▏       | 915/4096 [00:01<00:06, 515.34it/s]
Adding requests:  24%|██▎       | 968/4096 [00:01<00:06, 518.33it/s]
Adding requests:  25%|██▍       | 1020/4096 [00:02<00:05, 518.56it/s]
Adding requests:  26%|██▌       | 1072/4096 [00:02<00:06, 502.36it/s]
Adding requests:  27%|██▋       | 1124/4096 [00:02<00:05, 505.74it/s]
Adding requests:  29%|██▉       | 1178/4096 [00:02<00:05, 514.82it/s]
Adding requests:  30%|███       | 1232/4096 [00:02<00:05, 522.06it/s]
Adding requests:  31%|███▏      | 1285/4096 [00:02<00:05, 517.53it/s]
Adding requests:  33%|███▎      | 1338/4096 [00:02<00:05, 520.78it/s]
Adding requests:  34%|███▍      | 1392/4096 [00:02<00:05, 524.72it/s]
Adding requests:  35%|███▌      | 1445/4096 [00:02<00:05, 522.88it/s]
Adding requests:  37%|███▋      | 1500/4096 [00:02<00:04, 529.45it/s]
Adding requests:  38%|███▊      | 1553/4096 [00:03<00:04, 527.05it/s]
Adding requests:  39%|███▉      | 1608/4096 [00:03<00:04, 533.86it/s]
Adding requests:  41%|████      | 1662/4096 [00:03<00:04, 529.36it/s]
Adding requests:  42%|████▏     | 1715/4096 [00:03<00:04, 528.88it/s]
Adding requests:  43%|████▎     | 1768/4096 [00:03<00:04, 525.15it/s]
Adding requests:  44%|████▍     | 1821/4096 [00:03<00:04, 526.24it/s]
Adding requests:  46%|████▌     | 1874/4096 [00:03<00:04, 524.09it/s]
Adding requests:  47%|████▋     | 1927/4096 [00:03<00:04, 523.10it/s]
Adding requests:  48%|████▊     | 1980/4096 [00:03<00:04, 523.07it/s]
Adding requests:  50%|████▉     | 2034/4096 [00:03<00:03, 525.40it/s]
Adding requests:  51%|█████     | 2088/4096 [00:04<00:03, 528.06it/s]
Adding requests:  52%|█████▏    | 2141/4096 [00:04<00:03, 521.62it/s]
Adding requests:  54%|█████▎    | 2194/4096 [00:04<00:03, 519.04it/s]
Adding requests:  55%|█████▍    | 2246/4096 [00:04<00:03, 508.35it/s]
Adding requests:  56%|█████▌    | 2299/4096 [00:04<00:03, 513.56it/s]
Adding requests:  57%|█████▋    | 2351/4096 [00:04<00:03, 514.37it/s]
Adding requests:  59%|█████▊    | 2403/4096 [00:04<00:03, 515.38it/s]
Adding requests:  60%|█████▉    | 2456/4096 [00:04<00:03, 518.22it/s]
Adding requests:  61%|██████    | 2508/4096 [00:04<00:03, 517.41it/s]
Adding requests:  63%|██████▎   | 2562/4096 [00:04<00:02, 522.17it/s]
Adding requests:  64%|██████▍   | 2615/4096 [00:05<00:02, 523.00it/s]
Adding requests:  65%|██████▌   | 2669/4096 [00:05<00:02, 526.53it/s]
Adding requests:  66%|██████▋   | 2722/4096 [00:05<00:02, 521.29it/s]
Adding requests:  68%|██████▊   | 2775/4096 [00:05<00:02, 521.54it/s]
Adding requests:  69%|██████▉   | 2828/4096 [00:05<00:02, 516.92it/s]
Adding requests:  70%|███████   | 2881/4096 [00:05<00:02, 520.54it/s]
Adding requests:  72%|███████▏  | 2934/4096 [00:05<00:02, 518.94it/s]
Adding requests:  73%|███████▎  | 2987/4096 [00:05<00:02, 521.16it/s]
Adding requests:  74%|███████▍  | 3040/4096 [00:05<00:02, 519.75it/s]
Adding requests:  75%|███████▌  | 3092/4096 [00:06<00:01, 518.06it/s]
Adding requests:  77%|███████▋  | 3144/4096 [00:06<00:01, 517.03it/s]
Adding requests:  78%|███████▊  | 3197/4096 [00:06<00:01, 518.99it/s]
Adding requests:  79%|███████▉  | 3251/4096 [00:06<00:01, 523.29it/s]
Adding requests:  81%|████████  | 3304/4096 [00:06<00:01, 523.29it/s]
Adding requests:  82%|████████▏ | 3357/4096 [00:06<00:01, 524.27it/s]
Adding requests:  83%|████████▎ | 3410/4096 [00:06<00:01, 523.37it/s]
Adding requests:  85%|████████▍ | 3463/4096 [00:06<00:01, 519.81it/s]
Adding requests:  86%|████████▌ | 3515/4096 [00:06<00:01, 507.99it/s]
Adding requests:  87%|████████▋ | 3566/4096 [00:06<00:01, 502.12it/s]
Adding requests:  88%|████████▊ | 3619/4096 [00:07<00:00, 506.16it/s]
Adding requests:  90%|████████▉ | 3672/4096 [00:07<00:00, 511.85it/s]
Adding requests:  91%|█████████ | 3725/4096 [00:07<00:00, 516.23it/s]
Adding requests:  92%|█████████▏| 3779/4096 [00:07<00:00, 523.24it/s]
Adding requests:  94%|█████████▎| 3833/4096 [00:07<00:00, 526.02it/s]
Adding requests:  95%|█████████▍| 3887/4096 [00:07<00:00, 527.18it/s]
Adding requests:  96%|█████████▌| 3940/4096 [00:07<00:00, 527.48it/s]
Adding requests:  97%|█████████▋| 3993/4096 [00:07<00:00, 524.69it/s]
Adding requests:  99%|█████████▉| 4046/4096 [00:07<00:00, 523.89it/s]
Adding requests: 100%|██████████| 4096/4096 [00:07<00:00, 516.27it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▍      | 1391/4096 [00:00<00:00, 5701.87it/s, est. speed input: 5839780.17 toks/s, output: 5702.16 toks/s]
Processed prompts:  48%|████▊     | 1962/4096 [00:03<00:04, 476.66it/s, est. speed input: 606276.60 toks/s, output: 592.06 toks/s]   
Processed prompts:  54%|█████▍    | 2208/4096 [00:04<00:05, 359.51it/s, est. speed input: 477271.76 toks/s, output: 466.08 toks/s]
Processed prompts:  57%|█████▋    | 2350/4096 [00:05<00:05, 326.05it/s, est. speed input: 442510.16 toks/s, output: 432.14 toks/s]
Processed prompts:  60%|█████▉    | 2444/4096 [00:05<00:05, 298.98it/s, est. speed input: 419864.08 toks/s, output: 410.02 toks/s]
Processed prompts:  61%|██████▏   | 2511/4096 [00:06<00:06, 261.71it/s, est. speed input: 395703.93 toks/s, output: 386.43 toks/s]
Processed prompts:  62%|██████▎   | 2560/4096 [00:06<00:05, 262.15it/s, est. speed input: 392317.07 toks/s, output: 383.12 toks/s]
Processed prompts:  64%|██████▎   | 2602/4096 [00:06<00:05, 259.01it/s, est. speed input: 388368.56 toks/s, output: 379.27 toks/s]
Processed prompts:  64%|██████▍   | 2638/4096 [00:07<00:05, 249.99it/s, est. speed input: 383518.98 toks/s, output: 374.53 toks/s]
Processed prompts:  65%|██████▌   | 2669/4096 [00:07<00:06, 236.65it/s, est. speed input: 378319.05 toks/s, output: 369.45 toks/s]
Processed prompts:  66%|██████▌   | 2696/4096 [00:07<00:06, 219.50it/s, est. speed input: 372799.85 toks/s, output: 364.06 toks/s]
Processed prompts:  66%|██████▋   | 2719/4096 [00:07<00:06, 199.72it/s, est. speed input: 367092.39 toks/s, output: 358.49 toks/s]
Processed prompts:  67%|██████▋   | 2739/4096 [00:07<00:07, 178.03it/s, est. speed input: 361088.56 toks/s, output: 352.62 toks/s]
Processed prompts:  68%|██████▊   | 2767/4096 [00:07<00:07, 172.01it/s, est. speed input: 356455.46 toks/s, output: 348.10 toks/s]
Processed prompts:  68%|██████▊   | 2799/4096 [00:08<00:07, 173.34it/s, est. speed input: 352559.15 toks/s, output: 344.29 toks/s]
Processed prompts:  69%|██████▉   | 2831/4096 [00:08<00:07, 177.35it/s, est. speed input: 349299.84 toks/s, output: 341.11 toks/s]
Processed prompts:  70%|██████▉   | 2863/4096 [00:08<00:06, 178.33it/s, est. speed input: 345874.36 toks/s, output: 337.77 toks/s]
Processed prompts:  71%|███████   | 2895/4096 [00:08<00:06, 177.20it/s, est. speed input: 342332.49 toks/s, output: 334.31 toks/s]
Processed prompts:  71%|███████▏  | 2927/4096 [00:08<00:06, 176.41it/s, est. speed input: 338940.57 toks/s, output: 331.00 toks/s]
Processed prompts:  72%|███████▏  | 2959/4096 [00:09<00:06, 178.20it/s, est. speed input: 335988.66 toks/s, output: 328.11 toks/s]
Processed prompts:  73%|███████▎  | 2991/4096 [00:09<00:06, 177.68it/s, est. speed input: 332926.60 toks/s, output: 325.12 toks/s]
Processed prompts:  74%|███████▍  | 3023/4096 [00:09<00:06, 177.05it/s, est. speed input: 329952.44 toks/s, output: 322.22 toks/s]
Processed prompts:  75%|███████▍  | 3055/4096 [00:09<00:05, 176.55it/s, est. speed input: 327084.29 toks/s, output: 319.42 toks/s]
Processed prompts:  75%|███████▌  | 3087/4096 [00:09<00:05, 177.83it/s, est. speed input: 324508.57 toks/s, output: 316.90 toks/s]
Processed prompts:  76%|███████▌  | 3119/4096 [00:09<00:05, 180.43it/s, est. speed input: 322206.80 toks/s, output: 314.65 toks/s]
Processed prompts:  77%|███████▋  | 3151/4096 [00:10<00:05, 181.24it/s, est. speed input: 319875.08 toks/s, output: 312.38 toks/s]
Processed prompts:  78%|███████▊  | 3183/4096 [00:10<00:05, 179.91it/s, est. speed input: 317430.01 toks/s, output: 309.99 toks/s]
Processed prompts:  78%|███████▊  | 3215/4096 [00:10<00:04, 181.89it/s, est. speed input: 315357.59 toks/s, output: 307.97 toks/s]
Processed prompts:  79%|███████▉  | 3247/4096 [00:10<00:04, 179.84it/s, est. speed input: 313020.26 toks/s, output: 305.68 toks/s]
Processed prompts:  80%|████████  | 3279/4096 [00:10<00:04, 178.54it/s, est. speed input: 310772.79 toks/s, output: 303.49 toks/s]
Processed prompts:  81%|████████  | 3311/4096 [00:10<00:04, 177.68it/s, est. speed input: 308603.85 toks/s, output: 301.37 toks/s]
Processed prompts:  82%|████████▏ | 3343/4096 [00:11<00:04, 177.47it/s, est. speed input: 306540.27 toks/s, output: 299.36 toks/s]
Processed prompts:  82%|████████▏ | 3375/4096 [00:11<00:04, 176.95it/s, est. speed input: 304510.73 toks/s, output: 297.37 toks/s]
Processed prompts:  83%|████████▎ | 3407/4096 [00:11<00:03, 176.76it/s, est. speed input: 302559.93 toks/s, output: 295.47 toks/s]
Processed prompts:  84%|████████▍ | 3439/4096 [00:11<00:03, 177.92it/s, est. speed input: 300784.40 toks/s, output: 293.73 toks/s]
Processed prompts:  85%|████████▍ | 3471/4096 [00:11<00:03, 180.77it/s, est. speed input: 299225.57 toks/s, output: 292.21 toks/s]
Processed prompts:  86%|████████▌ | 3503/4096 [00:12<00:03, 180.88it/s, est. speed input: 297558.39 toks/s, output: 290.58 toks/s]
Processed prompts:  86%|████████▋ | 3535/4096 [00:12<00:03, 179.19it/s, est. speed input: 295799.42 toks/s, output: 288.87 toks/s]
Processed prompts:  87%|████████▋ | 3567/4096 [00:12<00:02, 178.07it/s, est. speed input: 294095.34 toks/s, output: 287.20 toks/s]
Processed prompts:  88%|████████▊ | 3599/4096 [00:12<00:02, 177.07it/s, est. speed input: 292422.46 toks/s, output: 285.57 toks/s]
Processed prompts:  89%|████████▊ | 3631/4096 [00:12<00:02, 176.68it/s, est. speed input: 290821.60 toks/s, output: 284.00 toks/s]
Processed prompts:  89%|████████▉ | 3663/4096 [00:12<00:02, 176.33it/s, est. speed input: 289259.69 toks/s, output: 282.48 toks/s]
Processed prompts:  90%|█████████ | 3695/4096 [00:13<00:02, 176.21it/s, est. speed input: 287750.66 toks/s, output: 281.01 toks/s]
Processed prompts:  91%|█████████ | 3727/4096 [00:13<00:02, 177.80it/s, est. speed input: 286405.08 toks/s, output: 279.69 toks/s]
Processed prompts:  92%|█████████▏| 3759/4096 [00:13<00:01, 177.52it/s, est. speed input: 284994.32 toks/s, output: 278.31 toks/s]
Processed prompts:  93%|█████████▎| 3791/4096 [00:13<00:01, 176.98it/s, est. speed input: 283596.98 toks/s, output: 276.95 toks/s]
Processed prompts:  93%|█████████▎| 3823/4096 [00:13<00:01, 176.81it/s, est. speed input: 282250.60 toks/s, output: 275.63 toks/s]
Processed prompts:  94%|█████████▍| 3855/4096 [00:14<00:01, 179.52it/s, est. speed input: 281129.64 toks/s, output: 274.54 toks/s]
Processed prompts:  95%|█████████▍| 3887/4096 [00:14<00:01, 178.18it/s, est. speed input: 279821.56 toks/s, output: 273.26 toks/s]
Processed prompts:  96%|█████████▌| 3919/4096 [00:14<00:00, 177.41it/s, est. speed input: 278557.50 toks/s, output: 272.03 toks/s]
Processed prompts:  96%|█████████▋| 3951/4096 [00:14<00:00, 176.72it/s, est. speed input: 277314.92 toks/s, output: 270.81 toks/s]
Processed prompts:  97%|█████████▋| 3983/4096 [00:14<00:00, 176.53it/s, est. speed input: 276121.44 toks/s, output: 269.65 toks/s]
Processed prompts:  98%|█████████▊| 4015/4096 [00:14<00:00, 177.69it/s, est. speed input: 275037.64 toks/s, output: 268.59 toks/s]
Processed prompts:  99%|█████████▉| 4047/4096 [00:15<00:00, 180.93it/s, est. speed input: 274124.44 toks/s, output: 267.70 toks/s]
Processed prompts: 100%|█████████▉| 4079/4096 [00:15<00:00, 206.58it/s, est. speed input: 274410.46 toks/s, output: 267.98 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:15<00:00, 206.58it/s, est. speed input: 275541.13 toks/s, output: 269.08 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:15<00:00, 269.08it/s, est. speed input: 275541.13 toks/s, output: 269.08 toks/s]
[rank0]:[W126 08:37:23.053405096 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:37:25
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:38:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1070759) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1070759) WARNING 01-26 08:38:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 178.87 requests/s, 183342.34 total tokens/s, 178.87 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:38:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:38:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:38:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:38:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:38:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:38:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:38:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:38:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:38:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:38:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:38:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:38:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:38:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:38:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:38:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:38:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:38:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1070759) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1070759) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.38it/s]
(EngineCore_DP0 pid=1070759) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.38it/s]
(EngineCore_DP0 pid=1070759) 
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6340608 bytes
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4227072 bytes
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 33816576 bytes
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1070759) [2026-01-26 08:38:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16793600 bytes
(EngineCore_DP0 pid=1070759) [rank0]:W0126 08:38:23.013000 1070759 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1070759) [rank0]:W0126 08:38:23.067000 1070759 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1070759) [rank0]:W0126 08:38:23.985000 1070759 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1070759) [rank0]:W0126 08:38:24.063000 1070759 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1070759) 2026-01-26 08:38:26,833 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1070759) 2026-01-26 08:38:26,864 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1070759) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:05,  3.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:04,  3.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:02,  5.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  8.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:00,  9.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00, 11.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:01<00:00, 14.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 15.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 10.32it/s]
(EngineCore_DP0 pid=1070759) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  4.01it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:02,  4.38it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  2.79it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:01,  5.40it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  9.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 10.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.61it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 41/8192 [00:00<00:20, 406.04it/s]
Adding requests:   1%|          | 93/8192 [00:00<00:17, 472.65it/s]
Adding requests:   2%|▏         | 144/8192 [00:00<00:16, 487.22it/s]
Adding requests:   2%|▏         | 194/8192 [00:00<00:16, 491.03it/s]
Adding requests:   3%|▎         | 247/8192 [00:00<00:15, 502.09it/s]
Adding requests:   4%|▎         | 299/8192 [00:00<00:15, 504.19it/s]
Adding requests:   4%|▍         | 350/8192 [00:00<00:15, 505.13it/s]
Adding requests:   5%|▍         | 402/8192 [00:00<00:15, 509.59it/s]
Adding requests:   6%|▌         | 454/8192 [00:00<00:15, 510.68it/s]
Adding requests:   6%|▌         | 506/8192 [00:01<00:15, 509.52it/s]
Adding requests:   7%|▋         | 557/8192 [00:01<00:15, 505.19it/s]
Adding requests:   7%|▋         | 608/8192 [00:01<00:15, 501.73it/s]
Adding requests:   8%|▊         | 662/8192 [00:01<00:14, 511.03it/s]
Adding requests:   9%|▊         | 716/8192 [00:01<00:14, 518.29it/s]
Adding requests:   9%|▉         | 768/8192 [00:01<00:14, 517.79it/s]
Adding requests:  10%|█         | 820/8192 [00:01<00:14, 508.86it/s]
Adding requests:  11%|█         | 872/8192 [00:01<00:14, 510.20it/s]
Adding requests:  11%|█▏        | 925/8192 [00:01<00:14, 515.94it/s]
Adding requests:  12%|█▏        | 978/8192 [00:01<00:13, 516.27it/s]
Adding requests:  13%|█▎        | 1032/8192 [00:02<00:13, 520.10it/s]
Adding requests:  13%|█▎        | 1085/8192 [00:02<00:13, 515.63it/s]
Adding requests:  14%|█▍        | 1137/8192 [00:02<00:13, 513.09it/s]
Adding requests:  15%|█▍        | 1192/8192 [00:02<00:13, 523.43it/s]
Adding requests:  15%|█▌        | 1245/8192 [00:02<00:13, 524.52it/s]
Adding requests:  16%|█▌        | 1298/8192 [00:02<00:13, 520.62it/s]
Adding requests:  16%|█▋        | 1351/8192 [00:02<00:13, 522.64it/s]
Adding requests:  17%|█▋        | 1406/8192 [00:02<00:12, 528.48it/s]
Adding requests:  18%|█▊        | 1459/8192 [00:02<00:12, 525.52it/s]
Adding requests:  18%|█▊        | 1513/8192 [00:02<00:12, 526.74it/s]
Adding requests:  19%|█▉        | 1566/8192 [00:03<00:12, 526.11it/s]
Adding requests:  20%|█▉        | 1620/8192 [00:03<00:12, 529.54it/s]
Adding requests:  20%|██        | 1673/8192 [00:03<00:12, 525.89it/s]
Adding requests:  21%|██        | 1726/8192 [00:03<00:12, 519.41it/s]
Adding requests:  22%|██▏       | 1778/8192 [00:03<00:12, 517.52it/s]
Adding requests:  22%|██▏       | 1831/8192 [00:03<00:12, 518.69it/s]
Adding requests:  23%|██▎       | 1884/8192 [00:03<00:12, 520.39it/s]
Adding requests:  24%|██▎       | 1937/8192 [00:03<00:12, 520.08it/s]
Adding requests:  24%|██▍       | 1990/8192 [00:03<00:11, 520.12it/s]
Adding requests:  25%|██▍       | 2043/8192 [00:03<00:11, 522.56it/s]
Adding requests:  26%|██▌       | 2097/8192 [00:04<00:11, 525.66it/s]
Adding requests:  26%|██▌       | 2150/8192 [00:04<00:11, 519.97it/s]
Adding requests:  27%|██▋       | 2203/8192 [00:04<00:11, 516.30it/s]
Adding requests:  28%|██▊       | 2257/8192 [00:04<00:11, 522.49it/s]
Adding requests:  28%|██▊       | 2310/8192 [00:04<00:11, 522.96it/s]
Adding requests:  29%|██▉       | 2363/8192 [00:04<00:11, 520.62it/s]
Adding requests:  29%|██▉       | 2416/8192 [00:04<00:11, 521.40it/s]
Adding requests:  30%|███       | 2469/8192 [00:04<00:10, 521.28it/s]
Adding requests:  31%|███       | 2522/8192 [00:04<00:10, 521.23it/s]
Adding requests:  31%|███▏      | 2576/8192 [00:04<00:10, 525.31it/s]
Adding requests:  32%|███▏      | 2629/8192 [00:05<00:10, 523.59it/s]
Adding requests:  33%|███▎      | 2682/8192 [00:05<00:10, 524.10it/s]
Adding requests:  33%|███▎      | 2735/8192 [00:05<00:10, 519.95it/s]
Adding requests:  34%|███▍      | 2788/8192 [00:05<00:10, 519.75it/s]
Adding requests:  35%|███▍      | 2840/8192 [00:05<00:10, 518.92it/s]
Adding requests:  35%|███▌      | 2893/8192 [00:05<00:10, 521.38it/s]
Adding requests:  36%|███▌      | 2946/8192 [00:05<00:10, 517.71it/s]
Adding requests:  37%|███▋      | 2998/8192 [00:05<00:10, 508.61it/s]
Adding requests:  37%|███▋      | 3051/8192 [00:05<00:10, 512.77it/s]
Adding requests:  38%|███▊      | 3103/8192 [00:06<00:09, 512.35it/s]
Adding requests:  39%|███▊      | 3155/8192 [00:06<00:09, 514.29it/s]
Adding requests:  39%|███▉      | 3207/8192 [00:06<00:09, 515.85it/s]
Adding requests:  40%|███▉      | 3260/8192 [00:06<00:09, 519.92it/s]
Adding requests:  40%|████      | 3313/8192 [00:06<00:09, 521.99it/s]
Adding requests:  41%|████      | 3367/8192 [00:06<00:09, 526.21it/s]
Adding requests:  42%|████▏     | 3420/8192 [00:06<00:09, 526.31it/s]
Adding requests:  42%|████▏     | 3473/8192 [00:06<00:09, 515.91it/s]
Adding requests:  43%|████▎     | 3526/8192 [00:06<00:09, 517.94it/s]
Adding requests:  44%|████▎     | 3578/8192 [00:06<00:08, 518.21it/s]
Adding requests:  44%|████▍     | 3630/8192 [00:07<00:08, 515.80it/s]
Adding requests:  45%|████▍     | 3683/8192 [00:07<00:08, 517.49it/s]
Adding requests:  46%|████▌     | 3735/8192 [00:07<00:08, 515.57it/s]
Adding requests:  46%|████▋     | 3790/8192 [00:07<00:08, 524.40it/s]
Adding requests:  47%|████▋     | 3844/8192 [00:07<00:08, 527.68it/s]
Adding requests:  48%|████▊     | 3897/8192 [00:07<00:08, 525.06it/s]
Adding requests:  48%|████▊     | 3950/8192 [00:07<00:08, 526.06it/s]
Adding requests:  49%|████▉     | 4003/8192 [00:07<00:08, 523.58it/s]
Adding requests:  50%|████▉     | 4056/8192 [00:07<00:07, 521.16it/s]
Adding requests:  50%|█████     | 4109/8192 [00:07<00:07, 521.66it/s]
Adding requests:  51%|█████     | 4162/8192 [00:08<00:07, 524.04it/s]
Adding requests:  51%|█████▏    | 4216/8192 [00:08<00:07, 525.76it/s]
Adding requests:  52%|█████▏    | 4269/8192 [00:08<00:07, 525.20it/s]
Adding requests:  53%|█████▎    | 4322/8192 [00:08<00:07, 514.10it/s]
Adding requests:  53%|█████▎    | 4376/8192 [00:08<00:07, 521.60it/s]
Adding requests:  54%|█████▍    | 4429/8192 [00:08<00:07, 519.22it/s]
Adding requests:  55%|█████▍    | 4481/8192 [00:08<00:07, 519.33it/s]
Adding requests:  55%|█████▌    | 4533/8192 [00:08<00:07, 516.32it/s]
Adding requests:  56%|█████▌    | 4586/8192 [00:08<00:06, 519.54it/s]
Adding requests:  57%|█████▋    | 4640/8192 [00:08<00:06, 523.84it/s]
Adding requests:  57%|█████▋    | 4693/8192 [00:09<00:06, 519.72it/s]
Adding requests:  58%|█████▊    | 4747/8192 [00:09<00:06, 524.29it/s]
Adding requests:  59%|█████▊    | 4800/8192 [00:09<00:06, 522.40it/s]
Adding requests:  59%|█████▉    | 4853/8192 [00:09<00:06, 522.75it/s]
Adding requests:  60%|█████▉    | 4906/8192 [00:09<00:06, 519.14it/s]
Adding requests:  61%|██████    | 4959/8192 [00:09<00:06, 521.58it/s]
Adding requests:  61%|██████    | 5013/8192 [00:09<00:06, 525.35it/s]
Adding requests:  62%|██████▏   | 5067/8192 [00:09<00:05, 527.32it/s]
Adding requests:  63%|██████▎   | 5122/8192 [00:09<00:05, 531.45it/s]
Adding requests:  63%|██████▎   | 5176/8192 [00:09<00:05, 529.98it/s]
Adding requests:  64%|██████▍   | 5230/8192 [00:10<00:05, 525.69it/s]
Adding requests:  64%|██████▍   | 5283/8192 [00:10<00:05, 522.70it/s]
Adding requests:  65%|██████▌   | 5337/8192 [00:10<00:05, 527.75it/s]
Adding requests:  66%|██████▌   | 5390/8192 [00:10<00:05, 528.16it/s]
Adding requests:  66%|██████▋   | 5443/8192 [00:10<00:05, 526.78it/s]
Adding requests:  67%|██████▋   | 5496/8192 [00:10<00:05, 523.09it/s]
Adding requests:  68%|██████▊   | 5549/8192 [00:10<00:05, 521.93it/s]
Adding requests:  68%|██████▊   | 5602/8192 [00:10<00:05, 509.14it/s]
Adding requests:  69%|██████▉   | 5653/8192 [00:10<00:04, 508.00it/s]
Adding requests:  70%|██████▉   | 5705/8192 [00:11<00:04, 511.48it/s]
Adding requests:  70%|███████   | 5758/8192 [00:11<00:04, 516.79it/s]
Adding requests:  71%|███████   | 5810/8192 [00:11<00:04, 514.66it/s]
Adding requests:  72%|███████▏  | 5863/8192 [00:11<00:04, 518.49it/s]
Adding requests:  72%|███████▏  | 5917/8192 [00:11<00:04, 523.35it/s]
Adding requests:  73%|███████▎  | 5970/8192 [00:11<00:04, 521.87it/s]
Adding requests:  74%|███████▎  | 6024/8192 [00:11<00:04, 526.32it/s]
Adding requests:  74%|███████▍  | 6077/8192 [00:11<00:04, 527.04it/s]
Adding requests:  75%|███████▍  | 6130/8192 [00:11<00:03, 526.02it/s]
Adding requests:  75%|███████▌  | 6183/8192 [00:11<00:03, 527.04it/s]
Adding requests:  76%|███████▌  | 6238/8192 [00:12<00:03, 532.98it/s]
Adding requests:  77%|███████▋  | 6292/8192 [00:12<00:03, 534.81it/s]
Adding requests:  77%|███████▋  | 6346/8192 [00:12<00:03, 535.36it/s]
Adding requests:  78%|███████▊  | 6400/8192 [00:12<00:03, 535.40it/s]
Adding requests:  79%|███████▉  | 6455/8192 [00:12<00:03, 539.22it/s]
Adding requests:  79%|███████▉  | 6510/8192 [00:12<00:03, 541.69it/s]
Adding requests:  80%|████████  | 6565/8192 [00:12<00:03, 538.53it/s]
Adding requests:  81%|████████  | 6619/8192 [00:12<00:02, 534.18it/s]
Adding requests:  81%|████████▏ | 6673/8192 [00:12<00:02, 532.51it/s]
Adding requests:  82%|████████▏ | 6727/8192 [00:12<00:02, 532.91it/s]
Adding requests:  83%|████████▎ | 6781/8192 [00:13<00:02, 532.87it/s]
Adding requests:  83%|████████▎ | 6835/8192 [00:13<00:02, 533.44it/s]
Adding requests:  84%|████████▍ | 6890/8192 [00:13<00:02, 536.78it/s]
Adding requests:  85%|████████▍ | 6944/8192 [00:13<00:02, 521.82it/s]
Adding requests:  85%|████████▌ | 6997/8192 [00:13<00:02, 523.25it/s]
Adding requests:  86%|████████▌ | 7050/8192 [00:13<00:02, 521.49it/s]
Adding requests:  87%|████████▋ | 7104/8192 [00:13<00:02, 526.41it/s]
Adding requests:  87%|████████▋ | 7157/8192 [00:13<00:01, 524.46it/s]
Adding requests:  88%|████████▊ | 7210/8192 [00:13<00:01, 525.52it/s]
Adding requests:  89%|████████▊ | 7264/8192 [00:13<00:01, 527.21it/s]
Adding requests:  89%|████████▉ | 7318/8192 [00:14<00:01, 530.92it/s]
Adding requests:  90%|████████▉ | 7372/8192 [00:14<00:01, 527.71it/s]
Adding requests:  91%|█████████ | 7428/8192 [00:14<00:01, 535.48it/s]
Adding requests:  91%|█████████▏| 7482/8192 [00:14<00:01, 536.18it/s]
Adding requests:  92%|█████████▏| 7536/8192 [00:14<00:01, 534.22it/s]
Adding requests:  93%|█████████▎| 7590/8192 [00:14<00:01, 532.13it/s]
Adding requests:  93%|█████████▎| 7644/8192 [00:14<00:01, 532.23it/s]
Adding requests:  94%|█████████▍| 7699/8192 [00:14<00:00, 535.38it/s]
Adding requests:  95%|█████████▍| 7753/8192 [00:14<00:00, 530.80it/s]
Adding requests:  95%|█████████▌| 7807/8192 [00:14<00:00, 523.99it/s]
Adding requests:  96%|█████████▌| 7862/8192 [00:15<00:00, 529.59it/s]
Adding requests:  97%|█████████▋| 7915/8192 [00:15<00:00, 523.17it/s]
Adding requests:  97%|█████████▋| 7968/8192 [00:15<00:00, 523.97it/s]
Adding requests:  98%|█████████▊| 8021/8192 [00:15<00:00, 520.20it/s]
Adding requests:  99%|█████████▊| 8075/8192 [00:15<00:00, 524.31it/s]
Adding requests:  99%|█████████▉| 8129/8192 [00:15<00:00, 524.82it/s]
Adding requests: 100%|█████████▉| 8184/8192 [00:15<00:00, 529.62it/s]
Adding requests: 100%|██████████| 8192/8192 [00:15<00:00, 521.89it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▍      | 2781/8192 [00:00<00:00, 7476.80it/s, est. speed input: 7656732.77 toks/s, output: 7476.95 toks/s]
Processed prompts:  43%|████▎     | 3529/8192 [00:04<00:07, 648.01it/s, est. speed input: 846296.33 toks/s, output: 826.46 toks/s]   
Processed prompts:  47%|████▋     | 3849/8192 [00:06<00:09, 470.19it/s, est. speed input: 651311.11 toks/s, output: 636.04 toks/s]
Processed prompts:  49%|████▉     | 4031/8192 [00:07<00:10, 396.71it/s, est. speed input: 579848.22 toks/s, output: 566.26 toks/s]
Processed prompts:  51%|█████     | 4148/8192 [00:07<00:11, 352.95it/s, est. speed input: 542622.76 toks/s, output: 529.90 toks/s]
Processed prompts:  52%|█████▏    | 4229/8192 [00:08<00:11, 338.86it/s, est. speed input: 529651.50 toks/s, output: 517.24 toks/s]
Processed prompts:  52%|█████▏    | 4291/8192 [00:08<00:12, 315.04it/s, est. speed input: 515090.61 toks/s, output: 503.02 toks/s]
Processed prompts:  53%|█████▎    | 4338/8192 [00:08<00:13, 283.69it/s, est. speed input: 499968.20 toks/s, output: 488.25 toks/s]
Processed prompts:  53%|█████▎    | 4381/8192 [00:09<00:15, 251.22it/s, est. speed input: 485387.07 toks/s, output: 474.01 toks/s]
Processed prompts:  54%|█████▍    | 4445/8192 [00:09<00:15, 235.92it/s, est. speed input: 474358.28 toks/s, output: 463.24 toks/s]
Processed prompts:  55%|█████▌    | 4509/8192 [00:09<00:16, 222.51it/s, est. speed input: 463989.39 toks/s, output: 453.11 toks/s]
Processed prompts:  56%|█████▌    | 4573/8192 [00:10<00:17, 211.51it/s, est. speed input: 454292.10 toks/s, output: 443.64 toks/s]
Processed prompts:  57%|█████▋    | 4637/8192 [00:10<00:17, 202.31it/s, est. speed input: 445071.14 toks/s, output: 434.64 toks/s]
Processed prompts:  57%|█████▋    | 4701/8192 [00:11<00:17, 195.38it/s, est. speed input: 436456.20 toks/s, output: 426.23 toks/s]
Processed prompts:  58%|█████▊    | 4765/8192 [00:11<00:17, 191.35it/s, est. speed input: 428654.04 toks/s, output: 418.61 toks/s]
Processed prompts:  59%|█████▉    | 4829/8192 [00:11<00:17, 188.17it/s, est. speed input: 421271.28 toks/s, output: 411.40 toks/s]
Processed prompts:  60%|█████▉    | 4893/8192 [00:12<00:17, 185.11it/s, est. speed input: 414150.96 toks/s, output: 404.44 toks/s]
Processed prompts:  61%|██████    | 4957/8192 [00:12<00:17, 183.88it/s, est. speed input: 407647.08 toks/s, output: 398.09 toks/s]
Processed prompts:  61%|██████▏   | 5021/8192 [00:12<00:17, 183.64it/s, est. speed input: 401633.87 toks/s, output: 392.22 toks/s]
Processed prompts:  62%|██████▏   | 5085/8192 [00:13<00:17, 182.60it/s, est. speed input: 395770.06 toks/s, output: 386.49 toks/s]
Processed prompts:  63%|██████▎   | 5149/8192 [00:13<00:16, 181.98it/s, est. speed input: 390234.98 toks/s, output: 381.09 toks/s]
Processed prompts:  64%|██████▎   | 5213/8192 [00:13<00:16, 183.03it/s, est. speed input: 385251.03 toks/s, output: 376.22 toks/s]
Processed prompts:  64%|██████▍   | 5277/8192 [00:14<00:16, 182.15it/s, est. speed input: 380229.54 toks/s, output: 371.32 toks/s]
Processed prompts:  65%|██████▌   | 5341/8192 [00:14<00:15, 181.65it/s, est. speed input: 375472.01 toks/s, output: 366.67 toks/s]
Processed prompts:  66%|██████▌   | 5405/8192 [00:14<00:15, 181.35it/s, est. speed input: 370949.67 toks/s, output: 362.25 toks/s]
Processed prompts:  67%|██████▋   | 5469/8192 [00:15<00:14, 181.74it/s, est. speed input: 366730.07 toks/s, output: 358.13 toks/s]
Processed prompts:  68%|██████▊   | 5533/8192 [00:15<00:14, 181.06it/s, est. speed input: 362555.11 toks/s, output: 354.06 toks/s]
Processed prompts:  68%|██████▊   | 5597/8192 [00:15<00:14, 180.51it/s, est. speed input: 358557.38 toks/s, output: 350.15 toks/s]
Processed prompts:  69%|██████▉   | 5661/8192 [00:16<00:13, 181.42it/s, est. speed input: 354916.40 toks/s, output: 346.60 toks/s]
Processed prompts:  70%|██████▉   | 5725/8192 [00:16<00:13, 180.39it/s, est. speed input: 351198.32 toks/s, output: 342.97 toks/s]
Processed prompts:  71%|███████   | 5789/8192 [00:17<00:13, 179.27it/s, est. speed input: 347582.65 toks/s, output: 339.44 toks/s]
Processed prompts:  71%|███████▏  | 5853/8192 [00:17<00:13, 178.94it/s, est. speed input: 344177.07 toks/s, output: 336.11 toks/s]
Processed prompts:  72%|███████▏  | 5917/8192 [00:17<00:12, 180.10it/s, est. speed input: 341085.02 toks/s, output: 333.09 toks/s]
Processed prompts:  73%|███████▎  | 5981/8192 [00:18<00:12, 178.97it/s, est. speed input: 337873.67 toks/s, output: 329.95 toks/s]
Processed prompts:  74%|███████▍  | 6045/8192 [00:18<00:11, 179.56it/s, est. speed input: 334953.43 toks/s, output: 327.10 toks/s]
Processed prompts:  75%|███████▍  | 6109/8192 [00:18<00:11, 179.52it/s, est. speed input: 332089.40 toks/s, output: 324.31 toks/s]
Processed prompts:  75%|███████▌  | 6173/8192 [00:19<00:11, 179.63it/s, est. speed input: 329347.91 toks/s, output: 321.63 toks/s]
Processed prompts:  76%|███████▌  | 6237/8192 [00:19<00:10, 179.92it/s, est. speed input: 326730.04 toks/s, output: 319.07 toks/s]
Processed prompts:  77%|███████▋  | 6301/8192 [00:19<00:10, 178.75it/s, est. speed input: 324056.79 toks/s, output: 316.46 toks/s]
Processed prompts:  78%|███████▊  | 6365/8192 [00:20<00:10, 180.03it/s, est. speed input: 321700.24 toks/s, output: 314.16 toks/s]
Processed prompts:  78%|███████▊  | 6429/8192 [00:20<00:09, 178.83it/s, est. speed input: 319208.61 toks/s, output: 311.73 toks/s]
Processed prompts:  79%|███████▉  | 6493/8192 [00:20<00:09, 178.25it/s, est. speed input: 316829.33 toks/s, output: 309.40 toks/s]
Processed prompts:  80%|████████  | 6557/8192 [00:21<00:09, 179.50it/s, est. speed input: 314693.21 toks/s, output: 307.32 toks/s]
Processed prompts:  81%|████████  | 6621/8192 [00:21<00:08, 179.84it/s, est. speed input: 312574.03 toks/s, output: 305.25 toks/s]
Processed prompts:  82%|████████▏ | 6685/8192 [00:22<00:08, 179.05it/s, est. speed input: 310427.30 toks/s, output: 303.15 toks/s]
Processed prompts:  82%|████████▏ | 6749/8192 [00:22<00:08, 178.62it/s, est. speed input: 308361.35 toks/s, output: 301.13 toks/s]
Processed prompts:  83%|████████▎ | 6813/8192 [00:22<00:07, 178.96it/s, est. speed input: 306417.38 toks/s, output: 299.24 toks/s]
Processed prompts:  84%|████████▍ | 6877/8192 [00:23<00:07, 178.83it/s, est. speed input: 304501.51 toks/s, output: 297.36 toks/s]
Processed prompts:  85%|████████▍ | 6941/8192 [00:23<00:07, 178.24it/s, est. speed input: 302601.04 toks/s, output: 295.51 toks/s]
Processed prompts:  86%|████████▌ | 7005/8192 [00:23<00:06, 178.56it/s, est. speed input: 300820.05 toks/s, output: 293.77 toks/s]
Processed prompts:  86%|████████▋ | 7069/8192 [00:24<00:06, 179.50it/s, est. speed input: 299150.41 toks/s, output: 292.14 toks/s]
Processed prompts:  87%|████████▋ | 7133/8192 [00:24<00:05, 180.33it/s, est. speed input: 297541.38 toks/s, output: 290.57 toks/s]
Processed prompts:  88%|████████▊ | 7197/8192 [00:24<00:05, 179.07it/s, est. speed input: 295833.95 toks/s, output: 288.90 toks/s]
Processed prompts:  89%|████████▊ | 7261/8192 [00:25<00:05, 180.91it/s, est. speed input: 294384.52 toks/s, output: 287.48 toks/s]
Processed prompts:  89%|████████▉ | 7325/8192 [00:25<00:04, 179.89it/s, est. speed input: 292800.82 toks/s, output: 285.94 toks/s]
Processed prompts:  90%|█████████ | 7389/8192 [00:25<00:04, 180.47it/s, est. speed input: 291355.97 toks/s, output: 284.53 toks/s]
Processed prompts:  91%|█████████ | 7453/8192 [00:26<00:04, 179.41it/s, est. speed input: 289843.60 toks/s, output: 283.05 toks/s]
Processed prompts:  92%|█████████▏| 7517/8192 [00:26<00:03, 180.36it/s, est. speed input: 288492.63 toks/s, output: 281.73 toks/s]
Processed prompts:  93%|█████████▎| 7581/8192 [00:27<00:03, 180.97it/s, est. speed input: 287172.50 toks/s, output: 280.44 toks/s]
Processed prompts:  93%|█████████▎| 7645/8192 [00:27<00:03, 179.77it/s, est. speed input: 285775.17 toks/s, output: 279.08 toks/s]
Processed prompts:  94%|█████████▍| 7709/8192 [00:27<00:02, 179.69it/s, est. speed input: 284465.18 toks/s, output: 277.80 toks/s]
Processed prompts:  95%|█████████▍| 7773/8192 [00:28<00:02, 178.86it/s, est. speed input: 283136.28 toks/s, output: 276.50 toks/s]
Processed prompts:  96%|█████████▌| 7837/8192 [00:28<00:01, 178.16it/s, est. speed input: 281833.62 toks/s, output: 275.23 toks/s]
Processed prompts:  96%|█████████▋| 7901/8192 [00:28<00:01, 178.55it/s, est. speed input: 280620.67 toks/s, output: 274.04 toks/s]
Processed prompts:  97%|█████████▋| 7965/8192 [00:29<00:01, 178.26it/s, est. speed input: 279400.97 toks/s, output: 272.85 toks/s]
Processed prompts:  98%|█████████▊| 8029/8192 [00:29<00:00, 178.36it/s, est. speed input: 278230.65 toks/s, output: 271.71 toks/s]
Processed prompts:  99%|█████████▉| 8093/8192 [00:29<00:00, 179.57it/s, est. speed input: 277158.25 toks/s, output: 270.66 toks/s]
Processed prompts: 100%|█████████▉| 8157/8192 [00:30<00:00, 207.73it/s, est. speed input: 277536.63 toks/s, output: 271.03 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:30<00:00, 207.73it/s, est. speed input: 278717.93 toks/s, output: 272.19 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:30<00:00, 272.18it/s, est. speed input: 278717.93 toks/s, output: 272.19 toks/s]
[rank0]:[W126 08:39:17.963420467 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 09:53:23
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:53:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1170452) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1170452) WARNING 01-26 09:53:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.83 requests/s, 16841.87 total tokens/s, 32.83 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 09:53:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:53:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:53:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:53:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:53:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:53:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:53:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:53:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:53:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:53:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:53:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:53:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:53:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:53:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:53:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:53:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:53:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1170452) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1170452) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.78it/s]
(EngineCore_DP0 pid=1170452) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.78it/s]
(EngineCore_DP0 pid=1170452) 
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1170452) [2026-01-26 09:53:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1170452) 2026-01-26 09:53:57,141 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1170452) 2026-01-26 09:53:57,164 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1170452) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]
(EngineCore_DP0 pid=1170452) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 476.17it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 680.99it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:27,  4.65it/s, est. speed input: 2381.97 toks/s, output: 4.65 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 18.23it/s, est. speed input: 7942.25 toks/s, output: 15.51 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.21it/s, est. speed input: 10692.04 toks/s, output: 20.88 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 29.07it/s, est. speed input: 12286.50 toks/s, output: 24.00 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 31.42it/s, est. speed input: 13337.63 toks/s, output: 26.05 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 32.86it/s, est. speed input: 14068.97 toks/s, output: 27.48 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 33.93it/s, est. speed input: 14635.34 toks/s, output: 28.58 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.65it/s, est. speed input: 15074.97 toks/s, output: 29.44 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 35.19it/s, est. speed input: 15432.81 toks/s, output: 30.14 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 35.60it/s, est. speed input: 15731.25 toks/s, output: 30.72 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 35.85it/s, est. speed input: 15974.18 toks/s, output: 31.20 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 35.93it/s, est. speed input: 16170.62 toks/s, output: 31.58 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 36.05it/s, est. speed input: 16344.76 toks/s, output: 31.92 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 36.09it/s, est. speed input: 16491.61 toks/s, output: 32.21 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 36.15it/s, est. speed input: 16622.32 toks/s, output: 32.46 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 36.16it/s, est. speed input: 16735.48 toks/s, output: 32.69 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 36.18it/s, est. speed input: 16836.60 toks/s, output: 32.88 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 36.16it/s, est. speed input: 16924.31 toks/s, output: 33.05 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 36.23it/s, est. speed input: 17010.10 toks/s, output: 33.22 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 36.31it/s, est. speed input: 17089.36 toks/s, output: 33.38 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 36.34it/s, est. speed input: 17159.78 toks/s, output: 33.51 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 36.33it/s, est. speed input: 17222.37 toks/s, output: 33.64 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 36.35it/s, est. speed input: 17281.33 toks/s, output: 33.75 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 36.37it/s, est. speed input: 17336.00 toks/s, output: 33.86 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 36.39it/s, est. speed input: 17386.33 toks/s, output: 33.96 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 36.40it/s, est. speed input: 17433.05 toks/s, output: 34.05 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 36.39it/s, est. speed input: 17475.47 toks/s, output: 34.13 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 36.41it/s, est. speed input: 17516.77 toks/s, output: 34.21 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 36.43it/s, est. speed input: 17555.21 toks/s, output: 34.29 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 36.37it/s, est. speed input: 17587.16 toks/s, output: 34.35 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 36.30it/s, est. speed input: 17616.12 toks/s, output: 34.41 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 36.35it/s, est. speed input: 17648.12 toks/s, output: 34.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.35it/s, est. speed input: 17669.13 toks/s, output: 34.51 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.51it/s, est. speed input: 17669.13 toks/s, output: 34.51 toks/s]
[rank0]:[W126 09:54:03.955181416 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 09:54:05
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:54:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1171599) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1171599) WARNING 01-26 09:54:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.72 requests/s, 35588.52 total tokens/s, 34.72 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 09:54:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:54:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:54:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:54:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:54:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:54:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:54:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:54:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:54:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:54:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:54:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:54:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1171599) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1171599) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1171599) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1171599) 
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1171599) [2026-01-26 09:54:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1171599) 2026-01-26 09:54:40,314 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1171599) 2026-01-26 09:54:40,338 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1171599) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.52it/s]
(EngineCore_DP0 pid=1171599) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|██▎       | 29/128 [00:00<00:00, 286.19it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 425.23it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 436.38it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 43.45it/s, est. speed input: 44503.19 toks/s, output: 43.46 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:02, 39.79it/s, est. speed input: 41273.67 toks/s, output: 40.30 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:02, 38.86it/s, est. speed input: 40423.77 toks/s, output: 39.47 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:02, 38.39it/s, est. speed input: 39984.59 toks/s, output: 39.04 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:02, 38.12it/s, est. speed input: 39709.62 toks/s, output: 38.78 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 37.95it/s, est. speed input: 39519.64 toks/s, output: 38.59 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 37.82it/s, est. speed input: 39374.77 toks/s, output: 38.45 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 37.77it/s, est. speed input: 39274.86 toks/s, output: 38.35 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:00<00:02, 37.71it/s, est. speed input: 39189.65 toks/s, output: 38.27 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 37.68it/s, est. speed input: 39123.32 toks/s, output: 38.21 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 37.59it/s, est. speed input: 39049.97 toks/s, output: 38.13 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 37.59it/s, est. speed input: 39004.86 toks/s, output: 38.09 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:01, 37.58it/s, est. speed input: 38964.33 toks/s, output: 38.05 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:01, 37.54it/s, est. speed input: 38919.38 toks/s, output: 38.01 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 37.52it/s, est. speed input: 38883.58 toks/s, output: 37.97 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 37.53it/s, est. speed input: 38859.59 toks/s, output: 37.95 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 37.57it/s, est. speed input: 38841.31 toks/s, output: 37.93 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:01<00:01, 37.56it/s, est. speed input: 38819.57 toks/s, output: 37.91 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 37.55it/s, est. speed input: 38799.78 toks/s, output: 37.89 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 37.52it/s, est. speed input: 38777.91 toks/s, output: 37.87 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 37.56it/s, est. speed input: 38766.54 toks/s, output: 37.86 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 37.58it/s, est. speed input: 38756.84 toks/s, output: 37.85 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:00, 37.58it/s, est. speed input: 38745.06 toks/s, output: 37.84 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 37.53it/s, est. speed input: 38726.25 toks/s, output: 37.82 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 37.52it/s, est. speed input: 38714.00 toks/s, output: 37.81 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 37.51it/s, est. speed input: 38701.83 toks/s, output: 37.79 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:02<00:00, 37.46it/s, est. speed input: 38685.00 toks/s, output: 37.78 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 37.43it/s, est. speed input: 38669.96 toks/s, output: 37.76 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 37.50it/s, est. speed input: 38665.66 toks/s, output: 37.76 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 37.45it/s, est. speed input: 38651.33 toks/s, output: 37.74 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 37.48it/s, est. speed input: 38644.97 toks/s, output: 37.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.48it/s, est. speed input: 38646.98 toks/s, output: 37.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.74it/s, est. speed input: 38646.98 toks/s, output: 37.74 toks/s]
[rank0]:[W126 09:54:46.241325004 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 09:54:48
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:54:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1172712) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1172712) WARNING 01-26 09:55:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 61.01 requests/s, 62534.80 total tokens/s, 61.01 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 09:54:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:54:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:54:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:54:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:54:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:54:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:54:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:54:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:55:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:55:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:55:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:55:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:55:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:55:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1172712) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1172712) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.76it/s]
(EngineCore_DP0 pid=1172712) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.76it/s]
(EngineCore_DP0 pid=1172712) 
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1172712) [2026-01-26 09:55:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1172712) 2026-01-26 09:55:23,973 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1172712) 2026-01-26 09:55:24,019 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1172712) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 14.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.12it/s]
(EngineCore_DP0 pid=1172712) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.89it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█▏        | 29/256 [00:00<00:00, 288.93it/s]
Adding requests:  32%|███▏      | 82/256 [00:00<00:00, 427.76it/s]
Adding requests:  52%|█████▏    | 133/256 [00:00<00:00, 464.63it/s]
Adding requests:  71%|███████▏  | 183/256 [00:00<00:00, 476.71it/s]
Adding requests:  91%|█████████▏| 234/256 [00:00<00:00, 487.37it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 468.68it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 210.94it/s, est. speed input: 216041.17 toks/s, output: 210.95 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:00<00:02, 92.27it/s, est. speed input: 103204.94 toks/s, output: 100.78 toks/s] 
Processed prompts:  22%|██▏       | 57/256 [00:00<00:02, 84.40it/s, est. speed input: 94588.62 toks/s, output: 92.37 toks/s]  
Processed prompts:  27%|██▋       | 68/256 [00:00<00:02, 75.81it/s, est. speed input: 87149.74 toks/s, output: 85.10 toks/s]
Processed prompts:  30%|███       | 77/256 [00:00<00:02, 75.47it/s, est. speed input: 85716.80 toks/s, output: 83.71 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:02, 70.35it/s, est. speed input: 82149.54 toks/s, output: 80.22 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:01<00:02, 69.15it/s, est. speed input: 80645.77 toks/s, output: 78.75 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:01<00:02, 68.26it/s, est. speed input: 79427.23 toks/s, output: 77.56 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:01<00:02, 67.63it/s, est. speed input: 78430.78 toks/s, output: 76.59 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:01<00:02, 67.24it/s, est. speed input: 77608.90 toks/s, output: 75.79 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:01<00:01, 66.88it/s, est. speed input: 76885.51 toks/s, output: 75.08 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:01<00:01, 66.57it/s, est. speed input: 76244.30 toks/s, output: 74.46 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:01<00:01, 66.36it/s, est. speed input: 75688.15 toks/s, output: 73.91 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:02<00:01, 66.29it/s, est. speed input: 75216.08 toks/s, output: 73.45 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:02<00:01, 66.18it/s, est. speed input: 74784.02 toks/s, output: 73.03 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:02<00:01, 66.10it/s, est. speed input: 74396.94 toks/s, output: 72.65 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:02<00:01, 66.06it/s, est. speed input: 74051.83 toks/s, output: 72.32 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:02<00:01, 66.09it/s, est. speed input: 73749.64 toks/s, output: 72.02 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:02<00:00, 66.02it/s, est. speed input: 73459.95 toks/s, output: 71.74 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:02<00:00, 65.89it/s, est. speed input: 73182.99 toks/s, output: 71.47 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:02<00:00, 65.82it/s, est. speed input: 72931.97 toks/s, output: 71.22 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:03<00:00, 65.81it/s, est. speed input: 72707.63 toks/s, output: 71.00 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:03<00:00, 65.93it/s, est. speed input: 72518.43 toks/s, output: 70.82 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:03<00:00, 65.93it/s, est. speed input: 72331.51 toks/s, output: 70.64 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:03<00:00, 65.95it/s, est. speed input: 72161.71 toks/s, output: 70.47 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:03<00:00, 65.99it/s, est. speed input: 72006.34 toks/s, output: 70.32 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:03<00:00, 65.95it/s, est. speed input: 71852.72 toks/s, output: 70.17 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.95it/s, est. speed input: 71860.59 toks/s, output: 70.18 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 70.17it/s, est. speed input: 71860.59 toks/s, output: 70.18 toks/s]
[rank0]:[W126 09:55:30.489083133 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 09:55:33
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:55:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1173830) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1173830) WARNING 01-26 09:55:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 68.37 requests/s, 70080.87 total tokens/s, 68.37 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 09:55:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:55:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:55:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:55:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:55:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:55:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:55:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:55:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:55:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:55:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:55:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:55:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:55:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:55:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1173830) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1173830) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.75it/s]
(EngineCore_DP0 pid=1173830) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.75it/s]
(EngineCore_DP0 pid=1173830) 
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1173830) [2026-01-26 09:55:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1173830) 2026-01-26 09:56:09,550 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1173830) 2026-01-26 09:56:09,574 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1173830) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00, 13.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.90it/s]
(EngineCore_DP0 pid=1173830) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 18.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 19.32it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 31/512 [00:00<00:01, 305.80it/s]
Adding requests:  16%|█▋        | 84/512 [00:00<00:00, 433.16it/s]
Adding requests:  27%|██▋       | 136/512 [00:00<00:00, 468.21it/s]
Adding requests:  36%|███▋      | 186/512 [00:00<00:00, 480.29it/s]
Adding requests:  46%|████▋     | 238/512 [00:00<00:00, 493.59it/s]
Adding requests:  56%|█████▋    | 289/512 [00:00<00:00, 496.93it/s]
Adding requests:  66%|██████▌   | 339/512 [00:00<00:00, 496.64it/s]
Adding requests:  77%|███████▋  | 392/512 [00:00<00:00, 504.69it/s]
Adding requests:  87%|████████▋ | 443/512 [00:00<00:00, 505.99it/s]
Adding requests:  97%|█████████▋| 495/512 [00:01<00:00, 507.23it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 489.55it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:00<00:00, 484.03it/s, est. speed input: 495794.35 toks/s, output: 484.07 toks/s]
Processed prompts:  23%|██▎       | 119/512 [00:00<00:03, 123.67it/s, est. speed input: 145793.08 toks/s, output: 142.37 toks/s]
Processed prompts:  28%|██▊       | 144/512 [00:01<00:03, 104.23it/s, est. speed input: 125057.03 toks/s, output: 122.12 toks/s]
Processed prompts:  31%|███▏      | 161/512 [00:01<00:03, 96.17it/s, est. speed input: 117046.02 toks/s, output: 114.30 toks/s] 
Processed prompts:  34%|███▍      | 174/512 [00:01<00:03, 85.23it/s, est. speed input: 108766.23 toks/s, output: 106.21 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:01<00:03, 86.88it/s, est. speed input: 108019.47 toks/s, output: 105.49 toks/s]
Processed prompts:  38%|███▊      | 196/512 [00:01<00:03, 80.85it/s, est. speed input: 104195.50 toks/s, output: 101.75 toks/s]
Processed prompts:  40%|████      | 205/512 [00:02<00:03, 80.38it/s, est. speed input: 102858.78 toks/s, output: 100.45 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:02<00:04, 72.03it/s, est. speed input: 99040.89 toks/s, output: 96.72 toks/s]  
Processed prompts:  43%|████▎     | 222/512 [00:02<00:04, 71.62it/s, est. speed input: 97707.35 toks/s, output: 95.42 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:02<00:03, 71.18it/s, est. speed input: 96476.44 toks/s, output: 94.21 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:02<00:03, 70.80it/s, est. speed input: 95349.01 toks/s, output: 93.11 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:02<00:03, 70.36it/s, est. speed input: 94286.19 toks/s, output: 92.08 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:02<00:03, 70.12it/s, est. speed input: 93331.62 toks/s, output: 91.14 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:02<00:03, 69.95it/s, est. speed input: 92453.44 toks/s, output: 90.29 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:03<00:03, 69.92it/s, est. speed input: 91657.91 toks/s, output: 89.51 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:03<00:03, 69.73it/s, est. speed input: 90894.09 toks/s, output: 88.76 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:03<00:03, 69.83it/s, est. speed input: 90220.50 toks/s, output: 88.11 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:03<00:03, 69.67it/s, est. speed input: 89558.66 toks/s, output: 87.46 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:03<00:03, 69.69it/s, est. speed input: 88959.48 toks/s, output: 86.87 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:03<00:02, 69.58it/s, est. speed input: 88381.87 toks/s, output: 86.31 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:03<00:02, 69.59it/s, est. speed input: 87852.61 toks/s, output: 85.79 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:03<00:02, 69.53it/s, est. speed input: 87344.98 toks/s, output: 85.30 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:03<00:02, 69.54it/s, est. speed input: 86874.86 toks/s, output: 84.84 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:04<00:02, 71.03it/s, est. speed input: 86602.47 toks/s, output: 84.57 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:04<00:02, 70.65it/s, est. speed input: 86184.15 toks/s, output: 84.16 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:04<00:02, 70.30it/s, est. speed input: 85779.34 toks/s, output: 83.77 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:04<00:02, 70.12it/s, est. speed input: 85402.69 toks/s, output: 83.40 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:04<00:01, 70.05it/s, est. speed input: 85050.99 toks/s, output: 83.06 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:04<00:01, 69.78it/s, est. speed input: 84694.73 toks/s, output: 82.71 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:04<00:01, 69.51it/s, est. speed input: 84347.50 toks/s, output: 82.37 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:04<00:01, 69.54it/s, est. speed input: 84037.38 toks/s, output: 82.07 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:04<00:01, 69.59it/s, est. speed input: 83744.87 toks/s, output: 81.78 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:05<00:01, 69.56it/s, est. speed input: 83459.31 toks/s, output: 81.50 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:05<00:01, 69.47it/s, est. speed input: 83181.56 toks/s, output: 81.23 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:05<00:01, 69.42it/s, est. speed input: 82915.22 toks/s, output: 80.97 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:05<00:01, 69.58it/s, est. speed input: 82677.78 toks/s, output: 80.74 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:05<00:00, 69.51it/s, est. speed input: 82434.82 toks/s, output: 80.50 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:05<00:00, 71.51it/s, est. speed input: 82361.69 toks/s, output: 80.43 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:05<00:00, 70.93it/s, est. speed input: 82141.14 toks/s, output: 80.22 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:05<00:00, 70.40it/s, est. speed input: 81918.42 toks/s, output: 80.00 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:05<00:00, 70.09it/s, est. speed input: 81709.01 toks/s, output: 79.79 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:06<00:00, 70.05it/s, est. speed input: 81520.14 toks/s, output: 79.61 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:06<00:00, 69.73it/s, est. speed input: 81317.81 toks/s, output: 79.41 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:06<00:00, 69.51it/s, est. speed input: 81122.76 toks/s, output: 79.22 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:06<00:00, 71.64it/s, est. speed input: 81088.44 toks/s, output: 79.19 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 71.64it/s, est. speed input: 81402.83 toks/s, output: 79.49 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 79.49it/s, est. speed input: 81402.83 toks/s, output: 79.49 toks/s]
[rank0]:[W126 09:56:19.649635874 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 09:56:21
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:56:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1175007) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1175007) WARNING 01-26 09:56:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 72.63 requests/s, 74448.62 total tokens/s, 72.63 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 09:56:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:56:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:56:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:56:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:56:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:56:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:56:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:56:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:56:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:56:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:56:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:56:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:56:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:56:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:56:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:56:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:56:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1175007) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1175007) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1175007) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1175007) 
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1175007) [2026-01-26 09:56:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1175007) 2026-01-26 09:56:58,841 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1175007) 2026-01-26 09:56:58,890 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1175007) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  7.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.27it/s]
(EngineCore_DP0 pid=1175007) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.01it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  4.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.77it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 31/1024 [00:00<00:03, 308.45it/s]
Adding requests:   8%|▊         | 84/1024 [00:00<00:02, 434.98it/s]
Adding requests:  13%|█▎        | 136/1024 [00:00<00:01, 470.16it/s]
Adding requests:  18%|█▊        | 186/1024 [00:00<00:01, 480.47it/s]
Adding requests:  23%|██▎       | 238/1024 [00:00<00:01, 493.29it/s]
Adding requests:  28%|██▊       | 289/1024 [00:00<00:01, 497.66it/s]
Adding requests:  33%|███▎      | 339/1024 [00:00<00:01, 498.40it/s]
Adding requests:  38%|███▊      | 392/1024 [00:00<00:01, 507.96it/s]
Adding requests:  43%|████▎     | 443/1024 [00:00<00:01, 508.21it/s]
Adding requests:  48%|████▊     | 495/1024 [00:01<00:01, 509.40it/s]
Adding requests:  53%|█████▎    | 546/1024 [00:01<00:00, 495.53it/s]
Adding requests:  58%|█████▊    | 599/1024 [00:01<00:00, 504.98it/s]
Adding requests:  64%|██████▎   | 652/1024 [00:01<00:00, 509.51it/s]
Adding requests:  69%|██████▉   | 706/1024 [00:01<00:00, 517.78it/s]
Adding requests:  74%|███████▍  | 758/1024 [00:01<00:00, 516.32it/s]
Adding requests:  79%|███████▉  | 810/1024 [00:01<00:00, 509.16it/s]
Adding requests:  84%|████████▍ | 861/1024 [00:01<00:00, 508.77it/s]
Adding requests:  89%|████████▉ | 914/1024 [00:01<00:00, 514.76it/s]
Adding requests:  95%|█████████▍| 968/1024 [00:01<00:00, 519.93it/s]
Adding requests: 100%|█████████▉| 1021/1024 [00:02<00:00, 520.94it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 503.01it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:00<00:00, 1145.07it/s, est. speed input: 1172761.89 toks/s, output: 1145.13 toks/s]
Processed prompts:  25%|██▌       | 261/1024 [00:01<00:05, 133.77it/s, est. speed input: 160812.29 toks/s, output: 157.04 toks/s]   
Processed prompts:  31%|███       | 313/1024 [00:02<00:06, 113.61it/s, est. speed input: 138068.98 toks/s, output: 134.83 toks/s]
Processed prompts:  34%|███▎      | 345/1024 [00:02<00:06, 103.56it/s, est. speed input: 128354.87 toks/s, output: 125.35 toks/s]
Processed prompts:  36%|███▌      | 368/1024 [00:03<00:06, 96.19it/s, est. speed input: 122267.40 toks/s, output: 119.40 toks/s] 
Processed prompts:  38%|███▊      | 385/1024 [00:03<00:06, 92.83it/s, est. speed input: 119341.80 toks/s, output: 116.54 toks/s]
Processed prompts:  39%|███▉      | 399/1024 [00:03<00:07, 87.11it/s, est. speed input: 115973.12 toks/s, output: 113.25 toks/s]
Processed prompts:  40%|████      | 411/1024 [00:03<00:07, 80.01it/s, est. speed input: 112463.21 toks/s, output: 109.83 toks/s]
Processed prompts:  41%|████      | 421/1024 [00:03<00:07, 81.51it/s, est. speed input: 111916.53 toks/s, output: 109.29 toks/s]
Processed prompts:  42%|████▏     | 431/1024 [00:03<00:07, 83.00it/s, est. speed input: 111383.95 toks/s, output: 108.77 toks/s]
Processed prompts:  43%|████▎     | 441/1024 [00:04<00:06, 84.44it/s, est. speed input: 110880.35 toks/s, output: 108.28 toks/s]
Processed prompts:  44%|████▍     | 451/1024 [00:04<00:08, 71.60it/s, est. speed input: 107758.19 toks/s, output: 105.23 toks/s]
Processed prompts:  45%|████▍     | 459/1024 [00:04<00:07, 71.96it/s, est. speed input: 106950.00 toks/s, output: 104.44 toks/s]
Processed prompts:  46%|████▌     | 467/1024 [00:04<00:07, 72.21it/s, est. speed input: 106169.51 toks/s, output: 103.68 toks/s]
Processed prompts:  46%|████▋     | 475/1024 [00:04<00:07, 72.36it/s, est. speed input: 105417.92 toks/s, output: 102.95 toks/s]
Processed prompts:  47%|████▋     | 483/1024 [00:04<00:07, 72.43it/s, est. speed input: 104693.69 toks/s, output: 102.24 toks/s]
Processed prompts:  48%|████▊     | 491/1024 [00:04<00:07, 72.57it/s, est. speed input: 104013.61 toks/s, output: 101.58 toks/s]
Processed prompts:  49%|████▊     | 499/1024 [00:04<00:07, 72.64it/s, est. speed input: 103359.45 toks/s, output: 100.94 toks/s]
Processed prompts:  50%|████▉     | 507/1024 [00:05<00:07, 72.67it/s, est. speed input: 102730.55 toks/s, output: 100.32 toks/s]
Processed prompts:  50%|█████     | 515/1024 [00:05<00:07, 72.39it/s, est. speed input: 102097.93 toks/s, output: 99.70 toks/s] 
Processed prompts:  51%|█████     | 523/1024 [00:05<00:06, 72.51it/s, est. speed input: 101524.37 toks/s, output: 99.14 toks/s]
Processed prompts:  52%|█████▏    | 531/1024 [00:05<00:06, 72.41it/s, est. speed input: 100955.38 toks/s, output: 98.59 toks/s]
Processed prompts:  53%|█████▎    | 539/1024 [00:05<00:06, 72.54it/s, est. speed input: 100429.36 toks/s, output: 98.08 toks/s]
Processed prompts:  53%|█████▎    | 547/1024 [00:05<00:06, 72.61it/s, est. speed input: 99920.94 toks/s, output: 97.58 toks/s] 
Processed prompts:  54%|█████▍    | 555/1024 [00:05<00:06, 72.77it/s, est. speed input: 99442.02 toks/s, output: 97.11 toks/s]
Processed prompts:  55%|█████▍    | 563/1024 [00:05<00:06, 72.80it/s, est. speed input: 98974.03 toks/s, output: 96.65 toks/s]
Processed prompts:  56%|█████▌    | 571/1024 [00:05<00:06, 72.91it/s, est. speed input: 98531.02 toks/s, output: 96.22 toks/s]
Processed prompts:  57%|█████▋    | 579/1024 [00:06<00:06, 72.78it/s, est. speed input: 98087.07 toks/s, output: 95.79 toks/s]
Processed prompts:  57%|█████▋    | 587/1024 [00:06<00:06, 72.59it/s, est. speed input: 97650.85 toks/s, output: 95.36 toks/s]
Processed prompts:  58%|█████▊    | 595/1024 [00:06<00:05, 72.52it/s, est. speed input: 97235.31 toks/s, output: 94.96 toks/s]
Processed prompts:  59%|█████▉    | 603/1024 [00:06<00:05, 72.57it/s, est. speed input: 96841.60 toks/s, output: 94.57 toks/s]
Processed prompts:  60%|█████▉    | 611/1024 [00:06<00:05, 72.47it/s, est. speed input: 96451.39 toks/s, output: 94.19 toks/s]
Processed prompts:  60%|██████    | 619/1024 [00:06<00:05, 72.67it/s, est. speed input: 96093.58 toks/s, output: 93.84 toks/s]
Processed prompts:  61%|██████    | 627/1024 [00:06<00:05, 72.75it/s, est. speed input: 95743.60 toks/s, output: 93.50 toks/s]
Processed prompts:  62%|██████▏   | 635/1024 [00:06<00:05, 72.90it/s, est. speed input: 95411.36 toks/s, output: 93.17 toks/s]
Processed prompts:  63%|██████▎   | 643/1024 [00:06<00:05, 72.75it/s, est. speed input: 95071.66 toks/s, output: 92.84 toks/s]
Processed prompts:  64%|██████▎   | 651/1024 [00:07<00:05, 72.72it/s, est. speed input: 94747.94 toks/s, output: 92.53 toks/s]
Processed prompts:  64%|██████▍   | 659/1024 [00:07<00:05, 72.56it/s, est. speed input: 94425.10 toks/s, output: 92.21 toks/s]
Processed prompts:  65%|██████▌   | 667/1024 [00:07<00:04, 72.54it/s, est. speed input: 94118.21 toks/s, output: 91.91 toks/s]
Processed prompts:  66%|██████▌   | 675/1024 [00:07<00:04, 72.37it/s, est. speed input: 93810.28 toks/s, output: 91.61 toks/s]
Processed prompts:  67%|██████▋   | 683/1024 [00:07<00:04, 72.58it/s, est. speed input: 93532.79 toks/s, output: 91.34 toks/s]
Processed prompts:  67%|██████▋   | 691/1024 [00:07<00:04, 72.55it/s, est. speed input: 93251.43 toks/s, output: 91.07 toks/s]
Processed prompts:  68%|██████▊   | 699/1024 [00:07<00:04, 72.64it/s, est. speed input: 92985.18 toks/s, output: 90.81 toks/s]
Processed prompts:  69%|██████▉   | 707/1024 [00:07<00:04, 72.63it/s, est. speed input: 92722.46 toks/s, output: 90.55 toks/s]
Processed prompts:  70%|██████▉   | 715/1024 [00:07<00:04, 72.75it/s, est. speed input: 92473.89 toks/s, output: 90.31 toks/s]
Processed prompts:  71%|███████   | 723/1024 [00:08<00:04, 72.71it/s, est. speed input: 92225.20 toks/s, output: 90.06 toks/s]
Processed prompts:  71%|███████▏  | 731/1024 [00:08<00:04, 72.82it/s, est. speed input: 91991.12 toks/s, output: 89.83 toks/s]
Processed prompts:  72%|███████▏  | 739/1024 [00:08<00:03, 72.75it/s, est. speed input: 91755.24 toks/s, output: 89.60 toks/s]
Processed prompts:  73%|███████▎  | 747/1024 [00:08<00:03, 72.60it/s, est. speed input: 91519.74 toks/s, output: 89.37 toks/s]
Processed prompts:  74%|███████▎  | 755/1024 [00:08<00:03, 72.55it/s, est. speed input: 91293.71 toks/s, output: 89.15 toks/s]
Processed prompts:  75%|███████▍  | 763/1024 [00:08<00:03, 72.66it/s, est. speed input: 91080.98 toks/s, output: 88.95 toks/s]
Processed prompts:  75%|███████▌  | 771/1024 [00:08<00:03, 72.63it/s, est. speed input: 90867.90 toks/s, output: 88.74 toks/s]
Processed prompts:  76%|███████▌  | 779/1024 [00:08<00:03, 72.68it/s, est. speed input: 90663.84 toks/s, output: 88.54 toks/s]
Processed prompts:  77%|███████▋  | 787/1024 [00:08<00:03, 72.65it/s, est. speed input: 90461.77 toks/s, output: 88.34 toks/s]
Processed prompts:  78%|███████▊  | 795/1024 [00:09<00:03, 72.80it/s, est. speed input: 90272.98 toks/s, output: 88.16 toks/s]
Processed prompts:  78%|███████▊  | 803/1024 [00:09<00:03, 72.70it/s, est. speed input: 90078.98 toks/s, output: 87.97 toks/s]
Processed prompts:  79%|███████▉  | 811/1024 [00:09<00:02, 72.71it/s, est. speed input: 89893.23 toks/s, output: 87.79 toks/s]
Processed prompts:  80%|███████▉  | 819/1024 [00:09<00:02, 72.69it/s, est. speed input: 89710.71 toks/s, output: 87.61 toks/s]
Processed prompts:  81%|████████  | 827/1024 [00:09<00:02, 72.71it/s, est. speed input: 89533.65 toks/s, output: 87.44 toks/s]
Processed prompts:  82%|████████▏ | 835/1024 [00:09<00:02, 72.71it/s, est. speed input: 89360.48 toks/s, output: 87.27 toks/s]
Processed prompts:  82%|████████▏ | 843/1024 [00:09<00:02, 72.84it/s, est. speed input: 89197.07 toks/s, output: 87.11 toks/s]
Processed prompts:  83%|████████▎ | 851/1024 [00:09<00:02, 72.90it/s, est. speed input: 89035.67 toks/s, output: 86.95 toks/s]
Processed prompts:  84%|████████▍ | 859/1024 [00:09<00:02, 72.96it/s, est. speed input: 88879.01 toks/s, output: 86.80 toks/s]
Processed prompts:  85%|████████▍ | 867/1024 [00:10<00:02, 73.03it/s, est. speed input: 88726.99 toks/s, output: 86.65 toks/s]
Processed prompts:  85%|████████▌ | 875/1024 [00:10<00:02, 73.10it/s, est. speed input: 88578.97 toks/s, output: 86.50 toks/s]
Processed prompts:  86%|████████▌ | 883/1024 [00:10<00:01, 73.03it/s, est. speed input: 88429.07 toks/s, output: 86.36 toks/s]
Processed prompts:  87%|████████▋ | 891/1024 [00:10<00:01, 73.07it/s, est. speed input: 88286.04 toks/s, output: 86.22 toks/s]
Processed prompts:  88%|████████▊ | 899/1024 [00:10<00:01, 72.99it/s, est. speed input: 88141.67 toks/s, output: 86.08 toks/s]
Processed prompts:  89%|████████▊ | 907/1024 [00:10<00:01, 72.93it/s, est. speed input: 88000.09 toks/s, output: 85.94 toks/s]
Processed prompts:  89%|████████▉ | 915/1024 [00:10<00:01, 72.76it/s, est. speed input: 87855.75 toks/s, output: 85.80 toks/s]
Processed prompts:  90%|█████████ | 923/1024 [00:10<00:01, 72.84it/s, est. speed input: 87722.96 toks/s, output: 85.67 toks/s]
Processed prompts:  91%|█████████ | 931/1024 [00:10<00:01, 72.81it/s, est. speed input: 87588.96 toks/s, output: 85.54 toks/s]
Processed prompts:  92%|█████████▏| 939/1024 [00:10<00:01, 74.64it/s, est. speed input: 87530.53 toks/s, output: 85.48 toks/s]
Processed prompts:  92%|█████████▏| 947/1024 [00:11<00:01, 74.34it/s, est. speed input: 87411.83 toks/s, output: 85.36 toks/s]
Processed prompts:  93%|█████████▎| 955/1024 [00:11<00:00, 73.94it/s, est. speed input: 87288.35 toks/s, output: 85.24 toks/s]
Processed prompts:  94%|█████████▍| 963/1024 [00:11<00:00, 73.87it/s, est. speed input: 87175.01 toks/s, output: 85.13 toks/s]
Processed prompts:  95%|█████████▍| 971/1024 [00:11<00:00, 73.59it/s, est. speed input: 87054.95 toks/s, output: 85.01 toks/s]
Processed prompts:  96%|█████████▌| 979/1024 [00:11<00:00, 73.41it/s, est. speed input: 86937.97 toks/s, output: 84.90 toks/s]
Processed prompts:  96%|█████████▋| 987/1024 [00:11<00:00, 74.90it/s, est. speed input: 86881.90 toks/s, output: 84.85 toks/s]
Processed prompts:  97%|█████████▋| 995/1024 [00:11<00:00, 74.35it/s, est. speed input: 86769.87 toks/s, output: 84.74 toks/s]
Processed prompts:  98%|█████████▊| 1003/1024 [00:11<00:00, 73.72it/s, est. speed input: 86650.82 toks/s, output: 84.62 toks/s]
Processed prompts:  99%|█████████▊| 1011/1024 [00:11<00:00, 73.35it/s, est. speed input: 86536.42 toks/s, output: 84.51 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:12<00:00, 73.35it/s, est. speed input: 86942.95 toks/s, output: 84.90 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:12<00:00, 84.90it/s, est. speed input: 86942.95 toks/s, output: 84.90 toks/s]
[rank0]:[W126 09:57:16.325077667 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 09:57:18
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:57:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1176340) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1176340) WARNING 01-26 09:57:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 74.39 requests/s, 76254.31 total tokens/s, 74.39 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 09:57:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:57:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:57:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:57:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:57:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:57:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:57:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:57:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:57:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:57:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:57:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:57:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:57:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:57:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:57:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:57:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:57:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1176340) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1176340) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.78it/s]
(EngineCore_DP0 pid=1176340) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.78it/s]
(EngineCore_DP0 pid=1176340) 
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1176340) [2026-01-26 09:57:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1176340) 2026-01-26 09:57:59,575 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1176340) 2026-01-26 09:57:59,615 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1176340) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  5.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  5.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  8.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.34it/s]
(EngineCore_DP0 pid=1176340) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  9.84it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  7.48it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.46it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 31/2048 [00:00<00:06, 308.67it/s]
Adding requests:   4%|▍         | 83/2048 [00:00<00:04, 430.83it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:04, 459.88it/s]
Adding requests:   9%|▉         | 182/2048 [00:00<00:03, 468.99it/s]
Adding requests:  11%|█▏        | 233/2048 [00:00<00:03, 482.94it/s]
Adding requests:  14%|█▍        | 283/2048 [00:00<00:03, 488.46it/s]
Adding requests:  16%|█▋        | 333/2048 [00:00<00:03, 488.56it/s]
Adding requests:  19%|█▉        | 384/2048 [00:00<00:03, 492.67it/s]
Adding requests:  21%|██        | 435/2048 [00:00<00:03, 497.17it/s]
Adding requests:  24%|██▎       | 486/2048 [00:01<00:03, 500.35it/s]
Adding requests:  26%|██▌       | 537/2048 [00:01<00:03, 488.10it/s]
Adding requests:  29%|██▉       | 590/2048 [00:01<00:02, 498.59it/s]
Adding requests:  31%|███▏      | 641/2048 [00:01<00:02, 501.77it/s]
Adding requests:  34%|███▍      | 694/2048 [00:01<00:02, 507.97it/s]
Adding requests:  36%|███▋      | 745/2048 [00:01<00:02, 499.66it/s]
Adding requests:  39%|███▉      | 796/2048 [00:01<00:02, 499.02it/s]
Adding requests:  41%|████▏     | 846/2048 [00:01<00:02, 491.14it/s]
Adding requests:  44%|████▍     | 899/2048 [00:01<00:02, 500.52it/s]
Adding requests:  46%|████▋     | 950/2048 [00:01<00:02, 501.22it/s]
Adding requests:  49%|████▉     | 1001/2048 [00:02<00:02, 503.37it/s]
Adding requests:  51%|█████▏    | 1053/2048 [00:02<00:01, 506.92it/s]
Adding requests:  54%|█████▍    | 1104/2048 [00:02<00:01, 503.94it/s]
Adding requests:  56%|█████▋    | 1155/2048 [00:02<00:01, 504.19it/s]
Adding requests:  59%|█████▉    | 1209/2048 [00:02<00:01, 514.22it/s]
Adding requests:  62%|██████▏   | 1261/2048 [00:02<00:01, 507.25it/s]
Adding requests:  64%|██████▍   | 1312/2048 [00:02<00:01, 506.82it/s]
Adding requests:  67%|██████▋   | 1364/2048 [00:02<00:01, 510.27it/s]
Adding requests:  69%|██████▉   | 1416/2048 [00:02<00:01, 511.94it/s]
Adding requests:  72%|███████▏  | 1468/2048 [00:02<00:01, 513.04it/s]
Adding requests:  74%|███████▍  | 1521/2048 [00:03<00:01, 514.72it/s]
Adding requests:  77%|███████▋  | 1573/2048 [00:03<00:00, 516.19it/s]
Adding requests:  79%|███████▉  | 1626/2048 [00:03<00:00, 520.14it/s]
Adding requests:  82%|████████▏ | 1679/2048 [00:03<00:00, 514.69it/s]
Adding requests:  85%|████████▍ | 1731/2048 [00:03<00:00, 516.02it/s]
Adding requests:  87%|████████▋ | 1783/2048 [00:03<00:00, 509.08it/s]
Adding requests:  90%|████████▉ | 1835/2048 [00:03<00:00, 510.48it/s]
Adding requests:  92%|█████████▏| 1887/2048 [00:03<00:00, 509.92it/s]
Adding requests:  95%|█████████▍| 1939/2048 [00:03<00:00, 498.87it/s]
Adding requests:  97%|█████████▋| 1991/2048 [00:03<00:00, 501.94it/s]
Adding requests: 100%|█████████▉| 2043/2048 [00:04<00:00, 506.35it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 500.50it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  15%|█▍        | 305/2048 [00:00<00:01, 987.28it/s, est. speed input: 1011115.64 toks/s, output: 987.32 toks/s]
Processed prompts:  20%|█▉        | 404/2048 [00:01<00:07, 209.56it/s, est. speed input: 261188.96 toks/s, output: 255.07 toks/s] 
Processed prompts:  22%|██▏       | 450/2048 [00:02<00:10, 157.94it/s, est. speed input: 207910.76 toks/s, output: 203.04 toks/s]
Processed prompts:  23%|██▎       | 478/2048 [00:02<00:10, 153.55it/s, est. speed input: 201242.96 toks/s, output: 196.53 toks/s]
Processed prompts:  24%|██▍       | 501/2048 [00:02<00:12, 123.10it/s, est. speed input: 179400.20 toks/s, output: 175.19 toks/s]
Processed prompts:  25%|██▌       | 518/2048 [00:03<00:13, 115.20it/s, est. speed input: 172532.25 toks/s, output: 168.49 toks/s]
Processed prompts:  26%|██▌       | 532/2048 [00:03<00:14, 104.87it/s, est. speed input: 165570.13 toks/s, output: 161.69 toks/s]
Processed prompts:  27%|██▋       | 545/2048 [00:03<00:15, 94.89it/s, est. speed input: 159235.98 toks/s, output: 155.50 toks/s] 
Processed prompts:  27%|██▋       | 561/2048 [00:03<00:16, 89.94it/s, est. speed input: 154455.66 toks/s, output: 150.83 toks/s]
Processed prompts:  28%|██▊       | 577/2048 [00:03<00:17, 85.96it/s, est. speed input: 150193.77 toks/s, output: 146.67 toks/s]
Processed prompts:  29%|██▉       | 593/2048 [00:04<00:17, 82.82it/s, est. speed input: 146352.06 toks/s, output: 142.92 toks/s]
Processed prompts:  30%|██▉       | 609/2048 [00:04<00:17, 80.19it/s, est. speed input: 142802.39 toks/s, output: 139.45 toks/s]
Processed prompts:  31%|███       | 625/2048 [00:04<00:18, 78.50it/s, est. speed input: 139664.32 toks/s, output: 136.39 toks/s]
Processed prompts:  31%|███▏      | 641/2048 [00:04<00:18, 77.51it/s, est. speed input: 136869.49 toks/s, output: 133.66 toks/s]
Processed prompts:  32%|███▏      | 657/2048 [00:05<00:18, 76.63it/s, est. speed input: 134273.52 toks/s, output: 131.12 toks/s]
Processed prompts:  33%|███▎      | 673/2048 [00:05<00:18, 75.88it/s, est. speed input: 131860.25 toks/s, output: 128.77 toks/s]
Processed prompts:  34%|███▎      | 689/2048 [00:05<00:18, 75.36it/s, est. speed input: 129639.39 toks/s, output: 126.60 toks/s]
Processed prompts:  34%|███▍      | 705/2048 [00:05<00:17, 75.13it/s, est. speed input: 127619.67 toks/s, output: 124.63 toks/s]
Processed prompts:  35%|███▌      | 721/2048 [00:05<00:17, 74.95it/s, est. speed input: 125744.05 toks/s, output: 122.80 toks/s]
Processed prompts:  36%|███▌      | 737/2048 [00:06<00:17, 74.78it/s, est. speed input: 123992.58 toks/s, output: 121.09 toks/s]
Processed prompts:  37%|███▋      | 753/2048 [00:06<00:17, 74.77it/s, est. speed input: 122380.95 toks/s, output: 119.51 toks/s]
Processed prompts:  38%|███▊      | 769/2048 [00:06<00:17, 74.82it/s, est. speed input: 120884.70 toks/s, output: 118.05 toks/s]
Processed prompts:  38%|███▊      | 785/2048 [00:06<00:16, 74.78it/s, est. speed input: 119470.23 toks/s, output: 116.67 toks/s]
Processed prompts:  39%|███▉      | 801/2048 [00:06<00:16, 74.78it/s, est. speed input: 118147.59 toks/s, output: 115.38 toks/s]
Processed prompts:  40%|███▉      | 817/2048 [00:07<00:16, 74.82it/s, est. speed input: 116911.00 toks/s, output: 114.17 toks/s]
Processed prompts:  41%|████      | 833/2048 [00:07<00:16, 74.68it/s, est. speed input: 115720.60 toks/s, output: 113.01 toks/s]
Processed prompts:  41%|████▏     | 849/2048 [00:07<00:16, 74.67it/s, est. speed input: 114611.56 toks/s, output: 111.92 toks/s]
Processed prompts:  42%|████▏     | 865/2048 [00:07<00:15, 74.64it/s, est. speed input: 113558.46 toks/s, output: 110.90 toks/s]
Processed prompts:  43%|████▎     | 881/2048 [00:08<00:15, 74.80it/s, est. speed input: 112586.92 toks/s, output: 109.95 toks/s]
Processed prompts:  44%|████▍     | 897/2048 [00:08<00:15, 74.58it/s, est. speed input: 111622.88 toks/s, output: 109.01 toks/s]
Processed prompts:  45%|████▍     | 913/2048 [00:08<00:15, 74.53it/s, est. speed input: 110720.13 toks/s, output: 108.12 toks/s]
Processed prompts:  45%|████▌     | 929/2048 [00:08<00:14, 75.83it/s, est. speed input: 110023.30 toks/s, output: 107.44 toks/s]
Processed prompts:  46%|████▌     | 945/2048 [00:08<00:14, 75.51it/s, est. speed input: 109214.69 toks/s, output: 106.65 toks/s]
Processed prompts:  47%|████▋     | 961/2048 [00:09<00:14, 75.35it/s, est. speed input: 108451.92 toks/s, output: 105.91 toks/s]
Processed prompts:  48%|████▊     | 977/2048 [00:09<00:14, 76.27it/s, est. speed input: 107836.15 toks/s, output: 105.31 toks/s]
Processed prompts:  48%|████▊     | 993/2048 [00:09<00:13, 75.90it/s, est. speed input: 107140.32 toks/s, output: 104.63 toks/s]
Processed prompts:  49%|████▉     | 1009/2048 [00:09<00:13, 75.47it/s, est. speed input: 106457.49 toks/s, output: 103.96 toks/s]
Processed prompts:  50%|█████     | 1025/2048 [00:09<00:13, 75.17it/s, est. speed input: 105802.83 toks/s, output: 103.32 toks/s]
Processed prompts:  51%|█████     | 1041/2048 [00:10<00:13, 75.12it/s, est. speed input: 105192.88 toks/s, output: 102.73 toks/s]
Processed prompts:  52%|█████▏    | 1057/2048 [00:10<00:13, 74.86it/s, est. speed input: 104586.17 toks/s, output: 102.13 toks/s]
Processed prompts:  52%|█████▏    | 1073/2048 [00:10<00:13, 74.73it/s, est. speed input: 104008.93 toks/s, output: 101.57 toks/s]
Processed prompts:  53%|█████▎    | 1089/2048 [00:10<00:12, 74.71it/s, est. speed input: 103460.50 toks/s, output: 101.04 toks/s]
Processed prompts:  54%|█████▍    | 1105/2048 [00:10<00:12, 74.83it/s, est. speed input: 102946.19 toks/s, output: 100.53 toks/s]
Processed prompts:  55%|█████▍    | 1121/2048 [00:11<00:12, 74.66it/s, est. speed input: 102429.15 toks/s, output: 100.03 toks/s]
Processed prompts:  56%|█████▌    | 1137/2048 [00:11<00:12, 74.60it/s, est. speed input: 101936.89 toks/s, output: 99.55 toks/s] 
Processed prompts:  56%|█████▋    | 1153/2048 [00:11<00:11, 75.87it/s, est. speed input: 101570.39 toks/s, output: 99.19 toks/s]
Processed prompts:  57%|█████▋    | 1169/2048 [00:11<00:11, 75.39it/s, est. speed input: 101106.93 toks/s, output: 98.74 toks/s]
Processed prompts:  58%|█████▊    | 1185/2048 [00:12<00:11, 75.25it/s, est. speed input: 100674.74 toks/s, output: 98.31 toks/s]
Processed prompts:  59%|█████▊    | 1201/2048 [00:12<00:11, 75.01it/s, est. speed input: 100247.06 toks/s, output: 97.90 toks/s]
Processed prompts:  59%|█████▉    | 1217/2048 [00:12<00:11, 74.73it/s, est. speed input: 99825.05 toks/s, output: 97.49 toks/s] 
Processed prompts:  60%|██████    | 1233/2048 [00:12<00:10, 74.61it/s, est. speed input: 99423.42 toks/s, output: 97.09 toks/s]
Processed prompts:  61%|██████    | 1249/2048 [00:12<00:10, 74.58it/s, est. speed input: 99039.00 toks/s, output: 96.72 toks/s]
Processed prompts:  62%|██████▏   | 1265/2048 [00:13<00:10, 74.53it/s, est. speed input: 98664.55 toks/s, output: 96.35 toks/s]
Processed prompts:  63%|██████▎   | 1281/2048 [00:13<00:10, 74.56it/s, est. speed input: 98307.17 toks/s, output: 96.00 toks/s]
Processed prompts:  63%|██████▎   | 1297/2048 [00:13<00:10, 74.53it/s, est. speed input: 97957.68 toks/s, output: 95.66 toks/s]
Processed prompts:  64%|██████▍   | 1313/2048 [00:13<00:09, 74.50it/s, est. speed input: 97618.50 toks/s, output: 95.33 toks/s]
Processed prompts:  65%|██████▍   | 1329/2048 [00:13<00:09, 74.50it/s, est. speed input: 97290.55 toks/s, output: 95.01 toks/s]
Processed prompts:  66%|██████▌   | 1345/2048 [00:14<00:09, 74.33it/s, est. speed input: 96962.16 toks/s, output: 94.69 toks/s]
Processed prompts:  66%|██████▋   | 1361/2048 [00:14<00:09, 74.41it/s, est. speed input: 96655.87 toks/s, output: 94.39 toks/s]
Processed prompts:  67%|██████▋   | 1377/2048 [00:14<00:09, 74.37it/s, est. speed input: 96353.10 toks/s, output: 94.09 toks/s]
Processed prompts:  68%|██████▊   | 1393/2048 [00:14<00:08, 74.37it/s, est. speed input: 96060.27 toks/s, output: 93.81 toks/s]
Processed prompts:  69%|██████▉   | 1409/2048 [00:15<00:08, 74.42it/s, est. speed input: 95779.26 toks/s, output: 93.53 toks/s]
Processed prompts:  70%|██████▉   | 1425/2048 [00:15<00:08, 74.32it/s, est. speed input: 95497.80 toks/s, output: 93.26 toks/s]
Processed prompts:  70%|███████   | 1441/2048 [00:15<00:08, 74.44it/s, est. speed input: 95235.14 toks/s, output: 93.00 toks/s]
Processed prompts:  71%|███████   | 1457/2048 [00:15<00:07, 74.40it/s, est. speed input: 94973.08 toks/s, output: 92.75 toks/s]
Processed prompts:  72%|███████▏  | 1473/2048 [00:15<00:07, 74.37it/s, est. speed input: 94717.67 toks/s, output: 92.50 toks/s]
Processed prompts:  73%|███████▎  | 1489/2048 [00:16<00:07, 74.27it/s, est. speed input: 94464.44 toks/s, output: 92.25 toks/s]
Processed prompts:  73%|███████▎  | 1505/2048 [00:16<00:07, 74.41it/s, est. speed input: 94229.97 toks/s, output: 92.02 toks/s]
Processed prompts:  74%|███████▍  | 1521/2048 [00:16<00:07, 74.43it/s, est. speed input: 93996.77 toks/s, output: 91.79 toks/s]
Processed prompts:  75%|███████▌  | 1537/2048 [00:16<00:06, 74.47it/s, est. speed input: 93771.19 toks/s, output: 91.57 toks/s]
Processed prompts:  76%|███████▌  | 1553/2048 [00:16<00:06, 74.39it/s, est. speed input: 93545.70 toks/s, output: 91.35 toks/s]
Processed prompts:  77%|███████▋  | 1569/2048 [00:17<00:06, 74.49it/s, est. speed input: 93333.56 toks/s, output: 91.15 toks/s]
Processed prompts:  77%|███████▋  | 1585/2048 [00:17<00:06, 74.51it/s, est. speed input: 93124.71 toks/s, output: 90.94 toks/s]
Processed prompts:  78%|███████▊  | 1601/2048 [00:17<00:06, 74.44it/s, est. speed input: 92916.33 toks/s, output: 90.74 toks/s]
Processed prompts:  79%|███████▉  | 1617/2048 [00:17<00:05, 74.48it/s, est. speed input: 92717.23 toks/s, output: 90.54 toks/s]
Processed prompts:  80%|███████▉  | 1633/2048 [00:18<00:05, 74.42it/s, est. speed input: 92519.15 toks/s, output: 90.35 toks/s]
Processed prompts:  81%|████████  | 1649/2048 [00:18<00:05, 74.34it/s, est. speed input: 92323.49 toks/s, output: 90.16 toks/s]
Processed prompts:  81%|████████▏ | 1665/2048 [00:18<00:05, 74.22it/s, est. speed input: 92129.31 toks/s, output: 89.97 toks/s]
Processed prompts:  82%|████████▏ | 1681/2048 [00:18<00:04, 74.27it/s, est. speed input: 91946.14 toks/s, output: 89.79 toks/s]
Processed prompts:  83%|████████▎ | 1697/2048 [00:18<00:04, 74.31it/s, est. speed input: 91766.78 toks/s, output: 89.62 toks/s]
Processed prompts:  84%|████████▎ | 1713/2048 [00:19<00:04, 74.35it/s, est. speed input: 91592.66 toks/s, output: 89.45 toks/s]
Processed prompts:  84%|████████▍ | 1729/2048 [00:19<00:04, 74.27it/s, est. speed input: 91417.25 toks/s, output: 89.27 toks/s]
Processed prompts:  85%|████████▌ | 1745/2048 [00:19<00:04, 74.29it/s, est. speed input: 91249.29 toks/s, output: 89.11 toks/s]
Processed prompts:  86%|████████▌ | 1761/2048 [00:19<00:03, 74.21it/s, est. speed input: 91080.42 toks/s, output: 88.95 toks/s]
Processed prompts:  87%|████████▋ | 1777/2048 [00:20<00:03, 74.34it/s, est. speed input: 90923.79 toks/s, output: 88.79 toks/s]
Processed prompts:  88%|████████▊ | 1793/2048 [00:20<00:03, 74.29it/s, est. speed input: 90763.81 toks/s, output: 88.64 toks/s]
Processed prompts:  88%|████████▊ | 1809/2048 [00:20<00:03, 74.25it/s, est. speed input: 90607.63 toks/s, output: 88.48 toks/s]
Processed prompts:  89%|████████▉ | 1825/2048 [00:20<00:03, 74.21it/s, est. speed input: 90453.79 toks/s, output: 88.33 toks/s]
Processed prompts:  90%|████████▉ | 1841/2048 [00:20<00:02, 74.34it/s, est. speed input: 90309.90 toks/s, output: 88.19 toks/s]
Processed prompts:  91%|█████████ | 1857/2048 [00:21<00:02, 74.24it/s, est. speed input: 90160.83 toks/s, output: 88.05 toks/s]
Processed prompts:  91%|█████████▏| 1873/2048 [00:21<00:02, 75.52it/s, est. speed input: 90069.51 toks/s, output: 87.96 toks/s]
Processed prompts:  92%|█████████▏| 1889/2048 [00:21<00:02, 75.19it/s, est. speed input: 89931.18 toks/s, output: 87.82 toks/s]
Processed prompts:  93%|█████████▎| 1905/2048 [00:21<00:01, 74.91it/s, est. speed input: 89793.47 toks/s, output: 87.69 toks/s]
Processed prompts:  94%|█████████▍| 1921/2048 [00:21<00:01, 74.74it/s, est. speed input: 89659.25 toks/s, output: 87.56 toks/s]
Processed prompts:  95%|█████████▍| 1937/2048 [00:22<00:01, 74.69it/s, est. speed input: 89530.44 toks/s, output: 87.43 toks/s]
Processed prompts:  95%|█████████▌| 1953/2048 [00:22<00:01, 75.83it/s, est. speed input: 89448.46 toks/s, output: 87.35 toks/s]
Processed prompts:  96%|█████████▌| 1969/2048 [00:22<00:01, 75.40it/s, est. speed input: 89322.09 toks/s, output: 87.23 toks/s]
Processed prompts:  97%|█████████▋| 1985/2048 [00:22<00:00, 75.07it/s, est. speed input: 89197.20 toks/s, output: 87.11 toks/s]
Processed prompts:  98%|█████████▊| 2001/2048 [00:23<00:00, 74.69it/s, est. speed input: 89069.06 toks/s, output: 86.98 toks/s]
Processed prompts:  98%|█████████▊| 2017/2048 [00:23<00:00, 74.52it/s, est. speed input: 88946.52 toks/s, output: 86.86 toks/s]
Processed prompts:  99%|█████████▉| 2033/2048 [00:23<00:00, 74.67it/s, est. speed input: 88836.21 toks/s, output: 86.75 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:23<00:00, 74.67it/s, est. speed input: 89489.39 toks/s, output: 87.39 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:23<00:00, 87.39it/s, est. speed input: 89489.39 toks/s, output: 87.39 toks/s]
[rank0]:[W126 09:58:30.734407128 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 09:58:32
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:58:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1177943) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1177943) WARNING 01-26 09:59:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 75.47 requests/s, 77357.68 total tokens/s, 75.47 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 09:58:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:58:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:58:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:58:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:58:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:58:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:58:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:58:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:58:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:59:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:59:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:59:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:59:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:59:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:59:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:59:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:59:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:59:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1177943) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1177943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1177943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=1177943) 
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1177943) [2026-01-26 09:59:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1177943) [rank0]:W0126 09:59:18.621000 1177943 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1177943) [rank0]:W0126 09:59:18.708000 1177943 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1177943) [rank0]:W0126 09:59:19.577000 1177943 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1177943) [rank0]:W0126 09:59:19.706000 1177943 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1177943) 2026-01-26 09:59:23,740 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1177943) 2026-01-26 09:59:23,806 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1177943) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00, 14.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 16.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 12.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  5.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  6.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.74it/s]
(EngineCore_DP0 pid=1177943) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 18.30it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 19.11it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 19.62it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 19.42it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 31/4096 [00:00<00:13, 309.31it/s]
Adding requests:   2%|▏         | 83/4096 [00:00<00:09, 430.99it/s]
Adding requests:   3%|▎         | 134/4096 [00:00<00:08, 466.51it/s]
Adding requests:   4%|▍         | 184/4096 [00:00<00:08, 476.31it/s]
Adding requests:   6%|▌         | 236/4096 [00:00<00:07, 491.18it/s]
Adding requests:   7%|▋         | 287/4096 [00:00<00:07, 496.44it/s]
Adding requests:   8%|▊         | 338/4096 [00:00<00:07, 497.67it/s]
Adding requests:  10%|▉         | 391/4096 [00:00<00:07, 506.53it/s]
Adding requests:  11%|█         | 442/4096 [00:00<00:07, 506.32it/s]
Adding requests:  12%|█▏        | 494/4096 [00:01<00:07, 508.12it/s]
Adding requests:  13%|█▎        | 545/4096 [00:01<00:07, 498.41it/s]
Adding requests:  15%|█▍        | 597/4096 [00:01<00:06, 504.45it/s]
Adding requests:  16%|█▌        | 649/4096 [00:01<00:06, 508.80it/s]
Adding requests:  17%|█▋        | 702/4096 [00:01<00:06, 514.57it/s]
Adding requests:  18%|█▊        | 754/4096 [00:01<00:06, 514.24it/s]
Adding requests:  20%|█▉        | 806/4096 [00:01<00:06, 504.95it/s]
Adding requests:  21%|██        | 857/4096 [00:01<00:06, 503.77it/s]
Adding requests:  22%|██▏       | 910/4096 [00:01<00:06, 510.65it/s]
Adding requests:  23%|██▎       | 962/4096 [00:01<00:06, 512.45it/s]
Adding requests:  25%|██▍       | 1014/4096 [00:02<00:05, 514.43it/s]
Adding requests:  26%|██▌       | 1066/4096 [00:02<00:05, 515.58it/s]
Adding requests:  27%|██▋       | 1118/4096 [00:02<00:05, 496.54it/s]
Adding requests:  29%|██▊       | 1171/4096 [00:02<00:05, 506.06it/s]
Adding requests:  30%|██▉       | 1225/4096 [00:02<00:05, 513.78it/s]
Adding requests:  31%|███       | 1277/4096 [00:02<00:05, 508.40it/s]
Adding requests:  32%|███▏      | 1330/4096 [00:02<00:05, 513.86it/s]
Adding requests:  34%|███▎      | 1382/4096 [00:02<00:05, 514.90it/s]
Adding requests:  35%|███▌      | 1435/4096 [00:02<00:05, 516.84it/s]
Adding requests:  36%|███▋      | 1488/4096 [00:02<00:05, 518.62it/s]
Adding requests:  38%|███▊      | 1541/4096 [00:03<00:04, 521.22it/s]
Adding requests:  39%|███▉      | 1595/4096 [00:03<00:04, 526.09it/s]
Adding requests:  40%|████      | 1648/4096 [00:03<00:04, 526.13it/s]
Adding requests:  42%|████▏     | 1701/4096 [00:03<00:04, 519.12it/s]
Adding requests:  43%|████▎     | 1754/4096 [00:03<00:04, 520.75it/s]
Adding requests:  44%|████▍     | 1807/4096 [00:03<00:04, 519.67it/s]
Adding requests:  45%|████▌     | 1860/4096 [00:03<00:04, 517.71it/s]
Adding requests:  47%|████▋     | 1912/4096 [00:03<00:04, 516.79it/s]
Adding requests:  48%|████▊     | 1964/4096 [00:03<00:04, 515.83it/s]
Adding requests:  49%|████▉     | 2017/4096 [00:03<00:04, 517.44it/s]
Adding requests:  51%|█████     | 2070/4096 [00:04<00:03, 519.53it/s]
Adding requests:  52%|█████▏    | 2122/4096 [00:04<00:03, 516.06it/s]
Adding requests:  53%|█████▎    | 2174/4096 [00:04<00:03, 511.30it/s]
Adding requests:  54%|█████▍    | 2226/4096 [00:04<00:03, 511.35it/s]
Adding requests:  56%|█████▌    | 2278/4096 [00:04<00:03, 512.98it/s]
Adding requests:  57%|█████▋    | 2330/4096 [00:04<00:03, 502.76it/s]
Adding requests:  58%|█████▊    | 2382/4096 [00:04<00:03, 507.15it/s]
Adding requests:  59%|█████▉    | 2434/4096 [00:04<00:03, 509.82it/s]
Adding requests:  61%|██████    | 2486/4096 [00:04<00:03, 510.91it/s]
Adding requests:  62%|██████▏   | 2538/4096 [00:04<00:03, 512.31it/s]
Adding requests:  63%|██████▎   | 2591/4096 [00:05<00:02, 515.40it/s]
Adding requests:  65%|██████▍   | 2643/4096 [00:05<00:02, 515.02it/s]
Adding requests:  66%|██████▌   | 2695/4096 [00:05<00:02, 512.97it/s]
Adding requests:  67%|██████▋   | 2747/4096 [00:05<00:02, 510.72it/s]
Adding requests:  68%|██████▊   | 2799/4096 [00:05<00:02, 508.77it/s]
Adding requests:  70%|██████▉   | 2851/4096 [00:05<00:02, 510.93it/s]
Adding requests:  71%|███████   | 2904/4096 [00:05<00:02, 514.45it/s]
Adding requests:  72%|███████▏  | 2956/4096 [00:05<00:02, 509.27it/s]
Adding requests:  73%|███████▎  | 3008/4096 [00:05<00:02, 511.66it/s]
Adding requests:  75%|███████▍  | 3060/4096 [00:06<00:02, 509.94it/s]
Adding requests:  76%|███████▌  | 3112/4096 [00:06<00:01, 510.31it/s]
Adding requests:  77%|███████▋  | 3164/4096 [00:06<00:01, 511.66it/s]
Adding requests:  79%|███████▊  | 3216/4096 [00:06<00:01, 512.44it/s]
Adding requests:  80%|███████▉  | 3268/4096 [00:06<00:01, 514.03it/s]
Adding requests:  81%|████████  | 3320/4096 [00:06<00:01, 514.01it/s]
Adding requests:  82%|████████▏ | 3372/4096 [00:06<00:01, 513.67it/s]
Adding requests:  84%|████████▎ | 3425/4096 [00:06<00:01, 517.02it/s]
Adding requests:  85%|████████▍ | 3477/4096 [00:06<00:01, 506.76it/s]
Adding requests:  86%|████████▌ | 3528/4096 [00:06<00:01, 506.45it/s]
Adding requests:  87%|████████▋ | 3580/4096 [00:07<00:01, 507.41it/s]
Adding requests:  89%|████████▊ | 3631/4096 [00:07<00:00, 495.60it/s]
Adding requests:  90%|████████▉ | 3683/4096 [00:07<00:00, 501.28it/s]
Adding requests:  91%|█████████ | 3735/4096 [00:07<00:00, 503.93it/s]
Adding requests:  93%|█████████▎| 3789/4096 [00:07<00:00, 514.52it/s]
Adding requests:  94%|█████████▍| 3842/4096 [00:07<00:00, 516.28it/s]
Adding requests:  95%|█████████▌| 3895/4096 [00:07<00:00, 518.49it/s]
Adding requests:  96%|█████████▋| 3948/4096 [00:07<00:00, 518.89it/s]
Adding requests:  98%|█████████▊| 4000/4096 [00:07<00:00, 515.37it/s]
Adding requests:  99%|█████████▉| 4052/4096 [00:07<00:00, 514.52it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 509.66it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  15%|█▍        | 596/4096 [00:00<00:01, 1801.73it/s, est. speed input: 1845148.62 toks/s, output: 1801.78 toks/s]
Processed prompts:  19%|█▉        | 777/4096 [00:02<00:12, 255.36it/s, est. speed input: 325849.47 toks/s, output: 318.21 toks/s]   
Processed prompts:  21%|██        | 857/4096 [00:03<00:18, 171.70it/s, est. speed input: 236755.10 toks/s, output: 231.21 toks/s]
Processed prompts:  22%|██▏       | 903/4096 [00:04<00:19, 160.88it/s, est. speed input: 223929.15 toks/s, output: 218.68 toks/s]
Processed prompts:  23%|██▎       | 936/4096 [00:04<00:21, 145.44it/s, est. speed input: 211175.27 toks/s, output: 206.23 toks/s]
Processed prompts:  23%|██▎       | 960/4096 [00:04<00:24, 125.87it/s, est. speed input: 198151.62 toks/s, output: 193.51 toks/s]
Processed prompts:  24%|██▍       | 980/4096 [00:05<00:28, 107.73it/s, est. speed input: 186804.47 toks/s, output: 182.43 toks/s]
Processed prompts:  25%|██▍       | 1012/4096 [00:05<00:31, 99.46it/s, est. speed input: 178805.01 toks/s, output: 174.61 toks/s]
Processed prompts:  25%|██▌       | 1044/4096 [00:06<00:32, 93.10it/s, est. speed input: 171924.82 toks/s, output: 167.89 toks/s]
Processed prompts:  26%|██▋       | 1076/4096 [00:06<00:34, 88.26it/s, est. speed input: 165907.36 toks/s, output: 162.02 toks/s]
Processed prompts:  27%|██▋       | 1108/4096 [00:07<00:35, 84.67it/s, est. speed input: 160604.85 toks/s, output: 156.84 toks/s]
Processed prompts:  28%|██▊       | 1140/4096 [00:07<00:35, 82.77it/s, est. speed input: 156167.42 toks/s, output: 152.51 toks/s]
Processed prompts:  29%|██▊       | 1172/4096 [00:07<00:36, 80.61it/s, est. speed input: 151927.11 toks/s, output: 148.37 toks/s]
Processed prompts:  29%|██▉       | 1204/4096 [00:08<00:36, 79.11it/s, est. speed input: 148132.31 toks/s, output: 144.66 toks/s]
Processed prompts:  30%|███       | 1236/4096 [00:08<00:36, 78.11it/s, est. speed input: 144721.94 toks/s, output: 141.33 toks/s]
Processed prompts:  31%|███       | 1268/4096 [00:09<00:36, 77.35it/s, est. speed input: 141611.05 toks/s, output: 138.29 toks/s]
Processed prompts:  32%|███▏      | 1300/4096 [00:09<00:36, 76.91it/s, est. speed input: 138799.37 toks/s, output: 135.55 toks/s]
Processed prompts:  33%|███▎      | 1332/4096 [00:10<00:36, 76.50it/s, est. speed input: 136199.82 toks/s, output: 133.01 toks/s]
Processed prompts:  33%|███▎      | 1364/4096 [00:10<00:35, 76.22it/s, est. speed input: 133814.17 toks/s, output: 130.68 toks/s]
Processed prompts:  34%|███▍      | 1396/4096 [00:10<00:35, 75.99it/s, est. speed input: 131606.21 toks/s, output: 128.52 toks/s]
Processed prompts:  35%|███▍      | 1428/4096 [00:11<00:35, 75.84it/s, est. speed input: 129566.19 toks/s, output: 126.53 toks/s]
Processed prompts:  36%|███▌      | 1460/4096 [00:11<00:34, 75.79it/s, est. speed input: 127684.84 toks/s, output: 124.69 toks/s]
Processed prompts:  36%|███▋      | 1492/4096 [00:12<00:34, 75.76it/s, est. speed input: 125935.90 toks/s, output: 122.98 toks/s]
Processed prompts:  37%|███▋      | 1524/4096 [00:12<00:33, 75.67it/s, est. speed input: 124293.51 toks/s, output: 121.38 toks/s]
Processed prompts:  38%|███▊      | 1556/4096 [00:12<00:33, 75.57it/s, est. speed input: 122749.58 toks/s, output: 119.87 toks/s]
Processed prompts:  39%|███▉      | 1588/4096 [00:13<00:33, 75.49it/s, est. speed input: 121302.78 toks/s, output: 118.46 toks/s]
Processed prompts:  40%|███▉      | 1620/4096 [00:13<00:32, 75.49it/s, est. speed input: 119955.07 toks/s, output: 117.14 toks/s]
Processed prompts:  40%|████      | 1652/4096 [00:14<00:32, 75.55it/s, est. speed input: 118695.54 toks/s, output: 115.91 toks/s]
Processed prompts:  41%|████      | 1684/4096 [00:14<00:31, 75.52it/s, est. speed input: 117497.73 toks/s, output: 114.74 toks/s]
Processed prompts:  42%|████▏     | 1716/4096 [00:15<00:31, 75.47it/s, est. speed input: 116362.90 toks/s, output: 113.64 toks/s]
Processed prompts:  43%|████▎     | 1748/4096 [00:15<00:31, 75.40it/s, est. speed input: 115286.79 toks/s, output: 112.58 toks/s]
Processed prompts:  43%|████▎     | 1780/4096 [00:15<00:30, 75.37it/s, est. speed input: 114269.64 toks/s, output: 111.59 toks/s]
Processed prompts:  44%|████▍     | 1812/4096 [00:16<00:30, 75.44it/s, est. speed input: 113316.81 toks/s, output: 110.66 toks/s]
Processed prompts:  45%|████▌     | 1844/4096 [00:16<00:29, 75.30it/s, est. speed input: 112387.98 toks/s, output: 109.75 toks/s]
Processed prompts:  46%|████▌     | 1876/4096 [00:17<00:29, 75.99it/s, est. speed input: 111601.33 toks/s, output: 108.99 toks/s]
Processed prompts:  47%|████▋     | 1908/4096 [00:17<00:28, 75.85it/s, est. speed input: 110777.92 toks/s, output: 108.18 toks/s]
Processed prompts:  47%|████▋     | 1940/4096 [00:18<00:28, 76.31it/s, est. speed input: 110056.03 toks/s, output: 107.48 toks/s]
Processed prompts:  48%|████▊     | 1972/4096 [00:18<00:27, 76.09it/s, est. speed input: 109307.81 toks/s, output: 106.75 toks/s]
Processed prompts:  49%|████▉     | 2004/4096 [00:18<00:27, 75.86it/s, est. speed input: 108584.88 toks/s, output: 106.04 toks/s]
Processed prompts:  50%|████▉     | 2036/4096 [00:19<00:27, 75.54it/s, est. speed input: 107877.11 toks/s, output: 105.35 toks/s]
Processed prompts:  50%|█████     | 2068/4096 [00:19<00:26, 75.61it/s, est. speed input: 107229.65 toks/s, output: 104.72 toks/s]
Processed prompts:  51%|█████▏    | 2100/4096 [00:20<00:26, 75.54it/s, est. speed input: 106597.10 toks/s, output: 104.10 toks/s]
Processed prompts:  52%|█████▏    | 2132/4096 [00:20<00:26, 75.54it/s, est. speed input: 105995.24 toks/s, output: 103.51 toks/s]
Processed prompts:  53%|█████▎    | 2164/4096 [00:21<00:25, 75.44it/s, est. speed input: 105408.66 toks/s, output: 102.94 toks/s]
Processed prompts:  54%|█████▎    | 2196/4096 [00:21<00:25, 75.42it/s, est. speed input: 104849.65 toks/s, output: 102.39 toks/s]
Processed prompts:  54%|█████▍    | 2228/4096 [00:21<00:24, 76.82it/s, est. speed input: 104436.83 toks/s, output: 101.99 toks/s]
Processed prompts:  55%|█████▌    | 2260/4096 [00:22<00:24, 76.28it/s, est. speed input: 103908.71 toks/s, output: 101.47 toks/s]
Processed prompts:  56%|█████▌    | 2292/4096 [00:22<00:23, 76.65it/s, est. speed input: 103462.89 toks/s, output: 101.04 toks/s]
Processed prompts:  57%|█████▋    | 2324/4096 [00:23<00:23, 76.88it/s, est. speed input: 103030.16 toks/s, output: 100.62 toks/s]
Processed prompts:  58%|█████▊    | 2356/4096 [00:23<00:22, 76.40it/s, est. speed input: 102562.14 toks/s, output: 100.16 toks/s]
Processed prompts:  58%|█████▊    | 2388/4096 [00:23<00:22, 76.04it/s, est. speed input: 102108.02 toks/s, output: 99.71 toks/s] 
Processed prompts:  59%|█████▉    | 2420/4096 [00:24<00:22, 75.85it/s, est. speed input: 101674.40 toks/s, output: 99.29 toks/s]
Processed prompts:  60%|█████▉    | 2452/4096 [00:24<00:21, 75.70it/s, est. speed input: 101254.67 toks/s, output: 98.88 toks/s]
Processed prompts:  61%|██████    | 2484/4096 [00:25<00:21, 76.10it/s, est. speed input: 100886.55 toks/s, output: 98.52 toks/s]
Processed prompts:  61%|██████▏   | 2516/4096 [00:25<00:20, 75.90it/s, est. speed input: 100495.24 toks/s, output: 98.14 toks/s]
Processed prompts:  62%|██████▏   | 2548/4096 [00:26<00:20, 75.70it/s, est. speed input: 100112.45 toks/s, output: 97.77 toks/s]
Processed prompts:  63%|██████▎   | 2580/4096 [00:26<00:19, 76.27it/s, est. speed input: 99791.75 toks/s, output: 97.45 toks/s] 
Processed prompts:  64%|██████▍   | 2612/4096 [00:26<00:19, 75.83it/s, est. speed input: 99423.29 toks/s, output: 97.09 toks/s]
Processed prompts:  65%|██████▍   | 2644/4096 [00:27<00:19, 75.68it/s, est. speed input: 99077.05 toks/s, output: 96.75 toks/s]
Processed prompts:  65%|██████▌   | 2676/4096 [00:27<00:18, 75.53it/s, est. speed input: 98738.04 toks/s, output: 96.42 toks/s]
Processed prompts:  66%|██████▌   | 2708/4096 [00:28<00:18, 75.43it/s, est. speed input: 98409.85 toks/s, output: 96.10 toks/s]
Processed prompts:  67%|██████▋   | 2740/4096 [00:28<00:17, 75.41it/s, est. speed input: 98094.42 toks/s, output: 95.80 toks/s]
Processed prompts:  68%|██████▊   | 2772/4096 [00:29<00:17, 75.28it/s, est. speed input: 97781.31 toks/s, output: 95.49 toks/s]
Processed prompts:  68%|██████▊   | 2804/4096 [00:29<00:17, 75.35it/s, est. speed input: 97486.72 toks/s, output: 95.20 toks/s]
Processed prompts:  69%|██████▉   | 2836/4096 [00:29<00:16, 75.27it/s, est. speed input: 97192.75 toks/s, output: 94.91 toks/s]
Processed prompts:  70%|███████   | 2868/4096 [00:30<00:16, 75.18it/s, est. speed input: 96904.99 toks/s, output: 94.63 toks/s]
Processed prompts:  71%|███████   | 2900/4096 [00:30<00:15, 75.17it/s, est. speed input: 96628.88 toks/s, output: 94.36 toks/s]
Processed prompts:  72%|███████▏  | 2932/4096 [00:31<00:15, 75.11it/s, est. speed input: 96356.73 toks/s, output: 94.10 toks/s]
Processed prompts:  72%|███████▏  | 2964/4096 [00:31<00:15, 75.17it/s, est. speed input: 96097.73 toks/s, output: 93.85 toks/s]
Processed prompts:  73%|███████▎  | 2996/4096 [00:32<00:14, 75.02it/s, est. speed input: 95835.01 toks/s, output: 93.59 toks/s]
Processed prompts:  74%|███████▍  | 3028/4096 [00:32<00:14, 75.12it/s, est. speed input: 95590.73 toks/s, output: 93.35 toks/s]
Processed prompts:  75%|███████▍  | 3060/4096 [00:32<00:13, 75.02it/s, est. speed input: 95342.98 toks/s, output: 93.11 toks/s]
Processed prompts:  75%|███████▌  | 3092/4096 [00:33<00:13, 75.04it/s, est. speed input: 95106.80 toks/s, output: 92.88 toks/s]
Processed prompts:  76%|███████▋  | 3124/4096 [00:33<00:12, 75.70it/s, est. speed input: 94910.55 toks/s, output: 92.69 toks/s]
Processed prompts:  77%|███████▋  | 3156/4096 [00:34<00:12, 75.47it/s, est. speed input: 94683.40 toks/s, output: 92.46 toks/s]
Processed prompts:  78%|███████▊  | 3188/4096 [00:34<00:12, 75.41it/s, est. speed input: 94466.97 toks/s, output: 92.25 toks/s]
Processed prompts:  79%|███████▊  | 3220/4096 [00:34<00:11, 75.17it/s, est. speed input: 94245.63 toks/s, output: 92.04 toks/s]
Processed prompts:  79%|███████▉  | 3252/4096 [00:35<00:11, 75.21it/s, est. speed input: 94039.84 toks/s, output: 91.84 toks/s]
Processed prompts:  80%|████████  | 3284/4096 [00:35<00:10, 75.14it/s, est. speed input: 93834.09 toks/s, output: 91.63 toks/s]
Processed prompts:  81%|████████  | 3316/4096 [00:36<00:10, 75.13it/s, est. speed input: 93635.35 toks/s, output: 91.44 toks/s]
Processed prompts:  82%|████████▏ | 3348/4096 [00:36<00:09, 75.14it/s, est. speed input: 93442.17 toks/s, output: 91.25 toks/s]
Processed prompts:  83%|████████▎ | 3380/4096 [00:37<00:09, 75.11it/s, est. speed input: 93251.12 toks/s, output: 91.07 toks/s]
Processed prompts:  83%|████████▎ | 3412/4096 [00:37<00:09, 75.13it/s, est. speed input: 93066.76 toks/s, output: 90.89 toks/s]
Processed prompts:  84%|████████▍ | 3444/4096 [00:37<00:08, 75.05it/s, est. speed input: 92881.96 toks/s, output: 90.70 toks/s]
Processed prompts:  85%|████████▍ | 3476/4096 [00:38<00:08, 75.14it/s, est. speed input: 92708.16 toks/s, output: 90.54 toks/s]
Processed prompts:  86%|████████▌ | 3508/4096 [00:38<00:07, 75.05it/s, est. speed input: 92530.91 toks/s, output: 90.36 toks/s]
Processed prompts:  86%|████████▋ | 3540/4096 [00:39<00:07, 75.06it/s, est. speed input: 92361.39 toks/s, output: 90.20 toks/s]
Processed prompts:  87%|████████▋ | 3572/4096 [00:39<00:06, 75.15it/s, est. speed input: 92198.43 toks/s, output: 90.04 toks/s]
Processed prompts:  88%|████████▊ | 3604/4096 [00:40<00:06, 75.08it/s, est. speed input: 92033.61 toks/s, output: 89.88 toks/s]
Processed prompts:  89%|████████▉ | 3636/4096 [00:40<00:06, 74.99it/s, est. speed input: 91870.50 toks/s, output: 89.72 toks/s]
Processed prompts:  90%|████████▉ | 3668/4096 [00:40<00:05, 75.01it/s, est. speed input: 91714.41 toks/s, output: 89.56 toks/s]
Processed prompts:  90%|█████████ | 3700/4096 [00:41<00:05, 75.03it/s, est. speed input: 91561.20 toks/s, output: 89.42 toks/s]
Processed prompts:  91%|█████████ | 3732/4096 [00:41<00:04, 75.63it/s, est. speed input: 91435.54 toks/s, output: 89.29 toks/s]
Processed prompts:  92%|█████████▏| 3764/4096 [00:42<00:04, 75.40it/s, est. speed input: 91286.35 toks/s, output: 89.15 toks/s]
Processed prompts:  93%|█████████▎| 3796/4096 [00:42<00:03, 75.25it/s, est. speed input: 91140.15 toks/s, output: 89.00 toks/s]
Processed prompts:  93%|█████████▎| 3828/4096 [00:43<00:03, 75.17it/s, est. speed input: 90997.82 toks/s, output: 88.86 toks/s]
Processed prompts:  94%|█████████▍| 3860/4096 [00:43<00:03, 75.05it/s, est. speed input: 90856.00 toks/s, output: 88.73 toks/s]
Processed prompts:  95%|█████████▌| 3892/4096 [00:43<00:02, 74.94it/s, est. speed input: 90715.66 toks/s, output: 88.59 toks/s]
Processed prompts:  96%|█████████▌| 3924/4096 [00:44<00:02, 74.98it/s, est. speed input: 90582.62 toks/s, output: 88.46 toks/s]
Processed prompts:  97%|█████████▋| 3956/4096 [00:44<00:01, 74.86it/s, est. speed input: 90446.64 toks/s, output: 88.33 toks/s]
Processed prompts:  97%|█████████▋| 3988/4096 [00:45<00:01, 75.02it/s, est. speed input: 90322.15 toks/s, output: 88.21 toks/s]
Processed prompts:  98%|█████████▊| 4020/4096 [00:45<00:01, 75.54it/s, est. speed input: 90215.36 toks/s, output: 88.10 toks/s]
Processed prompts:  99%|█████████▉| 4052/4096 [00:46<00:00, 75.40it/s, est. speed input: 90091.87 toks/s, output: 87.98 toks/s]
Processed prompts: 100%|█████████▉| 4084/4096 [00:46<00:00, 91.43it/s, est. speed input: 90456.98 toks/s, output: 88.34 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:46<00:00, 91.43it/s, est. speed input: 90721.75 toks/s, output: 88.60 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:46<00:00, 88.60it/s, est. speed input: 90721.75 toks/s, output: 88.60 toks/s]
[rank0]:[W126 10:00:21.781102286 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:00:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:01:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1180109) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1180109) WARNING 01-26 10:01:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 75.61 requests/s, 77496.52 total tokens/s, 75.61 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:01:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:01:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:01:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:01:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:01:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:01:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:01:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:01:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:01:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:01:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:01:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:01:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:01:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:01:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:01:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:01:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:01:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1180109) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1180109) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.76it/s]
(EngineCore_DP0 pid=1180109) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.76it/s]
(EngineCore_DP0 pid=1180109) 
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15769600 bytes
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9461760 bytes
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50462720 bytes
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1180109) [2026-01-26 10:01:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25190400 bytes
(EngineCore_DP0 pid=1180109) [rank0]:W0126 10:01:25.731000 1180109 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1180109) [rank0]:W0126 10:01:25.814000 1180109 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1180109) [rank0]:W0126 10:01:26.678000 1180109 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1180109) [rank0]:W0126 10:01:26.801000 1180109 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1180109) 2026-01-26 10:01:30,474 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1180109) 2026-01-26 10:01:30,509 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1180109) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:10,  1.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:11,  1.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:05,  2.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:03,  3.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:01<00:02,  5.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:02<00:01,  7.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:00,  9.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:00, 11.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00, 10.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:03<00:00,  6.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  6.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.76it/s]
(EngineCore_DP0 pid=1180109) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 18.74it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 19.77it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 20.11it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 15.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 16.37it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 41/8192 [00:00<00:19, 408.15it/s]
Adding requests:   1%|          | 93/8192 [00:00<00:17, 471.95it/s]
Adding requests:   2%|▏         | 144/8192 [00:00<00:16, 485.69it/s]
Adding requests:   2%|▏         | 194/8192 [00:00<00:16, 489.84it/s]
Adding requests:   3%|▎         | 246/8192 [00:00<00:15, 500.20it/s]
Adding requests:   4%|▎         | 297/8192 [00:00<00:15, 503.43it/s]
Adding requests:   4%|▍         | 348/8192 [00:00<00:15, 500.72it/s]
Adding requests:   5%|▍         | 401/8192 [00:00<00:15, 506.87it/s]
Adding requests:   6%|▌         | 452/8192 [00:00<00:15, 507.70it/s]
Adding requests:   6%|▌         | 503/8192 [00:01<00:15, 506.57it/s]
Adding requests:   7%|▋         | 554/8192 [00:01<00:15, 501.16it/s]
Adding requests:   7%|▋         | 605/8192 [00:01<00:15, 498.33it/s]
Adding requests:   8%|▊         | 658/8192 [00:01<00:14, 507.54it/s]
Adding requests:   9%|▊         | 712/8192 [00:01<00:14, 515.49it/s]
Adding requests:   9%|▉         | 764/8192 [00:01<00:14, 514.98it/s]
Adding requests:  10%|▉         | 816/8192 [00:01<00:14, 506.79it/s]
Adding requests:  11%|█         | 868/8192 [00:01<00:14, 508.39it/s]
Adding requests:  11%|█▏        | 922/8192 [00:01<00:14, 514.76it/s]
Adding requests:  12%|█▏        | 975/8192 [00:01<00:13, 516.55it/s]
Adding requests:  13%|█▎        | 1028/8192 [00:02<00:13, 518.44it/s]
Adding requests:  13%|█▎        | 1080/8192 [00:02<00:13, 516.36it/s]
Adding requests:  14%|█▍        | 1132/8192 [00:02<00:13, 513.40it/s]
Adding requests:  14%|█▍        | 1186/8192 [00:02<00:13, 520.00it/s]
Adding requests:  15%|█▌        | 1240/8192 [00:02<00:13, 523.01it/s]
Adding requests:  16%|█▌        | 1293/8192 [00:02<00:13, 518.95it/s]
Adding requests:  16%|█▋        | 1346/8192 [00:02<00:13, 521.68it/s]
Adding requests:  17%|█▋        | 1400/8192 [00:02<00:12, 524.79it/s]
Adding requests:  18%|█▊        | 1453/8192 [00:02<00:12, 523.24it/s]
Adding requests:  18%|█▊        | 1507/8192 [00:02<00:12, 526.08it/s]
Adding requests:  19%|█▉        | 1560/8192 [00:03<00:12, 526.81it/s]
Adding requests:  20%|█▉        | 1614/8192 [00:03<00:12, 529.67it/s]
Adding requests:  20%|██        | 1667/8192 [00:03<00:12, 525.54it/s]
Adding requests:  21%|██        | 1720/8192 [00:03<00:12, 526.81it/s]
Adding requests:  22%|██▏       | 1773/8192 [00:03<00:12, 511.75it/s]
Adding requests:  22%|██▏       | 1826/8192 [00:03<00:12, 515.05it/s]
Adding requests:  23%|██▎       | 1878/8192 [00:03<00:12, 516.37it/s]
Adding requests:  24%|██▎       | 1930/8192 [00:03<00:12, 517.32it/s]
Adding requests:  24%|██▍       | 1982/8192 [00:03<00:11, 518.10it/s]
Adding requests:  25%|██▍       | 2036/8192 [00:03<00:11, 521.84it/s]
Adding requests:  26%|██▌       | 2090/8192 [00:04<00:11, 524.26it/s]
Adding requests:  26%|██▌       | 2143/8192 [00:04<00:11, 519.92it/s]
Adding requests:  27%|██▋       | 2196/8192 [00:04<00:11, 514.91it/s]
Adding requests:  27%|██▋       | 2250/8192 [00:04<00:11, 520.46it/s]
Adding requests:  28%|██▊       | 2303/8192 [00:04<00:11, 518.83it/s]
Adding requests:  29%|██▊       | 2355/8192 [00:04<00:11, 519.05it/s]
Adding requests:  29%|██▉       | 2407/8192 [00:04<00:11, 518.41it/s]
Adding requests:  30%|███       | 2460/8192 [00:04<00:10, 521.47it/s]
Adding requests:  31%|███       | 2513/8192 [00:04<00:10, 520.79it/s]
Adding requests:  31%|███▏      | 2567/8192 [00:04<00:10, 524.48it/s]
Adding requests:  32%|███▏      | 2620/8192 [00:05<00:10, 522.78it/s]
Adding requests:  33%|███▎      | 2673/8192 [00:05<00:10, 522.58it/s]
Adding requests:  33%|███▎      | 2726/8192 [00:05<00:10, 519.97it/s]
Adding requests:  34%|███▍      | 2779/8192 [00:05<00:10, 518.22it/s]
Adding requests:  35%|███▍      | 2831/8192 [00:05<00:10, 514.71it/s]
Adding requests:  35%|███▌      | 2884/8192 [00:05<00:10, 518.31it/s]
Adding requests:  36%|███▌      | 2936/8192 [00:05<00:10, 514.65it/s]
Adding requests:  36%|███▋      | 2989/8192 [00:05<00:10, 517.30it/s]
Adding requests:  37%|███▋      | 3041/8192 [00:05<00:09, 516.07it/s]
Adding requests:  38%|███▊      | 3093/8192 [00:06<00:10, 503.52it/s]
Adding requests:  38%|███▊      | 3145/8192 [00:06<00:09, 506.08it/s]
Adding requests:  39%|███▉      | 3197/8192 [00:06<00:09, 510.07it/s]
Adding requests:  40%|███▉      | 3251/8192 [00:06<00:09, 517.43it/s]
Adding requests:  40%|████      | 3303/8192 [00:06<00:09, 518.13it/s]
Adding requests:  41%|████      | 3357/8192 [00:06<00:09, 523.32it/s]
Adding requests:  42%|████▏     | 3410/8192 [00:06<00:09, 521.54it/s]
Adding requests:  42%|████▏     | 3463/8192 [00:06<00:09, 516.55it/s]
Adding requests:  43%|████▎     | 3515/8192 [00:06<00:09, 517.49it/s]
Adding requests:  44%|████▎     | 3567/8192 [00:06<00:09, 513.26it/s]
Adding requests:  44%|████▍     | 3619/8192 [00:07<00:08, 513.50it/s]
Adding requests:  45%|████▍     | 3671/8192 [00:07<00:08, 514.94it/s]
Adding requests:  45%|████▌     | 3723/8192 [00:07<00:08, 514.06it/s]
Adding requests:  46%|████▌     | 3777/8192 [00:07<00:08, 521.10it/s]
Adding requests:  47%|████▋     | 3830/8192 [00:07<00:08, 522.32it/s]
Adding requests:  47%|████▋     | 3883/8192 [00:07<00:08, 522.97it/s]
Adding requests:  48%|████▊     | 3936/8192 [00:07<00:08, 522.00it/s]
Adding requests:  49%|████▊     | 3989/8192 [00:07<00:08, 519.78it/s]
Adding requests:  49%|████▉     | 4042/8192 [00:07<00:07, 520.16it/s]
Adding requests:  50%|████▉     | 4095/8192 [00:07<00:07, 521.95it/s]
Adding requests:  51%|█████     | 4148/8192 [00:08<00:07, 521.72it/s]
Adding requests:  51%|█████▏    | 4202/8192 [00:08<00:07, 526.94it/s]
Adding requests:  52%|█████▏    | 4255/8192 [00:08<00:07, 527.19it/s]
Adding requests:  53%|█████▎    | 4308/8192 [00:08<00:07, 523.52it/s]
Adding requests:  53%|█████▎    | 4362/8192 [00:08<00:07, 528.03it/s]
Adding requests:  54%|█████▍    | 4416/8192 [00:08<00:07, 531.58it/s]
Adding requests:  55%|█████▍    | 4470/8192 [00:08<00:07, 518.65it/s]
Adding requests:  55%|█████▌    | 4522/8192 [00:08<00:07, 512.65it/s]
Adding requests:  56%|█████▌    | 4575/8192 [00:08<00:07, 515.41it/s]
Adding requests:  57%|█████▋    | 4629/8192 [00:08<00:06, 520.02it/s]
Adding requests:  57%|█████▋    | 4682/8192 [00:09<00:06, 518.76it/s]
Adding requests:  58%|█████▊    | 4736/8192 [00:09<00:06, 522.41it/s]
Adding requests:  58%|█████▊    | 4789/8192 [00:09<00:06, 522.44it/s]
Adding requests:  59%|█████▉    | 4842/8192 [00:09<00:06, 522.93it/s]
Adding requests:  60%|█████▉    | 4895/8192 [00:09<00:06, 516.73it/s]
Adding requests:  60%|██████    | 4949/8192 [00:09<00:06, 521.35it/s]
Adding requests:  61%|██████    | 5002/8192 [00:09<00:06, 520.53it/s]
Adding requests:  62%|██████▏   | 5056/8192 [00:09<00:05, 524.34it/s]
Adding requests:  62%|██████▏   | 5110/8192 [00:09<00:05, 528.23it/s]
Adding requests:  63%|██████▎   | 5164/8192 [00:09<00:05, 528.61it/s]
Adding requests:  64%|██████▎   | 5217/8192 [00:10<00:05, 526.48it/s]
Adding requests:  64%|██████▍   | 5270/8192 [00:10<00:05, 522.04it/s]
Adding requests:  65%|██████▍   | 5324/8192 [00:10<00:05, 525.01it/s]
Adding requests:  66%|██████▌   | 5377/8192 [00:10<00:05, 523.63it/s]
Adding requests:  66%|██████▋   | 5431/8192 [00:10<00:05, 525.80it/s]
Adding requests:  67%|██████▋   | 5484/8192 [00:10<00:05, 520.93it/s]
Adding requests:  68%|██████▊   | 5537/8192 [00:10<00:05, 519.66it/s]
Adding requests:  68%|██████▊   | 5589/8192 [00:10<00:05, 519.68it/s]
Adding requests:  69%|██████▉   | 5641/8192 [00:10<00:04, 518.49it/s]
Adding requests:  69%|██████▉   | 5693/8192 [00:11<00:04, 515.32it/s]
Adding requests:  70%|███████   | 5746/8192 [00:11<00:04, 519.64it/s]
Adding requests:  71%|███████   | 5798/8192 [00:11<00:04, 506.95it/s]
Adding requests:  71%|███████▏  | 5850/8192 [00:11<00:04, 509.10it/s]
Adding requests:  72%|███████▏  | 5904/8192 [00:11<00:04, 516.48it/s]
Adding requests:  73%|███████▎  | 5956/8192 [00:11<00:04, 517.21it/s]
Adding requests:  73%|███████▎  | 6010/8192 [00:11<00:04, 523.19it/s]
Adding requests:  74%|███████▍  | 6065/8192 [00:11<00:04, 528.15it/s]
Adding requests:  75%|███████▍  | 6118/8192 [00:11<00:03, 523.66it/s]
Adding requests:  75%|███████▌  | 6171/8192 [00:11<00:03, 523.80it/s]
Adding requests:  76%|███████▌  | 6226/8192 [00:12<00:03, 530.88it/s]
Adding requests:  77%|███████▋  | 6280/8192 [00:12<00:03, 532.45it/s]
Adding requests:  77%|███████▋  | 6334/8192 [00:12<00:03, 531.67it/s]
Adding requests:  78%|███████▊  | 6388/8192 [00:12<00:03, 533.59it/s]
Adding requests:  79%|███████▊  | 6443/8192 [00:12<00:03, 537.20it/s]
Adding requests:  79%|███████▉  | 6498/8192 [00:12<00:03, 538.86it/s]
Adding requests:  80%|███████▉  | 6552/8192 [00:12<00:03, 537.35it/s]
Adding requests:  81%|████████  | 6606/8192 [00:12<00:02, 532.59it/s]
Adding requests:  81%|████████▏ | 6660/8192 [00:12<00:02, 533.85it/s]
Adding requests:  82%|████████▏ | 6714/8192 [00:12<00:02, 529.79it/s]
Adding requests:  83%|████████▎ | 6767/8192 [00:13<00:02, 527.89it/s]
Adding requests:  83%|████████▎ | 6821/8192 [00:13<00:02, 530.17it/s]
Adding requests:  84%|████████▍ | 6876/8192 [00:13<00:02, 534.63it/s]
Adding requests:  85%|████████▍ | 6930/8192 [00:13<00:02, 535.84it/s]
Adding requests:  85%|████████▌ | 6984/8192 [00:13<00:02, 531.98it/s]
Adding requests:  86%|████████▌ | 7038/8192 [00:13<00:02, 528.24it/s]
Adding requests:  87%|████████▋ | 7091/8192 [00:13<00:02, 528.40it/s]
Adding requests:  87%|████████▋ | 7144/8192 [00:13<00:02, 516.68it/s]
Adding requests:  88%|████████▊ | 7197/8192 [00:13<00:01, 519.21it/s]
Adding requests:  89%|████████▊ | 7251/8192 [00:13<00:01, 523.41it/s]
Adding requests:  89%|████████▉ | 7305/8192 [00:14<00:01, 526.85it/s]
Adding requests:  90%|████████▉ | 7358/8192 [00:14<00:01, 526.19it/s]
Adding requests:  90%|█████████ | 7413/8192 [00:14<00:01, 531.64it/s]
Adding requests:  91%|█████████ | 7467/8192 [00:14<00:01, 534.08it/s]
Adding requests:  92%|█████████▏| 7521/8192 [00:14<00:01, 533.40it/s]
Adding requests:  92%|█████████▏| 7575/8192 [00:14<00:01, 529.17it/s]
Adding requests:  93%|█████████▎| 7628/8192 [00:14<00:01, 525.35it/s]
Adding requests:  94%|█████████▍| 7683/8192 [00:14<00:00, 530.67it/s]
Adding requests:  94%|█████████▍| 7737/8192 [00:14<00:00, 528.91it/s]
Adding requests:  95%|█████████▌| 7790/8192 [00:14<00:00, 521.30it/s]
Adding requests:  96%|█████████▌| 7844/8192 [00:15<00:00, 525.83it/s]
Adding requests:  96%|█████████▋| 7897/8192 [00:15<00:00, 521.92it/s]
Adding requests:  97%|█████████▋| 7950/8192 [00:15<00:00, 514.67it/s]
Adding requests:  98%|█████████▊| 8002/8192 [00:15<00:00, 513.12it/s]
Adding requests:  98%|█████████▊| 8054/8192 [00:15<00:00, 511.05it/s]
Adding requests:  99%|█████████▉| 8107/8192 [00:15<00:00, 515.41it/s]
Adding requests: 100%|█████████▉| 8159/8192 [00:15<00:00, 515.07it/s]
Adding requests: 100%|██████████| 8192/8192 [00:15<00:00, 519.91it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 1179/8192 [00:00<00:03, 1830.25it/s, est. speed input: 1874302.82 toks/s, output: 1830.29 toks/s]
Processed prompts:  17%|█▋        | 1363/8192 [00:02<00:14, 472.71it/s, est. speed input: 599435.57 toks/s, output: 585.38 toks/s]   
Processed prompts:  18%|█▊        | 1445/8192 [00:04<00:27, 248.20it/s, est. speed input: 368931.70 toks/s, output: 360.28 toks/s]
Processed prompts:  18%|█▊        | 1499/8192 [00:04<00:33, 197.54it/s, est. speed input: 316207.70 toks/s, output: 308.79 toks/s]
Processed prompts:  19%|█▉        | 1563/8192 [00:05<00:40, 163.30it/s, est. speed input: 280964.02 toks/s, output: 274.38 toks/s]
Processed prompts:  20%|█▉        | 1627/8192 [00:06<00:47, 138.20it/s, est. speed input: 254763.78 toks/s, output: 248.79 toks/s]
Processed prompts:  21%|██        | 1691/8192 [00:07<00:54, 120.10it/s, est. speed input: 234558.62 toks/s, output: 229.06 toks/s]
Processed prompts:  21%|██▏       | 1755/8192 [00:08<01:00, 107.19it/s, est. speed input: 218531.97 toks/s, output: 213.41 toks/s]
Processed prompts:  22%|██▏       | 1819/8192 [00:09<01:04, 98.34it/s, est. speed input: 205700.70 toks/s, output: 200.88 toks/s] 
Processed prompts:  23%|██▎       | 1883/8192 [00:09<01:08, 91.56it/s, est. speed input: 194739.48 toks/s, output: 190.17 toks/s]
Processed prompts:  24%|██▍       | 1947/8192 [00:10<01:11, 87.19it/s, est. speed input: 185727.12 toks/s, output: 181.37 toks/s]
Processed prompts:  25%|██▍       | 2011/8192 [00:11<01:13, 83.65it/s, est. speed input: 177779.81 toks/s, output: 173.61 toks/s]
Processed prompts:  25%|██▌       | 2075/8192 [00:12<01:15, 81.37it/s, est. speed input: 171006.57 toks/s, output: 167.00 toks/s]
Processed prompts:  26%|██▌       | 2139/8192 [00:13<01:16, 79.60it/s, est. speed input: 165020.28 toks/s, output: 161.15 toks/s]
Processed prompts:  27%|██▋       | 2203/8192 [00:14<01:15, 79.13it/s, est. speed input: 160064.11 toks/s, output: 156.31 toks/s]
Processed prompts:  28%|██▊       | 2267/8192 [00:14<01:15, 78.44it/s, est. speed input: 155519.77 toks/s, output: 151.87 toks/s]
Processed prompts:  28%|██▊       | 2331/8192 [00:15<01:15, 77.85it/s, est. speed input: 151420.49 toks/s, output: 147.87 toks/s]
Processed prompts:  29%|██▉       | 2395/8192 [00:16<01:15, 77.08it/s, est. speed input: 147621.50 toks/s, output: 144.16 toks/s]
Processed prompts:  30%|███       | 2459/8192 [00:17<01:14, 76.94it/s, est. speed input: 144308.59 toks/s, output: 140.93 toks/s]
Processed prompts:  31%|███       | 2523/8192 [00:18<01:14, 76.58it/s, est. speed input: 141225.16 toks/s, output: 137.91 toks/s]
Processed prompts:  32%|███▏      | 2587/8192 [00:19<01:13, 76.58it/s, est. speed input: 138482.47 toks/s, output: 135.24 toks/s]
Processed prompts:  32%|███▏      | 2651/8192 [00:19<01:12, 76.32it/s, est. speed input: 135902.48 toks/s, output: 132.72 toks/s]
Processed prompts:  33%|███▎      | 2715/8192 [00:20<01:12, 76.03it/s, est. speed input: 133507.20 toks/s, output: 130.38 toks/s]
Processed prompts:  34%|███▍      | 2779/8192 [00:21<01:11, 75.81it/s, est. speed input: 131295.17 toks/s, output: 128.22 toks/s]
Processed prompts:  35%|███▍      | 2843/8192 [00:22<01:10, 75.67it/s, est. speed input: 129253.16 toks/s, output: 126.22 toks/s]
Processed prompts:  35%|███▌      | 2907/8192 [00:23<01:09, 75.54it/s, est. speed input: 127353.12 toks/s, output: 124.37 toks/s]
Processed prompts:  36%|███▋      | 2971/8192 [00:24<01:09, 75.46it/s, est. speed input: 125588.96 toks/s, output: 122.65 toks/s]
Processed prompts:  37%|███▋      | 3035/8192 [00:25<01:08, 75.41it/s, est. speed input: 123945.31 toks/s, output: 121.04 toks/s]
Processed prompts:  38%|███▊      | 3099/8192 [00:25<01:07, 75.71it/s, est. speed input: 122468.16 toks/s, output: 119.60 toks/s]
Processed prompts:  39%|███▊      | 3163/8192 [00:26<01:06, 75.68it/s, est. speed input: 121043.27 toks/s, output: 118.21 toks/s]
Processed prompts:  39%|███▉      | 3227/8192 [00:27<01:05, 75.69it/s, est. speed input: 119711.03 toks/s, output: 116.91 toks/s]
Processed prompts:  40%|████      | 3291/8192 [00:28<01:04, 75.58it/s, est. speed input: 118439.03 toks/s, output: 115.66 toks/s]
Processed prompts:  41%|████      | 3355/8192 [00:29<01:04, 75.50it/s, est. speed input: 117240.68 toks/s, output: 114.49 toks/s]
Processed prompts:  42%|████▏     | 3419/8192 [00:30<01:03, 75.44it/s, est. speed input: 116109.43 toks/s, output: 113.39 toks/s]
Processed prompts:  43%|████▎     | 3483/8192 [00:31<01:02, 75.38it/s, est. speed input: 115037.34 toks/s, output: 112.34 toks/s]
Processed prompts:  43%|████▎     | 3547/8192 [00:31<01:01, 75.36it/s, est. speed input: 114025.90 toks/s, output: 111.35 toks/s]
Processed prompts:  44%|████▍     | 3611/8192 [00:32<01:00, 75.31it/s, est. speed input: 113062.22 toks/s, output: 110.41 toks/s]
Processed prompts:  45%|████▍     | 3675/8192 [00:33<00:59, 75.30it/s, est. speed input: 112150.92 toks/s, output: 109.52 toks/s]
Processed prompts:  46%|████▌     | 3739/8192 [00:34<00:58, 75.66it/s, est. speed input: 111328.38 toks/s, output: 108.72 toks/s]
Processed prompts:  46%|████▋     | 3803/8192 [00:35<00:57, 75.69it/s, est. speed input: 110520.00 toks/s, output: 107.93 toks/s]
Processed prompts:  47%|████▋     | 3867/8192 [00:36<00:57, 75.60it/s, est. speed input: 109736.28 toks/s, output: 107.16 toks/s]
Processed prompts:  48%|████▊     | 3931/8192 [00:36<00:56, 75.55it/s, est. speed input: 108989.14 toks/s, output: 106.43 toks/s]
Processed prompts:  49%|████▉     | 3995/8192 [00:37<00:55, 75.75it/s, est. speed input: 108301.65 toks/s, output: 105.76 toks/s]
Processed prompts:  50%|████▉     | 4059/8192 [00:38<00:54, 75.60it/s, est. speed input: 107614.11 toks/s, output: 105.09 toks/s]
Processed prompts:  50%|█████     | 4123/8192 [00:39<00:53, 75.49it/s, est. speed input: 106954.54 toks/s, output: 104.45 toks/s]
Processed prompts:  51%|█████     | 4187/8192 [00:40<00:52, 75.74it/s, est. speed input: 106356.26 toks/s, output: 103.86 toks/s]
Processed prompts:  52%|█████▏    | 4251/8192 [00:41<00:51, 75.94it/s, est. speed input: 105784.20 toks/s, output: 103.30 toks/s]
Processed prompts:  53%|█████▎    | 4315/8192 [00:41<00:50, 76.10it/s, est. speed input: 105236.36 toks/s, output: 102.77 toks/s]
Processed prompts:  53%|█████▎    | 4379/8192 [00:42<00:50, 75.93it/s, est. speed input: 104684.83 toks/s, output: 102.23 toks/s]
Processed prompts:  54%|█████▍    | 4443/8192 [00:43<00:49, 75.72it/s, est. speed input: 104146.71 toks/s, output: 101.71 toks/s]
Processed prompts:  55%|█████▌    | 4507/8192 [00:44<00:48, 75.62it/s, est. speed input: 103632.54 toks/s, output: 101.20 toks/s]
Processed prompts:  56%|█████▌    | 4571/8192 [00:45<00:47, 75.50it/s, est. speed input: 103133.63 toks/s, output: 100.72 toks/s]
Processed prompts:  57%|█████▋    | 4635/8192 [00:46<00:47, 75.43it/s, est. speed input: 102654.42 toks/s, output: 100.25 toks/s]
Processed prompts:  57%|█████▋    | 4699/8192 [00:47<00:46, 75.38it/s, est. speed input: 102192.12 toks/s, output: 99.80 toks/s] 
Processed prompts:  58%|█████▊    | 4763/8192 [00:47<00:45, 75.61it/s, est. speed input: 101767.74 toks/s, output: 99.38 toks/s]
Processed prompts:  59%|█████▉    | 4827/8192 [00:48<00:44, 75.78it/s, est. speed input: 101358.28 toks/s, output: 98.98 toks/s]
Processed prompts:  60%|█████▉    | 4891/8192 [00:49<00:43, 75.67it/s, est. speed input: 100945.62 toks/s, output: 98.58 toks/s]
Processed prompts:  60%|██████    | 4955/8192 [00:50<00:42, 75.72it/s, est. speed input: 100556.21 toks/s, output: 98.20 toks/s]
Processed prompts:  61%|██████▏   | 5019/8192 [00:51<00:41, 75.68it/s, est. speed input: 100174.18 toks/s, output: 97.83 toks/s]
Processed prompts:  62%|██████▏   | 5083/8192 [00:52<00:41, 75.60it/s, est. speed input: 99800.90 toks/s, output: 97.46 toks/s] 
Processed prompts:  63%|██████▎   | 5147/8192 [00:53<00:40, 75.47it/s, est. speed input: 99433.98 toks/s, output: 97.10 toks/s]
Processed prompts:  64%|██████▎   | 5211/8192 [00:53<00:39, 75.40it/s, est. speed input: 99080.59 toks/s, output: 96.76 toks/s]
Processed prompts:  64%|██████▍   | 5275/8192 [00:54<00:38, 75.38it/s, est. speed input: 98739.98 toks/s, output: 96.43 toks/s]
Processed prompts:  65%|██████▌   | 5339/8192 [00:55<00:37, 75.33it/s, est. speed input: 98407.34 toks/s, output: 96.10 toks/s]
Processed prompts:  66%|██████▌   | 5403/8192 [00:56<00:37, 75.35it/s, est. speed input: 98087.81 toks/s, output: 95.79 toks/s]
Processed prompts:  67%|██████▋   | 5467/8192 [00:57<00:36, 75.32it/s, est. speed input: 97775.40 toks/s, output: 95.48 toks/s]
Processed prompts:  68%|██████▊   | 5531/8192 [00:58<00:35, 75.49it/s, est. speed input: 97484.04 toks/s, output: 95.20 toks/s]
Processed prompts:  68%|██████▊   | 5595/8192 [00:58<00:34, 75.44it/s, est. speed input: 97190.72 toks/s, output: 94.91 toks/s]
Processed prompts:  69%|██████▉   | 5659/8192 [00:59<00:33, 75.37it/s, est. speed input: 96903.47 toks/s, output: 94.63 toks/s]
Processed prompts:  70%|██████▉   | 5723/8192 [01:00<00:32, 75.35it/s, est. speed input: 96626.07 toks/s, output: 94.36 toks/s]
Processed prompts:  71%|███████   | 5787/8192 [01:01<00:31, 75.39it/s, est. speed input: 96359.57 toks/s, output: 94.10 toks/s]
Processed prompts:  71%|███████▏  | 5851/8192 [01:02<00:31, 75.29it/s, est. speed input: 96093.21 toks/s, output: 93.84 toks/s]
Processed prompts:  72%|███████▏  | 5915/8192 [01:03<00:30, 75.29it/s, est. speed input: 95837.80 toks/s, output: 93.59 toks/s]
Processed prompts:  73%|███████▎  | 5979/8192 [01:04<00:29, 75.30it/s, est. speed input: 95589.43 toks/s, output: 93.35 toks/s]
Processed prompts:  74%|███████▍  | 6043/8192 [01:04<00:28, 75.28it/s, est. speed input: 95346.46 toks/s, output: 93.11 toks/s]
Processed prompts:  75%|███████▍  | 6107/8192 [01:05<00:27, 75.31it/s, est. speed input: 95112.03 toks/s, output: 92.88 toks/s]
Processed prompts:  75%|███████▌  | 6171/8192 [01:06<00:26, 75.30it/s, est. speed input: 94881.80 toks/s, output: 92.66 toks/s]
Processed prompts:  76%|███████▌  | 6235/8192 [01:07<00:25, 75.29it/s, est. speed input: 94657.09 toks/s, output: 92.44 toks/s]
Processed prompts:  77%|███████▋  | 6299/8192 [01:08<00:25, 75.31it/s, est. speed input: 94439.64 toks/s, output: 92.23 toks/s]
Processed prompts:  78%|███████▊  | 6363/8192 [01:09<00:24, 75.29it/s, est. speed input: 94225.76 toks/s, output: 92.02 toks/s]
Processed prompts:  78%|███████▊  | 6427/8192 [01:09<00:23, 75.30it/s, est. speed input: 94018.08 toks/s, output: 91.81 toks/s]
Processed prompts:  79%|███████▉  | 6491/8192 [01:10<00:22, 75.29it/s, est. speed input: 93814.82 toks/s, output: 91.62 toks/s]
Processed prompts:  80%|████████  | 6555/8192 [01:11<00:21, 75.49it/s, est. speed input: 93626.61 toks/s, output: 91.43 toks/s]
Processed prompts:  81%|████████  | 6619/8192 [01:12<00:20, 75.66it/s, est. speed input: 93444.05 toks/s, output: 91.25 toks/s]
Processed prompts:  82%|████████▏ | 6683/8192 [01:13<00:19, 75.49it/s, est. speed input: 93251.94 toks/s, output: 91.07 toks/s]
Processed prompts:  82%|████████▏ | 6747/8192 [01:14<00:19, 75.40it/s, est. speed input: 93065.48 toks/s, output: 90.88 toks/s]
Processed prompts:  83%|████████▎ | 6811/8192 [01:15<00:18, 75.36it/s, est. speed input: 92884.43 toks/s, output: 90.71 toks/s]
Processed prompts:  84%|████████▍ | 6875/8192 [01:15<00:17, 75.37it/s, est. speed input: 92708.95 toks/s, output: 90.54 toks/s]
Processed prompts:  85%|████████▍ | 6939/8192 [01:16<00:16, 75.40it/s, est. speed input: 92538.46 toks/s, output: 90.37 toks/s]
Processed prompts:  85%|████████▌ | 7003/8192 [01:17<00:15, 75.32it/s, est. speed input: 92367.36 toks/s, output: 90.20 toks/s]
Processed prompts:  86%|████████▋ | 7067/8192 [01:18<00:14, 75.30it/s, est. speed input: 92201.48 toks/s, output: 90.04 toks/s]
Processed prompts:  87%|████████▋ | 7131/8192 [01:19<00:14, 75.39it/s, est. speed input: 92043.86 toks/s, output: 89.89 toks/s]
Processed prompts:  88%|████████▊ | 7195/8192 [01:20<00:13, 75.27it/s, est. speed input: 91881.62 toks/s, output: 89.73 toks/s]
Processed prompts:  89%|████████▊ | 7259/8192 [01:21<00:12, 75.36it/s, est. speed input: 91729.87 toks/s, output: 89.58 toks/s]
Processed prompts:  89%|████████▉ | 7323/8192 [01:21<00:11, 75.24it/s, est. speed input: 91574.02 toks/s, output: 89.43 toks/s]
Processed prompts:  90%|█████████ | 7387/8192 [01:22<00:10, 75.35it/s, est. speed input: 91429.24 toks/s, output: 89.29 toks/s]
Processed prompts:  91%|█████████ | 7451/8192 [01:23<00:09, 75.24it/s, est. speed input: 91279.71 toks/s, output: 89.14 toks/s]
Processed prompts:  92%|█████████▏| 7515/8192 [01:24<00:08, 75.27it/s, est. speed input: 91137.32 toks/s, output: 89.00 toks/s]
Processed prompts:  93%|█████████▎| 7579/8192 [01:25<00:08, 75.28it/s, est. speed input: 90997.78 toks/s, output: 88.86 toks/s]
Processed prompts:  93%|█████████▎| 7643/8192 [01:26<00:07, 75.27it/s, est. speed input: 90859.94 toks/s, output: 88.73 toks/s]
Processed prompts:  94%|█████████▍| 7707/8192 [01:26<00:06, 75.24it/s, est. speed input: 90723.93 toks/s, output: 88.60 toks/s]
Processed prompts:  95%|█████████▍| 7771/8192 [01:27<00:05, 75.21it/s, est. speed input: 90590.41 toks/s, output: 88.47 toks/s]
Processed prompts:  96%|█████████▌| 7835/8192 [01:28<00:04, 75.15it/s, est. speed input: 90457.80 toks/s, output: 88.34 toks/s]
Processed prompts:  96%|█████████▋| 7899/8192 [01:29<00:03, 75.10it/s, est. speed input: 90327.51 toks/s, output: 88.21 toks/s]
Processed prompts:  97%|█████████▋| 7963/8192 [01:30<00:03, 75.12it/s, est. speed input: 90201.84 toks/s, output: 88.09 toks/s]
Processed prompts:  98%|█████████▊| 8027/8192 [01:31<00:02, 75.11it/s, est. speed input: 90077.28 toks/s, output: 87.97 toks/s]
Processed prompts:  99%|█████████▉| 8091/8192 [01:32<00:01, 75.42it/s, est. speed input: 89966.86 toks/s, output: 87.86 toks/s]
Processed prompts: 100%|█████████▉| 8155/8192 [01:32<00:00, 86.15it/s, est. speed input: 90192.57 toks/s, output: 88.08 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:32<00:00, 86.15it/s, est. speed input: 90600.55 toks/s, output: 88.48 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:32<00:00, 88.48it/s, est. speed input: 90600.55 toks/s, output: 88.48 toks/s]
[rank0]:[W126 10:03:24.920351048 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:33:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:33:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1292207) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1292207) WARNING 01-26 11:33:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.41 requests/s, 18163.89 total tokens/s, 35.41 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:33:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:33:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:33:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:33:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:33:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:33:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:33:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:33:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:33:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:33:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:33:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:33:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1292207) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1292207) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1292207) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1292207) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1292207) 
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1292207) [2026-01-26 11:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1292207) 2026-01-26 11:33:41,269 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1292207) 2026-01-26 11:33:41,321 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1292207) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
(EngineCore_DP0 pid=1292207) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  28%|██▊       | 36/128 [00:00<00:00, 355.68it/s]
Adding requests:  84%|████████▎ | 107/128 [00:00<00:00, 560.63it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 551.38it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:26,  4.75it/s, est. speed input: 2430.13 toks/s, output: 4.75 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 21.17it/s, est. speed input: 9242.11 toks/s, output: 18.05 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:04, 29.07it/s, est. speed input: 12426.80 toks/s, output: 24.27 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 33.38it/s, est. speed input: 14246.01 toks/s, output: 27.82 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 35.98it/s, est. speed input: 15427.54 toks/s, output: 30.13 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 37.36it/s, est. speed input: 16205.49 toks/s, output: 31.65 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 38.20it/s, est. speed input: 16767.73 toks/s, output: 32.75 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:02, 38.66it/s, est. speed input: 17118.95 toks/s, output: 33.43 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 38.96it/s, est. speed input: 17401.59 toks/s, output: 33.99 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 39.22it/s, est. speed input: 17643.96 toks/s, output: 34.46 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 39.43it/s, est. speed input: 17852.58 toks/s, output: 34.87 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 39.48it/s, est. speed input: 18021.08 toks/s, output: 35.20 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:01, 39.57it/s, est. speed input: 18173.87 toks/s, output: 35.50 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:01, 39.64it/s, est. speed input: 18308.68 toks/s, output: 35.76 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 39.72it/s, est. speed input: 18429.84 toks/s, output: 36.00 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 39.77it/s, est. speed input: 18538.35 toks/s, output: 36.21 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 39.80it/s, est. speed input: 18634.74 toks/s, output: 36.40 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 39.82it/s, est. speed input: 18721.84 toks/s, output: 36.57 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 39.79it/s, est. speed input: 18796.86 toks/s, output: 36.71 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 39.88it/s, est. speed input: 18890.74 toks/s, output: 36.90 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:00, 39.93it/s, est. speed input: 18974.40 toks/s, output: 37.06 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 39.92it/s, est. speed input: 19032.41 toks/s, output: 37.17 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 39.82it/s, est. speed input: 19080.06 toks/s, output: 37.27 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 39.80it/s, est. speed input: 19127.52 toks/s, output: 37.36 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 39.83it/s, est. speed input: 19173.94 toks/s, output: 37.45 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:02<00:00, 39.81it/s, est. speed input: 19215.27 toks/s, output: 37.53 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 39.76it/s, est. speed input: 19251.16 toks/s, output: 37.60 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 39.82it/s, est. speed input: 19290.23 toks/s, output: 37.68 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 39.78it/s, est. speed input: 19322.67 toks/s, output: 37.74 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 39.83it/s, est. speed input: 19356.84 toks/s, output: 37.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.83it/s, est. speed input: 19382.86 toks/s, output: 37.86 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.85it/s, est. speed input: 19382.86 toks/s, output: 37.86 toks/s]
[rank0]:[W126 11:33:47.622440410 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:33:49
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:33:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1293376) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1293376) WARNING 01-26 11:34:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.64 requests/s, 32428.30 total tokens/s, 31.64 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 11:33:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:33:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:33:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:33:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:33:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:33:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:33:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:33:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:34:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:34:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:34:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:34:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:34:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:34:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1293376) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1293376) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.84it/s]
(EngineCore_DP0 pid=1293376) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1293376) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1293376) 
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1293376) [2026-01-26 11:34:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1293376) 2026-01-26 11:34:24,203 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1293376) 2026-01-26 11:34:24,227 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1293376) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.82it/s]
(EngineCore_DP0 pid=1293376) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.60it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  15%|█▍        | 19/128 [00:00<00:00, 186.16it/s]
Adding requests:  45%|████▍     | 57/128 [00:00<00:00, 297.13it/s]
Adding requests:  73%|███████▎  | 94/128 [00:00<00:00, 327.39it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 322.69it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:01, 68.02it/s, est. speed input: 69663.40 toks/s, output: 68.02 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:02, 43.22it/s, est. speed input: 46825.41 toks/s, output: 45.72 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:02, 39.40it/s, est. speed input: 43067.84 toks/s, output: 42.06 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:02, 37.47it/s, est. speed input: 41141.98 toks/s, output: 40.18 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:00<00:02, 36.47it/s, est. speed input: 40132.49 toks/s, output: 39.19 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:02, 35.83it/s, est. speed input: 39439.77 toks/s, output: 38.51 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:00<00:02, 35.23it/s, est. speed input: 38846.49 toks/s, output: 37.93 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 34.66it/s, est. speed input: 38322.74 toks/s, output: 37.42 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 34.53it/s, est. speed input: 38000.38 toks/s, output: 37.11 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 34.44it/s, est. speed input: 37735.34 toks/s, output: 36.85 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 34.35it/s, est. speed input: 37504.68 toks/s, output: 36.62 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:02, 34.38it/s, est. speed input: 37336.75 toks/s, output: 36.46 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:01<00:01, 34.32it/s, est. speed input: 37172.71 toks/s, output: 36.30 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:01<00:01, 34.26it/s, est. speed input: 37023.99 toks/s, output: 36.16 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:01<00:01, 34.24it/s, est. speed input: 36899.06 toks/s, output: 36.03 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:01, 34.07it/s, est. speed input: 36756.56 toks/s, output: 35.89 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 34.03it/s, est. speed input: 36644.72 toks/s, output: 35.79 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 34.07it/s, est. speed input: 36557.32 toks/s, output: 35.70 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 34.12it/s, est. speed input: 36484.23 toks/s, output: 35.63 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 34.15it/s, est. speed input: 36415.08 toks/s, output: 35.56 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:02<00:01, 34.15it/s, est. speed input: 36349.65 toks/s, output: 35.50 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 34.12it/s, est. speed input: 36285.57 toks/s, output: 35.43 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:02<00:00, 34.13it/s, est. speed input: 36230.96 toks/s, output: 35.38 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:02<00:00, 34.05it/s, est. speed input: 36168.56 toks/s, output: 35.32 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:03<00:00, 34.06it/s, est. speed input: 36119.85 toks/s, output: 35.27 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 34.05it/s, est. speed input: 36072.43 toks/s, output: 35.23 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 34.09it/s, est. speed input: 36035.21 toks/s, output: 35.19 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 34.10it/s, est. speed input: 35997.12 toks/s, output: 35.15 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:03<00:00, 34.13it/s, est. speed input: 35965.05 toks/s, output: 35.12 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.15it/s, est. speed input: 35934.77 toks/s, output: 35.09 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.15it/s, est. speed input: 35934.77 toks/s, output: 35.09 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.09it/s, est. speed input: 35934.77 toks/s, output: 35.09 toks/s]
[rank0]:[W126 11:34:30.557277335 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 11:34:32
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:34:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1294490) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1294490) WARNING 01-26 11:34:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.68 requests/s, 36571.99 total tokens/s, 35.68 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 11:34:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:34:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:34:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:34:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:34:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:34:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:34:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:34:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:34:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:34:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:34:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:34:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:34:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:34:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1294490) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1294490) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.85it/s]
(EngineCore_DP0 pid=1294490) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1294490) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1294490) 
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1294490) [2026-01-26 11:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1294490) 2026-01-26 11:35:08,877 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1294490) 2026-01-26 11:35:08,921 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1294490) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 16.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 15.49it/s]
(EngineCore_DP0 pid=1294490) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  6.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.82it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 20/256 [00:00<00:01, 199.84it/s]
Adding requests:  24%|██▍       | 61/256 [00:00<00:00, 320.22it/s]
Adding requests:  38%|███▊      | 98/256 [00:00<00:00, 339.32it/s]
Adding requests:  53%|█████▎    | 136/256 [00:00<00:00, 355.09it/s]
Adding requests:  69%|██████▉   | 176/256 [00:00<00:00, 368.66it/s]
Adding requests:  84%|████████▍ | 216/256 [00:00<00:00, 378.19it/s]
Adding requests: 100%|█████████▉| 255/256 [00:00<00:00, 380.47it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 360.03it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 180.91it/s, est. speed input: 185292.43 toks/s, output: 180.92 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:00<00:03, 58.96it/s, est. speed input: 67368.22 toks/s, output: 65.79 toks/s]   
Processed prompts:  19%|█▉        | 49/256 [00:00<00:04, 49.76it/s, est. speed input: 57927.10 toks/s, output: 56.57 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:01<00:04, 44.09it/s, est. speed input: 52856.48 toks/s, output: 51.62 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:01<00:04, 42.36it/s, est. speed input: 50950.75 toks/s, output: 49.76 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:01<00:04, 43.21it/s, est. speed input: 50710.24 toks/s, output: 49.52 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:01<00:04, 39.72it/s, est. speed input: 48728.55 toks/s, output: 47.59 toks/s]
Processed prompts:  30%|███       | 77/256 [00:01<00:04, 41.19it/s, est. speed input: 48650.36 toks/s, output: 47.51 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:04, 37.79it/s, est. speed input: 47066.95 toks/s, output: 45.96 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:04, 37.42it/s, est. speed input: 46487.36 toks/s, output: 45.40 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:04, 37.20it/s, est. speed input: 45990.91 toks/s, output: 44.91 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:04, 37.12it/s, est. speed input: 45569.26 toks/s, output: 44.50 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:04, 37.12it/s, est. speed input: 45202.86 toks/s, output: 44.14 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:02<00:04, 37.14it/s, est. speed input: 44873.88 toks/s, output: 43.82 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:04, 37.19it/s, est. speed input: 44581.35 toks/s, output: 43.54 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:02<00:03, 37.17it/s, est. speed input: 44302.55 toks/s, output: 43.26 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:02<00:03, 37.09it/s, est. speed input: 44036.42 toks/s, output: 43.00 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:03, 36.98it/s, est. speed input: 43782.53 toks/s, output: 42.76 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:02<00:03, 36.88it/s, est. speed input: 43543.59 toks/s, output: 42.52 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:02<00:03, 36.78it/s, est. speed input: 43319.24 toks/s, output: 42.30 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:03<00:03, 36.74it/s, est. speed input: 43114.17 toks/s, output: 42.10 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:03<00:03, 36.83it/s, est. speed input: 42939.10 toks/s, output: 41.93 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:03<00:03, 36.90it/s, est. speed input: 42776.41 toks/s, output: 41.77 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:03<00:03, 36.98it/s, est. speed input: 42628.09 toks/s, output: 41.63 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:03<00:02, 37.05it/s, est. speed input: 42489.57 toks/s, output: 41.49 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:03<00:02, 37.05it/s, est. speed input: 42354.10 toks/s, output: 41.36 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:03<00:02, 37.05it/s, est. speed input: 42225.88 toks/s, output: 41.24 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:03<00:02, 36.88it/s, est. speed input: 42087.42 toks/s, output: 41.10 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:03<00:02, 36.79it/s, est. speed input: 41959.96 toks/s, output: 40.98 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:04<00:02, 36.63it/s, est. speed input: 41828.89 toks/s, output: 40.85 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:04<00:02, 36.75it/s, est. speed input: 41727.32 toks/s, output: 40.75 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:04<00:02, 36.89it/s, est. speed input: 41636.18 toks/s, output: 40.66 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:04<00:02, 36.87it/s, est. speed input: 41539.14 toks/s, output: 40.57 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:04<00:02, 36.93it/s, est. speed input: 41453.81 toks/s, output: 40.48 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:04<00:01, 36.98it/s, est. speed input: 41372.81 toks/s, output: 40.40 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:04<00:01, 36.97it/s, est. speed input: 41291.37 toks/s, output: 40.32 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:04<00:01, 36.86it/s, est. speed input: 41204.66 toks/s, output: 40.24 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:04<00:01, 36.82it/s, est. speed input: 41125.22 toks/s, output: 40.16 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:05<00:01, 38.43it/s, est. speed input: 41156.96 toks/s, output: 40.19 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:05<00:01, 37.91it/s, est. speed input: 41078.62 toks/s, output: 40.12 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:05<00:01, 37.68it/s, est. speed input: 41015.51 toks/s, output: 40.05 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:05<00:01, 37.48it/s, est. speed input: 40953.26 toks/s, output: 39.99 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:05<00:00, 37.41it/s, est. speed input: 40898.22 toks/s, output: 39.94 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:05<00:00, 37.29it/s, est. speed input: 40840.38 toks/s, output: 39.88 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:05<00:00, 37.13it/s, est. speed input: 40779.45 toks/s, output: 39.82 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:05<00:00, 37.08it/s, est. speed input: 40724.82 toks/s, output: 39.77 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:05<00:00, 36.87it/s, est. speed input: 40660.60 toks/s, output: 39.71 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:06<00:00, 36.88it/s, est. speed input: 40609.45 toks/s, output: 39.66 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:06<00:00, 36.88it/s, est. speed input: 40559.47 toks/s, output: 39.61 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:06<00:00, 36.87it/s, est. speed input: 40510.25 toks/s, output: 39.56 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:06<00:00, 36.93it/s, est. speed input: 40466.85 toks/s, output: 39.52 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 36.93it/s, est. speed input: 40566.11 toks/s, output: 39.62 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 39.61it/s, est. speed input: 40566.11 toks/s, output: 39.62 toks/s]
[rank0]:[W126 11:35:18.296562959 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 11:35:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:35:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1295654) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1295654) WARNING 01-26 11:35:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.35 requests/s, 38278.80 total tokens/s, 37.35 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 11:35:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:35:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:35:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:35:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:35:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:35:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:35:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:35:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:35:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:35:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:35:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:35:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:35:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:35:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:35:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:35:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:35:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1295654) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1295654) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.85it/s]
(EngineCore_DP0 pid=1295654) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1295654) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1295654) 
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1295654) [2026-01-26 11:35:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1295654) 2026-01-26 11:35:56,398 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1295654) 2026-01-26 11:35:56,421 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1295654) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  2.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.07it/s]
(EngineCore_DP0 pid=1295654) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 18.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 19.00it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 21/512 [00:00<00:02, 208.94it/s]
Adding requests:  12%|█▏        | 62/512 [00:00<00:01, 324.10it/s]
Adding requests:  19%|█▉        | 98/512 [00:00<00:01, 337.99it/s]
Adding requests:  27%|██▋       | 136/512 [00:00<00:01, 353.04it/s]
Adding requests:  34%|███▍      | 175/512 [00:00<00:00, 364.57it/s]
Adding requests:  42%|████▏     | 215/512 [00:00<00:00, 374.35it/s]
Adding requests:  49%|████▉     | 253/512 [00:00<00:00, 374.48it/s]
Adding requests:  57%|█████▋    | 291/512 [00:00<00:00, 375.73it/s]
Adding requests:  65%|██████▍   | 331/512 [00:00<00:00, 381.40it/s]
Adding requests:  72%|███████▏  | 371/512 [00:01<00:00, 386.21it/s]
Adding requests:  80%|████████  | 411/512 [00:01<00:00, 389.52it/s]
Adding requests:  88%|████████▊ | 450/512 [00:01<00:00, 385.13it/s]
Adding requests:  96%|█████████▋| 493/512 [00:01<00:00, 396.28it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 374.37it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:00<00:01, 272.57it/s, est. speed input: 279145.94 toks/s, output: 272.58 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:00<00:05, 72.41it/s, est. speed input: 86350.98 toks/s, output: 84.32 toks/s]   
Processed prompts:  18%|█▊        | 92/512 [00:01<00:06, 62.74it/s, est. speed input: 75848.89 toks/s, output: 74.07 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:01<00:07, 52.76it/s, est. speed input: 67203.74 toks/s, output: 65.63 toks/s]
Processed prompts:  21%|██▏       | 109/512 [00:01<00:07, 54.52it/s, est. speed input: 67200.59 toks/s, output: 65.63 toks/s]
Processed prompts:  23%|██▎       | 116/512 [00:01<00:08, 48.24it/s, est. speed input: 63285.42 toks/s, output: 61.80 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:02<00:09, 42.50it/s, est. speed input: 59770.75 toks/s, output: 58.37 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:02<00:08, 43.30it/s, est. speed input: 59221.09 toks/s, output: 57.83 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:02<00:08, 44.16it/s, est. speed input: 58751.54 toks/s, output: 57.37 toks/s]
Processed prompts:  27%|██▋       | 137/512 [00:02<00:08, 45.05it/s, est. speed input: 58352.47 toks/s, output: 56.98 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:02<00:10, 36.84it/s, est. speed input: 55598.24 toks/s, output: 54.29 toks/s]
Processed prompts:  29%|██▊       | 147/512 [00:02<00:09, 39.04it/s, est. speed input: 55306.39 toks/s, output: 54.01 toks/s]
Processed prompts:  30%|██▉       | 152/512 [00:02<00:08, 40.80it/s, est. speed input: 55009.18 toks/s, output: 53.72 toks/s]
Processed prompts:  31%|███       | 157/512 [00:02<00:08, 42.25it/s, est. speed input: 54739.65 toks/s, output: 53.46 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:03<00:10, 34.44it/s, est. speed input: 52672.44 toks/s, output: 51.44 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:03<00:09, 35.19it/s, est. speed input: 52215.17 toks/s, output: 50.99 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:03<00:09, 35.98it/s, est. speed input: 51816.50 toks/s, output: 50.60 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:03<00:09, 36.57it/s, est. speed input: 51434.51 toks/s, output: 50.23 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:03<00:09, 36.92it/s, est. speed input: 51059.66 toks/s, output: 49.86 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:03<00:08, 37.06it/s, est. speed input: 50688.98 toks/s, output: 49.50 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:03<00:08, 37.20it/s, est. speed input: 50344.32 toks/s, output: 49.16 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:03<00:08, 37.35it/s, est. speed input: 50024.36 toks/s, output: 48.85 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:03<00:08, 37.31it/s, est. speed input: 49703.89 toks/s, output: 48.54 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:04<00:08, 37.36it/s, est. speed input: 49409.81 toks/s, output: 48.25 toks/s]
Processed prompts:  40%|████      | 206/512 [00:04<00:07, 38.31it/s, est. speed input: 48987.55 toks/s, output: 47.84 toks/s]
Processed prompts:  41%|████      | 210/512 [00:04<00:07, 38.27it/s, est. speed input: 48751.49 toks/s, output: 47.61 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:04<00:07, 38.14it/s, est. speed input: 48515.76 toks/s, output: 47.38 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:04<00:07, 38.00it/s, est. speed input: 48285.73 toks/s, output: 47.15 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:04<00:07, 37.94it/s, est. speed input: 48070.76 toks/s, output: 46.94 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:04<00:07, 37.77it/s, est. speed input: 47853.70 toks/s, output: 46.73 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:04<00:07, 37.64it/s, est. speed input: 47644.48 toks/s, output: 46.53 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:05<00:07, 37.61it/s, est. speed input: 47450.34 toks/s, output: 46.34 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:05<00:07, 37.54it/s, est. speed input: 47259.65 toks/s, output: 46.15 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:05<00:07, 37.66it/s, est. speed input: 47091.39 toks/s, output: 45.99 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:05<00:07, 37.78it/s, est. speed input: 46932.17 toks/s, output: 45.83 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:05<00:06, 37.82it/s, est. speed input: 46775.89 toks/s, output: 45.68 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:05<00:06, 37.75it/s, est. speed input: 46617.85 toks/s, output: 45.52 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:05<00:06, 37.78it/s, est. speed input: 46471.57 toks/s, output: 45.38 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:05<00:06, 37.75it/s, est. speed input: 46327.19 toks/s, output: 45.24 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:05<00:06, 37.64it/s, est. speed input: 46181.20 toks/s, output: 45.10 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:06<00:06, 37.50it/s, est. speed input: 46035.72 toks/s, output: 44.96 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:06<00:06, 37.60it/s, est. speed input: 45909.96 toks/s, output: 44.83 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:06<00:06, 37.69it/s, est. speed input: 45788.96 toks/s, output: 44.72 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:06<00:06, 37.73it/s, est. speed input: 45671.42 toks/s, output: 44.60 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:06<00:05, 37.82it/s, est. speed input: 45561.11 toks/s, output: 44.49 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:06<00:05, 37.80it/s, est. speed input: 45449.48 toks/s, output: 44.38 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:06<00:05, 37.78it/s, est. speed input: 45340.69 toks/s, output: 44.28 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:06<00:05, 37.77it/s, est. speed input: 45235.52 toks/s, output: 44.18 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:06<00:05, 37.71it/s, est. speed input: 45130.17 toks/s, output: 44.07 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:07<00:05, 38.41it/s, est. speed input: 44987.71 toks/s, output: 43.93 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:07<00:05, 38.19it/s, est. speed input: 44890.42 toks/s, output: 43.84 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:07<00:05, 38.12it/s, est. speed input: 44802.52 toks/s, output: 43.75 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:07<00:04, 38.03it/s, est. speed input: 44715.14 toks/s, output: 43.67 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:07<00:04, 37.96it/s, est. speed input: 44629.75 toks/s, output: 43.58 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:07<00:04, 37.94it/s, est. speed input: 44548.52 toks/s, output: 43.50 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:07<00:04, 37.95it/s, est. speed input: 44470.71 toks/s, output: 43.43 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:07<00:04, 37.71it/s, est. speed input: 44381.88 toks/s, output: 43.34 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:07<00:04, 37.68it/s, est. speed input: 44302.82 toks/s, output: 43.26 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:08<00:04, 37.76it/s, est. speed input: 44231.39 toks/s, output: 43.19 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:08<00:04, 37.57it/s, est. speed input: 44149.18 toks/s, output: 43.11 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:08<00:04, 37.60it/s, est. speed input: 44077.11 toks/s, output: 43.04 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:08<00:04, 37.76it/s, est. speed input: 44013.85 toks/s, output: 42.98 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:08<00:03, 37.75it/s, est. speed input: 43946.15 toks/s, output: 42.92 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:08<00:03, 37.68it/s, est. speed input: 43877.13 toks/s, output: 42.85 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:08<00:03, 37.74it/s, est. speed input: 43814.96 toks/s, output: 42.79 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:08<00:03, 37.68it/s, est. speed input: 43749.46 toks/s, output: 42.72 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:08<00:03, 37.64it/s, est. speed input: 43685.67 toks/s, output: 42.66 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:08<00:03, 37.63it/s, est. speed input: 43624.56 toks/s, output: 42.60 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:09<00:03, 37.61it/s, est. speed input: 43563.78 toks/s, output: 42.54 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:09<00:03, 37.63it/s, est. speed input: 43506.05 toks/s, output: 42.49 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:09<00:03, 37.68it/s, est. speed input: 43451.62 toks/s, output: 42.43 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:09<00:03, 37.79it/s, est. speed input: 43401.32 toks/s, output: 42.38 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:09<00:02, 37.76it/s, est. speed input: 43347.66 toks/s, output: 42.33 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:09<00:02, 37.74it/s, est. speed input: 43295.10 toks/s, output: 42.28 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:09<00:02, 37.72it/s, est. speed input: 43243.50 toks/s, output: 42.23 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:09<00:02, 37.63it/s, est. speed input: 43190.05 toks/s, output: 42.18 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:09<00:02, 37.59it/s, est. speed input: 43138.10 toks/s, output: 42.13 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:10<00:02, 37.57it/s, est. speed input: 43088.22 toks/s, output: 42.08 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:10<00:02, 37.55it/s, est. speed input: 43038.92 toks/s, output: 42.03 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:10<00:02, 37.59it/s, est. speed input: 42992.59 toks/s, output: 41.98 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:10<00:01, 38.51it/s, est. speed input: 42946.33 toks/s, output: 41.94 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:10<00:01, 38.34it/s, est. speed input: 42903.96 toks/s, output: 41.90 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:10<00:01, 38.13it/s, est. speed input: 42859.52 toks/s, output: 41.85 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:10<00:01, 37.97it/s, est. speed input: 42815.79 toks/s, output: 41.81 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:10<00:01, 37.85it/s, est. speed input: 42772.87 toks/s, output: 41.77 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:10<00:01, 37.76it/s, est. speed input: 42731.00 toks/s, output: 41.73 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:11<00:01, 37.67it/s, est. speed input: 42688.56 toks/s, output: 41.69 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:11<00:01, 37.67it/s, est. speed input: 42649.49 toks/s, output: 41.65 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:11<00:01, 37.64it/s, est. speed input: 42610.25 toks/s, output: 41.61 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:11<00:01, 37.63it/s, est. speed input: 42571.84 toks/s, output: 41.57 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:11<00:00, 37.68it/s, est. speed input: 42536.40 toks/s, output: 41.54 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:11<00:00, 37.70it/s, est. speed input: 42500.85 toks/s, output: 41.50 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:11<00:00, 37.63it/s, est. speed input: 42463.22 toks/s, output: 41.47 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:11<00:00, 37.60it/s, est. speed input: 42426.90 toks/s, output: 41.43 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:11<00:00, 37.64it/s, est. speed input: 42393.19 toks/s, output: 41.40 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:12<00:00, 37.59it/s, est. speed input: 42357.54 toks/s, output: 41.36 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:12<00:00, 37.61it/s, est. speed input: 42324.25 toks/s, output: 41.33 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:12<00:00, 37.66it/s, est. speed input: 42292.83 toks/s, output: 41.30 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 37.66it/s, est. speed input: 42486.12 toks/s, output: 41.49 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 41.49it/s, est. speed input: 42486.12 toks/s, output: 41.49 toks/s]
[rank0]:[W126 11:36:13.101652464 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 11:36:15
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:36:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1296949) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1296949) WARNING 01-26 11:36:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 38.36 requests/s, 39318.67 total tokens/s, 38.36 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 11:36:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:36:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:36:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:36:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:36:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:36:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:36:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:36:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:36:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:36:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:36:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:36:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:36:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:36:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:36:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:36:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:36:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1296949) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1296949) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.85it/s]
(EngineCore_DP0 pid=1296949) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1296949) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1296949) 
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1296949) [2026-01-26 11:36:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1296949) 2026-01-26 11:36:55,079 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1296949) 2026-01-26 11:36:55,122 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1296949) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:03,  1.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  6.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.81it/s]
(EngineCore_DP0 pid=1296949) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 18.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 19.64it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 28/1024 [00:00<00:03, 278.97it/s]
Adding requests:   7%|▋         | 68/1024 [00:00<00:02, 349.10it/s]
Adding requests:  10%|█         | 105/1024 [00:00<00:02, 357.04it/s]
Adding requests:  14%|█▍        | 142/1024 [00:00<00:02, 360.68it/s]
Adding requests:  18%|█▊        | 182/1024 [00:00<00:02, 371.97it/s]
Adding requests:  22%|██▏       | 223/1024 [00:00<00:02, 384.65it/s]
Adding requests:  26%|██▌       | 262/1024 [00:00<00:01, 381.24it/s]
Adding requests:  29%|██▉       | 302/1024 [00:00<00:01, 386.11it/s]
Adding requests:  33%|███▎      | 343/1024 [00:00<00:01, 390.00it/s]
Adding requests:  38%|███▊      | 384/1024 [00:01<00:01, 394.40it/s]
Adding requests:  42%|████▏     | 425/1024 [00:01<00:01, 397.14it/s]
Adding requests:  45%|████▌     | 465/1024 [00:01<00:01, 392.78it/s]
Adding requests:  50%|████▉     | 508/1024 [00:01<00:01, 403.10it/s]
Adding requests:  54%|█████▎    | 549/1024 [00:01<00:01, 400.44it/s]
Adding requests:  58%|█████▊    | 590/1024 [00:01<00:01, 395.77it/s]
Adding requests:  62%|██████▏   | 630/1024 [00:01<00:01, 391.48it/s]
Adding requests:  65%|██████▌   | 670/1024 [00:01<00:00, 379.45it/s]
Adding requests:  69%|██████▉   | 710/1024 [00:01<00:00, 384.22it/s]
Adding requests:  73%|███████▎  | 749/1024 [00:01<00:00, 378.51it/s]
Adding requests:  77%|███████▋  | 789/1024 [00:02<00:00, 383.04it/s]
Adding requests:  81%|████████  | 829/1024 [00:02<00:00, 387.25it/s]
Adding requests:  85%|████████▍ | 868/1024 [00:02<00:00, 387.81it/s]
Adding requests:  89%|████████▉ | 909/1024 [00:02<00:00, 392.70it/s]
Adding requests:  93%|█████████▎| 949/1024 [00:02<00:00, 383.95it/s]
Adding requests:  97%|█████████▋| 989/1024 [00:02<00:00, 386.50it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 384.04it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:00<00:01, 571.67it/s, est. speed input: 585554.06 toks/s, output: 571.71 toks/s]
Processed prompts:  15%|█▌        | 156/1024 [00:01<00:10, 80.13it/s, est. speed input: 97921.84 toks/s, output: 95.63 toks/s]  
Processed prompts:  18%|█▊        | 182/1024 [00:02<00:12, 66.43it/s, est. speed input: 82803.03 toks/s, output: 80.86 toks/s]
Processed prompts:  19%|█▉        | 198/1024 [00:02<00:13, 59.16it/s, est. speed input: 75944.05 toks/s, output: 74.16 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:03<00:15, 51.76it/s, est. speed input: 70179.10 toks/s, output: 68.53 toks/s]
Processed prompts:  21%|██▏       | 219/1024 [00:03<00:15, 50.51it/s, est. speed input: 68599.59 toks/s, output: 66.99 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:03<00:16, 47.34it/s, est. speed input: 66561.25 toks/s, output: 65.00 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:03<00:17, 45.27it/s, est. speed input: 64956.99 toks/s, output: 63.43 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:03<00:17, 43.68it/s, est. speed input: 63589.96 toks/s, output: 62.10 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:04<00:18, 42.50it/s, est. speed input: 62397.73 toks/s, output: 60.93 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:04<00:18, 41.52it/s, est. speed input: 61310.12 toks/s, output: 59.87 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:04<00:18, 40.65it/s, est. speed input: 60291.45 toks/s, output: 58.88 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:04<00:18, 39.83it/s, est. speed input: 59323.19 toks/s, output: 57.93 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:04<00:18, 39.41it/s, est. speed input: 58477.62 toks/s, output: 57.11 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:05<00:18, 39.24it/s, est. speed input: 57725.94 toks/s, output: 56.37 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:05<00:18, 39.08it/s, est. speed input: 57026.72 toks/s, output: 55.69 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:05<00:17, 40.01it/s, est. speed input: 56565.56 toks/s, output: 55.24 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:05<00:18, 39.43it/s, est. speed input: 55924.61 toks/s, output: 54.61 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:05<00:17, 39.19it/s, est. speed input: 55356.71 toks/s, output: 54.06 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:06<00:17, 39.07it/s, est. speed input: 54832.48 toks/s, output: 53.55 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:06<00:17, 38.89it/s, est. speed input: 54328.90 toks/s, output: 53.06 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:06<00:17, 38.63it/s, est. speed input: 53836.88 toks/s, output: 52.57 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:06<00:17, 38.49it/s, est. speed input: 53381.50 toks/s, output: 52.13 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:06<00:17, 38.47it/s, est. speed input: 52963.88 toks/s, output: 51.72 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:07<00:16, 38.49it/s, est. speed input: 52574.91 toks/s, output: 51.34 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:07<00:16, 38.56it/s, est. speed input: 52214.92 toks/s, output: 50.99 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:07<00:16, 38.38it/s, est. speed input: 51846.76 toks/s, output: 50.63 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:07<00:16, 38.35it/s, est. speed input: 51509.28 toks/s, output: 50.30 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:08<00:16, 38.42it/s, est. speed input: 51200.14 toks/s, output: 50.00 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:08<00:15, 38.43it/s, est. speed input: 50901.96 toks/s, output: 49.71 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:08<00:15, 38.46it/s, est. speed input: 50620.67 toks/s, output: 49.43 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:08<00:15, 38.35it/s, est. speed input: 50339.54 toks/s, output: 49.16 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:08<00:14, 39.65it/s, est. speed input: 50208.18 toks/s, output: 49.03 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:09<00:14, 39.26it/s, est. speed input: 49956.71 toks/s, output: 48.79 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:09<00:14, 38.96it/s, est. speed input: 49714.50 toks/s, output: 48.55 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:09<00:14, 38.77it/s, est. speed input: 49484.25 toks/s, output: 48.32 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:09<00:14, 38.50it/s, est. speed input: 49251.19 toks/s, output: 48.10 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:09<00:14, 38.53it/s, est. speed input: 49047.21 toks/s, output: 47.90 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:10<00:14, 38.58it/s, est. speed input: 48854.47 toks/s, output: 47.71 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:10<00:13, 38.49it/s, est. speed input: 48658.53 toks/s, output: 47.52 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:10<00:13, 38.36it/s, est. speed input: 48465.60 toks/s, output: 47.33 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:10<00:13, 38.30it/s, est. speed input: 48282.02 toks/s, output: 47.15 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:10<00:13, 38.27it/s, est. speed input: 48106.65 toks/s, output: 46.98 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:11<00:13, 38.36it/s, est. speed input: 47946.34 toks/s, output: 46.82 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:11<00:12, 38.39it/s, est. speed input: 47789.25 toks/s, output: 46.67 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:11<00:12, 38.24it/s, est. speed input: 47625.71 toks/s, output: 46.51 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:11<00:12, 38.34it/s, est. speed input: 47482.26 toks/s, output: 46.37 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:11<00:12, 38.27it/s, est. speed input: 47334.55 toks/s, output: 46.23 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:12<00:12, 38.30it/s, est. speed input: 47196.79 toks/s, output: 46.09 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:12<00:11, 38.31it/s, est. speed input: 47063.23 toks/s, output: 45.96 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:12<00:11, 38.26it/s, est. speed input: 46930.12 toks/s, output: 45.83 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:12<00:11, 38.29it/s, est. speed input: 46805.57 toks/s, output: 45.71 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:13<00:11, 38.24it/s, est. speed input: 46680.78 toks/s, output: 45.59 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:13<00:11, 38.28it/s, est. speed input: 46564.24 toks/s, output: 45.47 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:13<00:10, 38.23it/s, est. speed input: 46446.34 toks/s, output: 45.36 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:13<00:10, 38.33it/s, est. speed input: 46340.60 toks/s, output: 45.25 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:13<00:10, 38.24it/s, est. speed input: 46228.44 toks/s, output: 45.14 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:14<00:10, 38.35it/s, est. speed input: 46129.89 toks/s, output: 45.05 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:14<00:09, 38.36it/s, est. speed input: 46030.15 toks/s, output: 44.95 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:14<00:09, 38.40it/s, est. speed input: 45935.49 toks/s, output: 44.86 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:14<00:09, 38.41it/s, est. speed input: 45842.48 toks/s, output: 44.77 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:14<00:09, 38.33it/s, est. speed input: 45747.15 toks/s, output: 44.67 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:15<00:09, 38.46it/s, est. speed input: 45664.28 toks/s, output: 44.59 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:15<00:08, 38.45it/s, est. speed input: 45578.60 toks/s, output: 44.51 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:15<00:08, 38.50it/s, est. speed input: 45498.27 toks/s, output: 44.43 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:15<00:08, 38.47it/s, est. speed input: 45416.22 toks/s, output: 44.35 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:15<00:08, 38.35it/s, est. speed input: 45331.59 toks/s, output: 44.27 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:16<00:08, 38.43it/s, est. speed input: 45257.34 toks/s, output: 44.20 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:16<00:07, 38.41it/s, est. speed input: 45181.06 toks/s, output: 44.12 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:16<00:07, 38.49it/s, est. speed input: 45111.72 toks/s, output: 44.05 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:16<00:07, 38.41it/s, est. speed input: 45037.26 toks/s, output: 43.98 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:16<00:07, 38.30it/s, est. speed input: 44962.18 toks/s, output: 43.91 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:17<00:07, 38.38it/s, est. speed input: 44896.08 toks/s, output: 43.84 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:17<00:06, 38.35it/s, est. speed input: 44827.92 toks/s, output: 43.78 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:17<00:06, 38.53it/s, est. speed input: 44770.19 toks/s, output: 43.72 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:17<00:06, 38.44it/s, est. speed input: 44704.17 toks/s, output: 43.66 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:18<00:06, 39.63it/s, est. speed input: 44694.19 toks/s, output: 43.65 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:18<00:05, 39.33it/s, est. speed input: 44636.01 toks/s, output: 43.59 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:18<00:05, 39.11it/s, est. speed input: 44578.59 toks/s, output: 43.53 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:18<00:05, 38.93it/s, est. speed input: 44521.19 toks/s, output: 43.48 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:18<00:05, 38.81it/s, est. speed input: 44465.51 toks/s, output: 43.42 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:19<00:05, 38.67it/s, est. speed input: 44408.57 toks/s, output: 43.37 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:19<00:04, 38.58it/s, est. speed input: 44353.30 toks/s, output: 43.31 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:19<00:04, 38.47it/s, est. speed input: 44296.95 toks/s, output: 43.26 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:19<00:04, 38.49it/s, est. speed input: 44246.01 toks/s, output: 43.21 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:19<00:04, 38.35it/s, est. speed input: 44189.81 toks/s, output: 43.15 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:20<00:04, 38.42it/s, est. speed input: 44141.44 toks/s, output: 43.11 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:20<00:03, 38.48it/s, est. speed input: 44094.77 toks/s, output: 43.06 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:20<00:03, 38.45it/s, est. speed input: 44045.94 toks/s, output: 43.01 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:20<00:03, 38.49it/s, est. speed input: 44000.41 toks/s, output: 42.97 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:20<00:03, 38.39it/s, est. speed input: 43951.03 toks/s, output: 42.92 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:21<00:03, 38.36it/s, est. speed input: 43904.28 toks/s, output: 42.88 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:21<00:02, 38.35it/s, est. speed input: 43858.87 toks/s, output: 42.83 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:21<00:02, 38.41it/s, est. speed input: 43816.61 toks/s, output: 42.79 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:21<00:02, 38.39it/s, est. speed input: 43772.78 toks/s, output: 42.75 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:21<00:02, 38.28it/s, est. speed input: 43726.54 toks/s, output: 42.70 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:22<00:02, 38.36it/s, est. speed input: 43686.66 toks/s, output: 42.66 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:22<00:01, 38.37it/s, est. speed input: 43645.88 toks/s, output: 42.62 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:22<00:01, 38.41it/s, est. speed input: 43607.00 toks/s, output: 42.58 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:22<00:01, 38.45it/s, est. speed input: 43569.30 toks/s, output: 42.55 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:23<00:01, 38.34it/s, est. speed input: 43527.68 toks/s, output: 42.51 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:23<00:00, 38.40it/s, est. speed input: 43491.29 toks/s, output: 42.47 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:23<00:00, 38.36it/s, est. speed input: 43452.83 toks/s, output: 42.43 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:23<00:00, 38.37it/s, est. speed input: 43416.38 toks/s, output: 42.40 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:23<00:00, 38.30it/s, est. speed input: 43377.99 toks/s, output: 42.36 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:24<00:00, 39.74it/s, est. speed input: 43387.44 toks/s, output: 42.37 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:24<00:00, 39.74it/s, est. speed input: 43642.40 toks/s, output: 42.62 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:24<00:00, 42.62it/s, est. speed input: 43642.40 toks/s, output: 42.62 toks/s]
[rank0]:[W126 11:37:24.858716353 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 11:37:27
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:37:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1298480) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1298480) WARNING 01-26 11:38:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.53 requests/s, 40520.23 total tokens/s, 39.53 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 11:37:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:37:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:37:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:37:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:37:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:37:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:37:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:37:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:37:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:37:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:37:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:37:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:37:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:37:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:37:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:37:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:37:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1298480) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1298480) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1298480) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1298480) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1298480) 
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1298480) [2026-01-26 11:37:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1298480) [rank0]:W0126 11:38:08.078000 1298480 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1298480) [rank0]:W0126 11:38:08.156000 1298480 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1298480) [rank0]:W0126 11:38:09.106000 1298480 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1298480) [rank0]:W0126 11:38:09.233000 1298480 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1298480) 2026-01-26 11:38:13,189 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1298480) 2026-01-26 11:38:13,216 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1298480) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 14.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 10.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.77it/s]
(EngineCore_DP0 pid=1298480) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 18.84it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 19.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 19.51it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/2048 [00:00<00:08, 237.14it/s]
Adding requests:   3%|▎         | 64/2048 [00:00<00:06, 329.88it/s]
Adding requests:   5%|▍         | 100/2048 [00:00<00:05, 341.25it/s]
Adding requests:   7%|▋         | 138/2048 [00:00<00:05, 354.60it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:05, 366.83it/s]
Adding requests:  11%|█         | 218/2048 [00:00<00:04, 381.07it/s]
Adding requests:  13%|█▎        | 257/2048 [00:00<00:04, 379.42it/s]
Adding requests:  15%|█▍        | 297/2048 [00:00<00:04, 385.65it/s]
Adding requests:  17%|█▋        | 338/2048 [00:00<00:04, 390.59it/s]
Adding requests:  18%|█▊        | 378/2048 [00:01<00:04, 390.60it/s]
Adding requests:  21%|██        | 420/2048 [00:01<00:04, 398.16it/s]
Adding requests:  22%|██▏       | 460/2048 [00:01<00:04, 393.73it/s]
Adding requests:  25%|██▍       | 503/2048 [00:01<00:03, 402.45it/s]
Adding requests:  27%|██▋       | 546/2048 [00:01<00:03, 407.48it/s]
Adding requests:  29%|██▊       | 587/2048 [00:01<00:03, 402.43it/s]
Adding requests:  31%|███       | 628/2048 [00:01<00:03, 396.91it/s]
Adding requests:  33%|███▎      | 668/2048 [00:01<00:03, 385.21it/s]
Adding requests:  35%|███▍      | 709/2048 [00:01<00:03, 390.81it/s]
Adding requests:  37%|███▋      | 749/2048 [00:01<00:03, 379.05it/s]
Adding requests:  39%|███▊      | 789/2048 [00:02<00:03, 382.47it/s]
Adding requests:  41%|████      | 830/2048 [00:02<00:03, 389.18it/s]
Adding requests:  42%|████▏     | 870/2048 [00:02<00:03, 390.44it/s]
Adding requests:  44%|████▍     | 910/2048 [00:02<00:02, 392.18it/s]
Adding requests:  46%|████▋     | 950/2048 [00:02<00:02, 384.94it/s]
Adding requests:  48%|████▊     | 990/2048 [00:02<00:02, 386.61it/s]
Adding requests:  50%|█████     | 1029/2048 [00:02<00:02, 385.24it/s]
Adding requests:  52%|█████▏    | 1068/2048 [00:02<00:02, 381.58it/s]
Adding requests:  54%|█████▍    | 1107/2048 [00:02<00:02, 380.14it/s]
Adding requests:  56%|█████▌    | 1148/2048 [00:02<00:02, 385.80it/s]
Adding requests:  58%|█████▊    | 1187/2048 [00:03<00:02, 384.92it/s]
Adding requests:  60%|█████▉    | 1228/2048 [00:03<00:02, 390.91it/s]
Adding requests:  62%|██████▏   | 1268/2048 [00:03<00:02, 387.92it/s]
Adding requests:  64%|██████▍   | 1307/2048 [00:03<00:01, 386.79it/s]
Adding requests:  66%|██████▌   | 1347/2048 [00:03<00:01, 388.23it/s]
Adding requests:  68%|██████▊   | 1387/2048 [00:03<00:01, 391.07it/s]
Adding requests:  70%|██████▉   | 1427/2048 [00:03<00:01, 389.34it/s]
Adding requests:  72%|███████▏  | 1467/2048 [00:03<00:01, 391.76it/s]
Adding requests:  74%|███████▎  | 1508/2048 [00:03<00:01, 395.24it/s]
Adding requests:  76%|███████▌  | 1548/2048 [00:04<00:01, 392.95it/s]
Adding requests:  78%|███████▊  | 1588/2048 [00:04<00:01, 385.60it/s]
Adding requests:  79%|███████▉  | 1627/2048 [00:04<00:01, 379.85it/s]
Adding requests:  81%|████████▏ | 1666/2048 [00:04<00:01, 372.43it/s]
Adding requests:  83%|████████▎ | 1706/2048 [00:04<00:00, 380.01it/s]
Adding requests:  85%|████████▌ | 1746/2048 [00:04<00:00, 383.69it/s]
Adding requests:  87%|████████▋ | 1787/2048 [00:04<00:00, 388.17it/s]
Adding requests:  89%|████████▉ | 1826/2048 [00:04<00:00, 387.35it/s]
Adding requests:  91%|█████████ | 1866/2048 [00:04<00:00, 388.33it/s]
Adding requests:  93%|█████████▎| 1906/2048 [00:04<00:00, 390.10it/s]
Adding requests:  95%|█████████▌| 1946/2048 [00:05<00:00, 386.02it/s]
Adding requests:  97%|█████████▋| 1986/2048 [00:05<00:00, 386.74it/s]
Adding requests:  99%|█████████▉| 2025/2048 [00:05<00:00, 378.86it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 384.77it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:00<00:03, 472.80it/s, est. speed input: 484199.26 toks/s, output: 472.82 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:01<00:14, 127.59it/s, est. speed input: 159009.36 toks/s, output: 155.28 toks/s]
Processed prompts:  14%|█▎        | 280/2048 [00:02<00:16, 107.23it/s, est. speed input: 138524.24 toks/s, output: 135.28 toks/s]
Processed prompts:  14%|█▍        | 295/2048 [00:02<00:20, 87.53it/s, est. speed input: 122096.58 toks/s, output: 119.23 toks/s] 
Processed prompts:  15%|█▍        | 306/2048 [00:02<00:24, 71.51it/s, est. speed input: 109807.40 toks/s, output: 107.23 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:03<00:27, 61.93it/s, est. speed input: 101079.30 toks/s, output: 98.71 toks/s] 
Processed prompts:  17%|█▋        | 338/2048 [00:03<00:30, 55.33it/s, est. speed input: 94400.88 toks/s, output: 92.19 toks/s] 
Processed prompts:  17%|█▋        | 354/2048 [00:04<00:33, 50.49it/s, est. speed input: 88949.83 toks/s, output: 86.86 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:04<00:35, 47.26it/s, est. speed input: 84586.50 toks/s, output: 82.60 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:04<00:37, 44.91it/s, est. speed input: 80906.23 toks/s, output: 79.01 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:05<00:38, 43.26it/s, est. speed input: 77793.23 toks/s, output: 75.97 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:05<00:38, 42.15it/s, est. speed input: 75145.15 toks/s, output: 73.38 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:06<00:38, 42.02it/s, est. speed input: 73094.79 toks/s, output: 71.38 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:06<00:38, 41.27it/s, est. speed input: 71063.02 toks/s, output: 69.40 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:06<00:38, 40.70it/s, est. speed input: 69251.63 toks/s, output: 67.63 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:07<00:38, 40.34it/s, est. speed input: 67651.99 toks/s, output: 66.07 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:07<00:38, 40.14it/s, est. speed input: 66237.17 toks/s, output: 64.68 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:08<00:38, 39.99it/s, est. speed input: 64960.26 toks/s, output: 63.44 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:08<00:38, 39.88it/s, est. speed input: 63802.30 toks/s, output: 62.31 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:08<00:37, 39.77it/s, est. speed input: 62740.41 toks/s, output: 61.27 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:09<00:37, 39.72it/s, est. speed input: 61778.53 toks/s, output: 60.33 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:09<00:37, 39.70it/s, est. speed input: 60900.44 toks/s, output: 59.47 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:10<00:36, 39.68it/s, est. speed input: 60089.32 toks/s, output: 58.68 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:10<00:36, 39.64it/s, est. speed input: 59336.32 toks/s, output: 57.95 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:10<00:35, 39.62it/s, est. speed input: 58639.93 toks/s, output: 57.27 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:11<00:35, 39.57it/s, est. speed input: 57987.58 toks/s, output: 56.63 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:11<00:35, 39.56it/s, est. speed input: 57385.03 toks/s, output: 56.04 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:12<00:34, 39.59it/s, est. speed input: 56826.99 toks/s, output: 55.50 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:12<00:34, 39.53it/s, est. speed input: 56293.70 toks/s, output: 54.97 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:12<00:33, 39.52it/s, est. speed input: 55797.85 toks/s, output: 54.49 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:13<00:33, 39.52it/s, est. speed input: 55333.81 toks/s, output: 54.04 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:13<00:33, 39.50it/s, est. speed input: 54894.32 toks/s, output: 53.61 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:14<00:32, 39.47it/s, est. speed input: 54477.54 toks/s, output: 53.20 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:14<00:32, 39.52it/s, est. speed input: 54092.52 toks/s, output: 52.82 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:14<00:31, 40.17it/s, est. speed input: 53803.15 toks/s, output: 52.54 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:15<00:31, 39.98it/s, est. speed input: 53452.25 toks/s, output: 52.20 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:15<00:30, 39.82it/s, est. speed input: 53116.65 toks/s, output: 51.87 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:16<00:30, 39.69it/s, est. speed input: 52796.06 toks/s, output: 51.56 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:16<00:30, 39.64it/s, est. speed input: 52495.18 toks/s, output: 51.26 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:16<00:29, 39.60it/s, est. speed input: 52208.03 toks/s, output: 50.98 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:17<00:29, 39.56it/s, est. speed input: 51932.55 toks/s, output: 50.72 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:17<00:29, 39.53it/s, est. speed input: 51670.00 toks/s, output: 50.46 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:18<00:28, 39.52it/s, est. speed input: 51420.45 toks/s, output: 50.22 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:18<00:28, 39.54it/s, est. speed input: 51183.82 toks/s, output: 49.98 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:19<00:27, 39.39it/s, est. speed input: 50942.40 toks/s, output: 49.75 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:19<00:27, 39.45it/s, est. speed input: 50726.36 toks/s, output: 49.54 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:19<00:27, 39.38it/s, est. speed input: 50508.36 toks/s, output: 49.32 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:20<00:26, 39.37it/s, est. speed input: 50303.03 toks/s, output: 49.12 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:20<00:26, 39.41it/s, est. speed input: 50109.97 toks/s, output: 48.94 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:21<00:25, 39.39it/s, est. speed input: 49919.82 toks/s, output: 48.75 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:21<00:25, 39.34it/s, est. speed input: 49734.50 toks/s, output: 48.57 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:21<00:25, 39.35it/s, est. speed input: 49559.35 toks/s, output: 48.40 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:22<00:24, 39.40it/s, est. speed input: 49393.72 toks/s, output: 48.24 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:22<00:24, 39.36it/s, est. speed input: 49228.60 toks/s, output: 48.07 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:23<00:23, 39.32it/s, est. speed input: 49068.41 toks/s, output: 47.92 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:23<00:23, 39.37it/s, est. speed input: 48919.60 toks/s, output: 47.77 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:23<00:23, 39.31it/s, est. speed input: 48768.83 toks/s, output: 47.63 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:24<00:22, 39.33it/s, est. speed input: 48627.77 toks/s, output: 47.49 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:24<00:22, 39.35it/s, est. speed input: 48491.32 toks/s, output: 47.35 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:25<00:21, 39.35it/s, est. speed input: 48358.73 toks/s, output: 47.23 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:25<00:21, 40.07it/s, est. speed input: 48276.35 toks/s, output: 47.14 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:25<00:20, 39.82it/s, est. speed input: 48149.18 toks/s, output: 47.02 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:26<00:20, 40.33it/s, est. speed input: 48067.22 toks/s, output: 46.94 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:26<00:19, 39.94it/s, est. speed input: 47943.68 toks/s, output: 46.82 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:27<00:19, 39.74it/s, est. speed input: 47827.49 toks/s, output: 46.71 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:27<00:19, 39.66it/s, est. speed input: 47718.39 toks/s, output: 46.60 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:27<00:18, 39.52it/s, est. speed input: 47607.47 toks/s, output: 46.49 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:28<00:18, 39.51it/s, est. speed input: 47504.81 toks/s, output: 46.39 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:28<00:17, 40.06it/s, est. speed input: 47436.20 toks/s, output: 46.32 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:29<00:17, 39.76it/s, est. speed input: 47331.61 toks/s, output: 46.22 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:29<00:17, 39.68it/s, est. speed input: 47237.43 toks/s, output: 46.13 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:29<00:16, 39.50it/s, est. speed input: 47138.83 toks/s, output: 46.03 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:30<00:16, 39.49it/s, est. speed input: 47048.59 toks/s, output: 45.95 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:30<00:16, 39.42it/s, est. speed input: 46957.75 toks/s, output: 45.86 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:31<00:15, 39.35it/s, est. speed input: 46868.37 toks/s, output: 45.77 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:31<00:15, 39.35it/s, est. speed input: 46783.57 toks/s, output: 45.69 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:31<00:14, 39.94it/s, est. speed input: 46730.49 toks/s, output: 45.64 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:32<00:14, 39.74it/s, est. speed input: 46648.44 toks/s, output: 45.56 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:32<00:14, 39.60it/s, est. speed input: 46568.66 toks/s, output: 45.48 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:33<00:13, 39.45it/s, est. speed input: 46488.34 toks/s, output: 45.40 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:33<00:13, 40.06it/s, est. speed input: 46442.98 toks/s, output: 45.35 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:33<00:12, 39.85it/s, est. speed input: 46369.55 toks/s, output: 45.28 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:34<00:12, 40.25it/s, est. speed input: 46322.53 toks/s, output: 45.24 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:34<00:11, 39.95it/s, est. speed input: 46250.88 toks/s, output: 45.17 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:35<00:11, 39.74it/s, est. speed input: 46181.00 toks/s, output: 45.10 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:35<00:11, 39.55it/s, est. speed input: 46110.59 toks/s, output: 45.03 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:35<00:10, 40.15it/s, est. speed input: 46073.10 toks/s, output: 44.99 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:36<00:10, 39.84it/s, est. speed input: 46005.54 toks/s, output: 44.93 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:36<00:10, 39.65it/s, est. speed input: 45940.67 toks/s, output: 44.86 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:37<00:09, 39.50it/s, est. speed input: 45876.40 toks/s, output: 44.80 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:37<00:09, 39.40it/s, est. speed input: 45813.93 toks/s, output: 44.74 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:38<00:08, 39.37it/s, est. speed input: 45753.96 toks/s, output: 44.68 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:38<00:08, 39.24it/s, est. speed input: 45691.40 toks/s, output: 44.62 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:38<00:07, 39.89it/s, est. speed input: 45659.58 toks/s, output: 44.59 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:39<00:07, 40.33it/s, est. speed input: 45627.35 toks/s, output: 44.56 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:39<00:07, 39.95it/s, est. speed input: 45569.26 toks/s, output: 44.50 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:40<00:06, 39.72it/s, est. speed input: 45513.71 toks/s, output: 44.45 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:40<00:06, 39.48it/s, est. speed input: 45456.53 toks/s, output: 44.39 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:40<00:06, 39.39it/s, est. speed input: 45403.25 toks/s, output: 44.34 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:41<00:05, 39.30it/s, est. speed input: 45349.76 toks/s, output: 44.29 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:41<00:05, 39.21it/s, est. speed input: 45296.33 toks/s, output: 44.23 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:42<00:04, 39.25it/s, est. speed input: 45248.11 toks/s, output: 44.19 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:42<00:04, 39.15it/s, est. speed input: 45195.88 toks/s, output: 44.14 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:42<00:03, 39.84it/s, est. speed input: 45172.15 toks/s, output: 44.11 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:43<00:03, 39.62it/s, est. speed input: 45123.66 toks/s, output: 44.07 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:43<00:03, 39.43it/s, est. speed input: 45074.83 toks/s, output: 44.02 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:44<00:02, 39.38it/s, est. speed input: 45029.74 toks/s, output: 43.97 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:44<00:02, 39.21it/s, est. speed input: 44980.84 toks/s, output: 43.93 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:44<00:01, 39.19it/s, est. speed input: 44936.26 toks/s, output: 43.88 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:45<00:01, 39.80it/s, est. speed input: 44913.57 toks/s, output: 43.86 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:45<00:01, 39.56it/s, est. speed input: 44868.98 toks/s, output: 43.82 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:46<00:00, 39.42it/s, est. speed input: 44826.13 toks/s, output: 43.78 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:46<00:00, 40.11it/s, est. speed input: 44809.75 toks/s, output: 43.76 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:46<00:00, 40.11it/s, est. speed input: 45117.93 toks/s, output: 44.06 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:46<00:00, 44.06it/s, est. speed input: 45117.93 toks/s, output: 44.06 toks/s]
[rank0]:[W126 11:39:08.370224119 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 11:39:10
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:39:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1300495) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1300495) WARNING 01-26 11:39:56 [backends.py:609] Failed to read file <frozen os>
Throughput: 38.95 requests/s, 39928.40 total tokens/s, 38.95 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 11:39:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:39:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:39:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:39:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:39:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:39:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:39:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:39:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:39:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:39:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:39:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:39:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:39:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:39:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:39:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:39:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:39:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1300495) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1300495) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.85it/s]
(EngineCore_DP0 pid=1300495) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1300495) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1300495) 
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1300495) [2026-01-26 11:39:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1300495) [rank0]:W0126 11:40:01.989000 1300495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1300495) [rank0]:W0126 11:40:02.068000 1300495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1300495) [rank0]:W0126 11:40:03.017000 1300495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1300495) [rank0]:W0126 11:40:03.146000 1300495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1300495) 2026-01-26 11:40:07,086 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1300495) 2026-01-26 11:40:07,112 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1300495) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:08,  1.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  2.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  7.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  9.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00, 11.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.87it/s]
(EngineCore_DP0 pid=1300495) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 18.92it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 19.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  7.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.47it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:16, 253.29it/s]
Adding requests:   2%|▏         | 66/4096 [00:00<00:11, 338.23it/s]
Adding requests:   3%|▎         | 103/4096 [00:00<00:11, 349.41it/s]
Adding requests:   3%|▎         | 141/4096 [00:00<00:10, 359.59it/s]
Adding requests:   4%|▍         | 180/4096 [00:00<00:10, 370.24it/s]
Adding requests:   5%|▌         | 222/4096 [00:00<00:10, 384.40it/s]
Adding requests:   6%|▋         | 261/4096 [00:00<00:10, 382.72it/s]
Adding requests:   7%|▋         | 301/4096 [00:00<00:09, 386.04it/s]
Adding requests:   8%|▊         | 342/4096 [00:00<00:09, 391.61it/s]
Adding requests:   9%|▉         | 382/4096 [00:01<00:09, 394.14it/s]
Adding requests:  10%|█         | 424/4096 [00:01<00:09, 400.96it/s]
Adding requests:  11%|█▏        | 465/4096 [00:01<00:09, 396.46it/s]
Adding requests:  12%|█▏        | 509/4096 [00:01<00:08, 406.13it/s]
Adding requests:  13%|█▎        | 551/4096 [00:01<00:08, 408.47it/s]
Adding requests:  14%|█▍        | 592/4096 [00:01<00:08, 403.16it/s]
Adding requests:  15%|█▌        | 633/4096 [00:01<00:08, 398.14it/s]
Adding requests:  16%|█▋        | 673/4096 [00:01<00:08, 388.19it/s]
Adding requests:  17%|█▋        | 715/4096 [00:01<00:08, 394.39it/s]
Adding requests:  18%|█▊        | 755/4096 [00:01<00:08, 386.92it/s]
Adding requests:  19%|█▉        | 794/4096 [00:02<00:08, 387.13it/s]
Adding requests:  20%|██        | 835/4096 [00:02<00:08, 393.12it/s]
Adding requests:  21%|██▏       | 875/4096 [00:02<00:08, 393.12it/s]
Adding requests:  22%|██▏       | 915/4096 [00:02<00:08, 391.81it/s]
Adding requests:  23%|██▎       | 955/4096 [00:02<00:08, 390.88it/s]
Adding requests:  24%|██▍       | 995/4096 [00:02<00:08, 383.97it/s]
Adding requests:  25%|██▌       | 1034/4096 [00:02<00:07, 384.45it/s]
Adding requests:  26%|██▌       | 1073/4096 [00:02<00:07, 383.32it/s]
Adding requests:  27%|██▋       | 1112/4096 [00:02<00:08, 372.61it/s]
Adding requests:  28%|██▊       | 1151/4096 [00:02<00:07, 376.53it/s]
Adding requests:  29%|██▉       | 1189/4096 [00:03<00:07, 377.29it/s]
Adding requests:  30%|███       | 1230/4096 [00:03<00:07, 385.68it/s]
Adding requests:  31%|███       | 1269/4096 [00:03<00:07, 383.68it/s]
Adding requests:  32%|███▏      | 1308/4096 [00:03<00:07, 383.06it/s]
Adding requests:  33%|███▎      | 1348/4096 [00:03<00:07, 386.62it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:03<00:06, 388.63it/s]
Adding requests:  35%|███▍      | 1427/4096 [00:03<00:06, 386.48it/s]
Adding requests:  36%|███▌      | 1467/4096 [00:03<00:06, 389.78it/s]
Adding requests:  37%|███▋      | 1508/4096 [00:03<00:06, 392.77it/s]
Adding requests:  38%|███▊      | 1548/4096 [00:04<00:06, 391.96it/s]
Adding requests:  39%|███▉      | 1588/4096 [00:04<00:06, 383.58it/s]
Adding requests:  40%|███▉      | 1627/4096 [00:04<00:06, 378.41it/s]
Adding requests:  41%|████      | 1665/4096 [00:04<00:06, 370.98it/s]
Adding requests:  42%|████▏     | 1705/4096 [00:04<00:06, 376.93it/s]
Adding requests:  43%|████▎     | 1745/4096 [00:04<00:06, 382.66it/s]
Adding requests:  44%|████▎     | 1785/4096 [00:04<00:05, 387.24it/s]
Adding requests:  45%|████▍     | 1824/4096 [00:04<00:05, 384.65it/s]
Adding requests:  45%|████▌     | 1863/4096 [00:04<00:05, 384.54it/s]
Adding requests:  46%|████▋     | 1902/4096 [00:04<00:05, 385.42it/s]
Adding requests:  47%|████▋     | 1944/4096 [00:05<00:05, 392.94it/s]
Adding requests:  48%|████▊     | 1984/4096 [00:05<00:05, 391.71it/s]
Adding requests:  49%|████▉     | 2024/4096 [00:05<00:05, 381.27it/s]
Adding requests:  50%|█████     | 2063/4096 [00:05<00:05, 378.71it/s]
Adding requests:  51%|█████▏    | 2101/4096 [00:05<00:05, 374.67it/s]
Adding requests:  52%|█████▏    | 2140/4096 [00:05<00:05, 377.06it/s]
Adding requests:  53%|█████▎    | 2178/4096 [00:05<00:05, 371.28it/s]
Adding requests:  54%|█████▍    | 2216/4096 [00:05<00:05, 372.36it/s]
Adding requests:  55%|█████▌    | 2256/4096 [00:05<00:04, 380.17it/s]
Adding requests:  56%|█████▌    | 2296/4096 [00:05<00:04, 385.16it/s]
Adding requests:  57%|█████▋    | 2335/4096 [00:06<00:04, 377.23it/s]
Adding requests:  58%|█████▊    | 2375/4096 [00:06<00:04, 383.02it/s]
Adding requests:  59%|█████▉    | 2417/4096 [00:06<00:04, 391.81it/s]
Adding requests:  60%|█████▉    | 2457/4096 [00:06<00:04, 389.29it/s]
Adding requests:  61%|██████    | 2498/4096 [00:06<00:04, 392.76it/s]
Adding requests:  62%|██████▏   | 2538/4096 [00:06<00:03, 393.93it/s]
Adding requests:  63%|██████▎   | 2582/4096 [00:06<00:03, 405.04it/s]
Adding requests:  64%|██████▍   | 2623/4096 [00:06<00:03, 398.10it/s]
Adding requests:  65%|██████▌   | 2663/4096 [00:06<00:03, 390.47it/s]
Adding requests:  66%|██████▌   | 2703/4096 [00:07<00:03, 386.90it/s]
Adding requests:  67%|██████▋   | 2742/4096 [00:07<00:03, 383.19it/s]
Adding requests:  68%|██████▊   | 2783/4096 [00:07<00:03, 389.85it/s]
Adding requests:  69%|██████▉   | 2825/4096 [00:07<00:03, 395.71it/s]
Adding requests:  70%|██████▉   | 2865/4096 [00:07<00:03, 395.02it/s]
Adding requests:  71%|███████   | 2905/4096 [00:07<00:03, 394.98it/s]
Adding requests:  72%|███████▏  | 2946/4096 [00:07<00:02, 397.71it/s]
Adding requests:  73%|███████▎  | 2986/4096 [00:07<00:02, 394.89it/s]
Adding requests:  74%|███████▍  | 3028/4096 [00:07<00:02, 398.89it/s]
Adding requests:  75%|███████▍  | 3070/4096 [00:07<00:02, 403.22it/s]
Adding requests:  76%|███████▌  | 3111/4096 [00:08<00:02, 401.80it/s]
Adding requests:  77%|███████▋  | 3152/4096 [00:08<00:02, 401.83it/s]
Adding requests:  78%|███████▊  | 3193/4096 [00:08<00:02, 396.94it/s]
Adding requests:  79%|███████▉  | 3234/4096 [00:08<00:02, 398.22it/s]
Adding requests:  80%|███████▉  | 3274/4096 [00:08<00:02, 386.52it/s]
Adding requests:  81%|████████  | 3313/4096 [00:08<00:02, 379.43it/s]
Adding requests:  82%|████████▏ | 3352/4096 [00:08<00:01, 380.71it/s]
Adding requests:  83%|████████▎ | 3392/4096 [00:08<00:01, 385.58it/s]
Adding requests:  84%|████████▍ | 3432/4096 [00:08<00:01, 389.38it/s]
Adding requests:  85%|████████▍ | 3472/4096 [00:08<00:01, 392.04it/s]
Adding requests:  86%|████████▌ | 3512/4096 [00:09<00:01, 392.78it/s]
Adding requests:  87%|████████▋ | 3554/4096 [00:09<00:01, 398.85it/s]
Adding requests:  88%|████████▊ | 3594/4096 [00:09<00:01, 398.20it/s]
Adding requests:  89%|████████▊ | 3635/4096 [00:09<00:01, 399.18it/s]
Adding requests:  90%|████████▉ | 3675/4096 [00:09<00:01, 378.95it/s]
Adding requests:  91%|█████████ | 3714/4096 [00:09<00:01, 380.92it/s]
Adding requests:  92%|█████████▏| 3753/4096 [00:09<00:00, 379.11it/s]
Adding requests:  93%|█████████▎| 3792/4096 [00:09<00:00, 368.93it/s]
Adding requests:  94%|█████████▎| 3830/4096 [00:09<00:00, 367.87it/s]
Adding requests:  94%|█████████▍| 3870/4096 [00:10<00:00, 375.84it/s]
Adding requests:  95%|█████████▌| 3908/4096 [00:10<00:00, 371.83it/s]
Adding requests:  96%|█████████▋| 3946/4096 [00:10<00:00, 372.79it/s]
Adding requests:  97%|█████████▋| 3984/4096 [00:10<00:00, 372.60it/s]
Adding requests:  98%|█████████▊| 4022/4096 [00:10<00:00, 374.43it/s]
Adding requests:  99%|█████████▉| 4060/4096 [00:10<00:00, 375.15it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 385.61it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 396/4096 [00:00<00:05, 621.89it/s, est. speed input: 636839.19 toks/s, output: 621.90 toks/s]
Processed prompts:  11%|█         | 459/4096 [00:01<00:13, 274.09it/s, est. speed input: 328176.22 toks/s, output: 320.48 toks/s]
Processed prompts:  12%|█▏        | 490/4096 [00:02<00:22, 160.20it/s, est. speed input: 223664.64 toks/s, output: 218.42 toks/s]
Processed prompts:  12%|█▏        | 509/4096 [00:03<00:34, 104.31it/s, est. speed input: 170571.86 toks/s, output: 166.57 toks/s]
Processed prompts:  13%|█▎        | 524/4096 [00:03<00:49, 72.64it/s, est. speed input: 138689.71 toks/s, output: 135.44 toks/s] 
Processed prompts:  14%|█▎        | 556/4096 [00:04<00:57, 61.13it/s, est. speed input: 121571.36 toks/s, output: 118.72 toks/s]
Processed prompts:  14%|█▍        | 588/4096 [00:05<01:05, 53.93it/s, est. speed input: 109540.84 toks/s, output: 106.97 toks/s]
Processed prompts:  15%|█▌        | 620/4096 [00:06<01:10, 49.23it/s, est. speed input: 100590.66 toks/s, output: 98.23 toks/s] 
Processed prompts:  16%|█▌        | 652/4096 [00:07<01:14, 46.09it/s, est. speed input: 93678.48 toks/s, output: 91.48 toks/s] 
Processed prompts:  17%|█▋        | 684/4096 [00:07<01:17, 44.01it/s, est. speed input: 88213.67 toks/s, output: 86.15 toks/s]
Processed prompts:  17%|█▋        | 716/4096 [00:08<01:19, 42.55it/s, est. speed input: 83744.08 toks/s, output: 81.78 toks/s]
Processed prompts:  18%|█▊        | 748/4096 [00:09<01:20, 41.52it/s, est. speed input: 80022.64 toks/s, output: 78.15 toks/s]
Processed prompts:  19%|█▉        | 780/4096 [00:10<01:20, 41.12it/s, est. speed input: 77035.59 toks/s, output: 75.23 toks/s]
Processed prompts:  20%|█▉        | 812/4096 [00:11<01:20, 40.54it/s, est. speed input: 74346.28 toks/s, output: 72.60 toks/s]
Processed prompts:  21%|██        | 844/4096 [00:11<01:20, 40.15it/s, est. speed input: 72024.40 toks/s, output: 70.34 toks/s]
Processed prompts:  21%|██▏       | 876/4096 [00:12<01:20, 39.88it/s, est. speed input: 69999.96 toks/s, output: 68.36 toks/s]
Processed prompts:  22%|██▏       | 908/4096 [00:13<01:20, 39.66it/s, est. speed input: 68207.91 toks/s, output: 66.61 toks/s]
Processed prompts:  23%|██▎       | 940/4096 [00:14<01:19, 39.52it/s, est. speed input: 66619.74 toks/s, output: 65.06 toks/s]
Processed prompts:  24%|██▎       | 972/4096 [00:15<01:19, 39.42it/s, est. speed input: 65202.20 toks/s, output: 63.67 toks/s]
Processed prompts:  25%|██▍       | 1004/4096 [00:16<01:18, 39.35it/s, est. speed input: 63929.07 toks/s, output: 62.43 toks/s]
Processed prompts:  25%|██▌       | 1036/4096 [00:16<01:17, 39.30it/s, est. speed input: 62779.04 toks/s, output: 61.31 toks/s]
Processed prompts:  26%|██▌       | 1068/4096 [00:17<01:17, 39.30it/s, est. speed input: 61743.41 toks/s, output: 60.30 toks/s]
Processed prompts:  27%|██▋       | 1100/4096 [00:18<01:16, 39.25it/s, est. speed input: 60786.82 toks/s, output: 59.36 toks/s]
Processed prompts:  28%|██▊       | 1132/4096 [00:19<01:15, 39.17it/s, est. speed input: 59902.36 toks/s, output: 58.50 toks/s]
Processed prompts:  28%|██▊       | 1164/4096 [00:20<01:14, 39.13it/s, est. speed input: 59092.98 toks/s, output: 57.71 toks/s]
Processed prompts:  29%|██▉       | 1196/4096 [00:20<01:13, 39.41it/s, est. speed input: 58405.53 toks/s, output: 57.04 toks/s]
Processed prompts:  30%|██▉       | 1228/4096 [00:21<01:12, 39.60it/s, est. speed input: 57765.88 toks/s, output: 56.41 toks/s]
Processed prompts:  31%|███       | 1260/4096 [00:22<01:11, 39.45it/s, est. speed input: 57123.90 toks/s, output: 55.78 toks/s]
Processed prompts:  32%|███▏      | 1292/4096 [00:23<01:11, 39.33it/s, est. speed input: 56524.82 toks/s, output: 55.20 toks/s]
Processed prompts:  32%|███▏      | 1324/4096 [00:24<01:10, 39.54it/s, est. speed input: 56011.38 toks/s, output: 54.70 toks/s]
Processed prompts:  33%|███▎      | 1356/4096 [00:25<01:09, 39.39it/s, est. speed input: 55487.19 toks/s, output: 54.19 toks/s]
Processed prompts:  34%|███▍      | 1388/4096 [00:25<01:08, 39.28it/s, est. speed input: 54994.89 toks/s, output: 53.71 toks/s]
Processed prompts:  35%|███▍      | 1420/4096 [00:26<01:08, 39.23it/s, est. speed input: 54535.41 toks/s, output: 53.26 toks/s]
Processed prompts:  35%|███▌      | 1452/4096 [00:27<01:07, 39.44it/s, est. speed input: 54137.97 toks/s, output: 52.87 toks/s]
Processed prompts:  36%|███▌      | 1484/4096 [00:28<01:06, 39.30it/s, est. speed input: 53725.29 toks/s, output: 52.47 toks/s]
Processed prompts:  37%|███▋      | 1516/4096 [00:29<01:05, 39.51it/s, est. speed input: 53374.45 toks/s, output: 52.12 toks/s]
Processed prompts:  38%|███▊      | 1548/4096 [00:29<01:04, 39.63it/s, est. speed input: 53038.76 toks/s, output: 51.80 toks/s]
Processed prompts:  39%|███▊      | 1580/4096 [00:30<01:03, 39.45it/s, est. speed input: 52689.51 toks/s, output: 51.45 toks/s]
Processed prompts:  39%|███▉      | 1612/4096 [00:31<01:02, 39.59it/s, est. speed input: 52389.58 toks/s, output: 51.16 toks/s]
Processed prompts:  40%|████      | 1644/4096 [00:32<01:02, 39.41it/s, est. speed input: 52072.76 toks/s, output: 50.85 toks/s]
Processed prompts:  41%|████      | 1676/4096 [00:33<01:01, 39.26it/s, est. speed input: 51769.69 toks/s, output: 50.56 toks/s]
Processed prompts:  42%|████▏     | 1708/4096 [00:33<01:00, 39.16it/s, est. speed input: 51481.60 toks/s, output: 50.27 toks/s]
Processed prompts:  42%|████▏     | 1740/4096 [00:34<00:59, 39.77it/s, est. speed input: 51276.40 toks/s, output: 50.07 toks/s]
Processed prompts:  43%|████▎     | 1772/4096 [00:35<00:58, 39.51it/s, est. speed input: 51011.82 toks/s, output: 49.82 toks/s]
Processed prompts:  44%|████▍     | 1804/4096 [00:36<00:58, 39.32it/s, est. speed input: 50758.56 toks/s, output: 49.57 toks/s]
Processed prompts:  45%|████▍     | 1836/4096 [00:37<00:57, 39.18it/s, est. speed input: 50516.33 toks/s, output: 49.33 toks/s]
Processed prompts:  46%|████▌     | 1868/4096 [00:38<00:56, 39.38it/s, est. speed input: 50311.29 toks/s, output: 49.13 toks/s]
Processed prompts:  46%|████▋     | 1900/4096 [00:38<00:55, 39.23it/s, est. speed input: 50088.83 toks/s, output: 48.91 toks/s]
Processed prompts:  47%|████▋     | 1932/4096 [00:39<00:55, 39.14it/s, est. speed input: 49877.26 toks/s, output: 48.71 toks/s]
Processed prompts:  48%|████▊     | 1964/4096 [00:40<00:54, 39.36it/s, est. speed input: 49697.51 toks/s, output: 48.53 toks/s]
Processed prompts:  49%|████▊     | 1996/4096 [00:41<00:53, 39.17it/s, est. speed input: 49497.31 toks/s, output: 48.34 toks/s]
Processed prompts:  50%|████▉     | 2028/4096 [00:42<00:52, 39.08it/s, est. speed input: 49307.88 toks/s, output: 48.15 toks/s]
Processed prompts:  50%|█████     | 2060/4096 [00:42<00:51, 39.26it/s, est. speed input: 49144.77 toks/s, output: 47.99 toks/s]
Processed prompts:  51%|█████     | 2092/4096 [00:43<00:51, 39.15it/s, est. speed input: 48969.66 toks/s, output: 47.82 toks/s]
Processed prompts:  52%|█████▏    | 2124/4096 [00:44<00:50, 39.07it/s, est. speed input: 48800.93 toks/s, output: 47.66 toks/s]
Processed prompts:  53%|█████▎    | 2156/4096 [00:45<00:49, 38.99it/s, est. speed input: 48635.96 toks/s, output: 47.50 toks/s]
Processed prompts:  53%|█████▎    | 2188/4096 [00:46<00:48, 39.20it/s, est. speed input: 48496.76 toks/s, output: 47.36 toks/s]
Processed prompts:  54%|█████▍    | 2220/4096 [00:47<00:48, 39.07it/s, est. speed input: 48342.13 toks/s, output: 47.21 toks/s]
Processed prompts:  55%|█████▍    | 2252/4096 [00:47<00:47, 39.01it/s, est. speed input: 48195.47 toks/s, output: 47.07 toks/s]
Processed prompts:  56%|█████▌    | 2284/4096 [00:48<00:46, 38.96it/s, est. speed input: 48052.73 toks/s, output: 46.93 toks/s]
Processed prompts:  57%|█████▋    | 2316/4096 [00:49<00:45, 38.90it/s, est. speed input: 47913.32 toks/s, output: 46.79 toks/s]
Processed prompts:  57%|█████▋    | 2348/4096 [00:50<00:44, 38.90it/s, est. speed input: 47781.24 toks/s, output: 46.66 toks/s]
Processed prompts:  58%|█████▊    | 2380/4096 [00:51<00:44, 38.84it/s, est. speed input: 47649.50 toks/s, output: 46.53 toks/s]
Processed prompts:  59%|█████▉    | 2412/4096 [00:51<00:43, 38.83it/s, est. speed input: 47523.99 toks/s, output: 46.41 toks/s]
Processed prompts:  60%|█████▉    | 2444/4096 [00:52<00:42, 38.82it/s, est. speed input: 47402.25 toks/s, output: 46.29 toks/s]
Processed prompts:  60%|██████    | 2476/4096 [00:53<00:41, 38.81it/s, est. speed input: 47284.02 toks/s, output: 46.18 toks/s]
Processed prompts:  61%|██████    | 2508/4096 [00:54<00:40, 38.82it/s, est. speed input: 47170.36 toks/s, output: 46.06 toks/s]
Processed prompts:  62%|██████▏   | 2540/4096 [00:55<00:39, 39.06it/s, est. speed input: 47074.34 toks/s, output: 45.97 toks/s]
Processed prompts:  63%|██████▎   | 2572/4096 [00:56<00:39, 38.95it/s, est. speed input: 46964.40 toks/s, output: 45.86 toks/s]
Processed prompts:  64%|██████▎   | 2604/4096 [00:56<00:38, 39.16it/s, est. speed input: 46874.34 toks/s, output: 45.78 toks/s]
Processed prompts:  64%|██████▍   | 2636/4096 [00:57<00:37, 39.02it/s, est. speed input: 46770.52 toks/s, output: 45.67 toks/s]
Processed prompts:  65%|██████▌   | 2668/4096 [00:58<00:36, 38.93it/s, est. speed input: 46670.11 toks/s, output: 45.58 toks/s]
Processed prompts:  66%|██████▌   | 2700/4096 [00:59<00:35, 38.87it/s, est. speed input: 46572.47 toks/s, output: 45.48 toks/s]
Processed prompts:  67%|██████▋   | 2732/4096 [01:00<00:34, 39.11it/s, est. speed input: 46493.12 toks/s, output: 45.40 toks/s]
Processed prompts:  67%|██████▋   | 2764/4096 [01:00<00:34, 38.98it/s, est. speed input: 46399.59 toks/s, output: 45.31 toks/s]
Processed prompts:  68%|██████▊   | 2796/4096 [01:01<00:33, 38.88it/s, est. speed input: 46308.19 toks/s, output: 45.22 toks/s]
Processed prompts:  69%|██████▉   | 2828/4096 [01:02<00:32, 38.81it/s, est. speed input: 46218.96 toks/s, output: 45.14 toks/s]
Processed prompts:  70%|██████▉   | 2860/4096 [01:03<00:31, 38.75it/s, est. speed input: 46131.91 toks/s, output: 45.05 toks/s]
Processed prompts:  71%|███████   | 2892/4096 [01:04<00:30, 39.43it/s, est. speed input: 46082.87 toks/s, output: 45.00 toks/s]
Processed prompts:  71%|███████▏  | 2924/4096 [01:05<00:29, 39.50it/s, est. speed input: 46015.19 toks/s, output: 44.94 toks/s]
Processed prompts:  72%|███████▏  | 2956/4096 [01:05<00:29, 39.24it/s, est. speed input: 45934.27 toks/s, output: 44.86 toks/s]
Processed prompts:  73%|███████▎  | 2988/4096 [01:06<00:28, 39.05it/s, est. speed input: 45854.73 toks/s, output: 44.78 toks/s]
Processed prompts:  74%|███████▎  | 3020/4096 [01:07<00:27, 38.93it/s, est. speed input: 45777.77 toks/s, output: 44.70 toks/s]
Processed prompts:  75%|███████▍  | 3052/4096 [01:08<00:26, 38.81it/s, est. speed input: 45700.99 toks/s, output: 44.63 toks/s]
Processed prompts:  75%|███████▌  | 3084/4096 [01:09<00:26, 38.77it/s, est. speed input: 45628.18 toks/s, output: 44.56 toks/s]
Processed prompts:  76%|███████▌  | 3116/4096 [01:10<00:25, 38.73it/s, est. speed input: 45556.54 toks/s, output: 44.49 toks/s]
Processed prompts:  77%|███████▋  | 3148/4096 [01:10<00:24, 38.70it/s, est. speed input: 45486.22 toks/s, output: 44.42 toks/s]
Processed prompts:  78%|███████▊  | 3180/4096 [01:11<00:23, 38.63it/s, est. speed input: 45415.66 toks/s, output: 44.35 toks/s]
Processed prompts:  78%|███████▊  | 3212/4096 [01:12<00:22, 38.63it/s, est. speed input: 45348.87 toks/s, output: 44.29 toks/s]
Processed prompts:  79%|███████▉  | 3244/4096 [01:13<00:22, 38.66it/s, est. speed input: 45284.88 toks/s, output: 44.22 toks/s]
Processed prompts:  80%|███████▉  | 3276/4096 [01:14<00:21, 38.62it/s, est. speed input: 45219.23 toks/s, output: 44.16 toks/s]
Processed prompts:  81%|████████  | 3308/4096 [01:15<00:20, 38.59it/s, est. speed input: 45155.28 toks/s, output: 44.10 toks/s]
Processed prompts:  82%|████████▏ | 3340/4096 [01:15<00:19, 38.55it/s, est. speed input: 45091.90 toks/s, output: 44.04 toks/s]
Processed prompts:  82%|████████▏ | 3372/4096 [01:16<00:18, 38.55it/s, est. speed input: 45031.35 toks/s, output: 43.98 toks/s]
Processed prompts:  83%|████████▎ | 3404/4096 [01:17<00:17, 38.56it/s, est. speed input: 44972.00 toks/s, output: 43.92 toks/s]
Processed prompts:  84%|████████▍ | 3436/4096 [01:18<00:17, 38.59it/s, est. speed input: 44915.28 toks/s, output: 43.86 toks/s]
Processed prompts:  85%|████████▍ | 3468/4096 [01:19<00:16, 38.58it/s, est. speed input: 44858.44 toks/s, output: 43.81 toks/s]
Processed prompts:  85%|████████▌ | 3500/4096 [01:19<00:15, 38.58it/s, est. speed input: 44802.93 toks/s, output: 43.75 toks/s]
Processed prompts:  86%|████████▌ | 3532/4096 [01:20<00:14, 38.53it/s, est. speed input: 44746.36 toks/s, output: 43.70 toks/s]
Processed prompts:  87%|████████▋ | 3564/4096 [01:21<00:13, 38.83it/s, est. speed input: 44704.18 toks/s, output: 43.66 toks/s]
Processed prompts:  88%|████████▊ | 3596/4096 [01:22<00:12, 38.75it/s, est. speed input: 44651.88 toks/s, output: 43.61 toks/s]
Processed prompts:  89%|████████▊ | 3628/4096 [01:23<00:12, 38.70it/s, est. speed input: 44600.49 toks/s, output: 43.56 toks/s]
Processed prompts:  89%|████████▉ | 3660/4096 [01:24<00:11, 38.93it/s, est. speed input: 44560.19 toks/s, output: 43.52 toks/s]
Processed prompts:  90%|█████████ | 3692/4096 [01:24<00:10, 38.79it/s, est. speed input: 44509.53 toks/s, output: 43.47 toks/s]
Processed prompts:  91%|█████████ | 3724/4096 [01:25<00:09, 38.69it/s, est. speed input: 44459.81 toks/s, output: 43.42 toks/s]
Processed prompts:  92%|█████████▏| 3756/4096 [01:26<00:08, 38.63it/s, est. speed input: 44411.28 toks/s, output: 43.37 toks/s]
Processed prompts:  92%|█████████▏| 3788/4096 [01:27<00:07, 38.59it/s, est. speed input: 44364.02 toks/s, output: 43.32 toks/s]
Processed prompts:  93%|█████████▎| 3820/4096 [01:28<00:07, 38.54it/s, est. speed input: 44316.70 toks/s, output: 43.28 toks/s]
Processed prompts:  94%|█████████▍| 3852/4096 [01:29<00:06, 38.51it/s, est. speed input: 44270.46 toks/s, output: 43.23 toks/s]
Processed prompts:  95%|█████████▍| 3884/4096 [01:29<00:05, 38.50it/s, est. speed input: 44225.43 toks/s, output: 43.19 toks/s]
Processed prompts:  96%|█████████▌| 3916/4096 [01:30<00:04, 39.18it/s, est. speed input: 44204.98 toks/s, output: 43.17 toks/s]
Processed prompts:  96%|█████████▋| 3948/4096 [01:31<00:03, 38.94it/s, est. speed input: 44160.22 toks/s, output: 43.13 toks/s]
Processed prompts:  97%|█████████▋| 3980/4096 [01:32<00:02, 39.12it/s, est. speed input: 44128.02 toks/s, output: 43.09 toks/s]
Processed prompts:  98%|█████████▊| 4012/4096 [01:33<00:02, 38.92it/s, est. speed input: 44085.86 toks/s, output: 43.05 toks/s]
Processed prompts:  99%|█████████▊| 4044/4096 [01:33<00:01, 39.09it/s, est. speed input: 44054.41 toks/s, output: 43.02 toks/s]
Processed prompts: 100%|█████████▉| 4076/4096 [01:34<00:00, 43.84it/s, est. speed input: 44157.40 toks/s, output: 43.12 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:34<00:00, 43.84it/s, est. speed input: 44373.67 toks/s, output: 43.33 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:34<00:00, 43.33it/s, est. speed input: 44373.67 toks/s, output: 43.33 toks/s]
[rank0]:[W126 11:41:56.538679793 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 11:41:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:42:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1303467) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1303467) WARNING 01-26 11:43:06 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     def forward(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     raise e
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/tmp/torchinductor_root/h2/ch2f2fl72d437f7nhefu4ztoxpftxl7zqo6tizg6tnqnowdjohtd.py", line 1093, in call
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 339, in quant_slide_int8_triton
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) ERROR 01-26 11:43:14 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered

STDERR:
[2026-01-26 11:42:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:42:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:42:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:42:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:42:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:42:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:42:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:42:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:42:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:42:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:42:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 11:42:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 11:42:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:42:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:42:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:42:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:42:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1303467) [2026-01-26 11:42:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1303467) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1303467) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.85it/s]
(EngineCore_DP0 pid=1303467) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1303467) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1303467) 
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16588800 bytes
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12902400 bytes
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 136396800 bytes
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1303467) [2026-01-26 11:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 67952640 bytes
(EngineCore_DP0 pid=1303467) [rank0]:W0126 11:43:12.167000 1303467 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1303467) [rank0]:W0126 11:43:12.245000 1303467 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1303467) [rank0]:W0126 11:43:13.635000 1303467 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1303467) [rank0]:W0126 11:43:13.759000 1303467 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1303467) Process EngineCore_DP0:
(EngineCore_DP0 pid=1303467) Traceback (most recent call last):
(EngineCore_DP0 pid=1303467)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1303467)     self.run()
(EngineCore_DP0 pid=1303467)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1303467)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1303467)     raise e
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1303467)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1303467)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1303467)     super().__init__(
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1303467)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1303467)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1303467)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1303467)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1303467)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1303467)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1303467)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1303467)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1303467)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1303467)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1303467)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1303467)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1303467)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1303467)     outputs = self.model(
(EngineCore_DP0 pid=1303467)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1303467)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1303467)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1303467)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1303467)     hidden_states = self.model(
(EngineCore_DP0 pid=1303467)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1303467)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1303467)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1303467)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1303467)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1303467)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1303467)     def forward(
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1303467)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1303467)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1303467)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1303467)     raise e
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1303467)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1303467)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1303467)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1303467)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1303467)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1303467)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1303467)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1303467)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1303467)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1303467)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1303467)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1303467)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1303467)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1303467)                             ^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1303467)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1303467)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1303467)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1303467)     out = model(new_inputs)
(EngineCore_DP0 pid=1303467)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/tmp/torchinductor_root/h2/ch2f2fl72d437f7nhefu4ztoxpftxl7zqo6tizg6tnqnowdjohtd.py", line 1093, in call
(EngineCore_DP0 pid=1303467)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=1303467)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1303467)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1303467)     return fn(input, L)
(EngineCore_DP0 pid=1303467)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 339, in quant_slide_int8_triton
(EngineCore_DP0 pid=1303467)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1303467)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1303467)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1303467)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1303467)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1303467)     self._init_handles()
(EngineCore_DP0 pid=1303467)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1303467)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1303467)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1303467) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 11:43:15.599334067 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 13:54:11
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:54:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1445368) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1445368) WARNING 01-26 13:54:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.65 requests/s, 11616.99 total tokens/s, 22.65 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 13:54:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:54:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:54:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:54:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:54:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:54:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:54:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:54:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:54:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:54:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:54:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:54:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:54:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:54:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:54:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:54:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:54:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.19it/s]
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.11it/s]
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.54it/s]
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1445368) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.34it/s]
(EngineCore_DP0 pid=1445368) 
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1445368) [2026-01-26 13:54:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1445368) 2026-01-26 13:54:54,000 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1445368) 2026-01-26 13:54:54,049 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1445368) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]
(EngineCore_DP0 pid=1445368) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  27%|██▋       | 35/128 [00:00<00:00, 348.05it/s]
Adding requests:  78%|███████▊  | 100/128 [00:00<00:00, 524.43it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 532.95it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:21,  5.95it/s, est. speed input: 3046.81 toks/s, output: 5.95 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:08, 15.36it/s, est. speed input: 7029.28 toks/s, output: 13.73 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 19.22it/s, est. speed input: 8667.70 toks/s, output: 16.93 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 21.25it/s, est. speed input: 9564.89 toks/s, output: 18.68 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 22.38it/s, est. speed input: 10118.21 toks/s, output: 19.76 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 23.06it/s, est. speed input: 10493.53 toks/s, output: 20.49 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 23.51it/s, est. speed input: 10768.73 toks/s, output: 21.03 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 23.82it/s, est. speed input: 10980.83 toks/s, output: 21.45 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 24.02it/s, est. speed input: 11146.16 toks/s, output: 21.77 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 24.19it/s, est. speed input: 11283.78 toks/s, output: 22.04 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:03, 24.30it/s, est. speed input: 11396.92 toks/s, output: 22.26 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:03, 24.35it/s, est. speed input: 11488.06 toks/s, output: 22.44 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 24.39it/s, est. speed input: 11566.67 toks/s, output: 22.59 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 24.43it/s, est. speed input: 11634.88 toks/s, output: 22.72 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 24.47it/s, est. speed input: 11695.65 toks/s, output: 22.84 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 24.46it/s, est. speed input: 11745.59 toks/s, output: 22.94 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 24.34it/s, est. speed input: 11779.10 toks/s, output: 23.01 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 24.22it/s, est. speed input: 11806.16 toks/s, output: 23.06 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 24.12it/s, est. speed input: 11828.53 toks/s, output: 23.10 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 24.05it/s, est. speed input: 11848.37 toks/s, output: 23.14 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 23.99it/s, est. speed input: 11865.85 toks/s, output: 23.18 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 23.97it/s, est. speed input: 11883.10 toks/s, output: 23.21 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:02<00:02, 23.92it/s, est. speed input: 11896.85 toks/s, output: 23.24 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 23.79it/s, est. speed input: 11902.23 toks/s, output: 23.25 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 23.75it/s, est. speed input: 11910.75 toks/s, output: 23.26 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.79it/s, est. speed input: 11922.70 toks/s, output: 23.29 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.81it/s, est. speed input: 11933.65 toks/s, output: 23.31 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 23.83it/s, est. speed input: 11944.06 toks/s, output: 23.33 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 23.81it/s, est. speed input: 11951.85 toks/s, output: 23.34 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 23.80it/s, est. speed input: 11959.06 toks/s, output: 23.36 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:03<00:01, 23.79it/s, est. speed input: 11965.98 toks/s, output: 23.37 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.79it/s, est. speed input: 11972.73 toks/s, output: 23.38 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.79it/s, est. speed input: 11978.93 toks/s, output: 23.40 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.80it/s, est. speed input: 11985.54 toks/s, output: 23.41 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 24.02it/s, est. speed input: 12001.49 toks/s, output: 23.44 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 24.18it/s, est. speed input: 12017.20 toks/s, output: 23.47 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 24.30it/s, est. speed input: 12032.02 toks/s, output: 23.50 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 24.40it/s, est. speed input: 12046.85 toks/s, output: 23.53 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:04<00:00, 24.46it/s, est. speed input: 12060.65 toks/s, output: 23.56 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 24.52it/s, est. speed input: 12074.44 toks/s, output: 23.58 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 24.55it/s, est. speed input: 12086.96 toks/s, output: 23.61 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 24.57it/s, est. speed input: 12099.02 toks/s, output: 23.63 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 24.55it/s, est. speed input: 12109.28 toks/s, output: 23.65 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.55it/s, est. speed input: 12112.97 toks/s, output: 23.66 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.66it/s, est. speed input: 12112.97 toks/s, output: 23.66 toks/s]
[rank0]:[W126 13:55:02.824952893 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 13:55:04
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:55:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1446674) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1446674) WARNING 01-26 13:55:35 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.05 requests/s, 17472.15 total tokens/s, 17.05 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 13:55:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:55:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:55:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:55:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:55:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:55:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:55:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:55:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:55:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:55:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:55:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:55:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:55:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:55:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:55:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:55:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:55:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.20it/s]
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.11it/s]
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1446674) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1446674) 
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1446674) [2026-01-26 13:55:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1446674) 2026-01-26 13:55:49,163 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1446674) 2026-01-26 13:55:49,230 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1446674) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.91it/s]
(EngineCore_DP0 pid=1446674) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 11.03it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  21%|██        | 27/128 [00:00<00:00, 269.34it/s]
Adding requests:  52%|█████▏    | 67/128 [00:00<00:00, 344.56it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 352.21it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 347.71it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:08, 14.35it/s, est. speed input: 14698.10 toks/s, output: 14.35 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:07, 16.78it/s, est. speed input: 16755.06 toks/s, output: 16.36 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:06, 17.58it/s, est. speed input: 17469.35 toks/s, output: 17.06 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 17.92it/s, est. speed input: 17807.95 toks/s, output: 17.39 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:06, 17.98it/s, est. speed input: 17947.76 toks/s, output: 17.53 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:06, 18.04it/s, est. speed input: 18049.44 toks/s, output: 17.63 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 18.08it/s, est. speed input: 18128.68 toks/s, output: 17.70 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 18.09it/s, est. speed input: 18179.01 toks/s, output: 17.75 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:06, 17.78it/s, est. speed input: 18107.69 toks/s, output: 17.68 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 17.84it/s, est. speed input: 18136.61 toks/s, output: 17.71 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 17.89it/s, est. speed input: 18162.13 toks/s, output: 17.74 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 17.95it/s, est. speed input: 18193.63 toks/s, output: 17.77 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.97it/s, est. speed input: 18212.17 toks/s, output: 17.78 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 18.02it/s, est. speed input: 18236.62 toks/s, output: 17.81 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 18.05it/s, est. speed input: 18257.35 toks/s, output: 17.83 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 18.04it/s, est. speed input: 18270.23 toks/s, output: 17.84 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 18.00it/s, est. speed input: 18274.19 toks/s, output: 17.85 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 17.90it/s, est. speed input: 18263.15 toks/s, output: 17.83 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 17.91it/s, est. speed input: 18268.93 toks/s, output: 17.84 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:04, 17.92it/s, est. speed input: 18274.18 toks/s, output: 17.85 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 17.93it/s, est. speed input: 18279.04 toks/s, output: 17.85 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.98it/s, est. speed input: 18291.25 toks/s, output: 17.86 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 18.00it/s, est. speed input: 18299.52 toks/s, output: 17.87 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 18.09it/s, est. speed input: 18317.02 toks/s, output: 17.89 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 18.02it/s, est. speed input: 18316.07 toks/s, output: 17.89 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 18.00it/s, est. speed input: 18319.23 toks/s, output: 17.89 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 17.95it/s, est. speed input: 18317.11 toks/s, output: 17.89 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 17.97it/s, est. speed input: 18321.26 toks/s, output: 17.89 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:03, 17.94it/s, est. speed input: 18320.50 toks/s, output: 17.89 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.96it/s, est. speed input: 18324.82 toks/s, output: 17.90 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.98it/s, est. speed input: 18329.48 toks/s, output: 17.90 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.97it/s, est. speed input: 18330.66 toks/s, output: 17.90 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 18.05it/s, est. speed input: 18341.12 toks/s, output: 17.91 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 18.01it/s, est. speed input: 18341.59 toks/s, output: 17.91 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.98it/s, est. speed input: 18341.30 toks/s, output: 17.91 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 17.94it/s, est. speed input: 18339.05 toks/s, output: 17.91 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 17.95it/s, est. speed input: 18341.34 toks/s, output: 17.91 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:02, 17.96it/s, est. speed input: 18342.88 toks/s, output: 17.91 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.91it/s, est. speed input: 18340.12 toks/s, output: 17.91 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.94it/s, est. speed input: 18342.86 toks/s, output: 17.91 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.96it/s, est. speed input: 18345.09 toks/s, output: 17.91 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 18.07it/s, est. speed input: 18354.81 toks/s, output: 17.92 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 17.96it/s, est. speed input: 18349.99 toks/s, output: 17.92 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 17.92it/s, est. speed input: 18347.83 toks/s, output: 17.92 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 17.93it/s, est. speed input: 18348.62 toks/s, output: 17.92 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.92it/s, est. speed input: 18348.22 toks/s, output: 17.92 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.95it/s, est. speed input: 18350.31 toks/s, output: 17.92 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.92it/s, est. speed input: 18349.07 toks/s, output: 17.92 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.94it/s, est. speed input: 18350.28 toks/s, output: 17.92 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.96it/s, est. speed input: 18352.06 toks/s, output: 17.92 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 18.01it/s, est. speed input: 18356.03 toks/s, output: 17.93 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 18.00it/s, est. speed input: 18357.31 toks/s, output: 17.93 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 17.97it/s, est. speed input: 18356.44 toks/s, output: 17.93 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.96it/s, est. speed input: 18356.47 toks/s, output: 17.93 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.92it/s, est. speed input: 18355.04 toks/s, output: 17.92 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.95it/s, est. speed input: 18356.67 toks/s, output: 17.93 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.93it/s, est. speed input: 18355.57 toks/s, output: 17.93 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.94it/s, est. speed input: 18356.49 toks/s, output: 17.93 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 18.00it/s, est. speed input: 18360.27 toks/s, output: 17.93 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.97it/s, est. speed input: 18359.90 toks/s, output: 17.93 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 17.95it/s, est. speed input: 18359.56 toks/s, output: 17.93 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 17.93it/s, est. speed input: 18358.73 toks/s, output: 17.93 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.95it/s, est. speed input: 18359.82 toks/s, output: 17.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.94it/s, est. speed input: 18359.44 toks/s, output: 17.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.94it/s, est. speed input: 18359.44 toks/s, output: 17.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.93it/s, est. speed input: 18359.44 toks/s, output: 17.93 toks/s]
[rank0]:[W126 13:55:58.930853231 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 13:56:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:56:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1447956) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1447956) WARNING 01-26 13:56:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.30 requests/s, 19785.13 total tokens/s, 19.30 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 13:56:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:56:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:56:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:56:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:56:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:56:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:56:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:56:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:56:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:56:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:56:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:56:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:56:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:56:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:56:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:56:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:56:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.20it/s]
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.12it/s]
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1447956) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.34it/s]
(EngineCore_DP0 pid=1447956) 
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1447956) [2026-01-26 13:56:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1447956) 2026-01-26 13:56:44,242 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1447956) 2026-01-26 13:56:44,282 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1447956) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  4.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  2.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.47it/s]
(EngineCore_DP0 pid=1447956) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.02it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 209.03it/s]
Adding requests:  24%|██▍       | 62/256 [00:00<00:00, 326.01it/s]
Adding requests:  38%|███▊      | 98/256 [00:00<00:00, 340.06it/s]
Adding requests:  53%|█████▎    | 136/256 [00:00<00:00, 354.63it/s]
Adding requests:  69%|██████▉   | 176/256 [00:00<00:00, 367.30it/s]
Adding requests:  84%|████████▍ | 216/256 [00:00<00:00, 375.55it/s]
Adding requests:  99%|█████████▉| 254/256 [00:00<00:00, 376.46it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 358.52it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:00<00:02, 86.74it/s, est. speed input: 88840.41 toks/s, output: 86.74 toks/s]
Processed prompts:   8%|▊         | 21/256 [00:00<00:06, 34.36it/s, est. speed input: 39250.40 toks/s, output: 38.33 toks/s]
Processed prompts:  10%|█         | 26/256 [00:00<00:08, 25.88it/s, est. speed input: 31058.20 toks/s, output: 30.33 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:01<00:09, 24.00it/s, est. speed input: 28974.74 toks/s, output: 28.29 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:01<00:08, 24.98it/s, est. speed input: 29079.58 toks/s, output: 28.40 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:10, 21.58it/s, est. speed input: 27028.85 toks/s, output: 26.39 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:01<00:09, 23.09it/s, est. speed input: 27234.32 toks/s, output: 26.60 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:01<00:10, 19.96it/s, est. speed input: 25694.13 toks/s, output: 25.09 toks/s]
Processed prompts:  18%|█▊        | 45/256 [00:01<00:09, 21.82it/s, est. speed input: 25927.98 toks/s, output: 25.32 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:10, 19.21it/s, est. speed input: 24806.02 toks/s, output: 24.22 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:02<00:09, 21.38it/s, est. speed input: 25081.85 toks/s, output: 24.49 toks/s]
Processed prompts:  21%|██        | 54/256 [00:02<00:10, 18.93it/s, est. speed input: 24197.48 toks/s, output: 23.63 toks/s]
Processed prompts:  22%|██▏       | 57/256 [00:02<00:09, 21.18it/s, est. speed input: 24460.66 toks/s, output: 23.89 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:10, 18.71it/s, est. speed input: 23712.31 toks/s, output: 23.16 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:02<00:09, 20.91it/s, est. speed input: 23941.38 toks/s, output: 23.38 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:10, 18.51it/s, est. speed input: 23300.97 toks/s, output: 22.75 toks/s]
Processed prompts:  27%|██▋       | 69/256 [00:03<00:08, 20.82it/s, est. speed input: 23533.14 toks/s, output: 22.98 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:09, 18.59it/s, est. speed input: 23008.72 toks/s, output: 22.47 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:03<00:08, 20.92it/s, est. speed input: 23233.18 toks/s, output: 22.69 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 18.56it/s, est. speed input: 22756.21 toks/s, output: 22.22 toks/s]
Processed prompts:  32%|███▏      | 81/256 [00:03<00:08, 20.84it/s, est. speed input: 22959.77 toks/s, output: 22.42 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:09, 18.43it/s, est. speed input: 22522.19 toks/s, output: 21.99 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:03<00:08, 20.71it/s, est. speed input: 22713.57 toks/s, output: 22.18 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:04<00:08, 18.52it/s, est. speed input: 22346.41 toks/s, output: 21.82 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:04<00:07, 20.85it/s, est. speed input: 22535.22 toks/s, output: 22.01 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 18.55it/s, est. speed input: 22194.78 toks/s, output: 21.67 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:04<00:07, 20.84it/s, est. speed input: 22370.50 toks/s, output: 21.85 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:08, 18.44it/s, est. speed input: 22044.91 toks/s, output: 21.53 toks/s]
Processed prompts:  41%|████      | 105/256 [00:04<00:07, 20.72it/s, est. speed input: 22210.02 toks/s, output: 21.69 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:05<00:08, 18.43it/s, est. speed input: 21917.17 toks/s, output: 21.40 toks/s]
Processed prompts:  43%|████▎     | 111/256 [00:05<00:06, 20.73it/s, est. speed input: 22076.90 toks/s, output: 21.56 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:07, 18.49it/s, est. speed input: 21813.64 toks/s, output: 21.30 toks/s]
Processed prompts:  46%|████▌     | 117/256 [00:05<00:06, 20.78it/s, est. speed input: 21965.81 toks/s, output: 21.45 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:07, 18.46it/s, est. speed input: 21713.62 toks/s, output: 21.20 toks/s]
Processed prompts:  48%|████▊     | 123/256 [00:05<00:06, 20.74it/s, est. speed input: 21858.93 toks/s, output: 21.35 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:05<00:07, 18.47it/s, est. speed input: 21626.20 toks/s, output: 21.12 toks/s]
Processed prompts:  50%|█████     | 129/256 [00:06<00:06, 20.75it/s, est. speed input: 21766.01 toks/s, output: 21.26 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:06<00:06, 18.45it/s, est. speed input: 21545.65 toks/s, output: 21.04 toks/s]
Processed prompts:  53%|█████▎    | 135/256 [00:06<00:05, 20.74it/s, est. speed input: 21680.06 toks/s, output: 21.17 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:06<00:06, 18.39it/s, est. speed input: 21467.96 toks/s, output: 20.96 toks/s]
Processed prompts:  55%|█████▌    | 141/256 [00:06<00:05, 20.68it/s, est. speed input: 21596.24 toks/s, output: 21.09 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:06, 18.41it/s, est. speed input: 21400.72 toks/s, output: 20.90 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:06<00:05, 20.72it/s, est. speed input: 21526.70 toks/s, output: 21.02 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:07<00:05, 18.43it/s, est. speed input: 21341.23 toks/s, output: 20.84 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:07<00:04, 20.75it/s, est. speed input: 21463.16 toks/s, output: 20.96 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:05, 18.42it/s, est. speed input: 21285.14 toks/s, output: 20.79 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:07<00:04, 20.71it/s, est. speed input: 21401.30 toks/s, output: 20.90 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:07<00:05, 18.44it/s, est. speed input: 21234.36 toks/s, output: 20.74 toks/s]
Processed prompts:  64%|██████▍   | 165/256 [00:07<00:04, 20.71it/s, est. speed input: 21345.60 toks/s, output: 20.85 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:08<00:04, 18.42it/s, est. speed input: 21185.12 toks/s, output: 20.69 toks/s]
Processed prompts:  67%|██████▋   | 171/256 [00:08<00:04, 20.72it/s, est. speed input: 21294.40 toks/s, output: 20.80 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:08<00:04, 18.45it/s, est. speed input: 21143.47 toks/s, output: 20.65 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:08<00:03, 20.80it/s, est. speed input: 21251.85 toks/s, output: 20.75 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:08<00:04, 18.43it/s, est. speed input: 21102.50 toks/s, output: 20.61 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:08<00:03, 20.72it/s, est. speed input: 21204.51 toks/s, output: 20.71 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:09<00:03, 18.42it/s, est. speed input: 21063.21 toks/s, output: 20.57 toks/s]
Processed prompts:  74%|███████▍  | 189/256 [00:09<00:03, 20.71it/s, est. speed input: 21162.50 toks/s, output: 20.67 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:09<00:03, 18.45it/s, est. speed input: 21029.39 toks/s, output: 20.54 toks/s]
Processed prompts:  76%|███████▌  | 195/256 [00:09<00:02, 20.79it/s, est. speed input: 21127.99 toks/s, output: 20.63 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:09<00:03, 18.42it/s, est. speed input: 20995.40 toks/s, output: 20.50 toks/s]
Processed prompts:  79%|███████▊  | 201/256 [00:09<00:02, 20.71it/s, est. speed input: 21088.58 toks/s, output: 20.59 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:09<00:02, 19.86it/s, est. speed input: 21046.75 toks/s, output: 20.55 toks/s]
Processed prompts:  81%|████████  | 207/256 [00:10<00:02, 21.99it/s, est. speed input: 21138.44 toks/s, output: 20.64 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:10<00:02, 19.12it/s, est. speed input: 21015.82 toks/s, output: 20.52 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:10<00:02, 21.32it/s, est. speed input: 21103.69 toks/s, output: 20.61 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:10<00:02, 18.74it/s, est. speed input: 20984.36 toks/s, output: 20.49 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:10<00:01, 20.99it/s, est. speed input: 21069.90 toks/s, output: 20.58 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:10<00:01, 18.52it/s, est. speed input: 20952.32 toks/s, output: 20.46 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:10<00:01, 20.82it/s, est. speed input: 21037.08 toks/s, output: 20.54 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:11<00:01, 18.47it/s, est. speed input: 20925.43 toks/s, output: 20.43 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:11<00:01, 20.76it/s, est. speed input: 21007.40 toks/s, output: 20.52 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:11<00:01, 18.48it/s, est. speed input: 20901.82 toks/s, output: 20.41 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:11<00:00, 20.77it/s, est. speed input: 20981.63 toks/s, output: 20.49 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:11<00:00, 18.45it/s, est. speed input: 20877.24 toks/s, output: 20.39 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:11<00:00, 20.72it/s, est. speed input: 20954.53 toks/s, output: 20.46 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:12<00:00, 18.38it/s, est. speed input: 20851.24 toks/s, output: 20.36 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:12<00:00, 20.66it/s, est. speed input: 20926.58 toks/s, output: 20.44 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:12<00:00, 18.45it/s, est. speed input: 20831.45 toks/s, output: 20.34 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:12<00:00, 20.77it/s, est. speed input: 20907.19 toks/s, output: 20.42 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.77it/s, est. speed input: 20893.69 toks/s, output: 20.40 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.40it/s, est. speed input: 20893.69 toks/s, output: 20.40 toks/s]
[rank0]:[W126 13:57:00.587044852 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 13:57:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:57:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1449319) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1449319) WARNING 01-26 13:57:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.01 requests/s, 20512.00 total tokens/s, 20.01 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 13:57:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:57:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:57:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:57:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:57:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:57:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:57:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:57:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:57:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:57:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:57:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:57:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:57:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:57:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:57:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:57:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:57:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.21it/s]
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.12it/s]
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1449319) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1449319) 
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1449319) [2026-01-26 13:57:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1449319) 2026-01-26 13:57:47,485 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1449319) 2026-01-26 13:57:47,541 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1449319) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:01,  2.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  2.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  4.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.73it/s]
(EngineCore_DP0 pid=1449319) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 11.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.67it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 20/512 [00:00<00:02, 199.95it/s]
Adding requests:  12%|█▏        | 60/512 [00:00<00:01, 317.55it/s]
Adding requests:  19%|█▉        | 96/512 [00:00<00:01, 335.82it/s]
Adding requests:  26%|██▌       | 134/512 [00:00<00:01, 351.59it/s]
Adding requests:  34%|███▍      | 174/512 [00:00<00:00, 367.02it/s]
Adding requests:  42%|████▏     | 214/512 [00:00<00:00, 377.29it/s]
Adding requests:  49%|████▉     | 253/512 [00:00<00:00, 378.91it/s]
Adding requests:  57%|█████▋    | 293/512 [00:00<00:00, 382.05it/s]
Adding requests:  65%|██████▌   | 335/512 [00:00<00:00, 391.67it/s]
Adding requests:  73%|███████▎  | 375/512 [00:01<00:00, 393.09it/s]
Adding requests:  81%|████████▏ | 417/512 [00:01<00:00, 399.96it/s]
Adding requests:  89%|████████▉ | 457/512 [00:01<00:00, 395.69it/s]
Adding requests:  98%|█████████▊| 500/512 [00:01<00:00, 403.56it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 379.77it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:00<00:03, 131.37it/s, est. speed input: 134536.77 toks/s, output: 131.37 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:00<00:10, 43.88it/s, est. speed input: 51637.69 toks/s, output: 50.43 toks/s]   
Processed prompts:   9%|▉         | 47/512 [00:01<00:14, 32.38it/s, est. speed input: 40380.33 toks/s, output: 39.43 toks/s]
Processed prompts:  10%|█         | 52/512 [00:01<00:14, 30.79it/s, est. speed input: 38387.95 toks/s, output: 37.49 toks/s]
Processed prompts:  11%|█         | 56/512 [00:01<00:16, 28.15it/s, est. speed input: 36203.76 toks/s, output: 35.35 toks/s]
Processed prompts:  12%|█▏        | 60/512 [00:01<00:17, 25.92it/s, est. speed input: 34413.60 toks/s, output: 33.61 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:01<00:19, 22.81it/s, est. speed input: 32447.99 toks/s, output: 31.69 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:21, 20.66it/s, est. speed input: 30912.24 toks/s, output: 30.19 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:21, 20.57it/s, est. speed input: 30080.61 toks/s, output: 29.38 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:21, 20.54it/s, est. speed input: 29389.80 toks/s, output: 28.70 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:21, 20.41it/s, est. speed input: 28758.59 toks/s, output: 28.08 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:21, 20.19it/s, est. speed input: 28172.71 toks/s, output: 27.51 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:21, 20.15it/s, est. speed input: 27694.02 toks/s, output: 27.04 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:20, 20.22it/s, est. speed input: 27297.06 toks/s, output: 26.66 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:20, 20.26it/s, est. speed input: 26941.45 toks/s, output: 26.31 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:20, 20.16it/s, est. speed input: 26593.99 toks/s, output: 25.97 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:20, 20.05it/s, est. speed input: 26273.46 toks/s, output: 25.66 toks/s]
Processed prompts:  21%|██        | 106/512 [00:04<00:20, 20.11it/s, est. speed input: 26012.07 toks/s, output: 25.40 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:04<00:19, 20.12it/s, est. speed input: 25766.70 toks/s, output: 25.16 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:19, 20.12it/s, est. speed input: 25542.54 toks/s, output: 24.94 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:19, 20.05it/s, est. speed input: 25324.85 toks/s, output: 24.73 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:19, 19.99it/s, est. speed input: 25121.91 toks/s, output: 24.53 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:05<00:19, 20.02it/s, est. speed input: 24947.53 toks/s, output: 24.36 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:05<00:19, 20.06it/s, est. speed input: 24787.94 toks/s, output: 24.21 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:18, 20.07it/s, est. speed input: 24637.72 toks/s, output: 24.06 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:18, 20.04it/s, est. speed input: 24492.67 toks/s, output: 23.92 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:18, 19.95it/s, est. speed input: 24347.07 toks/s, output: 23.78 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:06<00:18, 19.95it/s, est. speed input: 24219.33 toks/s, output: 23.65 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:06<00:18, 19.99it/s, est. speed input: 24105.55 toks/s, output: 23.54 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:17, 20.08it/s, est. speed input: 24005.38 toks/s, output: 23.44 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:17, 20.01it/s, est. speed input: 23896.30 toks/s, output: 23.34 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:17, 20.00it/s, est. speed input: 23797.72 toks/s, output: 23.24 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:07<00:17, 20.00it/s, est. speed input: 23705.13 toks/s, output: 23.15 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:07<00:17, 20.00it/s, est. speed input: 23617.20 toks/s, output: 23.06 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:16, 20.01it/s, est. speed input: 23535.60 toks/s, output: 22.98 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:16, 19.97it/s, est. speed input: 23452.89 toks/s, output: 22.90 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:16, 20.03it/s, est. speed input: 23383.63 toks/s, output: 22.84 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:08<00:16, 20.02it/s, est. speed input: 23312.13 toks/s, output: 22.77 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:08<00:16, 20.03it/s, est. speed input: 23245.98 toks/s, output: 22.70 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:15, 19.99it/s, est. speed input: 23179.06 toks/s, output: 22.64 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:15, 19.93it/s, est. speed input: 23111.56 toks/s, output: 22.57 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:14, 21.25it/s, est. speed input: 23158.31 toks/s, output: 22.62 toks/s]
Processed prompts:  40%|████      | 206/512 [00:09<00:14, 20.90it/s, est. speed input: 23103.18 toks/s, output: 22.56 toks/s]
Processed prompts:  41%|████      | 210/512 [00:09<00:14, 20.61it/s, est. speed input: 23045.82 toks/s, output: 22.51 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:09<00:14, 20.45it/s, est. speed input: 22993.90 toks/s, output: 22.45 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:14, 20.23it/s, est. speed input: 22936.29 toks/s, output: 22.40 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:14, 20.20it/s, est. speed input: 22889.58 toks/s, output: 22.35 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:10<00:14, 20.10it/s, est. speed input: 22839.35 toks/s, output: 22.30 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:10<00:14, 20.09it/s, est. speed input: 22795.18 toks/s, output: 22.26 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:10<00:13, 20.07it/s, est. speed input: 22751.47 toks/s, output: 22.22 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:13, 20.02it/s, est. speed input: 22706.94 toks/s, output: 22.17 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:13, 19.99it/s, est. speed input: 22664.79 toks/s, output: 22.13 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:11<00:13, 20.00it/s, est. speed input: 22626.13 toks/s, output: 22.10 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:11<00:13, 20.02it/s, est. speed input: 22589.54 toks/s, output: 22.06 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:11<00:12, 20.02it/s, est. speed input: 22553.16 toks/s, output: 22.02 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:12, 20.01it/s, est. speed input: 22517.39 toks/s, output: 21.99 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:12, 20.04it/s, est. speed input: 22485.59 toks/s, output: 21.96 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:12<00:12, 20.06it/s, est. speed input: 22454.42 toks/s, output: 21.93 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:12<00:12, 20.06it/s, est. speed input: 22423.27 toks/s, output: 21.90 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:12<00:11, 20.09it/s, est. speed input: 22395.01 toks/s, output: 21.87 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:12<00:11, 20.05it/s, est. speed input: 22364.34 toks/s, output: 21.84 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:11, 20.05it/s, est. speed input: 22336.21 toks/s, output: 21.81 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:13<00:11, 20.08it/s, est. speed input: 22310.20 toks/s, output: 21.79 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:13<00:11, 20.07it/s, est. speed input: 22283.80 toks/s, output: 21.76 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:13<00:10, 20.11it/s, est. speed input: 22260.46 toks/s, output: 21.74 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:13<00:10, 20.16it/s, est. speed input: 22238.72 toks/s, output: 21.72 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:10, 20.16it/s, est. speed input: 22216.05 toks/s, output: 21.70 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:14<00:10, 20.16it/s, est. speed input: 22194.01 toks/s, output: 21.67 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:14<00:10, 20.12it/s, est. speed input: 22170.70 toks/s, output: 21.65 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:14<00:09, 20.10it/s, est. speed input: 22148.21 toks/s, output: 21.63 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:14<00:09, 20.09it/s, est. speed input: 22126.73 toks/s, output: 21.61 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:09, 20.06it/s, est. speed input: 22104.43 toks/s, output: 21.59 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:15<00:09, 20.12it/s, est. speed input: 22086.70 toks/s, output: 21.57 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:15<00:09, 20.13it/s, est. speed input: 22068.05 toks/s, output: 21.55 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:15<00:08, 20.09it/s, est. speed input: 22047.62 toks/s, output: 21.53 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:15<00:08, 20.12it/s, est. speed input: 22030.13 toks/s, output: 21.51 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:15<00:08, 20.05it/s, est. speed input: 22009.01 toks/s, output: 21.49 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:16<00:08, 20.08it/s, est. speed input: 21992.20 toks/s, output: 21.48 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:16<00:08, 20.06it/s, est. speed input: 21973.63 toks/s, output: 21.46 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:16<00:07, 20.05it/s, est. speed input: 21956.00 toks/s, output: 21.44 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:16<00:07, 20.10it/s, est. speed input: 21941.13 toks/s, output: 21.43 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:16<00:07, 20.03it/s, est. speed input: 21922.27 toks/s, output: 21.41 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:17<00:07, 20.08it/s, est. speed input: 21907.64 toks/s, output: 21.39 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:17<00:07, 20.13it/s, est. speed input: 21894.34 toks/s, output: 21.38 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:17<00:06, 20.13it/s, est. speed input: 21879.79 toks/s, output: 21.37 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:17<00:06, 20.12it/s, est. speed input: 21865.08 toks/s, output: 21.35 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:17<00:06, 20.11it/s, est. speed input: 21850.94 toks/s, output: 21.34 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:18<00:06, 20.11it/s, est. speed input: 21837.11 toks/s, output: 21.33 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:18<00:06, 20.07it/s, est. speed input: 21821.99 toks/s, output: 21.31 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:18<00:05, 20.09it/s, est. speed input: 21809.04 toks/s, output: 21.30 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:18<00:05, 20.13it/s, est. speed input: 21797.35 toks/s, output: 21.29 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:18<00:05, 20.17it/s, est. speed input: 21786.32 toks/s, output: 21.28 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:19<00:05, 20.16it/s, est. speed input: 21774.34 toks/s, output: 21.26 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:19<00:05, 20.11it/s, est. speed input: 21760.74 toks/s, output: 21.25 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:19<00:04, 20.10it/s, est. speed input: 21748.64 toks/s, output: 21.24 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:19<00:04, 20.10it/s, est. speed input: 21736.84 toks/s, output: 21.23 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:19<00:04, 20.06it/s, est. speed input: 21723.95 toks/s, output: 21.21 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:20<00:04, 20.06it/s, est. speed input: 21712.18 toks/s, output: 21.20 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:20<00:04, 20.05it/s, est. speed input: 21700.27 toks/s, output: 21.19 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:20<00:03, 20.02it/s, est. speed input: 21687.81 toks/s, output: 21.18 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:20<00:03, 19.99it/s, est. speed input: 21675.23 toks/s, output: 21.17 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:20<00:03, 19.98it/s, est. speed input: 21663.53 toks/s, output: 21.16 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:21<00:03, 19.96it/s, est. speed input: 21651.41 toks/s, output: 21.14 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:21<00:03, 20.01it/s, est. speed input: 21641.51 toks/s, output: 21.13 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:21<00:02, 20.05it/s, est. speed input: 21632.17 toks/s, output: 21.13 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:21<00:02, 20.04it/s, est. speed input: 21621.58 toks/s, output: 21.11 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:21<00:02, 20.07it/s, est. speed input: 21612.56 toks/s, output: 21.11 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:22<00:02, 20.03it/s, est. speed input: 21601.61 toks/s, output: 21.10 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:22<00:02, 20.04it/s, est. speed input: 21592.37 toks/s, output: 21.09 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:22<00:01, 20.03it/s, est. speed input: 21582.40 toks/s, output: 21.08 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:22<00:01, 20.06it/s, est. speed input: 21573.85 toks/s, output: 21.07 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:22<00:01, 20.05it/s, est. speed input: 21564.59 toks/s, output: 21.06 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:23<00:01, 20.09it/s, est. speed input: 21556.79 toks/s, output: 21.05 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:23<00:01, 20.09it/s, est. speed input: 21548.38 toks/s, output: 21.04 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:23<00:00, 20.06it/s, est. speed input: 21539.10 toks/s, output: 21.03 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:23<00:00, 20.11it/s, est. speed input: 21532.30 toks/s, output: 21.03 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:23<00:00, 20.07it/s, est. speed input: 21523.33 toks/s, output: 21.02 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:24<00:00, 20.13it/s, est. speed input: 21517.05 toks/s, output: 21.01 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:24<00:00, 21.58it/s, est. speed input: 21549.22 toks/s, output: 21.04 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:24<00:00, 21.58it/s, est. speed input: 21633.48 toks/s, output: 21.13 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:24<00:00, 21.13it/s, est. speed input: 21633.48 toks/s, output: 21.13 toks/s]
[rank0]:[W126 13:58:16.444937358 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 13:58:18
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:58:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1450860) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1450860) WARNING 01-26 13:58:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.36 requests/s, 20873.41 total tokens/s, 20.36 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 13:58:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:58:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:58:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:58:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:58:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:58:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:58:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:58:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:58:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:58:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:58:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 13:58:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 13:58:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:58:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:58:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:58:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:58:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.20it/s]
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.11it/s]
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1450860) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1450860) 
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1450860) [2026-01-26 13:58:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1450860) 2026-01-26 13:59:07,623 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1450860) 2026-01-26 13:59:07,735 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1450860) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  3.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.43it/s]
(EngineCore_DP0 pid=1450860) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.42it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00, 10.67it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 10.69it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 23/1024 [00:00<00:04, 226.75it/s]
Adding requests:   6%|▌         | 63/1024 [00:00<00:02, 327.97it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:02, 340.69it/s]
Adding requests:  13%|█▎        | 137/1024 [00:00<00:02, 355.10it/s]
Adding requests:  17%|█▋        | 177/1024 [00:00<00:02, 367.77it/s]
Adding requests:  21%|██▏       | 219/1024 [00:00<00:02, 383.39it/s]
Adding requests:  25%|██▌       | 258/1024 [00:00<00:02, 379.07it/s]
Adding requests:  29%|██▉       | 298/1024 [00:00<00:01, 385.46it/s]
Adding requests:  33%|███▎      | 339/1024 [00:00<00:01, 390.33it/s]
Adding requests:  37%|███▋      | 380/1024 [00:01<00:01, 392.95it/s]
Adding requests:  41%|████      | 422/1024 [00:01<00:01, 399.76it/s]
Adding requests:  45%|████▌     | 462/1024 [00:01<00:01, 394.59it/s]
Adding requests:  49%|████▉     | 504/1024 [00:01<00:01, 401.96it/s]
Adding requests:  53%|█████▎    | 545/1024 [00:01<00:01, 402.17it/s]
Adding requests:  57%|█████▋    | 586/1024 [00:01<00:01, 395.92it/s]
Adding requests:  61%|██████    | 626/1024 [00:01<00:01, 393.34it/s]
Adding requests:  65%|██████▌   | 666/1024 [00:01<00:00, 384.80it/s]
Adding requests:  69%|██████▉   | 706/1024 [00:01<00:00, 387.84it/s]
Adding requests:  73%|███████▎  | 745/1024 [00:01<00:00, 382.73it/s]
Adding requests:  77%|███████▋  | 785/1024 [00:02<00:00, 385.17it/s]
Adding requests:  80%|████████  | 824/1024 [00:02<00:00, 384.67it/s]
Adding requests:  84%|████████▍ | 864/1024 [00:02<00:00, 386.88it/s]
Adding requests:  88%|████████▊ | 905/1024 [00:02<00:00, 393.23it/s]
Adding requests:  92%|█████████▏| 945/1024 [00:02<00:00, 382.98it/s]
Adding requests:  96%|█████████▌| 984/1024 [00:02<00:00, 384.65it/s]
Adding requests: 100%|█████████▉| 1023/1024 [00:02<00:00, 381.71it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 382.56it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 50/1024 [00:00<00:04, 229.46it/s, est. speed input: 234994.81 toks/s, output: 229.47 toks/s]
Processed prompts:   7%|▋         | 73/1024 [00:01<00:15, 61.83it/s, est. speed input: 74497.33 toks/s, output: 72.75 toks/s]   
Processed prompts:   8%|▊         | 85/1024 [00:01<00:25, 36.53it/s, est. speed input: 48718.54 toks/s, output: 47.58 toks/s]
Processed prompts:   9%|▉         | 92/1024 [00:02<00:29, 31.41it/s, est. speed input: 43340.85 toks/s, output: 42.32 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:02<00:34, 26.74it/s, est. speed input: 39071.08 toks/s, output: 38.15 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:02<00:36, 24.94it/s, est. speed input: 36683.59 toks/s, output: 35.82 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:03<00:38, 23.67it/s, est. speed input: 34870.92 toks/s, output: 34.05 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:03<00:39, 22.63it/s, est. speed input: 33368.94 toks/s, output: 32.59 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:04<00:40, 21.98it/s, est. speed input: 32190.39 toks/s, output: 31.44 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:04<00:41, 21.51it/s, est. speed input: 31211.12 toks/s, output: 30.48 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:04<00:41, 21.18it/s, est. speed input: 30389.69 toks/s, output: 29.68 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:05<00:41, 21.01it/s, est. speed input: 29709.80 toks/s, output: 29.01 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:05<00:41, 20.80it/s, est. speed input: 29094.35 toks/s, output: 28.41 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:06<00:41, 20.72it/s, est. speed input: 28577.75 toks/s, output: 27.91 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:06<00:41, 20.62it/s, est. speed input: 28113.27 toks/s, output: 27.45 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:06<00:40, 20.56it/s, est. speed input: 27701.42 toks/s, output: 27.05 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:07<00:40, 20.52it/s, est. speed input: 27336.08 toks/s, output: 26.70 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:07<00:39, 21.07it/s, est. speed input: 27133.90 toks/s, output: 26.50 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:08<00:38, 20.88it/s, est. speed input: 26831.71 toks/s, output: 26.20 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:08<00:38, 20.75it/s, est. speed input: 26557.77 toks/s, output: 25.94 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:08<00:38, 20.68it/s, est. speed input: 26311.44 toks/s, output: 25.69 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:09<00:38, 20.66it/s, est. speed input: 26091.41 toks/s, output: 25.48 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:09<00:37, 20.63it/s, est. speed input: 25887.50 toks/s, output: 25.28 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:09<00:37, 20.58it/s, est. speed input: 25693.49 toks/s, output: 25.09 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:10<00:37, 20.58it/s, est. speed input: 25520.79 toks/s, output: 24.92 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:10<00:36, 20.56it/s, est. speed input: 25356.36 toks/s, output: 24.76 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:11<00:36, 20.56it/s, est. speed input: 25205.62 toks/s, output: 24.61 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:11<00:36, 20.54it/s, est. speed input: 25062.39 toks/s, output: 24.47 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:11<00:35, 20.51it/s, est. speed input: 24927.18 toks/s, output: 24.34 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:12<00:35, 20.52it/s, est. speed input: 24803.37 toks/s, output: 24.22 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:12<00:34, 20.52it/s, est. speed input: 24687.88 toks/s, output: 24.11 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:13<00:34, 20.49it/s, est. speed input: 24574.95 toks/s, output: 24.00 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:13<00:34, 20.52it/s, est. speed input: 24473.84 toks/s, output: 23.90 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:13<00:33, 20.49it/s, est. speed input: 24373.01 toks/s, output: 23.80 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:14<00:33, 20.47it/s, est. speed input: 24277.77 toks/s, output: 23.71 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:14<00:33, 20.50it/s, est. speed input: 24193.07 toks/s, output: 23.63 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:15<00:32, 20.49it/s, est. speed input: 24108.69 toks/s, output: 23.54 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:15<00:32, 20.49it/s, est. speed input: 24029.94 toks/s, output: 23.47 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:15<00:31, 20.49it/s, est. speed input: 23954.11 toks/s, output: 23.39 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:16<00:31, 20.48it/s, est. speed input: 23881.89 toks/s, output: 23.32 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:16<00:31, 20.48it/s, est. speed input: 23813.23 toks/s, output: 23.26 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:16<00:30, 20.45it/s, est. speed input: 23745.02 toks/s, output: 23.19 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:17<00:30, 20.44it/s, est. speed input: 23681.61 toks/s, output: 23.13 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:17<00:30, 20.46it/s, est. speed input: 23622.70 toks/s, output: 23.07 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:18<00:29, 20.42it/s, est. speed input: 23561.75 toks/s, output: 23.01 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:18<00:29, 20.44it/s, est. speed input: 23507.01 toks/s, output: 22.96 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:18<00:28, 20.43it/s, est. speed input: 23453.12 toks/s, output: 22.90 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:19<00:28, 20.40it/s, est. speed input: 23399.57 toks/s, output: 22.85 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:19<00:28, 20.44it/s, est. speed input: 23353.10 toks/s, output: 22.81 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:20<00:27, 20.39it/s, est. speed input: 23302.39 toks/s, output: 22.76 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:20<00:27, 20.39it/s, est. speed input: 23255.65 toks/s, output: 22.71 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:20<00:26, 20.42it/s, est. speed input: 23213.43 toks/s, output: 22.67 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:21<00:26, 20.38it/s, est. speed input: 23168.46 toks/s, output: 22.63 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:21<00:26, 20.40it/s, est. speed input: 23127.80 toks/s, output: 22.59 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:22<00:25, 20.38it/s, est. speed input: 23086.75 toks/s, output: 22.55 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:22<00:25, 20.39it/s, est. speed input: 23048.58 toks/s, output: 22.51 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:22<00:25, 20.39it/s, est. speed input: 23011.71 toks/s, output: 22.47 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:23<00:24, 20.38it/s, est. speed input: 22974.99 toks/s, output: 22.44 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:23<00:24, 20.37it/s, est. speed input: 22939.41 toks/s, output: 22.40 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:24<00:23, 20.38it/s, est. speed input: 22905.80 toks/s, output: 22.37 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:24<00:23, 20.39it/s, est. speed input: 22874.09 toks/s, output: 22.34 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:24<00:23, 20.39it/s, est. speed input: 22842.15 toks/s, output: 22.31 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:25<00:22, 20.39it/s, est. speed input: 22812.05 toks/s, output: 22.28 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:25<00:22, 20.35it/s, est. speed input: 22779.95 toks/s, output: 22.25 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:26<00:21, 20.37it/s, est. speed input: 22751.49 toks/s, output: 22.22 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:26<00:21, 20.38it/s, est. speed input: 22724.29 toks/s, output: 22.19 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:26<00:21, 20.37it/s, est. speed input: 22696.47 toks/s, output: 22.16 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:27<00:20, 20.42it/s, est. speed input: 22672.44 toks/s, output: 22.14 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:27<00:20, 20.37it/s, est. speed input: 22644.89 toks/s, output: 22.11 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:27<00:19, 20.37it/s, est. speed input: 22619.60 toks/s, output: 22.09 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:28<00:19, 20.38it/s, est. speed input: 22595.91 toks/s, output: 22.07 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:28<00:19, 20.35it/s, est. speed input: 22570.89 toks/s, output: 22.04 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:29<00:18, 20.36it/s, est. speed input: 22548.05 toks/s, output: 22.02 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:29<00:18, 20.35it/s, est. speed input: 22524.90 toks/s, output: 22.00 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:29<00:17, 20.34it/s, est. speed input: 22502.34 toks/s, output: 21.97 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:30<00:17, 20.33it/s, est. speed input: 22480.21 toks/s, output: 21.95 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:30<00:17, 20.35it/s, est. speed input: 22459.69 toks/s, output: 21.93 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:31<00:16, 20.36it/s, est. speed input: 22439.78 toks/s, output: 21.91 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:31<00:16, 20.35it/s, est. speed input: 22419.47 toks/s, output: 21.89 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:31<00:16, 20.37it/s, est. speed input: 22400.94 toks/s, output: 21.88 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:32<00:15, 20.34it/s, est. speed input: 22380.97 toks/s, output: 21.86 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:32<00:15, 20.34it/s, est. speed input: 22362.14 toks/s, output: 21.84 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:33<00:14, 20.35it/s, est. speed input: 22344.57 toks/s, output: 21.82 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:33<00:14, 20.33it/s, est. speed input: 22325.71 toks/s, output: 21.80 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:33<00:14, 20.34it/s, est. speed input: 22308.61 toks/s, output: 21.79 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:34<00:13, 20.33it/s, est. speed input: 22291.34 toks/s, output: 21.77 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:34<00:13, 20.29it/s, est. speed input: 22272.97 toks/s, output: 21.75 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:35<00:12, 20.32it/s, est. speed input: 22257.23 toks/s, output: 21.74 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:35<00:12, 20.31it/s, est. speed input: 22240.82 toks/s, output: 21.72 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:35<00:12, 20.31it/s, est. speed input: 22225.06 toks/s, output: 21.70 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:36<00:11, 20.93it/s, est. speed input: 22233.46 toks/s, output: 21.71 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:36<00:11, 20.74it/s, est. speed input: 22217.80 toks/s, output: 21.70 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:36<00:10, 20.60it/s, est. speed input: 22202.54 toks/s, output: 21.68 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:37<00:10, 20.51it/s, est. speed input: 22187.65 toks/s, output: 21.67 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:37<00:10, 20.45it/s, est. speed input: 22173.12 toks/s, output: 21.65 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:38<00:09, 20.42it/s, est. speed input: 22159.33 toks/s, output: 21.64 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:38<00:09, 20.33it/s, est. speed input: 22143.26 toks/s, output: 21.62 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:38<00:08, 20.32it/s, est. speed input: 22129.66 toks/s, output: 21.61 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:39<00:08, 20.32it/s, est. speed input: 22116.28 toks/s, output: 21.60 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:39<00:08, 20.32it/s, est. speed input: 22103.21 toks/s, output: 21.59 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:40<00:07, 20.30it/s, est. speed input: 22090.09 toks/s, output: 21.57 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:40<00:07, 20.32it/s, est. speed input: 22077.95 toks/s, output: 21.56 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:40<00:07, 20.28it/s, est. speed input: 22064.46 toks/s, output: 21.55 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:41<00:06, 20.29it/s, est. speed input: 22052.22 toks/s, output: 21.54 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:41<00:06, 20.25it/s, est. speed input: 22038.90 toks/s, output: 21.52 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:42<00:05, 20.25it/s, est. speed input: 22026.80 toks/s, output: 21.51 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:42<00:05, 20.27it/s, est. speed input: 22015.49 toks/s, output: 21.50 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:42<00:05, 20.26it/s, est. speed input: 22003.47 toks/s, output: 21.49 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:43<00:04, 20.27it/s, est. speed input: 21992.48 toks/s, output: 21.48 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:43<00:04, 20.27it/s, est. speed input: 21981.32 toks/s, output: 21.47 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:44<00:03, 20.30it/s, est. speed input: 21971.16 toks/s, output: 21.46 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:44<00:03, 20.26it/s, est. speed input: 21959.53 toks/s, output: 21.44 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:44<00:03, 20.24it/s, est. speed input: 21948.24 toks/s, output: 21.43 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:45<00:02, 20.25it/s, est. speed input: 21937.96 toks/s, output: 21.42 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:45<00:02, 20.23it/s, est. speed input: 21926.94 toks/s, output: 21.41 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:46<00:01, 20.25it/s, est. speed input: 21917.21 toks/s, output: 21.40 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:46<00:01, 20.22it/s, est. speed input: 21906.16 toks/s, output: 21.39 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:46<00:01, 20.22it/s, est. speed input: 21896.01 toks/s, output: 21.38 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:47<00:00, 20.22it/s, est. speed input: 21886.04 toks/s, output: 21.37 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:47<00:00, 20.95it/s, est. speed input: 21897.44 toks/s, output: 21.38 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:47<00:00, 20.95it/s, est. speed input: 22026.37 toks/s, output: 21.51 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:47<00:00, 21.51it/s, est. speed input: 22026.37 toks/s, output: 21.51 toks/s]
[rank0]:[W126 14:00:01.830333018 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 14:00:03
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:00:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1452802) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1452802) WARNING 01-26 14:00:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.73 requests/s, 21246.87 total tokens/s, 20.73 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 14:00:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:00:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:00:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:00:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:00:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:00:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:00:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:00:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:00:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:00:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:00:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:00:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:00:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:00:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:00:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:00:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:00:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.17it/s]
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.09it/s]
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.52it/s]
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.35it/s]
(EngineCore_DP0 pid=1452802) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.32it/s]
(EngineCore_DP0 pid=1452802) 
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1452802) [2026-01-26 14:00:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1452802) [rank0]:W0126 14:00:52.230000 1452802 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1452802) [rank0]:W0126 14:00:52.283000 1452802 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1452802) [rank0]:W0126 14:00:52.894000 1452802 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1452802) [rank0]:W0126 14:00:52.977000 1452802 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1452802) 2026-01-26 14:00:57,276 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1452802) 2026-01-26 14:00:57,520 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1452802) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:03,  1.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:01,  3.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  4.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.74it/s]
(EngineCore_DP0 pid=1452802) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  6.28it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  2.86it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:01<00:00,  3.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.26it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 19/2048 [00:00<00:10, 189.89it/s]
Adding requests:   3%|▎         | 58/2048 [00:00<00:06, 304.81it/s]
Adding requests:   5%|▍         | 95/2048 [00:00<00:05, 333.44it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:05, 350.07it/s]
Adding requests:   8%|▊         | 170/2048 [00:00<00:05, 356.99it/s]
Adding requests:  10%|█         | 211/2048 [00:00<00:04, 371.28it/s]
Adding requests:  12%|█▏        | 250/2048 [00:00<00:04, 376.61it/s]
Adding requests:  14%|█▍        | 289/2048 [00:00<00:04, 379.43it/s]
Adding requests:  16%|█▌        | 330/2048 [00:00<00:04, 386.47it/s]
Adding requests:  18%|█▊        | 371/2048 [00:01<00:04, 392.79it/s]
Adding requests:  20%|██        | 412/2048 [00:01<00:04, 397.06it/s]
Adding requests:  22%|██▏       | 452/2048 [00:01<00:04, 394.57it/s]
Adding requests:  24%|██▍       | 496/2048 [00:01<00:03, 405.09it/s]
Adding requests:  26%|██▋       | 538/2048 [00:01<00:03, 407.91it/s]
Adding requests:  28%|██▊       | 579/2048 [00:01<00:03, 404.93it/s]
Adding requests:  30%|███       | 620/2048 [00:01<00:03, 394.34it/s]
Adding requests:  32%|███▏      | 660/2048 [00:01<00:03, 389.22it/s]
Adding requests:  34%|███▍      | 700/2048 [00:01<00:03, 391.09it/s]
Adding requests:  36%|███▌      | 740/2048 [00:01<00:03, 386.24it/s]
Adding requests:  38%|███▊      | 779/2048 [00:02<00:03, 378.82it/s]
Adding requests:  40%|███▉      | 818/2048 [00:02<00:03, 380.53it/s]
Adding requests:  42%|████▏     | 859/2048 [00:02<00:03, 389.04it/s]
Adding requests:  44%|████▍     | 899/2048 [00:02<00:02, 392.10it/s]
Adding requests:  46%|████▌     | 939/2048 [00:02<00:02, 386.34it/s]
Adding requests:  48%|████▊     | 978/2048 [00:02<00:02, 386.71it/s]
Adding requests:  50%|████▉     | 1017/2048 [00:02<00:02, 382.63it/s]
Adding requests:  52%|█████▏    | 1056/2048 [00:02<00:02, 379.88it/s]
Adding requests:  53%|█████▎    | 1095/2048 [00:02<00:02, 379.24it/s]
Adding requests:  55%|█████▌    | 1136/2048 [00:02<00:02, 387.88it/s]
Adding requests:  57%|█████▋    | 1175/2048 [00:03<00:02, 384.13it/s]
Adding requests:  59%|█████▉    | 1215/2048 [00:03<00:02, 388.02it/s]
Adding requests:  61%|██████▏   | 1255/2048 [00:03<00:02, 388.65it/s]
Adding requests:  63%|██████▎   | 1294/2048 [00:03<00:01, 382.80it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:03<00:01, 384.21it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:03<00:01, 390.19it/s]
Adding requests:  69%|██████▉   | 1414/2048 [00:03<00:01, 386.08it/s]
Adding requests:  71%|███████   | 1454/2048 [00:03<00:01, 387.97it/s]
Adding requests:  73%|███████▎  | 1495/2048 [00:03<00:01, 392.68it/s]
Adding requests:  75%|███████▍  | 1535/2048 [00:04<00:01, 388.31it/s]
Adding requests:  77%|███████▋  | 1574/2048 [00:04<00:01, 383.20it/s]
Adding requests:  79%|███████▉  | 1613/2048 [00:04<00:01, 382.28it/s]
Adding requests:  81%|████████  | 1652/2048 [00:04<00:01, 372.83it/s]
Adding requests:  83%|████████▎ | 1690/2048 [00:04<00:00, 373.20it/s]
Adding requests:  84%|████████▍ | 1729/2048 [00:04<00:00, 378.03it/s]
Adding requests:  86%|████████▋ | 1770/2048 [00:04<00:00, 386.52it/s]
Adding requests:  88%|████████▊ | 1809/2048 [00:04<00:00, 382.09it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:04<00:00, 384.14it/s]
Adding requests:  92%|█████████▏| 1888/2048 [00:04<00:00, 388.15it/s]
Adding requests:  94%|█████████▍| 1927/2048 [00:05<00:00, 383.73it/s]
Adding requests:  96%|█████████▌| 1966/2048 [00:05<00:00, 383.70it/s]
Adding requests:  98%|█████████▊| 2005/2048 [00:05<00:00, 381.60it/s]
Adding requests: 100%|█████████▉| 2044/2048 [00:05<00:00, 376.74it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 382.22it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:00<00:04, 473.64it/s, est. speed input: 485060.96 toks/s, output: 473.66 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:02<00:39, 47.75it/s, est. speed input: 59712.77 toks/s, output: 58.31 toks/s]  
Processed prompts:   8%|▊         | 167/2048 [00:03<00:45, 41.44it/s, est. speed input: 52278.36 toks/s, output: 51.05 toks/s]
Processed prompts:   9%|▉         | 180/2048 [00:04<00:54, 34.01it/s, est. speed input: 45718.96 toks/s, output: 44.65 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:04<01:02, 29.74it/s, est. speed input: 41790.81 toks/s, output: 40.81 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:05<01:07, 27.06it/s, est. speed input: 38984.35 toks/s, output: 38.07 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:06<01:12, 25.22it/s, est. speed input: 36867.79 toks/s, output: 36.00 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:07<01:15, 23.94it/s, est. speed input: 35203.20 toks/s, output: 34.38 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:07<01:17, 23.04it/s, est. speed input: 33861.48 toks/s, output: 33.07 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:08<01:19, 22.43it/s, est. speed input: 32761.66 toks/s, output: 31.99 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:09<01:19, 21.98it/s, est. speed input: 31836.64 toks/s, output: 31.09 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:10<01:20, 21.68it/s, est. speed input: 31052.76 toks/s, output: 30.32 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:10<01:20, 21.46it/s, est. speed input: 30378.82 toks/s, output: 29.67 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:11<01:20, 21.30it/s, est. speed input: 29788.30 toks/s, output: 29.09 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:12<01:19, 21.18it/s, est. speed input: 29271.37 toks/s, output: 28.59 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:13<01:19, 21.10it/s, est. speed input: 28812.92 toks/s, output: 28.14 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:13<01:18, 21.05it/s, est. speed input: 28409.16 toks/s, output: 27.74 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:14<01:18, 21.00it/s, est. speed input: 28041.14 toks/s, output: 27.38 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:15<01:17, 20.98it/s, est. speed input: 27714.58 toks/s, output: 27.06 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:16<01:17, 20.96it/s, est. speed input: 27416.61 toks/s, output: 26.77 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:16<01:16, 20.94it/s, est. speed input: 27145.04 toks/s, output: 26.51 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:17<01:15, 20.92it/s, est. speed input: 26896.25 toks/s, output: 26.27 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:18<01:14, 20.89it/s, est. speed input: 26664.87 toks/s, output: 26.04 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:19<01:14, 20.89it/s, est. speed input: 26455.30 toks/s, output: 25.84 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:20<01:13, 20.89it/s, est. speed input: 26262.05 toks/s, output: 25.65 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:20<01:12, 20.88it/s, est. speed input: 26080.78 toks/s, output: 25.47 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:21<01:11, 20.89it/s, est. speed input: 25915.21 toks/s, output: 25.31 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:22<01:11, 20.87it/s, est. speed input: 25757.19 toks/s, output: 25.15 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:23<01:10, 20.86it/s, est. speed input: 25610.31 toks/s, output: 25.01 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:23<01:09, 20.86it/s, est. speed input: 25473.30 toks/s, output: 24.88 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:24<01:09, 20.83it/s, est. speed input: 25342.41 toks/s, output: 24.75 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:25<01:08, 20.84it/s, est. speed input: 25222.15 toks/s, output: 24.63 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:26<01:07, 20.82it/s, est. speed input: 25106.21 toks/s, output: 24.52 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:26<01:06, 20.83it/s, est. speed input: 24999.43 toks/s, output: 24.41 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:27<01:06, 20.81it/s, est. speed input: 24895.74 toks/s, output: 24.31 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:28<01:05, 20.81it/s, est. speed input: 24798.60 toks/s, output: 24.22 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:29<01:04, 20.81it/s, est. speed input: 24707.22 toks/s, output: 24.13 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:30<01:03, 20.79it/s, est. speed input: 24618.55 toks/s, output: 24.04 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:30<01:02, 20.80it/s, est. speed input: 24535.77 toks/s, output: 23.96 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:31<01:02, 20.80it/s, est. speed input: 24456.66 toks/s, output: 23.88 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:32<01:01, 20.80it/s, est. speed input: 24381.59 toks/s, output: 23.81 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:33<00:59, 21.10it/s, est. speed input: 24337.21 toks/s, output: 23.77 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:33<00:59, 20.99it/s, est. speed input: 24266.50 toks/s, output: 23.70 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:34<00:58, 20.93it/s, est. speed input: 24200.16 toks/s, output: 23.63 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:35<00:58, 20.88it/s, est. speed input: 24136.00 toks/s, output: 23.57 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:36<00:57, 20.83it/s, est. speed input: 24073.77 toks/s, output: 23.51 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:36<00:56, 20.80it/s, est. speed input: 24014.41 toks/s, output: 23.45 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:37<00:56, 20.79it/s, est. speed input: 23958.19 toks/s, output: 23.40 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:38<00:55, 20.78it/s, est. speed input: 23903.96 toks/s, output: 23.34 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:39<00:54, 20.77it/s, est. speed input: 23851.68 toks/s, output: 23.29 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:40<00:53, 20.76it/s, est. speed input: 23801.12 toks/s, output: 23.24 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:40<00:53, 20.74it/s, est. speed input: 23751.39 toks/s, output: 23.19 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:41<00:52, 20.74it/s, est. speed input: 23704.83 toks/s, output: 23.15 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:42<00:51, 20.74it/s, est. speed input: 23659.74 toks/s, output: 23.11 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:43<00:50, 20.73it/s, est. speed input: 23616.15 toks/s, output: 23.06 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:43<00:50, 20.73it/s, est. speed input: 23573.75 toks/s, output: 23.02 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:44<00:49, 20.73it/s, est. speed input: 23533.01 toks/s, output: 22.98 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:45<00:48, 20.72it/s, est. speed input: 23493.45 toks/s, output: 22.94 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:46<00:47, 20.70it/s, est. speed input: 23454.15 toks/s, output: 22.90 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:46<00:47, 20.70it/s, est. speed input: 23417.03 toks/s, output: 22.87 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:47<00:46, 20.71it/s, est. speed input: 23381.52 toks/s, output: 22.83 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:48<00:45, 20.70it/s, est. speed input: 23346.39 toks/s, output: 22.80 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:49<00:44, 20.73it/s, est. speed input: 23314.22 toks/s, output: 22.77 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:50<00:43, 20.71it/s, est. speed input: 23281.12 toks/s, output: 22.74 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:50<00:43, 20.70it/s, est. speed input: 23248.79 toks/s, output: 22.70 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:51<00:42, 20.69it/s, est. speed input: 23217.73 toks/s, output: 22.67 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:52<00:41, 20.71it/s, est. speed input: 23188.84 toks/s, output: 22.65 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:53<00:40, 20.72it/s, est. speed input: 23160.50 toks/s, output: 22.62 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:53<00:40, 20.71it/s, est. speed input: 23132.36 toks/s, output: 22.59 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:54<00:39, 20.70it/s, est. speed input: 23104.64 toks/s, output: 22.56 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:55<00:38, 20.69it/s, est. speed input: 23077.52 toks/s, output: 22.54 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:56<00:37, 20.70it/s, est. speed input: 23051.83 toks/s, output: 22.51 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:57<00:37, 20.67it/s, est. speed input: 23025.10 toks/s, output: 22.49 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:57<00:36, 20.65it/s, est. speed input: 22999.23 toks/s, output: 22.46 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:58<00:35, 20.65it/s, est. speed input: 22974.82 toks/s, output: 22.44 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:59<00:34, 20.67it/s, est. speed input: 22951.92 toks/s, output: 22.41 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:00<00:33, 20.67it/s, est. speed input: 22928.86 toks/s, output: 22.39 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:00<00:33, 20.64it/s, est. speed input: 22905.05 toks/s, output: 22.37 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:01<00:32, 20.64it/s, est. speed input: 22882.82 toks/s, output: 22.35 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:02<00:31, 20.63it/s, est. speed input: 22860.72 toks/s, output: 22.32 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:03<00:30, 20.65it/s, est. speed input: 22840.09 toks/s, output: 22.30 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:03<00:30, 20.64it/s, est. speed input: 22819.05 toks/s, output: 22.28 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:04<00:29, 20.63it/s, est. speed input: 22798.67 toks/s, output: 22.26 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:05<00:28, 20.64it/s, est. speed input: 22779.05 toks/s, output: 22.25 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:06<00:27, 20.64it/s, est. speed input: 22759.96 toks/s, output: 22.23 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:07<00:27, 20.60it/s, est. speed input: 22739.66 toks/s, output: 22.21 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:07<00:26, 20.62it/s, est. speed input: 22721.40 toks/s, output: 22.19 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:08<00:25, 20.60it/s, est. speed input: 22702.48 toks/s, output: 22.17 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:09<00:24, 20.59it/s, est. speed input: 22683.94 toks/s, output: 22.15 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:10<00:23, 20.91it/s, est. speed input: 22679.32 toks/s, output: 22.15 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:10<00:22, 20.79it/s, est. speed input: 22661.00 toks/s, output: 22.13 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:11<00:22, 20.76it/s, est. speed input: 22644.91 toks/s, output: 22.11 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:12<00:21, 20.70it/s, est. speed input: 22627.76 toks/s, output: 22.10 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:13<00:20, 20.97it/s, est. speed input: 22622.96 toks/s, output: 22.09 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:14<00:19, 20.84it/s, est. speed input: 22606.34 toks/s, output: 22.08 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:14<00:19, 20.78it/s, est. speed input: 22590.89 toks/s, output: 22.06 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:15<00:18, 20.70it/s, est. speed input: 22574.85 toks/s, output: 22.05 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:16<00:17, 20.67it/s, est. speed input: 22559.75 toks/s, output: 22.03 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:17<00:16, 20.64it/s, est. speed input: 22544.75 toks/s, output: 22.02 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:17<00:16, 20.61it/s, est. speed input: 22529.62 toks/s, output: 22.00 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:18<00:15, 20.61it/s, est. speed input: 22515.33 toks/s, output: 21.99 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:19<00:14, 20.60it/s, est. speed input: 22501.15 toks/s, output: 21.97 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:20<00:13, 20.58it/s, est. speed input: 22486.82 toks/s, output: 21.96 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:21<00:13, 20.55it/s, est. speed input: 22472.35 toks/s, output: 21.95 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:21<00:12, 20.56it/s, est. speed input: 22459.03 toks/s, output: 21.93 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:22<00:11, 20.56it/s, est. speed input: 22445.93 toks/s, output: 21.92 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:23<00:10, 20.55it/s, est. speed input: 22432.53 toks/s, output: 21.91 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:24<00:10, 20.53it/s, est. speed input: 22418.86 toks/s, output: 21.89 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:24<00:09, 20.53it/s, est. speed input: 22406.28 toks/s, output: 21.88 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:25<00:08, 20.53it/s, est. speed input: 22393.72 toks/s, output: 21.87 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:26<00:07, 20.55it/s, est. speed input: 22381.85 toks/s, output: 21.86 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:27<00:06, 20.55it/s, est. speed input: 22369.96 toks/s, output: 21.85 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:28<00:06, 20.55it/s, est. speed input: 22358.28 toks/s, output: 21.83 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:28<00:05, 20.55it/s, est. speed input: 22346.60 toks/s, output: 21.82 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:29<00:04, 20.54it/s, est. speed input: 22335.01 toks/s, output: 21.81 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:30<00:03, 20.53it/s, est. speed input: 22323.54 toks/s, output: 21.80 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:31<00:03, 20.51it/s, est. speed input: 22311.82 toks/s, output: 21.79 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:31<00:02, 20.52it/s, est. speed input: 22300.87 toks/s, output: 21.78 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:32<00:01, 20.53it/s, est. speed input: 22290.55 toks/s, output: 21.77 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:33<00:00, 20.89it/s, est. speed input: 22290.54 toks/s, output: 21.77 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:33<00:00, 20.89it/s, est. speed input: 22443.83 toks/s, output: 21.92 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:33<00:00, 21.92it/s, est. speed input: 22443.83 toks/s, output: 21.92 toks/s]
[rank0]:[W126 14:02:41.088006950 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 14:02:43
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:03:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1455522) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1455522) WARNING 01-26 14:03:35 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.55 requests/s, 21065.76 total tokens/s, 20.55 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 14:03:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:03:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:03:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:03:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:03:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:03:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:03:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:03:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:03:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:03:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:03:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:03:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:03:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:03:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:03:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:03:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:03:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.19it/s]
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.11it/s]
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.54it/s]
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1455522) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.34it/s]
(EngineCore_DP0 pid=1455522) 
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1455522) [2026-01-26 14:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1455522) [rank0]:W0126 14:03:44.235000 1455522 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1455522) [rank0]:W0126 14:03:44.288000 1455522 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1455522) [rank0]:W0126 14:03:45.015000 1455522 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1455522) [rank0]:W0126 14:03:45.099000 1455522 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1455522) 2026-01-26 14:03:49,595 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1455522) 2026-01-26 14:03:50,108 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1455522) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:05,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  4.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:01,  5.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  7.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  8.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.42it/s]
(EngineCore_DP0 pid=1455522) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:01,  4.37it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:01,  2.54it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  5.05it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:01<00:00,  7.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  6.12it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:15, 254.39it/s]
Adding requests:   2%|▏         | 66/4096 [00:00<00:11, 337.37it/s]
Adding requests:   3%|▎         | 103/4096 [00:00<00:11, 348.27it/s]
Adding requests:   3%|▎         | 141/4096 [00:00<00:11, 358.56it/s]
Adding requests:   4%|▍         | 180/4096 [00:00<00:10, 369.09it/s]
Adding requests:   5%|▌         | 222/4096 [00:00<00:10, 383.08it/s]
Adding requests:   6%|▋         | 261/4096 [00:00<00:10, 381.10it/s]
Adding requests:   7%|▋         | 301/4096 [00:00<00:09, 385.15it/s]
Adding requests:   8%|▊         | 342/4096 [00:00<00:09, 390.53it/s]
Adding requests:   9%|▉         | 382/4096 [00:01<00:09, 392.95it/s]
Adding requests:  10%|█         | 424/4096 [00:01<00:09, 399.99it/s]
Adding requests:  11%|█▏        | 465/4096 [00:01<00:09, 395.34it/s]
Adding requests:  12%|█▏        | 508/4096 [00:01<00:08, 405.58it/s]
Adding requests:  13%|█▎        | 549/4096 [00:01<00:08, 406.83it/s]
Adding requests:  14%|█▍        | 590/4096 [00:01<00:08, 402.33it/s]
Adding requests:  15%|█▌        | 631/4096 [00:01<00:08, 397.59it/s]
Adding requests:  16%|█▋        | 671/4096 [00:01<00:08, 387.48it/s]
Adding requests:  17%|█▋        | 712/4096 [00:01<00:08, 392.70it/s]
Adding requests:  18%|█▊        | 752/4096 [00:01<00:08, 385.25it/s]
Adding requests:  19%|█▉        | 792/4096 [00:02<00:08, 385.81it/s]
Adding requests:  20%|██        | 832/4096 [00:02<00:08, 387.13it/s]
Adding requests:  21%|██▏       | 873/4096 [00:02<00:08, 390.53it/s]
Adding requests:  22%|██▏       | 913/4096 [00:02<00:08, 389.78it/s]
Adding requests:  23%|██▎       | 952/4096 [00:02<00:08, 386.19it/s]
Adding requests:  24%|██▍       | 991/4096 [00:02<00:08, 385.67it/s]
Adding requests:  25%|██▌       | 1030/4096 [00:02<00:07, 383.85it/s]
Adding requests:  26%|██▌       | 1069/4096 [00:02<00:07, 383.56it/s]
Adding requests:  27%|██▋       | 1108/4096 [00:02<00:08, 372.69it/s]
Adding requests:  28%|██▊       | 1148/4096 [00:02<00:07, 378.42it/s]
Adding requests:  29%|██▉       | 1187/4096 [00:03<00:07, 379.22it/s]
Adding requests:  30%|██▉       | 1228/4096 [00:03<00:07, 385.95it/s]
Adding requests:  31%|███       | 1267/4096 [00:03<00:07, 385.95it/s]
Adding requests:  32%|███▏      | 1306/4096 [00:03<00:07, 382.85it/s]
Adding requests:  33%|███▎      | 1345/4096 [00:03<00:07, 384.36it/s]
Adding requests:  34%|███▍      | 1385/4096 [00:03<00:06, 388.18it/s]
Adding requests:  35%|███▍      | 1424/4096 [00:03<00:06, 384.02it/s]
Adding requests:  36%|███▌      | 1464/4096 [00:03<00:06, 388.43it/s]
Adding requests:  37%|███▋      | 1505/4096 [00:03<00:06, 391.80it/s]
Adding requests:  38%|███▊      | 1545/4096 [00:04<00:06, 391.59it/s]
Adding requests:  39%|███▊      | 1585/4096 [00:04<00:06, 383.75it/s]
Adding requests:  40%|███▉      | 1624/4096 [00:04<00:06, 377.48it/s]
Adding requests:  41%|████      | 1662/4096 [00:04<00:06, 372.19it/s]
Adding requests:  42%|████▏     | 1701/4096 [00:04<00:06, 375.32it/s]
Adding requests:  43%|████▎     | 1741/4096 [00:04<00:06, 380.51it/s]
Adding requests:  44%|████▎     | 1782/4096 [00:04<00:05, 387.71it/s]
Adding requests:  44%|████▍     | 1821/4096 [00:04<00:05, 383.38it/s]
Adding requests:  45%|████▌     | 1861/4096 [00:04<00:05, 387.81it/s]
Adding requests:  46%|████▋     | 1900/4096 [00:04<00:05, 386.36it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:05<00:05, 395.67it/s]
Adding requests:  48%|████▊     | 1982/4096 [00:05<00:05, 395.98it/s]
Adding requests:  49%|████▉     | 2022/4096 [00:05<00:05, 383.94it/s]
Adding requests:  50%|█████     | 2061/4096 [00:05<00:05, 382.17it/s]
Adding requests:  51%|█████▏    | 2100/4096 [00:05<00:05, 378.58it/s]
Adding requests:  52%|█████▏    | 2139/4096 [00:05<00:05, 381.82it/s]
Adding requests:  53%|█████▎    | 2178/4096 [00:05<00:05, 374.36it/s]
Adding requests:  54%|█████▍    | 2216/4096 [00:05<00:05, 374.74it/s]
Adding requests:  55%|█████▌    | 2257/4096 [00:05<00:04, 382.02it/s]
Adding requests:  56%|█████▌    | 2297/4096 [00:05<00:04, 387.01it/s]
Adding requests:  57%|█████▋    | 2336/4096 [00:06<00:04, 384.32it/s]
Adding requests:  58%|█████▊    | 2376/4096 [00:06<00:04, 385.69it/s]
Adding requests:  59%|█████▉    | 2418/4096 [00:06<00:04, 394.34it/s]
Adding requests:  60%|██████    | 2458/4096 [00:06<00:04, 390.78it/s]
Adding requests:  61%|██████    | 2499/4096 [00:06<00:04, 395.51it/s]
Adding requests:  62%|██████▏   | 2540/4096 [00:06<00:03, 398.11it/s]
Adding requests:  63%|██████▎   | 2583/4096 [00:06<00:03, 406.54it/s]
Adding requests:  64%|██████▍   | 2624/4096 [00:06<00:03, 399.71it/s]
Adding requests:  65%|██████▌   | 2665/4096 [00:06<00:03, 392.83it/s]
Adding requests:  66%|██████▌   | 2705/4096 [00:07<00:03, 388.32it/s]
Adding requests:  67%|██████▋   | 2745/4096 [00:07<00:03, 391.03it/s]
Adding requests:  68%|██████▊   | 2786/4096 [00:07<00:03, 394.88it/s]
Adding requests:  69%|██████▉   | 2827/4096 [00:07<00:03, 398.95it/s]
Adding requests:  70%|██████▉   | 2867/4096 [00:07<00:03, 397.89it/s]
Adding requests:  71%|███████   | 2907/4096 [00:07<00:02, 396.91it/s]
Adding requests:  72%|███████▏  | 2948/4096 [00:07<00:02, 398.86it/s]
Adding requests:  73%|███████▎  | 2989/4096 [00:07<00:02, 399.68it/s]
Adding requests:  74%|███████▍  | 3030/4096 [00:07<00:02, 402.38it/s]
Adding requests:  75%|███████▍  | 3071/4096 [00:07<00:02, 403.05it/s]
Adding requests:  76%|███████▌  | 3112/4096 [00:08<00:02, 403.16it/s]
Adding requests:  77%|███████▋  | 3153/4096 [00:08<00:02, 401.93it/s]
Adding requests:  78%|███████▊  | 3194/4096 [00:08<00:02, 396.28it/s]
Adding requests:  79%|███████▉  | 3235/4096 [00:08<00:02, 398.98it/s]
Adding requests:  80%|███████▉  | 3275/4096 [00:08<00:02, 393.03it/s]
Adding requests:  81%|████████  | 3315/4096 [00:08<00:02, 383.80it/s]
Adding requests:  82%|████████▏ | 3354/4096 [00:08<00:01, 385.23it/s]
Adding requests:  83%|████████▎ | 3395/4096 [00:08<00:01, 391.32it/s]
Adding requests:  84%|████████▍ | 3435/4096 [00:08<00:01, 391.17it/s]
Adding requests:  85%|████████▍ | 3476/4096 [00:08<00:01, 394.96it/s]
Adding requests:  86%|████████▌ | 3516/4096 [00:09<00:01, 394.11it/s]
Adding requests:  87%|████████▋ | 3559/4096 [00:09<00:01, 403.65it/s]
Adding requests:  88%|████████▊ | 3600/4096 [00:09<00:01, 396.68it/s]
Adding requests:  89%|████████▉ | 3641/4096 [00:09<00:01, 398.58it/s]
Adding requests:  90%|████████▉ | 3681/4096 [00:09<00:01, 390.45it/s]
Adding requests:  91%|█████████ | 3721/4096 [00:09<00:00, 383.68it/s]
Adding requests:  92%|█████████▏| 3760/4096 [00:09<00:00, 377.40it/s]
Adding requests:  93%|█████████▎| 3798/4096 [00:09<00:00, 369.58it/s]
Adding requests:  94%|█████████▎| 3836/4096 [00:09<00:00, 370.86it/s]
Adding requests:  95%|█████████▍| 3875/4096 [00:10<00:00, 375.79it/s]
Adding requests:  96%|█████████▌| 3913/4096 [00:10<00:00, 372.28it/s]
Adding requests:  96%|█████████▋| 3952/4096 [00:10<00:00, 374.17it/s]
Adding requests:  97%|█████████▋| 3990/4096 [00:10<00:00, 373.62it/s]
Adding requests:  98%|█████████▊| 4028/4096 [00:10<00:00, 374.76it/s]
Adding requests:  99%|█████████▉| 4066/4096 [00:10<00:00, 375.54it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 386.67it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:00<00:04, 902.09it/s, est. speed input: 923833.22 toks/s, output: 902.12 toks/s]
Processed prompts:   7%|▋         | 285/4096 [00:03<00:53, 70.68it/s, est. speed input: 89160.43 toks/s, output: 87.07 toks/s]   
Processed prompts:   8%|▊         | 324/4096 [00:06<01:41, 37.25it/s, est. speed input: 52362.43 toks/s, output: 51.14 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:07<01:56, 32.09it/s, est. speed input: 46065.93 toks/s, output: 44.99 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:09<02:08, 28.77it/s, est. speed input: 42025.72 toks/s, output: 41.04 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:10<02:19, 26.41it/s, est. speed input: 39117.02 toks/s, output: 38.20 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:12<02:27, 24.76it/s, est. speed input: 36930.67 toks/s, output: 36.06 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:14<02:33, 23.58it/s, est. speed input: 35215.98 toks/s, output: 34.39 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:15<02:37, 22.75it/s, est. speed input: 33838.87 toks/s, output: 33.05 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:17<02:40, 22.17it/s, est. speed input: 32710.95 toks/s, output: 31.94 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:18<02:41, 21.75it/s, est. speed input: 31764.35 toks/s, output: 31.02 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:20<02:42, 21.46it/s, est. speed input: 30963.76 toks/s, output: 30.24 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:21<02:42, 21.23it/s, est. speed input: 30270.27 toks/s, output: 29.56 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:23<02:42, 21.09it/s, est. speed input: 29673.70 toks/s, output: 28.98 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:24<02:41, 20.98it/s, est. speed input: 29146.37 toks/s, output: 28.46 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:26<02:40, 20.90it/s, est. speed input: 28680.67 toks/s, output: 28.01 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:27<02:38, 21.00it/s, est. speed input: 28307.28 toks/s, output: 27.64 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:29<02:37, 20.91it/s, est. speed input: 27933.64 toks/s, output: 27.28 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:30<02:36, 20.85it/s, est. speed input: 27597.16 toks/s, output: 26.95 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:32<02:35, 20.79it/s, est. speed input: 27290.33 toks/s, output: 26.65 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:34<02:34, 20.76it/s, est. speed input: 27012.30 toks/s, output: 26.38 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:35<02:32, 20.72it/s, est. speed input: 26756.25 toks/s, output: 26.13 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:37<02:31, 20.70it/s, est. speed input: 26521.92 toks/s, output: 25.90 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:38<02:30, 20.67it/s, est. speed input: 26304.11 toks/s, output: 25.69 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:40<02:28, 20.66it/s, est. speed input: 26105.52 toks/s, output: 25.49 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:41<02:27, 20.65it/s, est. speed input: 25919.56 toks/s, output: 25.31 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:43<02:25, 20.64it/s, est. speed input: 25747.50 toks/s, output: 25.14 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:44<02:24, 20.61it/s, est. speed input: 25584.42 toks/s, output: 24.98 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:46<02:22, 20.61it/s, est. speed input: 25434.40 toks/s, output: 24.84 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:48<02:21, 20.61it/s, est. speed input: 25294.24 toks/s, output: 24.70 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:49<02:19, 20.59it/s, est. speed input: 25161.12 toks/s, output: 24.57 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:51<02:18, 20.59it/s, est. speed input: 25036.45 toks/s, output: 24.45 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:52<02:16, 20.59it/s, est. speed input: 24919.92 toks/s, output: 24.34 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:54<02:15, 20.58it/s, est. speed input: 24808.44 toks/s, output: 24.23 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:55<02:13, 20.57it/s, est. speed input: 24703.30 toks/s, output: 24.12 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:57<02:12, 20.56it/s, est. speed input: 24603.85 toks/s, output: 24.03 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:58<02:10, 20.55it/s, est. speed input: 24509.28 toks/s, output: 23.93 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [01:00<02:09, 20.54it/s, est. speed input: 24419.22 toks/s, output: 23.85 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [01:02<02:07, 20.54it/s, est. speed input: 24333.72 toks/s, output: 23.76 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [01:03<02:06, 20.52it/s, est. speed input: 24251.27 toks/s, output: 23.68 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [01:05<02:03, 20.68it/s, est. speed input: 24188.54 toks/s, output: 23.62 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [01:06<02:02, 20.63it/s, est. speed input: 24113.78 toks/s, output: 23.55 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [01:08<02:00, 20.74it/s, est. speed input: 24055.95 toks/s, output: 23.49 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [01:09<01:59, 20.66it/s, est. speed input: 23986.81 toks/s, output: 23.42 toks/s]
Processed prompts:  41%|████      | 1666/4096 [01:11<01:57, 20.61it/s, est. speed input: 23921.08 toks/s, output: 23.36 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [01:12<01:56, 20.58it/s, est. speed input: 23858.25 toks/s, output: 23.30 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [01:14<01:55, 20.54it/s, est. speed input: 23797.42 toks/s, output: 23.24 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [01:16<01:53, 20.53it/s, est. speed input: 23739.63 toks/s, output: 23.18 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:17<01:52, 20.51it/s, est. speed input: 23683.88 toks/s, output: 23.13 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [01:19<01:50, 20.50it/s, est. speed input: 23630.07 toks/s, output: 23.08 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [01:20<01:49, 20.48it/s, est. speed input: 23577.63 toks/s, output: 23.03 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:22<01:47, 20.48it/s, est. speed input: 23528.11 toks/s, output: 22.98 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:23<01:46, 20.47it/s, est. speed input: 23479.83 toks/s, output: 22.93 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:25<01:44, 20.47it/s, est. speed input: 23433.77 toks/s, output: 22.88 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:26<01:43, 20.46it/s, est. speed input: 23388.69 toks/s, output: 22.84 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:28<01:41, 20.45it/s, est. speed input: 23344.95 toks/s, output: 22.80 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:30<01:40, 20.45it/s, est. speed input: 23302.81 toks/s, output: 22.76 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:31<01:38, 20.44it/s, est. speed input: 23262.14 toks/s, output: 22.72 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:33<01:37, 20.43it/s, est. speed input: 23222.32 toks/s, output: 22.68 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [01:34<01:35, 20.43it/s, est. speed input: 23184.21 toks/s, output: 22.64 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:36<01:33, 20.59it/s, est. speed input: 23157.47 toks/s, output: 22.61 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:37<01:31, 20.54it/s, est. speed input: 23121.25 toks/s, output: 22.58 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:39<01:30, 20.51it/s, est. speed input: 23086.64 toks/s, output: 22.55 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:41<01:28, 20.48it/s, est. speed input: 23053.14 toks/s, output: 22.51 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:42<01:27, 20.46it/s, est. speed input: 23020.25 toks/s, output: 22.48 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:44<01:25, 20.45it/s, est. speed input: 22988.77 toks/s, output: 22.45 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:45<01:24, 20.44it/s, est. speed input: 22957.87 toks/s, output: 22.42 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:47<01:22, 20.43it/s, est. speed input: 22927.78 toks/s, output: 22.39 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:48<01:21, 20.42it/s, est. speed input: 22898.40 toks/s, output: 22.36 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:50<01:19, 20.41it/s, est. speed input: 22869.58 toks/s, output: 22.33 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:51<01:18, 20.41it/s, est. speed input: 22842.14 toks/s, output: 22.31 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [01:53<01:16, 20.42it/s, est. speed input: 22815.72 toks/s, output: 22.28 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [01:55<01:15, 20.40it/s, est. speed input: 22788.95 toks/s, output: 22.25 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [01:56<01:13, 20.40it/s, est. speed input: 22763.20 toks/s, output: 22.23 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [01:58<01:12, 20.39it/s, est. speed input: 22737.89 toks/s, output: 22.20 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [01:59<01:10, 20.40it/s, est. speed input: 22713.99 toks/s, output: 22.18 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [02:01<01:08, 20.39it/s, est. speed input: 22689.95 toks/s, output: 22.16 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [02:02<01:07, 20.39it/s, est. speed input: 22667.05 toks/s, output: 22.14 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [02:04<01:05, 20.39it/s, est. speed input: 22644.26 toks/s, output: 22.11 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [02:06<01:04, 20.39it/s, est. speed input: 22622.28 toks/s, output: 22.09 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [02:07<01:02, 20.39it/s, est. speed input: 22600.94 toks/s, output: 22.07 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [02:09<01:01, 20.39it/s, est. speed input: 22579.97 toks/s, output: 22.05 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [02:10<00:59, 20.55it/s, est. speed input: 22566.51 toks/s, output: 22.04 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [02:12<00:57, 20.51it/s, est. speed input: 22546.90 toks/s, output: 22.02 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [02:13<00:56, 20.48it/s, est. speed input: 22527.56 toks/s, output: 22.00 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [02:15<00:54, 20.45it/s, est. speed input: 22508.36 toks/s, output: 21.98 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [02:17<00:53, 20.44it/s, est. speed input: 22489.90 toks/s, output: 21.96 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [02:18<00:51, 20.42it/s, est. speed input: 22471.74 toks/s, output: 21.95 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [02:20<00:50, 20.42it/s, est. speed input: 22454.09 toks/s, output: 21.93 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [02:21<00:48, 20.41it/s, est. speed input: 22436.68 toks/s, output: 21.91 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [02:23<00:46, 20.40it/s, est. speed input: 22419.65 toks/s, output: 21.89 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [02:24<00:45, 20.40it/s, est. speed input: 22402.83 toks/s, output: 21.88 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [02:26<00:43, 20.39it/s, est. speed input: 22386.26 toks/s, output: 21.86 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [02:28<00:42, 20.39it/s, est. speed input: 22370.28 toks/s, output: 21.85 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [02:29<00:40, 20.38it/s, est. speed input: 22354.47 toks/s, output: 21.83 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [02:31<00:39, 20.38it/s, est. speed input: 22339.09 toks/s, output: 21.82 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [02:32<00:37, 20.39it/s, est. speed input: 22324.34 toks/s, output: 21.80 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [02:34<00:35, 20.39it/s, est. speed input: 22309.62 toks/s, output: 21.79 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [02:35<00:34, 20.39it/s, est. speed input: 22295.03 toks/s, output: 21.77 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [02:37<00:32, 20.39it/s, est. speed input: 22280.91 toks/s, output: 21.76 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [02:39<00:31, 20.39it/s, est. speed input: 22267.24 toks/s, output: 21.75 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:40<00:29, 20.40it/s, est. speed input: 22253.94 toks/s, output: 21.73 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:42<00:28, 20.40it/s, est. speed input: 22240.68 toks/s, output: 21.72 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:43<00:26, 20.40it/s, est. speed input: 22227.91 toks/s, output: 21.71 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:45<00:25, 20.40it/s, est. speed input: 22215.05 toks/s, output: 21.69 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:46<00:23, 20.39it/s, est. speed input: 22202.42 toks/s, output: 21.68 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:48<00:21, 20.39it/s, est. speed input: 22190.06 toks/s, output: 21.67 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:49<00:20, 20.55it/s, est. speed input: 22183.35 toks/s, output: 21.66 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [02:51<00:18, 20.51it/s, est. speed input: 22171.57 toks/s, output: 21.65 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [02:53<00:17, 20.48it/s, est. speed input: 22160.04 toks/s, output: 21.64 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [02:54<00:15, 20.46it/s, est. speed input: 22148.74 toks/s, output: 21.63 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [02:56<00:13, 20.43it/s, est. speed input: 22137.22 toks/s, output: 21.62 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [02:57<00:12, 20.42it/s, est. speed input: 22126.24 toks/s, output: 21.61 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [02:59<00:10, 20.41it/s, est. speed input: 22115.12 toks/s, output: 21.60 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [03:00<00:09, 20.57it/s, est. speed input: 22109.71 toks/s, output: 21.59 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [03:02<00:07, 20.52it/s, est. speed input: 22099.15 toks/s, output: 21.58 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [03:04<00:06, 20.48it/s, est. speed input: 22088.83 toks/s, output: 21.57 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [03:05<00:04, 20.46it/s, est. speed input: 22078.64 toks/s, output: 21.56 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [03:07<00:03, 20.42it/s, est. speed input: 22068.24 toks/s, output: 21.55 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [03:08<00:01, 20.62it/s, est. speed input: 22064.31 toks/s, output: 21.55 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:08<00:00, 20.62it/s, est. speed input: 22227.00 toks/s, output: 21.71 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:08<00:00, 21.71it/s, est. speed input: 22227.00 toks/s, output: 21.71 toks/s]
[rank0]:[W126 14:07:14.391029664 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 14:07:16
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:08:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1459853) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1459853) WARNING 01-26 14:08:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.82 requests/s, 21340.99 total tokens/s, 20.82 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 14:08:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:08:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:08:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:08:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:08:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:08:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:08:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:08:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:08:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:08:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:08:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 14:08:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 14:08:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:08:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:08:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:08:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:08:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.20it/s]
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.12it/s]
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1459853) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1459853) 
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36700160 bytes
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26214400 bytes
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 141557760 bytes
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1459853) [2026-01-26 14:08:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70860800 bytes
(EngineCore_DP0 pid=1459853) [rank0]:W0126 14:08:38.156000 1459853 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1459853) [rank0]:W0126 14:08:38.210000 1459853 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1459853) [rank0]:W0126 14:08:38.827000 1459853 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1459853) [rank0]:W0126 14:08:38.911000 1459853 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1459853) 2026-01-26 14:08:43,975 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1459853) 2026-01-26 14:08:44,881 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1459853) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:34,  1.90s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:02<00:16,  1.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:09,  1.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:04,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:03<00:03,  3.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:03,  3.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:03<00:02,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:04<00:02,  3.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:04<00:01,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:04<00:00,  5.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:04<00:00,  6.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:05<00:00,  3.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:05<00:00,  4.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  4.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  3.34it/s]
(EngineCore_DP0 pid=1459853) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 11.43it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 11.88it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 10.15it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  4.24it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:01<00:00,  5.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  5.69it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.16it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 29/8192 [00:00<00:28, 285.42it/s]
Adding requests:   1%|          | 69/8192 [00:00<00:23, 351.35it/s]
Adding requests:   1%|▏         | 106/8192 [00:00<00:22, 355.35it/s]
Adding requests:   2%|▏         | 143/8192 [00:00<00:22, 359.68it/s]
Adding requests:   2%|▏         | 182/8192 [00:00<00:21, 368.30it/s]
Adding requests:   3%|▎         | 222/8192 [00:00<00:21, 378.08it/s]
Adding requests:   3%|▎         | 260/8192 [00:00<00:21, 374.70it/s]
Adding requests:   4%|▎         | 300/8192 [00:00<00:20, 380.52it/s]
Adding requests:   4%|▍         | 340/8192 [00:00<00:20, 385.02it/s]
Adding requests:   5%|▍         | 380/8192 [00:01<00:20, 387.31it/s]
Adding requests:   5%|▌         | 422/8192 [00:01<00:19, 394.27it/s]
Adding requests:   6%|▌         | 462/8192 [00:01<00:19, 390.42it/s]
Adding requests:   6%|▌         | 504/8192 [00:01<00:19, 397.92it/s]
Adding requests:   7%|▋         | 546/8192 [00:01<00:19, 402.34it/s]
Adding requests:   7%|▋         | 587/8192 [00:01<00:19, 396.76it/s]
Adding requests:   8%|▊         | 627/8192 [00:01<00:19, 392.63it/s]
Adding requests:   8%|▊         | 667/8192 [00:01<00:19, 377.13it/s]
Adding requests:   9%|▊         | 707/8192 [00:01<00:19, 382.29it/s]
Adding requests:   9%|▉         | 746/8192 [00:01<00:19, 372.58it/s]
Adding requests:  10%|▉         | 786/8192 [00:02<00:19, 379.45it/s]
Adding requests:  10%|█         | 825/8192 [00:02<00:19, 379.85it/s]
Adding requests:  11%|█         | 865/8192 [00:02<00:19, 385.48it/s]
Adding requests:  11%|█         | 906/8192 [00:02<00:18, 392.47it/s]
Adding requests:  12%|█▏        | 946/8192 [00:02<00:18, 382.21it/s]
Adding requests:  12%|█▏        | 985/8192 [00:02<00:18, 384.34it/s]
Adding requests:  12%|█▎        | 1024/8192 [00:02<00:18, 379.14it/s]
Adding requests:  13%|█▎        | 1062/8192 [00:02<00:18, 378.72it/s]
Adding requests:  13%|█▎        | 1100/8192 [00:02<00:18, 377.80it/s]
Adding requests:  14%|█▍        | 1141/8192 [00:02<00:18, 385.33it/s]
Adding requests:  14%|█▍        | 1180/8192 [00:03<00:18, 382.13it/s]
Adding requests:  15%|█▍        | 1221/8192 [00:03<00:17, 387.67it/s]
Adding requests:  15%|█▌        | 1260/8192 [00:03<00:18, 384.70it/s]
Adding requests:  16%|█▌        | 1299/8192 [00:03<00:18, 381.18it/s]
Adding requests:  16%|█▋        | 1338/8192 [00:03<00:17, 381.18it/s]
Adding requests:  17%|█▋        | 1379/8192 [00:03<00:17, 386.53it/s]
Adding requests:  17%|█▋        | 1418/8192 [00:03<00:17, 381.07it/s]
Adding requests:  18%|█▊        | 1458/8192 [00:03<00:17, 385.66it/s]
Adding requests:  18%|█▊        | 1499/8192 [00:03<00:17, 389.35it/s]
Adding requests:  19%|█▉        | 1538/8192 [00:04<00:17, 389.39it/s]
Adding requests:  19%|█▉        | 1577/8192 [00:04<00:17, 382.37it/s]
Adding requests:  20%|█▉        | 1616/8192 [00:04<00:17, 378.44it/s]
Adding requests:  20%|██        | 1654/8192 [00:04<00:17, 371.67it/s]
Adding requests:  21%|██        | 1692/8192 [00:04<00:17, 372.62it/s]
Adding requests:  21%|██        | 1731/8192 [00:04<00:17, 377.21it/s]
Adding requests:  22%|██▏       | 1772/8192 [00:04<00:16, 384.32it/s]
Adding requests:  22%|██▏       | 1811/8192 [00:04<00:16, 381.31it/s]
Adding requests:  23%|██▎       | 1850/8192 [00:04<00:16, 381.81it/s]
Adding requests:  23%|██▎       | 1890/8192 [00:04<00:16, 379.70it/s]
Adding requests:  24%|██▎       | 1929/8192 [00:05<00:16, 382.57it/s]
Adding requests:  24%|██▍       | 1968/8192 [00:05<00:16, 384.29it/s]
Adding requests:  24%|██▍       | 2007/8192 [00:05<00:16, 382.78it/s]
Adding requests:  25%|██▍       | 2046/8192 [00:05<00:16, 378.31it/s]
Adding requests:  25%|██▌       | 2084/8192 [00:05<00:16, 370.07it/s]
Adding requests:  26%|██▌       | 2125/8192 [00:05<00:16, 378.50it/s]
Adding requests:  26%|██▋       | 2163/8192 [00:05<00:16, 374.83it/s]
Adding requests:  27%|██▋       | 2201/8192 [00:05<00:16, 370.12it/s]
Adding requests:  27%|██▋       | 2240/8192 [00:05<00:15, 375.47it/s]
Adding requests:  28%|██▊       | 2280/8192 [00:05<00:15, 382.38it/s]
Adding requests:  28%|██▊       | 2319/8192 [00:06<00:15, 383.38it/s]
Adding requests:  29%|██▉       | 2360/8192 [00:06<00:14, 390.32it/s]
Adding requests:  29%|██▉       | 2401/8192 [00:06<00:14, 394.79it/s]
Adding requests:  30%|██▉       | 2441/8192 [00:06<00:14, 394.16it/s]
Adding requests:  30%|███       | 2481/8192 [00:06<00:14, 392.10it/s]
Adding requests:  31%|███       | 2521/8192 [00:06<00:14, 393.86it/s]
Adding requests:  31%|███▏      | 2564/8192 [00:06<00:13, 402.48it/s]
Adding requests:  32%|███▏      | 2605/8192 [00:06<00:13, 403.61it/s]
Adding requests:  32%|███▏      | 2646/8192 [00:06<00:14, 391.79it/s]
Adding requests:  33%|███▎      | 2686/8192 [00:07<00:14, 389.09it/s]
Adding requests:  33%|███▎      | 2725/8192 [00:07<00:14, 387.54it/s]
Adding requests:  34%|███▍      | 2766/8192 [00:07<00:13, 393.35it/s]
Adding requests:  34%|███▍      | 2807/8192 [00:07<00:13, 397.02it/s]
Adding requests:  35%|███▍      | 2847/8192 [00:07<00:13, 397.63it/s]
Adding requests:  35%|███▌      | 2887/8192 [00:07<00:13, 393.77it/s]
Adding requests:  36%|███▌      | 2927/8192 [00:07<00:13, 392.72it/s]
Adding requests:  36%|███▌      | 2967/8192 [00:07<00:13, 393.87it/s]
Adding requests:  37%|███▋      | 3008/8192 [00:07<00:13, 398.44it/s]
Adding requests:  37%|███▋      | 3048/8192 [00:07<00:12, 397.60it/s]
Adding requests:  38%|███▊      | 3089/8192 [00:08<00:12, 400.56it/s]
Adding requests:  38%|███▊      | 3130/8192 [00:08<00:12, 403.04it/s]
Adding requests:  39%|███▊      | 3171/8192 [00:08<00:12, 395.87it/s]
Adding requests:  39%|███▉      | 3211/8192 [00:08<00:12, 392.93it/s]
Adding requests:  40%|███▉      | 3251/8192 [00:08<00:12, 387.67it/s]
Adding requests:  40%|████      | 3290/8192 [00:08<00:13, 375.87it/s]
Adding requests:  41%|████      | 3328/8192 [00:08<00:12, 375.39it/s]
Adding requests:  41%|████      | 3368/8192 [00:08<00:12, 380.07it/s]
Adding requests:  42%|████▏     | 3408/8192 [00:08<00:12, 385.81it/s]
Adding requests:  42%|████▏     | 3449/8192 [00:08<00:12, 391.94it/s]
Adding requests:  43%|████▎     | 3489/8192 [00:09<00:12, 385.53it/s]
Adding requests:  43%|████▎     | 3531/8192 [00:09<00:11, 395.38it/s]
Adding requests:  44%|████▎     | 3572/8192 [00:09<00:11, 398.67it/s]
Adding requests:  44%|████▍     | 3612/8192 [00:09<00:11, 397.70it/s]
Adding requests:  45%|████▍     | 3652/8192 [00:09<00:11, 397.19it/s]
Adding requests:  45%|████▌     | 3692/8192 [00:09<00:11, 388.48it/s]
Adding requests:  46%|████▌     | 3732/8192 [00:09<00:11, 389.70it/s]
Adding requests:  46%|████▌     | 3772/8192 [00:09<00:11, 380.60it/s]
Adding requests:  47%|████▋     | 3811/8192 [00:09<00:11, 367.97it/s]
Adding requests:  47%|████▋     | 3850/8192 [00:10<00:11, 371.82it/s]
Adding requests:  47%|████▋     | 3889/8192 [00:10<00:11, 375.54it/s]
Adding requests:  48%|████▊     | 3927/8192 [00:10<00:11, 371.12it/s]
Adding requests:  48%|████▊     | 3966/8192 [00:10<00:11, 373.69it/s]
Adding requests:  49%|████▉     | 4004/8192 [00:10<00:11, 373.51it/s]
Adding requests:  49%|████▉     | 4042/8192 [00:10<00:11, 373.70it/s]
Adding requests:  50%|████▉     | 4080/8192 [00:10<00:11, 373.55it/s]
Adding requests:  50%|█████     | 4119/8192 [00:10<00:10, 378.08it/s]
Adding requests:  51%|█████     | 4157/8192 [00:10<00:10, 376.32it/s]
Adding requests:  51%|█████     | 4196/8192 [00:10<00:10, 379.12it/s]
Adding requests:  52%|█████▏    | 4235/8192 [00:11<00:10, 380.07it/s]
Adding requests:  52%|█████▏    | 4274/8192 [00:11<00:10, 378.83it/s]
Adding requests:  53%|█████▎    | 4314/8192 [00:11<00:10, 381.83it/s]
Adding requests:  53%|█████▎    | 4353/8192 [00:11<00:10, 381.80it/s]
Adding requests:  54%|█████▎    | 4392/8192 [00:11<00:09, 381.02it/s]
Adding requests:  54%|█████▍    | 4432/8192 [00:11<00:09, 384.82it/s]
Adding requests:  55%|█████▍    | 4471/8192 [00:11<00:09, 385.52it/s]
Adding requests:  55%|█████▌    | 4510/8192 [00:11<00:09, 386.41it/s]
Adding requests:  56%|█████▌    | 4550/8192 [00:11<00:09, 388.70it/s]
Adding requests:  56%|█████▌    | 4589/8192 [00:11<00:09, 387.67it/s]
Adding requests:  56%|█████▋    | 4628/8192 [00:12<00:09, 374.01it/s]
Adding requests:  57%|█████▋    | 4666/8192 [00:12<00:09, 371.31it/s]
Adding requests:  57%|█████▋    | 4704/8192 [00:12<00:09, 369.06it/s]
Adding requests:  58%|█████▊    | 4746/8192 [00:12<00:08, 383.20it/s]
Adding requests:  58%|█████▊    | 4785/8192 [00:12<00:08, 379.40it/s]
Adding requests:  59%|█████▉    | 4824/8192 [00:12<00:08, 379.86it/s]
Adding requests:  59%|█████▉    | 4863/8192 [00:12<00:08, 376.85it/s]
Adding requests:  60%|█████▉    | 4902/8192 [00:12<00:08, 380.67it/s]
Adding requests:  60%|██████    | 4943/8192 [00:12<00:08, 387.67it/s]
Adding requests:  61%|██████    | 4982/8192 [00:12<00:08, 384.71it/s]
Adding requests:  61%|██████▏   | 5022/8192 [00:13<00:08, 388.71it/s]
Adding requests:  62%|██████▏   | 5061/8192 [00:13<00:08, 387.03it/s]
Adding requests:  62%|██████▏   | 5101/8192 [00:13<00:07, 388.77it/s]
Adding requests:  63%|██████▎   | 5140/8192 [00:13<00:07, 388.55it/s]
Adding requests:  63%|██████▎   | 5179/8192 [00:13<00:07, 387.13it/s]
Adding requests:  64%|██████▎   | 5218/8192 [00:13<00:07, 383.35it/s]
Adding requests:  64%|██████▍   | 5257/8192 [00:13<00:07, 379.36it/s]
Adding requests:  65%|██████▍   | 5296/8192 [00:13<00:07, 382.32it/s]
Adding requests:  65%|██████▌   | 5335/8192 [00:13<00:07, 380.98it/s]
Adding requests:  66%|██████▌   | 5375/8192 [00:14<00:07, 383.69it/s]
Adding requests:  66%|██████▌   | 5414/8192 [00:14<00:07, 374.96it/s]
Adding requests:  67%|██████▋   | 5454/8192 [00:14<00:07, 382.08it/s]
Adding requests:  67%|██████▋   | 5494/8192 [00:14<00:06, 385.78it/s]
Adding requests:  68%|██████▊   | 5533/8192 [00:14<00:06, 386.27it/s]
Adding requests:  68%|██████▊   | 5572/8192 [00:14<00:06, 382.82it/s]
Adding requests:  68%|██████▊   | 5611/8192 [00:14<00:06, 381.72it/s]
Adding requests:  69%|██████▉   | 5651/8192 [00:14<00:06, 384.37it/s]
Adding requests:  69%|██████▉   | 5690/8192 [00:14<00:06, 384.46it/s]
Adding requests:  70%|██████▉   | 5729/8192 [00:14<00:06, 385.83it/s]
Adding requests:  70%|███████   | 5769/8192 [00:15<00:06, 388.23it/s]
Adding requests:  71%|███████   | 5809/8192 [00:15<00:06, 389.30it/s]
Adding requests:  71%|███████▏  | 5848/8192 [00:15<00:06, 387.67it/s]
Adding requests:  72%|███████▏  | 5888/8192 [00:15<00:05, 389.10it/s]
Adding requests:  72%|███████▏  | 5928/8192 [00:15<00:05, 390.91it/s]
Adding requests:  73%|███████▎  | 5968/8192 [00:15<00:05, 387.04it/s]
Adding requests:  73%|███████▎  | 6007/8192 [00:15<00:05, 381.35it/s]
Adding requests:  74%|███████▍  | 6046/8192 [00:15<00:05, 383.05it/s]
Adding requests:  74%|███████▍  | 6085/8192 [00:15<00:05, 377.45it/s]
Adding requests:  75%|███████▍  | 6124/8192 [00:15<00:05, 379.61it/s]
Adding requests:  75%|███████▌  | 6164/8192 [00:16<00:05, 383.48it/s]
Adding requests:  76%|███████▌  | 6203/8192 [00:16<00:05, 376.05it/s]
Adding requests:  76%|███████▌  | 6242/8192 [00:16<00:05, 379.37it/s]
Adding requests:  77%|███████▋  | 6281/8192 [00:16<00:05, 381.92it/s]
Adding requests:  77%|███████▋  | 6322/8192 [00:16<00:04, 388.98it/s]
Adding requests:  78%|███████▊  | 6363/8192 [00:16<00:04, 394.14it/s]
Adding requests:  78%|███████▊  | 6403/8192 [00:16<00:04, 386.82it/s]
Adding requests:  79%|███████▊  | 6442/8192 [00:16<00:04, 378.77it/s]
Adding requests:  79%|███████▉  | 6480/8192 [00:16<00:04, 377.15it/s]
Adding requests:  80%|███████▉  | 6520/8192 [00:16<00:04, 382.67it/s]
Adding requests:  80%|████████  | 6559/8192 [00:17<00:04, 383.23it/s]
Adding requests:  81%|████████  | 6598/8192 [00:17<00:04, 378.01it/s]
Adding requests:  81%|████████  | 6638/8192 [00:17<00:04, 383.89it/s]
Adding requests:  82%|████████▏ | 6677/8192 [00:17<00:03, 382.09it/s]
Adding requests:  82%|████████▏ | 6716/8192 [00:17<00:03, 381.70it/s]
Adding requests:  82%|████████▏ | 6757/8192 [00:17<00:03, 387.73it/s]
Adding requests:  83%|████████▎ | 6796/8192 [00:17<00:03, 384.18it/s]
Adding requests:  83%|████████▎ | 6835/8192 [00:17<00:03, 379.27it/s]
Adding requests:  84%|████████▍ | 6875/8192 [00:17<00:03, 384.83it/s]
Adding requests:  84%|████████▍ | 6914/8192 [00:18<00:03, 383.97it/s]
Adding requests:  85%|████████▍ | 6953/8192 [00:18<00:03, 384.63it/s]
Adding requests:  85%|████████▌ | 6993/8192 [00:18<00:03, 387.07it/s]
Adding requests:  86%|████████▌ | 7032/8192 [00:18<00:03, 386.32it/s]
Adding requests:  86%|████████▋ | 7071/8192 [00:18<00:02, 381.89it/s]
Adding requests:  87%|████████▋ | 7110/8192 [00:18<00:02, 381.43it/s]
Adding requests:  87%|████████▋ | 7150/8192 [00:18<00:02, 383.15it/s]
Adding requests:  88%|████████▊ | 7191/8192 [00:18<00:02, 389.03it/s]
Adding requests:  88%|████████▊ | 7231/8192 [00:18<00:02, 390.21it/s]
Adding requests:  89%|████████▉ | 7272/8192 [00:18<00:02, 393.52it/s]
Adding requests:  89%|████████▉ | 7312/8192 [00:19<00:02, 389.28it/s]
Adding requests:  90%|████████▉ | 7351/8192 [00:19<00:02, 382.72it/s]
Adding requests:  90%|█████████ | 7390/8192 [00:19<00:02, 381.55it/s]
Adding requests:  91%|█████████ | 7429/8192 [00:19<00:01, 382.75it/s]
Adding requests:  91%|█████████ | 7468/8192 [00:19<00:01, 379.54it/s]
Adding requests:  92%|█████████▏| 7508/8192 [00:19<00:01, 383.26it/s]
Adding requests:  92%|█████████▏| 7547/8192 [00:19<00:01, 381.62it/s]
Adding requests:  93%|█████████▎| 7586/8192 [00:19<00:01, 378.72it/s]
Adding requests:  93%|█████████▎| 7625/8192 [00:19<00:01, 381.24it/s]
Adding requests:  94%|█████████▎| 7667/8192 [00:19<00:01, 391.38it/s]
Adding requests:  94%|█████████▍| 7708/8192 [00:20<00:01, 394.12it/s]
Adding requests:  95%|█████████▍| 7748/8192 [00:20<00:01, 390.88it/s]
Adding requests:  95%|█████████▌| 7788/8192 [00:20<00:01, 387.71it/s]
Adding requests:  96%|█████████▌| 7827/8192 [00:20<00:00, 386.15it/s]
Adding requests:  96%|█████████▌| 7866/8192 [00:20<00:00, 380.07it/s]
Adding requests:  97%|█████████▋| 7906/8192 [00:20<00:00, 384.47it/s]
Adding requests:  97%|█████████▋| 7948/8192 [00:20<00:00, 393.91it/s]
Adding requests:  98%|█████████▊| 7990/8192 [00:20<00:00, 398.62it/s]
Adding requests:  98%|█████████▊| 8030/8192 [00:20<00:00, 391.21it/s]
Adding requests:  99%|█████████▊| 8071/8192 [00:21<00:00, 395.06it/s]
Adding requests:  99%|█████████▉| 8111/8192 [00:21<00:00, 391.34it/s]
Adding requests:  99%|█████████▉| 8151/8192 [00:21<00:00, 385.52it/s]
Adding requests: 100%|█████████▉| 8190/8192 [00:21<00:00, 379.80it/s]
Adding requests: 100%|██████████| 8192/8192 [00:21<00:00, 384.08it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 429/8192 [00:01<00:34, 226.49it/s, est. speed input: 231931.34 toks/s, output: 226.49 toks/s]
Processed prompts:   6%|▌         | 493/8192 [00:04<01:32, 83.66it/s, est. speed input: 102550.98 toks/s, output: 100.15 toks/s] 
Processed prompts:   7%|▋         | 557/8192 [00:07<02:25, 52.49it/s, est. speed input: 71722.75 toks/s, output: 70.04 toks/s]  
Processed prompts:   8%|▊         | 621/8192 [00:10<03:12, 39.41it/s, est. speed input: 57871.85 toks/s, output: 56.52 toks/s]
Processed prompts:   8%|▊         | 685/8192 [00:14<03:50, 32.58it/s, est. speed input: 50023.78 toks/s, output: 48.85 toks/s]
Processed prompts:   9%|▉         | 749/8192 [00:17<04:19, 28.69it/s, est. speed input: 45049.74 toks/s, output: 43.99 toks/s]
Processed prompts:  10%|▉         | 813/8192 [00:20<04:42, 26.15it/s, est. speed input: 41495.82 toks/s, output: 40.52 toks/s]
Processed prompts:  11%|█         | 877/8192 [00:23<04:58, 24.50it/s, est. speed input: 38868.26 toks/s, output: 37.96 toks/s]
Processed prompts:  11%|█▏        | 941/8192 [00:26<05:09, 23.40it/s, est. speed input: 36848.30 toks/s, output: 35.98 toks/s]
Processed prompts:  12%|█▏        | 1005/8192 [00:29<05:17, 22.66it/s, est. speed input: 35250.51 toks/s, output: 34.42 toks/s]
Processed prompts:  13%|█▎        | 1069/8192 [00:32<05:21, 22.15it/s, est. speed input: 33952.83 toks/s, output: 33.16 toks/s]
Processed prompts:  14%|█▍        | 1133/8192 [00:35<05:23, 21.79it/s, est. speed input: 32874.35 toks/s, output: 32.10 toks/s]
Processed prompts:  15%|█▍        | 1197/8192 [00:38<05:24, 21.54it/s, est. speed input: 31966.59 toks/s, output: 31.22 toks/s]
Processed prompts:  15%|█▌        | 1261/8192 [00:41<05:24, 21.37it/s, est. speed input: 31194.08 toks/s, output: 30.46 toks/s]
Processed prompts:  16%|█▌        | 1325/8192 [00:44<05:23, 21.24it/s, est. speed input: 30523.53 toks/s, output: 29.81 toks/s]
Processed prompts:  17%|█▋        | 1389/8192 [00:47<05:21, 21.14it/s, est. speed input: 29937.52 toks/s, output: 29.24 toks/s]
Processed prompts:  18%|█▊        | 1453/8192 [00:50<05:19, 21.08it/s, est. speed input: 29421.94 toks/s, output: 28.73 toks/s]
Processed prompts:  19%|█▊        | 1517/8192 [00:53<05:17, 21.02it/s, est. speed input: 28962.43 toks/s, output: 28.28 toks/s]
Processed prompts:  19%|█▉        | 1581/8192 [00:56<05:13, 21.06it/s, est. speed input: 28573.72 toks/s, output: 27.90 toks/s]
Processed prompts:  20%|██        | 1645/8192 [00:59<05:11, 21.00it/s, est. speed input: 28202.98 toks/s, output: 27.54 toks/s]
Processed prompts:  21%|██        | 1709/8192 [01:02<05:09, 20.96it/s, est. speed input: 27868.33 toks/s, output: 27.22 toks/s]
Processed prompts:  22%|██▏       | 1773/8192 [01:05<05:06, 20.92it/s, est. speed input: 27563.80 toks/s, output: 26.92 toks/s]
Processed prompts:  22%|██▏       | 1837/8192 [01:08<05:04, 20.90it/s, est. speed input: 27286.79 toks/s, output: 26.65 toks/s]
Processed prompts:  23%|██▎       | 1901/8192 [01:12<05:01, 20.87it/s, est. speed input: 27032.19 toks/s, output: 26.40 toks/s]
Processed prompts:  24%|██▍       | 1965/8192 [01:15<04:58, 20.85it/s, est. speed input: 26796.57 toks/s, output: 26.17 toks/s]
Processed prompts:  25%|██▍       | 2029/8192 [01:18<04:55, 20.83it/s, est. speed input: 26579.94 toks/s, output: 25.96 toks/s]
Processed prompts:  26%|██▌       | 2093/8192 [01:21<04:52, 20.82it/s, est. speed input: 26379.91 toks/s, output: 25.76 toks/s]
Processed prompts:  26%|██▋       | 2157/8192 [01:24<04:48, 20.90it/s, est. speed input: 26207.41 toks/s, output: 25.59 toks/s]
Processed prompts:  27%|██▋       | 2221/8192 [01:27<04:46, 20.87it/s, est. speed input: 26034.71 toks/s, output: 25.42 toks/s]
Processed prompts:  28%|██▊       | 2285/8192 [01:30<04:43, 20.84it/s, est. speed input: 25872.78 toks/s, output: 25.27 toks/s]
Processed prompts:  29%|██▊       | 2349/8192 [01:33<04:40, 20.83it/s, est. speed input: 25721.71 toks/s, output: 25.12 toks/s]
Processed prompts:  29%|██▉       | 2413/8192 [01:36<04:37, 20.82it/s, est. speed input: 25580.47 toks/s, output: 24.98 toks/s]
Processed prompts:  30%|███       | 2477/8192 [01:39<04:34, 20.80it/s, est. speed input: 25447.07 toks/s, output: 24.85 toks/s]
Processed prompts:  31%|███       | 2541/8192 [01:42<04:31, 20.78it/s, est. speed input: 25320.33 toks/s, output: 24.73 toks/s]
Processed prompts:  32%|███▏      | 2605/8192 [01:45<04:29, 20.77it/s, est. speed input: 25200.99 toks/s, output: 24.61 toks/s]
Processed prompts:  33%|███▎      | 2669/8192 [01:48<04:26, 20.76it/s, est. speed input: 25088.84 toks/s, output: 24.50 toks/s]
Processed prompts:  33%|███▎      | 2733/8192 [01:52<04:22, 20.76it/s, est. speed input: 24983.45 toks/s, output: 24.40 toks/s]
Processed prompts:  34%|███▍      | 2797/8192 [01:55<04:19, 20.76it/s, est. speed input: 24883.75 toks/s, output: 24.30 toks/s]
Processed prompts:  35%|███▍      | 2861/8192 [01:58<04:15, 20.84it/s, est. speed input: 24797.49 toks/s, output: 24.22 toks/s]
Processed prompts:  36%|███▌      | 2925/8192 [02:01<04:13, 20.81it/s, est. speed input: 24706.52 toks/s, output: 24.13 toks/s]
Processed prompts:  36%|███▋      | 2989/8192 [02:04<04:10, 20.79it/s, est. speed input: 24620.32 toks/s, output: 24.04 toks/s]
Processed prompts:  37%|███▋      | 3053/8192 [02:07<04:07, 20.78it/s, est. speed input: 24538.91 toks/s, output: 23.96 toks/s]
Processed prompts:  38%|███▊      | 3117/8192 [02:10<04:04, 20.76it/s, est. speed input: 24460.59 toks/s, output: 23.89 toks/s]
Processed prompts:  39%|███▉      | 3181/8192 [02:13<04:01, 20.76it/s, est. speed input: 24386.11 toks/s, output: 23.81 toks/s]
Processed prompts:  40%|███▉      | 3245/8192 [02:16<03:58, 20.76it/s, est. speed input: 24315.40 toks/s, output: 23.75 toks/s]
Processed prompts:  40%|████      | 3309/8192 [02:19<03:55, 20.75it/s, est. speed input: 24247.15 toks/s, output: 23.68 toks/s]
Processed prompts:  41%|████      | 3373/8192 [02:22<03:52, 20.75it/s, est. speed input: 24182.15 toks/s, output: 23.62 toks/s]
Processed prompts:  42%|████▏     | 3437/8192 [02:25<03:49, 20.74it/s, est. speed input: 24119.91 toks/s, output: 23.55 toks/s]
Processed prompts:  43%|████▎     | 3501/8192 [02:29<03:46, 20.74it/s, est. speed input: 24060.31 toks/s, output: 23.50 toks/s]
Processed prompts:  44%|████▎     | 3565/8192 [02:32<03:43, 20.74it/s, est. speed input: 24002.47 toks/s, output: 23.44 toks/s]
Processed prompts:  44%|████▍     | 3629/8192 [02:35<03:39, 20.82it/s, est. speed input: 23953.92 toks/s, output: 23.39 toks/s]
Processed prompts:  45%|████▌     | 3693/8192 [02:38<03:36, 20.80it/s, est. speed input: 23900.90 toks/s, output: 23.34 toks/s]
Processed prompts:  46%|████▌     | 3757/8192 [02:41<03:33, 20.78it/s, est. speed input: 23849.87 toks/s, output: 23.29 toks/s]
Processed prompts:  47%|████▋     | 3821/8192 [02:44<03:30, 20.77it/s, est. speed input: 23800.88 toks/s, output: 23.24 toks/s]
Processed prompts:  47%|████▋     | 3885/8192 [02:47<03:26, 20.84it/s, est. speed input: 23759.39 toks/s, output: 23.20 toks/s]
Processed prompts:  48%|████▊     | 3949/8192 [02:50<03:23, 20.80it/s, est. speed input: 23713.00 toks/s, output: 23.16 toks/s]
Processed prompts:  49%|████▉     | 4013/8192 [02:53<03:21, 20.77it/s, est. speed input: 23668.55 toks/s, output: 23.11 toks/s]
Processed prompts:  50%|████▉     | 4077/8192 [02:56<03:17, 20.84it/s, est. speed input: 23630.89 toks/s, output: 23.08 toks/s]
Processed prompts:  51%|█████     | 4141/8192 [02:59<03:14, 20.80it/s, est. speed input: 23589.09 toks/s, output: 23.04 toks/s]
Processed prompts:  51%|█████▏    | 4205/8192 [03:02<03:11, 20.77it/s, est. speed input: 23548.99 toks/s, output: 23.00 toks/s]
Processed prompts:  52%|█████▏    | 4269/8192 [03:05<03:08, 20.76it/s, est. speed input: 23510.53 toks/s, output: 22.96 toks/s]
Processed prompts:  53%|█████▎    | 4333/8192 [03:09<03:05, 20.76it/s, est. speed input: 23473.72 toks/s, output: 22.92 toks/s]
Processed prompts:  54%|█████▎    | 4397/8192 [03:12<03:02, 20.74it/s, est. speed input: 23436.96 toks/s, output: 22.89 toks/s]
Processed prompts:  54%|█████▍    | 4461/8192 [03:15<02:59, 20.74it/s, est. speed input: 23402.35 toks/s, output: 22.85 toks/s]
Processed prompts:  55%|█████▌    | 4525/8192 [03:18<02:56, 20.74it/s, est. speed input: 23368.49 toks/s, output: 22.82 toks/s]
Processed prompts:  56%|█████▌    | 4589/8192 [03:21<02:53, 20.72it/s, est. speed input: 23334.92 toks/s, output: 22.79 toks/s]
Processed prompts:  57%|█████▋    | 4653/8192 [03:24<02:50, 20.73it/s, est. speed input: 23303.25 toks/s, output: 22.76 toks/s]
Processed prompts:  58%|█████▊    | 4717/8192 [03:27<02:47, 20.73it/s, est. speed input: 23272.48 toks/s, output: 22.73 toks/s]
Processed prompts:  58%|█████▊    | 4781/8192 [03:30<02:44, 20.73it/s, est. speed input: 23242.22 toks/s, output: 22.70 toks/s]
Processed prompts:  59%|█████▉    | 4845/8192 [03:33<02:41, 20.72it/s, est. speed input: 23212.98 toks/s, output: 22.67 toks/s]
Processed prompts:  60%|█████▉    | 4909/8192 [03:36<02:38, 20.73it/s, est. speed input: 23184.86 toks/s, output: 22.64 toks/s]
Processed prompts:  61%|██████    | 4973/8192 [03:39<02:34, 20.81it/s, est. speed input: 23161.49 toks/s, output: 22.62 toks/s]
Processed prompts:  61%|██████▏   | 5037/8192 [03:42<02:31, 20.78it/s, est. speed input: 23134.38 toks/s, output: 22.59 toks/s]
Processed prompts:  62%|██████▏   | 5101/8192 [03:46<02:28, 20.76it/s, est. speed input: 23108.17 toks/s, output: 22.57 toks/s]
Processed prompts:  63%|██████▎   | 5165/8192 [03:49<02:25, 20.75it/s, est. speed input: 23082.59 toks/s, output: 22.54 toks/s]
Processed prompts:  64%|██████▍   | 5229/8192 [03:52<02:22, 20.74it/s, est. speed input: 23057.84 toks/s, output: 22.52 toks/s]
Processed prompts:  65%|██████▍   | 5293/8192 [03:55<02:19, 20.73it/s, est. speed input: 23033.62 toks/s, output: 22.49 toks/s]
Processed prompts:  65%|██████▌   | 5357/8192 [03:58<02:16, 20.73it/s, est. speed input: 23010.33 toks/s, output: 22.47 toks/s]
Processed prompts:  66%|██████▌   | 5421/8192 [04:01<02:13, 20.73it/s, est. speed input: 22987.33 toks/s, output: 22.45 toks/s]
Processed prompts:  67%|██████▋   | 5485/8192 [04:04<02:10, 20.73it/s, est. speed input: 22965.03 toks/s, output: 22.43 toks/s]
Processed prompts:  68%|██████▊   | 5549/8192 [04:07<02:07, 20.73it/s, est. speed input: 22943.27 toks/s, output: 22.41 toks/s]
Processed prompts:  69%|██████▊   | 5613/8192 [04:10<02:04, 20.72it/s, est. speed input: 22921.72 toks/s, output: 22.38 toks/s]
Processed prompts:  69%|██████▉   | 5677/8192 [04:13<02:01, 20.72it/s, est. speed input: 22901.10 toks/s, output: 22.36 toks/s]
Processed prompts:  70%|███████   | 5741/8192 [04:16<01:58, 20.72it/s, est. speed input: 22880.63 toks/s, output: 22.34 toks/s]
Processed prompts:  71%|███████   | 5805/8192 [04:20<01:55, 20.72it/s, est. speed input: 22860.93 toks/s, output: 22.33 toks/s]
Processed prompts:  72%|███████▏  | 5869/8192 [04:23<01:51, 20.80it/s, est. speed input: 22845.27 toks/s, output: 22.31 toks/s]
Processed prompts:  72%|███████▏  | 5933/8192 [04:26<01:48, 20.79it/s, est. speed input: 22826.79 toks/s, output: 22.29 toks/s]
Processed prompts:  73%|███████▎  | 5997/8192 [04:29<01:45, 20.86it/s, est. speed input: 22812.12 toks/s, output: 22.28 toks/s]
Processed prompts:  74%|███████▍  | 6061/8192 [04:32<01:42, 20.81it/s, est. speed input: 22793.95 toks/s, output: 22.26 toks/s]
Processed prompts:  75%|███████▍  | 6125/8192 [04:35<01:39, 20.79it/s, est. speed input: 22776.49 toks/s, output: 22.24 toks/s]
Processed prompts:  76%|███████▌  | 6189/8192 [04:38<01:36, 20.77it/s, est. speed input: 22759.03 toks/s, output: 22.23 toks/s]
Processed prompts:  76%|███████▋  | 6253/8192 [04:41<01:33, 20.75it/s, est. speed input: 22742.03 toks/s, output: 22.21 toks/s]
Processed prompts:  77%|███████▋  | 6317/8192 [04:44<01:30, 20.75it/s, est. speed input: 22725.79 toks/s, output: 22.19 toks/s]
Processed prompts:  78%|███████▊  | 6381/8192 [04:47<01:27, 20.73it/s, est. speed input: 22709.37 toks/s, output: 22.18 toks/s]
Processed prompts:  79%|███████▊  | 6445/8192 [04:50<01:24, 20.73it/s, est. speed input: 22693.57 toks/s, output: 22.16 toks/s]
Processed prompts:  79%|███████▉  | 6509/8192 [04:53<01:21, 20.73it/s, est. speed input: 22678.26 toks/s, output: 22.15 toks/s]
Processed prompts:  80%|████████  | 6573/8192 [04:56<01:18, 20.73it/s, est. speed input: 22663.01 toks/s, output: 22.13 toks/s]
Processed prompts:  81%|████████  | 6637/8192 [05:00<01:15, 20.72it/s, est. speed input: 22648.00 toks/s, output: 22.12 toks/s]
Processed prompts:  82%|████████▏ | 6701/8192 [05:03<01:11, 20.72it/s, est. speed input: 22633.34 toks/s, output: 22.10 toks/s]
Processed prompts:  83%|████████▎ | 6765/8192 [05:06<01:08, 20.72it/s, est. speed input: 22619.03 toks/s, output: 22.09 toks/s]
Processed prompts:  83%|████████▎ | 6829/8192 [05:09<01:05, 20.71it/s, est. speed input: 22604.82 toks/s, output: 22.08 toks/s]
Processed prompts:  84%|████████▍ | 6893/8192 [05:12<01:02, 20.71it/s, est. speed input: 22590.89 toks/s, output: 22.06 toks/s]
Processed prompts:  85%|████████▍ | 6957/8192 [05:15<00:59, 20.71it/s, est. speed input: 22577.42 toks/s, output: 22.05 toks/s]
Processed prompts:  86%|████████▌ | 7021/8192 [05:18<00:56, 20.71it/s, est. speed input: 22564.21 toks/s, output: 22.04 toks/s]
Processed prompts:  86%|████████▋ | 7085/8192 [05:21<00:53, 20.70it/s, est. speed input: 22550.89 toks/s, output: 22.02 toks/s]
Processed prompts:  87%|████████▋ | 7149/8192 [05:24<00:50, 20.71it/s, est. speed input: 22538.29 toks/s, output: 22.01 toks/s]
Processed prompts:  88%|████████▊ | 7213/8192 [05:27<00:47, 20.71it/s, est. speed input: 22525.61 toks/s, output: 22.00 toks/s]
Processed prompts:  89%|████████▉ | 7277/8192 [05:30<00:44, 20.71it/s, est. speed input: 22513.31 toks/s, output: 21.99 toks/s]
Processed prompts:  90%|████████▉ | 7341/8192 [05:34<00:41, 20.71it/s, est. speed input: 22501.21 toks/s, output: 21.97 toks/s]
Processed prompts:  90%|█████████ | 7405/8192 [05:37<00:38, 20.71it/s, est. speed input: 22489.38 toks/s, output: 21.96 toks/s]
Processed prompts:  91%|█████████ | 7469/8192 [05:40<00:34, 20.71it/s, est. speed input: 22477.84 toks/s, output: 21.95 toks/s]
Processed prompts:  92%|█████████▏| 7533/8192 [05:43<00:31, 20.72it/s, est. speed input: 22466.72 toks/s, output: 21.94 toks/s]
Processed prompts:  93%|█████████▎| 7597/8192 [05:46<00:28, 20.73it/s, est. speed input: 22455.79 toks/s, output: 21.93 toks/s]
Processed prompts:  94%|█████████▎| 7661/8192 [05:49<00:25, 20.73it/s, est. speed input: 22445.08 toks/s, output: 21.92 toks/s]
Processed prompts:  94%|█████████▍| 7725/8192 [05:52<00:22, 20.72it/s, est. speed input: 22434.09 toks/s, output: 21.91 toks/s]
Processed prompts:  95%|█████████▌| 7789/8192 [05:55<00:19, 20.72it/s, est. speed input: 22423.37 toks/s, output: 21.90 toks/s]
Processed prompts:  96%|█████████▌| 7853/8192 [05:58<00:16, 20.71it/s, est. speed input: 22412.75 toks/s, output: 21.89 toks/s]
Processed prompts:  97%|█████████▋| 7917/8192 [06:01<00:13, 20.72it/s, est. speed input: 22402.67 toks/s, output: 21.88 toks/s]
Processed prompts:  97%|█████████▋| 7981/8192 [06:04<00:10, 20.71it/s, est. speed input: 22392.48 toks/s, output: 21.87 toks/s]
Processed prompts:  98%|█████████▊| 8045/8192 [06:08<00:07, 20.72it/s, est. speed input: 22382.72 toks/s, output: 21.86 toks/s]
Processed prompts:  99%|█████████▉| 8109/8192 [06:11<00:04, 20.72it/s, est. speed input: 22373.15 toks/s, output: 21.85 toks/s]
Processed prompts: 100%|█████████▉| 8173/8192 [06:12<00:00, 26.05it/s, est. speed input: 22490.21 toks/s, output: 21.96 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:12<00:00, 26.05it/s, est. speed input: 22542.46 toks/s, output: 22.01 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:12<00:00, 22.01it/s, est. speed input: 22542.46 toks/s, output: 22.01 toks/s]
[rank0]:[W126 14:15:28.072663523 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 08:50:36
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:50:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3334698) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3334698) WARNING 01-28 08:50:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.85 requests/s, 16337.85 total tokens/s, 31.85 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 08:50:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:50:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:50:43] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:50:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:50:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:50:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:50:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:50:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:50:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:50:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:50:51] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:50:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:50:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:50:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:50:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:50:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:50:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3334698) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3334698) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=3334698) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=3334698) 
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3334698) [2026-01-28 08:50:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3334698) 2026-01-28 08:51:10,633 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3334698) 2026-01-28 08:51:10,660 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3334698) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.82it/s]
(EngineCore_DP0 pid=3334698) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.07it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  42%|████▏     | 54/128 [00:00<00:00, 536.70it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 709.73it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:33,  3.81it/s, est. speed input: 1949.44 toks/s, output: 3.81 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 16.03it/s, est. speed input: 6882.06 toks/s, output: 13.44 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 23.22it/s, est. speed input: 9587.40 toks/s, output: 18.72 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 27.62it/s, est. speed input: 11271.82 toks/s, output: 22.01 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 30.56it/s, est. speed input: 12447.98 toks/s, output: 24.31 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 32.51it/s, est. speed input: 13307.40 toks/s, output: 25.99 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 33.90it/s, est. speed input: 13972.54 toks/s, output: 27.29 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:02, 34.74it/s, est. speed input: 14482.07 toks/s, output: 28.28 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 35.31it/s, est. speed input: 14892.18 toks/s, output: 29.09 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 35.78it/s, est. speed input: 15240.18 toks/s, output: 29.77 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 36.15it/s, est. speed input: 15536.04 toks/s, output: 30.34 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 36.23it/s, est. speed input: 15769.71 toks/s, output: 30.80 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 36.00it/s, est. speed input: 15941.37 toks/s, output: 31.14 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 34.56it/s, est. speed input: 15961.49 toks/s, output: 31.17 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.67it/s, est. speed input: 15982.12 toks/s, output: 31.21 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 33.06it/s, est. speed input: 15999.22 toks/s, output: 31.25 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.73it/s, est. speed input: 16022.47 toks/s, output: 31.29 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.47it/s, est. speed input: 16128.92 toks/s, output: 31.50 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 34.14it/s, est. speed input: 16235.93 toks/s, output: 31.71 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 34.64it/s, est. speed input: 16333.88 toks/s, output: 31.90 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 34.99it/s, est. speed input: 16423.01 toks/s, output: 32.08 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 35.32it/s, est. speed input: 16509.77 toks/s, output: 32.25 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 35.54it/s, est. speed input: 16588.88 toks/s, output: 32.40 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 35.77it/s, est. speed input: 16666.34 toks/s, output: 32.55 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 35.90it/s, est. speed input: 16735.94 toks/s, output: 32.69 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 35.56it/s, est. speed input: 16776.21 toks/s, output: 32.77 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 35.72it/s, est. speed input: 16835.07 toks/s, output: 32.88 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 35.83it/s, est. speed input: 16890.31 toks/s, output: 32.99 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 35.81it/s, est. speed input: 16936.81 toks/s, output: 33.08 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 35.86it/s, est. speed input: 16983.83 toks/s, output: 33.17 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 35.76it/s, est. speed input: 17021.19 toks/s, output: 33.24 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 35.65it/s, est. speed input: 17054.38 toks/s, output: 33.31 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.65it/s, est. speed input: 17080.42 toks/s, output: 33.36 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.36it/s, est. speed input: 17080.42 toks/s, output: 33.36 toks/s]
[rank0]:[W128 08:51:17.251531929 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 08:51:19
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:51:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3335831) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3335831) WARNING 01-28 08:51:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.76 requests/s, 33578.68 total tokens/s, 32.76 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 08:51:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:51:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:51:26] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:51:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:51:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:51:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:51:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:51:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:51:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:51:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:51:33] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:51:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:51:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:51:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:51:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:51:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:51:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3335831) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3335831) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.06it/s]
(EngineCore_DP0 pid=3335831) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.06it/s]
(EngineCore_DP0 pid=3335831) 
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3335831) [2026-01-28 08:51:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3335831) 2026-01-28 08:51:52,344 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3335831) 2026-01-28 08:51:52,383 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3335831) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 12.15it/s]
(EngineCore_DP0 pid=3335831) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.81it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|██        | 26/128 [00:00<00:00, 258.35it/s]
Adding requests:  60%|██████    | 77/128 [00:00<00:00, 402.20it/s]
Adding requests:  99%|█████████▉| 127/128 [00:00<00:00, 445.92it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 419.87it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 45.10it/s, est. speed input: 46198.94 toks/s, output: 45.11 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:03, 38.63it/s, est. speed input: 40434.56 toks/s, output: 39.48 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:03, 37.19it/s, est. speed input: 39090.95 toks/s, output: 38.17 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:03, 36.14it/s, est. speed input: 38171.00 toks/s, output: 37.27 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:02, 35.80it/s, est. speed input: 37763.19 toks/s, output: 36.88 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 35.61it/s, est. speed input: 37488.24 toks/s, output: 36.61 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 35.56it/s, est. speed input: 37325.58 toks/s, output: 36.45 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 35.43it/s, est. speed input: 37165.19 toks/s, output: 36.29 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 35.33it/s, est. speed input: 37034.25 toks/s, output: 36.17 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 35.29it/s, est. speed input: 36935.20 toks/s, output: 36.07 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 35.27it/s, est. speed input: 36860.08 toks/s, output: 36.00 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 35.23it/s, est. speed input: 36788.38 toks/s, output: 35.93 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 35.27it/s, est. speed input: 36745.19 toks/s, output: 35.88 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:01, 35.23it/s, est. speed input: 36690.21 toks/s, output: 35.83 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 35.25it/s, est. speed input: 36654.56 toks/s, output: 35.79 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 35.23it/s, est. speed input: 36617.06 toks/s, output: 35.76 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 35.27it/s, est. speed input: 36592.38 toks/s, output: 35.73 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 35.29it/s, est. speed input: 36571.17 toks/s, output: 35.71 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 35.30it/s, est. speed input: 36549.32 toks/s, output: 35.69 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 35.37it/s, est. speed input: 36542.12 toks/s, output: 35.69 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 35.36it/s, est. speed input: 36525.43 toks/s, output: 35.67 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 35.34it/s, est. speed input: 36508.33 toks/s, output: 35.65 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:00, 35.39it/s, est. speed input: 36501.51 toks/s, output: 35.65 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 35.41it/s, est. speed input: 36492.88 toks/s, output: 35.64 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 35.35it/s, est. speed input: 36475.67 toks/s, output: 35.62 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 35.36it/s, est. speed input: 36466.42 toks/s, output: 35.61 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 35.43it/s, est. speed input: 36465.28 toks/s, output: 35.61 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 35.39it/s, est. speed input: 36454.18 toks/s, output: 35.60 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 35.30it/s, est. speed input: 36436.61 toks/s, output: 35.58 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 35.30it/s, est. speed input: 36426.75 toks/s, output: 35.57 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 35.28it/s, est. speed input: 36415.14 toks/s, output: 35.56 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.28it/s, est. speed input: 36403.56 toks/s, output: 35.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.55it/s, est. speed input: 36403.56 toks/s, output: 35.55 toks/s]
[rank0]:[W128 08:51:58.319142240 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 08:52:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:52:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3336925) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3336925) WARNING 01-28 08:52:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 64.14 requests/s, 65745.67 total tokens/s, 64.14 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 08:52:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:52:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:52:08] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:52:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:52:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:52:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:52:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:52:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:52:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:52:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:52:14] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:52:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:52:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:52:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:52:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:52:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3336925) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3336925) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.04it/s]
(EngineCore_DP0 pid=3336925) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.03it/s]
(EngineCore_DP0 pid=3336925) 
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3336925) [2026-01-28 08:52:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3336925) 2026-01-28 08:52:33,883 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3336925) 2026-01-28 08:52:33,916 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3336925) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  6.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.31it/s]
(EngineCore_DP0 pid=3336925) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  9.51it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 243.91it/s]
Adding requests:  28%|██▊       | 72/256 [00:00<00:00, 374.33it/s]
Adding requests:  48%|████▊     | 122/256 [00:00<00:00, 429.43it/s]
Adding requests:  67%|██████▋   | 171/256 [00:00<00:00, 452.74it/s]
Adding requests:  86%|████████▋ | 221/256 [00:00<00:00, 468.84it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 446.77it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 213.62it/s, est. speed input: 218787.99 toks/s, output: 213.63 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:00<00:02, 97.07it/s, est. speed input: 108268.69 toks/s, output: 105.73 toks/s] 
Processed prompts:  22%|██▏       | 57/256 [00:00<00:02, 89.03it/s, est. speed input: 99516.00 toks/s, output: 97.18 toks/s]  
Processed prompts:  27%|██▋       | 68/256 [00:00<00:02, 80.37it/s, est. speed input: 92039.92 toks/s, output: 89.88 toks/s]
Processed prompts:  30%|███       | 77/256 [00:00<00:02, 80.32it/s, est. speed input: 90749.32 toks/s, output: 88.62 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:02, 75.12it/s, est. speed input: 87167.74 toks/s, output: 85.12 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:01<00:02, 73.92it/s, est. speed input: 85660.66 toks/s, output: 83.65 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:01<00:02, 73.05it/s, est. speed input: 84451.03 toks/s, output: 82.47 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:01<00:02, 72.44it/s, est. speed input: 83457.06 toks/s, output: 81.50 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:01<00:01, 72.01it/s, est. speed input: 82623.29 toks/s, output: 80.69 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:01<00:01, 71.55it/s, est. speed input: 81866.26 toks/s, output: 79.94 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:01<00:01, 71.45it/s, est. speed input: 81270.88 toks/s, output: 79.36 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:01<00:01, 71.32it/s, est. speed input: 80736.42 toks/s, output: 78.84 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:01<00:01, 71.07it/s, est. speed input: 80228.19 toks/s, output: 78.35 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:02<00:01, 70.99it/s, est. speed input: 79796.12 toks/s, output: 77.92 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:02<00:01, 70.92it/s, est. speed input: 79409.09 toks/s, output: 77.55 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:02<00:01, 70.67it/s, est. speed input: 79022.18 toks/s, output: 77.17 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:02<00:01, 70.70it/s, est. speed input: 78710.05 toks/s, output: 76.86 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:02<00:00, 70.79it/s, est. speed input: 78436.57 toks/s, output: 76.60 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:02<00:00, 70.66it/s, est. speed input: 78157.01 toks/s, output: 76.32 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:02<00:00, 70.50it/s, est. speed input: 77889.45 toks/s, output: 76.06 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:02<00:00, 70.37it/s, est. speed input: 77641.62 toks/s, output: 75.82 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:02<00:00, 70.50it/s, est. speed input: 77443.02 toks/s, output: 75.63 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:03<00:00, 70.51it/s, est. speed input: 77249.78 toks/s, output: 75.44 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:03<00:00, 70.69it/s, est. speed input: 77091.18 toks/s, output: 75.28 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:03<00:00, 70.46it/s, est. speed input: 76900.65 toks/s, output: 75.10 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:03<00:00, 70.60it/s, est. speed input: 76758.50 toks/s, output: 74.96 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 70.60it/s, est. speed input: 76732.84 toks/s, output: 74.93 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 74.93it/s, est. speed input: 76732.84 toks/s, output: 74.93 toks/s]
[rank0]:[W128 08:52:40.252019400 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 08:52:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:52:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3338043) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3338043) WARNING 01-28 08:53:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 81.14 requests/s, 83164.06 total tokens/s, 81.14 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 08:52:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:52:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:52:51] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:52:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:52:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:52:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:52:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:52:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:52:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:52:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:52:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:52:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:52:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:52:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:52:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:52:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:52:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3338043) [2026-01-28 08:52:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3338043) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3338043) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.04it/s]
(EngineCore_DP0 pid=3338043) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.04it/s]
(EngineCore_DP0 pid=3338043) 
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3338043) [2026-01-28 08:53:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3338043) 2026-01-28 08:53:17,764 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3338043) 2026-01-28 08:53:17,795 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3338043) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 14.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 13.72it/s]
(EngineCore_DP0 pid=3338043) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  8.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 12.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.64it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 30/512 [00:00<00:01, 296.52it/s]
Adding requests:  16%|█▌        | 81/512 [00:00<00:01, 420.41it/s]
Adding requests:  26%|██▌       | 131/512 [00:00<00:00, 452.23it/s]
Adding requests:  35%|███▍      | 179/512 [00:00<00:00, 461.36it/s]
Adding requests:  45%|████▍     | 230/512 [00:00<00:00, 476.53it/s]
Adding requests:  55%|█████▍    | 280/512 [00:00<00:00, 483.49it/s]
Adding requests:  64%|██████▍   | 330/512 [00:00<00:00, 487.41it/s]
Adding requests:  74%|███████▍  | 381/512 [00:00<00:00, 494.33it/s]
Adding requests:  85%|████████▍ | 433/512 [00:00<00:00, 499.69it/s]
Adding requests:  94%|█████████▍| 483/512 [00:01<00:00, 499.37it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 478.44it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:00<00:00, 543.32it/s, est. speed input: 556441.76 toks/s, output: 543.34 toks/s]
Processed prompts:  24%|██▍       | 125/512 [00:00<00:02, 151.35it/s, est. speed input: 176365.75 toks/s, output: 172.23 toks/s]
Processed prompts:  30%|██▉       | 153/512 [00:01<00:02, 124.14it/s, est. speed input: 148258.90 toks/s, output: 144.78 toks/s]
Processed prompts:  34%|███▎      | 172/512 [00:01<00:03, 112.02it/s, est. speed input: 136760.17 toks/s, output: 133.55 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:01<00:03, 104.40it/s, est. speed input: 130055.71 toks/s, output: 127.01 toks/s]
Processed prompts:  39%|███▉      | 200/512 [00:01<00:03, 102.27it/s, est. speed input: 127176.50 toks/s, output: 124.19 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:01<00:03, 98.64it/s, est. speed input: 124121.85 toks/s, output: 121.21 toks/s] 
Processed prompts:  44%|████▎     | 223/512 [00:01<00:03, 93.34it/s, est. speed input: 120776.81 toks/s, output: 117.95 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:02<00:03, 89.24it/s, est. speed input: 117922.63 toks/s, output: 115.16 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:02<00:03, 88.28it/s, est. speed input: 115980.48 toks/s, output: 113.26 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:02<00:02, 87.54it/s, est. speed input: 114268.22 toks/s, output: 111.59 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:02<00:02, 87.33it/s, est. speed input: 112834.15 toks/s, output: 110.19 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:02<00:02, 87.34it/s, est. speed input: 111592.88 toks/s, output: 108.98 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:02<00:02, 87.14it/s, est. speed input: 110431.81 toks/s, output: 107.84 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:02<00:02, 86.52it/s, est. speed input: 109283.90 toks/s, output: 106.72 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:03<00:02, 86.29it/s, est. speed input: 108283.24 toks/s, output: 105.74 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:03<00:02, 83.13it/s, est. speed input: 106799.21 toks/s, output: 104.29 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:03<00:01, 85.05it/s, est. speed input: 106203.55 toks/s, output: 103.71 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:03<00:01, 85.65it/s, est. speed input: 105522.04 toks/s, output: 103.05 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:03<00:01, 86.00it/s, est. speed input: 104878.99 toks/s, output: 102.42 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:03<00:01, 86.20it/s, est. speed input: 104277.70 toks/s, output: 101.83 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:03<00:01, 86.07it/s, est. speed input: 103680.49 toks/s, output: 101.25 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:03<00:01, 85.87it/s, est. speed input: 103108.49 toks/s, output: 100.69 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:04<00:01, 85.46it/s, est. speed input: 102540.85 toks/s, output: 100.14 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:04<00:01, 85.47it/s, est. speed input: 102047.52 toks/s, output: 99.66 toks/s] 
Processed prompts:  86%|████████▌ | 438/512 [00:04<00:00, 85.77it/s, est. speed input: 101623.19 toks/s, output: 99.24 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:04<00:00, 87.15it/s, est. speed input: 101364.25 toks/s, output: 98.99 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:04<00:00, 87.12it/s, est. speed input: 101003.98 toks/s, output: 98.64 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:04<00:00, 86.84it/s, est. speed input: 100636.63 toks/s, output: 98.28 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:04<00:00, 86.43it/s, est. speed input: 100265.70 toks/s, output: 97.92 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:05<00:00, 85.97it/s, est. speed input: 99897.33 toks/s, output: 97.56 toks/s] 
Processed prompts: 100%|█████████▉| 510/512 [00:05<00:00, 87.13it/s, est. speed input: 99698.76 toks/s, output: 97.36 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 87.13it/s, est. speed input: 100084.72 toks/s, output: 97.74 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 97.74it/s, est. speed input: 100084.72 toks/s, output: 97.74 toks/s]
[rank0]:[W128 08:53:26.472315907 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 08:53:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:53:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3339208) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3339208) WARNING 01-28 08:53:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 88.40 requests/s, 90608.08 total tokens/s, 88.40 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 08:53:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:53:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:53:39] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:53:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:53:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:53:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:53:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:53:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:53:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:53:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:53:46] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:53:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:53:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:53:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:53:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:53:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:53:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3339208) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3339208) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=3339208) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=3339208) 
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3339208) [2026-01-28 08:53:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3339208) 2026-01-28 08:54:05,634 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3339208) 2026-01-28 08:54:05,662 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3339208) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 10.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  9.03it/s]
(EngineCore_DP0 pid=3339208) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 16.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 17.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.91it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 32/1024 [00:00<00:03, 317.10it/s]
Adding requests:   8%|▊         | 83/1024 [00:00<00:02, 427.07it/s]
Adding requests:  13%|█▎        | 133/1024 [00:00<00:01, 457.28it/s]
Adding requests:  18%|█▊        | 181/1024 [00:00<00:01, 464.76it/s]
Adding requests:  23%|██▎       | 231/1024 [00:00<00:01, 477.21it/s]
Adding requests:  27%|██▋       | 280/1024 [00:00<00:01, 480.93it/s]
Adding requests:  32%|███▏      | 329/1024 [00:00<00:01, 482.21it/s]
Adding requests:  37%|███▋      | 380/1024 [00:00<00:01, 490.50it/s]
Adding requests:  42%|████▏     | 430/1024 [00:00<00:01, 492.79it/s]
Adding requests:  47%|████▋     | 480/1024 [00:01<00:01, 491.24it/s]
Adding requests:  52%|█████▏    | 530/1024 [00:01<00:01, 475.34it/s]
Adding requests:  57%|█████▋    | 580/1024 [00:01<00:00, 481.16it/s]
Adding requests:  62%|██████▏   | 631/1024 [00:01<00:00, 489.34it/s]
Adding requests:  67%|██████▋   | 683/1024 [00:01<00:00, 498.27it/s]
Adding requests:  72%|███████▏  | 735/1024 [00:01<00:00, 503.78it/s]
Adding requests:  77%|███████▋  | 786/1024 [00:01<00:00, 501.44it/s]
Adding requests:  82%|████████▏ | 837/1024 [00:01<00:00, 492.55it/s]
Adding requests:  87%|████████▋ | 890/1024 [00:01<00:00, 502.65it/s]
Adding requests:  92%|█████████▏| 941/1024 [00:01<00:00, 503.82it/s]
Adding requests:  97%|█████████▋| 993/1024 [00:02<00:00, 507.51it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 488.61it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:00<00:00, 1232.30it/s, est. speed input: 1262279.56 toks/s, output: 1232.40 toks/s]
Processed prompts:  30%|███       | 310/1024 [00:01<00:04, 174.77it/s, est. speed input: 211660.68 toks/s, output: 206.70 toks/s]   
Processed prompts:  36%|███▌      | 367/1024 [00:02<00:04, 142.96it/s, est. speed input: 176854.26 toks/s, output: 172.71 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:02<00:04, 124.83it/s, est. speed input: 160027.93 toks/s, output: 156.27 toks/s]
Processed prompts:  42%|████▏     | 427/1024 [00:02<00:05, 118.60it/s, est. speed input: 153854.32 toks/s, output: 150.25 toks/s]
Processed prompts:  44%|████▎     | 446/1024 [00:03<00:04, 116.44it/s, est. speed input: 151069.93 toks/s, output: 147.53 toks/s]
Processed prompts:  45%|████▌     | 462/1024 [00:03<00:05, 111.93it/s, est. speed input: 147903.01 toks/s, output: 144.44 toks/s]
Processed prompts:  46%|████▋     | 476/1024 [00:03<00:05, 104.86it/s, est. speed input: 144271.47 toks/s, output: 140.89 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:03<00:05, 98.85it/s, est. speed input: 141060.37 toks/s, output: 137.75 toks/s] 
Processed prompts:  49%|████▉     | 506/1024 [00:03<00:05, 96.48it/s, est. speed input: 138675.31 toks/s, output: 135.42 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:03<00:05, 94.46it/s, est. speed input: 136473.36 toks/s, output: 133.27 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:04<00:05, 92.63it/s, est. speed input: 134400.89 toks/s, output: 131.25 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:04<00:05, 91.44it/s, est. speed input: 132543.96 toks/s, output: 129.44 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:04<00:05, 90.76it/s, est. speed input: 130877.22 toks/s, output: 127.81 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:04<00:04, 90.29it/s, est. speed input: 129345.70 toks/s, output: 126.31 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:04<00:04, 89.93it/s, est. speed input: 127922.13 toks/s, output: 124.92 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:04<00:04, 89.49it/s, est. speed input: 126571.49 toks/s, output: 123.60 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:05<00:04, 89.13it/s, est. speed input: 125305.27 toks/s, output: 122.37 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:05<00:04, 89.02it/s, est. speed input: 124148.54 toks/s, output: 121.24 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:05<00:04, 89.05it/s, est. speed input: 123082.49 toks/s, output: 120.20 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:05<00:03, 88.98it/s, est. speed input: 122071.50 toks/s, output: 119.21 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:05<00:03, 88.92it/s, est. speed input: 121119.25 toks/s, output: 118.28 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:06<00:03, 88.83it/s, est. speed input: 120217.89 toks/s, output: 117.40 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:06<00:03, 88.81it/s, est. speed input: 119373.59 toks/s, output: 116.58 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:06<00:03, 88.85it/s, est. speed input: 118583.95 toks/s, output: 115.80 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:06<00:02, 88.86it/s, est. speed input: 117834.33 toks/s, output: 115.07 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:06<00:02, 88.86it/s, est. speed input: 117123.99 toks/s, output: 114.38 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:06<00:02, 88.85it/s, est. speed input: 116449.13 toks/s, output: 113.72 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:07<00:02, 88.84it/s, est. speed input: 115807.11 toks/s, output: 113.09 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:07<00:02, 88.81it/s, est. speed input: 115195.55 toks/s, output: 112.50 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:07<00:02, 88.70it/s, est. speed input: 114603.27 toks/s, output: 111.92 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:07<00:01, 88.60it/s, est. speed input: 114036.63 toks/s, output: 111.36 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:07<00:01, 88.66it/s, est. speed input: 113508.25 toks/s, output: 110.85 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:08<00:01, 88.84it/s, est. speed input: 113017.05 toks/s, output: 110.37 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:08<00:01, 88.88it/s, est. speed input: 112539.66 toks/s, output: 109.90 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:08<00:01, 88.87it/s, est. speed input: 112077.75 toks/s, output: 109.45 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:08<00:00, 89.56it/s, est. speed input: 111697.22 toks/s, output: 109.08 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:08<00:00, 89.29it/s, est. speed input: 111267.36 toks/s, output: 108.66 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:08<00:00, 89.02it/s, est. speed input: 110848.04 toks/s, output: 108.25 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:09<00:00, 89.80it/s, est. speed input: 110524.34 toks/s, output: 107.93 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:09<00:00, 89.56it/s, est. speed input: 110149.65 toks/s, output: 107.57 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:09<00:00, 90.76it/s, est. speed input: 109893.63 toks/s, output: 107.32 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 90.76it/s, est. speed input: 110537.29 toks/s, output: 107.95 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 107.94it/s, est. speed input: 110537.29 toks/s, output: 107.95 toks/s]
[rank0]:[W128 08:54:19.891363108 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 08:54:21
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:54:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3340517) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3340517) WARNING 01-28 08:54:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 92.39 requests/s, 94697.67 total tokens/s, 92.39 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 08:54:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:54:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:54:37] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:54:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:54:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:54:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:54:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:54:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:54:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:54:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:54:44] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:54:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:54:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:54:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:54:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:54:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:54:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:45] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3340517) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3340517) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3340517) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3340517) 
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3340517) [2026-01-28 08:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3340517) 2026-01-28 08:55:03,450 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3340517) 2026-01-28 08:55:03,478 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3340517) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  9.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 13.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 15.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 14.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 14.56it/s]
(EngineCore_DP0 pid=3340517) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  9.94it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.60it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 34/2048 [00:00<00:06, 334.00it/s]
Adding requests:   4%|▍         | 85/2048 [00:00<00:04, 434.79it/s]
Adding requests:   7%|▋         | 134/2048 [00:00<00:04, 459.57it/s]
Adding requests:   9%|▉         | 182/2048 [00:00<00:04, 465.60it/s]
Adding requests:  11%|█▏        | 233/2048 [00:00<00:03, 478.78it/s]
Adding requests:  14%|█▍        | 283/2048 [00:00<00:03, 482.60it/s]
Adding requests:  16%|█▌        | 332/2048 [00:00<00:03, 483.38it/s]
Adding requests:  19%|█▊        | 382/2048 [00:00<00:03, 488.41it/s]
Adding requests:  21%|██        | 433/2048 [00:00<00:03, 492.94it/s]
Adding requests:  24%|██▎       | 483/2048 [00:01<00:03, 490.84it/s]
Adding requests:  26%|██▌       | 533/2048 [00:01<00:03, 479.59it/s]
Adding requests:  29%|██▊       | 584/2048 [00:01<00:03, 487.65it/s]
Adding requests:  31%|███       | 635/2048 [00:01<00:02, 492.50it/s]
Adding requests:  34%|███▎      | 687/2048 [00:01<00:02, 497.59it/s]
Adding requests:  36%|███▌      | 737/2048 [00:01<00:02, 496.17it/s]
Adding requests:  38%|███▊      | 787/2048 [00:01<00:02, 491.78it/s]
Adding requests:  41%|████      | 837/2048 [00:01<00:02, 477.61it/s]
Adding requests:  43%|████▎     | 889/2048 [00:01<00:02, 487.79it/s]
Adding requests:  46%|████▌     | 939/2048 [00:01<00:02, 490.01it/s]
Adding requests:  48%|████▊     | 990/2048 [00:02<00:02, 493.79it/s]
Adding requests:  51%|█████     | 1041/2048 [00:02<00:02, 495.24it/s]
Adding requests:  53%|█████▎    | 1091/2048 [00:02<00:01, 492.15it/s]
Adding requests:  56%|█████▌    | 1141/2048 [00:02<00:01, 485.07it/s]
Adding requests:  58%|█████▊    | 1196/2048 [00:02<00:01, 503.09it/s]
Adding requests:  61%|██████    | 1248/2048 [00:02<00:01, 507.21it/s]
Adding requests:  63%|██████▎   | 1299/2048 [00:02<00:01, 507.49it/s]
Adding requests:  66%|██████▌   | 1353/2048 [00:02<00:01, 514.21it/s]
Adding requests:  69%|██████▊   | 1407/2048 [00:02<00:01, 519.76it/s]
Adding requests:  71%|███████   | 1459/2048 [00:02<00:01, 516.95it/s]
Adding requests:  74%|███████▍  | 1512/2048 [00:03<00:01, 519.98it/s]
Adding requests:  76%|███████▋  | 1565/2048 [00:03<00:00, 519.90it/s]
Adding requests:  79%|███████▉  | 1618/2048 [00:03<00:00, 521.71it/s]
Adding requests:  82%|████████▏ | 1671/2048 [00:03<00:00, 518.74it/s]
Adding requests:  84%|████████▍ | 1724/2048 [00:03<00:00, 520.95it/s]
Adding requests:  87%|████████▋ | 1777/2048 [00:03<00:00, 515.23it/s]
Adding requests:  89%|████████▉ | 1829/2048 [00:03<00:00, 514.16it/s]
Adding requests:  92%|█████████▏| 1881/2048 [00:03<00:00, 514.22it/s]
Adding requests:  94%|█████████▍| 1933/2048 [00:03<00:00, 449.59it/s]
Adding requests:  97%|█████████▋| 1983/2048 [00:04<00:00, 462.32it/s]
Adding requests:  99%|█████████▉| 2036/2048 [00:04<00:00, 478.48it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 492.54it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:00<00:00, 3646.05it/s, est. speed input: 3735684.80 toks/s, output: 3647.12 toks/s]
Processed prompts:  36%|███▌      | 735/2048 [00:03<00:08, 161.85it/s, est. speed input: 193686.77 toks/s, output: 189.15 toks/s]   
Processed prompts:  44%|████▎     | 891/2048 [00:05<00:08, 134.01it/s, est. speed input: 162612.89 toks/s, output: 158.80 toks/s]
Processed prompts:  48%|████▊     | 980/2048 [00:06<00:08, 122.43it/s, est. speed input: 151349.48 toks/s, output: 147.80 toks/s]
Processed prompts:  51%|█████     | 1038/2048 [00:07<00:08, 120.84it/s, est. speed input: 148692.82 toks/s, output: 145.21 toks/s]
Processed prompts:  53%|█████▎    | 1079/2048 [00:07<00:08, 113.35it/s, est. speed input: 144106.75 toks/s, output: 140.73 toks/s]
Processed prompts:  54%|█████▍    | 1109/2048 [00:08<00:08, 109.51it/s, est. speed input: 141733.79 toks/s, output: 138.41 toks/s]
Processed prompts:  55%|█████▌    | 1132/2048 [00:08<00:08, 111.76it/s, est. speed input: 141626.39 toks/s, output: 138.31 toks/s]
Processed prompts:  56%|█████▋    | 1152/2048 [00:08<00:07, 112.25it/s, est. speed input: 141152.28 toks/s, output: 137.84 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:08<00:09, 97.51it/s, est. speed input: 137775.43 toks/s, output: 134.55 toks/s] 
Processed prompts:  58%|█████▊    | 1186/2048 [00:08<00:08, 96.72it/s, est. speed input: 136931.62 toks/s, output: 133.72 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:09<00:08, 96.04it/s, est. speed input: 136135.70 toks/s, output: 132.94 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:09<00:08, 95.33it/s, est. speed input: 135360.07 toks/s, output: 132.19 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:09<00:08, 94.58it/s, est. speed input: 134599.63 toks/s, output: 131.44 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:09<00:08, 94.11it/s, est. speed input: 133881.45 toks/s, output: 130.74 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:09<00:08, 94.81it/s, est. speed input: 133293.08 toks/s, output: 130.17 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:09<00:08, 94.24it/s, est. speed input: 132624.34 toks/s, output: 129.52 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:10<00:07, 93.78it/s, est. speed input: 131976.27 toks/s, output: 128.88 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:10<00:07, 93.63it/s, est. speed input: 131365.27 toks/s, output: 128.29 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:10<00:07, 93.16it/s, est. speed input: 130744.70 toks/s, output: 127.68 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:10<00:07, 92.59it/s, est. speed input: 130126.68 toks/s, output: 127.08 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:10<00:07, 92.61it/s, est. speed input: 129561.47 toks/s, output: 126.52 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:10<00:07, 92.57it/s, est. speed input: 129009.86 toks/s, output: 125.99 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:11<00:07, 92.54it/s, est. speed input: 128475.41 toks/s, output: 125.46 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:11<00:06, 92.72it/s, est. speed input: 127971.23 toks/s, output: 124.97 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:11<00:06, 92.34it/s, est. speed input: 127447.63 toks/s, output: 124.46 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:11<00:06, 91.77it/s, est. speed input: 126917.92 toks/s, output: 123.94 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:11<00:06, 91.94it/s, est. speed input: 126443.12 toks/s, output: 123.48 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:11<00:06, 92.22it/s, est. speed input: 125992.89 toks/s, output: 123.04 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:12<00:06, 92.28it/s, est. speed input: 125546.63 toks/s, output: 122.60 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:12<00:05, 92.41it/s, est. speed input: 125117.40 toks/s, output: 122.18 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:12<00:05, 92.26it/s, est. speed input: 124686.07 toks/s, output: 121.76 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:12<00:05, 92.43it/s, est. speed input: 124282.71 toks/s, output: 121.37 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:12<00:05, 92.42it/s, est. speed input: 123883.15 toks/s, output: 120.98 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:13<00:05, 92.44it/s, est. speed input: 123495.05 toks/s, output: 120.60 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:13<00:04, 93.62it/s, est. speed input: 123184.81 toks/s, output: 120.30 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:13<00:04, 93.43it/s, est. speed input: 122824.20 toks/s, output: 119.95 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:13<00:04, 93.06it/s, est. speed input: 122459.92 toks/s, output: 119.59 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:13<00:04, 92.82it/s, est. speed input: 122105.77 toks/s, output: 119.24 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:13<00:04, 92.67it/s, est. speed input: 121761.51 toks/s, output: 118.91 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:14<00:04, 92.51it/s, est. speed input: 121422.99 toks/s, output: 118.58 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:14<00:03, 92.56it/s, est. speed input: 121100.88 toks/s, output: 118.26 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:14<00:03, 92.46it/s, est. speed input: 120779.72 toks/s, output: 117.95 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:14<00:03, 92.37it/s, est. speed input: 120464.86 toks/s, output: 117.64 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:14<00:03, 92.53it/s, est. speed input: 120169.17 toks/s, output: 117.35 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:14<00:03, 92.47it/s, est. speed input: 119871.13 toks/s, output: 117.06 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:15<00:03, 92.34it/s, est. speed input: 119576.23 toks/s, output: 116.77 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:15<00:02, 92.57it/s, est. speed input: 119303.12 toks/s, output: 116.51 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:15<00:02, 92.35it/s, est. speed input: 119018.29 toks/s, output: 116.23 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:15<00:02, 92.34it/s, est. speed input: 118746.19 toks/s, output: 115.96 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:15<00:02, 92.51it/s, est. speed input: 118488.77 toks/s, output: 115.71 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:15<00:02, 92.42it/s, est. speed input: 118226.97 toks/s, output: 115.46 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:16<00:02, 91.59it/s, est. speed input: 117935.52 toks/s, output: 115.17 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:16<00:01, 93.74it/s, est. speed input: 117772.99 toks/s, output: 115.01 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:16<00:01, 93.41it/s, est. speed input: 117532.91 toks/s, output: 114.78 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:16<00:01, 93.00it/s, est. speed input: 117289.82 toks/s, output: 114.54 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:16<00:01, 92.64it/s, est. speed input: 117048.65 toks/s, output: 114.31 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:16<00:01, 92.45it/s, est. speed input: 116814.94 toks/s, output: 114.08 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:17<00:01, 93.78it/s, est. speed input: 116647.09 toks/s, output: 113.91 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:17<00:00, 93.49it/s, est. speed input: 116432.37 toks/s, output: 113.70 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:17<00:00, 93.44it/s, est. speed input: 116228.08 toks/s, output: 113.50 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:17<00:00, 93.11it/s, est. speed input: 116015.40 toks/s, output: 113.30 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:17<00:00, 92.98it/s, est. speed input: 115811.03 toks/s, output: 113.10 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:18<00:00, 94.43it/s, est. speed input: 115671.01 toks/s, output: 112.96 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:18<00:00, 94.43it/s, est. speed input: 116463.61 toks/s, output: 113.73 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:18<00:00, 113.73it/s, est. speed input: 116463.61 toks/s, output: 113.73 toks/s]
[rank0]:[W128 08:55:28.533264016 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 08:55:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:55:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3342023) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3342023) WARNING 01-28 08:56:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 93.80 requests/s, 96147.59 total tokens/s, 93.80 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 08:55:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:55:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:55:54] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:55:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:55:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:55:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:55:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:55:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:55:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:56:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 08:56:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:56:01] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:56:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:56:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:56:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:56:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:56:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:56:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3342023) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3342023) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3342023) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3342023) 
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9830400 bytes
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6553600 bytes
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35389440 bytes
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3342023) [2026-01-28 08:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17715200 bytes
(EngineCore_DP0 pid=3342023) [rank0]:W0128 08:56:15.544000 3342023 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3342023) [rank0]:W0128 08:56:15.636000 3342023 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3342023) [rank0]:W0128 08:56:16.643000 3342023 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3342023) [rank0]:W0128 08:56:16.772000 3342023 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3342023) 2026-01-28 08:56:20,668 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3342023) 2026-01-28 08:56:20,698 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3342023) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  5.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 10.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 12.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 13.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.96it/s]
(EngineCore_DP0 pid=3342023) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 15.79it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 16.56it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 16.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 16.72it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 35/4096 [00:00<00:11, 346.64it/s]
Adding requests:   2%|▏         | 86/4096 [00:00<00:09, 438.37it/s]
Adding requests:   3%|▎         | 135/4096 [00:00<00:08, 461.21it/s]
Adding requests:   5%|▍         | 185/4096 [00:00<00:08, 474.78it/s]
Adding requests:   6%|▌         | 237/4096 [00:00<00:07, 489.70it/s]
Adding requests:   7%|▋         | 288/4096 [00:00<00:07, 495.13it/s]
Adding requests:   8%|▊         | 339/4096 [00:00<00:07, 496.83it/s]
Adding requests:  10%|▉         | 392/4096 [00:00<00:07, 506.51it/s]
Adding requests:  11%|█         | 443/4096 [00:00<00:07, 506.57it/s]
Adding requests:  12%|█▏        | 495/4096 [00:01<00:07, 508.85it/s]
Adding requests:  13%|█▎        | 546/4096 [00:01<00:07, 500.97it/s]
Adding requests:  15%|█▍        | 599/4096 [00:01<00:06, 508.24it/s]
Adding requests:  16%|█▌        | 652/4096 [00:01<00:06, 513.05it/s]
Adding requests:  17%|█▋        | 706/4096 [00:01<00:06, 519.58it/s]
Adding requests:  19%|█▊        | 758/4096 [00:01<00:06, 518.43it/s]
Adding requests:  20%|█▉        | 810/4096 [00:01<00:07, 455.49it/s]
Adding requests:  21%|██        | 858/4096 [00:01<00:07, 462.04it/s]
Adding requests:  22%|██▏       | 910/4096 [00:01<00:06, 477.93it/s]
Adding requests:  23%|██▎       | 962/4096 [00:01<00:06, 488.92it/s]
Adding requests:  25%|██▍       | 1014/4096 [00:02<00:06, 496.21it/s]
Adding requests:  26%|██▌       | 1065/4096 [00:02<00:06, 500.08it/s]
Adding requests:  27%|██▋       | 1116/4096 [00:02<00:06, 482.24it/s]
Adding requests:  29%|██▊       | 1169/4096 [00:02<00:05, 495.67it/s]
Adding requests:  30%|██▉       | 1222/4096 [00:02<00:05, 505.41it/s]
Adding requests:  31%|███       | 1273/4096 [00:02<00:05, 501.94it/s]
Adding requests:  32%|███▏      | 1326/4096 [00:02<00:05, 506.39it/s]
Adding requests:  34%|███▎      | 1379/4096 [00:02<00:05, 510.43it/s]
Adding requests:  35%|███▍      | 1432/4096 [00:02<00:05, 514.63it/s]
Adding requests:  36%|███▋      | 1485/4096 [00:02<00:05, 516.70it/s]
Adding requests:  38%|███▊      | 1538/4096 [00:03<00:04, 520.35it/s]
Adding requests:  39%|███▉      | 1592/4096 [00:03<00:04, 523.92it/s]
Adding requests:  40%|████      | 1645/4096 [00:03<00:04, 525.11it/s]
Adding requests:  41%|████▏     | 1698/4096 [00:03<00:04, 519.81it/s]
Adding requests:  43%|████▎     | 1751/4096 [00:03<00:04, 520.13it/s]
Adding requests:  44%|████▍     | 1804/4096 [00:03<00:04, 518.46it/s]
Adding requests:  45%|████▌     | 1857/4096 [00:03<00:04, 519.14it/s]
Adding requests:  47%|████▋     | 1909/4096 [00:03<00:04, 514.65it/s]
Adding requests:  48%|████▊     | 1962/4096 [00:03<00:04, 516.68it/s]
Adding requests:  49%|████▉     | 2015/4096 [00:04<00:04, 519.25it/s]
Adding requests:  50%|█████     | 2067/4096 [00:04<00:03, 512.75it/s]
Adding requests:  52%|█████▏    | 2119/4096 [00:04<00:03, 512.83it/s]
Adding requests:  53%|█████▎    | 2171/4096 [00:04<00:03, 506.53it/s]
Adding requests:  54%|█████▍    | 2223/4096 [00:04<00:03, 509.36it/s]
Adding requests:  56%|█████▌    | 2274/4096 [00:04<00:03, 498.11it/s]
Adding requests:  57%|█████▋    | 2325/4096 [00:04<00:03, 501.17it/s]
Adding requests:  58%|█████▊    | 2377/4096 [00:04<00:03, 504.95it/s]
Adding requests:  59%|█████▉    | 2429/4096 [00:04<00:03, 508.88it/s]
Adding requests:  61%|██████    | 2481/4096 [00:04<00:03, 510.46it/s]
Adding requests:  62%|██████▏   | 2533/4096 [00:05<00:03, 510.24it/s]
Adding requests:  63%|██████▎   | 2586/4096 [00:05<00:02, 515.02it/s]
Adding requests:  64%|██████▍   | 2638/4096 [00:05<00:02, 514.73it/s]
Adding requests:  66%|██████▌   | 2691/4096 [00:05<00:02, 516.34it/s]
Adding requests:  67%|██████▋   | 2743/4096 [00:05<00:02, 514.39it/s]
Adding requests:  68%|██████▊   | 2795/4096 [00:05<00:02, 511.52it/s]
Adding requests:  70%|██████▉   | 2848/4096 [00:05<00:02, 514.04it/s]
Adding requests:  71%|███████   | 2900/4096 [00:05<00:02, 515.30it/s]
Adding requests:  72%|███████▏  | 2952/4096 [00:05<00:02, 511.91it/s]
Adding requests:  73%|███████▎  | 3004/4096 [00:05<00:02, 512.74it/s]
Adding requests:  75%|███████▍  | 3056/4096 [00:06<00:02, 514.78it/s]
Adding requests:  76%|███████▌  | 3108/4096 [00:06<00:01, 510.45it/s]
Adding requests:  77%|███████▋  | 3160/4096 [00:06<00:01, 513.01it/s]
Adding requests:  78%|███████▊  | 3212/4096 [00:06<00:01, 512.10it/s]
Adding requests:  80%|███████▉  | 3265/4096 [00:06<00:01, 515.84it/s]
Adding requests:  81%|████████  | 3317/4096 [00:06<00:01, 514.59it/s]
Adding requests:  82%|████████▏ | 3369/4096 [00:06<00:01, 515.76it/s]
Adding requests:  84%|████████▎ | 3421/4096 [00:06<00:01, 516.68it/s]
Adding requests:  85%|████████▍ | 3473/4096 [00:06<00:01, 508.01it/s]
Adding requests:  86%|████████▌ | 3525/4096 [00:06<00:01, 508.77it/s]
Adding requests:  87%|████████▋ | 3576/4096 [00:07<00:01, 508.62it/s]
Adding requests:  89%|████████▊ | 3627/4096 [00:07<00:00, 490.41it/s]
Adding requests:  90%|████████▉ | 3680/4096 [00:07<00:00, 500.78it/s]
Adding requests:  91%|█████████ | 3732/4096 [00:07<00:00, 503.84it/s]
Adding requests:  92%|█████████▏| 3787/4096 [00:07<00:00, 514.81it/s]
Adding requests:  94%|█████████▎| 3839/4096 [00:07<00:00, 515.87it/s]
Adding requests:  95%|█████████▌| 3893/4096 [00:07<00:00, 520.07it/s]
Adding requests:  96%|█████████▋| 3946/4096 [00:07<00:00, 519.48it/s]
Adding requests:  98%|█████████▊| 3998/4096 [00:07<00:00, 516.67it/s]
Adding requests:  99%|█████████▉| 4050/4096 [00:07<00:00, 511.66it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 506.55it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:00<00:01, 2713.39it/s, est. speed input: 2778978.20 toks/s, output: 2713.52 toks/s]
Processed prompts:  25%|██▍       | 1010/4096 [00:02<00:11, 272.57it/s, est. speed input: 347665.64 toks/s, output: 339.52 toks/s]  
Processed prompts:  28%|██▊       | 1128/4096 [00:04<00:14, 197.91it/s, est. speed input: 266455.47 toks/s, output: 260.21 toks/s]
Processed prompts:  29%|██▉       | 1196/4096 [00:05<00:16, 176.60it/s, est. speed input: 244649.28 toks/s, output: 238.91 toks/s]
Processed prompts:  30%|███       | 1242/4096 [00:05<00:16, 170.69it/s, est. speed input: 237755.83 toks/s, output: 232.18 toks/s]
Processed prompts:  31%|███       | 1276/4096 [00:05<00:17, 159.66it/s, est. speed input: 229970.25 toks/s, output: 224.58 toks/s]
Processed prompts:  32%|███▏      | 1302/4096 [00:06<00:19, 143.86it/s, est. speed input: 221431.31 toks/s, output: 216.24 toks/s]
Processed prompts:  32%|███▏      | 1322/4096 [00:06<00:22, 125.49it/s, est. speed input: 212744.90 toks/s, output: 207.76 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:06<00:24, 112.64it/s, est. speed input: 205619.84 toks/s, output: 200.80 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:07<00:25, 107.93it/s, est. speed input: 200321.73 toks/s, output: 195.63 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:07<00:25, 104.13it/s, est. speed input: 195481.25 toks/s, output: 190.90 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:07<00:26, 101.41it/s, est. speed input: 191123.96 toks/s, output: 186.64 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [00:08<00:26, 99.20it/s, est. speed input: 187083.43 toks/s, output: 182.70 toks/s] 
Processed prompts:  37%|███▋      | 1506/4096 [00:08<00:26, 97.58it/s, est. speed input: 183372.45 toks/s, output: 179.07 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:08<00:26, 96.50it/s, est. speed input: 179970.90 toks/s, output: 175.75 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:09<00:26, 96.35it/s, est. speed input: 176974.73 toks/s, output: 172.83 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [00:09<00:26, 95.36it/s, est. speed input: 173992.25 toks/s, output: 169.91 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [00:09<00:25, 94.82it/s, est. speed input: 171255.39 toks/s, output: 167.24 toks/s]
Processed prompts:  41%|████      | 1666/4096 [00:10<00:25, 94.52it/s, est. speed input: 168717.82 toks/s, output: 164.76 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [00:10<00:25, 94.28it/s, est. speed input: 166341.15 toks/s, output: 162.44 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [00:10<00:25, 94.21it/s, est. speed input: 164133.67 toks/s, output: 160.29 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [00:11<00:24, 94.01it/s, est. speed input: 162034.60 toks/s, output: 158.24 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [00:11<00:24, 93.95it/s, est. speed input: 160072.68 toks/s, output: 156.32 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [00:11<00:24, 94.09it/s, est. speed input: 158253.95 toks/s, output: 154.54 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [00:12<00:23, 94.71it/s, est. speed input: 156619.03 toks/s, output: 152.95 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [00:12<00:23, 94.47it/s, est. speed input: 154969.54 toks/s, output: 151.34 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [00:12<00:23, 94.30it/s, est. speed input: 153407.51 toks/s, output: 149.81 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [00:13<00:22, 94.88it/s, est. speed input: 152022.75 toks/s, output: 148.46 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [00:13<00:22, 94.50it/s, est. speed input: 150601.85 toks/s, output: 147.07 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [00:13<00:22, 94.40it/s, est. speed input: 149271.37 toks/s, output: 145.77 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [00:14<00:21, 94.28it/s, est. speed input: 147999.35 toks/s, output: 144.53 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [00:14<00:21, 94.18it/s, est. speed input: 146783.99 toks/s, output: 143.34 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [00:14<00:21, 93.66it/s, est. speed input: 145571.67 toks/s, output: 142.16 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [00:15<00:20, 94.02it/s, est. speed input: 144498.38 toks/s, output: 141.11 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [00:15<00:20, 93.91it/s, est. speed input: 143430.32 toks/s, output: 140.07 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [00:15<00:19, 95.50it/s, est. speed input: 142586.87 toks/s, output: 139.24 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [00:16<00:19, 95.09it/s, est. speed input: 141618.10 toks/s, output: 138.30 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [00:16<00:19, 95.44it/s, est. speed input: 140753.28 toks/s, output: 137.45 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [00:16<00:18, 94.88it/s, est. speed input: 139844.07 toks/s, output: 136.57 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [00:17<00:18, 95.16it/s, est. speed input: 139034.52 toks/s, output: 135.78 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [00:17<00:17, 96.58it/s, est. speed input: 138367.70 toks/s, output: 135.12 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [00:17<00:17, 95.64it/s, est. speed input: 137552.95 toks/s, output: 134.33 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [00:18<00:17, 95.12it/s, est. speed input: 136778.78 toks/s, output: 133.57 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [00:18<00:17, 94.73it/s, est. speed input: 136031.01 toks/s, output: 132.84 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [00:18<00:16, 95.13it/s, est. speed input: 135367.70 toks/s, output: 132.19 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [00:19<00:16, 94.74it/s, est. speed input: 134671.59 toks/s, output: 131.51 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [00:19<00:16, 95.19it/s, est. speed input: 134058.17 toks/s, output: 130.92 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [00:19<00:15, 94.70it/s, est. speed input: 133401.31 toks/s, output: 130.27 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [00:20<00:15, 94.39it/s, est. speed input: 132769.73 toks/s, output: 129.66 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [00:20<00:15, 94.29it/s, est. speed input: 132167.16 toks/s, output: 129.07 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [00:20<00:14, 94.10it/s, est. speed input: 131575.69 toks/s, output: 128.49 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [00:21<00:14, 94.00it/s, est. speed input: 131005.51 toks/s, output: 127.93 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [00:21<00:14, 94.04it/s, est. speed input: 130460.95 toks/s, output: 127.40 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [00:21<00:13, 93.96it/s, est. speed input: 129925.61 toks/s, output: 126.88 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [00:22<00:13, 93.93it/s, est. speed input: 129408.40 toks/s, output: 126.38 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [00:22<00:13, 93.87it/s, est. speed input: 128904.74 toks/s, output: 125.88 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [00:22<00:12, 93.78it/s, est. speed input: 128412.15 toks/s, output: 125.40 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [00:23<00:12, 93.73it/s, est. speed input: 127935.38 toks/s, output: 124.94 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [00:23<00:12, 93.62it/s, est. speed input: 127467.19 toks/s, output: 124.48 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [00:24<00:11, 93.55it/s, est. speed input: 127012.86 toks/s, output: 124.04 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [00:24<00:11, 93.59it/s, est. speed input: 126576.81 toks/s, output: 123.61 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [00:24<00:11, 93.57it/s, est. speed input: 126150.11 toks/s, output: 123.19 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [00:25<00:10, 93.56it/s, est. speed input: 125734.79 toks/s, output: 122.79 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [00:25<00:10, 93.76it/s, est. speed input: 125343.47 toks/s, output: 122.41 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [00:25<00:10, 94.36it/s, est. speed input: 124989.11 toks/s, output: 122.06 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [00:26<00:09, 93.96it/s, est. speed input: 124596.98 toks/s, output: 121.68 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [00:26<00:09, 94.00it/s, est. speed input: 124233.09 toks/s, output: 121.32 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [00:26<00:09, 93.86it/s, est. speed input: 123868.93 toks/s, output: 120.97 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [00:27<00:08, 93.67it/s, est. speed input: 123508.63 toks/s, output: 120.61 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [00:27<00:08, 93.76it/s, est. speed input: 123170.03 toks/s, output: 120.28 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [00:27<00:08, 93.74it/s, est. speed input: 122834.70 toks/s, output: 119.96 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [00:28<00:07, 93.66it/s, est. speed input: 122504.33 toks/s, output: 119.63 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [00:28<00:07, 93.64it/s, est. speed input: 122183.98 toks/s, output: 119.32 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [00:28<00:07, 93.68it/s, est. speed input: 121873.57 toks/s, output: 119.02 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [00:29<00:06, 93.60it/s, est. speed input: 121565.52 toks/s, output: 118.72 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [00:29<00:06, 95.13it/s, est. speed input: 121342.72 toks/s, output: 118.50 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [00:29<00:06, 94.73it/s, est. speed input: 121053.45 toks/s, output: 118.22 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [00:30<00:05, 94.39it/s, est. speed input: 120767.09 toks/s, output: 117.94 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [00:30<00:05, 94.11it/s, est. speed input: 120485.89 toks/s, output: 117.66 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [00:30<00:05, 93.95it/s, est. speed input: 120211.91 toks/s, output: 117.39 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [00:31<00:04, 93.89it/s, est. speed input: 119946.66 toks/s, output: 117.14 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [00:31<00:04, 93.87it/s, est. speed input: 119688.23 toks/s, output: 116.88 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [00:31<00:04, 94.37it/s, est. speed input: 119458.59 toks/s, output: 116.66 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [00:32<00:03, 94.09it/s, est. speed input: 119205.84 toks/s, output: 116.41 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [00:32<00:03, 93.99it/s, est. speed input: 118962.17 toks/s, output: 116.17 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [00:32<00:03, 93.81it/s, est. speed input: 118718.91 toks/s, output: 115.94 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [00:33<00:02, 94.29it/s, est. speed input: 118506.82 toks/s, output: 115.73 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [00:33<00:02, 94.12it/s, est. speed input: 118277.36 toks/s, output: 115.51 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [00:33<00:02, 93.94it/s, est. speed input: 118049.91 toks/s, output: 115.28 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [00:34<00:01, 93.80it/s, est. speed input: 117826.51 toks/s, output: 115.06 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [00:34<00:01, 93.66it/s, est. speed input: 117606.11 toks/s, output: 114.85 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [00:34<00:01, 93.57it/s, est. speed input: 117389.99 toks/s, output: 114.64 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [00:35<00:00, 94.08it/s, est. speed input: 117201.37 toks/s, output: 114.45 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [00:35<00:00, 94.91it/s, est. speed input: 117034.34 toks/s, output: 114.29 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 94.91it/s, est. speed input: 117894.33 toks/s, output: 115.13 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 115.13it/s, est. speed input: 117894.33 toks/s, output: 115.13 toks/s]
[rank0]:[W128 08:57:07.773285610 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

