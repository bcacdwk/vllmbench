
========== M=16 ==========
Time: 2026-01-26 07:59:38
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:59:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1015714) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1015714) WARNING 01-26 07:59:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.70 requests/s, 521.93 total tokens/s, 30.70 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:59:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:59:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:59:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:59:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:59:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:59:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:59:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:59:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:59:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:59:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:59:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:59:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:59:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:59:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:59:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:59:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:59:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1015714) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1015714) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.01it/s]
(EngineCore_DP0 pid=1015714) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.01it/s]
(EngineCore_DP0 pid=1015714) 
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1015714) [2026-01-26 07:59:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1015714) 2026-01-26 08:00:07,235 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1015714) 2026-01-26 08:00:07,293 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1015714) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.22it/s]
(EngineCore_DP0 pid=1015714) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.89it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2765.41it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:34,  3.67it/s, est. speed input: 58.78 toks/s, output: 3.67 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:08, 15.06it/s, est. speed input: 203.18 toks/s, output: 12.70 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 21.60it/s, est. speed input: 280.83 toks/s, output: 17.55 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 25.48it/s, est. speed input: 328.20 toks/s, output: 20.51 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 27.93it/s, est. speed input: 360.21 toks/s, output: 22.51 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.52it/s, est. speed input: 383.31 toks/s, output: 23.96 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 30.58it/s, est. speed input: 400.73 toks/s, output: 25.04 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.29it/s, est. speed input: 414.34 toks/s, output: 25.90 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 31.81it/s, est. speed input: 425.46 toks/s, output: 26.59 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.12it/s, est. speed input: 434.38 toks/s, output: 27.15 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.37it/s, est. speed input: 441.96 toks/s, output: 27.62 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.55it/s, est. speed input: 448.40 toks/s, output: 28.02 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.66it/s, est. speed input: 453.93 toks/s, output: 28.37 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.78it/s, est. speed input: 458.82 toks/s, output: 28.68 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.85it/s, est. speed input: 463.10 toks/s, output: 28.94 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.85it/s, est. speed input: 466.73 toks/s, output: 29.17 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.09it/s, est. speed input: 470.59 toks/s, output: 29.41 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.30it/s, est. speed input: 474.15 toks/s, output: 29.63 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.44it/s, est. speed input: 477.36 toks/s, output: 29.83 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.48it/s, est. speed input: 480.15 toks/s, output: 30.01 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.50it/s, est. speed input: 482.66 toks/s, output: 30.17 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.43it/s, est. speed input: 484.78 toks/s, output: 30.30 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.18it/s, est. speed input: 486.33 toks/s, output: 30.40 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.06it/s, est. speed input: 487.86 toks/s, output: 30.49 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.95it/s, est. speed input: 489.23 toks/s, output: 30.58 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.94it/s, est. speed input: 490.61 toks/s, output: 30.66 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.90it/s, est. speed input: 491.83 toks/s, output: 30.74 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.86it/s, est. speed input: 492.96 toks/s, output: 30.81 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.81it/s, est. speed input: 493.95 toks/s, output: 30.87 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.78it/s, est. speed input: 494.91 toks/s, output: 30.93 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.56it/s, est. speed input: 495.49 toks/s, output: 30.97 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 32.62it/s, est. speed input: 496.36 toks/s, output: 31.02 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.62it/s, est. speed input: 496.98 toks/s, output: 31.06 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.06it/s, est. speed input: 496.98 toks/s, output: 31.06 toks/s]
[rank0]:[W126 08:00:13.726739660 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 08:00:16
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:00:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1016792) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1016792) WARNING 01-26 08:00:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.36 requests/s, 4045.85 total tokens/s, 31.36 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 08:00:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:00:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:00:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:00:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:00:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:00:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:00:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:00:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:00:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:00:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:00:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:00:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:00:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:00:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:00:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:00:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:00:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1016792) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1016792) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.74it/s]
(EngineCore_DP0 pid=1016792) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.74it/s]
(EngineCore_DP0 pid=1016792) 
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1016792) [2026-01-26 08:00:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1016792) 2026-01-26 08:00:45,869 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1016792) 2026-01-26 08:00:45,940 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1016792) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 13.49it/s]
(EngineCore_DP0 pid=1016792) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.27it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1665.96it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:19,  6.41it/s, est. speed input: 820.23 toks/s, output: 6.41 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 20.52it/s, est. speed input: 2320.61 toks/s, output: 18.13 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.86it/s, est. speed input: 2898.74 toks/s, output: 22.64 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 28.61it/s, est. speed input: 3210.65 toks/s, output: 25.08 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 30.16it/s, est. speed input: 3402.78 toks/s, output: 26.58 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 31.07it/s, est. speed input: 3531.51 toks/s, output: 27.59 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.67it/s, est. speed input: 3625.50 toks/s, output: 28.32 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.15it/s, est. speed input: 3700.55 toks/s, output: 28.91 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.38it/s, est. speed input: 3755.56 toks/s, output: 29.34 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.57it/s, est. speed input: 3801.07 toks/s, output: 29.69 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.71it/s, est. speed input: 3838.88 toks/s, output: 29.99 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.76it/s, est. speed input: 3868.88 toks/s, output: 30.22 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.78it/s, est. speed input: 3894.03 toks/s, output: 30.42 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.88it/s, est. speed input: 3918.15 toks/s, output: 30.61 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.91it/s, est. speed input: 3938.11 toks/s, output: 30.77 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 32.92it/s, est. speed input: 3955.09 toks/s, output: 30.90 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.88it/s, est. speed input: 3969.25 toks/s, output: 31.01 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.92it/s, est. speed input: 3983.16 toks/s, output: 31.12 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.14it/s, est. speed input: 3999.72 toks/s, output: 31.25 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.11it/s, est. speed input: 4010.95 toks/s, output: 31.34 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.10it/s, est. speed input: 4021.46 toks/s, output: 31.42 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.09it/s, est. speed input: 4030.89 toks/s, output: 31.49 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.07it/s, est. speed input: 4039.38 toks/s, output: 31.56 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.05it/s, est. speed input: 4046.91 toks/s, output: 31.62 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.02it/s, est. speed input: 4053.79 toks/s, output: 31.67 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.04it/s, est. speed input: 4060.61 toks/s, output: 31.72 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.02it/s, est. speed input: 4066.48 toks/s, output: 31.77 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.05it/s, est. speed input: 4072.56 toks/s, output: 31.82 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.00it/s, est. speed input: 4077.25 toks/s, output: 31.85 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.98it/s, est. speed input: 4081.91 toks/s, output: 31.89 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.94it/s, est. speed input: 4085.86 toks/s, output: 31.92 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 32.96it/s, est. speed input: 4090.15 toks/s, output: 31.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.96it/s, est. speed input: 4093.08 toks/s, output: 31.98 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.97it/s, est. speed input: 4093.08 toks/s, output: 31.98 toks/s]
[rank0]:[W126 08:00:52.120962910 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 08:00:54
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:01:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1017840) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1017840) WARNING 01-26 08:01:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.06 requests/s, 7725.29 total tokens/s, 30.06 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 08:01:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:01:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:01:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:01:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1017840) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1017840) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=1017840) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=1017840) 
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1017840) [2026-01-26 08:01:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1017840) 2026-01-26 08:01:21,857 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1017840) 2026-01-26 08:01:22,147 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1017840) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.43it/s]
(EngineCore_DP0 pid=1017840) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 19.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|██████▉   | 89/128 [00:00<00:00, 884.68it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1021.55it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:34,  3.66it/s, est. speed input: 936.12 toks/s, output: 3.66 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:08, 15.14it/s, est. speed input: 3261.23 toks/s, output: 12.74 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 21.69it/s, est. speed input: 4507.07 toks/s, output: 17.60 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 25.68it/s, est. speed input: 5278.61 toks/s, output: 20.62 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 28.01it/s, est. speed input: 5782.53 toks/s, output: 22.59 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.53it/s, est. speed input: 6146.02 toks/s, output: 24.01 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 30.72it/s, est. speed input: 6434.38 toks/s, output: 25.13 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.60it/s, est. speed input: 6665.99 toks/s, output: 26.04 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.04it/s, est. speed input: 6841.63 toks/s, output: 26.72 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.25it/s, est. speed input: 6980.24 toks/s, output: 27.27 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.38it/s, est. speed input: 7094.60 toks/s, output: 27.71 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.48it/s, est. speed input: 7192.28 toks/s, output: 28.09 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.47it/s, est. speed input: 7272.04 toks/s, output: 28.41 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.54it/s, est. speed input: 7344.95 toks/s, output: 28.69 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.56it/s, est. speed input: 7407.12 toks/s, output: 28.93 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.60it/s, est. speed input: 7463.33 toks/s, output: 29.15 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.61it/s, est. speed input: 7512.94 toks/s, output: 29.35 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.53it/s, est. speed input: 7553.28 toks/s, output: 29.50 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.56it/s, est. speed input: 7593.27 toks/s, output: 29.66 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.56it/s, est. speed input: 7628.58 toks/s, output: 29.80 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.57it/s, est. speed input: 7660.86 toks/s, output: 29.92 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.58it/s, est. speed input: 7690.73 toks/s, output: 30.04 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 32.60it/s, est. speed input: 7718.20 toks/s, output: 30.15 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.71it/s, est. speed input: 7746.88 toks/s, output: 30.26 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.66it/s, est. speed input: 7769.35 toks/s, output: 30.35 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.62it/s, est. speed input: 7790.10 toks/s, output: 30.43 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.63it/s, est. speed input: 7810.30 toks/s, output: 30.51 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.81it/s, est. speed input: 7833.93 toks/s, output: 30.60 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.85it/s, est. speed input: 7853.79 toks/s, output: 30.68 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.04it/s, est. speed input: 7876.39 toks/s, output: 30.77 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.19it/s, est. speed input: 7897.96 toks/s, output: 30.85 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.31it/s, est. speed input: 7918.71 toks/s, output: 30.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.31it/s, est. speed input: 7932.06 toks/s, output: 30.98 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.98it/s, est. speed input: 7932.06 toks/s, output: 30.98 toks/s]
[rank0]:[W126 08:01:28.497299937 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 09:08:05
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:08:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1113279) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1113279) WARNING 01-26 09:08:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.70 requests/s, 16259.67 total tokens/s, 31.70 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 09:08:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:08:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:08:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:08:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:08:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:08:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:08:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:08:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:08:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:08:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:08:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:08:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1113279) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1113279) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.41it/s]
(EngineCore_DP0 pid=1113279) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.41it/s]
(EngineCore_DP0 pid=1113279) 
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1113279) [2026-01-26 09:08:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1113279) 2026-01-26 09:08:34,076 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1113279) 2026-01-26 09:08:34,105 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1113279) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.49it/s]
(EngineCore_DP0 pid=1113279) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 19.18it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 519.77it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 694.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 51.64it/s, est. speed input: 26443.10 toks/s, output: 51.64 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:02, 38.82it/s, est. speed input: 20646.14 toks/s, output: 40.32 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 36.18it/s, est. speed input: 19376.71 toks/s, output: 37.84 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 35.06it/s, est. speed input: 18836.99 toks/s, output: 36.79 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.44it/s, est. speed input: 18513.15 toks/s, output: 36.16 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.06it/s, est. speed input: 18291.86 toks/s, output: 35.72 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 33.85it/s, est. speed input: 18137.34 toks/s, output: 35.42 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.66it/s, est. speed input: 18009.32 toks/s, output: 35.17 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.59it/s, est. speed input: 17918.14 toks/s, output: 35.00 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.24it/s, est. speed input: 17793.57 toks/s, output: 34.75 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.00it/s, est. speed input: 17691.46 toks/s, output: 34.55 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.81it/s, est. speed input: 17602.73 toks/s, output: 34.38 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.72it/s, est. speed input: 17532.51 toks/s, output: 34.24 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 32.62it/s, est. speed input: 17466.38 toks/s, output: 34.11 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 32.57it/s, est. speed input: 17411.93 toks/s, output: 34.01 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.49it/s, est. speed input: 17359.12 toks/s, output: 33.90 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.53it/s, est. speed input: 17321.69 toks/s, output: 33.83 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.51it/s, est. speed input: 17283.81 toks/s, output: 33.76 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.50it/s, est. speed input: 17250.47 toks/s, output: 33.69 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.46it/s, est. speed input: 17216.71 toks/s, output: 33.63 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 32.44it/s, est. speed input: 17187.34 toks/s, output: 33.57 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 32.46it/s, est. speed input: 17163.07 toks/s, output: 33.52 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 32.45it/s, est. speed input: 17139.75 toks/s, output: 33.48 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.43it/s, est. speed input: 17116.82 toks/s, output: 33.43 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.46it/s, est. speed input: 17098.52 toks/s, output: 33.40 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.45it/s, est. speed input: 17080.16 toks/s, output: 33.36 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.46it/s, est. speed input: 17063.46 toks/s, output: 33.33 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.48it/s, est. speed input: 17049.08 toks/s, output: 33.30 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.49it/s, est. speed input: 17035.67 toks/s, output: 33.27 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 32.47it/s, est. speed input: 17021.33 toks/s, output: 33.24 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.47it/s, est. speed input: 17012.05 toks/s, output: 33.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.22it/s, est. speed input: 17012.05 toks/s, output: 33.23 toks/s]
[rank0]:[W126 09:08:40.295790270 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 09:08:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:08:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1114307) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1114307) WARNING 01-26 09:09:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.38 requests/s, 32163.88 total tokens/s, 31.38 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 09:08:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:08:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:08:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:08:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:08:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:08:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:08:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:08:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:08:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:08:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:08:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:08:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:08:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:08:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1114307) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1114307) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1114307) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1114307) 
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1114307) [2026-01-26 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1114307) 2026-01-26 09:09:11,213 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1114307) 2026-01-26 09:09:11,243 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1114307) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.15it/s]
(EngineCore_DP0 pid=1114307) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  22%|██▏       | 28/128 [00:00<00:00, 277.08it/s]
Adding requests:  62%|██████▏   | 79/128 [00:00<00:00, 411.45it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 426.14it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 68.56it/s, est. speed input: 70217.07 toks/s, output: 68.56 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:02, 43.18it/s, est. speed input: 47008.51 toks/s, output: 45.90 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:02, 39.03it/s, est. speed input: 42975.46 toks/s, output: 41.97 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 36.72it/s, est. speed input: 40745.12 toks/s, output: 39.79 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 35.56it/s, est. speed input: 39597.44 toks/s, output: 38.67 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 34.65it/s, est. speed input: 38720.45 toks/s, output: 37.81 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:00<00:02, 34.05it/s, est. speed input: 38070.51 toks/s, output: 37.18 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.69it/s, est. speed input: 37587.27 toks/s, output: 36.71 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.39it/s, est. speed input: 37180.72 toks/s, output: 36.31 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.05it/s, est. speed input: 36806.33 toks/s, output: 35.94 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.90it/s, est. speed input: 36517.00 toks/s, output: 35.66 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.80it/s, est. speed input: 36277.21 toks/s, output: 35.43 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 32.76it/s, est. speed input: 36076.78 toks/s, output: 35.23 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 32.68it/s, est. speed input: 35889.76 toks/s, output: 35.05 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 32.63it/s, est. speed input: 35729.56 toks/s, output: 34.89 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.80it/s, est. speed input: 35629.08 toks/s, output: 34.79 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.70it/s, est. speed input: 35498.31 toks/s, output: 34.67 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.65it/s, est. speed input: 35383.72 toks/s, output: 34.55 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.61it/s, est. speed input: 35278.44 toks/s, output: 34.45 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 32.58it/s, est. speed input: 35183.79 toks/s, output: 34.36 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 32.56it/s, est. speed input: 35099.18 toks/s, output: 34.28 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 32.73it/s, est. speed input: 35049.74 toks/s, output: 34.23 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 32.99it/s, est. speed input: 35023.19 toks/s, output: 34.20 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.01it/s, est. speed input: 34977.00 toks/s, output: 34.16 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.94it/s, est. speed input: 34923.99 toks/s, output: 34.11 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.89it/s, est. speed input: 34873.71 toks/s, output: 34.06 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.85it/s, est. speed input: 34826.51 toks/s, output: 34.01 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 32.83it/s, est. speed input: 34784.09 toks/s, output: 33.97 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 32.86it/s, est. speed input: 34748.66 toks/s, output: 33.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.86it/s, est. speed input: 34704.24 toks/s, output: 33.89 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.89it/s, est. speed input: 34704.24 toks/s, output: 33.89 toks/s]
[rank0]:[W126 09:09:17.612065287 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 09:09:19
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:09:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1115313) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1115313) WARNING 01-26 09:09:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 60.10 requests/s, 61606.22 total tokens/s, 60.10 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 09:09:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:09:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:09:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:09:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:09:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:09:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:09:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:09:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:09:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:09:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:09:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:09:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:09:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:09:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:09:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:09:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:09:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1115313) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1115313) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=1115313) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.39it/s]
(EngineCore_DP0 pid=1115313) 
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1115313) [2026-01-26 09:09:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1115313) 2026-01-26 09:09:48,168 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1115313) 2026-01-26 09:09:48,233 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1115313) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 14.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.45it/s]
(EngineCore_DP0 pid=1115313) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.70it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|█         | 26/256 [00:00<00:00, 257.40it/s]
Adding requests:  30%|███       | 77/256 [00:00<00:00, 403.60it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 446.12it/s]
Adding requests:  69%|██████▉   | 176/256 [00:00<00:00, 460.79it/s]
Adding requests:  88%|████████▊ | 226/256 [00:00<00:00, 471.98it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 453.41it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 187.45it/s, est. speed input: 191980.37 toks/s, output: 187.46 toks/s]
Processed prompts:  16%|█▌        | 41/256 [00:00<00:02, 97.39it/s, est. speed input: 108092.01 toks/s, output: 105.55 toks/s] 
Processed prompts:  21%|██        | 53/256 [00:00<00:02, 84.29it/s, est. speed input: 95350.17 toks/s, output: 93.11 toks/s]  
Processed prompts:  25%|██▍       | 63/256 [00:00<00:02, 77.73it/s, est. speed input: 89208.44 toks/s, output: 87.12 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:00<00:02, 71.40it/s, est. speed input: 84039.96 toks/s, output: 82.07 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:01<00:02, 69.64it/s, est. speed input: 81874.32 toks/s, output: 79.95 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:01<00:02, 68.28it/s, est. speed input: 80168.19 toks/s, output: 78.29 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:01<00:02, 67.36it/s, est. speed input: 78833.26 toks/s, output: 76.98 toks/s]
Processed prompts:  41%|████      | 104/256 [00:01<00:02, 66.53it/s, est. speed input: 77675.98 toks/s, output: 75.85 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:01<00:02, 65.83it/s, est. speed input: 76678.36 toks/s, output: 74.88 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:01<00:02, 65.41it/s, est. speed input: 75854.87 toks/s, output: 74.08 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:01<00:01, 65.16it/s, est. speed input: 75162.36 toks/s, output: 73.40 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:01<00:01, 65.14it/s, est. speed input: 74602.82 toks/s, output: 72.85 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:01<00:01, 65.76it/s, est. speed input: 74259.55 toks/s, output: 72.52 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:02<00:01, 66.05it/s, est. speed input: 73922.44 toks/s, output: 72.19 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:02<00:01, 66.21it/s, est. speed input: 73612.89 toks/s, output: 71.89 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:02<00:01, 66.03it/s, est. speed input: 73278.73 toks/s, output: 71.56 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:02<00:01, 65.79it/s, est. speed input: 72957.57 toks/s, output: 71.25 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:02<00:01, 65.60it/s, est. speed input: 72661.66 toks/s, output: 70.96 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:02<00:00, 65.55it/s, est. speed input: 72407.36 toks/s, output: 70.71 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:02<00:00, 65.78it/s, est. speed input: 72215.81 toks/s, output: 70.52 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:02<00:00, 65.96it/s, est. speed input: 72044.05 toks/s, output: 70.35 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:03<00:00, 66.04it/s, est. speed input: 71877.53 toks/s, output: 70.19 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:03<00:00, 65.67it/s, est. speed input: 71666.16 toks/s, output: 69.99 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:03<00:00, 65.48it/s, est. speed input: 71477.74 toks/s, output: 69.80 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:03<00:00, 65.30it/s, est. speed input: 71298.23 toks/s, output: 69.63 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:03<00:00, 65.23it/s, est. speed input: 71137.26 toks/s, output: 69.47 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.24it/s, est. speed input: 70994.19 toks/s, output: 69.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.24it/s, est. speed input: 70994.19 toks/s, output: 69.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 69.32it/s, est. speed input: 70994.19 toks/s, output: 69.33 toks/s]
[rank0]:[W126 09:09:54.622966665 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 09:09:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:10:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1116362) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1116362) WARNING 01-26 09:10:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 110.30 requests/s, 113057.16 total tokens/s, 110.30 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 09:10:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:10:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:10:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:10:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:10:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:10:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:10:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:10:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:10:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:10:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:10:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:10:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1116362) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1116362) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.16it/s]
(EngineCore_DP0 pid=1116362) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.15it/s]
(EngineCore_DP0 pid=1116362) 
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1116362) [2026-01-26 09:10:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1116362) 2026-01-26 09:10:27,305 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1116362) 2026-01-26 09:10:27,334 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1116362) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:01,  1.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.96it/s]
(EngineCore_DP0 pid=1116362) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 20.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 20.59it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 287.39it/s]
Adding requests:  16%|█▌        | 80/512 [00:00<00:01, 414.28it/s]
Adding requests:  25%|██▌       | 129/512 [00:00<00:00, 447.09it/s]
Adding requests:  35%|███▍      | 177/512 [00:00<00:00, 456.24it/s]
Adding requests:  44%|████▍     | 227/512 [00:00<00:00, 468.82it/s]
Adding requests:  54%|█████▍    | 277/512 [00:00<00:00, 474.14it/s]
Adding requests:  63%|██████▎   | 325/512 [00:00<00:00, 475.79it/s]
Adding requests:  73%|███████▎  | 375/512 [00:00<00:00, 482.10it/s]
Adding requests:  83%|████████▎ | 425/512 [00:00<00:00, 486.79it/s]
Adding requests:  93%|█████████▎| 474/512 [00:01<00:00, 485.87it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 468.14it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:00<00:00, 572.93it/s, est. speed input: 586729.00 toks/s, output: 572.94 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:00<00:01, 208.51it/s, est. speed input: 239098.36 toks/s, output: 233.49 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:00<00:01, 176.85it/s, est. speed input: 206748.95 toks/s, output: 201.90 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:00<00:02, 160.43it/s, est. speed input: 191538.69 toks/s, output: 187.05 toks/s]
Processed prompts:  40%|████      | 206/512 [00:01<00:02, 150.40it/s, est. speed input: 182645.34 toks/s, output: 178.36 toks/s]
Processed prompts:  44%|████▎     | 223/512 [00:01<00:01, 147.49it/s, est. speed input: 178634.75 toks/s, output: 174.45 toks/s]
Processed prompts:  47%|████▋     | 239/512 [00:01<00:01, 142.53it/s, est. speed input: 174362.33 toks/s, output: 170.27 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:01<00:01, 136.30it/s, est. speed input: 170037.53 toks/s, output: 166.05 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:01<00:01, 133.80it/s, est. speed input: 167013.42 toks/s, output: 163.10 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:01<00:01, 131.81it/s, est. speed input: 164376.64 toks/s, output: 160.52 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:01<00:01, 130.39it/s, est. speed input: 162097.83 toks/s, output: 158.30 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:02<00:01, 129.70it/s, est. speed input: 160192.31 toks/s, output: 156.44 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:02<00:01, 129.73it/s, est. speed input: 158633.20 toks/s, output: 154.91 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:02<00:01, 128.16it/s, est. speed input: 156880.68 toks/s, output: 153.20 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:02<00:01, 127.81it/s, est. speed input: 155478.00 toks/s, output: 151.83 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:02<00:01, 128.29it/s, est. speed input: 154357.78 toks/s, output: 150.74 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:02<00:00, 127.79it/s, est. speed input: 153184.24 toks/s, output: 149.59 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:02<00:00, 127.26it/s, est. speed input: 152086.42 toks/s, output: 148.52 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:02<00:00, 127.02it/s, est. speed input: 151105.49 toks/s, output: 147.56 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:03<00:00, 126.80it/s, est. speed input: 150198.06 toks/s, output: 146.68 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:03<00:00, 125.95it/s, est. speed input: 149252.12 toks/s, output: 145.75 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:03<00:00, 126.09it/s, est. speed input: 148492.05 toks/s, output: 145.01 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:03<00:00, 127.09it/s, est. speed input: 147917.64 toks/s, output: 144.45 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:03<00:00, 127.10it/s, est. speed input: 147288.08 toks/s, output: 143.84 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 127.10it/s, est. speed input: 147852.28 toks/s, output: 144.39 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 144.38it/s, est. speed input: 147852.28 toks/s, output: 144.39 toks/s]
[rank0]:[W126 09:10:34.803800065 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 09:10:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:10:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1117422) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1117422) WARNING 01-26 09:11:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 148.20 requests/s, 151901.08 total tokens/s, 148.20 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 09:10:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:10:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:10:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:10:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:10:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:10:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:10:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:10:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:10:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:10:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:10:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:10:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:10:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:10:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1117422) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1117422) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.14it/s]
(EngineCore_DP0 pid=1117422) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.14it/s]
(EngineCore_DP0 pid=1117422) 
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1117422) [2026-01-26 09:10:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1117422) 2026-01-26 09:11:09,208 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1117422) 2026-01-26 09:11:09,240 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1117422) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  9.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00, 10.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.81it/s]
(EngineCore_DP0 pid=1117422) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:01,  2.72it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  4.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  7.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 32/1024 [00:00<00:03, 315.25it/s]
Adding requests:   8%|▊         | 84/1024 [00:00<00:02, 430.26it/s]
Adding requests:  13%|█▎        | 135/1024 [00:00<00:01, 462.92it/s]
Adding requests:  18%|█▊        | 184/1024 [00:00<00:01, 472.28it/s]
Adding requests:  23%|██▎       | 236/1024 [00:00<00:01, 486.14it/s]
Adding requests:  28%|██▊       | 285/1024 [00:00<00:01, 482.91it/s]
Adding requests:  33%|███▎      | 335/1024 [00:00<00:01, 484.24it/s]
Adding requests:  38%|███▊      | 387/1024 [00:00<00:01, 492.79it/s]
Adding requests:  43%|████▎     | 438/1024 [00:00<00:01, 495.73it/s]
Adding requests:  48%|████▊     | 489/1024 [00:01<00:01, 497.22it/s]
Adding requests:  53%|█████▎    | 539/1024 [00:01<00:00, 488.69it/s]
Adding requests:  58%|█████▊    | 592/1024 [00:01<00:00, 499.26it/s]
Adding requests:  63%|██████▎   | 642/1024 [00:01<00:00, 492.89it/s]
Adding requests:  68%|██████▊   | 695/1024 [00:01<00:00, 500.60it/s]
Adding requests:  73%|███████▎  | 746/1024 [00:01<00:00, 501.41it/s]
Adding requests:  78%|███████▊  | 797/1024 [00:01<00:00, 501.30it/s]
Adding requests:  83%|████████▎ | 848/1024 [00:01<00:00, 493.90it/s]
Adding requests:  88%|████████▊ | 901/1024 [00:01<00:00, 502.63it/s]
Adding requests:  93%|█████████▎| 952/1024 [00:01<00:00, 502.91it/s]
Adding requests:  98%|█████████▊| 1004/1024 [00:02<00:00, 505.54it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 491.34it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:00<00:00, 1820.84it/s, est. speed input: 1864938.07 toks/s, output: 1820.94 toks/s]
Processed prompts:  42%|████▏     | 433/1024 [00:01<00:01, 305.46it/s, est. speed input: 365483.30 toks/s, output: 356.91 toks/s]   
Processed prompts:  51%|█████     | 518/1024 [00:01<00:02, 248.22it/s, est. speed input: 304004.00 toks/s, output: 296.88 toks/s]
Processed prompts:  56%|█████▌    | 572/1024 [00:02<00:02, 223.89it/s, est. speed input: 280406.28 toks/s, output: 273.83 toks/s]
Processed prompts:  60%|█████▉    | 611/1024 [00:02<00:01, 209.87it/s, est. speed input: 267944.82 toks/s, output: 261.66 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:02<00:01, 199.83it/s, est. speed input: 259792.21 toks/s, output: 253.70 toks/s]
Processed prompts:  65%|██████▌   | 668/1024 [00:02<00:01, 196.04it/s, est. speed input: 255547.45 toks/s, output: 249.56 toks/s]
Processed prompts:  67%|██████▋   | 691/1024 [00:02<00:01, 188.24it/s, est. speed input: 250608.18 toks/s, output: 244.73 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:02<00:01, 181.20it/s, est. speed input: 246134.06 toks/s, output: 240.36 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:03<00:01, 176.64it/s, est. speed input: 242342.62 toks/s, output: 236.66 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:03<00:01, 172.86it/s, est. speed input: 238873.77 toks/s, output: 233.27 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:03<00:01, 170.11it/s, est. speed input: 235740.21 toks/s, output: 230.21 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:03<00:01, 168.34it/s, est. speed input: 232933.78 toks/s, output: 227.47 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:03<00:01, 167.11it/s, est. speed input: 230367.67 toks/s, output: 224.97 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:03<00:01, 165.79it/s, est. speed input: 227918.45 toks/s, output: 222.57 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:04<00:00, 165.05it/s, est. speed input: 225687.44 toks/s, output: 220.40 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:04<00:00, 164.26it/s, est. speed input: 223570.86 toks/s, output: 218.33 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:04<00:00, 163.72it/s, est. speed input: 221602.22 toks/s, output: 216.41 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:04<00:00, 164.78it/s, est. speed input: 219980.62 toks/s, output: 214.82 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:04<00:00, 164.36it/s, est. speed input: 218293.99 toks/s, output: 213.18 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:04<00:00, 165.71it/s, est. speed input: 216934.81 toks/s, output: 211.85 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 165.71it/s, est. speed input: 217385.38 toks/s, output: 212.29 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 212.28it/s, est. speed input: 217385.38 toks/s, output: 212.29 toks/s]
[rank0]:[W126 09:11:19.303114194 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 09:11:21
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:11:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1118602) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1118602) WARNING 01-26 09:11:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 167.85 requests/s, 172047.24 total tokens/s, 167.85 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 09:11:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:11:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:11:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:11:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:11:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:11:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:11:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:11:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:11:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:11:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:11:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:11:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:11:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:11:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:11:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:11:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:11:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1118602) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1118602) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.38it/s]
(EngineCore_DP0 pid=1118602) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.38it/s]
(EngineCore_DP0 pid=1118602) 
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1118602) [2026-01-26 09:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1118602) 2026-01-26 09:11:57,178 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1118602) 2026-01-26 09:11:57,210 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1118602) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:02,  2.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  4.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.72it/s]
(EngineCore_DP0 pid=1118602) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 19.01it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 14.28it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 15.74it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 33/2048 [00:00<00:06, 326.37it/s]
Adding requests:   4%|▍         | 84/2048 [00:00<00:04, 430.28it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:04, 457.26it/s]
Adding requests:   9%|▉         | 181/2048 [00:00<00:04, 464.41it/s]
Adding requests:  11%|█▏        | 232/2048 [00:00<00:03, 478.39it/s]
Adding requests:  14%|█▎        | 281/2048 [00:00<00:03, 482.03it/s]
Adding requests:  16%|█▌        | 330/2048 [00:00<00:03, 483.74it/s]
Adding requests:  19%|█▊        | 381/2048 [00:00<00:03, 490.80it/s]
Adding requests:  21%|██        | 432/2048 [00:00<00:03, 494.77it/s]
Adding requests:  24%|██▎       | 482/2048 [00:01<00:03, 493.07it/s]
Adding requests:  26%|██▌       | 532/2048 [00:01<00:03, 482.54it/s]
Adding requests:  28%|██▊       | 583/2048 [00:01<00:02, 490.48it/s]
Adding requests:  31%|███       | 633/2048 [00:01<00:02, 488.82it/s]
Adding requests:  33%|███▎      | 684/2048 [00:01<00:02, 492.46it/s]
Adding requests:  36%|███▌      | 734/2048 [00:01<00:02, 488.53it/s]
Adding requests:  38%|███▊      | 783/2048 [00:01<00:02, 484.50it/s]
Adding requests:  41%|████      | 832/2048 [00:01<00:02, 476.04it/s]
Adding requests:  43%|████▎     | 882/2048 [00:01<00:02, 482.60it/s]
Adding requests:  46%|████▌     | 934/2048 [00:01<00:02, 491.56it/s]
Adding requests:  48%|████▊     | 984/2048 [00:02<00:02, 492.37it/s]
Adding requests:  50%|█████     | 1034/2048 [00:02<00:02, 491.89it/s]
Adding requests:  53%|█████▎    | 1084/2048 [00:02<00:01, 487.13it/s]
Adding requests:  55%|█████▌    | 1133/2048 [00:02<00:01, 482.33it/s]
Adding requests:  58%|█████▊    | 1184/2048 [00:02<00:01, 489.75it/s]
Adding requests:  60%|██████    | 1234/2048 [00:02<00:01, 490.42it/s]
Adding requests:  63%|██████▎   | 1284/2048 [00:02<00:01, 484.31it/s]
Adding requests:  65%|██████▌   | 1334/2048 [00:02<00:01, 488.24it/s]
Adding requests:  68%|██████▊   | 1384/2048 [00:02<00:01, 489.41it/s]
Adding requests:  70%|███████   | 1435/2048 [00:02<00:01, 493.56it/s]
Adding requests:  73%|███████▎  | 1487/2048 [00:03<00:01, 498.50it/s]
Adding requests:  75%|███████▌  | 1538/2048 [00:03<00:01, 499.68it/s]
Adding requests:  78%|███████▊  | 1589/2048 [00:03<00:00, 501.26it/s]
Adding requests:  80%|████████  | 1641/2048 [00:03<00:00, 506.46it/s]
Adding requests:  83%|████████▎ | 1692/2048 [00:03<00:00, 501.47it/s]
Adding requests:  85%|████████▌ | 1744/2048 [00:03<00:00, 503.49it/s]
Adding requests:  88%|████████▊ | 1795/2048 [00:03<00:00, 501.63it/s]
Adding requests:  90%|█████████ | 1846/2048 [00:03<00:00, 494.63it/s]
Adding requests:  93%|█████████▎| 1896/2048 [00:03<00:00, 493.73it/s]
Adding requests:  95%|█████████▌| 1947/2048 [00:03<00:00, 496.69it/s]
Adding requests:  98%|█████████▊| 1998/2048 [00:04<00:00, 499.59it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 489.29it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:00<00:00, 6829.02it/s, est. speed input: 6994565.45 toks/s, output: 6829.49 toks/s]
Processed prompts:  67%|██████▋   | 1373/2048 [00:04<00:02, 289.28it/s, est. speed input: 346212.30 toks/s, output: 338.10 toks/s]  
Processed prompts:  81%|████████▏ | 1665/2048 [00:05<00:01, 245.09it/s, est. speed input: 295943.88 toks/s, output: 289.01 toks/s]
Processed prompts:  89%|████████▉ | 1832/2048 [00:06<00:00, 223.99it/s, est. speed input: 275682.62 toks/s, output: 269.22 toks/s]
Processed prompts:  95%|█████████▍| 1939/2048 [00:07<00:00, 212.69it/s, est. speed input: 265999.64 toks/s, output: 259.76 toks/s]
Processed prompts:  98%|█████████▊| 2014/2048 [00:07<00:00, 211.68it/s, est. speed input: 263361.22 toks/s, output: 257.19 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:08<00:00, 211.68it/s, est. speed input: 261715.83 toks/s, output: 255.58 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:08<00:00, 255.57it/s, est. speed input: 261715.83 toks/s, output: 255.58 toks/s]
[rank0]:[W126 09:12:12.593216137 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 09:12:14
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:12:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1119939) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1119939) WARNING 01-26 09:12:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 172.52 requests/s, 176827.95 total tokens/s, 172.52 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 09:12:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:12:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:12:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:12:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:12:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:12:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:12:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:12:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:12:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:12:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:12:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:12:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:12:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:12:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:12:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:12:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:12:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1119939) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1119939) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.16it/s]
(EngineCore_DP0 pid=1119939) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.15it/s]
(EngineCore_DP0 pid=1119939) 
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1119939) [2026-01-26 09:12:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1119939) [rank0]:W0126 09:12:56.390000 1119939 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1119939) [rank0]:W0126 09:12:56.444000 1119939 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1119939) [rank0]:W0126 09:12:57.076000 1119939 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1119939) [rank0]:W0126 09:12:57.152000 1119939 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1119939) 2026-01-26 09:12:59,832 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1119939) 2026-01-26 09:12:59,864 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1119939) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 13.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 10.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  5.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  5.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  7.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.68it/s]
(EngineCore_DP0 pid=1119939) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 19.35it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 20.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 16.13it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 31/4096 [00:00<00:13, 307.57it/s]
Adding requests:   2%|▏         | 82/4096 [00:00<00:09, 424.07it/s]
Adding requests:   3%|▎         | 133/4096 [00:00<00:08, 458.81it/s]
Adding requests:   4%|▍         | 182/4096 [00:00<00:08, 468.80it/s]
Adding requests:   6%|▌         | 233/4096 [00:00<00:07, 483.07it/s]
Adding requests:   7%|▋         | 284/4096 [00:00<00:07, 488.88it/s]
Adding requests:   8%|▊         | 333/4096 [00:00<00:07, 488.11it/s]
Adding requests:   9%|▉         | 384/4096 [00:00<00:07, 492.67it/s]
Adding requests:  11%|█         | 435/4096 [00:00<00:07, 495.02it/s]
Adding requests:  12%|█▏        | 486/4096 [00:01<00:07, 498.80it/s]
Adding requests:  13%|█▎        | 536/4096 [00:01<00:07, 485.87it/s]
Adding requests:  14%|█▍        | 588/4096 [00:01<00:07, 495.36it/s]
Adding requests:  16%|█▌        | 639/4096 [00:01<00:06, 498.73it/s]
Adding requests:  17%|█▋        | 691/4096 [00:01<00:06, 503.64it/s]
Adding requests:  18%|█▊        | 742/4096 [00:01<00:06, 502.99it/s]
Adding requests:  19%|█▉        | 793/4096 [00:01<00:06, 501.36it/s]
Adding requests:  21%|██        | 844/4096 [00:01<00:06, 492.67it/s]
Adding requests:  22%|██▏       | 897/4096 [00:01<00:06, 501.20it/s]
Adding requests:  23%|██▎       | 948/4096 [00:01<00:06, 503.28it/s]
Adding requests:  24%|██▍       | 999/4096 [00:02<00:06, 503.15it/s]
Adding requests:  26%|██▌       | 1051/4096 [00:02<00:05, 507.75it/s]
Adding requests:  27%|██▋       | 1102/4096 [00:02<00:06, 488.48it/s]
Adding requests:  28%|██▊       | 1152/4096 [00:02<00:06, 489.95it/s]
Adding requests:  29%|██▉       | 1206/4096 [00:02<00:05, 502.43it/s]
Adding requests:  31%|███       | 1257/4096 [00:02<00:05, 498.40it/s]
Adding requests:  32%|███▏      | 1308/4096 [00:02<00:05, 500.61it/s]
Adding requests:  33%|███▎      | 1359/4096 [00:02<00:05, 502.93it/s]
Adding requests:  34%|███▍      | 1413/4096 [00:02<00:05, 511.25it/s]
Adding requests:  36%|███▌      | 1465/4096 [00:02<00:05, 510.10it/s]
Adding requests:  37%|███▋      | 1517/4096 [00:03<00:05, 512.49it/s]
Adding requests:  38%|███▊      | 1569/4096 [00:03<00:04, 512.24it/s]
Adding requests:  40%|███▉      | 1622/4096 [00:03<00:04, 515.63it/s]
Adding requests:  41%|████      | 1674/4096 [00:03<00:04, 511.60it/s]
Adding requests:  42%|████▏     | 1726/4096 [00:03<00:04, 513.75it/s]
Adding requests:  43%|████▎     | 1778/4096 [00:03<00:04, 510.04it/s]
Adding requests:  45%|████▍     | 1830/4096 [00:03<00:04, 508.91it/s]
Adding requests:  46%|████▌     | 1882/4096 [00:03<00:04, 509.45it/s]
Adding requests:  47%|████▋     | 1933/4096 [00:03<00:04, 508.36it/s]
Adding requests:  48%|████▊     | 1984/4096 [00:03<00:04, 508.09it/s]
Adding requests:  50%|████▉     | 2036/4096 [00:04<00:04, 509.99it/s]
Adding requests:  51%|█████     | 2088/4096 [00:04<00:03, 512.28it/s]
Adding requests:  52%|█████▏    | 2140/4096 [00:04<00:03, 505.80it/s]
Adding requests:  53%|█████▎    | 2191/4096 [00:04<00:03, 502.65it/s]
Adding requests:  55%|█████▍    | 2242/4096 [00:04<00:03, 490.35it/s]
Adding requests:  56%|█████▌    | 2293/4096 [00:04<00:03, 494.00it/s]
Adding requests:  57%|█████▋    | 2344/4096 [00:04<00:03, 497.88it/s]
Adding requests:  58%|█████▊    | 2395/4096 [00:04<00:03, 501.41it/s]
Adding requests:  60%|█████▉    | 2446/4096 [00:04<00:03, 501.98it/s]
Adding requests:  61%|██████    | 2498/4096 [00:05<00:03, 507.16it/s]
Adding requests:  62%|██████▏   | 2549/4096 [00:05<00:03, 506.52it/s]
Adding requests:  64%|██████▎   | 2601/4096 [00:05<00:02, 507.79it/s]
Adding requests:  65%|██████▍   | 2653/4096 [00:05<00:02, 510.94it/s]
Adding requests:  66%|██████▌   | 2705/4096 [00:05<00:02, 506.75it/s]
Adding requests:  67%|██████▋   | 2756/4096 [00:05<00:02, 506.89it/s]
Adding requests:  69%|██████▊   | 2807/4096 [00:05<00:02, 504.83it/s]
Adding requests:  70%|██████▉   | 2858/4096 [00:05<00:02, 505.66it/s]
Adding requests:  71%|███████   | 2909/4096 [00:05<00:02, 505.82it/s]
Adding requests:  72%|███████▏  | 2960/4096 [00:05<00:02, 501.41it/s]
Adding requests:  74%|███████▎  | 3012/4096 [00:06<00:02, 503.96it/s]
Adding requests:  75%|███████▍  | 3063/4096 [00:06<00:02, 502.37it/s]
Adding requests:  76%|███████▌  | 3114/4096 [00:06<00:01, 503.44it/s]
Adding requests:  77%|███████▋  | 3165/4096 [00:06<00:01, 503.68it/s]
Adding requests:  79%|███████▊  | 3216/4096 [00:06<00:01, 504.50it/s]
Adding requests:  80%|███████▉  | 3268/4096 [00:06<00:01, 507.29it/s]
Adding requests:  81%|████████  | 3320/4096 [00:06<00:01, 508.48it/s]
Adding requests:  82%|████████▏ | 3371/4096 [00:06<00:01, 508.08it/s]
Adding requests:  84%|████████▎ | 3423/4096 [00:06<00:01, 511.32it/s]
Adding requests:  85%|████████▍ | 3475/4096 [00:06<00:01, 500.57it/s]
Adding requests:  86%|████████▌ | 3526/4096 [00:07<00:01, 488.08it/s]
Adding requests:  87%|████████▋ | 3576/4096 [00:07<00:01, 489.83it/s]
Adding requests:  89%|████████▊ | 3626/4096 [00:07<00:00, 490.95it/s]
Adding requests:  90%|████████▉ | 3677/4096 [00:07<00:00, 495.86it/s]
Adding requests:  91%|█████████ | 3728/4096 [00:07<00:00, 499.86it/s]
Adding requests:  92%|█████████▏| 3781/4096 [00:07<00:00, 507.12it/s]
Adding requests:  94%|█████████▎| 3832/4096 [00:07<00:00, 507.56it/s]
Adding requests:  95%|█████████▍| 3884/4096 [00:07<00:00, 510.46it/s]
Adding requests:  96%|█████████▌| 3936/4096 [00:07<00:00, 509.36it/s]
Adding requests:  97%|█████████▋| 3987/4096 [00:07<00:00, 505.91it/s]
Adding requests:  99%|█████████▊| 4039/4096 [00:08<00:00, 507.63it/s]
Adding requests: 100%|█████████▉| 4090/4096 [00:08<00:00, 507.25it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 501.08it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  33%|███▎      | 1366/4096 [00:00<00:00, 9164.83it/s, est. speed input: 9390010.21 toks/s, output: 9165.59 toks/s]
Processed prompts:  56%|█████▌    | 2283/4096 [00:05<00:05, 357.94it/s, est. speed input: 442928.44 toks/s, output: 432.55 toks/s]   
Processed prompts:  65%|██████▌   | 2671/4096 [00:07<00:04, 291.23it/s, est. speed input: 367152.86 toks/s, output: 358.55 toks/s]
Processed prompts:  71%|███████   | 2890/4096 [00:08<00:04, 262.58it/s, est. speed input: 339022.94 toks/s, output: 331.08 toks/s]
Processed prompts:  74%|███████▍  | 3030/4096 [00:09<00:04, 240.95it/s, est. speed input: 321617.19 toks/s, output: 314.08 toks/s]
Processed prompts:  76%|███████▋  | 3125/4096 [00:10<00:03, 242.76it/s, est. speed input: 319546.85 toks/s, output: 312.06 toks/s]
Processed prompts:  78%|███████▊  | 3197/4096 [00:10<00:04, 224.01it/s, est. speed input: 310341.42 toks/s, output: 303.07 toks/s]
Processed prompts:  79%|███████▉  | 3250/4096 [00:10<00:03, 229.25it/s, est. speed input: 310141.13 toks/s, output: 302.87 toks/s]
Processed prompts:  80%|████████  | 3295/4096 [00:11<00:03, 209.50it/s, est. speed input: 303976.65 toks/s, output: 296.85 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [00:11<00:03, 207.18it/s, est. speed input: 302179.46 toks/s, output: 295.10 toks/s]
Processed prompts:  82%|████████▏ | 3360/4096 [00:11<00:03, 200.49it/s, est. speed input: 299938.56 toks/s, output: 292.91 toks/s]
Processed prompts:  83%|████████▎ | 3386/4096 [00:11<00:03, 190.37it/s, est. speed input: 297464.21 toks/s, output: 290.49 toks/s]
Processed prompts:  83%|████████▎ | 3414/4096 [00:11<00:03, 182.61it/s, est. speed input: 295216.91 toks/s, output: 288.30 toks/s]
Processed prompts:  84%|████████▍ | 3446/4096 [00:12<00:03, 181.40it/s, est. speed input: 293501.34 toks/s, output: 286.62 toks/s]
Processed prompts:  85%|████████▍ | 3478/4096 [00:12<00:03, 182.12it/s, est. speed input: 292016.33 toks/s, output: 285.17 toks/s]
Processed prompts:  86%|████████▌ | 3510/4096 [00:12<00:03, 180.81it/s, est. speed input: 290398.08 toks/s, output: 283.59 toks/s]
Processed prompts:  86%|████████▋ | 3542/4096 [00:12<00:03, 178.77it/s, est. speed input: 288734.09 toks/s, output: 281.97 toks/s]
Processed prompts:  87%|████████▋ | 3574/4096 [00:12<00:02, 176.94it/s, est. speed input: 287095.92 toks/s, output: 280.37 toks/s]
Processed prompts:  88%|████████▊ | 3606/4096 [00:12<00:02, 175.58it/s, est. speed input: 285503.91 toks/s, output: 278.81 toks/s]
Processed prompts:  89%|████████▉ | 3638/4096 [00:13<00:02, 174.98it/s, est. speed input: 283987.21 toks/s, output: 277.33 toks/s]
Processed prompts:  90%|████████▉ | 3670/4096 [00:13<00:02, 174.36it/s, est. speed input: 282498.72 toks/s, output: 275.88 toks/s]
Processed prompts:  90%|█████████ | 3702/4096 [00:13<00:02, 173.66it/s, est. speed input: 281030.89 toks/s, output: 274.44 toks/s]
Processed prompts:  91%|█████████ | 3734/4096 [00:13<00:02, 174.23it/s, est. speed input: 279681.91 toks/s, output: 273.13 toks/s]
Processed prompts:  92%|█████████▏| 3766/4096 [00:13<00:01, 173.45it/s, est. speed input: 278283.37 toks/s, output: 271.76 toks/s]
Processed prompts:  93%|█████████▎| 3798/4096 [00:14<00:01, 173.39it/s, est. speed input: 276956.68 toks/s, output: 270.46 toks/s]
Processed prompts:  94%|█████████▎| 3830/4096 [00:14<00:01, 176.37it/s, est. speed input: 275869.57 toks/s, output: 269.40 toks/s]
Processed prompts:  94%|█████████▍| 3862/4096 [00:14<00:01, 175.34it/s, est. speed input: 274601.26 toks/s, output: 268.16 toks/s]
Processed prompts:  95%|█████████▌| 3894/4096 [00:14<00:01, 174.64it/s, est. speed input: 273365.74 toks/s, output: 266.96 toks/s]
Processed prompts:  96%|█████████▌| 3926/4096 [00:14<00:00, 173.38it/s, est. speed input: 272110.55 toks/s, output: 265.73 toks/s]
Processed prompts:  97%|█████████▋| 3958/4096 [00:14<00:00, 173.38it/s, est. speed input: 270944.24 toks/s, output: 264.59 toks/s]
Processed prompts:  97%|█████████▋| 3990/4096 [00:15<00:00, 173.02it/s, est. speed input: 269782.75 toks/s, output: 263.46 toks/s]
Processed prompts:  98%|█████████▊| 4022/4096 [00:15<00:00, 175.64it/s, est. speed input: 268826.88 toks/s, output: 262.53 toks/s]
Processed prompts:  99%|█████████▉| 4054/4096 [00:15<00:00, 177.48it/s, est. speed input: 267889.86 toks/s, output: 261.61 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:15<00:00, 177.48it/s, est. speed input: 269472.83 toks/s, output: 263.16 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:15<00:00, 263.15it/s, est. speed input: 269472.83 toks/s, output: 263.16 toks/s]
[rank0]:[W126 09:13:27.624353076 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 09:13:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:14:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1121661) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1121661) WARNING 01-26 09:14:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 174.01 requests/s, 178363.71 total tokens/s, 174.01 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 09:14:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:14:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:14:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:14:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:14:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:14:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:14:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:14:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:14:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:14:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 09:14:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 09:14:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 09:14:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:14:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:14:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:14:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:14:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1121661) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1121661) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1121661) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.37it/s]
(EngineCore_DP0 pid=1121661) 
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1121661) [2026-01-26 09:14:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16793600 bytes
(EngineCore_DP0 pid=1121661) [rank0]:W0126 09:14:29.251000 1121661 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1121661) [rank0]:W0126 09:14:29.306000 1121661 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1121661) [rank0]:W0126 09:14:30.406000 1121661 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1121661) [rank0]:W0126 09:14:30.483000 1121661 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1121661) 2026-01-26 09:14:33,204 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1121661) 2026-01-26 09:14:33,671 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1121661) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:03,  4.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:01, 10.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:00, 14.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 16.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:00<00:00, 10.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:01<00:01,  5.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:01<00:00,  7.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:01<00:00,  9.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 11.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00,  9.78it/s]
(EngineCore_DP0 pid=1121661) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  6.58it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:01,  7.18it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 10.86it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:00<00:00,  9.54it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  6.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.81it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.76it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 39/8192 [00:00<00:21, 384.45it/s]
Adding requests:   1%|          | 89/8192 [00:00<00:17, 451.95it/s]
Adding requests:   2%|▏         | 137/8192 [00:00<00:17, 463.78it/s]
Adding requests:   2%|▏         | 185/8192 [00:00<00:17, 468.35it/s]
Adding requests:   3%|▎         | 235/8192 [00:00<00:16, 478.70it/s]
Adding requests:   3%|▎         | 284/8192 [00:00<00:16, 482.24it/s]
Adding requests:   4%|▍         | 333/8192 [00:00<00:16, 480.85it/s]
Adding requests:   5%|▍         | 383/8192 [00:00<00:16, 484.86it/s]
Adding requests:   5%|▌         | 434/8192 [00:00<00:15, 487.75it/s]
Adding requests:   6%|▌         | 484/8192 [00:01<00:15, 490.32it/s]
Adding requests:   7%|▋         | 534/8192 [00:01<00:15, 478.74it/s]
Adding requests:   7%|▋         | 584/8192 [00:01<00:15, 482.05it/s]
Adding requests:   8%|▊         | 633/8192 [00:01<00:15, 482.73it/s]
Adding requests:   8%|▊         | 684/8192 [00:01<00:15, 490.45it/s]
Adding requests:   9%|▉         | 735/8192 [00:01<00:15, 495.34it/s]
Adding requests:  10%|▉         | 785/8192 [00:01<00:15, 490.84it/s]
Adding requests:  10%|█         | 835/8192 [00:01<00:15, 481.87it/s]
Adding requests:  11%|█         | 886/8192 [00:01<00:14, 487.82it/s]
Adding requests:  11%|█▏        | 937/8192 [00:01<00:14, 492.11it/s]
Adding requests:  12%|█▏        | 987/8192 [00:02<00:14, 494.02it/s]
Adding requests:  13%|█▎        | 1038/8192 [00:02<00:14, 497.06it/s]
Adding requests:  13%|█▎        | 1088/8192 [00:02<00:14, 493.64it/s]
Adding requests:  14%|█▍        | 1138/8192 [00:02<00:14, 489.72it/s]
Adding requests:  15%|█▍        | 1191/8192 [00:02<00:13, 500.88it/s]
Adding requests:  15%|█▌        | 1242/8192 [00:02<00:13, 501.27it/s]
Adding requests:  16%|█▌        | 1293/8192 [00:02<00:13, 496.90it/s]
Adding requests:  16%|█▋        | 1344/8192 [00:02<00:13, 499.47it/s]
Adding requests:  17%|█▋        | 1396/8192 [00:02<00:13, 502.47it/s]
Adding requests:  18%|█▊        | 1447/8192 [00:02<00:13, 499.85it/s]
Adding requests:  18%|█▊        | 1499/8192 [00:03<00:13, 503.12it/s]
Adding requests:  19%|█▉        | 1550/8192 [00:03<00:13, 503.80it/s]
Adding requests:  20%|█▉        | 1603/8192 [00:03<00:12, 511.40it/s]
Adding requests:  20%|██        | 1655/8192 [00:03<00:12, 509.16it/s]
Adding requests:  21%|██        | 1706/8192 [00:03<00:12, 508.01it/s]
Adding requests:  21%|██▏       | 1757/8192 [00:03<00:12, 495.72it/s]
Adding requests:  22%|██▏       | 1808/8192 [00:03<00:12, 497.58it/s]
Adding requests:  23%|██▎       | 1859/8192 [00:03<00:12, 500.33it/s]
Adding requests:  23%|██▎       | 1910/8192 [00:03<00:12, 497.49it/s]
Adding requests:  24%|██▍       | 1962/8192 [00:03<00:12, 501.11it/s]
Adding requests:  25%|██▍       | 2014/8192 [00:04<00:12, 504.40it/s]
Adding requests:  25%|██▌       | 2066/8192 [00:04<00:12, 508.12it/s]
Adding requests:  26%|██▌       | 2117/8192 [00:04<00:11, 508.07it/s]
Adding requests:  26%|██▋       | 2168/8192 [00:04<00:12, 501.33it/s]
Adding requests:  27%|██▋       | 2219/8192 [00:04<00:11, 500.29it/s]
Adding requests:  28%|██▊       | 2270/8192 [00:04<00:11, 500.85it/s]
Adding requests:  28%|██▊       | 2322/8192 [00:04<00:11, 504.49it/s]
Adding requests:  29%|██▉       | 2373/8192 [00:04<00:11, 502.30it/s]
Adding requests:  30%|██▉       | 2425/8192 [00:04<00:11, 505.16it/s]
Adding requests:  30%|███       | 2476/8192 [00:05<00:11, 503.86it/s]
Adding requests:  31%|███       | 2527/8192 [00:05<00:11, 504.03it/s]
Adding requests:  31%|███▏      | 2580/8192 [00:05<00:10, 511.40it/s]
Adding requests:  32%|███▏      | 2632/8192 [00:05<00:10, 508.72it/s]
Adding requests:  33%|███▎      | 2683/8192 [00:05<00:10, 508.76it/s]
Adding requests:  33%|███▎      | 2734/8192 [00:05<00:10, 504.65it/s]
Adding requests:  34%|███▍      | 2785/8192 [00:05<00:10, 505.26it/s]
Adding requests:  35%|███▍      | 2836/8192 [00:05<00:10, 502.34it/s]
Adding requests:  35%|███▌      | 2888/8192 [00:05<00:10, 506.71it/s]
Adding requests:  36%|███▌      | 2939/8192 [00:05<00:10, 500.10it/s]
Adding requests:  36%|███▋      | 2990/8192 [00:06<00:10, 493.09it/s]
Adding requests:  37%|███▋      | 3040/8192 [00:06<00:10, 491.83it/s]
Adding requests:  38%|███▊      | 3090/8192 [00:06<00:10, 492.88it/s]
Adding requests:  38%|███▊      | 3141/8192 [00:06<00:10, 496.66it/s]
Adding requests:  39%|███▉      | 3192/8192 [00:06<00:10, 498.91it/s]
Adding requests:  40%|███▉      | 3243/8192 [00:06<00:09, 501.64it/s]
Adding requests:  40%|████      | 3295/8192 [00:06<00:09, 504.80it/s]
Adding requests:  41%|████      | 3347/8192 [00:06<00:09, 507.16it/s]
Adding requests:  41%|████▏     | 3398/8192 [00:06<00:09, 505.75it/s]
Adding requests:  42%|████▏     | 3449/8192 [00:06<00:09, 505.58it/s]
Adding requests:  43%|████▎     | 3500/8192 [00:07<00:09, 501.61it/s]
Adding requests:  43%|████▎     | 3551/8192 [00:07<00:09, 502.92it/s]
Adding requests:  44%|████▍     | 3602/8192 [00:07<00:09, 500.86it/s]
Adding requests:  45%|████▍     | 3653/8192 [00:07<00:09, 499.23it/s]
Adding requests:  45%|████▌     | 3705/8192 [00:07<00:08, 502.80it/s]
Adding requests:  46%|████▌     | 3756/8192 [00:07<00:08, 500.42it/s]
Adding requests:  46%|████▋     | 3809/8192 [00:07<00:08, 506.97it/s]
Adding requests:  47%|████▋     | 3861/8192 [00:07<00:08, 510.52it/s]
Adding requests:  48%|████▊     | 3913/8192 [00:07<00:08, 507.55it/s]
Adding requests:  48%|████▊     | 3965/8192 [00:07<00:08, 509.17it/s]
Adding requests:  49%|████▉     | 4016/8192 [00:08<00:08, 506.62it/s]
Adding requests:  50%|████▉     | 4067/8192 [00:08<00:08, 502.11it/s]
Adding requests:  50%|█████     | 4118/8192 [00:08<00:08, 503.37it/s]
Adding requests:  51%|█████     | 4170/8192 [00:08<00:07, 506.83it/s]
Adding requests:  52%|█████▏    | 4222/8192 [00:08<00:07, 507.63it/s]
Adding requests:  52%|█████▏    | 4273/8192 [00:08<00:07, 506.96it/s]
Adding requests:  53%|█████▎    | 4324/8192 [00:08<00:07, 496.41it/s]
Adding requests:  53%|█████▎    | 4376/8192 [00:08<00:07, 503.15it/s]
Adding requests:  54%|█████▍    | 4427/8192 [00:08<00:07, 500.35it/s]
Adding requests:  55%|█████▍    | 4479/8192 [00:08<00:07, 500.66it/s]
Adding requests:  55%|█████▌    | 4530/8192 [00:09<00:07, 495.68it/s]
Adding requests:  56%|█████▌    | 4581/8192 [00:09<00:07, 498.15it/s]
Adding requests:  57%|█████▋    | 4632/8192 [00:09<00:07, 500.24it/s]
Adding requests:  57%|█████▋    | 4683/8192 [00:09<00:07, 498.24it/s]
Adding requests:  58%|█████▊    | 4734/8192 [00:09<00:06, 500.53it/s]
Adding requests:  58%|█████▊    | 4785/8192 [00:09<00:06, 500.98it/s]
Adding requests:  59%|█████▉    | 4836/8192 [00:09<00:06, 502.54it/s]
Adding requests:  60%|█████▉    | 4887/8192 [00:09<00:06, 500.51it/s]
Adding requests:  60%|██████    | 4938/8192 [00:09<00:06, 502.16it/s]
Adding requests:  61%|██████    | 4989/8192 [00:10<00:06, 501.54it/s]
Adding requests:  62%|██████▏   | 5040/8192 [00:10<00:06, 503.98it/s]
Adding requests:  62%|██████▏   | 5092/8192 [00:10<00:06, 508.38it/s]
Adding requests:  63%|██████▎   | 5143/8192 [00:10<00:06, 505.25it/s]
Adding requests:  63%|██████▎   | 5194/8192 [00:10<00:05, 504.63it/s]
Adding requests:  64%|██████▍   | 5245/8192 [00:10<00:05, 499.75it/s]
Adding requests:  65%|██████▍   | 5295/8192 [00:10<00:05, 499.05it/s]
Adding requests:  65%|██████▌   | 5347/8192 [00:10<00:05, 502.64it/s]
Adding requests:  66%|██████▌   | 5398/8192 [00:10<00:05, 504.07it/s]
Adding requests:  67%|██████▋   | 5449/8192 [00:10<00:05, 503.22it/s]
Adding requests:  67%|██████▋   | 5500/8192 [00:11<00:05, 500.02it/s]
Adding requests:  68%|██████▊   | 5551/8192 [00:11<00:05, 498.56it/s]
Adding requests:  68%|██████▊   | 5602/8192 [00:11<00:05, 500.05it/s]
Adding requests:  69%|██████▉   | 5653/8192 [00:11<00:05, 480.72it/s]
Adding requests:  70%|██████▉   | 5704/8192 [00:11<00:05, 487.76it/s]
Adding requests:  70%|███████   | 5755/8192 [00:11<00:04, 492.02it/s]
Adding requests:  71%|███████   | 5805/8192 [00:11<00:04, 493.33it/s]
Adding requests:  71%|███████▏  | 5855/8192 [00:11<00:04, 494.62it/s]
Adding requests:  72%|███████▏  | 5907/8192 [00:11<00:04, 500.90it/s]
Adding requests:  73%|███████▎  | 5958/8192 [00:11<00:04, 500.42it/s]
Adding requests:  73%|███████▎  | 6011/8192 [00:12<00:04, 507.43it/s]
Adding requests:  74%|███████▍  | 6063/8192 [00:12<00:04, 510.61it/s]
Adding requests:  75%|███████▍  | 6115/8192 [00:12<00:04, 506.83it/s]
Adding requests:  75%|███████▌  | 6166/8192 [00:12<00:04, 503.64it/s]
Adding requests:  76%|███████▌  | 6220/8192 [00:12<00:03, 512.33it/s]
Adding requests:  77%|███████▋  | 6272/8192 [00:12<00:03, 512.87it/s]
Adding requests:  77%|███████▋  | 6324/8192 [00:12<00:03, 514.53it/s]
Adding requests:  78%|███████▊  | 6376/8192 [00:12<00:03, 508.39it/s]
Adding requests:  78%|███████▊  | 6429/8192 [00:12<00:03, 513.75it/s]
Adding requests:  79%|███████▉  | 6481/8192 [00:12<00:03, 513.27it/s]
Adding requests:  80%|███████▉  | 6534/8192 [00:13<00:03, 514.74it/s]
Adding requests:  80%|████████  | 6586/8192 [00:13<00:03, 510.39it/s]
Adding requests:  81%|████████  | 6638/8192 [00:13<00:03, 507.83it/s]
Adding requests:  82%|████████▏ | 6689/8192 [00:13<00:02, 505.31it/s]
Adding requests:  82%|████████▏ | 6740/8192 [00:13<00:02, 506.39it/s]
Adding requests:  83%|████████▎ | 6792/8192 [00:13<00:02, 508.66it/s]
Adding requests:  84%|████████▎ | 6843/8192 [00:13<00:02, 507.38it/s]
Adding requests:  84%|████████▍ | 6896/8192 [00:13<00:02, 511.69it/s]
Adding requests:  85%|████████▍ | 6948/8192 [00:13<00:02, 501.99it/s]
Adding requests:  85%|████████▌ | 6999/8192 [00:13<00:02, 500.64it/s]
Adding requests:  86%|████████▌ | 7050/8192 [00:14<00:02, 498.65it/s]
Adding requests:  87%|████████▋ | 7101/8192 [00:14<00:02, 501.26it/s]
Adding requests:  87%|████████▋ | 7152/8192 [00:14<00:02, 500.75it/s]
Adding requests:  88%|████████▊ | 7203/8192 [00:14<00:01, 500.49it/s]
Adding requests:  89%|████████▊ | 7254/8192 [00:14<00:01, 501.83it/s]
Adding requests:  89%|████████▉ | 7306/8192 [00:14<00:01, 505.10it/s]
Adding requests:  90%|████████▉ | 7357/8192 [00:14<00:01, 503.99it/s]
Adding requests:  90%|█████████ | 7410/8192 [00:14<00:01, 509.64it/s]
Adding requests:  91%|█████████ | 7462/8192 [00:14<00:01, 512.60it/s]
Adding requests:  92%|█████████▏| 7514/8192 [00:15<00:01, 511.91it/s]
Adding requests:  92%|█████████▏| 7566/8192 [00:15<00:01, 509.13it/s]
Adding requests:  93%|█████████▎| 7617/8192 [00:15<00:01, 503.68it/s]
Adding requests:  94%|█████████▎| 7670/8192 [00:15<00:01, 509.17it/s]
Adding requests:  94%|█████████▍| 7721/8192 [00:15<00:00, 508.40it/s]
Adding requests:  95%|█████████▍| 7772/8192 [00:15<00:00, 504.82it/s]
Adding requests:  95%|█████████▌| 7823/8192 [00:15<00:00, 502.76it/s]
Adding requests:  96%|█████████▌| 7874/8192 [00:15<00:00, 504.22it/s]
Adding requests:  97%|█████████▋| 7925/8192 [00:15<00:00, 503.79it/s]
Adding requests:  97%|█████████▋| 7976/8192 [00:15<00:00, 503.12it/s]
Adding requests:  98%|█████████▊| 8027/8192 [00:16<00:00, 498.70it/s]
Adding requests:  99%|█████████▊| 8080/8192 [00:16<00:00, 506.34it/s]
Adding requests:  99%|█████████▉| 8132/8192 [00:16<00:00, 507.61it/s]
Adding requests: 100%|█████████▉| 8184/8192 [00:16<00:00, 511.04it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 501.00it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▍      | 2781/8192 [00:00<00:00, 18226.10it/s, est. speed input: 18668867.44 toks/s, output: 18227.53 toks/s]
Processed prompts:  56%|█████▌    | 4604/8192 [00:10<00:09, 365.28it/s, est. speed input: 454813.95 toks/s, output: 444.15 toks/s]      
Processed prompts:  57%|█████▋    | 4637/8192 [00:10<00:10, 351.70it/s, est. speed input: 442174.67 toks/s, output: 431.81 toks/s]
Processed prompts:  66%|██████▌   | 5393/8192 [00:14<00:09, 281.44it/s, est. speed input: 374347.02 toks/s, output: 365.57 toks/s]
Processed prompts:  71%|███████   | 5813/8192 [00:17<00:09, 248.46it/s, est. speed input: 343883.77 toks/s, output: 335.82 toks/s]
Processed prompts:  74%|███████▍  | 6074/8192 [00:18<00:09, 235.24it/s, est. speed input: 331247.51 toks/s, output: 323.48 toks/s]
Processed prompts:  76%|███████▋  | 6247/8192 [00:19<00:08, 222.27it/s, est. speed input: 321857.59 toks/s, output: 314.31 toks/s]
Processed prompts:  78%|███████▊  | 6367/8192 [00:20<00:08, 214.30it/s, est. speed input: 316399.12 toks/s, output: 308.98 toks/s]
Processed prompts:  79%|███████▉  | 6453/8192 [00:20<00:08, 215.79it/s, est. speed input: 314975.01 toks/s, output: 307.59 toks/s]
Processed prompts:  80%|███████▉  | 6519/8192 [00:21<00:07, 211.46it/s, est. speed input: 312668.61 toks/s, output: 305.34 toks/s]
Processed prompts:  80%|████████  | 6570/8192 [00:21<00:08, 201.96it/s, est. speed input: 309897.52 toks/s, output: 302.63 toks/s]
Processed prompts:  81%|████████  | 6621/8192 [00:22<00:08, 191.57it/s, est. speed input: 307123.47 toks/s, output: 299.92 toks/s]
Processed prompts:  82%|████████▏ | 6685/8192 [00:22<00:08, 187.88it/s, est. speed input: 304966.50 toks/s, output: 297.82 toks/s]
Processed prompts:  82%|████████▏ | 6749/8192 [00:22<00:07, 184.53it/s, est. speed input: 302877.87 toks/s, output: 295.78 toks/s]
Processed prompts:  83%|████████▎ | 6813/8192 [00:23<00:07, 182.23it/s, est. speed input: 300918.87 toks/s, output: 293.87 toks/s]
Processed prompts:  84%|████████▍ | 6877/8192 [00:23<00:07, 180.21it/s, est. speed input: 299007.13 toks/s, output: 292.00 toks/s]
Processed prompts:  85%|████████▍ | 6941/8192 [00:23<00:07, 178.23it/s, est. speed input: 297115.74 toks/s, output: 290.15 toks/s]
Processed prompts:  86%|████████▌ | 7005/8192 [00:24<00:06, 177.43it/s, est. speed input: 295347.86 toks/s, output: 288.43 toks/s]
Processed prompts:  86%|████████▋ | 7069/8192 [00:24<00:06, 176.98it/s, est. speed input: 293645.38 toks/s, output: 286.76 toks/s]
Processed prompts:  87%|████████▋ | 7133/8192 [00:25<00:05, 177.09it/s, est. speed input: 292028.85 toks/s, output: 285.18 toks/s]
Processed prompts:  88%|████████▊ | 7197/8192 [00:25<00:05, 175.90it/s, est. speed input: 290355.58 toks/s, output: 283.55 toks/s]
Processed prompts:  89%|████████▊ | 7261/8192 [00:25<00:05, 176.89it/s, est. speed input: 288875.91 toks/s, output: 282.10 toks/s]
Processed prompts:  89%|████████▉ | 7325/8192 [00:26<00:04, 175.56it/s, est. speed input: 287279.74 toks/s, output: 280.55 toks/s]
Processed prompts:  90%|█████████ | 7389/8192 [00:26<00:04, 176.17it/s, est. speed input: 285845.13 toks/s, output: 279.15 toks/s]
Processed prompts:  91%|█████████ | 7453/8192 [00:26<00:04, 174.63it/s, est. speed input: 284303.75 toks/s, output: 277.64 toks/s]
Processed prompts:  92%|█████████▏| 7517/8192 [00:27<00:03, 175.54it/s, est. speed input: 282949.22 toks/s, output: 276.32 toks/s]
Processed prompts:  93%|█████████▎| 7581/8192 [00:27<00:03, 175.97it/s, est. speed input: 281615.30 toks/s, output: 275.01 toks/s]
Processed prompts:  93%|█████████▎| 7645/8192 [00:27<00:03, 174.50it/s, est. speed input: 280191.95 toks/s, output: 273.62 toks/s]
Processed prompts:  94%|█████████▍| 7709/8192 [00:28<00:02, 174.70it/s, est. speed input: 278890.44 toks/s, output: 272.35 toks/s]
Processed prompts:  95%|█████████▍| 7773/8192 [00:28<00:02, 173.82it/s, est. speed input: 277552.54 toks/s, output: 271.05 toks/s]
Processed prompts:  96%|█████████▌| 7837/8192 [00:29<00:02, 173.14it/s, est. speed input: 276244.78 toks/s, output: 269.77 toks/s]
Processed prompts:  96%|█████████▋| 7901/8192 [00:29<00:01, 173.71it/s, est. speed input: 275039.13 toks/s, output: 268.59 toks/s]
Processed prompts:  97%|█████████▋| 7965/8192 [00:29<00:01, 173.17it/s, est. speed input: 273802.42 toks/s, output: 267.38 toks/s]
Processed prompts:  98%|█████████▊| 8029/8192 [00:30<00:00, 173.33it/s, est. speed input: 272630.13 toks/s, output: 266.24 toks/s]
Processed prompts:  99%|█████████▉| 8093/8192 [00:30<00:00, 174.58it/s, est. speed input: 271557.47 toks/s, output: 265.19 toks/s]
Processed prompts: 100%|█████████▉| 8157/8192 [00:30<00:00, 201.76it/s, est. speed input: 271905.94 toks/s, output: 265.53 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:30<00:00, 201.76it/s, est. speed input: 273063.32 toks/s, output: 266.66 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:30<00:00, 266.66it/s, est. speed input: 273063.32 toks/s, output: 266.66 toks/s]
[rank0]:[W126 09:15:26.210353750 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:42:45
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:42:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1230633) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1230633) WARNING 01-26 10:43:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.66 requests/s, 17265.08 total tokens/s, 33.66 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 10:42:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:42:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:42:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:42:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:42:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:42:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:42:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:42:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:42:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:42:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:43:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:43:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:43:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:43:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:43:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1230633) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1230633) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1230633) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1230633) 
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1230633) [2026-01-26 10:43:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1230633) 2026-01-26 10:43:21,044 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1230633) 2026-01-26 10:43:21,079 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1230633) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]
(EngineCore_DP0 pid=1230633) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 517.69it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 695.53it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:31,  3.99it/s, est. speed input: 2045.07 toks/s, output: 3.99 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 15.81it/s, est. speed input: 6873.91 toks/s, output: 13.42 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 23.21it/s, est. speed input: 9633.05 toks/s, output: 18.81 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 27.95it/s, est. speed input: 11393.79 toks/s, output: 22.25 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 31.09it/s, est. speed input: 12616.90 toks/s, output: 24.64 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.14it/s, est. speed input: 13505.35 toks/s, output: 26.38 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.57it/s, est. speed input: 14190.67 toks/s, output: 27.72 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:02, 35.54it/s, est. speed input: 14730.43 toks/s, output: 28.77 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 36.24it/s, est. speed input: 15171.94 toks/s, output: 29.63 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 36.73it/s, est. speed input: 15536.45 toks/s, output: 30.34 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 37.09it/s, est. speed input: 15845.90 toks/s, output: 30.95 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 37.40it/s, est. speed input: 16115.00 toks/s, output: 31.47 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 37.55it/s, est. speed input: 16341.80 toks/s, output: 31.92 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 37.71it/s, est. speed input: 16544.01 toks/s, output: 32.31 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 37.75it/s, est. speed input: 16715.45 toks/s, output: 32.65 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 37.85it/s, est. speed input: 16873.23 toks/s, output: 32.95 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 37.86it/s, est. speed input: 17009.45 toks/s, output: 33.22 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 37.86it/s, est. speed input: 17131.04 toks/s, output: 33.46 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 37.83it/s, est. speed input: 17238.84 toks/s, output: 33.67 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 37.85it/s, est. speed input: 17339.23 toks/s, output: 33.87 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 37.91it/s, est. speed input: 17433.68 toks/s, output: 34.05 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 37.93it/s, est. speed input: 17519.39 toks/s, output: 34.22 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 37.97it/s, est. speed input: 17598.99 toks/s, output: 34.37 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 37.96it/s, est. speed input: 17670.25 toks/s, output: 34.51 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 37.97it/s, est. speed input: 17737.31 toks/s, output: 34.64 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 37.97it/s, est. speed input: 17799.32 toks/s, output: 34.76 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 37.98it/s, est. speed input: 17857.35 toks/s, output: 34.88 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 37.98it/s, est. speed input: 17910.90 toks/s, output: 34.98 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 37.93it/s, est. speed input: 17958.46 toks/s, output: 35.07 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 37.93it/s, est. speed input: 18004.59 toks/s, output: 35.16 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 37.92it/s, est. speed input: 18047.60 toks/s, output: 35.25 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 37.90it/s, est. speed input: 18087.55 toks/s, output: 35.33 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.90it/s, est. speed input: 18116.70 toks/s, output: 35.38 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.38it/s, est. speed input: 18116.70 toks/s, output: 35.38 toks/s]
[rank0]:[W126 10:43:28.010454673 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 10:43:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:43:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1231788) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1231788) WARNING 01-26 10:43:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.28 requests/s, 35133.30 total tokens/s, 34.28 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 10:43:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:43:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:43:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:43:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:43:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:43:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:43:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:43:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:43:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:43:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:43:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:43:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:43:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:43:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1231788) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1231788) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.79it/s]
(EngineCore_DP0 pid=1231788) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.79it/s]
(EngineCore_DP0 pid=1231788) 
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1231788) [2026-01-26 10:43:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1231788) 2026-01-26 10:44:06,034 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1231788) 2026-01-26 10:44:06,078 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1231788) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.23it/s]
(EngineCore_DP0 pid=1231788) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  21%|██        | 27/128 [00:00<00:00, 268.08it/s]
Adding requests:  60%|██████    | 77/128 [00:00<00:00, 401.96it/s]
Adding requests:  99%|█████████▉| 127/128 [00:00<00:00, 445.23it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 420.28it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:03, 37.52it/s, est. speed input: 38426.15 toks/s, output: 37.52 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:03, 37.40it/s, est. speed input: 38320.64 toks/s, output: 37.42 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:03, 37.34it/s, est. speed input: 38269.93 toks/s, output: 37.37 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 37.32it/s, est. speed input: 38253.04 toks/s, output: 37.35 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:02, 37.30it/s, est. speed input: 38231.01 toks/s, output: 37.33 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:02, 37.31it/s, est. speed input: 38230.90 toks/s, output: 37.33 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:00<00:02, 37.30it/s, est. speed input: 38223.22 toks/s, output: 37.33 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:02, 37.30it/s, est. speed input: 38217.18 toks/s, output: 37.32 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:00<00:02, 37.33it/s, est. speed input: 38225.05 toks/s, output: 37.33 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 37.27it/s, est. speed input: 38207.76 toks/s, output: 37.31 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 37.21it/s, est. speed input: 38185.05 toks/s, output: 37.29 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 37.24it/s, est. speed input: 38185.84 toks/s, output: 37.29 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 37.26it/s, est. speed input: 38188.34 toks/s, output: 37.29 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 37.30it/s, est. speed input: 38194.67 toks/s, output: 37.30 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:01<00:01, 37.34it/s, est. speed input: 38203.74 toks/s, output: 37.31 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:01<00:01, 37.36it/s, est. speed input: 38209.52 toks/s, output: 37.31 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:01<00:01, 37.34it/s, est. speed input: 38207.70 toks/s, output: 37.31 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:01<00:01, 37.39it/s, est. speed input: 38218.89 toks/s, output: 37.32 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 37.44it/s, est. speed input: 38231.46 toks/s, output: 37.33 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 37.45it/s, est. speed input: 38238.47 toks/s, output: 37.34 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 37.42it/s, est. speed input: 38239.10 toks/s, output: 37.34 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 37.38it/s, est. speed input: 38235.78 toks/s, output: 37.34 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:02<00:00, 37.36it/s, est. speed input: 38234.62 toks/s, output: 37.34 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 37.35it/s, est. speed input: 38234.50 toks/s, output: 37.34 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:02<00:00, 37.31it/s, est. speed input: 38229.15 toks/s, output: 37.33 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:02<00:00, 37.33it/s, est. speed input: 38231.34 toks/s, output: 37.33 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:02<00:00, 37.30it/s, est. speed input: 38226.97 toks/s, output: 37.33 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 37.32it/s, est. speed input: 38228.26 toks/s, output: 37.33 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 37.31it/s, est. speed input: 38226.08 toks/s, output: 37.33 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 37.32it/s, est. speed input: 38227.24 toks/s, output: 37.33 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:03<00:00, 37.35it/s, est. speed input: 38229.80 toks/s, output: 37.33 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.42it/s, est. speed input: 38237.77 toks/s, output: 37.34 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.42it/s, est. speed input: 38237.77 toks/s, output: 37.34 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.34it/s, est. speed input: 38237.77 toks/s, output: 37.34 toks/s]
[rank0]:[W126 10:44:12.279662348 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 10:44:14
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:44:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1232924) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1232924) WARNING 01-26 10:44:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 57.99 requests/s, 59441.39 total tokens/s, 57.99 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 10:44:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:44:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:44:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:44:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:44:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:44:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:44:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:44:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:44:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:44:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:44:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:44:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:44:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:44:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:44:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:44:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:44:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:31] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1232924) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1232924) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
(EngineCore_DP0 pid=1232924) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
(EngineCore_DP0 pid=1232924) 
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1232924) [2026-01-26 10:44:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1232924) 2026-01-26 10:44:49,334 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1232924) 2026-01-26 10:44:49,358 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1232924) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.20it/s]
(EngineCore_DP0 pid=1232924) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.78it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|█         | 26/256 [00:00<00:00, 255.53it/s]
Adding requests:  30%|███       | 77/256 [00:00<00:00, 404.12it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 446.27it/s]
Adding requests:  69%|██████▉   | 176/256 [00:00<00:00, 460.85it/s]
Adding requests:  88%|████████▊ | 226/256 [00:00<00:00, 471.97it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 453.38it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:01, 146.26it/s, est. speed input: 149799.51 toks/s, output: 146.27 toks/s]
Processed prompts:  12%|█▏        | 31/256 [00:00<00:02, 88.82it/s, est. speed input: 96842.48 toks/s, output: 94.57 toks/s]   
Processed prompts:  16%|█▋        | 42/256 [00:00<00:02, 74.64it/s, est. speed input: 83615.02 toks/s, output: 81.65 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:00<00:02, 74.07it/s, est. speed input: 81857.85 toks/s, output: 79.94 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:00<00:02, 70.97it/s, est. speed input: 79190.22 toks/s, output: 77.33 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:00<00:02, 68.92it/s, est. speed input: 77314.40 toks/s, output: 75.50 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:01<00:02, 67.41it/s, est. speed input: 75855.46 toks/s, output: 74.08 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:02, 63.97it/s, est. speed input: 73828.70 toks/s, output: 72.10 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:01<00:02, 63.97it/s, est. speed input: 73005.16 toks/s, output: 71.29 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:01<00:02, 64.03it/s, est. speed input: 72348.04 toks/s, output: 70.65 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:01<00:02, 64.15it/s, est. speed input: 71825.03 toks/s, output: 70.14 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:01<00:02, 64.10it/s, est. speed input: 71343.54 toks/s, output: 69.67 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:01<00:02, 64.10it/s, est. speed input: 70939.85 toks/s, output: 69.28 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:01<00:01, 64.11it/s, est. speed input: 70591.60 toks/s, output: 68.94 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:02<00:01, 64.16it/s, est. speed input: 70295.06 toks/s, output: 68.65 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:02<00:01, 64.05it/s, est. speed input: 70004.77 toks/s, output: 68.36 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:02<00:01, 64.02it/s, est. speed input: 69753.65 toks/s, output: 68.12 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:02<00:01, 63.99it/s, est. speed input: 69527.67 toks/s, output: 67.90 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:02<00:01, 64.17it/s, est. speed input: 69361.42 toks/s, output: 67.73 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:02<00:01, 64.20it/s, est. speed input: 69193.19 toks/s, output: 67.57 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:02<00:01, 64.15it/s, est. speed input: 69028.54 toks/s, output: 67.41 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:02<00:00, 64.12it/s, est. speed input: 68879.63 toks/s, output: 67.26 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:03<00:00, 64.10it/s, est. speed input: 68743.76 toks/s, output: 67.13 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:03<00:00, 64.04it/s, est. speed input: 68610.80 toks/s, output: 67.00 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:03<00:00, 64.04it/s, est. speed input: 68495.18 toks/s, output: 66.89 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:03<00:00, 63.96it/s, est. speed input: 68376.78 toks/s, output: 66.77 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:03<00:00, 64.10it/s, est. speed input: 68292.16 toks/s, output: 66.69 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:03<00:00, 64.12it/s, est. speed input: 68202.88 toks/s, output: 66.60 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:03<00:00, 64.08it/s, est. speed input: 68114.14 toks/s, output: 66.52 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 64.08it/s, est. speed input: 68130.58 toks/s, output: 66.53 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 66.53it/s, est. speed input: 68130.58 toks/s, output: 66.53 toks/s]
[rank0]:[W126 10:44:56.496817068 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 10:44:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:45:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1234044) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1234044) WARNING 01-26 10:45:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 63.31 requests/s, 64896.59 total tokens/s, 63.31 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 10:45:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:45:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:45:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:45:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:45:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:45:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:45:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:45:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:45:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:45:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:45:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:45:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1234044) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1234044) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.81it/s]
(EngineCore_DP0 pid=1234044) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.81it/s]
(EngineCore_DP0 pid=1234044) 
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1234044) [2026-01-26 10:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1234044) 2026-01-26 10:45:34,597 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1234044) 2026-01-26 10:45:34,621 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1234044) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  5.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  3.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]
(EngineCore_DP0 pid=1234044) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 13.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 15.61it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 289.11it/s]
Adding requests:  16%|█▌        | 80/512 [00:00<00:01, 415.83it/s]
Adding requests:  25%|██▌       | 130/512 [00:00<00:00, 452.61it/s]
Adding requests:  35%|███▍      | 178/512 [00:00<00:00, 461.89it/s]
Adding requests:  45%|████▍     | 228/512 [00:00<00:00, 475.10it/s]
Adding requests:  54%|█████▍    | 278/512 [00:00<00:00, 480.41it/s]
Adding requests:  64%|██████▍   | 327/512 [00:00<00:00, 481.78it/s]
Adding requests:  74%|███████▍  | 378/512 [00:00<00:00, 488.74it/s]
Adding requests:  84%|████████▎ | 428/512 [00:00<00:00, 491.26it/s]
Adding requests:  93%|█████████▎| 478/512 [00:01<00:00, 492.85it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 474.32it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:00<00:01, 365.04it/s, est. speed input: 373869.41 toks/s, output: 365.06 toks/s]
Processed prompts:  15%|█▌        | 79/512 [00:00<00:03, 109.86it/s, est. speed input: 126615.06 toks/s, output: 123.64 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:00<00:04, 91.71it/s, est. speed input: 107763.63 toks/s, output: 105.24 toks/s] 
Processed prompts:  22%|██▏       | 113/512 [00:01<00:04, 88.40it/s, est. speed input: 103490.05 toks/s, output: 101.06 toks/s]
Processed prompts:  24%|██▍       | 125/512 [00:01<00:04, 82.94it/s, est. speed input: 98890.87 toks/s, output: 96.57 toks/s]  
Processed prompts:  26%|██▋       | 135/512 [00:01<00:04, 75.85it/s, est. speed input: 94098.47 toks/s, output: 91.89 toks/s]
Processed prompts:  28%|██▊       | 144/512 [00:01<00:04, 76.20it/s, est. speed input: 93023.36 toks/s, output: 90.84 toks/s]
Processed prompts:  30%|██▉       | 153/512 [00:01<00:04, 76.30it/s, est. speed input: 92017.94 toks/s, output: 89.86 toks/s]
Processed prompts:  31%|███▏      | 161/512 [00:01<00:04, 73.91it/s, est. speed input: 90465.88 toks/s, output: 88.35 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:01<00:04, 71.80it/s, est. speed input: 89040.43 toks/s, output: 86.95 toks/s]
Processed prompts:  35%|███▍      | 177/512 [00:02<00:04, 70.35it/s, est. speed input: 87819.96 toks/s, output: 85.76 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:02<00:04, 69.68it/s, est. speed input: 86833.91 toks/s, output: 84.80 toks/s]
Processed prompts:  38%|███▊      | 192/512 [00:02<00:04, 66.76it/s, est. speed input: 85499.91 toks/s, output: 83.50 toks/s]
Processed prompts:  39%|███▉      | 199/512 [00:02<00:04, 64.75it/s, est. speed input: 84323.58 toks/s, output: 82.35 toks/s]
Processed prompts:  40%|████      | 206/512 [00:02<00:04, 63.34it/s, est. speed input: 83263.40 toks/s, output: 81.31 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:02<00:04, 64.85it/s, est. speed input: 82684.87 toks/s, output: 80.75 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:02<00:04, 65.67it/s, est. speed input: 82109.21 toks/s, output: 80.18 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:02<00:04, 66.05it/s, est. speed input: 81548.31 toks/s, output: 79.64 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:03<00:04, 66.25it/s, est. speed input: 81020.17 toks/s, output: 79.12 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:03<00:03, 66.50it/s, est. speed input: 80550.88 toks/s, output: 78.66 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:03<00:03, 66.87it/s, est. speed input: 80143.18 toks/s, output: 78.26 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:03<00:03, 67.28it/s, est. speed input: 79785.50 toks/s, output: 77.91 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:03<00:03, 67.56it/s, est. speed input: 79450.76 toks/s, output: 77.59 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:03<00:03, 67.70it/s, est. speed input: 79131.02 toks/s, output: 77.28 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:03<00:03, 67.66it/s, est. speed input: 78814.60 toks/s, output: 76.97 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:03<00:03, 67.40it/s, est. speed input: 78488.98 toks/s, output: 76.65 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:03<00:03, 67.11it/s, est. speed input: 78171.51 toks/s, output: 76.34 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:04<00:03, 66.84it/s, est. speed input: 77863.73 toks/s, output: 76.04 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:04<00:02, 67.01it/s, est. speed input: 77614.49 toks/s, output: 75.79 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:04<00:02, 67.33it/s, est. speed input: 77399.52 toks/s, output: 75.58 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:04<00:02, 67.68it/s, est. speed input: 77209.46 toks/s, output: 75.40 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:04<00:02, 69.36it/s, est. speed input: 77165.19 toks/s, output: 75.36 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:04<00:02, 69.02it/s, est. speed input: 76981.50 toks/s, output: 75.18 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:04<00:02, 68.63it/s, est. speed input: 76792.61 toks/s, output: 74.99 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:04<00:02, 68.07it/s, est. speed input: 76587.60 toks/s, output: 74.79 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:05<00:02, 67.92it/s, est. speed input: 76413.18 toks/s, output: 74.62 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:05<00:01, 67.88it/s, est. speed input: 76251.61 toks/s, output: 74.46 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:05<00:01, 67.95it/s, est. speed input: 76106.09 toks/s, output: 74.32 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:05<00:01, 67.93it/s, est. speed input: 75961.48 toks/s, output: 74.18 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:05<00:01, 67.95it/s, est. speed input: 75825.63 toks/s, output: 74.05 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:05<00:01, 68.07it/s, est. speed input: 75703.32 toks/s, output: 73.93 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:05<00:01, 67.73it/s, est. speed input: 75554.28 toks/s, output: 73.78 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:05<00:01, 67.58it/s, est. speed input: 75417.75 toks/s, output: 73.65 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:05<00:01, 67.29it/s, est. speed input: 75272.29 toks/s, output: 73.51 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:06<00:00, 67.30it/s, est. speed input: 75148.34 toks/s, output: 73.39 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:06<00:00, 69.23it/s, est. speed input: 75162.75 toks/s, output: 73.40 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:06<00:00, 68.70it/s, est. speed input: 75049.18 toks/s, output: 73.29 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:06<00:00, 68.30it/s, est. speed input: 74936.95 toks/s, output: 73.18 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:06<00:00, 68.27it/s, est. speed input: 74845.64 toks/s, output: 73.09 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:06<00:00, 68.02it/s, est. speed input: 74742.41 toks/s, output: 72.99 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:06<00:00, 67.91it/s, est. speed input: 74647.39 toks/s, output: 72.90 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:06<00:00, 67.42it/s, est. speed input: 74528.96 toks/s, output: 72.78 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:07<00:00, 69.31it/s, est. speed input: 74550.70 toks/s, output: 72.80 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 69.31it/s, est. speed input: 74840.07 toks/s, output: 73.09 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 73.08it/s, est. speed input: 74840.07 toks/s, output: 73.09 toks/s]
[rank0]:[W126 10:45:45.716528722 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 10:45:47
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:45:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1235229) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1235229) WARNING 01-26 10:46:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 69.82 requests/s, 71566.58 total tokens/s, 69.82 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 10:45:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:45:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:45:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:45:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:45:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:45:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:45:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:45:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:46:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:46:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:46:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:46:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:46:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:46:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:46:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:46:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:46:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1235229) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1235229) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1235229) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.81it/s]
(EngineCore_DP0 pid=1235229) 
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1235229) [2026-01-26 10:46:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1235229) 2026-01-26 10:46:24,819 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1235229) 2026-01-26 10:46:24,843 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1235229) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:03,  1.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:01,  2.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.31it/s]
(EngineCore_DP0 pid=1235229) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.98it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 14.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 13.68it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 31/1024 [00:00<00:03, 306.58it/s]
Adding requests:   8%|▊         | 82/1024 [00:00<00:02, 425.02it/s]
Adding requests:  13%|█▎        | 132/1024 [00:00<00:01, 458.06it/s]
Adding requests:  18%|█▊        | 180/1024 [00:00<00:01, 465.54it/s]
Adding requests:  23%|██▎       | 231/1024 [00:00<00:01, 479.63it/s]
Adding requests:  27%|██▋       | 281/1024 [00:00<00:01, 483.70it/s]
Adding requests:  32%|███▏      | 330/1024 [00:00<00:01, 483.58it/s]
Adding requests:  37%|███▋      | 381/1024 [00:00<00:01, 489.87it/s]
Adding requests:  42%|████▏     | 432/1024 [00:00<00:01, 493.48it/s]
Adding requests:  47%|████▋     | 482/1024 [00:01<00:01, 493.09it/s]
Adding requests:  52%|█████▏    | 532/1024 [00:01<00:01, 475.93it/s]
Adding requests:  57%|█████▋    | 583/1024 [00:01<00:00, 484.38it/s]
Adding requests:  62%|██████▏   | 634/1024 [00:01<00:00, 489.86it/s]
Adding requests:  67%|██████▋   | 686/1024 [00:01<00:00, 497.63it/s]
Adding requests:  72%|███████▏  | 738/1024 [00:01<00:00, 502.99it/s]
Adding requests:  77%|███████▋  | 789/1024 [00:01<00:00, 498.27it/s]
Adding requests:  82%|████████▏ | 839/1024 [00:01<00:00, 489.98it/s]
Adding requests:  87%|████████▋ | 891/1024 [00:01<00:00, 498.73it/s]
Adding requests:  92%|█████████▏| 942/1024 [00:01<00:00, 500.25it/s]
Adding requests:  97%|█████████▋| 994/1024 [00:02<00:00, 503.74it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 487.49it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:00<00:01, 801.16it/s, est. speed input: 820588.78 toks/s, output: 801.21 toks/s]
Processed prompts:  22%|██▏       | 227/1024 [00:01<00:05, 144.85it/s, est. speed input: 176176.75 toks/s, output: 172.05 toks/s]
Processed prompts:  26%|██▌       | 265/1024 [00:01<00:06, 124.36it/s, est. speed input: 153237.01 toks/s, output: 149.64 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:02<00:07, 101.42it/s, est. speed input: 133230.33 toks/s, output: 130.11 toks/s]
Processed prompts:  30%|██▉       | 307/1024 [00:02<00:07, 96.44it/s, est. speed input: 128015.68 toks/s, output: 125.01 toks/s] 
Processed prompts:  31%|███▏      | 321/1024 [00:02<00:07, 99.75it/s, est. speed input: 127998.27 toks/s, output: 125.00 toks/s]
Processed prompts:  33%|███▎      | 335/1024 [00:02<00:07, 90.08it/s, est. speed input: 122724.00 toks/s, output: 119.85 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:03<00:08, 79.70it/s, est. speed input: 117524.05 toks/s, output: 114.77 toks/s]
Processed prompts:  35%|███▍      | 355/1024 [00:03<00:08, 79.61it/s, est. speed input: 116196.76 toks/s, output: 113.47 toks/s]
Processed prompts:  36%|███▌      | 364/1024 [00:03<00:08, 79.51it/s, est. speed input: 114959.45 toks/s, output: 112.26 toks/s]
Processed prompts:  36%|███▋      | 373/1024 [00:03<00:08, 79.46it/s, est. speed input: 113816.82 toks/s, output: 111.15 toks/s]
Processed prompts:  37%|███▋      | 382/1024 [00:03<00:08, 79.42it/s, est. speed input: 112748.24 toks/s, output: 110.11 toks/s]
Processed prompts:  38%|███▊      | 391/1024 [00:03<00:07, 79.46it/s, est. speed input: 111762.24 toks/s, output: 109.14 toks/s]
Processed prompts:  39%|███▉      | 400/1024 [00:03<00:07, 79.41it/s, est. speed input: 110822.44 toks/s, output: 108.22 toks/s]
Processed prompts:  40%|███▉      | 409/1024 [00:03<00:07, 79.54it/s, est. speed input: 109964.80 toks/s, output: 107.39 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:04<00:09, 61.47it/s, est. speed input: 105932.84 toks/s, output: 103.45 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:04<00:09, 63.59it/s, est. speed input: 105006.97 toks/s, output: 102.54 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:04<00:09, 65.31it/s, est. speed input: 104130.31 toks/s, output: 101.69 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:04<00:08, 66.68it/s, est. speed input: 103301.78 toks/s, output: 100.88 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:04<00:08, 69.43it/s, est. speed input: 102748.34 toks/s, output: 100.34 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:04<00:08, 69.77it/s, est. speed input: 101998.63 toks/s, output: 99.61 toks/s] 
Processed prompts:  46%|████▌     | 466/1024 [00:04<00:07, 70.02it/s, est. speed input: 101285.16 toks/s, output: 98.91 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:04<00:07, 70.20it/s, est. speed input: 100604.64 toks/s, output: 98.25 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:04<00:07, 69.84it/s, est. speed input: 99901.81 toks/s, output: 97.56 toks/s] 
Processed prompts:  48%|████▊     | 490/1024 [00:05<00:07, 69.92it/s, est. speed input: 99267.25 toks/s, output: 96.94 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:05<00:07, 69.99it/s, est. speed input: 98662.82 toks/s, output: 96.35 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:05<00:07, 70.09it/s, est. speed input: 98088.50 toks/s, output: 95.79 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:05<00:07, 70.19it/s, est. speed input: 97541.90 toks/s, output: 95.25 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:05<00:07, 70.16it/s, est. speed input: 97007.48 toks/s, output: 94.73 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:05<00:07, 70.10it/s, est. speed input: 96491.98 toks/s, output: 94.23 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:05<00:06, 70.01it/s, est. speed input: 95992.15 toks/s, output: 93.74 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:05<00:06, 70.01it/s, est. speed input: 95517.97 toks/s, output: 93.28 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:05<00:06, 69.71it/s, est. speed input: 95035.84 toks/s, output: 92.81 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:06<00:06, 69.68it/s, est. speed input: 94586.99 toks/s, output: 92.37 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:06<00:06, 69.69it/s, est. speed input: 94157.30 toks/s, output: 91.95 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:06<00:06, 70.06it/s, est. speed input: 93773.09 toks/s, output: 91.57 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:06<00:06, 70.02it/s, est. speed input: 93378.17 toks/s, output: 91.19 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:06<00:06, 70.22it/s, est. speed input: 93015.42 toks/s, output: 90.83 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:06<00:06, 70.14it/s, est. speed input: 92647.58 toks/s, output: 90.48 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:06<00:05, 69.95it/s, est. speed input: 92282.52 toks/s, output: 90.12 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:06<00:05, 69.91it/s, est. speed input: 91936.36 toks/s, output: 89.78 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:06<00:05, 69.88it/s, est. speed input: 91601.34 toks/s, output: 89.45 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:07<00:05, 69.94it/s, est. speed input: 91283.22 toks/s, output: 89.14 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:07<00:05, 69.98it/s, est. speed input: 90974.71 toks/s, output: 88.84 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:07<00:05, 70.08it/s, est. speed input: 90680.17 toks/s, output: 88.55 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:07<00:05, 70.31it/s, est. speed input: 90405.81 toks/s, output: 88.29 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:07<00:05, 70.33it/s, est. speed input: 90130.18 toks/s, output: 88.02 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:07<00:04, 70.24it/s, est. speed input: 89856.43 toks/s, output: 87.75 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:07<00:04, 70.31it/s, est. speed input: 89598.80 toks/s, output: 87.50 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:07<00:04, 70.31it/s, est. speed input: 89345.58 toks/s, output: 87.25 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:08<00:04, 69.98it/s, est. speed input: 89079.65 toks/s, output: 86.99 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:08<00:04, 69.90it/s, est. speed input: 88830.08 toks/s, output: 86.75 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:08<00:04, 70.00it/s, est. speed input: 88596.71 toks/s, output: 86.52 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:08<00:04, 69.94it/s, est. speed input: 88362.42 toks/s, output: 86.29 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:08<00:04, 69.92it/s, est. speed input: 88135.30 toks/s, output: 86.07 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:08<00:04, 70.03it/s, est. speed input: 87921.28 toks/s, output: 85.86 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:08<00:03, 70.21it/s, est. speed input: 87718.48 toks/s, output: 85.66 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:08<00:03, 70.06it/s, est. speed input: 87506.10 toks/s, output: 85.45 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:08<00:03, 70.05it/s, est. speed input: 87303.97 toks/s, output: 85.26 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:09<00:03, 69.96it/s, est. speed input: 87103.04 toks/s, output: 85.06 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:09<00:03, 69.78it/s, est. speed input: 86900.50 toks/s, output: 84.86 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:09<00:03, 69.74it/s, est. speed input: 86707.62 toks/s, output: 84.68 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:09<00:03, 69.99it/s, est. speed input: 86533.83 toks/s, output: 84.51 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:09<00:03, 70.04it/s, est. speed input: 86357.39 toks/s, output: 84.33 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:09<00:03, 69.96it/s, est. speed input: 86179.92 toks/s, output: 84.16 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:09<00:02, 69.89it/s, est. speed input: 86005.57 toks/s, output: 83.99 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:09<00:02, 70.00it/s, est. speed input: 85843.43 toks/s, output: 83.83 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:09<00:02, 69.76it/s, est. speed input: 85669.69 toks/s, output: 83.66 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:10<00:02, 69.88it/s, est. speed input: 85513.21 toks/s, output: 83.51 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:10<00:02, 69.68it/s, est. speed input: 85347.37 toks/s, output: 83.35 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:10<00:02, 69.98it/s, est. speed input: 85205.21 toks/s, output: 83.21 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:10<00:02, 70.14it/s, est. speed input: 85063.74 toks/s, output: 83.07 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:10<00:02, 69.95it/s, est. speed input: 84912.27 toks/s, output: 82.92 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:10<00:02, 69.99it/s, est. speed input: 84771.08 toks/s, output: 82.78 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:10<00:01, 69.92it/s, est. speed input: 84628.91 toks/s, output: 82.65 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:10<00:01, 69.82it/s, est. speed input: 84487.68 toks/s, output: 82.51 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:10<00:01, 69.67it/s, est. speed input: 84346.07 toks/s, output: 82.37 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:11<00:01, 69.96it/s, est. speed input: 84223.63 toks/s, output: 82.25 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:11<00:01, 70.16it/s, est. speed input: 84103.87 toks/s, output: 82.13 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:11<00:01, 70.10it/s, est. speed input: 83978.07 toks/s, output: 82.01 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:11<00:01, 72.34it/s, est. speed input: 83942.77 toks/s, output: 81.98 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:11<00:01, 71.69it/s, est. speed input: 83824.02 toks/s, output: 81.86 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:11<00:00, 71.03it/s, est. speed input: 83699.64 toks/s, output: 81.74 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:11<00:00, 70.76it/s, est. speed input: 83584.59 toks/s, output: 81.63 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:11<00:00, 70.21it/s, est. speed input: 83458.41 toks/s, output: 81.50 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:12<00:00, 70.21it/s, est. speed input: 83348.74 toks/s, output: 81.40 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:12<00:00, 72.41it/s, est. speed input: 83320.32 toks/s, output: 81.37 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:12<00:00, 71.83it/s, est. speed input: 83217.18 toks/s, output: 81.27 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:12<00:00, 71.20it/s, est. speed input: 83108.01 toks/s, output: 81.16 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:12<00:00, 70.66it/s, est. speed input: 82996.96 toks/s, output: 81.05 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:12<00:00, 72.85it/s, est. speed input: 82975.88 toks/s, output: 81.03 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:12<00:00, 72.85it/s, est. speed input: 83462.45 toks/s, output: 81.51 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:12<00:00, 81.51it/s, est. speed input: 83462.45 toks/s, output: 81.51 toks/s]
[rank0]:[W126 10:46:42.878580165 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 10:46:44
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:47:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1236571) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1236571) WARNING 01-26 10:47:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 71.49 requests/s, 73272.91 total tokens/s, 71.49 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 10:46:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:47:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:47:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:47:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:47:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:47:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:47:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:47:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:47:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:47:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:47:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:47:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:47:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:47:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:47:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:47:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:47:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:08] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1236571) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1236571) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1236571) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1236571) 
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1236571) [2026-01-26 10:47:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1236571) 2026-01-26 10:47:26,253 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1236571) 2026-01-26 10:47:26,278 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1236571) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  5.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 11.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 14.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 15.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 13.95it/s]
(EngineCore_DP0 pid=1236571) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  9.92it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  9.35it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  4.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  4.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  5.21it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 32/2048 [00:00<00:06, 316.47it/s]
Adding requests:   4%|▍         | 83/2048 [00:00<00:04, 429.07it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:04, 459.95it/s]
Adding requests:   9%|▉         | 181/2048 [00:00<00:03, 467.62it/s]
Adding requests:  11%|█▏        | 232/2048 [00:00<00:03, 480.10it/s]
Adding requests:  14%|█▍        | 282/2048 [00:00<00:03, 484.37it/s]
Adding requests:  16%|█▌        | 331/2048 [00:00<00:03, 484.29it/s]
Adding requests:  19%|█▊        | 382/2048 [00:00<00:03, 489.27it/s]
Adding requests:  21%|██        | 433/2048 [00:00<00:03, 493.45it/s]
Adding requests:  24%|██▎       | 483/2048 [00:01<00:03, 492.76it/s]
Adding requests:  26%|██▌       | 533/2048 [00:01<00:03, 481.61it/s]
Adding requests:  29%|██▊       | 584/2048 [00:01<00:02, 488.35it/s]
Adding requests:  31%|███       | 635/2048 [00:01<00:02, 491.80it/s]
Adding requests:  33%|███▎      | 686/2048 [00:01<00:02, 496.04it/s]
Adding requests:  36%|███▌      | 737/2048 [00:01<00:02, 499.88it/s]
Adding requests:  38%|███▊      | 788/2048 [00:01<00:02, 486.79it/s]
Adding requests:  41%|████      | 837/2048 [00:01<00:02, 479.11it/s]
Adding requests:  43%|████▎     | 888/2048 [00:01<00:02, 485.25it/s]
Adding requests:  46%|████▌     | 939/2048 [00:01<00:02, 489.64it/s]
Adding requests:  48%|████▊     | 990/2048 [00:02<00:02, 493.24it/s]
Adding requests:  51%|█████     | 1041/2048 [00:02<00:02, 494.89it/s]
Adding requests:  53%|█████▎    | 1091/2048 [00:02<00:01, 493.95it/s]
Adding requests:  56%|█████▌    | 1141/2048 [00:02<00:01, 488.84it/s]
Adding requests:  58%|█████▊    | 1194/2048 [00:02<00:01, 500.00it/s]
Adding requests:  61%|██████    | 1245/2048 [00:02<00:01, 499.48it/s]
Adding requests:  63%|██████▎   | 1295/2048 [00:02<00:01, 495.64it/s]
Adding requests:  66%|██████▌   | 1346/2048 [00:02<00:01, 497.53it/s]
Adding requests:  68%|██████▊   | 1398/2048 [00:02<00:01, 503.94it/s]
Adding requests:  71%|███████   | 1449/2048 [00:02<00:01, 501.92it/s]
Adding requests:  73%|███████▎  | 1501/2048 [00:03<00:01, 506.65it/s]
Adding requests:  76%|███████▌  | 1552/2048 [00:03<00:00, 505.33it/s]
Adding requests:  78%|███████▊  | 1605/2048 [00:03<00:00, 512.28it/s]
Adding requests:  81%|████████  | 1657/2048 [00:03<00:00, 508.82it/s]
Adding requests:  83%|████████▎ | 1708/2048 [00:03<00:00, 505.77it/s]
Adding requests:  86%|████████▌ | 1759/2048 [00:03<00:00, 504.73it/s]
Adding requests:  88%|████████▊ | 1810/2048 [00:03<00:00, 503.38it/s]
Adding requests:  91%|█████████ | 1861/2048 [00:03<00:00, 501.29it/s]
Adding requests:  93%|█████████▎| 1912/2048 [00:03<00:00, 489.39it/s]
Adding requests:  96%|█████████▌| 1962/2048 [00:03<00:00, 491.86it/s]
Adding requests:  98%|█████████▊| 2014/2048 [00:04<00:00, 496.15it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 492.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:00<00:01, 901.15it/s, est. speed input: 922850.24 toks/s, output: 901.17 toks/s]
Processed prompts:  19%|█▊        | 381/2048 [00:01<00:07, 221.72it/s, est. speed input: 274261.58 toks/s, output: 267.83 toks/s]
Processed prompts:  21%|██        | 423/2048 [00:02<00:10, 155.50it/s, est. speed input: 207455.83 toks/s, output: 202.59 toks/s]
Processed prompts:  22%|██▏       | 449/2048 [00:02<00:10, 148.94it/s, est. speed input: 198897.83 toks/s, output: 194.24 toks/s]
Processed prompts:  23%|██▎       | 470/2048 [00:02<00:13, 117.22it/s, est. speed input: 175367.70 toks/s, output: 171.26 toks/s]
Processed prompts:  24%|██▎       | 485/2048 [00:02<00:14, 107.83it/s, est. speed input: 167387.52 toks/s, output: 163.46 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:03<00:15, 97.53it/s, est. speed input: 159974.54 toks/s, output: 156.22 toks/s] 
Processed prompts:  25%|██▌       | 514/2048 [00:03<00:16, 91.46it/s, est. speed input: 154292.24 toks/s, output: 150.67 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:03<00:17, 86.52it/s, est. speed input: 149324.55 toks/s, output: 145.82 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:03<00:18, 82.93it/s, est. speed input: 145051.31 toks/s, output: 141.65 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:04<00:18, 80.06it/s, est. speed input: 141205.05 toks/s, output: 137.89 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:04<00:18, 77.59it/s, est. speed input: 137646.94 toks/s, output: 134.42 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:04<00:19, 75.81it/s, est. speed input: 134451.55 toks/s, output: 131.30 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:04<00:19, 74.63it/s, est. speed input: 131585.86 toks/s, output: 128.50 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:04<00:19, 73.84it/s, est. speed input: 128992.46 toks/s, output: 125.97 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:05<00:19, 73.45it/s, est. speed input: 126664.44 toks/s, output: 123.69 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:05<00:19, 73.07it/s, est. speed input: 124503.42 toks/s, output: 121.58 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:05<00:18, 72.68it/s, est. speed input: 122484.85 toks/s, output: 119.61 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:05<00:18, 72.45it/s, est. speed input: 120629.50 toks/s, output: 117.80 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:06<00:18, 72.42it/s, est. speed input: 118936.42 toks/s, output: 116.15 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:06<00:18, 72.34it/s, est. speed input: 117350.00 toks/s, output: 114.60 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:06<00:18, 72.12it/s, est. speed input: 115841.49 toks/s, output: 113.13 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:06<00:17, 71.90it/s, est. speed input: 114423.01 toks/s, output: 111.74 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:06<00:17, 71.90it/s, est. speed input: 113120.37 toks/s, output: 110.47 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:07<00:17, 72.00it/s, est. speed input: 111914.79 toks/s, output: 109.29 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:07<00:17, 71.94it/s, est. speed input: 110760.29 toks/s, output: 108.16 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:07<00:17, 71.97it/s, est. speed input: 109685.04 toks/s, output: 107.11 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:07<00:16, 71.87it/s, est. speed input: 108652.75 toks/s, output: 106.11 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:08<00:16, 71.90it/s, est. speed input: 107691.13 toks/s, output: 105.17 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:08<00:16, 71.99it/s, est. speed input: 106790.41 toks/s, output: 104.29 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:08<00:16, 71.83it/s, est. speed input: 105907.52 toks/s, output: 103.42 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:08<00:16, 71.76it/s, est. speed input: 105075.80 toks/s, output: 102.61 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:08<00:15, 71.79it/s, est. speed input: 104294.54 toks/s, output: 101.85 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:09<00:15, 73.04it/s, est. speed input: 103691.65 toks/s, output: 101.26 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:09<00:15, 72.73it/s, est. speed input: 102983.96 toks/s, output: 100.57 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:09<00:15, 72.34it/s, est. speed input: 102290.70 toks/s, output: 99.89 toks/s] 
Processed prompts:  48%|████▊     | 978/2048 [00:09<00:14, 73.39it/s, est. speed input: 101766.66 toks/s, output: 99.38 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:10<00:14, 72.73it/s, est. speed input: 101123.10 toks/s, output: 98.75 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:10<00:14, 72.61it/s, est. speed input: 100541.56 toks/s, output: 98.18 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:10<00:14, 72.33it/s, est. speed input: 99965.41 toks/s, output: 97.62 toks/s] 
Processed prompts:  51%|█████     | 1042/2048 [00:10<00:13, 72.10it/s, est. speed input: 99409.21 toks/s, output: 97.08 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:10<00:13, 71.96it/s, est. speed input: 98878.73 toks/s, output: 96.56 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:11<00:13, 72.07it/s, est. speed input: 98387.18 toks/s, output: 96.08 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:11<00:13, 72.08it/s, est. speed input: 97909.09 toks/s, output: 95.61 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:11<00:13, 71.82it/s, est. speed input: 97426.23 toks/s, output: 95.14 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:11<00:12, 71.75it/s, est. speed input: 96971.86 toks/s, output: 94.70 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:12<00:12, 71.67it/s, est. speed input: 96530.50 toks/s, output: 94.27 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:12<00:12, 72.90it/s, est. speed input: 96208.60 toks/s, output: 93.95 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:12<00:12, 72.53it/s, est. speed input: 95801.48 toks/s, output: 93.56 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:12<00:11, 72.16it/s, est. speed input: 95400.07 toks/s, output: 93.16 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:12<00:11, 71.99it/s, est. speed input: 95019.11 toks/s, output: 92.79 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:13<00:11, 72.04it/s, est. speed input: 94663.16 toks/s, output: 92.44 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:13<00:11, 72.08it/s, est. speed input: 94319.57 toks/s, output: 92.11 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:13<00:11, 72.03it/s, est. speed input: 93981.62 toks/s, output: 91.78 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:13<00:10, 71.78it/s, est. speed input: 93639.72 toks/s, output: 91.44 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:14<00:10, 71.61it/s, est. speed input: 93309.27 toks/s, output: 91.12 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:14<00:10, 71.62it/s, est. speed input: 92997.52 toks/s, output: 90.82 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:14<00:10, 71.76it/s, est. speed input: 92704.03 toks/s, output: 90.53 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:14<00:10, 71.70it/s, est. speed input: 92409.29 toks/s, output: 90.24 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:14<00:09, 71.74it/s, est. speed input: 92128.48 toks/s, output: 89.97 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:15<00:09, 71.66it/s, est. speed input: 91849.52 toks/s, output: 89.70 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:15<00:09, 71.57it/s, est. speed input: 91576.48 toks/s, output: 89.43 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:15<00:09, 71.52it/s, est. speed input: 91311.73 toks/s, output: 89.17 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:15<00:08, 71.57it/s, est. speed input: 91059.58 toks/s, output: 88.93 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:16<00:08, 71.78it/s, est. speed input: 90824.87 toks/s, output: 88.70 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:16<00:08, 71.79it/s, est. speed input: 90588.51 toks/s, output: 88.47 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:16<00:08, 71.59it/s, est. speed input: 90346.92 toks/s, output: 88.23 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:16<00:08, 71.55it/s, est. speed input: 90117.28 toks/s, output: 88.00 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:16<00:07, 71.58it/s, est. speed input: 89896.82 toks/s, output: 87.79 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:17<00:07, 71.70it/s, est. speed input: 89687.95 toks/s, output: 87.59 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:17<00:07, 71.98it/s, est. speed input: 89494.36 toks/s, output: 87.40 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:17<00:07, 72.09it/s, est. speed input: 89300.72 toks/s, output: 87.21 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:17<00:06, 71.97it/s, est. speed input: 89102.26 toks/s, output: 87.01 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:18<00:06, 72.21it/s, est. speed input: 88924.87 toks/s, output: 86.84 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:18<00:06, 72.07it/s, est. speed input: 88736.35 toks/s, output: 86.66 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:18<00:06, 71.97it/s, est. speed input: 88552.75 toks/s, output: 86.48 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:18<00:05, 71.93it/s, est. speed input: 88374.57 toks/s, output: 86.30 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:18<00:05, 71.93it/s, est. speed input: 88202.02 toks/s, output: 86.13 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:19<00:05, 72.06it/s, est. speed input: 88039.38 toks/s, output: 85.98 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:19<00:05, 72.04it/s, est. speed input: 87875.48 toks/s, output: 85.82 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:19<00:05, 72.00it/s, est. speed input: 87714.02 toks/s, output: 85.66 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:19<00:04, 72.17it/s, est. speed input: 87565.08 toks/s, output: 85.51 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:20<00:04, 72.06it/s, est. speed input: 87409.45 toks/s, output: 85.36 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:20<00:04, 72.14it/s, est. speed input: 87264.13 toks/s, output: 85.22 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:20<00:04, 71.93it/s, est. speed input: 87110.38 toks/s, output: 85.07 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:20<00:03, 71.80it/s, est. speed input: 86960.29 toks/s, output: 84.92 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:20<00:03, 71.92it/s, est. speed input: 86822.51 toks/s, output: 84.79 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:21<00:03, 71.95it/s, est. speed input: 86685.38 toks/s, output: 84.65 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:21<00:03, 71.93it/s, est. speed input: 86549.54 toks/s, output: 84.52 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:21<00:03, 71.98it/s, est. speed input: 86419.24 toks/s, output: 84.39 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:21<00:02, 72.00it/s, est. speed input: 86290.52 toks/s, output: 84.27 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:22<00:02, 72.02it/s, est. speed input: 86165.07 toks/s, output: 84.15 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:22<00:02, 73.20it/s, est. speed input: 86087.42 toks/s, output: 84.07 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:22<00:02, 72.79it/s, est. speed input: 85963.66 toks/s, output: 83.95 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:22<00:01, 72.64it/s, est. speed input: 85847.44 toks/s, output: 83.84 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:22<00:01, 72.44it/s, est. speed input: 85729.90 toks/s, output: 83.72 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:23<00:01, 72.44it/s, est. speed input: 85619.79 toks/s, output: 83.61 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:23<00:01, 73.45it/s, est. speed input: 85548.85 toks/s, output: 83.54 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:23<00:01, 73.05it/s, est. speed input: 85438.93 toks/s, output: 83.44 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:23<00:00, 72.51it/s, est. speed input: 85321.85 toks/s, output: 83.32 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:24<00:00, 72.41it/s, est. speed input: 85216.76 toks/s, output: 83.22 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:24<00:00, 72.46it/s, est. speed input: 85117.57 toks/s, output: 83.12 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:24<00:00, 73.84it/s, est. speed input: 85067.12 toks/s, output: 83.07 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:24<00:00, 73.84it/s, est. speed input: 85650.47 toks/s, output: 83.64 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:24<00:00, 83.64it/s, est. speed input: 85650.47 toks/s, output: 83.64 toks/s]
[rank0]:[W126 10:47:58.331600458 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 10:48:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:48:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1238203) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1238203) WARNING 01-26 10:48:42 [backends.py:609] Failed to read file <frozen os>
Throughput: 72.58 requests/s, 74396.17 total tokens/s, 72.58 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 10:48:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:48:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:48:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:48:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:48:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:48:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:48:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:48:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:48:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:48:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:48:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:48:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:48:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:48:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:48:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:48:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:48:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1238203) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1238203) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1238203) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1238203) 
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1238203) [2026-01-26 10:48:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1238203) [rank0]:W0126 10:48:48.085000 1238203 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1238203) [rank0]:W0126 10:48:48.167000 1238203 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1238203) [rank0]:W0126 10:48:49.011000 1238203 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1238203) [rank0]:W0126 10:48:49.133000 1238203 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1238203) 2026-01-26 10:48:53,101 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1238203) 2026-01-26 10:48:53,126 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1238203) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 12.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  9.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:01,  4.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  6.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  6.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.99it/s]
(EngineCore_DP0 pid=1238203) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 16.97it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 19.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 14.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 15.23it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 34/4096 [00:00<00:12, 338.11it/s]
Adding requests:   2%|▏         | 84/4096 [00:00<00:09, 432.86it/s]
Adding requests:   3%|▎         | 133/4096 [00:00<00:08, 458.23it/s]
Adding requests:   4%|▍         | 180/4096 [00:00<00:08, 460.07it/s]
Adding requests:   6%|▌         | 230/4096 [00:00<00:08, 473.36it/s]
Adding requests:   7%|▋         | 280/4096 [00:00<00:07, 479.09it/s]
Adding requests:   8%|▊         | 328/4096 [00:00<00:07, 479.03it/s]
Adding requests:   9%|▉         | 379/4096 [00:00<00:07, 486.16it/s]
Adding requests:  10%|█         | 428/4096 [00:00<00:07, 486.95it/s]
Adding requests:  12%|█▏        | 478/4096 [00:01<00:07, 488.57it/s]
Adding requests:  13%|█▎        | 527/4096 [00:01<00:07, 477.17it/s]
Adding requests:  14%|█▍        | 578/4096 [00:01<00:07, 485.33it/s]
Adding requests:  15%|█▌        | 628/4096 [00:01<00:07, 488.84it/s]
Adding requests:  17%|█▋        | 679/4096 [00:01<00:06, 493.62it/s]
Adding requests:  18%|█▊        | 730/4096 [00:01<00:06, 498.10it/s]
Adding requests:  19%|█▉        | 780/4096 [00:01<00:06, 493.18it/s]
Adding requests:  20%|██        | 830/4096 [00:01<00:06, 484.66it/s]
Adding requests:  21%|██▏       | 880/4096 [00:01<00:06, 488.25it/s]
Adding requests:  23%|██▎       | 931/4096 [00:01<00:06, 493.13it/s]
Adding requests:  24%|██▍       | 981/4096 [00:02<00:06, 494.20it/s]
Adding requests:  25%|██▌       | 1032/4096 [00:02<00:06, 497.34it/s]
Adding requests:  26%|██▋       | 1082/4096 [00:02<00:06, 494.35it/s]
Adding requests:  28%|██▊       | 1132/4096 [00:02<00:06, 476.07it/s]
Adding requests:  29%|██▉       | 1184/4096 [00:02<00:05, 487.15it/s]
Adding requests:  30%|███       | 1235/4096 [00:02<00:05, 492.62it/s]
Adding requests:  31%|███▏      | 1285/4096 [00:02<00:05, 490.85it/s]
Adding requests:  33%|███▎      | 1337/4096 [00:02<00:05, 496.24it/s]
Adding requests:  34%|███▍      | 1387/4096 [00:02<00:05, 496.90it/s]
Adding requests:  35%|███▌      | 1437/4096 [00:02<00:05, 496.62it/s]
Adding requests:  36%|███▋      | 1488/4096 [00:03<00:05, 500.11it/s]
Adding requests:  38%|███▊      | 1540/4096 [00:03<00:05, 503.19it/s]
Adding requests:  39%|███▉      | 1592/4096 [00:03<00:04, 507.13it/s]
Adding requests:  40%|████      | 1644/4096 [00:03<00:04, 508.18it/s]
Adding requests:  41%|████▏     | 1695/4096 [00:03<00:04, 502.65it/s]
Adding requests:  43%|████▎     | 1746/4096 [00:03<00:04, 502.09it/s]
Adding requests:  44%|████▍     | 1797/4096 [00:03<00:04, 502.37it/s]
Adding requests:  45%|████▌     | 1848/4096 [00:03<00:04, 502.47it/s]
Adding requests:  46%|████▋     | 1899/4096 [00:03<00:04, 500.80it/s]
Adding requests:  48%|████▊     | 1950/4096 [00:03<00:04, 500.29it/s]
Adding requests:  49%|████▉     | 2001/4096 [00:04<00:04, 500.96it/s]
Adding requests:  50%|█████     | 2052/4096 [00:04<00:04, 502.37it/s]
Adding requests:  51%|█████▏    | 2103/4096 [00:04<00:03, 503.22it/s]
Adding requests:  53%|█████▎    | 2154/4096 [00:04<00:03, 497.06it/s]
Adding requests:  54%|█████▍    | 2204/4096 [00:04<00:03, 492.75it/s]
Adding requests:  55%|█████▌    | 2256/4096 [00:04<00:03, 499.35it/s]
Adding requests:  56%|█████▋    | 2306/4096 [00:04<00:03, 487.58it/s]
Adding requests:  58%|█████▊    | 2356/4096 [00:04<00:03, 489.12it/s]
Adding requests:  59%|█████▊    | 2406/4096 [00:04<00:03, 491.19it/s]
Adding requests:  60%|█████▉    | 2457/4096 [00:05<00:03, 495.80it/s]
Adding requests:  61%|██████    | 2507/4096 [00:05<00:03, 494.98it/s]
Adding requests:  62%|██████▏   | 2558/4096 [00:05<00:03, 499.12it/s]
Adding requests:  64%|██████▎   | 2608/4096 [00:05<00:02, 498.83it/s]
Adding requests:  65%|██████▍   | 2659/4096 [00:05<00:02, 502.09it/s]
Adding requests:  66%|██████▌   | 2710/4096 [00:05<00:02, 497.40it/s]
Adding requests:  67%|██████▋   | 2760/4096 [00:05<00:02, 497.22it/s]
Adding requests:  69%|██████▊   | 2810/4096 [00:05<00:02, 495.48it/s]
Adding requests:  70%|██████▉   | 2860/4096 [00:05<00:02, 494.39it/s]
Adding requests:  71%|███████   | 2911/4096 [00:05<00:02, 498.55it/s]
Adding requests:  72%|███████▏  | 2961/4096 [00:06<00:02, 492.41it/s]
Adding requests:  74%|███████▎  | 3012/4096 [00:06<00:02, 496.39it/s]
Adding requests:  75%|███████▍  | 3062/4096 [00:06<00:02, 495.40it/s]
Adding requests:  76%|███████▌  | 3113/4096 [00:06<00:01, 497.57it/s]
Adding requests:  77%|███████▋  | 3163/4096 [00:06<00:01, 497.91it/s]
Adding requests:  78%|███████▊  | 3213/4096 [00:06<00:01, 497.56it/s]
Adding requests:  80%|███████▉  | 3264/4096 [00:06<00:01, 500.88it/s]
Adding requests:  81%|████████  | 3315/4096 [00:06<00:01, 498.99it/s]
Adding requests:  82%|████████▏ | 3366/4096 [00:06<00:01, 501.26it/s]
Adding requests:  83%|████████▎ | 3417/4096 [00:06<00:01, 500.26it/s]
Adding requests:  85%|████████▍ | 3468/4096 [00:07<00:01, 495.32it/s]
Adding requests:  86%|████████▌ | 3518/4096 [00:07<00:01, 494.49it/s]
Adding requests:  87%|████████▋ | 3568/4096 [00:07<00:01, 491.74it/s]
Adding requests:  88%|████████▊ | 3619/4096 [00:07<00:00, 492.89it/s]
Adding requests:  90%|████████▉ | 3669/4096 [00:07<00:00, 480.85it/s]
Adding requests:  91%|█████████ | 3719/4096 [00:07<00:00, 485.49it/s]
Adding requests:  92%|█████████▏| 3770/4096 [00:07<00:00, 491.70it/s]
Adding requests:  93%|█████████▎| 3822/4096 [00:07<00:00, 497.13it/s]
Adding requests:  95%|█████████▍| 3874/4096 [00:07<00:00, 503.34it/s]
Adding requests:  96%|█████████▌| 3925/4096 [00:07<00:00, 501.59it/s]
Adding requests:  97%|█████████▋| 3976/4096 [00:08<00:00, 500.78it/s]
Adding requests:  98%|█████████▊| 4027/4096 [00:08<00:00, 498.77it/s]
Adding requests: 100%|█████████▉| 4077/4096 [00:08<00:00, 494.67it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 493.32it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 568/4096 [00:00<00:01, 2527.21it/s, est. speed input: 2588241.05 toks/s, output: 2527.29 toks/s]
Processed prompts:  20%|██        | 821/4096 [00:03<00:16, 201.61it/s, est. speed input: 255183.16 toks/s, output: 249.20 toks/s]   
Processed prompts:  23%|██▎       | 930/4096 [00:05<00:22, 141.21it/s, est. speed input: 189227.68 toks/s, output: 184.79 toks/s]
Processed prompts:  24%|██▍       | 993/4096 [00:05<00:24, 125.01it/s, est. speed input: 172369.73 toks/s, output: 168.33 toks/s]
Processed prompts:  25%|██▌       | 1034/4096 [00:06<00:25, 120.40it/s, est. speed input: 167059.59 toks/s, output: 163.14 toks/s]
Processed prompts:  26%|██▌       | 1064/4096 [00:06<00:27, 111.30it/s, est. speed input: 160716.09 toks/s, output: 156.95 toks/s]
Processed prompts:  27%|██▋       | 1086/4096 [00:07<00:30, 99.21it/s, est. speed input: 154067.01 toks/s, output: 150.46 toks/s] 
Processed prompts:  27%|██▋       | 1112/4096 [00:07<00:33, 90.32it/s, est. speed input: 148675.01 toks/s, output: 145.19 toks/s]
Processed prompts:  28%|██▊       | 1144/4096 [00:08<00:34, 86.63it/s, est. speed input: 144842.50 toks/s, output: 141.45 toks/s]
Processed prompts:  29%|██▊       | 1176/4096 [00:08<00:35, 83.23it/s, est. speed input: 141266.62 toks/s, output: 137.96 toks/s]
Processed prompts:  29%|██▉       | 1208/4096 [00:08<00:35, 80.35it/s, est. speed input: 137970.93 toks/s, output: 134.74 toks/s]
Processed prompts:  30%|███       | 1240/4096 [00:09<00:36, 78.27it/s, est. speed input: 135008.81 toks/s, output: 131.84 toks/s]
Processed prompts:  31%|███       | 1272/4096 [00:09<00:36, 76.73it/s, est. speed input: 132310.57 toks/s, output: 129.21 toks/s]
Processed prompts:  32%|███▏      | 1304/4096 [00:10<00:36, 75.72it/s, est. speed input: 129872.80 toks/s, output: 126.83 toks/s]
Processed prompts:  33%|███▎      | 1336/4096 [00:10<00:36, 74.99it/s, est. speed input: 127633.92 toks/s, output: 124.64 toks/s]
Processed prompts:  33%|███▎      | 1368/4096 [00:11<00:36, 74.49it/s, est. speed input: 125575.51 toks/s, output: 122.63 toks/s]
Processed prompts:  34%|███▍      | 1400/4096 [00:11<00:36, 73.98it/s, est. speed input: 123639.75 toks/s, output: 120.74 toks/s]
Processed prompts:  35%|███▍      | 1432/4096 [00:12<00:36, 73.71it/s, est. speed input: 121862.68 toks/s, output: 119.01 toks/s]
Processed prompts:  36%|███▌      | 1464/4096 [00:12<00:35, 73.45it/s, est. speed input: 120197.13 toks/s, output: 117.38 toks/s]
Processed prompts:  37%|███▋      | 1496/4096 [00:12<00:35, 73.46it/s, est. speed input: 118681.19 toks/s, output: 115.90 toks/s]
Processed prompts:  37%|███▋      | 1528/4096 [00:13<00:34, 73.41it/s, est. speed input: 117254.22 toks/s, output: 114.51 toks/s]
Processed prompts:  38%|███▊      | 1560/4096 [00:13<00:34, 73.38it/s, est. speed input: 115917.04 toks/s, output: 113.20 toks/s]
Processed prompts:  39%|███▉      | 1592/4096 [00:14<00:34, 73.28it/s, est. speed input: 114650.73 toks/s, output: 111.96 toks/s]
Processed prompts:  40%|███▉      | 1624/4096 [00:14<00:33, 73.19it/s, est. speed input: 113455.87 toks/s, output: 110.80 toks/s]
Processed prompts:  40%|████      | 1656/4096 [00:15<00:33, 73.18it/s, est. speed input: 112338.61 toks/s, output: 109.71 toks/s]
Processed prompts:  41%|████      | 1688/4096 [00:15<00:32, 73.07it/s, est. speed input: 111270.25 toks/s, output: 108.66 toks/s]
Processed prompts:  42%|████▏     | 1720/4096 [00:15<00:32, 72.98it/s, est. speed input: 110258.70 toks/s, output: 107.67 toks/s]
Processed prompts:  43%|████▎     | 1752/4096 [00:16<00:32, 73.08it/s, est. speed input: 109323.26 toks/s, output: 106.76 toks/s]
Processed prompts:  44%|████▎     | 1784/4096 [00:16<00:31, 72.85it/s, est. speed input: 108397.03 toks/s, output: 105.86 toks/s]
Processed prompts:  44%|████▍     | 1816/4096 [00:17<00:31, 72.91it/s, est. speed input: 107546.13 toks/s, output: 105.03 toks/s]
Processed prompts:  45%|████▌     | 1848/4096 [00:17<00:30, 72.95it/s, est. speed input: 106736.89 toks/s, output: 104.24 toks/s]
Processed prompts:  46%|████▌     | 1880/4096 [00:18<00:30, 73.65it/s, est. speed input: 106044.19 toks/s, output: 103.56 toks/s]
Processed prompts:  47%|████▋     | 1912/4096 [00:18<00:29, 73.49it/s, est. speed input: 105310.70 toks/s, output: 102.84 toks/s]
Processed prompts:  47%|████▋     | 1944/4096 [00:19<00:29, 73.96it/s, est. speed input: 104673.87 toks/s, output: 102.22 toks/s]
Processed prompts:  48%|████▊     | 1976/4096 [00:19<00:28, 73.65it/s, est. speed input: 103997.23 toks/s, output: 101.56 toks/s]
Processed prompts:  49%|████▉     | 2008/4096 [00:19<00:28, 73.40it/s, est. speed input: 103347.52 toks/s, output: 100.93 toks/s]
Processed prompts:  50%|████▉     | 2040/4096 [00:20<00:28, 73.14it/s, est. speed input: 102717.14 toks/s, output: 100.31 toks/s]
Processed prompts:  51%|█████     | 2072/4096 [00:20<00:27, 73.10it/s, est. speed input: 102126.70 toks/s, output: 99.73 toks/s] 
Processed prompts:  51%|█████▏    | 2104/4096 [00:21<00:27, 72.91it/s, est. speed input: 101546.35 toks/s, output: 99.17 toks/s]
Processed prompts:  52%|█████▏    | 2136/4096 [00:21<00:26, 72.89it/s, est. speed input: 100999.15 toks/s, output: 98.63 toks/s]
Processed prompts:  53%|█████▎    | 2168/4096 [00:22<00:26, 72.80it/s, est. speed input: 100467.49 toks/s, output: 98.11 toks/s]
Processed prompts:  54%|█████▎    | 2200/4096 [00:22<00:26, 72.75it/s, est. speed input: 99957.74 toks/s, output: 97.61 toks/s] 
Processed prompts:  54%|█████▍    | 2232/4096 [00:22<00:25, 73.99it/s, est. speed input: 99576.56 toks/s, output: 97.24 toks/s]
Processed prompts:  55%|█████▌    | 2264/4096 [00:23<00:24, 73.66it/s, est. speed input: 99109.19 toks/s, output: 96.79 toks/s]
Processed prompts:  56%|█████▌    | 2296/4096 [00:23<00:24, 74.09it/s, est. speed input: 98711.66 toks/s, output: 96.40 toks/s]
Processed prompts:  57%|█████▋    | 2328/4096 [00:24<00:23, 74.25it/s, est. speed input: 98317.36 toks/s, output: 96.01 toks/s]
Processed prompts:  58%|█████▊    | 2360/4096 [00:24<00:23, 73.92it/s, est. speed input: 97902.57 toks/s, output: 95.61 toks/s]
Processed prompts:  58%|█████▊    | 2392/4096 [00:25<00:23, 73.44it/s, est. speed input: 97483.04 toks/s, output: 95.20 toks/s]
Processed prompts:  59%|█████▉    | 2424/4096 [00:25<00:22, 73.35it/s, est. speed input: 97096.78 toks/s, output: 94.82 toks/s]
Processed prompts:  60%|█████▉    | 2456/4096 [00:26<00:22, 73.12it/s, est. speed input: 96710.94 toks/s, output: 94.44 toks/s]
Processed prompts:  61%|██████    | 2488/4096 [00:26<00:21, 73.64it/s, est. speed input: 96386.93 toks/s, output: 94.13 toks/s]
Processed prompts:  62%|██████▏   | 2520/4096 [00:26<00:21, 73.40it/s, est. speed input: 96030.74 toks/s, output: 93.78 toks/s]
Processed prompts:  62%|██████▏   | 2552/4096 [00:27<00:21, 73.16it/s, est. speed input: 95680.84 toks/s, output: 93.44 toks/s]
Processed prompts:  63%|██████▎   | 2584/4096 [00:27<00:20, 73.76it/s, est. speed input: 95394.43 toks/s, output: 93.16 toks/s]
Processed prompts:  64%|██████▍   | 2616/4096 [00:28<00:20, 73.30it/s, est. speed input: 95057.77 toks/s, output: 92.83 toks/s]
Processed prompts:  65%|██████▍   | 2648/4096 [00:28<00:19, 73.18it/s, est. speed input: 94744.91 toks/s, output: 92.52 toks/s]
Processed prompts:  65%|██████▌   | 2680/4096 [00:29<00:19, 72.96it/s, est. speed input: 94432.72 toks/s, output: 92.22 toks/s]
Processed prompts:  66%|██████▌   | 2712/4096 [00:29<00:18, 72.92it/s, est. speed input: 94136.75 toks/s, output: 91.93 toks/s]
Processed prompts:  67%|██████▋   | 2744/4096 [00:29<00:18, 72.79it/s, est. speed input: 93843.47 toks/s, output: 91.64 toks/s]
Processed prompts:  68%|██████▊   | 2776/4096 [00:30<00:18, 72.72it/s, est. speed input: 93559.70 toks/s, output: 91.37 toks/s]
Processed prompts:  69%|██████▊   | 2808/4096 [00:30<00:17, 72.70it/s, est. speed input: 93285.79 toks/s, output: 91.10 toks/s]
Processed prompts:  69%|██████▉   | 2840/4096 [00:31<00:17, 72.67it/s, est. speed input: 93018.90 toks/s, output: 90.84 toks/s]
Processed prompts:  70%|███████   | 2872/4096 [00:31<00:16, 72.61it/s, est. speed input: 92756.55 toks/s, output: 90.58 toks/s]
Processed prompts:  71%|███████   | 2904/4096 [00:32<00:16, 72.71it/s, est. speed input: 92510.26 toks/s, output: 90.34 toks/s]
Processed prompts:  72%|███████▏  | 2936/4096 [00:32<00:15, 72.68it/s, est. speed input: 92264.47 toks/s, output: 90.10 toks/s]
Processed prompts:  72%|███████▏  | 2968/4096 [00:33<00:15, 72.57it/s, est. speed input: 92020.73 toks/s, output: 89.86 toks/s]
Processed prompts:  73%|███████▎  | 3000/4096 [00:33<00:15, 72.72it/s, est. speed input: 91795.41 toks/s, output: 89.64 toks/s]
Processed prompts:  74%|███████▍  | 3032/4096 [00:33<00:14, 72.74it/s, est. speed input: 91571.65 toks/s, output: 89.43 toks/s]
Processed prompts:  75%|███████▍  | 3064/4096 [00:34<00:14, 72.66it/s, est. speed input: 91348.72 toks/s, output: 89.21 toks/s]
Processed prompts:  76%|███████▌  | 3096/4096 [00:34<00:13, 72.72it/s, est. speed input: 91137.41 toks/s, output: 89.00 toks/s]
Processed prompts:  76%|███████▋  | 3128/4096 [00:35<00:13, 73.24it/s, est. speed input: 90956.04 toks/s, output: 88.82 toks/s]
Processed prompts:  77%|███████▋  | 3160/4096 [00:35<00:12, 73.02it/s, est. speed input: 90749.08 toks/s, output: 88.62 toks/s]
Processed prompts:  78%|███████▊  | 3192/4096 [00:36<00:12, 72.87it/s, est. speed input: 90547.59 toks/s, output: 88.43 toks/s]
Processed prompts:  79%|███████▊  | 3224/4096 [00:36<00:11, 72.74it/s, est. speed input: 90349.94 toks/s, output: 88.23 toks/s]
Processed prompts:  79%|███████▉  | 3256/4096 [00:36<00:11, 72.63it/s, est. speed input: 90155.76 toks/s, output: 88.04 toks/s]
Processed prompts:  80%|████████  | 3288/4096 [00:37<00:11, 72.62it/s, est. speed input: 89969.16 toks/s, output: 87.86 toks/s]
Processed prompts:  81%|████████  | 3320/4096 [00:37<00:10, 72.55it/s, est. speed input: 89784.39 toks/s, output: 87.68 toks/s]
Processed prompts:  82%|████████▏ | 3352/4096 [00:38<00:10, 72.56it/s, est. speed input: 89606.54 toks/s, output: 87.51 toks/s]
Processed prompts:  83%|████████▎ | 3384/4096 [00:38<00:09, 72.50it/s, est. speed input: 89429.28 toks/s, output: 87.33 toks/s]
Processed prompts:  83%|████████▎ | 3416/4096 [00:39<00:09, 72.57it/s, est. speed input: 89261.45 toks/s, output: 87.17 toks/s]
Processed prompts:  84%|████████▍ | 3448/4096 [00:39<00:08, 72.63it/s, est. speed input: 89098.06 toks/s, output: 87.01 toks/s]
Processed prompts:  85%|████████▍ | 3480/4096 [00:40<00:08, 72.60it/s, est. speed input: 88934.58 toks/s, output: 86.85 toks/s]
Processed prompts:  86%|████████▌ | 3512/4096 [00:40<00:08, 72.62it/s, est. speed input: 88776.83 toks/s, output: 86.70 toks/s]
Processed prompts:  87%|████████▋ | 3544/4096 [00:40<00:07, 72.61it/s, est. speed input: 88621.06 toks/s, output: 86.54 toks/s]
Processed prompts:  87%|████████▋ | 3576/4096 [00:41<00:07, 72.64it/s, est. speed input: 88470.62 toks/s, output: 86.40 toks/s]
Processed prompts:  88%|████████▊ | 3608/4096 [00:41<00:06, 72.52it/s, est. speed input: 88316.93 toks/s, output: 86.25 toks/s]
Processed prompts:  89%|████████▉ | 3640/4096 [00:42<00:06, 72.50it/s, est. speed input: 88169.42 toks/s, output: 86.10 toks/s]
Processed prompts:  90%|████████▉ | 3672/4096 [00:42<00:05, 72.46it/s, est. speed input: 88023.68 toks/s, output: 85.96 toks/s]
Processed prompts:  90%|█████████ | 3704/4096 [00:43<00:05, 72.39it/s, est. speed input: 87879.31 toks/s, output: 85.82 toks/s]
Processed prompts:  91%|█████████ | 3736/4096 [00:43<00:04, 73.03it/s, est. speed input: 87766.07 toks/s, output: 85.71 toks/s]
Processed prompts:  92%|█████████▏| 3768/4096 [00:44<00:04, 72.87it/s, est. speed input: 87630.53 toks/s, output: 85.58 toks/s]
Processed prompts:  93%|█████████▎| 3800/4096 [00:44<00:04, 72.82it/s, est. speed input: 87499.99 toks/s, output: 85.45 toks/s]
Processed prompts:  94%|█████████▎| 3832/4096 [00:44<00:03, 72.70it/s, est. speed input: 87368.90 toks/s, output: 85.32 toks/s]
Processed prompts:  94%|█████████▍| 3864/4096 [00:45<00:03, 72.67it/s, est. speed input: 87242.25 toks/s, output: 85.20 toks/s]
Processed prompts:  95%|█████████▌| 3896/4096 [00:45<00:02, 72.47it/s, est. speed input: 87111.21 toks/s, output: 85.07 toks/s]
Processed prompts:  96%|█████████▌| 3928/4096 [00:46<00:02, 72.39it/s, est. speed input: 86984.81 toks/s, output: 84.95 toks/s]
Processed prompts:  97%|█████████▋| 3960/4096 [00:46<00:01, 72.33it/s, est. speed input: 86860.87 toks/s, output: 84.83 toks/s]
Processed prompts:  97%|█████████▋| 3992/4096 [00:47<00:01, 72.31it/s, est. speed input: 86740.15 toks/s, output: 84.71 toks/s]
Processed prompts:  98%|█████████▊| 4024/4096 [00:47<00:00, 73.02it/s, est. speed input: 86648.19 toks/s, output: 84.62 toks/s]
Processed prompts:  99%|█████████▉| 4056/4096 [00:47<00:00, 72.84it/s, est. speed input: 86533.32 toks/s, output: 84.51 toks/s]
Processed prompts: 100%|█████████▉| 4088/4096 [00:48<00:00, 92.43it/s, est. speed input: 86982.14 toks/s, output: 84.94 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:48<00:00, 92.43it/s, est. speed input: 87151.58 toks/s, output: 85.11 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:48<00:00, 85.11it/s, est. speed input: 87151.58 toks/s, output: 85.11 toks/s]
[rank0]:[W126 10:49:53.677624550 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:49:55
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:50:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1240432) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1240432) WARNING 01-26 10:50:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 72.59 requests/s, 74403.22 total tokens/s, 72.59 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:50:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:50:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:50:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:50:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:50:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:50:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:50:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:50:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:50:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:50:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:50:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:50:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:50:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:50:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1240432) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1240432) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
(EngineCore_DP0 pid=1240432) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
(EngineCore_DP0 pid=1240432) 
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15769600 bytes
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9461760 bytes
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50462720 bytes
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1240432) [2026-01-26 10:50:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25190400 bytes
(EngineCore_DP0 pid=1240432) [rank0]:W0126 10:50:58.282000 1240432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1240432) [rank0]:W0126 10:50:58.368000 1240432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1240432) [rank0]:W0126 10:50:59.306000 1240432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1240432) [rank0]:W0126 10:50:59.434000 1240432 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1240432) 2026-01-26 10:51:03,651 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1240432) 2026-01-26 10:51:03,697 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1240432) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:17,  1.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:09,  1.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:03,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  5.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  6.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  6.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:01,  4.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:01,  4.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:02<00:00,  5.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:03<00:00,  5.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:03<00:00,  7.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  9.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.64it/s]
(EngineCore_DP0 pid=1240432) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  6.19it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00, 11.33it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  9.93it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  5.35it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  5.08it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:01<00:00,  7.16it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.30it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 48/8192 [00:00<00:17, 477.31it/s]
Adding requests:   1%|          | 98/8192 [00:00<00:16, 486.25it/s]
Adding requests:   2%|▏         | 147/8192 [00:00<00:16, 485.57it/s]
Adding requests:   2%|▏         | 196/8192 [00:00<00:16, 482.98it/s]
Adding requests:   3%|▎         | 245/8192 [00:00<00:16, 485.00it/s]
Adding requests:   4%|▎         | 294/8192 [00:00<00:16, 485.87it/s]
Adding requests:   4%|▍         | 343/8192 [00:00<00:16, 483.51it/s]
Adding requests:   5%|▍         | 394/8192 [00:00<00:15, 490.77it/s]
Adding requests:   5%|▌         | 444/8192 [00:00<00:15, 489.48it/s]
Adding requests:   6%|▌         | 494/8192 [00:01<00:15, 491.71it/s]
Adding requests:   7%|▋         | 544/8192 [00:01<00:15, 483.10it/s]
Adding requests:   7%|▋         | 596/8192 [00:01<00:15, 490.16it/s]
Adding requests:   8%|▊         | 646/8192 [00:01<00:15, 485.08it/s]
Adding requests:   9%|▊         | 698/8192 [00:01<00:15, 494.32it/s]
Adding requests:   9%|▉         | 748/8192 [00:01<00:15, 493.76it/s]
Adding requests:  10%|▉         | 798/8192 [00:01<00:15, 492.77it/s]
Adding requests:  10%|█         | 848/8192 [00:01<00:15, 486.47it/s]
Adding requests:  11%|█         | 900/8192 [00:01<00:14, 493.91it/s]
Adding requests:  12%|█▏        | 950/8192 [00:01<00:14, 495.22it/s]
Adding requests:  12%|█▏        | 1001/8192 [00:02<00:14, 497.32it/s]
Adding requests:  13%|█▎        | 1052/8192 [00:02<00:14, 500.32it/s]
Adding requests:  13%|█▎        | 1103/8192 [00:02<00:14, 496.33it/s]
Adding requests:  14%|█▍        | 1153/8192 [00:02<00:14, 493.34it/s]
Adding requests:  15%|█▍        | 1207/8192 [00:02<00:13, 504.53it/s]
Adding requests:  15%|█▌        | 1258/8192 [00:02<00:13, 499.20it/s]
Adding requests:  16%|█▌        | 1309/8192 [00:02<00:13, 499.56it/s]
Adding requests:  17%|█▋        | 1360/8192 [00:02<00:13, 502.38it/s]
Adding requests:  17%|█▋        | 1413/8192 [00:02<00:13, 508.10it/s]
Adding requests:  18%|█▊        | 1464/8192 [00:02<00:13, 507.74it/s]
Adding requests:  18%|█▊        | 1515/8192 [00:03<00:13, 507.51it/s]
Adding requests:  19%|█▉        | 1567/8192 [00:03<00:13, 508.41it/s]
Adding requests:  20%|█▉        | 1619/8192 [00:03<00:12, 511.13it/s]
Adding requests:  20%|██        | 1671/8192 [00:03<00:12, 508.06it/s]
Adding requests:  21%|██        | 1723/8192 [00:03<00:12, 511.35it/s]
Adding requests:  22%|██▏       | 1775/8192 [00:03<00:13, 491.70it/s]
Adding requests:  22%|██▏       | 1826/8192 [00:03<00:12, 496.86it/s]
Adding requests:  23%|██▎       | 1877/8192 [00:03<00:12, 499.20it/s]
Adding requests:  24%|██▎       | 1928/8192 [00:03<00:12, 500.58it/s]
Adding requests:  24%|██▍       | 1979/8192 [00:03<00:12, 502.22it/s]
Adding requests:  25%|██▍       | 2032/8192 [00:04<00:12, 507.73it/s]
Adding requests:  25%|██▌       | 2084/8192 [00:04<00:12, 508.94it/s]
Adding requests:  26%|██▌       | 2135/8192 [00:04<00:12, 504.62it/s]
Adding requests:  27%|██▋       | 2186/8192 [00:04<00:12, 498.89it/s]
Adding requests:  27%|██▋       | 2238/8192 [00:04<00:11, 505.08it/s]
Adding requests:  28%|██▊       | 2289/8192 [00:04<00:11, 502.13it/s]
Adding requests:  29%|██▊       | 2340/8192 [00:04<00:11, 503.36it/s]
Adding requests:  29%|██▉       | 2391/8192 [00:04<00:11, 505.06it/s]
Adding requests:  30%|██▉       | 2442/8192 [00:04<00:11, 504.95it/s]
Adding requests:  30%|███       | 2493/8192 [00:05<00:11, 504.68it/s]
Adding requests:  31%|███       | 2544/8192 [00:05<00:11, 499.42it/s]
Adding requests:  32%|███▏      | 2596/8192 [00:05<00:11, 503.57it/s]
Adding requests:  32%|███▏      | 2647/8192 [00:05<00:10, 504.87it/s]
Adding requests:  33%|███▎      | 2698/8192 [00:05<00:10, 502.81it/s]
Adding requests:  34%|███▎      | 2749/8192 [00:05<00:10, 501.63it/s]
Adding requests:  34%|███▍      | 2800/8192 [00:05<00:10, 500.03it/s]
Adding requests:  35%|███▍      | 2851/8192 [00:05<00:10, 501.97it/s]
Adding requests:  35%|███▌      | 2902/8192 [00:05<00:10, 503.73it/s]
Adding requests:  36%|███▌      | 2953/8192 [00:05<00:10, 499.06it/s]
Adding requests:  37%|███▋      | 3004/8192 [00:06<00:10, 499.75it/s]
Adding requests:  37%|███▋      | 3055/8192 [00:06<00:10, 502.23it/s]
Adding requests:  38%|███▊      | 3106/8192 [00:06<00:10, 480.72it/s]
Adding requests:  39%|███▊      | 3157/8192 [00:06<00:10, 487.41it/s]
Adding requests:  39%|███▉      | 3208/8192 [00:06<00:10, 492.02it/s]
Adding requests:  40%|███▉      | 3260/8192 [00:06<00:09, 498.90it/s]
Adding requests:  40%|████      | 3311/8192 [00:06<00:09, 502.09it/s]
Adding requests:  41%|████      | 3363/8192 [00:06<00:09, 507.00it/s]
Adding requests:  42%|████▏     | 3414/8192 [00:06<00:09, 507.72it/s]
Adding requests:  42%|████▏     | 3465/8192 [00:06<00:09, 502.52it/s]
Adding requests:  43%|████▎     | 3516/8192 [00:07<00:09, 503.52it/s]
Adding requests:  44%|████▎     | 3567/8192 [00:07<00:09, 500.83it/s]
Adding requests:  44%|████▍     | 3618/8192 [00:07<00:09, 503.39it/s]
Adding requests:  45%|████▍     | 3669/8192 [00:07<00:09, 500.44it/s]
Adding requests:  45%|████▌     | 3720/8192 [00:07<00:08, 500.60it/s]
Adding requests:  46%|████▌     | 3772/8192 [00:07<00:08, 505.66it/s]
Adding requests:  47%|████▋     | 3824/8192 [00:07<00:08, 508.85it/s]
Adding requests:  47%|████▋     | 3876/8192 [00:07<00:08, 511.66it/s]
Adding requests:  48%|████▊     | 3928/8192 [00:07<00:08, 509.76it/s]
Adding requests:  49%|████▊     | 3979/8192 [00:07<00:08, 508.33it/s]
Adding requests:  49%|████▉     | 4030/8192 [00:08<00:08, 505.13it/s]
Adding requests:  50%|████▉     | 4081/8192 [00:08<00:08, 502.29it/s]
Adding requests:  50%|█████     | 4134/8192 [00:08<00:07, 507.88it/s]
Adding requests:  51%|█████     | 4186/8192 [00:08<00:07, 509.36it/s]
Adding requests:  52%|█████▏    | 4237/8192 [00:08<00:07, 508.39it/s]
Adding requests:  52%|█████▏    | 4288/8192 [00:08<00:07, 506.64it/s]
Adding requests:  53%|█████▎    | 4339/8192 [00:08<00:07, 502.26it/s]
Adding requests:  54%|█████▎    | 4392/8192 [00:08<00:07, 508.95it/s]
Adding requests:  54%|█████▍    | 4443/8192 [00:08<00:07, 490.59it/s]
Adding requests:  55%|█████▍    | 4493/8192 [00:08<00:07, 491.67it/s]
Adding requests:  55%|█████▌    | 4544/8192 [00:09<00:07, 494.97it/s]
Adding requests:  56%|█████▌    | 4596/8192 [00:09<00:07, 500.52it/s]
Adding requests:  57%|█████▋    | 4648/8192 [00:09<00:07, 506.12it/s]
Adding requests:  57%|█████▋    | 4699/8192 [00:09<00:06, 500.92it/s]
Adding requests:  58%|█████▊    | 4751/8192 [00:09<00:06, 504.91it/s]
Adding requests:  59%|█████▊    | 4802/8192 [00:09<00:06, 505.08it/s]
Adding requests:  59%|█████▉    | 4853/8192 [00:09<00:06, 505.75it/s]
Adding requests:  60%|█████▉    | 4904/8192 [00:09<00:06, 501.18it/s]
Adding requests:  60%|██████    | 4956/8192 [00:09<00:06, 506.18it/s]
Adding requests:  61%|██████    | 5007/8192 [00:10<00:06, 505.71it/s]
Adding requests:  62%|██████▏   | 5059/8192 [00:10<00:06, 508.96it/s]
Adding requests:  62%|██████▏   | 5112/8192 [00:10<00:05, 514.06it/s]
Adding requests:  63%|██████▎   | 5164/8192 [00:10<00:05, 512.55it/s]
Adding requests:  64%|██████▎   | 5216/8192 [00:10<00:05, 509.91it/s]
Adding requests:  64%|██████▍   | 5268/8192 [00:10<00:05, 505.99it/s]
Adding requests:  65%|██████▍   | 5320/8192 [00:10<00:05, 509.04it/s]
Adding requests:  66%|██████▌   | 5372/8192 [00:10<00:05, 509.64it/s]
Adding requests:  66%|██████▌   | 5424/8192 [00:10<00:05, 510.24it/s]
Adding requests:  67%|██████▋   | 5476/8192 [00:10<00:05, 507.20it/s]
Adding requests:  67%|██████▋   | 5527/8192 [00:11<00:05, 503.82it/s]
Adding requests:  68%|██████▊   | 5578/8192 [00:11<00:05, 503.67it/s]
Adding requests:  69%|██████▊   | 5629/8192 [00:11<00:05, 501.45it/s]
Adding requests:  69%|██████▉   | 5680/8192 [00:11<00:05, 500.29it/s]
Adding requests:  70%|██████▉   | 5732/8192 [00:11<00:04, 503.36it/s]
Adding requests:  71%|███████   | 5783/8192 [00:11<00:04, 487.16it/s]
Adding requests:  71%|███████   | 5833/8192 [00:11<00:04, 488.34it/s]
Adding requests:  72%|███████▏  | 5885/8192 [00:11<00:04, 497.28it/s]
Adding requests:  72%|███████▏  | 5937/8192 [00:11<00:04, 501.47it/s]
Adding requests:  73%|███████▎  | 5989/8192 [00:11<00:04, 505.33it/s]
Adding requests:  74%|███████▎  | 6041/8192 [00:12<00:04, 509.27it/s]
Adding requests:  74%|███████▍  | 6092/8192 [00:12<00:04, 506.48it/s]
Adding requests:  75%|███████▌  | 6144/8192 [00:12<00:04, 507.41it/s]
Adding requests:  76%|███████▌  | 6196/8192 [00:12<00:03, 509.86it/s]
Adding requests:  76%|███████▋  | 6249/8192 [00:12<00:03, 514.74it/s]
Adding requests:  77%|███████▋  | 6302/8192 [00:12<00:03, 517.12it/s]
Adding requests:  78%|███████▊  | 6355/8192 [00:12<00:03, 518.48it/s]
Adding requests:  78%|███████▊  | 6407/8192 [00:12<00:03, 517.77it/s]
Adding requests:  79%|███████▉  | 6460/8192 [00:12<00:03, 519.90it/s]
Adding requests:  80%|███████▉  | 6514/8192 [00:12<00:03, 523.88it/s]
Adding requests:  80%|████████  | 6567/8192 [00:13<00:03, 518.73it/s]
Adding requests:  81%|████████  | 6619/8192 [00:13<00:03, 515.48it/s]
Adding requests:  81%|████████▏ | 6671/8192 [00:13<00:02, 512.87it/s]
Adding requests:  82%|████████▏ | 6723/8192 [00:13<00:02, 514.34it/s]
Adding requests:  83%|████████▎ | 6775/8192 [00:13<00:02, 512.67it/s]
Adding requests:  83%|████████▎ | 6827/8192 [00:13<00:02, 514.46it/s]
Adding requests:  84%|████████▍ | 6880/8192 [00:13<00:02, 517.68it/s]
Adding requests:  85%|████████▍ | 6934/8192 [00:13<00:02, 521.64it/s]
Adding requests:  85%|████████▌ | 6987/8192 [00:13<00:02, 516.71it/s]
Adding requests:  86%|████████▌ | 7039/8192 [00:13<00:02, 512.57it/s]
Adding requests:  87%|████████▋ | 7091/8192 [00:14<00:02, 512.72it/s]
Adding requests:  87%|████████▋ | 7143/8192 [00:14<00:02, 493.74it/s]
Adding requests:  88%|████████▊ | 7194/8192 [00:14<00:02, 497.71it/s]
Adding requests:  88%|████████▊ | 7246/8192 [00:14<00:01, 501.96it/s]
Adding requests:  89%|████████▉ | 7299/8192 [00:14<00:01, 507.96it/s]
Adding requests:  90%|████████▉ | 7350/8192 [00:14<00:01, 506.72it/s]
Adding requests:  90%|█████████ | 7403/8192 [00:14<00:01, 512.09it/s]
Adding requests:  91%|█████████ | 7457/8192 [00:14<00:01, 519.01it/s]
Adding requests:  92%|█████████▏| 7509/8192 [00:14<00:01, 517.49it/s]
Adding requests:  92%|█████████▏| 7561/8192 [00:15<00:01, 515.26it/s]
Adding requests:  93%|█████████▎| 7613/8192 [00:15<00:01, 510.49it/s]
Adding requests:  94%|█████████▎| 7667/8192 [00:15<00:01, 516.50it/s]
Adding requests:  94%|█████████▍| 7719/8192 [00:15<00:00, 515.71it/s]
Adding requests:  95%|█████████▍| 7771/8192 [00:15<00:00, 511.92it/s]
Adding requests:  95%|█████████▌| 7823/8192 [00:15<00:00, 509.31it/s]
Adding requests:  96%|█████████▌| 7874/8192 [00:15<00:00, 509.03it/s]
Adding requests:  97%|█████████▋| 7925/8192 [00:15<00:00, 507.74it/s]
Adding requests:  97%|█████████▋| 7976/8192 [00:15<00:00, 505.84it/s]
Adding requests:  98%|█████████▊| 8027/8192 [00:15<00:00, 500.54it/s]
Adding requests:  99%|█████████▊| 8080/8192 [00:16<00:00, 508.32it/s]
Adding requests:  99%|█████████▉| 8132/8192 [00:16<00:00, 510.03it/s]
Adding requests: 100%|█████████▉| 8185/8192 [00:16<00:00, 513.46it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 503.96it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 1128/8192 [00:00<00:00, 9878.22it/s, est. speed input: 10117370.52 toks/s, output: 9878.84 toks/s]
Processed prompts:  26%|██▌       | 2116/8192 [00:13<00:45, 134.76it/s, est. speed input: 163844.15 toks/s, output: 160.00 toks/s]    
Processed prompts:  26%|██▋       | 2152/8192 [00:14<00:47, 126.60it/s, est. speed input: 156233.74 toks/s, output: 152.57 toks/s]
Processed prompts:  31%|███▏      | 2562/8192 [00:19<00:52, 106.44it/s, est. speed input: 135948.18 toks/s, output: 132.76 toks/s]
Processed prompts:  34%|███▍      | 2788/8192 [00:21<00:53, 101.54it/s, est. speed input: 130137.82 toks/s, output: 127.09 toks/s]
Processed prompts:  36%|███▌      | 2929/8192 [00:24<00:58, 89.44it/s, est. speed input: 122031.53 toks/s, output: 119.17 toks/s] 
Processed prompts:  37%|███▋      | 3021/8192 [00:25<00:56, 91.04it/s, est. speed input: 121508.38 toks/s, output: 118.66 toks/s]
Processed prompts:  38%|███▊      | 3085/8192 [00:26<00:57, 88.62it/s, est. speed input: 119939.26 toks/s, output: 117.13 toks/s]
Processed prompts:  38%|███▊      | 3131/8192 [00:27<01:00, 83.01it/s, est. speed input: 117843.00 toks/s, output: 115.08 toks/s]
Processed prompts:  39%|███▉      | 3176/8192 [00:28<01:05, 77.10it/s, est. speed input: 115791.04 toks/s, output: 113.08 toks/s]
Processed prompts:  40%|███▉      | 3240/8192 [00:28<01:05, 76.17it/s, est. speed input: 114533.64 toks/s, output: 111.85 toks/s]
Processed prompts:  40%|████      | 3304/8192 [00:29<01:04, 75.33it/s, est. speed input: 113343.46 toks/s, output: 110.69 toks/s]
Processed prompts:  41%|████      | 3368/8192 [00:30<01:04, 74.67it/s, est. speed input: 112226.98 toks/s, output: 109.60 toks/s]
Processed prompts:  42%|████▏     | 3432/8192 [00:31<01:04, 74.10it/s, est. speed input: 111166.88 toks/s, output: 108.56 toks/s]
Processed prompts:  43%|████▎     | 3496/8192 [00:32<01:03, 73.66it/s, est. speed input: 110162.30 toks/s, output: 107.58 toks/s]
Processed prompts:  43%|████▎     | 3560/8192 [00:33<01:03, 73.31it/s, est. speed input: 109209.51 toks/s, output: 106.65 toks/s]
Processed prompts:  44%|████▍     | 3624/8192 [00:34<01:02, 73.03it/s, est. speed input: 108301.86 toks/s, output: 105.76 toks/s]
Processed prompts:  45%|████▌     | 3688/8192 [00:35<01:01, 73.19it/s, est. speed input: 107485.54 toks/s, output: 104.97 toks/s]
Processed prompts:  46%|████▌     | 3752/8192 [00:36<01:00, 72.93it/s, est. speed input: 106664.57 toks/s, output: 104.16 toks/s]
Processed prompts:  47%|████▋     | 3816/8192 [00:36<01:00, 72.75it/s, est. speed input: 105881.84 toks/s, output: 103.40 toks/s]
Processed prompts:  47%|████▋     | 3880/8192 [00:37<00:59, 72.67it/s, est. speed input: 105142.19 toks/s, output: 102.68 toks/s]
Processed prompts:  48%|████▊     | 3944/8192 [00:38<00:58, 72.61it/s, est. speed input: 104435.55 toks/s, output: 101.99 toks/s]
Processed prompts:  49%|████▉     | 4008/8192 [00:39<00:57, 72.84it/s, est. speed input: 103790.36 toks/s, output: 101.36 toks/s]
Processed prompts:  50%|████▉     | 4072/8192 [00:40<00:56, 72.66it/s, est. speed input: 103136.98 toks/s, output: 100.72 toks/s]
Processed prompts:  50%|█████     | 4136/8192 [00:41<00:55, 72.57it/s, est. speed input: 102515.27 toks/s, output: 100.11 toks/s]
Processed prompts:  51%|█████▏    | 4200/8192 [00:42<00:54, 72.87it/s, est. speed input: 101955.09 toks/s, output: 99.57 toks/s] 
Processed prompts:  52%|█████▏    | 4264/8192 [00:43<00:53, 72.99it/s, est. speed input: 101409.06 toks/s, output: 99.03 toks/s]
Processed prompts:  53%|█████▎    | 4328/8192 [00:43<00:52, 73.10it/s, est. speed input: 100886.81 toks/s, output: 98.52 toks/s]
Processed prompts:  54%|█████▎    | 4392/8192 [00:44<00:52, 72.83it/s, est. speed input: 100353.83 toks/s, output: 98.00 toks/s]
Processed prompts:  54%|█████▍    | 4456/8192 [00:45<00:51, 72.67it/s, est. speed input: 99844.00 toks/s, output: 97.50 toks/s] 
Processed prompts:  55%|█████▌    | 4520/8192 [00:46<00:50, 72.47it/s, est. speed input: 99345.84 toks/s, output: 97.02 toks/s]
Processed prompts:  56%|█████▌    | 4584/8192 [00:47<00:49, 72.39it/s, est. speed input: 98871.89 toks/s, output: 96.55 toks/s]
Processed prompts:  57%|█████▋    | 4648/8192 [00:48<00:48, 72.34it/s, est. speed input: 98415.37 toks/s, output: 96.11 toks/s]
Processed prompts:  58%|█████▊    | 4712/8192 [00:49<00:48, 72.26it/s, est. speed input: 97971.73 toks/s, output: 95.68 toks/s]
Processed prompts:  58%|█████▊    | 4776/8192 [00:50<00:47, 72.61it/s, est. speed input: 97575.72 toks/s, output: 95.29 toks/s]
Processed prompts:  59%|█████▉    | 4840/8192 [00:50<00:46, 72.75it/s, est. speed input: 97185.41 toks/s, output: 94.91 toks/s]
Processed prompts:  60%|█████▉    | 4904/8192 [00:51<00:45, 72.51it/s, est. speed input: 96782.38 toks/s, output: 94.51 toks/s]
Processed prompts:  61%|██████    | 4968/8192 [00:52<00:44, 72.74it/s, est. speed input: 96422.21 toks/s, output: 94.16 toks/s]
Processed prompts:  61%|██████▏   | 5032/8192 [00:53<00:43, 72.50it/s, est. speed input: 96045.05 toks/s, output: 93.79 toks/s]
Processed prompts:  62%|██████▏   | 5096/8192 [00:54<00:42, 72.41it/s, est. speed input: 95685.68 toks/s, output: 93.44 toks/s]
Processed prompts:  63%|██████▎   | 5160/8192 [00:55<00:41, 72.43it/s, est. speed input: 95343.66 toks/s, output: 93.11 toks/s]
Processed prompts:  64%|██████▍   | 5224/8192 [00:56<00:41, 72.28it/s, est. speed input: 95001.07 toks/s, output: 92.77 toks/s]
Processed prompts:  65%|██████▍   | 5288/8192 [00:57<00:40, 72.25it/s, est. speed input: 94674.21 toks/s, output: 92.46 toks/s]
Processed prompts:  65%|██████▌   | 5352/8192 [00:58<00:39, 72.25it/s, est. speed input: 94358.74 toks/s, output: 92.15 toks/s]
Processed prompts:  66%|██████▌   | 5416/8192 [00:58<00:38, 72.16it/s, est. speed input: 94046.91 toks/s, output: 91.84 toks/s]
Processed prompts:  67%|██████▋   | 5480/8192 [00:59<00:37, 72.11it/s, est. speed input: 93744.91 toks/s, output: 91.55 toks/s]
Processed prompts:  68%|██████▊   | 5544/8192 [01:00<00:36, 72.46it/s, est. speed input: 93475.81 toks/s, output: 91.28 toks/s]
Processed prompts:  68%|██████▊   | 5608/8192 [01:01<00:35, 72.37it/s, est. speed input: 93194.06 toks/s, output: 91.01 toks/s]
Processed prompts:  69%|██████▉   | 5672/8192 [01:02<00:34, 72.25it/s, est. speed input: 92916.75 toks/s, output: 90.74 toks/s]
Processed prompts:  70%|███████   | 5736/8192 [01:03<00:34, 72.21it/s, est. speed input: 92649.80 toks/s, output: 90.48 toks/s]
Processed prompts:  71%|███████   | 5800/8192 [01:04<00:33, 72.16it/s, est. speed input: 92388.82 toks/s, output: 90.22 toks/s]
Processed prompts:  72%|███████▏  | 5864/8192 [01:05<00:32, 72.11it/s, est. speed input: 92134.50 toks/s, output: 89.98 toks/s]
Processed prompts:  72%|███████▏  | 5928/8192 [01:06<00:31, 72.09it/s, est. speed input: 91887.44 toks/s, output: 89.73 toks/s]
Processed prompts:  73%|███████▎  | 5992/8192 [01:06<00:30, 72.06it/s, est. speed input: 91646.44 toks/s, output: 89.50 toks/s]
Processed prompts:  74%|███████▍  | 6056/8192 [01:07<00:29, 72.06it/s, est. speed input: 91412.60 toks/s, output: 89.27 toks/s]
Processed prompts:  75%|███████▍  | 6120/8192 [01:08<00:28, 72.06it/s, est. speed input: 91184.91 toks/s, output: 89.05 toks/s]
Processed prompts:  75%|███████▌  | 6184/8192 [01:09<00:27, 72.03it/s, est. speed input: 90961.52 toks/s, output: 88.83 toks/s]
Processed prompts:  76%|███████▋  | 6248/8192 [01:10<00:26, 72.03it/s, est. speed input: 90744.46 toks/s, output: 88.62 toks/s]
Processed prompts:  77%|███████▋  | 6312/8192 [01:11<00:26, 71.99it/s, est. speed input: 90531.15 toks/s, output: 88.41 toks/s]
Processed prompts:  78%|███████▊  | 6376/8192 [01:12<00:25, 71.97it/s, est. speed input: 90323.35 toks/s, output: 88.21 toks/s]
Processed prompts:  79%|███████▊  | 6440/8192 [01:13<00:24, 71.97it/s, est. speed input: 90121.49 toks/s, output: 88.01 toks/s]
Processed prompts:  79%|███████▉  | 6504/8192 [01:14<00:23, 72.04it/s, est. speed input: 89927.78 toks/s, output: 87.82 toks/s]
Processed prompts:  80%|████████  | 6568/8192 [01:14<00:22, 72.37it/s, est. speed input: 89752.14 toks/s, output: 87.65 toks/s]
Processed prompts:  81%|████████  | 6632/8192 [01:15<00:21, 72.56it/s, est. speed input: 89579.09 toks/s, output: 87.48 toks/s]
Processed prompts:  82%|████████▏ | 6696/8192 [01:16<00:20, 72.35it/s, est. speed input: 89393.19 toks/s, output: 87.30 toks/s]
Processed prompts:  83%|████████▎ | 6760/8192 [01:17<00:19, 72.19it/s, est. speed input: 89211.40 toks/s, output: 87.12 toks/s]
Processed prompts:  83%|████████▎ | 6824/8192 [01:18<00:18, 72.11it/s, est. speed input: 89034.80 toks/s, output: 86.95 toks/s]
Processed prompts:  84%|████████▍ | 6888/8192 [01:19<00:18, 72.03it/s, est. speed input: 88861.47 toks/s, output: 86.78 toks/s]
Processed prompts:  85%|████████▍ | 6952/8192 [01:20<00:17, 72.00it/s, est. speed input: 88692.60 toks/s, output: 86.61 toks/s]
Processed prompts:  86%|████████▌ | 7016/8192 [01:21<00:16, 72.00it/s, est. speed input: 88528.70 toks/s, output: 86.45 toks/s]
Processed prompts:  86%|████████▋ | 7080/8192 [01:22<00:15, 71.95it/s, est. speed input: 88366.28 toks/s, output: 86.30 toks/s]
Processed prompts:  87%|████████▋ | 7144/8192 [01:22<00:14, 72.25it/s, est. speed input: 88221.85 toks/s, output: 86.15 toks/s]
Processed prompts:  88%|████████▊ | 7208/8192 [01:23<00:13, 72.07it/s, est. speed input: 88063.40 toks/s, output: 86.00 toks/s]
Processed prompts:  89%|████████▉ | 7272/8192 [01:24<00:12, 72.29it/s, est. speed input: 87923.17 toks/s, output: 85.86 toks/s]
Processed prompts:  90%|████████▉ | 7336/8192 [01:25<00:11, 72.14it/s, est. speed input: 87773.22 toks/s, output: 85.72 toks/s]
Processed prompts:  90%|█████████ | 7400/8192 [01:26<00:10, 72.39it/s, est. speed input: 87641.10 toks/s, output: 85.59 toks/s]
Processed prompts:  91%|█████████ | 7464/8192 [01:27<00:10, 72.22it/s, est. speed input: 87497.36 toks/s, output: 85.45 toks/s]
Processed prompts:  92%|█████████▏| 7528/8192 [01:28<00:09, 72.08it/s, est. speed input: 87355.68 toks/s, output: 85.31 toks/s]
Processed prompts:  93%|█████████▎| 7592/8192 [01:29<00:08, 71.98it/s, est. speed input: 87216.74 toks/s, output: 85.17 toks/s]
Processed prompts:  93%|█████████▎| 7656/8192 [01:30<00:07, 71.92it/s, est. speed input: 87080.91 toks/s, output: 85.04 toks/s]
Processed prompts:  94%|█████████▍| 7720/8192 [01:30<00:06, 71.88it/s, est. speed input: 86947.94 toks/s, output: 84.91 toks/s]
Processed prompts:  95%|█████████▌| 7784/8192 [01:31<00:05, 71.84it/s, est. speed input: 86816.69 toks/s, output: 84.78 toks/s]
Processed prompts:  96%|█████████▌| 7848/8192 [01:32<00:04, 71.81it/s, est. speed input: 86688.27 toks/s, output: 84.66 toks/s]
Processed prompts:  97%|█████████▋| 7912/8192 [01:33<00:03, 71.78it/s, est. speed input: 86562.00 toks/s, output: 84.53 toks/s]
Processed prompts:  97%|█████████▋| 7976/8192 [01:34<00:03, 71.73it/s, est. speed input: 86436.75 toks/s, output: 84.41 toks/s]
Processed prompts:  98%|█████████▊| 8040/8192 [01:35<00:02, 71.73it/s, est. speed input: 86315.31 toks/s, output: 84.29 toks/s]
Processed prompts:  99%|█████████▉| 8104/8192 [01:36<00:01, 72.18it/s, est. speed input: 86212.78 toks/s, output: 84.19 toks/s]
Processed prompts: 100%|█████████▉| 8168/8192 [01:36<00:00, 88.64it/s, est. speed input: 86589.64 toks/s, output: 84.56 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:36<00:00, 88.64it/s, est. speed input: 86843.26 toks/s, output: 84.81 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:36<00:00, 84.81it/s, est. speed input: 86843.26 toks/s, output: 84.81 toks/s]
[rank0]:[W126 10:53:03.587540125 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 12:23:03
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:23:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1352824) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1352824) WARNING 01-26 12:23:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.10 requests/s, 19032.15 total tokens/s, 37.10 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 12:23:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:23:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:23:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:23:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:23:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:23:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:23:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:23:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:23:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:23:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:23:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:23:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1352824) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1352824) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1352824) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1352824) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1352824) 
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1352824) [2026-01-26 12:23:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1352824) 2026-01-26 12:23:40,518 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1352824) 2026-01-26 12:23:40,565 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1352824) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
(EngineCore_DP0 pid=1352824) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.60it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.58it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  29%|██▉       | 37/128 [00:00<00:00, 364.48it/s]
Adding requests:  84%|████████▍ | 108/128 [00:00<00:00, 565.51it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 556.25it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:20,  6.19it/s, est. speed input: 3170.75 toks/s, output: 6.19 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 24.30it/s, est. speed input: 10856.88 toks/s, output: 21.20 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 31.55it/s, est. speed input: 13949.75 toks/s, output: 27.24 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 35.33it/s, est. speed input: 15636.00 toks/s, output: 30.54 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 37.47it/s, est. speed input: 16681.35 toks/s, output: 32.58 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 38.83it/s, est. speed input: 17404.01 toks/s, output: 33.99 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 39.69it/s, est. speed input: 17926.39 toks/s, output: 35.01 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 40.29it/s, est. speed input: 18330.27 toks/s, output: 35.80 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 40.70it/s, est. speed input: 18647.02 toks/s, output: 36.42 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 40.95it/s, est. speed input: 18899.66 toks/s, output: 36.91 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 41.01it/s, est. speed input: 19091.97 toks/s, output: 37.29 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 41.15it/s, est. speed input: 19265.37 toks/s, output: 37.63 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 41.31it/s, est. speed input: 19419.93 toks/s, output: 37.93 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 41.39it/s, est. speed input: 19550.32 toks/s, output: 38.18 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 41.44it/s, est. speed input: 19662.18 toks/s, output: 38.40 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:01<00:01, 41.51it/s, est. speed input: 19764.82 toks/s, output: 38.60 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 41.53it/s, est. speed input: 19852.50 toks/s, output: 38.77 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 41.57it/s, est. speed input: 19932.42 toks/s, output: 38.93 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 41.55it/s, est. speed input: 20000.53 toks/s, output: 39.06 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 41.55it/s, est. speed input: 20063.40 toks/s, output: 39.19 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 41.60it/s, est. speed input: 20123.59 toks/s, output: 39.30 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 41.65it/s, est. speed input: 20179.56 toks/s, output: 39.41 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:02<00:00, 41.68it/s, est. speed input: 20230.97 toks/s, output: 39.51 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:02<00:00, 41.57it/s, est. speed input: 20269.11 toks/s, output: 39.59 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 41.58it/s, est. speed input: 20309.67 toks/s, output: 39.67 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 41.61it/s, est. speed input: 20348.36 toks/s, output: 39.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 41.61it/s, est. speed input: 20363.99 toks/s, output: 39.77 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.77it/s, est. speed input: 20363.99 toks/s, output: 39.77 toks/s]
[rank0]:[W126 12:23:46.624739682 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 12:23:48
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:23:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1353986) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1353986) WARNING 01-26 12:24:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.52 requests/s, 31283.71 total tokens/s, 30.52 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:23:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:23:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:23:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:23:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:23:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:23:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:23:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:23:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:24:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:24:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:24:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:24:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:24:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:24:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1353986) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1353986) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1353986) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1353986) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1353986) 
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1353986) [2026-01-26 12:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1353986) 2026-01-26 12:24:23,979 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1353986) 2026-01-26 12:24:24,022 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1353986) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 15.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 15.33it/s]
(EngineCore_DP0 pid=1353986) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.90it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▌        | 20/128 [00:00<00:00, 195.71it/s]
Adding requests:  45%|████▌     | 58/128 [00:00<00:00, 301.06it/s]
Adding requests:  74%|███████▍  | 95/128 [00:00<00:00, 329.76it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 323.96it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 78.19it/s, est. speed input: 80076.95 toks/s, output: 78.19 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:02, 42.85it/s, est. speed input: 47073.55 toks/s, output: 45.97 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:02, 38.24it/s, est. speed input: 42365.34 toks/s, output: 41.37 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 36.24it/s, est. speed input: 40336.06 toks/s, output: 39.39 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 35.16it/s, est. speed input: 39256.62 toks/s, output: 38.34 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:00<00:02, 34.35it/s, est. speed input: 38449.76 toks/s, output: 37.55 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 33.77it/s, est. speed input: 37827.67 toks/s, output: 36.94 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 33.33it/s, est. speed input: 37326.59 toks/s, output: 36.45 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 33.06it/s, est. speed input: 36935.68 toks/s, output: 36.07 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:02, 32.87it/s, est. speed input: 36613.28 toks/s, output: 35.75 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:02, 32.75it/s, est. speed input: 36344.40 toks/s, output: 35.49 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:02, 32.72it/s, est. speed input: 36131.73 toks/s, output: 35.28 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 32.65it/s, est. speed input: 35935.64 toks/s, output: 35.09 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 32.61it/s, est. speed input: 35766.41 toks/s, output: 34.93 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:01, 32.55it/s, est. speed input: 35609.93 toks/s, output: 34.77 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 32.49it/s, est. speed input: 35467.83 toks/s, output: 34.64 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 32.48it/s, est. speed input: 35348.13 toks/s, output: 34.52 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 32.49it/s, est. speed input: 35243.97 toks/s, output: 34.42 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 32.42it/s, est. speed input: 35134.75 toks/s, output: 34.31 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:01, 32.47it/s, est. speed input: 35054.06 toks/s, output: 34.23 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:01, 32.50it/s, est. speed input: 34979.30 toks/s, output: 34.16 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 32.46it/s, est. speed input: 34900.26 toks/s, output: 34.08 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:03<00:00, 32.46it/s, est. speed input: 34833.64 toks/s, output: 34.02 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:03<00:00, 32.50it/s, est. speed input: 34775.81 toks/s, output: 33.96 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:03<00:00, 32.50it/s, est. speed input: 34719.34 toks/s, output: 33.91 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 32.50it/s, est. speed input: 34667.58 toks/s, output: 33.85 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 32.51it/s, est. speed input: 34620.58 toks/s, output: 33.81 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 32.46it/s, est. speed input: 34569.24 toks/s, output: 33.76 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 32.47it/s, est. speed input: 34527.11 toks/s, output: 33.72 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.47it/s, est. speed input: 34520.52 toks/s, output: 33.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.71it/s, est. speed input: 34520.52 toks/s, output: 33.71 toks/s]
[rank0]:[W126 12:24:30.208881521 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:24:32
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:24:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1355116) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1355116) WARNING 01-26 12:24:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.13 requests/s, 34979.82 total tokens/s, 34.13 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:24:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:24:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:24:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:24:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:24:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:24:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:24:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:24:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:24:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:24:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:24:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:24:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:24:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:24:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1355116) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1355116) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.87it/s]
(EngineCore_DP0 pid=1355116) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1355116) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1355116) 
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1355116) [2026-01-26 12:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1355116) 2026-01-26 12:25:09,133 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1355116) 2026-01-26 12:25:09,183 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1355116) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 15.19it/s]
(EngineCore_DP0 pid=1355116) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.97it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.94it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 20/256 [00:00<00:01, 196.83it/s]
Adding requests:  24%|██▍       | 61/256 [00:00<00:00, 317.66it/s]
Adding requests:  38%|███▊      | 97/256 [00:00<00:00, 335.97it/s]
Adding requests:  53%|█████▎    | 135/256 [00:00<00:00, 352.10it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 366.33it/s]
Adding requests:  84%|████████▍ | 215/256 [00:00<00:00, 377.62it/s]
Adding requests:  99%|█████████▉| 253/256 [00:00<00:00, 378.24it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 357.44it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 146.40it/s, est. speed input: 149938.55 toks/s, output: 146.41 toks/s]
Processed prompts:  14%|█▎        | 35/256 [00:00<00:03, 59.52it/s, est. speed input: 67850.22 toks/s, output: 66.26 toks/s]   
Processed prompts:  17%|█▋        | 44/256 [00:00<00:04, 47.00it/s, est. speed input: 55586.88 toks/s, output: 54.28 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:00<00:04, 43.34it/s, est. speed input: 51936.54 toks/s, output: 50.72 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:01<00:04, 43.43it/s, est. speed input: 51194.65 toks/s, output: 49.99 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:01<00:04, 39.31it/s, est. speed input: 48491.90 toks/s, output: 47.35 toks/s]
Processed prompts:  25%|██▌       | 65/256 [00:01<00:04, 40.45it/s, est. speed input: 48234.62 toks/s, output: 47.10 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:05, 36.96it/s, est. speed input: 46306.80 toks/s, output: 45.22 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:01<00:04, 36.55it/s, est. speed input: 45611.47 toks/s, output: 44.54 toks/s]
Processed prompts:  30%|███       | 78/256 [00:01<00:04, 36.25it/s, est. speed input: 45011.94 toks/s, output: 43.96 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:04, 35.84it/s, est. speed input: 44435.55 toks/s, output: 43.39 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:02<00:04, 35.51it/s, est. speed input: 43921.07 toks/s, output: 42.89 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:04, 35.34it/s, est. speed input: 43478.61 toks/s, output: 42.46 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:04, 35.44it/s, est. speed input: 43130.15 toks/s, output: 42.12 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:04, 35.46it/s, est. speed input: 42805.15 toks/s, output: 41.80 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:02<00:04, 35.47it/s, est. speed input: 42508.19 toks/s, output: 41.51 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:04, 35.56it/s, est. speed input: 42253.31 toks/s, output: 41.26 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:02<00:04, 35.47it/s, est. speed input: 41993.69 toks/s, output: 41.01 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:02<00:04, 35.39it/s, est. speed input: 41751.11 toks/s, output: 40.77 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:03, 35.33it/s, est. speed input: 41527.78 toks/s, output: 40.55 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:03<00:03, 35.20it/s, est. speed input: 41308.10 toks/s, output: 40.34 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:03<00:03, 35.08it/s, est. speed input: 41100.57 toks/s, output: 40.14 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:03<00:03, 35.22it/s, est. speed input: 40938.91 toks/s, output: 39.98 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:03<00:03, 35.26it/s, est. speed input: 40778.83 toks/s, output: 39.82 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:03<00:03, 35.33it/s, est. speed input: 40635.47 toks/s, output: 39.68 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:03<00:03, 35.50it/s, est. speed input: 40515.02 toks/s, output: 39.57 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:03<00:03, 35.31it/s, est. speed input: 40367.00 toks/s, output: 39.42 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:03<00:03, 35.19it/s, est. speed input: 40228.44 toks/s, output: 39.29 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:03<00:02, 35.22it/s, est. speed input: 40110.13 toks/s, output: 39.17 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:04<00:02, 35.19it/s, est. speed input: 39993.54 toks/s, output: 39.06 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:04<00:02, 35.11it/s, est. speed input: 39877.06 toks/s, output: 38.94 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:04<00:02, 35.20it/s, est. speed input: 39781.72 toks/s, output: 38.85 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:04<00:02, 35.23it/s, est. speed input: 39687.92 toks/s, output: 38.76 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:04<00:02, 35.27it/s, est. speed input: 39599.99 toks/s, output: 38.67 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:04<00:02, 35.34it/s, est. speed input: 39521.34 toks/s, output: 38.59 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:04<00:02, 35.27it/s, est. speed input: 39434.87 toks/s, output: 38.51 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:04<00:01, 35.10it/s, est. speed input: 39342.26 toks/s, output: 38.42 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:04<00:01, 35.17it/s, est. speed input: 39270.24 toks/s, output: 38.35 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:05<00:01, 35.23it/s, est. speed input: 39201.90 toks/s, output: 38.28 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:05<00:01, 35.15it/s, est. speed input: 39127.09 toks/s, output: 38.21 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:05<00:01, 36.82it/s, est. speed input: 39172.13 toks/s, output: 38.25 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:05<00:01, 36.49it/s, est. speed input: 39116.69 toks/s, output: 38.20 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:05<00:01, 36.14it/s, est. speed input: 39055.38 toks/s, output: 38.14 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:05<00:01, 35.93it/s, est. speed input: 38999.43 toks/s, output: 38.09 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:05<00:01, 35.69it/s, est. speed input: 38940.08 toks/s, output: 38.03 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:05<00:00, 35.50it/s, est. speed input: 38880.53 toks/s, output: 37.97 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:06<00:00, 35.44it/s, est. speed input: 38829.22 toks/s, output: 37.92 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:06<00:00, 35.29it/s, est. speed input: 38772.43 toks/s, output: 37.86 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:06<00:00, 35.20it/s, est. speed input: 38718.30 toks/s, output: 37.81 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:06<00:00, 35.29it/s, est. speed input: 38676.12 toks/s, output: 37.77 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:06<00:00, 35.28it/s, est. speed input: 38631.38 toks/s, output: 37.73 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:06<00:00, 35.18it/s, est. speed input: 38581.51 toks/s, output: 37.68 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:06<00:00, 35.20it/s, est. speed input: 38539.45 toks/s, output: 37.64 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 35.20it/s, est. speed input: 38644.53 toks/s, output: 37.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 37.74it/s, est. speed input: 38644.53 toks/s, output: 37.74 toks/s]
[rank0]:[W126 12:25:18.766370833 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:25:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:25:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1356274) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1356274) WARNING 01-26 12:25:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.66 requests/s, 36550.54 total tokens/s, 35.66 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:25:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:25:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:25:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:25:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:25:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:25:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:25:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:25:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:25:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:25:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:25:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:25:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:25:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:25:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:25:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:25:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:25:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1356274) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1356274) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1356274) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1356274) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1356274) 
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1356274) [2026-01-26 12:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1356274) 2026-01-26 12:25:57,307 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1356274) 2026-01-26 12:25:57,331 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1356274) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:01,  2.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  5.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  6.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  5.27it/s]
(EngineCore_DP0 pid=1356274) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 19.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 19.07it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 285.77it/s]
Adding requests:  13%|█▎        | 69/512 [00:00<00:01, 351.72it/s]
Adding requests:  21%|██        | 106/512 [00:00<00:01, 355.89it/s]
Adding requests:  28%|██▊       | 144/512 [00:00<00:01, 361.94it/s]
Adding requests:  36%|███▌      | 184/512 [00:00<00:00, 375.00it/s]
Adding requests:  44%|████▍     | 224/512 [00:00<00:00, 381.39it/s]
Adding requests:  51%|█████▏    | 263/512 [00:00<00:00, 380.15it/s]
Adding requests:  59%|█████▉    | 303/512 [00:00<00:00, 384.03it/s]
Adding requests:  67%|██████▋   | 343/512 [00:00<00:00, 388.44it/s]
Adding requests:  75%|███████▌  | 384/512 [00:01<00:00, 392.24it/s]
Adding requests:  83%|████████▎ | 425/512 [00:01<00:00, 397.51it/s]
Adding requests:  91%|█████████ | 465/512 [00:01<00:00, 393.71it/s]
Adding requests:  99%|█████████▉| 507/512 [00:01<00:00, 401.13it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 384.02it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:00<00:01, 380.95it/s, est. speed input: 390167.81 toks/s, output: 380.97 toks/s]
Processed prompts:  17%|█▋        | 85/512 [00:01<00:06, 65.47it/s, est. speed input: 77457.81 toks/s, output: 75.64 toks/s]   
Processed prompts:  20%|██        | 103/512 [00:01<00:07, 51.55it/s, est. speed input: 62841.32 toks/s, output: 61.37 toks/s]
Processed prompts:  22%|██▏       | 115/512 [00:02<00:08, 47.14it/s, est. speed input: 58321.12 toks/s, output: 56.95 toks/s]
Processed prompts:  24%|██▍       | 124/512 [00:02<00:08, 45.84it/s, est. speed input: 56670.72 toks/s, output: 55.34 toks/s]
Processed prompts:  26%|██▌       | 131/512 [00:02<00:08, 42.73it/s, est. speed input: 54513.34 toks/s, output: 53.24 toks/s]
Processed prompts:  27%|██▋       | 137/512 [00:02<00:08, 44.29it/s, est. speed input: 54552.31 toks/s, output: 53.27 toks/s]
Processed prompts:  28%|██▊       | 143/512 [00:02<00:09, 39.21it/s, est. speed input: 52336.43 toks/s, output: 51.11 toks/s]
Processed prompts:  29%|██▉       | 148/512 [00:02<00:09, 40.08it/s, est. speed input: 52069.45 toks/s, output: 50.85 toks/s]
Processed prompts:  30%|██▉       | 153/512 [00:03<00:08, 40.89it/s, est. speed input: 51815.58 toks/s, output: 50.60 toks/s]
Processed prompts:  31%|███       | 158/512 [00:03<00:10, 34.38it/s, est. speed input: 49847.27 toks/s, output: 48.68 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:03<00:10, 34.73it/s, est. speed input: 49421.19 toks/s, output: 48.26 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:03<00:09, 35.05it/s, est. speed input: 49027.62 toks/s, output: 47.88 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:03<00:09, 35.17it/s, est. speed input: 48630.09 toks/s, output: 47.49 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:03<00:09, 35.28it/s, est. speed input: 48258.73 toks/s, output: 47.13 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:03<00:09, 35.35it/s, est. speed input: 47907.87 toks/s, output: 46.78 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:03<00:09, 35.36it/s, est. speed input: 47571.52 toks/s, output: 46.46 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:04<00:09, 35.48it/s, est. speed input: 47267.98 toks/s, output: 46.16 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:04<00:09, 35.58it/s, est. speed input: 46982.62 toks/s, output: 45.88 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:04<00:08, 35.85it/s, est. speed input: 46736.14 toks/s, output: 45.64 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:04<00:08, 35.86it/s, est. speed input: 46480.43 toks/s, output: 45.39 toks/s]
Processed prompts:  40%|████      | 206/512 [00:04<00:08, 37.37it/s, est. speed input: 46204.34 toks/s, output: 45.12 toks/s]
Processed prompts:  41%|████      | 210/512 [00:04<00:08, 36.86it/s, est. speed input: 45963.73 toks/s, output: 44.89 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:04<00:08, 36.54it/s, est. speed input: 45742.05 toks/s, output: 44.67 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:04<00:08, 36.24it/s, est. speed input: 45524.86 toks/s, output: 44.46 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:05<00:08, 35.98it/s, est. speed input: 45313.52 toks/s, output: 44.25 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:05<00:07, 35.91it/s, est. speed input: 45123.27 toks/s, output: 44.07 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:05<00:07, 35.93it/s, est. speed input: 44948.21 toks/s, output: 43.89 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:05<00:07, 36.00it/s, est. speed input: 44784.52 toks/s, output: 43.73 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:05<00:07, 35.98it/s, est. speed input: 44621.62 toks/s, output: 43.58 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:05<00:07, 35.96it/s, est. speed input: 44464.43 toks/s, output: 43.42 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:05<00:07, 35.82it/s, est. speed input: 44304.06 toks/s, output: 43.27 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:05<00:07, 35.72it/s, est. speed input: 44148.57 toks/s, output: 43.11 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:05<00:07, 35.72it/s, est. speed input: 44005.47 toks/s, output: 42.97 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:06<00:07, 35.59it/s, est. speed input: 43857.43 toks/s, output: 42.83 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:06<00:07, 35.57it/s, est. speed input: 43720.36 toks/s, output: 42.70 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:06<00:06, 35.66it/s, est. speed input: 43595.46 toks/s, output: 42.57 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:06<00:06, 35.71it/s, est. speed input: 43474.37 toks/s, output: 42.46 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:06<00:06, 35.87it/s, est. speed input: 43365.78 toks/s, output: 42.35 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:06<00:06, 35.79it/s, est. speed input: 43247.78 toks/s, output: 42.23 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:06<00:06, 35.77it/s, est. speed input: 43136.34 toks/s, output: 42.13 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:06<00:06, 35.69it/s, est. speed input: 43024.21 toks/s, output: 42.02 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:06<00:06, 35.69it/s, est. speed input: 42919.44 toks/s, output: 41.91 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:07<00:06, 35.72it/s, est. speed input: 42819.93 toks/s, output: 41.82 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:07<00:06, 35.63it/s, est. speed input: 42715.95 toks/s, output: 41.71 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:07<00:05, 35.56it/s, est. speed input: 42615.52 toks/s, output: 41.62 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:07<00:05, 37.45it/s, est. speed input: 42568.72 toks/s, output: 41.57 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:07<00:05, 36.99it/s, est. speed input: 42479.43 toks/s, output: 41.48 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:07<00:05, 36.56it/s, est. speed input: 42387.39 toks/s, output: 41.39 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:07<00:05, 36.27it/s, est. speed input: 42300.79 toks/s, output: 41.31 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:07<00:05, 36.05it/s, est. speed input: 42215.74 toks/s, output: 41.23 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:08<00:05, 35.93it/s, est. speed input: 42135.72 toks/s, output: 41.15 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:08<00:04, 35.95it/s, est. speed input: 42063.75 toks/s, output: 41.08 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:08<00:04, 35.79it/s, est. speed input: 41984.03 toks/s, output: 41.00 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:08<00:04, 35.82it/s, est. speed input: 41914.32 toks/s, output: 40.93 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:08<00:04, 35.82it/s, est. speed input: 41845.36 toks/s, output: 40.86 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:08<00:04, 35.71it/s, est. speed input: 41772.55 toks/s, output: 40.79 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:08<00:04, 35.69it/s, est. speed input: 41704.54 toks/s, output: 40.73 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:08<00:04, 35.67it/s, est. speed input: 41637.85 toks/s, output: 40.66 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:08<00:04, 35.63it/s, est. speed input: 41571.80 toks/s, output: 40.60 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:09<00:04, 35.62it/s, est. speed input: 41507.88 toks/s, output: 40.53 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:09<00:03, 35.66it/s, est. speed input: 41447.91 toks/s, output: 40.48 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:09<00:03, 35.77it/s, est. speed input: 41393.06 toks/s, output: 40.42 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:09<00:03, 35.77it/s, est. speed input: 41336.16 toks/s, output: 40.37 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:09<00:03, 35.64it/s, est. speed input: 41274.96 toks/s, output: 40.31 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:09<00:03, 35.60it/s, est. speed input: 41216.98 toks/s, output: 40.25 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:09<00:03, 35.59it/s, est. speed input: 41161.17 toks/s, output: 40.20 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:09<00:03, 35.65it/s, est. speed input: 41110.16 toks/s, output: 40.15 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:09<00:03, 35.65it/s, est. speed input: 41057.92 toks/s, output: 40.10 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:10<00:03, 35.62it/s, est. speed input: 41005.77 toks/s, output: 40.04 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:10<00:02, 35.70it/s, est. speed input: 40959.14 toks/s, output: 40.00 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:10<00:02, 35.76it/s, est. speed input: 40913.53 toks/s, output: 39.95 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:10<00:02, 35.73it/s, est. speed input: 40865.73 toks/s, output: 39.91 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:10<00:02, 35.60it/s, est. speed input: 40814.85 toks/s, output: 39.86 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:10<00:02, 35.56it/s, est. speed input: 40767.14 toks/s, output: 39.81 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:10<00:02, 35.67it/s, est. speed input: 40725.90 toks/s, output: 39.77 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:10<00:02, 35.66it/s, est. speed input: 40681.96 toks/s, output: 39.73 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:11<00:01, 37.39it/s, est. speed input: 40679.91 toks/s, output: 39.73 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:11<00:01, 36.83it/s, est. speed input: 40632.98 toks/s, output: 39.68 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:11<00:01, 36.61it/s, est. speed input: 40595.67 toks/s, output: 39.64 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:11<00:01, 36.28it/s, est. speed input: 40553.00 toks/s, output: 39.60 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:11<00:01, 36.04it/s, est. speed input: 40511.06 toks/s, output: 39.56 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:11<00:01, 35.91it/s, est. speed input: 40471.37 toks/s, output: 39.52 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:11<00:01, 35.83it/s, est. speed input: 40433.12 toks/s, output: 39.49 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:11<00:01, 35.88it/s, est. speed input: 40399.52 toks/s, output: 39.45 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:11<00:01, 35.83it/s, est. speed input: 40363.63 toks/s, output: 39.42 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:12<00:01, 35.72it/s, est. speed input: 40325.76 toks/s, output: 39.38 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:12<00:00, 35.66it/s, est. speed input: 40289.16 toks/s, output: 39.34 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:12<00:00, 35.63it/s, est. speed input: 40253.67 toks/s, output: 39.31 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:12<00:00, 35.63it/s, est. speed input: 40219.46 toks/s, output: 39.28 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:12<00:00, 35.57it/s, est. speed input: 40183.87 toks/s, output: 39.24 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:12<00:00, 35.51it/s, est. speed input: 40148.07 toks/s, output: 39.21 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:12<00:00, 35.57it/s, est. speed input: 40116.69 toks/s, output: 39.18 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:12<00:00, 35.62it/s, est. speed input: 40085.98 toks/s, output: 39.15 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:12<00:00, 35.60it/s, est. speed input: 40054.00 toks/s, output: 39.12 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:13<00:00, 35.60it/s, est. speed input: 40258.72 toks/s, output: 39.32 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:13<00:00, 39.31it/s, est. speed input: 40258.72 toks/s, output: 39.32 toks/s]
[rank0]:[W126 12:26:14.449872782 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:26:16
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:26:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1357583) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1357583) WARNING 01-26 12:26:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 36.40 requests/s, 37307.48 total tokens/s, 36.40 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:26:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:26:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:26:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:26:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:26:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:26:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:26:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:26:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:26:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:26:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:26:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:26:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:26:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:26:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:26:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:26:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:26:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1357583) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1357583) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=1357583) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=1357583) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=1357583) 
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1357583) [2026-01-26 12:26:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1357583) 2026-01-26 12:26:56,774 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1357583) 2026-01-26 12:26:56,800 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1357583) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  4.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  4.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  2.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  3.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.29it/s]
(EngineCore_DP0 pid=1357583) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.82it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00, 12.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.72it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 18/1024 [00:00<00:05, 175.41it/s]
Adding requests:   6%|▌         | 57/1024 [00:00<00:03, 296.59it/s]
Adding requests:   9%|▉         | 95/1024 [00:00<00:02, 331.18it/s]
Adding requests:  13%|█▎        | 133/1024 [00:00<00:02, 347.42it/s]
Adding requests:  17%|█▋        | 172/1024 [00:00<00:02, 361.12it/s]
Adding requests:  21%|██        | 212/1024 [00:00<00:02, 373.39it/s]
Adding requests:  25%|██▍       | 251/1024 [00:00<00:02, 377.36it/s]
Adding requests:  28%|██▊       | 290/1024 [00:00<00:01, 380.22it/s]
Adding requests:  32%|███▏      | 331/1024 [00:00<00:01, 388.14it/s]
Adding requests:  36%|███▋      | 372/1024 [00:01<00:01, 392.96it/s]
Adding requests:  40%|████      | 413/1024 [00:01<00:01, 397.43it/s]
Adding requests:  44%|████▍     | 453/1024 [00:01<00:01, 396.62it/s]
Adding requests:  48%|████▊     | 496/1024 [00:01<00:01, 405.77it/s]
Adding requests:  52%|█████▏    | 537/1024 [00:01<00:01, 404.13it/s]
Adding requests:  56%|█████▋    | 578/1024 [00:01<00:01, 401.59it/s]
Adding requests:  60%|██████    | 619/1024 [00:01<00:01, 392.98it/s]
Adding requests:  64%|██████▍   | 659/1024 [00:01<00:00, 388.11it/s]
Adding requests:  68%|██████▊   | 698/1024 [00:01<00:00, 388.64it/s]
Adding requests:  72%|███████▏  | 737/1024 [00:01<00:00, 383.10it/s]
Adding requests:  76%|███████▌  | 777/1024 [00:02<00:00, 386.38it/s]
Adding requests:  80%|███████▉  | 816/1024 [00:02<00:00, 385.86it/s]
Adding requests:  84%|████████▎ | 857/1024 [00:02<00:00, 392.53it/s]
Adding requests:  88%|████████▊ | 897/1024 [00:02<00:00, 394.15it/s]
Adding requests:  92%|█████████▏| 937/1024 [00:02<00:00, 386.49it/s]
Adding requests:  95%|█████████▌| 976/1024 [00:02<00:00, 387.29it/s]
Adding requests:  99%|█████████▉| 1015/1024 [00:02<00:00, 380.53it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 381.28it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:00<00:02, 440.63it/s, est. speed input: 451255.05 toks/s, output: 440.65 toks/s]
Processed prompts:  14%|█▍        | 143/1024 [00:01<00:09, 90.27it/s, est. speed input: 110502.27 toks/s, output: 107.91 toks/s]
Processed prompts:  16%|█▌        | 164/1024 [00:01<00:13, 65.17it/s, est. speed input: 84533.21 toks/s, output: 82.55 toks/s]  
Processed prompts:  17%|█▋        | 177/1024 [00:02<00:13, 64.23it/s, est. speed input: 82203.78 toks/s, output: 80.28 toks/s]
Processed prompts:  18%|█▊        | 187/1024 [00:02<00:16, 50.47it/s, est. speed input: 72241.83 toks/s, output: 70.55 toks/s]
Processed prompts:  19%|█▉        | 195/1024 [00:02<00:17, 47.93it/s, est. speed input: 69628.66 toks/s, output: 68.00 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:03<00:18, 45.64it/s, est. speed input: 67552.06 toks/s, output: 65.97 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:03<00:18, 43.35it/s, est. speed input: 65482.17 toks/s, output: 63.95 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:03<00:19, 41.43it/s, est. speed input: 63649.32 toks/s, output: 62.16 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:03<00:19, 40.06it/s, est. speed input: 62080.22 toks/s, output: 60.62 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:03<00:20, 39.13it/s, est. speed input: 60723.33 toks/s, output: 59.30 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:04<00:20, 38.47it/s, est. speed input: 59517.94 toks/s, output: 58.12 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:04<00:20, 37.72it/s, est. speed input: 58361.78 toks/s, output: 56.99 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:04<00:20, 37.22it/s, est. speed input: 57324.39 toks/s, output: 55.98 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:04<00:20, 37.04it/s, est. speed input: 56427.34 toks/s, output: 55.10 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:05<00:20, 36.94it/s, est. speed input: 55612.78 toks/s, output: 54.31 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:05<00:20, 36.69it/s, est. speed input: 54828.22 toks/s, output: 53.54 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:05<00:20, 36.48it/s, est. speed input: 54099.85 toks/s, output: 52.83 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:05<00:19, 36.39it/s, est. speed input: 53438.98 toks/s, output: 52.19 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:05<00:19, 37.72it/s, est. speed input: 53072.11 toks/s, output: 51.83 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:06<00:19, 37.33it/s, est. speed input: 52507.67 toks/s, output: 51.28 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:06<00:19, 36.91it/s, est. speed input: 51958.18 toks/s, output: 50.74 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:06<00:18, 36.71it/s, est. speed input: 51459.37 toks/s, output: 50.25 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:06<00:18, 36.59it/s, est. speed input: 50995.21 toks/s, output: 49.80 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:07<00:18, 36.55it/s, est. speed input: 50568.22 toks/s, output: 49.38 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:07<00:18, 36.49it/s, est. speed input: 50162.13 toks/s, output: 48.99 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:07<00:18, 36.37it/s, est. speed input: 49768.99 toks/s, output: 48.60 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:07<00:18, 36.26it/s, est. speed input: 49395.75 toks/s, output: 48.24 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:07<00:17, 36.40it/s, est. speed input: 49070.29 toks/s, output: 47.92 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:08<00:17, 36.35it/s, est. speed input: 48744.45 toks/s, output: 47.60 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:08<00:17, 36.30it/s, est. speed input: 48433.43 toks/s, output: 47.30 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:08<00:17, 36.25it/s, est. speed input: 48137.47 toks/s, output: 47.01 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:08<00:16, 36.29it/s, est. speed input: 47864.63 toks/s, output: 46.74 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:08<00:16, 36.32it/s, est. speed input: 47605.12 toks/s, output: 46.49 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:09<00:16, 36.32it/s, est. speed input: 47356.39 toks/s, output: 46.25 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:09<00:15, 37.68it/s, est. speed input: 47251.56 toks/s, output: 46.14 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:09<00:15, 37.16it/s, est. speed input: 47011.69 toks/s, output: 45.91 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:09<00:15, 36.84it/s, est. speed input: 46785.89 toks/s, output: 45.69 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:10<00:15, 36.72it/s, est. speed input: 46579.89 toks/s, output: 45.49 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:10<00:15, 36.51it/s, est. speed input: 46370.68 toks/s, output: 45.28 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:10<00:15, 36.47it/s, est. speed input: 46179.79 toks/s, output: 45.10 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:10<00:14, 36.38it/s, est. speed input: 45991.50 toks/s, output: 44.91 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:10<00:14, 36.41it/s, est. speed input: 45818.19 toks/s, output: 44.74 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:11<00:14, 36.41it/s, est. speed input: 45650.32 toks/s, output: 44.58 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:11<00:14, 36.30it/s, est. speed input: 45480.33 toks/s, output: 44.41 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:11<00:14, 36.32it/s, est. speed input: 45324.30 toks/s, output: 44.26 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:11<00:13, 36.27it/s, est. speed input: 45168.98 toks/s, output: 44.11 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:12<00:13, 36.25it/s, est. speed input: 45020.89 toks/s, output: 43.97 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:12<00:13, 36.22it/s, est. speed input: 44876.30 toks/s, output: 43.82 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:12<00:13, 36.17it/s, est. speed input: 44735.27 toks/s, output: 43.69 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:12<00:13, 36.09it/s, est. speed input: 44595.79 toks/s, output: 43.55 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:12<00:12, 36.06it/s, est. speed input: 44462.47 toks/s, output: 43.42 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:13<00:12, 36.22it/s, est. speed input: 44346.38 toks/s, output: 43.31 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:13<00:12, 36.24it/s, est. speed input: 44228.38 toks/s, output: 43.19 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:13<00:12, 36.22it/s, est. speed input: 44111.59 toks/s, output: 43.08 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:13<00:11, 36.30it/s, est. speed input: 44004.20 toks/s, output: 42.97 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:14<00:11, 36.30it/s, est. speed input: 43897.31 toks/s, output: 42.87 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:14<00:11, 36.31it/s, est. speed input: 43794.03 toks/s, output: 42.77 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:14<00:11, 36.35it/s, est. speed input: 43695.95 toks/s, output: 42.67 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:14<00:10, 36.32it/s, est. speed input: 43597.32 toks/s, output: 42.58 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:14<00:10, 36.36it/s, est. speed input: 43504.94 toks/s, output: 42.49 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:15<00:10, 36.33it/s, est. speed input: 43412.07 toks/s, output: 42.39 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:15<00:10, 36.31it/s, est. speed input: 43322.23 toks/s, output: 42.31 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:15<00:10, 36.37it/s, est. speed input: 43238.39 toks/s, output: 42.22 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:15<00:09, 36.37it/s, est. speed input: 43154.93 toks/s, output: 42.14 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:16<00:09, 36.34it/s, est. speed input: 43072.43 toks/s, output: 42.06 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:16<00:09, 36.34it/s, est. speed input: 42992.92 toks/s, output: 41.99 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:16<00:09, 36.34it/s, est. speed input: 42915.67 toks/s, output: 41.91 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:16<00:08, 36.35it/s, est. speed input: 42840.97 toks/s, output: 41.84 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:16<00:08, 36.35it/s, est. speed input: 42767.93 toks/s, output: 41.77 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:17<00:08, 36.31it/s, est. speed input: 42694.60 toks/s, output: 41.69 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:17<00:08, 36.31it/s, est. speed input: 42624.68 toks/s, output: 41.63 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:17<00:08, 36.32it/s, est. speed input: 42556.99 toks/s, output: 41.56 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:17<00:07, 36.37it/s, est. speed input: 42492.87 toks/s, output: 41.50 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:18<00:07, 36.32it/s, est. speed input: 42426.38 toks/s, output: 41.43 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:18<00:07, 36.32it/s, est. speed input: 42362.99 toks/s, output: 41.37 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:18<00:07, 36.33it/s, est. speed input: 42301.91 toks/s, output: 41.31 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:18<00:06, 36.37it/s, est. speed input: 42243.44 toks/s, output: 41.25 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:18<00:06, 36.33it/s, est. speed input: 42183.37 toks/s, output: 41.19 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:19<00:06, 37.59it/s, est. speed input: 42180.19 toks/s, output: 41.19 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:19<00:06, 37.15it/s, est. speed input: 42121.37 toks/s, output: 41.13 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:19<00:06, 36.93it/s, est. speed input: 42067.10 toks/s, output: 41.08 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:19<00:05, 36.74it/s, est. speed input: 42012.53 toks/s, output: 41.03 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:19<00:05, 36.59it/s, est. speed input: 41958.49 toks/s, output: 40.98 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:20<00:05, 36.51it/s, est. speed input: 41906.35 toks/s, output: 40.92 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:20<00:05, 36.42it/s, est. speed input: 41854.06 toks/s, output: 40.87 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:20<00:04, 36.44it/s, est. speed input: 41806.17 toks/s, output: 40.83 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:20<00:04, 36.30it/s, est. speed input: 41753.25 toks/s, output: 40.77 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:21<00:04, 36.31it/s, est. speed input: 41705.96 toks/s, output: 40.73 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:21<00:04, 36.36it/s, est. speed input: 41661.09 toks/s, output: 40.68 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:21<00:04, 36.34it/s, est. speed input: 41614.90 toks/s, output: 40.64 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:21<00:03, 36.29it/s, est. speed input: 41568.39 toks/s, output: 40.59 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:21<00:03, 36.23it/s, est. speed input: 41521.91 toks/s, output: 40.55 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:22<00:03, 36.31it/s, est. speed input: 41481.00 toks/s, output: 40.51 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:22<00:03, 36.35it/s, est. speed input: 41440.13 toks/s, output: 40.47 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:22<00:03, 36.29it/s, est. speed input: 41396.67 toks/s, output: 40.43 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:22<00:02, 36.22it/s, est. speed input: 41353.36 toks/s, output: 40.38 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:23<00:02, 36.29it/s, est. speed input: 41314.88 toks/s, output: 40.35 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:23<00:02, 36.32it/s, est. speed input: 41276.74 toks/s, output: 40.31 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:23<00:02, 36.40it/s, est. speed input: 41241.30 toks/s, output: 40.27 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:23<00:01, 36.35it/s, est. speed input: 41202.77 toks/s, output: 40.24 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:23<00:01, 36.30it/s, est. speed input: 41164.45 toks/s, output: 40.20 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:24<00:01, 36.32it/s, est. speed input: 41128.53 toks/s, output: 40.16 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:24<00:01, 36.31it/s, est. speed input: 41092.59 toks/s, output: 40.13 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:24<00:01, 36.26it/s, est. speed input: 41055.91 toks/s, output: 40.09 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:24<00:00, 36.29it/s, est. speed input: 41021.95 toks/s, output: 40.06 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:25<00:00, 36.30it/s, est. speed input: 40988.48 toks/s, output: 40.03 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:25<00:00, 36.28it/s, est. speed input: 40954.47 toks/s, output: 39.99 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:25<00:00, 37.74it/s, est. speed input: 40967.11 toks/s, output: 40.01 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:25<00:00, 37.74it/s, est. speed input: 41207.87 toks/s, output: 40.24 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:25<00:00, 40.24it/s, est. speed input: 41207.87 toks/s, output: 40.24 toks/s]
[rank0]:[W126 12:27:28.234958777 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 12:27:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:27:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1359131) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1359131) WARNING 01-26 12:28:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.58 requests/s, 38517.92 total tokens/s, 37.58 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 12:27:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:27:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:27:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:27:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:27:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:27:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:27:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:27:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:27:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:27:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:27:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:27:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:27:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:27:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:27:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:27:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:27:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1359131) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1359131) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1359131) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
(EngineCore_DP0 pid=1359131) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=1359131) 
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1359131) [2026-01-26 12:27:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1359131) [rank0]:W0126 12:28:10.780000 1359131 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1359131) [rank0]:W0126 12:28:10.858000 1359131 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1359131) [rank0]:W0126 12:28:12.017000 1359131 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1359131) [rank0]:W0126 12:28:12.149000 1359131 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1359131) 2026-01-26 12:28:15,995 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1359131) 2026-01-26 12:28:16,022 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1359131) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  7.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  3.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  5.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.77it/s]
(EngineCore_DP0 pid=1359131) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 14.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 18.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 17.61it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 22/2048 [00:00<00:09, 218.71it/s]
Adding requests:   3%|▎         | 62/2048 [00:00<00:06, 323.74it/s]
Adding requests:   5%|▍         | 96/2048 [00:00<00:05, 330.34it/s]
Adding requests:   7%|▋         | 134/2048 [00:00<00:05, 349.56it/s]
Adding requests:   8%|▊         | 174/2048 [00:00<00:05, 365.86it/s]
Adding requests:  10%|█         | 215/2048 [00:00<00:04, 377.85it/s]
Adding requests:  12%|█▏        | 254/2048 [00:00<00:04, 379.08it/s]
Adding requests:  14%|█▍        | 293/2048 [00:00<00:04, 382.20it/s]
Adding requests:  16%|█▋        | 335/2048 [00:00<00:04, 391.42it/s]
Adding requests:  18%|█▊        | 375/2048 [00:01<00:04, 393.08it/s]
Adding requests:  20%|██        | 417/2048 [00:01<00:04, 400.54it/s]
Adding requests:  22%|██▏       | 458/2048 [00:01<00:04, 391.19it/s]
Adding requests:  24%|██▍       | 501/2048 [00:01<00:03, 400.08it/s]
Adding requests:  27%|██▋       | 543/2048 [00:01<00:03, 405.77it/s]
Adding requests:  29%|██▊       | 584/2048 [00:01<00:03, 400.10it/s]
Adding requests:  31%|███       | 625/2048 [00:01<00:03, 391.37it/s]
Adding requests:  32%|███▏      | 665/2048 [00:01<00:03, 383.11it/s]
Adding requests:  34%|███▍      | 705/2048 [00:01<00:03, 385.71it/s]
Adding requests:  36%|███▋      | 744/2048 [00:01<00:03, 380.35it/s]
Adding requests:  38%|███▊      | 783/2048 [00:02<00:03, 375.53it/s]
Adding requests:  40%|████      | 822/2048 [00:02<00:03, 378.14it/s]
Adding requests:  42%|████▏     | 862/2048 [00:02<00:03, 382.67it/s]
Adding requests:  44%|████▍     | 902/2048 [00:02<00:02, 385.59it/s]
Adding requests:  46%|████▌     | 941/2048 [00:02<00:02, 381.50it/s]
Adding requests:  48%|████▊     | 980/2048 [00:02<00:02, 379.45it/s]
Adding requests:  50%|████▉     | 1018/2048 [00:02<00:02, 375.93it/s]
Adding requests:  52%|█████▏    | 1056/2048 [00:02<00:02, 373.79it/s]
Adding requests:  53%|█████▎    | 1094/2048 [00:02<00:02, 373.48it/s]
Adding requests:  55%|█████▌    | 1135/2048 [00:02<00:02, 381.28it/s]
Adding requests:  57%|█████▋    | 1174/2048 [00:03<00:02, 378.10it/s]
Adding requests:  59%|█████▉    | 1213/2048 [00:03<00:02, 380.41it/s]
Adding requests:  61%|██████    | 1252/2048 [00:03<00:02, 382.93it/s]
Adding requests:  63%|██████▎   | 1291/2048 [00:03<00:02, 375.51it/s]
Adding requests:  65%|██████▍   | 1330/2048 [00:03<00:01, 379.04it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:03<00:01, 381.27it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:03<00:01, 379.60it/s]
Adding requests:  71%|███████   | 1446/2048 [00:03<00:01, 378.83it/s]
Adding requests:  73%|███████▎  | 1487/2048 [00:03<00:01, 384.68it/s]
Adding requests:  75%|███████▍  | 1526/2048 [00:04<00:01, 385.39it/s]
Adding requests:  76%|███████▋  | 1565/2048 [00:04<00:01, 381.88it/s]
Adding requests:  78%|███████▊  | 1604/2048 [00:04<00:01, 380.18it/s]
Adding requests:  80%|████████  | 1643/2048 [00:04<00:01, 373.84it/s]
Adding requests:  82%|████████▏ | 1681/2048 [00:04<00:00, 374.15it/s]
Adding requests:  84%|████████▍ | 1721/2048 [00:04<00:00, 378.39it/s]
Adding requests:  86%|████████▌ | 1761/2048 [00:04<00:00, 383.56it/s]
Adding requests:  88%|████████▊ | 1801/2048 [00:04<00:00, 386.46it/s]
Adding requests:  90%|████████▉ | 1841/2048 [00:04<00:00, 387.73it/s]
Adding requests:  92%|█████████▏| 1881/2048 [00:04<00:00, 389.03it/s]
Adding requests:  94%|█████████▍| 1920/2048 [00:05<00:00, 382.66it/s]
Adding requests:  96%|█████████▌| 1961/2048 [00:05<00:00, 388.26it/s]
Adding requests:  98%|█████████▊| 2000/2048 [00:05<00:00, 383.19it/s]
Adding requests: 100%|█████████▉| 2039/2048 [00:05<00:00, 378.96it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 380.40it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:00<00:02, 712.71it/s, est. speed input: 729874.84 toks/s, output: 712.72 toks/s]
Processed prompts:  13%|█▎        | 266/2048 [00:01<00:16, 109.76it/s, est. speed input: 137928.43 toks/s, output: 134.69 toks/s]
Processed prompts:  15%|█▍        | 298/2048 [00:02<00:21, 81.43it/s, est. speed input: 107871.15 toks/s, output: 105.34 toks/s] 
Processed prompts:  16%|█▌        | 318/2048 [00:03<00:23, 74.74it/s, est. speed input: 100719.31 toks/s, output: 98.36 toks/s] 
Processed prompts:  16%|█▌        | 332/2048 [00:03<00:26, 64.74it/s, est. speed input: 92938.03 toks/s, output: 90.76 toks/s] 
Processed prompts:  17%|█▋        | 342/2048 [00:04<00:31, 54.20it/s, est. speed input: 85748.23 toks/s, output: 83.74 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:04<00:35, 47.33it/s, est. speed input: 80423.13 toks/s, output: 78.54 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:04<00:37, 44.59it/s, est. speed input: 76778.61 toks/s, output: 74.98 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:05<00:39, 42.56it/s, est. speed input: 73715.48 toks/s, output: 71.99 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:05<00:39, 41.19it/s, est. speed input: 71150.25 toks/s, output: 69.48 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:06<00:40, 40.12it/s, est. speed input: 68905.99 toks/s, output: 67.29 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:06<00:40, 40.05it/s, est. speed input: 67202.82 toks/s, output: 65.63 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:07<00:40, 39.36it/s, est. speed input: 65481.80 toks/s, output: 63.95 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:07<00:40, 38.80it/s, est. speed input: 63934.26 toks/s, output: 62.44 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:07<00:40, 38.46it/s, est. speed input: 62566.77 toks/s, output: 61.10 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:08<00:40, 38.19it/s, est. speed input: 61331.31 toks/s, output: 59.89 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:08<00:40, 38.04it/s, est. speed input: 60228.12 toks/s, output: 58.82 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:09<00:40, 37.92it/s, est. speed input: 59221.66 toks/s, output: 57.83 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:09<00:39, 37.87it/s, est. speed input: 58311.96 toks/s, output: 56.95 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:10<00:39, 37.76it/s, est. speed input: 57464.72 toks/s, output: 56.12 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:10<00:38, 37.74it/s, est. speed input: 56697.53 toks/s, output: 55.37 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:10<00:38, 37.72it/s, est. speed input: 55989.45 toks/s, output: 54.68 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:11<00:38, 37.73it/s, est. speed input: 55338.74 toks/s, output: 54.04 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:11<00:37, 37.71it/s, est. speed input: 54730.47 toks/s, output: 53.45 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:12<00:37, 37.62it/s, est. speed input: 54151.76 toks/s, output: 52.88 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:12<00:36, 37.64it/s, est. speed input: 53626.69 toks/s, output: 52.37 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:12<00:36, 37.62it/s, est. speed input: 53129.08 toks/s, output: 51.88 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:13<00:36, 37.57it/s, est. speed input: 52658.62 toks/s, output: 51.42 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:13<00:35, 37.56it/s, est. speed input: 52220.88 toks/s, output: 51.00 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:14<00:35, 37.61it/s, est. speed input: 51817.06 toks/s, output: 50.60 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:14<00:34, 37.59it/s, est. speed input: 51428.65 toks/s, output: 50.22 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:15<00:34, 37.54it/s, est. speed input: 51057.91 toks/s, output: 49.86 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:15<00:34, 37.54it/s, est. speed input: 50712.67 toks/s, output: 49.52 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:15<00:33, 38.20it/s, est. speed input: 50462.87 toks/s, output: 49.28 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:16<00:32, 37.96it/s, est. speed input: 50145.60 toks/s, output: 48.97 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:16<00:32, 37.83it/s, est. speed input: 49847.86 toks/s, output: 48.68 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:17<00:32, 37.77it/s, est. speed input: 49568.74 toks/s, output: 48.41 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:17<00:31, 37.65it/s, est. speed input: 49295.09 toks/s, output: 48.14 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:18<00:31, 37.60it/s, est. speed input: 49036.97 toks/s, output: 47.89 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:18<00:31, 37.58it/s, est. speed input: 48793.14 toks/s, output: 47.65 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:18<00:30, 37.52it/s, est. speed input: 48555.57 toks/s, output: 47.42 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:19<00:30, 37.51it/s, est. speed input: 48331.31 toks/s, output: 47.20 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:19<00:29, 37.48it/s, est. speed input: 48114.34 toks/s, output: 46.99 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:20<00:29, 37.51it/s, est. speed input: 47911.50 toks/s, output: 46.79 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:20<00:28, 37.48it/s, est. speed input: 47712.92 toks/s, output: 46.59 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:21<00:28, 37.45it/s, est. speed input: 47521.10 toks/s, output: 46.41 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:21<00:28, 37.45it/s, est. speed input: 47339.14 toks/s, output: 46.23 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:21<00:27, 37.43it/s, est. speed input: 47162.05 toks/s, output: 46.06 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:22<00:27, 37.45it/s, est. speed input: 46994.44 toks/s, output: 45.89 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:22<00:26, 37.37it/s, est. speed input: 46826.38 toks/s, output: 45.73 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:23<00:26, 37.42it/s, est. speed input: 46672.03 toks/s, output: 45.58 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:23<00:26, 37.44it/s, est. speed input: 46522.98 toks/s, output: 45.43 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:24<00:25, 37.40it/s, est. speed input: 46374.42 toks/s, output: 45.29 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:24<00:25, 37.45it/s, est. speed input: 46237.09 toks/s, output: 45.15 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:24<00:24, 37.41it/s, est. speed input: 46099.15 toks/s, output: 45.02 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:25<00:24, 37.45it/s, est. speed input: 45970.44 toks/s, output: 44.89 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:25<00:23, 37.41it/s, est. speed input: 45841.48 toks/s, output: 44.77 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:26<00:23, 37.45it/s, est. speed input: 45721.00 toks/s, output: 44.65 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:26<00:23, 37.45it/s, est. speed input: 45602.98 toks/s, output: 44.53 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:27<00:22, 38.07it/s, est. speed input: 45527.22 toks/s, output: 44.46 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:27<00:21, 37.88it/s, est. speed input: 45415.47 toks/s, output: 44.35 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:27<00:21, 38.36it/s, est. speed input: 45344.03 toks/s, output: 44.28 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:28<00:20, 38.08it/s, est. speed input: 45238.00 toks/s, output: 44.18 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:28<00:20, 37.86it/s, est. speed input: 45134.03 toks/s, output: 44.08 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:29<00:20, 37.72it/s, est. speed input: 45033.32 toks/s, output: 43.98 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:29<00:19, 37.59it/s, est. speed input: 44934.06 toks/s, output: 43.88 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:30<00:19, 37.51it/s, est. speed input: 44838.24 toks/s, output: 43.79 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:30<00:18, 38.14it/s, est. speed input: 44782.93 toks/s, output: 43.73 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:30<00:18, 37.84it/s, est. speed input: 44688.49 toks/s, output: 43.64 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:31<00:18, 37.71it/s, est. speed input: 44601.52 toks/s, output: 43.56 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:31<00:17, 37.53it/s, est. speed input: 44511.86 toks/s, output: 43.47 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:32<00:17, 37.51it/s, est. speed input: 44429.91 toks/s, output: 43.39 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:32<00:17, 37.45it/s, est. speed input: 44347.90 toks/s, output: 43.31 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:32<00:16, 37.38it/s, est. speed input: 44266.82 toks/s, output: 43.23 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:33<00:16, 37.42it/s, est. speed input: 44191.85 toks/s, output: 43.16 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:33<00:15, 37.95it/s, est. speed input: 44143.85 toks/s, output: 43.11 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:34<00:15, 37.80it/s, est. speed input: 44071.60 toks/s, output: 43.04 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:34<00:14, 37.62it/s, est. speed input: 43997.61 toks/s, output: 42.97 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:35<00:14, 37.49it/s, est. speed input: 43924.83 toks/s, output: 42.90 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:35<00:13, 38.06it/s, est. speed input: 43884.66 toks/s, output: 42.86 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:35<00:13, 37.78it/s, est. speed input: 43814.48 toks/s, output: 42.79 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:36<00:12, 38.30it/s, est. speed input: 43777.91 toks/s, output: 42.75 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:36<00:12, 37.94it/s, est. speed input: 43710.58 toks/s, output: 42.69 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:37<00:12, 37.75it/s, est. speed input: 43646.93 toks/s, output: 42.62 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:37<00:11, 37.57it/s, est. speed input: 43582.82 toks/s, output: 42.56 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:38<00:11, 38.10it/s, est. speed input: 43548.33 toks/s, output: 42.53 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:38<00:10, 37.85it/s, est. speed input: 43488.19 toks/s, output: 42.47 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:38<00:10, 37.57it/s, est. speed input: 43425.06 toks/s, output: 42.41 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:39<00:10, 37.49it/s, est. speed input: 43368.18 toks/s, output: 42.35 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:39<00:09, 37.38it/s, est. speed input: 43310.27 toks/s, output: 42.30 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:40<00:09, 37.35it/s, est. speed input: 43255.54 toks/s, output: 42.24 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:40<00:08, 37.26it/s, est. speed input: 43198.79 toks/s, output: 42.19 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:41<00:08, 37.88it/s, est. speed input: 43170.85 toks/s, output: 42.16 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:41<00:07, 38.32it/s, est. speed input: 43143.14 toks/s, output: 42.13 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:41<00:07, 37.93it/s, est. speed input: 43089.48 toks/s, output: 42.08 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:42<00:07, 37.72it/s, est. speed input: 43039.16 toks/s, output: 42.03 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:42<00:06, 37.57it/s, est. speed input: 42989.57 toks/s, output: 41.98 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:43<00:06, 37.46it/s, est. speed input: 42940.92 toks/s, output: 41.93 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:43<00:05, 37.38it/s, est. speed input: 42892.93 toks/s, output: 41.89 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:44<00:05, 37.33it/s, est. speed input: 42846.37 toks/s, output: 41.84 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:44<00:05, 37.29it/s, est. speed input: 42800.31 toks/s, output: 41.80 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:44<00:04, 37.24it/s, est. speed input: 42754.45 toks/s, output: 41.75 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:45<00:04, 37.88it/s, est. speed input: 42733.48 toks/s, output: 41.73 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:45<00:03, 37.63it/s, est. speed input: 42688.20 toks/s, output: 41.69 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:46<00:03, 37.53it/s, est. speed input: 42646.53 toks/s, output: 41.65 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:46<00:02, 37.35it/s, est. speed input: 42601.71 toks/s, output: 41.60 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:47<00:02, 37.37it/s, est. speed input: 42562.65 toks/s, output: 41.57 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:47<00:02, 37.27it/s, est. speed input: 42520.54 toks/s, output: 41.52 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:47<00:01, 37.89it/s, est. speed input: 42502.36 toks/s, output: 41.51 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:48<00:01, 37.67it/s, est. speed input: 42462.51 toks/s, output: 41.47 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:48<00:00, 37.46it/s, est. speed input: 42421.76 toks/s, output: 41.43 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:49<00:00, 38.16it/s, est. speed input: 42408.98 toks/s, output: 41.41 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:49<00:00, 38.16it/s, est. speed input: 42700.40 toks/s, output: 41.70 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:49<00:00, 41.70it/s, est. speed input: 42700.40 toks/s, output: 41.70 toks/s]
[rank0]:[W126 12:29:13.980652061 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 12:29:16
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:29:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1361187) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1361187) WARNING 01-26 12:30:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.29 requests/s, 38224.13 total tokens/s, 37.29 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 12:29:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:29:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:29:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:29:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:29:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:29:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:29:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:29:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:29:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:29:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:29:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:29:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:29:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:29:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:29:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:29:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:29:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1361187) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1361187) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1361187) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
(EngineCore_DP0 pid=1361187) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1361187) 
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1361187) [2026-01-26 12:29:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1361187) [rank0]:W0126 12:30:07.082000 1361187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1361187) [rank0]:W0126 12:30:07.160000 1361187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1361187) [rank0]:W0126 12:30:08.139000 1361187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1361187) [rank0]:W0126 12:30:08.265000 1361187 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1361187) 2026-01-26 12:30:11,910 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1361187) 2026-01-26 12:30:11,937 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1361187) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:05,  1.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:04,  2.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  4.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  7.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  9.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00, 12.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.19it/s]
(EngineCore_DP0 pid=1361187) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 19.21it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  9.55it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.46it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 243.30it/s]
Adding requests:   2%|▏         | 65/4096 [00:00<00:12, 331.90it/s]
Adding requests:   2%|▏         | 101/4096 [00:00<00:11, 341.35it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:11, 354.86it/s]
Adding requests:   4%|▍         | 178/4096 [00:00<00:10, 366.13it/s]
Adding requests:   5%|▌         | 219/4096 [00:00<00:10, 380.16it/s]
Adding requests:   6%|▋         | 258/4096 [00:00<00:10, 373.34it/s]
Adding requests:   7%|▋         | 298/4096 [00:00<00:10, 379.48it/s]
Adding requests:   8%|▊         | 338/4096 [00:00<00:09, 384.36it/s]
Adding requests:   9%|▉         | 378/4096 [00:01<00:09, 386.33it/s]
Adding requests:  10%|█         | 420/4096 [00:01<00:09, 393.72it/s]
Adding requests:  11%|█         | 460/4096 [00:01<00:09, 388.67it/s]
Adding requests:  12%|█▏        | 502/4096 [00:01<00:09, 396.11it/s]
Adding requests:  13%|█▎        | 545/4096 [00:01<00:08, 402.84it/s]
Adding requests:  14%|█▍        | 586/4096 [00:01<00:08, 398.42it/s]
Adding requests:  15%|█▌        | 626/4096 [00:01<00:08, 395.29it/s]
Adding requests:  16%|█▋        | 666/4096 [00:01<00:08, 387.51it/s]
Adding requests:  17%|█▋        | 706/4096 [00:01<00:08, 390.28it/s]
Adding requests:  18%|█▊        | 746/4096 [00:01<00:08, 384.76it/s]
Adding requests:  19%|█▉        | 786/4096 [00:02<00:08, 388.34it/s]
Adding requests:  20%|██        | 825/4096 [00:02<00:08, 386.62it/s]
Adding requests:  21%|██        | 866/4096 [00:02<00:08, 391.46it/s]
Adding requests:  22%|██▏       | 907/4096 [00:02<00:08, 394.63it/s]
Adding requests:  23%|██▎       | 947/4096 [00:02<00:08, 385.54it/s]
Adding requests:  24%|██▍       | 986/4096 [00:02<00:08, 386.74it/s]
Adding requests:  25%|██▌       | 1025/4096 [00:02<00:08, 382.18it/s]
Adding requests:  26%|██▌       | 1064/4096 [00:02<00:07, 382.25it/s]
Adding requests:  27%|██▋       | 1103/4096 [00:02<00:08, 373.57it/s]
Adding requests:  28%|██▊       | 1143/4096 [00:02<00:07, 379.32it/s]
Adding requests:  29%|██▉       | 1182/4096 [00:03<00:07, 379.61it/s]
Adding requests:  30%|██▉       | 1222/4096 [00:03<00:07, 385.11it/s]
Adding requests:  31%|███       | 1261/4096 [00:03<00:07, 383.69it/s]
Adding requests:  32%|███▏      | 1300/4096 [00:03<00:07, 381.04it/s]
Adding requests:  33%|███▎      | 1339/4096 [00:03<00:07, 383.11it/s]
Adding requests:  34%|███▎      | 1379/4096 [00:03<00:07, 387.57it/s]
Adding requests:  35%|███▍      | 1418/4096 [00:03<00:06, 382.92it/s]
Adding requests:  36%|███▌      | 1458/4096 [00:03<00:06, 387.56it/s]
Adding requests:  37%|███▋      | 1499/4096 [00:03<00:06, 390.95it/s]
Adding requests:  38%|███▊      | 1539/4096 [00:04<00:06, 391.56it/s]
Adding requests:  39%|███▊      | 1579/4096 [00:04<00:06, 383.21it/s]
Adding requests:  40%|███▉      | 1618/4096 [00:04<00:06, 378.51it/s]
Adding requests:  40%|████      | 1656/4096 [00:04<00:06, 372.93it/s]
Adding requests:  41%|████▏     | 1694/4096 [00:04<00:06, 373.28it/s]
Adding requests:  42%|████▏     | 1734/4096 [00:04<00:06, 378.98it/s]
Adding requests:  43%|████▎     | 1775/4096 [00:04<00:05, 387.83it/s]
Adding requests:  44%|████▍     | 1814/4096 [00:04<00:05, 382.81it/s]
Adding requests:  45%|████▌     | 1853/4096 [00:04<00:05, 384.10it/s]
Adding requests:  46%|████▌     | 1893/4096 [00:04<00:05, 386.96it/s]
Adding requests:  47%|████▋     | 1934/4096 [00:05<00:05, 391.33it/s]
Adding requests:  48%|████▊     | 1974/4096 [00:05<00:05, 391.44it/s]
Adding requests:  49%|████▉     | 2014/4096 [00:05<00:05, 387.94it/s]
Adding requests:  50%|█████     | 2053/4096 [00:05<00:05, 380.81it/s]
Adding requests:  51%|█████     | 2092/4096 [00:05<00:05, 373.69it/s]
Adding requests:  52%|█████▏    | 2132/4096 [00:05<00:05, 378.55it/s]
Adding requests:  53%|█████▎    | 2170/4096 [00:05<00:05, 375.02it/s]
Adding requests:  54%|█████▍    | 2208/4096 [00:05<00:05, 371.45it/s]
Adding requests:  55%|█████▍    | 2247/4096 [00:05<00:04, 375.62it/s]
Adding requests:  56%|█████▌    | 2288/4096 [00:05<00:04, 384.49it/s]
Adding requests:  57%|█████▋    | 2327/4096 [00:06<00:04, 379.77it/s]
Adding requests:  58%|█████▊    | 2367/4096 [00:06<00:04, 383.56it/s]
Adding requests:  59%|█████▉    | 2408/4096 [00:06<00:04, 389.99it/s]
Adding requests:  60%|█████▉    | 2448/4096 [00:06<00:04, 391.10it/s]
Adding requests:  61%|██████    | 2488/4096 [00:06<00:04, 392.05it/s]
Adding requests:  62%|██████▏   | 2529/4096 [00:06<00:03, 394.89it/s]
Adding requests:  63%|██████▎   | 2572/4096 [00:06<00:03, 403.93it/s]
Adding requests:  64%|██████▍   | 2613/4096 [00:06<00:03, 400.81it/s]
Adding requests:  65%|██████▍   | 2654/4096 [00:06<00:03, 390.92it/s]
Adding requests:  66%|██████▌   | 2694/4096 [00:07<00:03, 387.56it/s]
Adding requests:  67%|██████▋   | 2733/4096 [00:07<00:03, 385.73it/s]
Adding requests:  68%|██████▊   | 2774/4096 [00:07<00:03, 391.82it/s]
Adding requests:  69%|██████▉   | 2816/4096 [00:07<00:03, 398.39it/s]
Adding requests:  70%|██████▉   | 2856/4096 [00:07<00:03, 396.68it/s]
Adding requests:  71%|███████   | 2896/4096 [00:07<00:03, 393.92it/s]
Adding requests:  72%|███████▏  | 2937/4096 [00:07<00:02, 398.00it/s]
Adding requests:  73%|███████▎  | 2977/4096 [00:07<00:02, 395.91it/s]
Adding requests:  74%|███████▎  | 3018/4096 [00:07<00:02, 397.66it/s]
Adding requests:  75%|███████▍  | 3059/4096 [00:07<00:02, 398.96it/s]
Adding requests:  76%|███████▌  | 3100/4096 [00:08<00:02, 401.48it/s]
Adding requests:  77%|███████▋  | 3141/4096 [00:08<00:02, 401.78it/s]
Adding requests:  78%|███████▊  | 3182/4096 [00:08<00:02, 394.02it/s]
Adding requests:  79%|███████▊  | 3222/4096 [00:08<00:02, 392.40it/s]
Adding requests:  80%|███████▉  | 3262/4096 [00:08<00:02, 393.18it/s]
Adding requests:  81%|████████  | 3302/4096 [00:08<00:02, 382.07it/s]
Adding requests:  82%|████████▏ | 3341/4096 [00:08<00:01, 383.06it/s]
Adding requests:  83%|████████▎ | 3381/4096 [00:08<00:01, 387.00it/s]
Adding requests:  84%|████████▎ | 3421/4096 [00:08<00:01, 389.22it/s]
Adding requests:  84%|████████▍ | 3461/4096 [00:08<00:01, 389.23it/s]
Adding requests:  85%|████████▌ | 3500/4096 [00:09<00:01, 389.19it/s]
Adding requests:  86%|████████▋ | 3543/4096 [00:09<00:01, 399.10it/s]
Adding requests:  87%|████████▋ | 3583/4096 [00:09<00:01, 395.60it/s]
Adding requests:  88%|████████▊ | 3623/4096 [00:09<00:01, 396.63it/s]
Adding requests:  89%|████████▉ | 3663/4096 [00:09<00:01, 393.30it/s]
Adding requests:  90%|█████████ | 3703/4096 [00:09<00:01, 380.51it/s]
Adding requests:  91%|█████████▏| 3742/4096 [00:09<00:00, 381.16it/s]
Adding requests:  92%|█████████▏| 3781/4096 [00:09<00:00, 372.99it/s]
Adding requests:  93%|█████████▎| 3819/4096 [00:09<00:00, 365.80it/s]
Adding requests:  94%|█████████▍| 3858/4096 [00:10<00:00, 371.79it/s]
Adding requests:  95%|█████████▌| 3896/4096 [00:10<00:00, 372.60it/s]
Adding requests:  96%|█████████▌| 3934/4096 [00:10<00:00, 369.21it/s]
Adding requests:  97%|█████████▋| 3972/4096 [00:10<00:00, 371.56it/s]
Adding requests:  98%|█████████▊| 4011/4096 [00:10<00:00, 373.77it/s]
Adding requests:  99%|█████████▉| 4049/4096 [00:10<00:00, 373.31it/s]
Adding requests: 100%|█████████▉| 4087/4096 [00:10<00:00, 373.38it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 384.52it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 371/4096 [00:00<00:02, 1802.21it/s, est. speed input: 1845677.99 toks/s, output: 1802.28 toks/s]
Processed prompts:  13%|█▎        | 552/4096 [00:04<00:35, 100.75it/s, est. speed input: 127420.97 toks/s, output: 124.43 toks/s]   
Processed prompts:  15%|█▌        | 629/4096 [00:06<00:50, 68.68it/s, est. speed input: 92185.77 toks/s, output: 90.03 toks/s]   
Processed prompts:  16%|█▋        | 673/4096 [00:07<00:52, 65.68it/s, est. speed input: 87940.61 toks/s, output: 85.88 toks/s]
Processed prompts:  17%|█▋        | 702/4096 [00:08<00:57, 59.28it/s, est. speed input: 82753.26 toks/s, output: 80.81 toks/s]
Processed prompts:  18%|█▊        | 723/4096 [00:09<01:05, 51.50it/s, est. speed input: 77619.60 toks/s, output: 75.80 toks/s]
Processed prompts:  18%|█▊        | 755/4096 [00:10<01:09, 48.15it/s, est. speed input: 74432.25 toks/s, output: 72.69 toks/s]
Processed prompts:  19%|█▉        | 787/4096 [00:11<01:12, 45.65it/s, est. speed input: 71811.87 toks/s, output: 70.13 toks/s]
Processed prompts:  20%|█▉        | 819/4096 [00:12<01:15, 43.42it/s, est. speed input: 69440.65 toks/s, output: 67.81 toks/s]
Processed prompts:  21%|██        | 851/4096 [00:12<01:17, 41.72it/s, est. speed input: 67372.26 toks/s, output: 65.79 toks/s]
Processed prompts:  22%|██▏       | 883/4096 [00:13<01:19, 40.51it/s, est. speed input: 65576.06 toks/s, output: 64.04 toks/s]
Processed prompts:  22%|██▏       | 915/4096 [00:14<01:20, 39.67it/s, est. speed input: 64003.52 toks/s, output: 62.50 toks/s]
Processed prompts:  23%|██▎       | 947/4096 [00:15<01:20, 39.01it/s, est. speed input: 62585.41 toks/s, output: 61.12 toks/s]
Processed prompts:  24%|██▍       | 979/4096 [00:16<01:20, 38.59it/s, est. speed input: 61329.98 toks/s, output: 59.89 toks/s]
Processed prompts:  25%|██▍       | 1011/4096 [00:17<01:20, 38.23it/s, est. speed input: 60181.96 toks/s, output: 58.77 toks/s]
Processed prompts:  25%|██▌       | 1043/4096 [00:18<01:20, 37.98it/s, est. speed input: 59144.40 toks/s, output: 57.76 toks/s]
Processed prompts:  26%|██▌       | 1075/4096 [00:18<01:19, 37.84it/s, est. speed input: 58210.08 toks/s, output: 56.85 toks/s]
Processed prompts:  27%|██▋       | 1107/4096 [00:19<01:19, 37.74it/s, est. speed input: 57354.81 toks/s, output: 56.01 toks/s]
Processed prompts:  28%|██▊       | 1139/4096 [00:20<01:18, 37.62it/s, est. speed input: 56560.82 toks/s, output: 55.24 toks/s]
Processed prompts:  29%|██▊       | 1171/4096 [00:21<01:17, 37.53it/s, est. speed input: 55827.74 toks/s, output: 54.52 toks/s]
Processed prompts:  29%|██▉       | 1203/4096 [00:22<01:16, 37.62it/s, est. speed input: 55180.53 toks/s, output: 53.89 toks/s]
Processed prompts:  30%|███       | 1235/4096 [00:23<01:15, 37.77it/s, est. speed input: 54596.34 toks/s, output: 53.32 toks/s]
Processed prompts:  31%|███       | 1267/4096 [00:24<01:15, 37.66it/s, est. speed input: 54014.99 toks/s, output: 52.75 toks/s]
Processed prompts:  32%|███▏      | 1299/4096 [00:24<01:14, 37.55it/s, est. speed input: 53469.33 toks/s, output: 52.22 toks/s]
Processed prompts:  32%|███▏      | 1331/4096 [00:25<01:13, 37.71it/s, est. speed input: 52997.58 toks/s, output: 51.76 toks/s]
Processed prompts:  33%|███▎      | 1363/4096 [00:26<01:12, 37.57it/s, est. speed input: 52517.20 toks/s, output: 51.29 toks/s]
Processed prompts:  34%|███▍      | 1395/4096 [00:27<01:11, 37.55it/s, est. speed input: 52077.56 toks/s, output: 50.86 toks/s]
Processed prompts:  35%|███▍      | 1427/4096 [00:28<01:11, 37.46it/s, est. speed input: 51655.20 toks/s, output: 50.44 toks/s]
Processed prompts:  36%|███▌      | 1459/4096 [00:29<01:10, 37.59it/s, est. speed input: 51282.37 toks/s, output: 50.08 toks/s]
Processed prompts:  36%|███▋      | 1491/4096 [00:29<01:09, 37.50it/s, est. speed input: 50907.33 toks/s, output: 49.71 toks/s]
Processed prompts:  37%|███▋      | 1523/4096 [00:30<01:08, 37.63it/s, est. speed input: 50577.41 toks/s, output: 49.39 toks/s]
Processed prompts:  38%|███▊      | 1555/4096 [00:31<01:07, 37.78it/s, est. speed input: 50272.04 toks/s, output: 49.09 toks/s]
Processed prompts:  39%|███▊      | 1587/4096 [00:32<01:06, 37.59it/s, est. speed input: 49948.84 toks/s, output: 48.78 toks/s]
Processed prompts:  40%|███▉      | 1619/4096 [00:33<01:05, 37.77it/s, est. speed input: 49676.67 toks/s, output: 48.51 toks/s]
Processed prompts:  40%|████      | 1651/4096 [00:34<01:05, 37.55it/s, est. speed input: 49380.75 toks/s, output: 48.22 toks/s]
Processed prompts:  41%|████      | 1683/4096 [00:35<01:04, 37.44it/s, est. speed input: 49103.24 toks/s, output: 47.95 toks/s]
Processed prompts:  42%|████▏     | 1715/4096 [00:35<01:03, 37.53it/s, est. speed input: 48856.58 toks/s, output: 47.71 toks/s]
Processed prompts:  43%|████▎     | 1747/4096 [00:36<01:02, 37.68it/s, est. speed input: 48629.67 toks/s, output: 47.49 toks/s]
Processed prompts:  43%|████▎     | 1779/4096 [00:37<01:01, 37.52it/s, est. speed input: 48387.95 toks/s, output: 47.25 toks/s]
Processed prompts:  44%|████▍     | 1811/4096 [00:38<01:01, 37.41it/s, est. speed input: 48156.33 toks/s, output: 47.03 toks/s]
Processed prompts:  45%|████▍     | 1843/4096 [00:39<01:00, 37.36it/s, est. speed input: 47938.10 toks/s, output: 46.81 toks/s]
Processed prompts:  46%|████▌     | 1875/4096 [00:40<00:59, 37.50it/s, est. speed input: 47743.97 toks/s, output: 46.62 toks/s]
Processed prompts:  47%|████▋     | 1907/4096 [00:41<00:58, 37.40it/s, est. speed input: 47540.89 toks/s, output: 46.43 toks/s]
Processed prompts:  47%|████▋     | 1939/4096 [00:41<00:57, 37.34it/s, est. speed input: 47347.20 toks/s, output: 46.24 toks/s]
Processed prompts:  48%|████▊     | 1971/4096 [00:42<00:56, 37.45it/s, est. speed input: 47173.82 toks/s, output: 46.07 toks/s]
Processed prompts:  49%|████▉     | 2003/4096 [00:43<00:56, 37.33it/s, est. speed input: 46991.13 toks/s, output: 45.89 toks/s]
Processed prompts:  50%|████▉     | 2035/4096 [00:44<00:55, 37.28it/s, est. speed input: 46818.78 toks/s, output: 45.72 toks/s]
Processed prompts:  50%|█████     | 2067/4096 [00:45<00:54, 37.43it/s, est. speed input: 46667.13 toks/s, output: 45.57 toks/s]
Processed prompts:  51%|█████     | 2099/4096 [00:46<00:53, 37.36it/s, est. speed input: 46507.28 toks/s, output: 45.42 toks/s]
Processed prompts:  52%|█████▏    | 2131/4096 [00:47<00:52, 37.28it/s, est. speed input: 46351.33 toks/s, output: 45.26 toks/s]
Processed prompts:  53%|█████▎    | 2163/4096 [00:47<00:51, 37.25it/s, est. speed input: 46202.20 toks/s, output: 45.12 toks/s]
Processed prompts:  54%|█████▎    | 2195/4096 [00:48<00:50, 37.40it/s, est. speed input: 46071.76 toks/s, output: 44.99 toks/s]
Processed prompts:  54%|█████▍    | 2227/4096 [00:49<00:50, 37.32it/s, est. speed input: 45931.99 toks/s, output: 44.86 toks/s]
Processed prompts:  55%|█████▌    | 2259/4096 [00:50<00:49, 37.26it/s, est. speed input: 45796.97 toks/s, output: 44.72 toks/s]
Processed prompts:  56%|█████▌    | 2291/4096 [00:51<00:48, 37.24it/s, est. speed input: 45667.54 toks/s, output: 44.60 toks/s]
Processed prompts:  57%|█████▋    | 2323/4096 [00:52<00:47, 37.19it/s, est. speed input: 45540.13 toks/s, output: 44.47 toks/s]
Processed prompts:  57%|█████▋    | 2355/4096 [00:53<00:46, 37.13it/s, est. speed input: 45415.38 toks/s, output: 44.35 toks/s]
Processed prompts:  58%|█████▊    | 2387/4096 [00:53<00:46, 37.15it/s, est. speed input: 45298.62 toks/s, output: 44.24 toks/s]
Processed prompts:  59%|█████▉    | 2419/4096 [00:54<00:45, 37.09it/s, est. speed input: 45180.47 toks/s, output: 44.12 toks/s]
Processed prompts:  60%|█████▉    | 2451/4096 [00:55<00:44, 37.07it/s, est. speed input: 45067.82 toks/s, output: 44.01 toks/s]
Processed prompts:  61%|██████    | 2483/4096 [00:56<00:43, 37.06it/s, est. speed input: 44958.79 toks/s, output: 43.91 toks/s]
Processed prompts:  61%|██████▏   | 2515/4096 [00:57<00:42, 37.34it/s, est. speed input: 44870.45 toks/s, output: 43.82 toks/s]
Processed prompts:  62%|██████▏   | 2547/4096 [00:58<00:41, 37.26it/s, est. speed input: 44767.79 toks/s, output: 43.72 toks/s]
Processed prompts:  63%|██████▎   | 2579/4096 [00:59<00:40, 37.42it/s, est. speed input: 44681.23 toks/s, output: 43.63 toks/s]
Processed prompts:  64%|██████▎   | 2611/4096 [00:59<00:39, 37.30it/s, est. speed input: 44583.83 toks/s, output: 43.54 toks/s]
Processed prompts:  65%|██████▍   | 2643/4096 [01:00<00:39, 37.25it/s, est. speed input: 44490.72 toks/s, output: 43.45 toks/s]
Processed prompts:  65%|██████▌   | 2675/4096 [01:01<00:38, 37.20it/s, est. speed input: 44399.37 toks/s, output: 43.36 toks/s]
Processed prompts:  66%|██████▌   | 2707/4096 [01:02<00:37, 37.13it/s, est. speed input: 44309.00 toks/s, output: 43.27 toks/s]
Processed prompts:  67%|██████▋   | 2739/4096 [01:03<00:36, 37.33it/s, est. speed input: 44234.03 toks/s, output: 43.20 toks/s]
Processed prompts:  68%|██████▊   | 2771/4096 [01:04<00:35, 37.24it/s, est. speed input: 44149.26 toks/s, output: 43.11 toks/s]
Processed prompts:  68%|██████▊   | 2803/4096 [01:05<00:34, 37.14it/s, est. speed input: 44064.56 toks/s, output: 43.03 toks/s]
Processed prompts:  69%|██████▉   | 2835/4096 [01:06<00:33, 37.11it/s, est. speed input: 43984.14 toks/s, output: 42.95 toks/s]
Processed prompts:  70%|██████▉   | 2867/4096 [01:06<00:33, 37.05it/s, est. speed input: 43904.03 toks/s, output: 42.87 toks/s]
Processed prompts:  71%|███████   | 2899/4096 [01:07<00:31, 37.91it/s, est. speed input: 43870.34 toks/s, output: 42.84 toks/s]
Processed prompts:  72%|███████▏  | 2931/4096 [01:08<00:30, 37.63it/s, est. speed input: 43794.81 toks/s, output: 42.77 toks/s]
Processed prompts:  72%|███████▏  | 2963/4096 [01:09<00:30, 37.46it/s, est. speed input: 43721.97 toks/s, output: 42.70 toks/s]
Processed prompts:  73%|███████▎  | 2995/4096 [01:10<00:29, 37.31it/s, est. speed input: 43649.83 toks/s, output: 42.63 toks/s]
Processed prompts:  74%|███████▍  | 3027/4096 [01:11<00:28, 37.20it/s, est. speed input: 43578.72 toks/s, output: 42.56 toks/s]
Processed prompts:  75%|███████▍  | 3059/4096 [01:11<00:27, 37.11it/s, est. speed input: 43509.07 toks/s, output: 42.49 toks/s]
Processed prompts:  75%|███████▌  | 3091/4096 [01:12<00:27, 37.07it/s, est. speed input: 43442.00 toks/s, output: 42.42 toks/s]
Processed prompts:  76%|███████▌  | 3123/4096 [01:13<00:26, 37.04it/s, est. speed input: 43376.50 toks/s, output: 42.36 toks/s]
Processed prompts:  77%|███████▋  | 3155/4096 [01:14<00:25, 37.00it/s, est. speed input: 43311.58 toks/s, output: 42.30 toks/s]
Processed prompts:  78%|███████▊  | 3187/4096 [01:15<00:24, 36.94it/s, est. speed input: 43246.80 toks/s, output: 42.23 toks/s]
Processed prompts:  79%|███████▊  | 3219/4096 [01:16<00:23, 36.89it/s, est. speed input: 43183.07 toks/s, output: 42.17 toks/s]
Processed prompts:  79%|███████▉  | 3251/4096 [01:17<00:22, 36.88it/s, est. speed input: 43122.00 toks/s, output: 42.11 toks/s]
Processed prompts:  80%|████████  | 3283/4096 [01:18<00:22, 36.86it/s, est. speed input: 43061.65 toks/s, output: 42.05 toks/s]
Processed prompts:  81%|████████  | 3315/4096 [01:18<00:21, 36.88it/s, est. speed input: 43003.84 toks/s, output: 42.00 toks/s]
Processed prompts:  82%|████████▏ | 3347/4096 [01:19<00:20, 36.86it/s, est. speed input: 42946.29 toks/s, output: 41.94 toks/s]
Processed prompts:  82%|████████▏ | 3379/4096 [01:20<00:19, 36.83it/s, est. speed input: 42888.76 toks/s, output: 41.88 toks/s]
Processed prompts:  83%|████████▎ | 3411/4096 [01:21<00:18, 36.81it/s, est. speed input: 42832.84 toks/s, output: 41.83 toks/s]
Processed prompts:  84%|████████▍ | 3443/4096 [01:22<00:17, 36.78it/s, est. speed input: 42777.52 toks/s, output: 41.77 toks/s]
Processed prompts:  85%|████████▍ | 3475/4096 [01:23<00:16, 36.79it/s, est. speed input: 42724.60 toks/s, output: 41.72 toks/s]
Processed prompts:  86%|████████▌ | 3507/4096 [01:24<00:16, 36.81it/s, est. speed input: 42673.06 toks/s, output: 41.67 toks/s]
Processed prompts:  86%|████████▋ | 3539/4096 [01:25<00:15, 37.04it/s, est. speed input: 42631.27 toks/s, output: 41.63 toks/s]
Processed prompts:  87%|████████▋ | 3571/4096 [01:25<00:14, 36.96it/s, est. speed input: 42580.64 toks/s, output: 41.58 toks/s]
Processed prompts:  88%|████████▊ | 3603/4096 [01:26<00:13, 36.91it/s, est. speed input: 42531.58 toks/s, output: 41.53 toks/s]
Processed prompts:  89%|████████▊ | 3635/4096 [01:27<00:12, 36.86it/s, est. speed input: 42482.85 toks/s, output: 41.49 toks/s]
Processed prompts:  90%|████████▉ | 3667/4096 [01:28<00:11, 37.09it/s, est. speed input: 42444.83 toks/s, output: 41.45 toks/s]
Processed prompts:  90%|█████████ | 3699/4096 [01:29<00:10, 37.00it/s, est. speed input: 42398.61 toks/s, output: 41.40 toks/s]
Processed prompts:  91%|█████████ | 3731/4096 [01:30<00:09, 36.92it/s, est. speed input: 42352.32 toks/s, output: 41.36 toks/s]
Processed prompts:  92%|█████████▏| 3763/4096 [01:31<00:09, 36.88it/s, est. speed input: 42307.71 toks/s, output: 41.32 toks/s]
Processed prompts:  93%|█████████▎| 3795/4096 [01:31<00:08, 36.85it/s, est. speed input: 42263.61 toks/s, output: 41.27 toks/s]
Processed prompts:  93%|█████████▎| 3827/4096 [01:32<00:07, 36.83it/s, est. speed input: 42220.59 toks/s, output: 41.23 toks/s]
Processed prompts:  94%|█████████▍| 3859/4096 [01:33<00:06, 36.81it/s, est. speed input: 42178.05 toks/s, output: 41.19 toks/s]
Processed prompts:  95%|█████████▍| 3891/4096 [01:34<00:05, 36.81it/s, est. speed input: 42136.70 toks/s, output: 41.15 toks/s]
Processed prompts:  96%|█████████▌| 3923/4096 [01:35<00:04, 37.44it/s, est. speed input: 42118.00 toks/s, output: 41.13 toks/s]
Processed prompts:  97%|█████████▋| 3955/4096 [01:36<00:03, 37.22it/s, est. speed input: 42076.81 toks/s, output: 41.09 toks/s]
Processed prompts:  97%|█████████▋| 3987/4096 [01:37<00:02, 37.37it/s, est. speed input: 42046.70 toks/s, output: 41.06 toks/s]
Processed prompts:  98%|█████████▊| 4019/4096 [01:37<00:02, 37.21it/s, est. speed input: 42008.36 toks/s, output: 41.02 toks/s]
Processed prompts:  99%|█████████▉| 4051/4096 [01:38<00:01, 37.37it/s, est. speed input: 41979.62 toks/s, output: 41.00 toks/s]
Processed prompts: 100%|█████████▉| 4083/4096 [01:39<00:00, 45.15it/s, est. speed input: 42155.72 toks/s, output: 41.17 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:39<00:00, 45.15it/s, est. speed input: 42289.67 toks/s, output: 41.30 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:39<00:00, 41.30it/s, est. speed input: 42289.67 toks/s, output: 41.30 toks/s]
[rank0]:[W126 12:32:05.991828768 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 12:32:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:32:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1364190) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1364190) WARNING 01-26 12:33:15 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     def forward(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     raise e
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/tmp/torchinductor_root/kv/ckvsudmg3oshri77cui5ty5sl2ycn552zf2cmu7poci642f5nfto.py", line 1093, in call
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 10)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 233, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) ERROR 01-26 12:33:23 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered

STDERR:
[2026-01-26 12:32:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:32:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:32:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:32:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:32:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:32:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:32:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:32:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:32:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:33:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:33:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:33:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:33:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:33:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:33:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:33:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:33:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:33:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1364190) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1364190) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=1364190) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=1364190) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=1364190) 
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1364190) [2026-01-26 12:33:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1364190) [rank0]:W0126 12:33:21.277000 1364190 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1364190) [rank0]:W0126 12:33:21.355000 1364190 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1364190) [rank0]:W0126 12:33:22.678000 1364190 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1364190) [rank0]:W0126 12:33:22.800000 1364190 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1364190) Process EngineCore_DP0:
(EngineCore_DP0 pid=1364190) Traceback (most recent call last):
(EngineCore_DP0 pid=1364190)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1364190)     self.run()
(EngineCore_DP0 pid=1364190)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1364190)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1364190)     raise e
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1364190)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1364190)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1364190)     super().__init__(
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1364190)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1364190)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1364190)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1364190)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1364190)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1364190)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1364190)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1364190)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1364190)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1364190)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1364190)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1364190)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1364190)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1364190)     outputs = self.model(
(EngineCore_DP0 pid=1364190)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1364190)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1364190)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1364190)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1364190)     hidden_states = self.model(
(EngineCore_DP0 pid=1364190)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1364190)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1364190)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1364190)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1364190)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1364190)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1364190)     def forward(
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1364190)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1364190)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1364190)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1364190)     raise e
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1364190)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1364190)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1364190)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1364190)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1364190)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1364190)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1364190)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1364190)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1364190)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1364190)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1364190)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1364190)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1364190)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1364190)                             ^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1364190)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1364190)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1364190)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1364190)     out = model(new_inputs)
(EngineCore_DP0 pid=1364190)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/tmp/torchinductor_root/kv/ckvsudmg3oshri77cui5ty5sl2ycn552zf2cmu7poci642f5nfto.py", line 1093, in call
(EngineCore_DP0 pid=1364190)     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 10)
(EngineCore_DP0 pid=1364190)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1364190)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1364190)     return fn(input, L)
(EngineCore_DP0 pid=1364190)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 233, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1364190)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1364190)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1364190)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1364190)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1364190)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1364190)     self._init_handles()
(EngineCore_DP0 pid=1364190)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1364190)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1364190)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1364190) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 12:33:24.414817257 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 15:37:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:37:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1546482) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1546482) WARNING 01-26 15:37:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.23 requests/s, 11401.76 total tokens/s, 22.23 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 15:37:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:37:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:37:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:37:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:37:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:37:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:37:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:37:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:37:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:37:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:37:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:37:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:37:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:37:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:37:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:37:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:37:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.24it/s]
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1546482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1546482) 
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1546482) [2026-01-26 15:37:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1546482) 2026-01-26 15:37:43,967 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1546482) 2026-01-26 15:37:44,030 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1546482) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.81it/s]
(EngineCore_DP0 pid=1546482) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  26%|██▌       | 33/128 [00:00<00:00, 325.32it/s]
Adding requests:  76%|███████▌  | 97/128 [00:00<00:00, 508.36it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 521.26it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:21,  5.80it/s, est. speed input: 2970.56 toks/s, output: 5.80 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:08, 15.12it/s, est. speed input: 6910.99 toks/s, output: 13.50 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 18.82it/s, est. speed input: 8492.72 toks/s, output: 16.59 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 20.73it/s, est. speed input: 9349.37 toks/s, output: 18.26 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 21.83it/s, est. speed input: 9884.72 toks/s, output: 19.31 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 22.50it/s, est. speed input: 10249.90 toks/s, output: 20.02 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 22.86it/s, est. speed input: 10503.38 toks/s, output: 20.51 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 23.16it/s, est. speed input: 10704.58 toks/s, output: 20.91 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 23.36it/s, est. speed input: 10863.86 toks/s, output: 21.22 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 23.49it/s, est. speed input: 10990.78 toks/s, output: 21.47 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.58it/s, est. speed input: 11095.87 toks/s, output: 21.67 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:03, 23.65it/s, est. speed input: 11184.54 toks/s, output: 21.84 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 23.72it/s, est. speed input: 11261.56 toks/s, output: 22.00 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 23.73it/s, est. speed input: 11324.86 toks/s, output: 22.12 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 23.74it/s, est. speed input: 11380.04 toks/s, output: 22.23 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 23.72it/s, est. speed input: 11425.77 toks/s, output: 22.32 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 23.75it/s, est. speed input: 11469.77 toks/s, output: 22.40 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 23.80it/s, est. speed input: 11511.92 toks/s, output: 22.48 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 23.81it/s, est. speed input: 11547.23 toks/s, output: 22.55 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 23.84it/s, est. speed input: 11581.41 toks/s, output: 22.62 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 23.84it/s, est. speed input: 11610.25 toks/s, output: 22.68 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 23.81it/s, est. speed input: 11635.17 toks/s, output: 22.72 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:02<00:02, 23.81it/s, est. speed input: 11658.92 toks/s, output: 22.77 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 23.77it/s, est. speed input: 11678.14 toks/s, output: 22.81 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 23.72it/s, est. speed input: 11694.27 toks/s, output: 22.84 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.73it/s, est. speed input: 11712.28 toks/s, output: 22.88 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.75it/s, est. speed input: 11729.31 toks/s, output: 22.91 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 23.75it/s, est. speed input: 11744.82 toks/s, output: 22.94 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 23.78it/s, est. speed input: 11760.46 toks/s, output: 22.97 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 23.78it/s, est. speed input: 11774.42 toks/s, output: 23.00 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:03<00:01, 23.76it/s, est. speed input: 11785.89 toks/s, output: 23.02 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.74it/s, est. speed input: 11796.90 toks/s, output: 23.04 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.75it/s, est. speed input: 11808.12 toks/s, output: 23.06 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.74it/s, est. speed input: 11817.72 toks/s, output: 23.08 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 23.74it/s, est. speed input: 11827.37 toks/s, output: 23.10 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 23.74it/s, est. speed input: 11836.47 toks/s, output: 23.12 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 23.74it/s, est. speed input: 11845.00 toks/s, output: 23.13 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 23.73it/s, est. speed input: 11852.83 toks/s, output: 23.15 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:04<00:00, 23.75it/s, est. speed input: 11861.05 toks/s, output: 23.17 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 23.76it/s, est. speed input: 11869.00 toks/s, output: 23.18 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 23.72it/s, est. speed input: 11874.61 toks/s, output: 23.19 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.73it/s, est. speed input: 11881.31 toks/s, output: 23.21 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.75it/s, est. speed input: 11888.10 toks/s, output: 23.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.75it/s, est. speed input: 11890.41 toks/s, output: 23.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.22it/s, est. speed input: 11890.41 toks/s, output: 23.22 toks/s]
[rank0]:[W126 15:37:52.966008241 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 15:37:54
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:38:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1547787) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1547787) WARNING 01-26 15:38:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.54 requests/s, 16952.18 total tokens/s, 16.54 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 15:38:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:38:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:38:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:38:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:38:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:38:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:38:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:38:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:38:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:38:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:38:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:38:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.23it/s]
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1547787) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1547787) 
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1547787) [2026-01-26 15:38:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1547787) 2026-01-26 15:38:38,111 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1547787) 2026-01-26 15:38:38,172 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1547787) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.08it/s]
(EngineCore_DP0 pid=1547787) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 11.19it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▋        | 21/128 [00:00<00:00, 209.41it/s]
Adding requests:  48%|████▊     | 62/128 [00:00<00:00, 324.31it/s]
Adding requests:  77%|███████▋  | 98/128 [00:00<00:00, 338.61it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 334.18it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 22.52it/s, est. speed input: 23070.71 toks/s, output: 22.52 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:06, 19.24it/s, est. speed input: 20140.59 toks/s, output: 19.67 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 18.57it/s, est. speed input: 19529.29 toks/s, output: 19.07 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:06, 18.16it/s, est. speed input: 19164.69 toks/s, output: 18.71 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:06, 17.92it/s, est. speed input: 18932.27 toks/s, output: 18.49 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 17.74it/s, est. speed input: 18759.42 toks/s, output: 18.32 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 17.60it/s, est. speed input: 18622.38 toks/s, output: 18.19 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:06, 17.38it/s, est. speed input: 18467.94 toks/s, output: 18.03 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 17.40it/s, est. speed input: 18403.71 toks/s, output: 17.97 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 17.38it/s, est. speed input: 18341.93 toks/s, output: 17.91 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 17.36it/s, est. speed input: 18289.51 toks/s, output: 17.86 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.40it/s, est. speed input: 18260.16 toks/s, output: 17.83 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 17.39it/s, est. speed input: 18225.07 toks/s, output: 17.80 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 17.35it/s, est. speed input: 18188.36 toks/s, output: 17.76 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 17.36it/s, est. speed input: 18162.58 toks/s, output: 17.74 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 17.32it/s, est. speed input: 18130.70 toks/s, output: 17.71 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:05, 17.33it/s, est. speed input: 18111.45 toks/s, output: 17.69 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 17.28it/s, est. speed input: 18082.66 toks/s, output: 17.66 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 17.30it/s, est. speed input: 18065.75 toks/s, output: 17.64 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 17.29it/s, est. speed input: 18046.80 toks/s, output: 17.62 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.36it/s, est. speed input: 18042.01 toks/s, output: 17.62 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.37it/s, est. speed input: 18032.77 toks/s, output: 17.61 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 17.35it/s, est. speed input: 18018.35 toks/s, output: 17.60 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 17.30it/s, est. speed input: 18002.09 toks/s, output: 17.58 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 17.32it/s, est. speed input: 17993.63 toks/s, output: 17.57 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 17.27it/s, est. speed input: 17976.70 toks/s, output: 17.56 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 17.30it/s, est. speed input: 17970.38 toks/s, output: 17.55 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 17.28it/s, est. speed input: 17959.07 toks/s, output: 17.54 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.25it/s, est. speed input: 17946.63 toks/s, output: 17.53 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.31it/s, est. speed input: 17944.17 toks/s, output: 17.52 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.34it/s, est. speed input: 17940.31 toks/s, output: 17.52 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.35it/s, est. speed input: 17935.54 toks/s, output: 17.51 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 17.29it/s, est. speed input: 17924.21 toks/s, output: 17.50 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 17.28it/s, est. speed input: 17917.57 toks/s, output: 17.50 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 17.31it/s, est. speed input: 17913.94 toks/s, output: 17.49 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 17.32it/s, est. speed input: 17910.11 toks/s, output: 17.49 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 17.31it/s, est. speed input: 17903.99 toks/s, output: 17.48 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.26it/s, est. speed input: 17894.99 toks/s, output: 17.48 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.32it/s, est. speed input: 17894.55 toks/s, output: 17.48 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.34it/s, est. speed input: 17892.33 toks/s, output: 17.47 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 17.35it/s, est. speed input: 17889.65 toks/s, output: 17.47 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 17.30it/s, est. speed input: 17882.69 toks/s, output: 17.46 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 17.29it/s, est. speed input: 17878.41 toks/s, output: 17.46 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 17.29it/s, est. speed input: 17874.73 toks/s, output: 17.46 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.32it/s, est. speed input: 17872.82 toks/s, output: 17.45 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.27it/s, est. speed input: 17866.39 toks/s, output: 17.45 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.27it/s, est. speed input: 17862.31 toks/s, output: 17.44 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.29it/s, est. speed input: 17860.16 toks/s, output: 17.44 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.29it/s, est. speed input: 17856.96 toks/s, output: 17.44 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.32it/s, est. speed input: 17856.30 toks/s, output: 17.44 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 17.25it/s, est. speed input: 17849.37 toks/s, output: 17.43 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 17.24it/s, est. speed input: 17844.83 toks/s, output: 17.43 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.31it/s, est. speed input: 17845.70 toks/s, output: 17.43 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.33it/s, est. speed input: 17844.85 toks/s, output: 17.43 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.27it/s, est. speed input: 17839.09 toks/s, output: 17.42 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.24it/s, est. speed input: 17834.71 toks/s, output: 17.42 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.26it/s, est. speed input: 17832.59 toks/s, output: 17.41 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.29it/s, est. speed input: 17831.90 toks/s, output: 17.41 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.26it/s, est. speed input: 17828.20 toks/s, output: 17.41 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 17.26it/s, est. speed input: 17825.20 toks/s, output: 17.41 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:07<00:00, 17.26it/s, est. speed input: 17822.80 toks/s, output: 17.40 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.29it/s, est. speed input: 17821.91 toks/s, output: 17.40 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.32it/s, est. speed input: 17822.02 toks/s, output: 17.40 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.32it/s, est. speed input: 17822.02 toks/s, output: 17.40 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.40it/s, est. speed input: 17822.02 toks/s, output: 17.40 toks/s]
[rank0]:[W126 15:38:48.330682429 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 15:38:50
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:38:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1549063) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1549063) WARNING 01-26 15:39:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.49 requests/s, 18953.72 total tokens/s, 18.49 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 15:38:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:38:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:38:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:38:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:38:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:38:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:38:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:38:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:39:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:39:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:39:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:39:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:39:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:39:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:39:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:39:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:39:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.25it/s]
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1549063) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.36it/s]
(EngineCore_DP0 pid=1549063) 
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1549063) [2026-01-26 15:39:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1549063) 2026-01-26 15:39:34,016 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1549063) 2026-01-26 15:39:34,055 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1549063) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.68it/s]
(EngineCore_DP0 pid=1549063) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  5.77it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.54it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   7%|▋         | 19/256 [00:00<00:01, 184.82it/s]
Adding requests:  23%|██▎       | 58/256 [00:00<00:00, 303.68it/s]
Adding requests:  38%|███▊      | 96/256 [00:00<00:00, 334.12it/s]
Adding requests:  52%|█████▏    | 134/256 [00:00<00:00, 349.80it/s]
Adding requests:  68%|██████▊   | 174/256 [00:00<00:00, 365.75it/s]
Adding requests:  84%|████████▎ | 214/256 [00:00<00:00, 374.60it/s]
Adding requests:  99%|█████████▉| 253/256 [00:00<00:00, 376.76it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 354.50it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 14/256 [00:00<00:01, 122.54it/s, est. speed input: 125505.20 toks/s, output: 122.55 toks/s]
Processed prompts:  11%|█         | 27/256 [00:00<00:07, 31.05it/s, est. speed input: 35968.91 toks/s, output: 35.13 toks/s]   
Processed prompts:  13%|█▎        | 34/256 [00:01<00:09, 24.37it/s, est. speed input: 29097.24 toks/s, output: 28.41 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:01<00:09, 23.96it/s, est. speed input: 28187.17 toks/s, output: 27.53 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:01<00:09, 22.55it/s, est. speed input: 26969.32 toks/s, output: 26.34 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:01<00:10, 20.25it/s, est. speed input: 25506.73 toks/s, output: 24.91 toks/s]
Processed prompts:  19%|█▉        | 49/256 [00:01<00:09, 21.54it/s, est. speed input: 25696.02 toks/s, output: 25.09 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:10, 19.17it/s, est. speed input: 24575.70 toks/s, output: 24.00 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:02<00:09, 20.74it/s, est. speed input: 24752.37 toks/s, output: 24.17 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:10, 18.33it/s, est. speed input: 23825.57 toks/s, output: 23.27 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:02<00:09, 20.16it/s, est. speed input: 24008.94 toks/s, output: 23.45 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:10, 17.89it/s, est. speed input: 23256.77 toks/s, output: 22.71 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:10, 18.08it/s, est. speed input: 23111.24 toks/s, output: 22.57 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:03<00:10, 18.25it/s, est. speed input: 22978.70 toks/s, output: 22.44 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:03<00:10, 18.31it/s, est. speed input: 22838.34 toks/s, output: 22.30 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:10, 18.31it/s, est. speed input: 22701.27 toks/s, output: 22.17 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:03<00:09, 18.32it/s, est. speed input: 22574.48 toks/s, output: 22.05 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:09, 18.34it/s, est. speed input: 22457.15 toks/s, output: 21.93 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 18.40it/s, est. speed input: 22352.69 toks/s, output: 21.83 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:09, 18.43it/s, est. speed input: 22252.07 toks/s, output: 21.73 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:09, 18.50it/s, est. speed input: 22164.10 toks/s, output: 21.64 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:09, 18.50it/s, est. speed input: 22074.61 toks/s, output: 21.56 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:04<00:09, 18.54it/s, est. speed input: 21994.05 toks/s, output: 21.48 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:04<00:09, 18.57it/s, est. speed input: 21918.39 toks/s, output: 21.40 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:04<00:08, 18.55it/s, est. speed input: 21842.07 toks/s, output: 21.33 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:04<00:08, 18.49it/s, est. speed input: 21765.81 toks/s, output: 21.26 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:08, 18.44it/s, est. speed input: 21691.48 toks/s, output: 21.18 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 18.44it/s, est. speed input: 21624.38 toks/s, output: 21.12 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:04<00:08, 18.50it/s, est. speed input: 21565.88 toks/s, output: 21.06 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:08, 18.50it/s, est. speed input: 21506.42 toks/s, output: 21.00 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:08, 18.50it/s, est. speed input: 21449.83 toks/s, output: 20.95 toks/s]
Processed prompts:  41%|████      | 104/256 [00:04<00:08, 18.56it/s, est. speed input: 21399.86 toks/s, output: 20.90 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:05<00:08, 18.57it/s, est. speed input: 21349.88 toks/s, output: 20.85 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:05<00:07, 18.59it/s, est. speed input: 21303.47 toks/s, output: 20.80 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:05<00:07, 18.54it/s, est. speed input: 21253.45 toks/s, output: 20.76 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:07, 18.46it/s, est. speed input: 21202.06 toks/s, output: 20.70 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:07, 18.41it/s, est. speed input: 21153.08 toks/s, output: 20.66 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:05<00:07, 18.41it/s, est. speed input: 21108.61 toks/s, output: 20.61 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:05<00:07, 18.46it/s, est. speed input: 21069.81 toks/s, output: 20.58 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:07, 18.48it/s, est. speed input: 21030.52 toks/s, output: 20.54 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:05<00:07, 18.53it/s, est. speed input: 20995.96 toks/s, output: 20.50 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:06<00:07, 18.51it/s, est. speed input: 20958.58 toks/s, output: 20.47 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:06<00:07, 18.50it/s, est. speed input: 20922.78 toks/s, output: 20.43 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:06<00:06, 18.53it/s, est. speed input: 20890.53 toks/s, output: 20.40 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:06<00:06, 18.45it/s, est. speed input: 20852.84 toks/s, output: 20.36 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:06<00:06, 18.46it/s, est. speed input: 20820.82 toks/s, output: 20.33 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:06<00:06, 18.40it/s, est. speed input: 20785.52 toks/s, output: 20.30 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:06, 18.40it/s, est. speed input: 20754.01 toks/s, output: 20.27 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:06<00:06, 18.39it/s, est. speed input: 20722.89 toks/s, output: 20.24 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:06<00:06, 18.43it/s, est. speed input: 20695.49 toks/s, output: 20.21 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:07<00:06, 18.49it/s, est. speed input: 20670.81 toks/s, output: 20.19 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:07<00:06, 18.46it/s, est. speed input: 20643.07 toks/s, output: 20.16 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:07<00:05, 18.53it/s, est. speed input: 20620.74 toks/s, output: 20.14 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:07<00:05, 18.49it/s, est. speed input: 20594.41 toks/s, output: 20.11 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:07<00:05, 18.45it/s, est. speed input: 20568.46 toks/s, output: 20.09 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:07<00:05, 18.44it/s, est. speed input: 20543.92 toks/s, output: 20.06 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:07<00:05, 18.40it/s, est. speed input: 20518.13 toks/s, output: 20.04 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:05, 18.45it/s, est. speed input: 20497.46 toks/s, output: 20.02 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:07<00:05, 18.43it/s, est. speed input: 20474.35 toks/s, output: 19.99 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:08<00:05, 18.46it/s, est. speed input: 20454.39 toks/s, output: 19.97 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:08<00:05, 18.45it/s, est. speed input: 20433.07 toks/s, output: 19.95 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:08<00:04, 18.45it/s, est. speed input: 20412.87 toks/s, output: 19.93 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:08<00:04, 18.51it/s, est. speed input: 20395.87 toks/s, output: 19.92 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:08<00:04, 18.46it/s, est. speed input: 20375.23 toks/s, output: 19.90 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:08<00:04, 18.47it/s, est. speed input: 20356.71 toks/s, output: 19.88 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:08<00:04, 18.44it/s, est. speed input: 20337.56 toks/s, output: 19.86 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:08<00:04, 18.44it/s, est. speed input: 20319.60 toks/s, output: 19.84 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:08<00:04, 18.38it/s, est. speed input: 20299.13 toks/s, output: 19.82 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:08<00:04, 18.45it/s, est. speed input: 20284.42 toks/s, output: 19.81 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:09<00:04, 18.52it/s, est. speed input: 20270.94 toks/s, output: 19.80 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:09<00:03, 18.51it/s, est. speed input: 20255.12 toks/s, output: 19.78 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:09<00:03, 18.53it/s, est. speed input: 20240.99 toks/s, output: 19.77 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:09<00:03, 18.50it/s, est. speed input: 20225.29 toks/s, output: 19.75 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:09<00:03, 18.44it/s, est. speed input: 20208.35 toks/s, output: 19.73 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:09<00:03, 18.50it/s, est. speed input: 20195.81 toks/s, output: 19.72 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:09<00:03, 18.45it/s, est. speed input: 20179.77 toks/s, output: 19.71 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:09<00:03, 18.45it/s, est. speed input: 20165.83 toks/s, output: 19.69 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:09<00:03, 18.47it/s, est. speed input: 20152.56 toks/s, output: 19.68 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:10<00:03, 18.46it/s, est. speed input: 20139.01 toks/s, output: 19.67 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:10<00:03, 18.47it/s, est. speed input: 20126.32 toks/s, output: 19.65 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:10<00:02, 20.26it/s, est. speed input: 20181.30 toks/s, output: 19.71 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:10<00:02, 19.75it/s, est. speed input: 20166.82 toks/s, output: 19.69 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:10<00:02, 19.39it/s, est. speed input: 20153.81 toks/s, output: 19.68 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:10<00:02, 19.11it/s, est. speed input: 20140.44 toks/s, output: 19.67 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:10<00:02, 18.90it/s, est. speed input: 20126.95 toks/s, output: 19.66 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:10<00:02, 18.79it/s, est. speed input: 20115.57 toks/s, output: 19.64 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:11<00:02, 18.66it/s, est. speed input: 20102.22 toks/s, output: 19.63 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:11<00:02, 18.56it/s, est. speed input: 20089.05 toks/s, output: 19.62 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:11<00:01, 18.48it/s, est. speed input: 20075.97 toks/s, output: 19.61 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:11<00:01, 18.53it/s, est. speed input: 20066.49 toks/s, output: 19.60 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:11<00:01, 18.49it/s, est. speed input: 20054.98 toks/s, output: 19.58 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:11<00:01, 18.48it/s, est. speed input: 20044.06 toks/s, output: 19.57 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:11<00:01, 18.49it/s, est. speed input: 20033.91 toks/s, output: 19.56 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:11<00:01, 18.46it/s, est. speed input: 20022.71 toks/s, output: 19.55 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:11<00:01, 18.46it/s, est. speed input: 20012.68 toks/s, output: 19.54 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:11<00:01, 18.41it/s, est. speed input: 20001.09 toks/s, output: 19.53 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:12<00:01, 18.38it/s, est. speed input: 19989.67 toks/s, output: 19.52 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:12<00:00, 18.37it/s, est. speed input: 19979.03 toks/s, output: 19.51 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:12<00:00, 18.39it/s, est. speed input: 19969.31 toks/s, output: 19.50 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:12<00:00, 18.46it/s, est. speed input: 19961.38 toks/s, output: 19.49 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:12<00:00, 18.46it/s, est. speed input: 19952.34 toks/s, output: 19.48 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:12<00:00, 18.55it/s, est. speed input: 19946.09 toks/s, output: 19.48 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:12<00:00, 18.57it/s, est. speed input: 19938.57 toks/s, output: 19.47 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:12<00:00, 18.53it/s, est. speed input: 19929.70 toks/s, output: 19.46 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:12<00:00, 18.58it/s, est. speed input: 19923.35 toks/s, output: 19.46 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:13<00:00, 18.53it/s, est. speed input: 19914.43 toks/s, output: 19.45 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 18.53it/s, est. speed input: 19980.15 toks/s, output: 19.51 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:13<00:00, 19.51it/s, est. speed input: 19980.15 toks/s, output: 19.51 toks/s]
[rank0]:[W126 15:39:50.515419160 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 15:39:52
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:40:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1550428) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1550428) WARNING 01-26 15:40:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.12 requests/s, 19599.66 total tokens/s, 19.12 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 15:40:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:40:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:40:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:40:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:40:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:40:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:40:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:40:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:40:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:40:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:40:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:40:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:40:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:40:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:40:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:40:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:40:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.24it/s]
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1550428) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1550428) 
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1550428) [2026-01-26 15:40:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1550428) 2026-01-26 15:40:38,033 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1550428) 2026-01-26 15:40:38,090 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1550428) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  6.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.09it/s]
(EngineCore_DP0 pid=1550428) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  3.34it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  2.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.40it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  3.25it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 20/512 [00:00<00:02, 193.69it/s]
Adding requests:  12%|█▏        | 61/512 [00:00<00:01, 315.19it/s]
Adding requests:  19%|█▉        | 97/512 [00:00<00:01, 334.98it/s]
Adding requests:  26%|██▋       | 135/512 [00:00<00:01, 352.42it/s]
Adding requests:  34%|███▍      | 175/512 [00:00<00:00, 366.92it/s]
Adding requests:  42%|████▏     | 216/512 [00:00<00:00, 377.62it/s]
Adding requests:  50%|████▉     | 255/512 [00:00<00:00, 379.64it/s]
Adding requests:  58%|█████▊    | 295/512 [00:00<00:00, 383.21it/s]
Adding requests:  66%|██████▌   | 337/512 [00:00<00:00, 392.09it/s]
Adding requests:  74%|███████▎  | 377/512 [00:01<00:00, 393.90it/s]
Adding requests:  82%|████████▏ | 419/512 [00:01<00:00, 400.55it/s]
Adding requests:  90%|████████▉ | 460/512 [00:01<00:00, 396.14it/s]
Adding requests:  98%|█████████▊| 502/512 [00:01<00:00, 403.01it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 379.63it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:00<00:03, 129.87it/s, est. speed input: 133000.26 toks/s, output: 129.87 toks/s]
Processed prompts:   8%|▊         | 39/512 [00:00<00:11, 40.56it/s, est. speed input: 48154.09 toks/s, output: 47.02 toks/s]   
Processed prompts:   9%|▉         | 46/512 [00:01<00:15, 30.22it/s, est. speed input: 37833.09 toks/s, output: 36.95 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:01<00:16, 28.81it/s, est. speed input: 35978.80 toks/s, output: 35.14 toks/s]
Processed prompts:  11%|█         | 55/512 [00:01<00:17, 26.32it/s, est. speed input: 33902.39 toks/s, output: 33.11 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:01<00:19, 22.99it/s, est. speed input: 31677.03 toks/s, output: 30.93 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:02<00:20, 21.95it/s, est. speed input: 30474.43 toks/s, output: 29.76 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:20, 21.27it/s, est. speed input: 29533.44 toks/s, output: 28.84 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:21, 20.71it/s, est. speed input: 28724.85 toks/s, output: 28.05 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:21, 20.17it/s, est. speed input: 27987.36 toks/s, output: 27.33 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:21, 19.77it/s, est. speed input: 27353.58 toks/s, output: 26.71 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:03<00:21, 19.58it/s, est. speed input: 26835.04 toks/s, output: 26.21 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:21, 19.57it/s, est. speed input: 26415.30 toks/s, output: 25.80 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:21, 19.49it/s, est. speed input: 26025.54 toks/s, output: 25.42 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:21, 19.30it/s, est. speed input: 25646.74 toks/s, output: 25.05 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:21, 19.15it/s, est. speed input: 25304.82 toks/s, output: 24.71 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:04<00:21, 19.15it/s, est. speed input: 25020.12 toks/s, output: 24.43 toks/s]
Processed prompts:  21%|██        | 106/512 [00:04<00:21, 19.23it/s, est. speed input: 24777.61 toks/s, output: 24.20 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:04<00:20, 19.21it/s, est. speed input: 24544.02 toks/s, output: 23.97 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:20, 19.17it/s, est. speed input: 24325.25 toks/s, output: 23.75 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:05<00:20, 19.12it/s, est. speed input: 24119.89 toks/s, output: 23.55 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:05<00:20, 19.12it/s, est. speed input: 23938.33 toks/s, output: 23.38 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:05<00:20, 19.14it/s, est. speed input: 23773.57 toks/s, output: 23.22 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:05<00:19, 19.15it/s, est. speed input: 23619.67 toks/s, output: 23.07 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:19, 19.11it/s, est. speed input: 23470.75 toks/s, output: 22.92 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:06<00:19, 19.09it/s, est. speed input: 23333.63 toks/s, output: 22.79 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:06<00:19, 19.06it/s, est. speed input: 23202.64 toks/s, output: 22.66 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:06<00:19, 19.10it/s, est. speed input: 23088.57 toks/s, output: 22.55 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:06<00:18, 19.17it/s, est. speed input: 22986.86 toks/s, output: 22.45 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:18, 19.15it/s, est. speed input: 22882.74 toks/s, output: 22.35 toks/s]
Processed prompts:  31%|███       | 158/512 [00:07<00:18, 19.11it/s, est. speed input: 22781.97 toks/s, output: 22.25 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:07<00:18, 19.08it/s, est. speed input: 22686.24 toks/s, output: 22.15 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:07<00:18, 19.07it/s, est. speed input: 22597.34 toks/s, output: 22.07 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:07<00:17, 19.07it/s, est. speed input: 22514.25 toks/s, output: 21.99 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:17, 19.10it/s, est. speed input: 22438.45 toks/s, output: 21.91 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:08<00:17, 19.10it/s, est. speed input: 22364.00 toks/s, output: 21.84 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:08<00:17, 19.06it/s, est. speed input: 22290.36 toks/s, output: 21.77 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:08<00:17, 19.05it/s, est. speed input: 22221.25 toks/s, output: 21.70 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:08<00:16, 19.07it/s, est. speed input: 22158.50 toks/s, output: 21.64 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:16, 19.08it/s, est. speed input: 22097.94 toks/s, output: 21.58 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:09<00:16, 19.08it/s, est. speed input: 22039.50 toks/s, output: 21.52 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:09<00:15, 20.29it/s, est. speed input: 22081.92 toks/s, output: 21.56 toks/s]
Processed prompts:  40%|████      | 206/512 [00:09<00:15, 19.93it/s, est. speed input: 22027.18 toks/s, output: 21.51 toks/s]
Processed prompts:  41%|████      | 210/512 [00:09<00:15, 19.66it/s, est. speed input: 21973.73 toks/s, output: 21.46 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:09<00:15, 19.50it/s, est. speed input: 21923.72 toks/s, output: 21.41 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:10<00:15, 19.33it/s, est. speed input: 21871.37 toks/s, output: 21.36 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:10<00:15, 19.25it/s, est. speed input: 21824.50 toks/s, output: 21.31 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:10<00:14, 19.23it/s, est. speed input: 21781.24 toks/s, output: 21.27 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:10<00:14, 19.27it/s, est. speed input: 21744.36 toks/s, output: 21.23 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:11<00:14, 19.24it/s, est. speed input: 21704.38 toks/s, output: 21.20 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:11<00:14, 19.18it/s, est. speed input: 21662.89 toks/s, output: 21.16 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:11<00:14, 19.20it/s, est. speed input: 21627.29 toks/s, output: 21.12 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:11<00:13, 19.20it/s, est. speed input: 21592.62 toks/s, output: 21.09 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:11<00:13, 19.26it/s, est. speed input: 21562.19 toks/s, output: 21.06 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:12<00:13, 19.19it/s, est. speed input: 21526.34 toks/s, output: 21.02 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:12<00:13, 19.20it/s, est. speed input: 21494.89 toks/s, output: 20.99 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:12<00:13, 19.20it/s, est. speed input: 21464.62 toks/s, output: 20.96 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:12<00:12, 19.20it/s, est. speed input: 21434.77 toks/s, output: 20.93 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:12<00:12, 19.23it/s, est. speed input: 21408.29 toks/s, output: 20.91 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:13<00:12, 19.17it/s, est. speed input: 21377.39 toks/s, output: 20.88 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:13<00:12, 19.17it/s, est. speed input: 21350.29 toks/s, output: 20.85 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:13<00:12, 19.16it/s, est. speed input: 21322.75 toks/s, output: 20.82 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:13<00:11, 19.17it/s, est. speed input: 21297.69 toks/s, output: 20.80 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:13<00:11, 19.21it/s, est. speed input: 21275.16 toks/s, output: 20.78 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:14<00:11, 19.17it/s, est. speed input: 21249.03 toks/s, output: 20.75 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:14<00:11, 19.18it/s, est. speed input: 21226.25 toks/s, output: 20.73 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:14<00:10, 19.13it/s, est. speed input: 21200.93 toks/s, output: 20.70 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:14<00:10, 19.15it/s, est. speed input: 21179.20 toks/s, output: 20.68 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:15<00:10, 19.14it/s, est. speed input: 21156.58 toks/s, output: 20.66 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:15<00:10, 19.20it/s, est. speed input: 21138.18 toks/s, output: 20.64 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:15<00:10, 19.18it/s, est. speed input: 21117.37 toks/s, output: 20.62 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:15<00:09, 19.12it/s, est. speed input: 21094.54 toks/s, output: 20.60 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:15<00:09, 19.13it/s, est. speed input: 21075.15 toks/s, output: 20.58 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:16<00:09, 19.12it/s, est. speed input: 21055.41 toks/s, output: 20.56 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:16<00:09, 19.17it/s, est. speed input: 21038.60 toks/s, output: 20.55 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:16<00:09, 19.11it/s, est. speed input: 21018.12 toks/s, output: 20.53 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:16<00:08, 19.13it/s, est. speed input: 21000.84 toks/s, output: 20.51 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:16<00:08, 19.15it/s, est. speed input: 20984.22 toks/s, output: 20.49 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:17<00:08, 19.17it/s, est. speed input: 20968.19 toks/s, output: 20.48 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:17<00:08, 19.13it/s, est. speed input: 20950.63 toks/s, output: 20.46 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:17<00:08, 19.14it/s, est. speed input: 20934.54 toks/s, output: 20.44 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:17<00:07, 19.10it/s, est. speed input: 20916.92 toks/s, output: 20.43 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:17<00:07, 19.11it/s, est. speed input: 20901.77 toks/s, output: 20.41 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:18<00:07, 19.14it/s, est. speed input: 20887.55 toks/s, output: 20.40 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:18<00:07, 19.10it/s, est. speed input: 20871.34 toks/s, output: 20.38 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:18<00:07, 19.11it/s, est. speed input: 20856.91 toks/s, output: 20.37 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:18<00:06, 19.07it/s, est. speed input: 20841.03 toks/s, output: 20.35 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:18<00:06, 19.15it/s, est. speed input: 20829.67 toks/s, output: 20.34 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:19<00:06, 19.14it/s, est. speed input: 20815.88 toks/s, output: 20.33 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:19<00:06, 19.12it/s, est. speed input: 20802.15 toks/s, output: 20.31 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:19<00:05, 19.12it/s, est. speed input: 20788.98 toks/s, output: 20.30 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:19<00:05, 19.10it/s, est. speed input: 20775.45 toks/s, output: 20.29 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:20<00:05, 19.11it/s, est. speed input: 20763.10 toks/s, output: 20.28 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:20<00:05, 19.09it/s, est. speed input: 20750.10 toks/s, output: 20.26 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:20<00:05, 19.09it/s, est. speed input: 20737.85 toks/s, output: 20.25 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:20<00:04, 19.09it/s, est. speed input: 20725.57 toks/s, output: 20.24 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:20<00:04, 19.11it/s, est. speed input: 20714.67 toks/s, output: 20.23 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:21<00:04, 19.10it/s, est. speed input: 20702.93 toks/s, output: 20.22 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:21<00:04, 19.12it/s, est. speed input: 20692.32 toks/s, output: 20.21 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:21<00:04, 19.08it/s, est. speed input: 20680.19 toks/s, output: 20.20 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:21<00:03, 19.07it/s, est. speed input: 20668.73 toks/s, output: 20.18 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:21<00:03, 19.09it/s, est. speed input: 20658.53 toks/s, output: 20.17 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:22<00:03, 19.06it/s, est. speed input: 20647.00 toks/s, output: 20.16 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:22<00:03, 19.13it/s, est. speed input: 20638.58 toks/s, output: 20.15 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:22<00:03, 19.09it/s, est. speed input: 20627.54 toks/s, output: 20.14 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:22<00:02, 19.07it/s, est. speed input: 20617.01 toks/s, output: 20.13 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:22<00:02, 19.12it/s, est. speed input: 20608.60 toks/s, output: 20.13 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:23<00:02, 19.11it/s, est. speed input: 20599.12 toks/s, output: 20.12 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:23<00:02, 19.15it/s, est. speed input: 20591.24 toks/s, output: 20.11 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:23<00:01, 19.13it/s, est. speed input: 20581.68 toks/s, output: 20.10 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:23<00:01, 19.11it/s, est. speed input: 20572.44 toks/s, output: 20.09 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:24<00:01, 19.05it/s, est. speed input: 20561.65 toks/s, output: 20.08 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:24<00:01, 19.07it/s, est. speed input: 20553.33 toks/s, output: 20.07 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:24<00:01, 19.07it/s, est. speed input: 20544.36 toks/s, output: 20.06 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:24<00:00, 19.07it/s, est. speed input: 20535.74 toks/s, output: 20.05 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:24<00:00, 19.01it/s, est. speed input: 20525.40 toks/s, output: 20.04 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:25<00:00, 19.03it/s, est. speed input: 20517.18 toks/s, output: 20.04 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:25<00:00, 19.07it/s, est. speed input: 20509.69 toks/s, output: 20.03 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:25<00:00, 20.48it/s, est. speed input: 20540.35 toks/s, output: 20.06 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:25<00:00, 20.48it/s, est. speed input: 20620.67 toks/s, output: 20.14 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:25<00:00, 20.14it/s, est. speed input: 20620.67 toks/s, output: 20.14 toks/s]
[rank0]:[W126 15:41:08.323937534 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 15:41:10
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:41:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1551992) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1551992) WARNING 01-26 15:41:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.41 requests/s, 19899.71 total tokens/s, 19.41 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 15:41:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:41:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:41:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:41:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:41:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:41:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:41:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:41:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:41:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:41:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:41:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:41:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:41:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:41:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:41:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:41:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:41:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.24it/s]
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1551992) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1551992) 
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1551992) [2026-01-26 15:41:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1551992) 2026-01-26 15:41:59,058 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1551992) 2026-01-26 15:41:59,164 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1551992) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  4.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  6.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.33it/s]
(EngineCore_DP0 pid=1551992) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.77it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  7.65it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 21/1024 [00:00<00:04, 205.98it/s]
Adding requests:   6%|▌         | 62/1024 [00:00<00:02, 321.65it/s]
Adding requests:  10%|▉         | 98/1024 [00:00<00:02, 337.69it/s]
Adding requests:  13%|█▎        | 136/1024 [00:00<00:02, 352.24it/s]
Adding requests:  17%|█▋        | 174/1024 [00:00<00:02, 360.13it/s]
Adding requests:  21%|██        | 215/1024 [00:00<00:02, 373.93it/s]
Adding requests:  25%|██▍       | 254/1024 [00:00<00:02, 375.86it/s]
Adding requests:  29%|██▊       | 294/1024 [00:00<00:01, 381.10it/s]
Adding requests:  33%|███▎      | 335/1024 [00:00<00:01, 389.82it/s]
Adding requests:  37%|███▋      | 375/1024 [00:01<00:01, 392.06it/s]
Adding requests:  41%|████      | 417/1024 [00:01<00:01, 399.55it/s]
Adding requests:  45%|████▍     | 457/1024 [00:01<00:01, 394.44it/s]
Adding requests:  49%|████▉     | 500/1024 [00:01<00:01, 403.36it/s]
Adding requests:  53%|█████▎    | 543/1024 [00:01<00:01, 407.75it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:01<00:01, 402.29it/s]
Adding requests:  61%|██████    | 625/1024 [00:01<00:01, 395.58it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:01<00:00, 381.47it/s]
Adding requests:  69%|██████▉   | 705/1024 [00:01<00:00, 383.77it/s]
Adding requests:  73%|███████▎  | 744/1024 [00:01<00:00, 377.62it/s]
Adding requests:  76%|███████▋  | 783/1024 [00:02<00:00, 379.50it/s]
Adding requests:  80%|████████  | 821/1024 [00:02<00:00, 378.85it/s]
Adding requests:  84%|████████▍ | 861/1024 [00:02<00:00, 383.39it/s]
Adding requests:  88%|████████▊ | 900/1024 [00:02<00:00, 385.27it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:02<00:00, 378.58it/s]
Adding requests:  95%|█████████▌| 977/1024 [00:02<00:00, 378.97it/s]
Adding requests:  99%|█████████▉| 1015/1024 [00:02<00:00, 372.63it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 379.02it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 50/1024 [00:00<00:05, 194.33it/s, est. speed input: 199009.32 toks/s, output: 194.33 toks/s]
Processed prompts:   7%|▋         | 70/1024 [00:01<00:17, 54.90it/s, est. speed input: 66434.98 toks/s, output: 64.88 toks/s]   
Processed prompts:   8%|▊         | 80/1024 [00:01<00:21, 43.40it/s, est. speed input: 54785.03 toks/s, output: 53.50 toks/s]
Processed prompts:   8%|▊         | 87/1024 [00:01<00:27, 34.33it/s, est. speed input: 46745.65 toks/s, output: 45.65 toks/s]
Processed prompts:   9%|▉         | 92/1024 [00:02<00:34, 27.01it/s, est. speed input: 40651.71 toks/s, output: 39.70 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:02<00:40, 22.97it/s, est. speed input: 36734.90 toks/s, output: 35.87 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:03<00:41, 21.90it/s, est. speed input: 34557.84 toks/s, output: 33.75 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:03<00:43, 21.10it/s, est. speed input: 32838.20 toks/s, output: 32.07 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:03<00:43, 20.62it/s, est. speed input: 31509.02 toks/s, output: 30.77 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:04<00:44, 20.21it/s, est. speed input: 30395.11 toks/s, output: 29.68 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:04<00:44, 19.93it/s, est. speed input: 29476.45 toks/s, output: 28.79 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:05<00:44, 19.78it/s, est. speed input: 28717.71 toks/s, output: 28.04 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:05<00:44, 19.63it/s, est. speed input: 28057.29 toks/s, output: 27.40 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:06<00:44, 19.56it/s, est. speed input: 27496.02 toks/s, output: 26.85 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:06<00:43, 19.50it/s, est. speed input: 27003.72 toks/s, output: 26.37 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:06<00:43, 19.49it/s, est. speed input: 26581.68 toks/s, output: 25.96 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:07<00:42, 19.52it/s, est. speed input: 26215.26 toks/s, output: 25.60 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:07<00:42, 19.53it/s, est. speed input: 25885.04 toks/s, output: 25.28 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:08<00:40, 20.18it/s, est. speed input: 25725.54 toks/s, output: 25.12 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:08<00:40, 19.99it/s, est. speed input: 25450.11 toks/s, output: 24.85 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:08<00:40, 19.83it/s, est. speed input: 25194.46 toks/s, output: 24.60 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:09<00:40, 19.74it/s, est. speed input: 24964.39 toks/s, output: 24.38 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:09<00:40, 19.67it/s, est. speed input: 24753.28 toks/s, output: 24.17 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:10<00:39, 19.60it/s, est. speed input: 24555.40 toks/s, output: 23.98 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:10<00:39, 19.57it/s, est. speed input: 24376.32 toks/s, output: 23.80 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:10<00:39, 19.53it/s, est. speed input: 24208.00 toks/s, output: 23.64 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:11<00:38, 19.54it/s, est. speed input: 24056.52 toks/s, output: 23.49 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:11<00:38, 19.53it/s, est. speed input: 23914.16 toks/s, output: 23.35 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:12<00:38, 19.52it/s, est. speed input: 23781.08 toks/s, output: 23.22 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:12<00:37, 19.50it/s, est. speed input: 23654.75 toks/s, output: 23.10 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:12<00:37, 19.52it/s, est. speed input: 23540.82 toks/s, output: 22.99 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:13<00:36, 19.51it/s, est. speed input: 23430.28 toks/s, output: 22.88 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:13<00:36, 19.52it/s, est. speed input: 23329.01 toks/s, output: 22.78 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:14<00:35, 19.50it/s, est. speed input: 23230.68 toks/s, output: 22.69 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:14<00:35, 19.50it/s, est. speed input: 23138.17 toks/s, output: 22.60 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:15<00:35, 19.48it/s, est. speed input: 23050.25 toks/s, output: 22.51 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:15<00:34, 19.50it/s, est. speed input: 22968.96 toks/s, output: 22.43 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:15<00:34, 19.51it/s, est. speed input: 22892.60 toks/s, output: 22.36 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:16<00:33, 19.49it/s, est. speed input: 22816.54 toks/s, output: 22.28 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:16<00:33, 19.48it/s, est. speed input: 22745.03 toks/s, output: 22.21 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:17<00:33, 19.48it/s, est. speed input: 22678.37 toks/s, output: 22.15 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:17<00:32, 19.47it/s, est. speed input: 22613.13 toks/s, output: 22.08 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:17<00:32, 19.48it/s, est. speed input: 22552.57 toks/s, output: 22.02 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:18<00:31, 19.47it/s, est. speed input: 22492.82 toks/s, output: 21.97 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:18<00:31, 19.44it/s, est. speed input: 22434.09 toks/s, output: 21.91 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:19<00:31, 19.47it/s, est. speed input: 22382.29 toks/s, output: 21.86 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:19<00:30, 19.42it/s, est. speed input: 22326.93 toks/s, output: 21.80 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:19<00:30, 19.41it/s, est. speed input: 22275.58 toks/s, output: 21.75 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:20<00:29, 19.43it/s, est. speed input: 22228.42 toks/s, output: 21.71 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:20<00:29, 19.40it/s, est. speed input: 22180.13 toks/s, output: 21.66 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:21<00:29, 19.45it/s, est. speed input: 22138.64 toks/s, output: 21.62 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:21<00:28, 19.42it/s, est. speed input: 22094.03 toks/s, output: 21.58 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:22<00:28, 19.41it/s, est. speed input: 22052.39 toks/s, output: 21.54 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:22<00:27, 19.45it/s, est. speed input: 22015.06 toks/s, output: 21.50 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:22<00:27, 19.41it/s, est. speed input: 21974.67 toks/s, output: 21.46 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:23<00:27, 19.43it/s, est. speed input: 21938.50 toks/s, output: 21.42 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:23<00:26, 19.44it/s, est. speed input: 21903.52 toks/s, output: 21.39 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:24<00:26, 19.47it/s, est. speed input: 21871.31 toks/s, output: 21.36 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:24<00:25, 19.46it/s, est. speed input: 21838.29 toks/s, output: 21.33 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:24<00:25, 19.44it/s, est. speed input: 21805.73 toks/s, output: 21.29 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:25<00:24, 19.45it/s, est. speed input: 21775.55 toks/s, output: 21.27 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:25<00:24, 19.43it/s, est. speed input: 21744.36 toks/s, output: 21.23 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:26<00:24, 19.44it/s, est. speed input: 21716.01 toks/s, output: 21.21 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:26<00:23, 19.43it/s, est. speed input: 21687.44 toks/s, output: 21.18 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:26<00:23, 19.45it/s, est. speed input: 21661.20 toks/s, output: 21.15 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:27<00:22, 19.43it/s, est. speed input: 21633.83 toks/s, output: 21.13 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:27<00:22, 19.40it/s, est. speed input: 21606.55 toks/s, output: 21.10 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:28<00:22, 19.41it/s, est. speed input: 21581.70 toks/s, output: 21.08 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:28<00:21, 19.40it/s, est. speed input: 21556.58 toks/s, output: 21.05 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:29<00:21, 19.39it/s, est. speed input: 21532.17 toks/s, output: 21.03 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:29<00:20, 19.40it/s, est. speed input: 21508.87 toks/s, output: 21.00 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:29<00:20, 19.38it/s, est. speed input: 21485.46 toks/s, output: 20.98 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:30<00:20, 19.40it/s, est. speed input: 21463.79 toks/s, output: 20.96 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:30<00:19, 19.40it/s, est. speed input: 21442.26 toks/s, output: 20.94 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:31<00:19, 19.39it/s, est. speed input: 21420.86 toks/s, output: 20.92 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:31<00:18, 19.39it/s, est. speed input: 21400.15 toks/s, output: 20.90 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:31<00:18, 19.37it/s, est. speed input: 21379.33 toks/s, output: 20.88 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:32<00:18, 19.37it/s, est. speed input: 21359.45 toks/s, output: 20.86 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:32<00:17, 19.38it/s, est. speed input: 21340.79 toks/s, output: 20.84 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:33<00:17, 19.36it/s, est. speed input: 21321.27 toks/s, output: 20.82 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:33<00:16, 19.36it/s, est. speed input: 21302.63 toks/s, output: 20.80 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:33<00:16, 19.37it/s, est. speed input: 21285.05 toks/s, output: 20.79 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:34<00:16, 19.35it/s, est. speed input: 21266.77 toks/s, output: 20.77 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:34<00:15, 19.36it/s, est. speed input: 21249.82 toks/s, output: 20.75 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:35<00:15, 19.34it/s, est. speed input: 21232.42 toks/s, output: 20.73 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:35<00:14, 19.35it/s, est. speed input: 21216.07 toks/s, output: 20.72 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:36<00:14, 19.33it/s, est. speed input: 21199.10 toks/s, output: 20.70 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:36<00:13, 19.33it/s, est. speed input: 21183.27 toks/s, output: 20.69 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:36<00:13, 19.32it/s, est. speed input: 21167.24 toks/s, output: 20.67 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:37<00:13, 19.31it/s, est. speed input: 21151.53 toks/s, output: 20.66 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:37<00:12, 19.33it/s, est. speed input: 21137.02 toks/s, output: 20.64 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:38<00:11, 19.97it/s, est. speed input: 21147.16 toks/s, output: 20.65 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:38<00:11, 19.77it/s, est. speed input: 21132.21 toks/s, output: 20.64 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:38<00:11, 19.65it/s, est. speed input: 21118.48 toks/s, output: 20.62 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:39<00:10, 19.57it/s, est. speed input: 21105.11 toks/s, output: 20.61 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:39<00:10, 19.46it/s, est. speed input: 21090.31 toks/s, output: 20.60 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:40<00:10, 19.44it/s, est. speed input: 21077.39 toks/s, output: 20.58 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:40<00:09, 19.39it/s, est. speed input: 21063.78 toks/s, output: 20.57 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:40<00:09, 19.35it/s, est. speed input: 21050.08 toks/s, output: 20.56 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:41<00:09, 19.33it/s, est. speed input: 21037.17 toks/s, output: 20.54 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:41<00:08, 19.34it/s, est. speed input: 21025.03 toks/s, output: 20.53 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:42<00:08, 19.33it/s, est. speed input: 21012.64 toks/s, output: 20.52 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:42<00:07, 19.29it/s, est. speed input: 20999.53 toks/s, output: 20.51 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:43<00:07, 19.32it/s, est. speed input: 20988.67 toks/s, output: 20.50 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:43<00:06, 19.28it/s, est. speed input: 20975.88 toks/s, output: 20.48 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:43<00:06, 19.28it/s, est. speed input: 20964.05 toks/s, output: 20.47 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:44<00:06, 19.30it/s, est. speed input: 20953.27 toks/s, output: 20.46 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:44<00:05, 19.27it/s, est. speed input: 20941.34 toks/s, output: 20.45 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:45<00:05, 19.31it/s, est. speed input: 20931.48 toks/s, output: 20.44 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:45<00:04, 19.28it/s, est. speed input: 20919.97 toks/s, output: 20.43 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:45<00:04, 19.29it/s, est. speed input: 20909.49 toks/s, output: 20.42 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:46<00:04, 19.28it/s, est. speed input: 20898.80 toks/s, output: 20.41 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:46<00:03, 19.29it/s, est. speed input: 20888.80 toks/s, output: 20.40 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:47<00:03, 19.29it/s, est. speed input: 20878.89 toks/s, output: 20.39 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:47<00:02, 19.28it/s, est. speed input: 20868.65 toks/s, output: 20.38 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:48<00:02, 19.27it/s, est. speed input: 20858.79 toks/s, output: 20.37 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:48<00:01, 19.28it/s, est. speed input: 20849.31 toks/s, output: 20.36 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:48<00:01, 19.27it/s, est. speed input: 20839.79 toks/s, output: 20.35 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:49<00:01, 19.25it/s, est. speed input: 20829.78 toks/s, output: 20.34 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:49<00:00, 19.25it/s, est. speed input: 20820.38 toks/s, output: 20.33 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:50<00:00, 19.96it/s, est. speed input: 20831.80 toks/s, output: 20.34 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:50<00:00, 19.96it/s, est. speed input: 20954.42 toks/s, output: 20.46 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:50<00:00, 20.46it/s, est. speed input: 20954.42 toks/s, output: 20.46 toks/s]
[rank0]:[W126 15:42:55.586640383 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 15:42:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:43:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1553997) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1553997) WARNING 01-26 15:43:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.58 requests/s, 20069.01 total tokens/s, 19.58 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 15:43:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:43:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:43:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:43:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:43:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:43:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:43:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:43:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:43:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:43:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:43:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:43:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:43:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:43:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:43:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:43:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:43:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.22it/s]
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1553997) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1553997) 
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1553997) [2026-01-26 15:43:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1553997) [rank0]:W0126 15:43:47.782000 1553997 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1553997) [rank0]:W0126 15:43:47.836000 1553997 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1553997) [rank0]:W0126 15:43:48.451000 1553997 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1553997) [rank0]:W0126 15:43:48.535000 1553997 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1553997) 2026-01-26 15:43:53,337 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1553997) 2026-01-26 15:43:53,602 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1553997) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:04,  1.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:02,  2.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  5.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.76it/s]
(EngineCore_DP0 pid=1553997) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 11.58it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 11.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.53it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/2048 [00:00<00:08, 229.91it/s]
Adding requests:   3%|▎         | 62/2048 [00:00<00:06, 323.38it/s]
Adding requests:   5%|▍         | 98/2048 [00:00<00:05, 336.31it/s]
Adding requests:   7%|▋         | 136/2048 [00:00<00:05, 350.89it/s]
Adding requests:   9%|▊         | 175/2048 [00:00<00:05, 363.62it/s]
Adding requests:  10%|█         | 214/2048 [00:00<00:04, 369.91it/s]
Adding requests:  12%|█▏        | 252/2048 [00:00<00:04, 372.91it/s]
Adding requests:  14%|█▍        | 291/2048 [00:00<00:04, 375.97it/s]
Adding requests:  16%|█▌        | 331/2048 [00:00<00:04, 383.33it/s]
Adding requests:  18%|█▊        | 372/2048 [00:01<00:04, 388.51it/s]
Adding requests:  20%|██        | 413/2048 [00:01<00:04, 392.96it/s]
Adding requests:  22%|██▏       | 453/2048 [00:01<00:04, 392.54it/s]
Adding requests:  24%|██▍       | 496/2048 [00:01<00:03, 400.95it/s]
Adding requests:  26%|██▋       | 538/2048 [00:01<00:03, 403.98it/s]
Adding requests:  28%|██▊       | 579/2048 [00:01<00:03, 399.97it/s]
Adding requests:  30%|███       | 620/2048 [00:01<00:03, 388.96it/s]
Adding requests:  32%|███▏      | 659/2048 [00:01<00:03, 383.89it/s]
Adding requests:  34%|███▍      | 698/2048 [00:01<00:03, 383.27it/s]
Adding requests:  36%|███▌      | 737/2048 [00:01<00:03, 376.38it/s]
Adding requests:  38%|███▊      | 775/2048 [00:02<00:03, 373.32it/s]
Adding requests:  40%|███▉      | 813/2048 [00:02<00:03, 373.99it/s]
Adding requests:  42%|████▏     | 854/2048 [00:02<00:03, 383.57it/s]
Adding requests:  44%|████▎     | 893/2048 [00:02<00:02, 385.17it/s]
Adding requests:  46%|████▌     | 932/2048 [00:02<00:02, 376.76it/s]
Adding requests:  47%|████▋     | 971/2048 [00:02<00:02, 379.42it/s]
Adding requests:  49%|████▉     | 1009/2048 [00:02<00:02, 375.30it/s]
Adding requests:  51%|█████     | 1047/2048 [00:02<00:02, 375.06it/s]
Adding requests:  53%|█████▎    | 1085/2048 [00:02<00:02, 374.96it/s]
Adding requests:  55%|█████▍    | 1124/2048 [00:02<00:02, 376.22it/s]
Adding requests:  57%|█████▋    | 1162/2048 [00:03<00:02, 374.88it/s]
Adding requests:  59%|█████▊    | 1201/2048 [00:03<00:02, 377.17it/s]
Adding requests:  61%|██████    | 1241/2048 [00:03<00:02, 383.18it/s]
Adding requests:  62%|██████▎   | 1280/2048 [00:03<00:02, 379.25it/s]
Adding requests:  64%|██████▍   | 1319/2048 [00:03<00:01, 379.41it/s]
Adding requests:  66%|██████▋   | 1358/2048 [00:03<00:01, 381.95it/s]
Adding requests:  68%|██████▊   | 1397/2048 [00:03<00:01, 382.37it/s]
Adding requests:  70%|███████   | 1436/2048 [00:03<00:01, 380.90it/s]
Adding requests:  72%|███████▏  | 1475/2048 [00:03<00:01, 381.14it/s]
Adding requests:  74%|███████▍  | 1515/2048 [00:04<00:01, 385.68it/s]
Adding requests:  76%|███████▌  | 1554/2048 [00:04<00:01, 380.50it/s]
Adding requests:  78%|███████▊  | 1593/2048 [00:04<00:01, 375.79it/s]
Adding requests:  80%|███████▉  | 1631/2048 [00:04<00:01, 369.74it/s]
Adding requests:  81%|████████▏ | 1669/2048 [00:04<00:01, 363.70it/s]
Adding requests:  83%|████████▎ | 1709/2048 [00:04<00:00, 371.23it/s]
Adding requests:  85%|████████▌ | 1748/2048 [00:04<00:00, 374.83it/s]
Adding requests:  87%|████████▋ | 1787/2048 [00:04<00:00, 378.25it/s]
Adding requests:  89%|████████▉ | 1826/2048 [00:04<00:00, 378.15it/s]
Adding requests:  91%|█████████ | 1864/2048 [00:04<00:00, 378.62it/s]
Adding requests:  93%|█████████▎| 1903/2048 [00:05<00:00, 380.98it/s]
Adding requests:  95%|█████████▍| 1942/2048 [00:05<00:00, 377.36it/s]
Adding requests:  97%|█████████▋| 1981/2048 [00:05<00:00, 379.39it/s]
Adding requests:  99%|█████████▊| 2019/2048 [00:05<00:00, 370.04it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 377.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:00<00:17, 112.88it/s, est. speed input: 115592.96 toks/s, output: 112.88 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:01<00:32, 59.72it/s, est. speed input: 69604.76 toks/s, output: 67.97 toks/s]  
Processed prompts:   6%|▋         | 130/2048 [00:02<00:45, 41.78it/s, est. speed input: 53553.14 toks/s, output: 52.30 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:03<00:57, 33.32it/s, est. speed input: 45495.40 toks/s, output: 44.43 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:04<01:06, 28.55it/s, est. speed input: 40586.58 toks/s, output: 39.63 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:04<01:12, 25.66it/s, est. speed input: 37291.60 toks/s, output: 36.42 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:05<01:16, 24.20it/s, est. speed input: 35165.05 toks/s, output: 34.34 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:06<01:20, 22.82it/s, est. speed input: 33326.35 toks/s, output: 32.55 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:07<01:23, 21.89it/s, est. speed input: 31888.17 toks/s, output: 31.14 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:08<01:24, 21.29it/s, est. speed input: 30746.22 toks/s, output: 30.03 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:08<01:25, 20.90it/s, est. speed input: 29823.18 toks/s, output: 29.12 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:09<01:26, 20.61it/s, est. speed input: 29041.20 toks/s, output: 28.36 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:10<01:26, 20.40it/s, est. speed input: 28378.76 toks/s, output: 27.71 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:11<01:25, 20.28it/s, est. speed input: 27816.78 toks/s, output: 27.16 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:12<01:25, 20.17it/s, est. speed input: 27322.65 toks/s, output: 26.68 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:12<01:25, 20.08it/s, est. speed input: 26887.51 toks/s, output: 26.26 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:13<01:24, 20.04it/s, est. speed input: 26508.84 toks/s, output: 25.89 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:14<01:23, 20.00it/s, est. speed input: 26168.04 toks/s, output: 25.55 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:15<01:23, 19.98it/s, est. speed input: 25865.53 toks/s, output: 25.26 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:16<01:22, 19.94it/s, est. speed input: 25587.79 toks/s, output: 24.99 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:16<01:21, 19.91it/s, est. speed input: 25336.42 toks/s, output: 24.74 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:17<01:21, 19.88it/s, est. speed input: 25105.11 toks/s, output: 24.52 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:18<01:20, 19.87it/s, est. speed input: 24896.54 toks/s, output: 24.31 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:19<01:19, 19.86it/s, est. speed input: 24705.37 toks/s, output: 24.13 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:20<01:18, 19.85it/s, est. speed input: 24528.77 toks/s, output: 23.95 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:20<01:18, 19.86it/s, est. speed input: 24369.40 toks/s, output: 23.80 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:21<01:17, 19.86it/s, est. speed input: 24219.77 toks/s, output: 23.65 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:22<01:16, 19.84it/s, est. speed input: 24077.13 toks/s, output: 23.51 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:23<01:15, 19.84it/s, est. speed input: 23947.55 toks/s, output: 23.39 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:24<01:14, 19.83it/s, est. speed input: 23824.41 toks/s, output: 23.27 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:24<01:14, 19.80it/s, est. speed input: 23707.85 toks/s, output: 23.15 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:25<01:13, 19.79it/s, est. speed input: 23599.22 toks/s, output: 23.05 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:26<01:12, 19.80it/s, est. speed input: 23498.49 toks/s, output: 22.95 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:27<01:11, 19.80it/s, est. speed input: 23403.44 toks/s, output: 22.85 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:28<01:11, 19.77it/s, est. speed input: 23310.24 toks/s, output: 22.76 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:29<01:10, 19.76it/s, est. speed input: 23223.96 toks/s, output: 22.68 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:29<01:09, 19.76it/s, est. speed input: 23142.84 toks/s, output: 22.60 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:30<01:08, 19.76it/s, est. speed input: 23065.53 toks/s, output: 22.52 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:31<01:07, 19.74it/s, est. speed input: 22991.21 toks/s, output: 22.45 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:32<01:07, 19.76it/s, est. speed input: 22922.70 toks/s, output: 22.39 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:33<01:06, 19.73it/s, est. speed input: 22854.44 toks/s, output: 22.32 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:33<01:05, 19.73it/s, est. speed input: 22790.64 toks/s, output: 22.26 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:34<01:04, 19.72it/s, est. speed input: 22729.61 toks/s, output: 22.20 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:35<01:03, 20.00it/s, est. speed input: 22696.03 toks/s, output: 22.16 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:36<01:02, 19.91it/s, est. speed input: 22639.45 toks/s, output: 22.11 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:37<01:02, 19.83it/s, est. speed input: 22584.26 toks/s, output: 22.05 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:37<01:01, 19.78it/s, est. speed input: 22531.61 toks/s, output: 22.00 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:38<01:00, 19.76it/s, est. speed input: 22482.11 toks/s, output: 21.96 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:39<00:59, 19.73it/s, est. speed input: 22433.96 toks/s, output: 21.91 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:40<00:59, 19.72it/s, est. speed input: 22388.26 toks/s, output: 21.86 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:41<00:58, 19.69it/s, est. speed input: 22343.14 toks/s, output: 21.82 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:41<00:57, 19.66it/s, est. speed input: 22298.53 toks/s, output: 21.78 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:42<00:56, 19.64it/s, est. speed input: 22256.08 toks/s, output: 21.73 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:43<00:56, 19.63it/s, est. speed input: 22215.34 toks/s, output: 21.69 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:44<00:55, 19.65it/s, est. speed input: 22177.72 toks/s, output: 21.66 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:45<00:54, 19.64it/s, est. speed input: 22140.23 toks/s, output: 21.62 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:46<00:53, 19.64it/s, est. speed input: 22103.95 toks/s, output: 21.59 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:46<00:52, 19.62it/s, est. speed input: 22068.22 toks/s, output: 21.55 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:47<00:52, 19.63it/s, est. speed input: 22035.02 toks/s, output: 21.52 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:48<00:51, 19.63it/s, est. speed input: 22002.71 toks/s, output: 21.49 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:49<00:50, 19.64it/s, est. speed input: 21971.89 toks/s, output: 21.46 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:50<00:49, 19.64it/s, est. speed input: 21941.60 toks/s, output: 21.43 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:50<00:48, 19.62it/s, est. speed input: 21911.17 toks/s, output: 21.40 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:51<00:47, 19.63it/s, est. speed input: 21882.83 toks/s, output: 21.37 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:52<00:47, 19.61it/s, est. speed input: 21854.24 toks/s, output: 21.34 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:53<00:46, 19.60it/s, est. speed input: 21826.79 toks/s, output: 21.32 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:54<00:45, 19.60it/s, est. speed input: 21800.15 toks/s, output: 21.29 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:55<00:44, 19.61it/s, est. speed input: 21774.83 toks/s, output: 21.26 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:55<00:43, 19.62it/s, est. speed input: 21750.71 toks/s, output: 21.24 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:56<00:43, 19.62it/s, est. speed input: 21726.61 toks/s, output: 21.22 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:57<00:42, 19.61it/s, est. speed input: 21702.82 toks/s, output: 21.19 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:58<00:41, 19.60it/s, est. speed input: 21679.54 toks/s, output: 21.17 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:59<00:40, 19.57it/s, est. speed input: 21656.09 toks/s, output: 21.15 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:59<00:39, 19.58it/s, est. speed input: 21634.60 toks/s, output: 21.13 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:00<00:39, 19.59it/s, est. speed input: 21613.78 toks/s, output: 21.11 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [01:01<00:38, 19.59it/s, est. speed input: 21593.01 toks/s, output: 21.09 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:02<00:37, 19.58it/s, est. speed input: 21572.33 toks/s, output: 21.07 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:03<00:36, 19.56it/s, est. speed input: 21551.76 toks/s, output: 21.05 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:04<00:35, 19.55it/s, est. speed input: 21532.02 toks/s, output: 21.03 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:04<00:35, 19.54it/s, est. speed input: 21512.41 toks/s, output: 21.01 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:05<00:34, 19.55it/s, est. speed input: 21493.96 toks/s, output: 20.99 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:06<00:33, 19.54it/s, est. speed input: 21475.65 toks/s, output: 20.97 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:07<00:32, 19.54it/s, est. speed input: 21457.43 toks/s, output: 20.95 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:08<00:31, 19.53it/s, est. speed input: 21439.85 toks/s, output: 20.94 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:08<00:31, 19.52it/s, est. speed input: 21422.30 toks/s, output: 20.92 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:09<00:30, 19.53it/s, est. speed input: 21405.76 toks/s, output: 20.90 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:10<00:29, 19.53it/s, est. speed input: 21389.53 toks/s, output: 20.89 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:11<00:28, 19.53it/s, est. speed input: 21373.61 toks/s, output: 20.87 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:12<00:27, 19.54it/s, est. speed input: 21358.55 toks/s, output: 20.86 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:13<00:26, 19.55it/s, est. speed input: 21343.88 toks/s, output: 20.84 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:13<00:26, 19.56it/s, est. speed input: 21329.30 toks/s, output: 20.83 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:14<00:24, 19.84it/s, est. speed input: 21325.98 toks/s, output: 20.83 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:15<00:24, 19.73it/s, est. speed input: 21310.99 toks/s, output: 20.81 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:16<00:23, 19.66it/s, est. speed input: 21296.71 toks/s, output: 20.80 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:17<00:22, 19.64it/s, est. speed input: 21283.49 toks/s, output: 20.78 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:17<00:21, 19.88it/s, est. speed input: 21280.09 toks/s, output: 20.78 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:18<00:20, 19.77it/s, est. speed input: 21266.56 toks/s, output: 20.77 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:19<00:20, 19.68it/s, est. speed input: 21253.04 toks/s, output: 20.75 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:20<00:19, 19.63it/s, est. speed input: 21239.97 toks/s, output: 20.74 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:21<00:18, 19.58it/s, est. speed input: 21226.91 toks/s, output: 20.73 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:21<00:17, 19.55it/s, est. speed input: 21214.03 toks/s, output: 20.72 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:22<00:17, 19.53it/s, est. speed input: 21201.33 toks/s, output: 20.70 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:23<00:16, 19.53it/s, est. speed input: 21189.47 toks/s, output: 20.69 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:24<00:15, 19.52it/s, est. speed input: 21177.74 toks/s, output: 20.68 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:25<00:14, 19.51it/s, est. speed input: 21166.07 toks/s, output: 20.67 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:26<00:13, 19.52it/s, est. speed input: 21155.07 toks/s, output: 20.66 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:26<00:13, 19.52it/s, est. speed input: 21143.94 toks/s, output: 20.65 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:27<00:12, 19.50it/s, est. speed input: 21132.48 toks/s, output: 20.64 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:28<00:11, 19.50it/s, est. speed input: 21121.67 toks/s, output: 20.63 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:29<00:10, 19.50it/s, est. speed input: 21111.03 toks/s, output: 20.62 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:30<00:09, 19.50it/s, est. speed input: 21100.66 toks/s, output: 20.61 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:30<00:08, 19.49it/s, est. speed input: 21089.98 toks/s, output: 20.60 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:31<00:08, 19.48it/s, est. speed input: 21079.62 toks/s, output: 20.59 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:32<00:07, 19.46it/s, est. speed input: 21069.11 toks/s, output: 20.58 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:33<00:06, 19.47it/s, est. speed input: 21059.27 toks/s, output: 20.57 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:34<00:05, 19.47it/s, est. speed input: 21049.47 toks/s, output: 20.56 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:35<00:04, 19.46it/s, est. speed input: 21039.60 toks/s, output: 20.55 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:35<00:04, 19.47it/s, est. speed input: 21030.35 toks/s, output: 20.54 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:36<00:03, 19.46it/s, est. speed input: 21020.68 toks/s, output: 20.53 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:37<00:02, 19.46it/s, est. speed input: 21011.45 toks/s, output: 20.52 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:38<00:01, 19.45it/s, est. speed input: 21002.04 toks/s, output: 20.51 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:39<00:00, 19.80it/s, est. speed input: 21003.27 toks/s, output: 20.51 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:39<00:00, 19.80it/s, est. speed input: 21147.71 toks/s, output: 20.65 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:39<00:00, 20.65it/s, est. speed input: 21147.71 toks/s, output: 20.65 toks/s]
[rank0]:[W126 15:45:42.510892705 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 15:45:44
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:46:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1556778) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1556778) WARNING 01-26 15:46:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.54 requests/s, 20023.86 total tokens/s, 19.54 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 15:46:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:46:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:46:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:46:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:46:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:46:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:46:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:46:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:46:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:46:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:46:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:46:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:46:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:46:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:46:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:46:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:46:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.24it/s]
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.13it/s]
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=1556778) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=1556778) 
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1556778) [2026-01-26 15:46:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1556778) [rank0]:W0126 15:46:44.841000 1556778 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1556778) [rank0]:W0126 15:46:44.894000 1556778 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1556778) [rank0]:W0126 15:46:45.510000 1556778 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1556778) [rank0]:W0126 15:46:45.594000 1556778 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1556778) 2026-01-26 15:46:50,012 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1556778) 2026-01-26 15:46:50,589 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1556778) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:09,  1.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:01<00:02,  2.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  5.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  5.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:02<00:00,  5.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.07it/s]
(EngineCore_DP0 pid=1556778) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.23it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  7.91it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  7.85it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.44it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.14it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 19/4096 [00:00<00:21, 186.33it/s]
Adding requests:   1%|▏         | 58/4096 [00:00<00:13, 303.75it/s]
Adding requests:   2%|▏         | 96/4096 [00:00<00:11, 333.64it/s]
Adding requests:   3%|▎         | 134/4096 [00:00<00:11, 348.79it/s]
Adding requests:   4%|▍         | 173/4096 [00:00<00:10, 363.30it/s]
Adding requests:   5%|▌         | 214/4096 [00:00<00:10, 375.49it/s]
Adding requests:   6%|▌         | 252/4096 [00:00<00:10, 375.94it/s]
Adding requests:   7%|▋         | 291/4096 [00:00<00:10, 378.82it/s]
Adding requests:   8%|▊         | 331/4096 [00:00<00:09, 384.95it/s]
Adding requests:   9%|▉         | 372/4096 [00:01<00:09, 390.06it/s]
Adding requests:  10%|█         | 413/4096 [00:01<00:09, 394.19it/s]
Adding requests:  11%|█         | 453/4096 [00:01<00:09, 392.94it/s]
Adding requests:  12%|█▏        | 496/4096 [00:01<00:08, 402.26it/s]
Adding requests:  13%|█▎        | 538/4096 [00:01<00:08, 404.80it/s]
Adding requests:  14%|█▍        | 579/4096 [00:01<00:08, 402.17it/s]
Adding requests:  15%|█▌        | 620/4096 [00:01<00:08, 392.06it/s]
Adding requests:  16%|█▌        | 660/4096 [00:01<00:08, 385.60it/s]
Adding requests:  17%|█▋        | 699/4096 [00:01<00:08, 386.55it/s]
Adding requests:  18%|█▊        | 738/4096 [00:01<00:08, 381.16it/s]
Adding requests:  19%|█▉        | 777/4096 [00:02<00:08, 380.68it/s]
Adding requests:  20%|█▉        | 816/4096 [00:02<00:08, 379.57it/s]
Adding requests:  21%|██        | 858/4096 [00:02<00:08, 388.50it/s]
Adding requests:  22%|██▏       | 897/4096 [00:02<00:08, 384.82it/s]
Adding requests:  23%|██▎       | 936/4096 [00:02<00:08, 378.58it/s]
Adding requests:  24%|██▍       | 976/4096 [00:02<00:08, 383.64it/s]
Adding requests:  25%|██▍       | 1015/4096 [00:02<00:08, 377.88it/s]
Adding requests:  26%|██▌       | 1054/4096 [00:02<00:08, 379.47it/s]
Adding requests:  27%|██▋       | 1092/4096 [00:02<00:07, 379.42it/s]
Adding requests:  28%|██▊       | 1130/4096 [00:02<00:07, 377.38it/s]
Adding requests:  29%|██▊       | 1168/4096 [00:03<00:07, 375.34it/s]
Adding requests:  29%|██▉       | 1208/4096 [00:03<00:07, 381.61it/s]
Adding requests:  30%|███       | 1247/4096 [00:03<00:07, 382.72it/s]
Adding requests:  31%|███▏      | 1286/4096 [00:03<00:07, 380.91it/s]
Adding requests:  32%|███▏      | 1325/4096 [00:03<00:07, 383.53it/s]
Adding requests:  33%|███▎      | 1365/4096 [00:03<00:07, 387.91it/s]
Adding requests:  34%|███▍      | 1404/4096 [00:03<00:06, 385.50it/s]
Adding requests:  35%|███▌      | 1443/4096 [00:03<00:06, 386.52it/s]
Adding requests:  36%|███▌      | 1483/4096 [00:03<00:06, 388.60it/s]
Adding requests:  37%|███▋      | 1523/4096 [00:03<00:06, 390.64it/s]
Adding requests:  38%|███▊      | 1563/4096 [00:04<00:06, 385.54it/s]
Adding requests:  39%|███▉      | 1602/4096 [00:04<00:06, 381.01it/s]
Adding requests:  40%|████      | 1641/4096 [00:04<00:06, 373.98it/s]
Adding requests:  41%|████      | 1679/4096 [00:04<00:06, 371.38it/s]
Adding requests:  42%|████▏     | 1719/4096 [00:04<00:06, 377.95it/s]
Adding requests:  43%|████▎     | 1758/4096 [00:04<00:06, 381.38it/s]
Adding requests:  44%|████▍     | 1797/4096 [00:04<00:06, 382.67it/s]
Adding requests:  45%|████▍     | 1836/4096 [00:04<00:05, 382.52it/s]
Adding requests:  46%|████▌     | 1876/4096 [00:04<00:05, 386.32it/s]
Adding requests:  47%|████▋     | 1916/4096 [00:05<00:05, 390.09it/s]
Adding requests:  48%|████▊     | 1957/4096 [00:05<00:05, 395.95it/s]
Adding requests:  49%|████▉     | 1997/4096 [00:05<00:05, 387.74it/s]
Adding requests:  50%|████▉     | 2036/4096 [00:05<00:05, 381.11it/s]
Adding requests:  51%|█████     | 2075/4096 [00:05<00:05, 374.61it/s]
Adding requests:  52%|█████▏    | 2115/4096 [00:05<00:05, 379.54it/s]
Adding requests:  53%|█████▎    | 2154/4096 [00:05<00:05, 378.83it/s]
Adding requests:  54%|█████▎    | 2192/4096 [00:05<00:05, 372.77it/s]
Adding requests:  54%|█████▍    | 2230/4096 [00:05<00:05, 373.07it/s]
Adding requests:  55%|█████▌    | 2271/4096 [00:05<00:04, 382.38it/s]
Adding requests:  56%|█████▋    | 2310/4096 [00:06<00:04, 382.62it/s]
Adding requests:  57%|█████▋    | 2349/4096 [00:06<00:04, 379.42it/s]
Adding requests:  58%|█████▊    | 2390/4096 [00:06<00:04, 386.49it/s]
Adding requests:  59%|█████▉    | 2430/4096 [00:06<00:04, 388.22it/s]
Adding requests:  60%|██████    | 2469/4096 [00:06<00:04, 383.52it/s]
Adding requests:  61%|██████▏   | 2510/4096 [00:06<00:04, 391.21it/s]
Adding requests:  62%|██████▏   | 2552/4096 [00:06<00:03, 399.51it/s]
Adding requests:  63%|██████▎   | 2594/4096 [00:06<00:03, 403.62it/s]
Adding requests:  64%|██████▍   | 2635/4096 [00:06<00:03, 392.78it/s]
Adding requests:  65%|██████▌   | 2675/4096 [00:06<00:03, 389.93it/s]
Adding requests:  66%|██████▋   | 2715/4096 [00:07<00:03, 382.27it/s]
Adding requests:  67%|██████▋   | 2756/4096 [00:07<00:03, 389.68it/s]
Adding requests:  68%|██████▊   | 2798/4096 [00:07<00:03, 396.40it/s]
Adding requests:  69%|██████▉   | 2838/4096 [00:07<00:03, 395.48it/s]
Adding requests:  70%|███████   | 2878/4096 [00:07<00:03, 392.53it/s]
Adding requests:  71%|███████   | 2918/4096 [00:07<00:03, 391.71it/s]
Adding requests:  72%|███████▏  | 2959/4096 [00:07<00:02, 395.31it/s]
Adding requests:  73%|███████▎  | 2999/4096 [00:07<00:02, 394.37it/s]
Adding requests:  74%|███████▍  | 3039/4096 [00:07<00:02, 395.09it/s]
Adding requests:  75%|███████▌  | 3080/4096 [00:08<00:02, 397.45it/s]
Adding requests:  76%|███████▌  | 3122/4096 [00:08<00:02, 401.87it/s]
Adding requests:  77%|███████▋  | 3163/4096 [00:08<00:02, 394.57it/s]
Adding requests:  78%|███████▊  | 3203/4096 [00:08<00:02, 388.72it/s]
Adding requests:  79%|███████▉  | 3243/4096 [00:08<00:02, 391.77it/s]
Adding requests:  80%|████████  | 3283/4096 [00:08<00:02, 385.90it/s]
Adding requests:  81%|████████  | 3322/4096 [00:08<00:02, 379.54it/s]
Adding requests:  82%|████████▏ | 3361/4096 [00:08<00:01, 381.40it/s]
Adding requests:  83%|████████▎ | 3401/4096 [00:08<00:01, 385.90it/s]
Adding requests:  84%|████████▍ | 3441/4096 [00:08<00:01, 388.01it/s]
Adding requests:  85%|████████▍ | 3481/4096 [00:09<00:01, 388.40it/s]
Adding requests:  86%|████████▌ | 3521/4096 [00:09<00:01, 390.68it/s]
Adding requests:  87%|████████▋ | 3564/4096 [00:09<00:01, 398.77it/s]
Adding requests:  88%|████████▊ | 3604/4096 [00:09<00:01, 391.13it/s]
Adding requests:  89%|████████▉ | 3645/4096 [00:09<00:01, 395.27it/s]
Adding requests:  90%|████████▉ | 3685/4096 [00:09<00:01, 386.73it/s]
Adding requests:  91%|█████████ | 3724/4096 [00:09<00:00, 380.45it/s]
Adding requests:  92%|█████████▏| 3763/4096 [00:09<00:00, 375.89it/s]
Adding requests:  93%|█████████▎| 3801/4096 [00:09<00:00, 368.01it/s]
Adding requests:  94%|█████████▎| 3839/4096 [00:10<00:00, 371.26it/s]
Adding requests:  95%|█████████▍| 3878/4096 [00:10<00:00, 376.28it/s]
Adding requests:  96%|█████████▌| 3916/4096 [00:10<00:00, 370.70it/s]
Adding requests:  97%|█████████▋| 3954/4096 [00:10<00:00, 372.62it/s]
Adding requests:  97%|█████████▋| 3992/4096 [00:10<00:00, 372.20it/s]
Adding requests:  98%|█████████▊| 4031/4096 [00:10<00:00, 374.98it/s]
Adding requests:  99%|█████████▉| 4069/4096 [00:10<00:00, 375.89it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 383.15it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:01<00:20, 187.75it/s, est. speed input: 192267.18 toks/s, output: 187.75 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:02<00:53, 71.96it/s, est. speed input: 87605.76 toks/s, output: 85.55 toks/s]   
Processed prompts:   6%|▋         | 258/4096 [00:04<01:23, 46.13it/s, est. speed input: 62172.49 toks/s, output: 60.72 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:05<01:47, 35.26it/s, est. speed input: 50705.78 toks/s, output: 49.52 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:07<02:07, 29.55it/s, est. speed input: 44177.09 toks/s, output: 43.14 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:09<02:22, 26.21it/s, est. speed input: 39968.66 toks/s, output: 39.03 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:10<02:34, 24.09it/s, est. speed input: 36996.07 toks/s, output: 36.13 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:12<02:41, 22.72it/s, est. speed input: 34808.49 toks/s, output: 33.99 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:13<02:47, 21.81it/s, est. speed input: 33124.72 toks/s, output: 32.35 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:15<02:50, 21.20it/s, est. speed input: 31796.14 toks/s, output: 31.05 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:17<02:52, 20.78it/s, est. speed input: 30716.17 toks/s, output: 30.00 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:18<02:53, 20.49it/s, est. speed input: 29819.31 toks/s, output: 29.12 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:20<02:53, 20.28it/s, est. speed input: 29061.01 toks/s, output: 28.38 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:21<02:53, 20.13it/s, est. speed input: 28413.07 toks/s, output: 27.75 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:23<02:52, 20.02it/s, est. speed input: 27851.75 toks/s, output: 27.20 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:25<02:51, 19.94it/s, est. speed input: 27363.80 toks/s, output: 26.72 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:26<02:50, 19.88it/s, est. speed input: 26931.32 toks/s, output: 26.30 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:28<02:49, 19.84it/s, est. speed input: 26549.85 toks/s, output: 25.93 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:30<02:46, 19.96it/s, est. speed input: 26242.59 toks/s, output: 25.63 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:31<02:45, 19.90it/s, est. speed input: 25936.27 toks/s, output: 25.33 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:33<02:44, 19.84it/s, est. speed input: 25655.89 toks/s, output: 25.05 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:34<02:43, 19.80it/s, est. speed input: 25400.30 toks/s, output: 24.80 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:36<02:41, 19.75it/s, est. speed input: 25163.81 toks/s, output: 24.57 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:38<02:40, 19.73it/s, est. speed input: 24951.72 toks/s, output: 24.37 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:39<02:38, 19.72it/s, est. speed input: 24755.89 toks/s, output: 24.18 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:41<02:37, 19.69it/s, est. speed input: 24572.30 toks/s, output: 24.00 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:43<02:35, 19.68it/s, est. speed input: 24404.80 toks/s, output: 23.83 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:44<02:34, 19.67it/s, est. speed input: 24248.52 toks/s, output: 23.68 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:46<02:32, 19.66it/s, est. speed input: 24102.82 toks/s, output: 23.54 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:47<02:31, 19.65it/s, est. speed input: 23966.85 toks/s, output: 23.41 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:49<02:29, 19.66it/s, est. speed input: 23841.11 toks/s, output: 23.28 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:51<02:28, 19.65it/s, est. speed input: 23721.61 toks/s, output: 23.17 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:52<02:26, 19.63it/s, est. speed input: 23608.70 toks/s, output: 23.06 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:54<02:25, 19.62it/s, est. speed input: 23502.15 toks/s, output: 22.95 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:56<02:23, 19.60it/s, est. speed input: 23401.07 toks/s, output: 22.85 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:57<02:21, 19.60it/s, est. speed input: 23306.49 toks/s, output: 22.76 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:59<02:20, 19.58it/s, est. speed input: 23215.57 toks/s, output: 22.67 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [01:01<02:18, 19.58it/s, est. speed input: 23130.27 toks/s, output: 22.59 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [01:02<02:17, 19.57it/s, est. speed input: 23049.18 toks/s, output: 22.51 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [01:04<02:15, 19.57it/s, est. speed input: 22972.38 toks/s, output: 22.43 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [01:05<02:13, 19.57it/s, est. speed input: 22899.61 toks/s, output: 22.36 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [01:07<02:12, 19.54it/s, est. speed input: 22827.67 toks/s, output: 22.29 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [01:09<02:09, 19.69it/s, est. speed input: 22774.47 toks/s, output: 22.24 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [01:10<02:08, 19.63it/s, est. speed input: 22709.58 toks/s, output: 22.18 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [01:12<02:06, 19.75it/s, est. speed input: 22661.21 toks/s, output: 22.13 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [01:14<02:05, 19.67it/s, est. speed input: 22600.66 toks/s, output: 22.07 toks/s]
Processed prompts:  41%|████      | 1666/4096 [01:15<02:03, 19.61it/s, est. speed input: 22543.01 toks/s, output: 22.01 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [01:17<02:02, 19.57it/s, est. speed input: 22488.03 toks/s, output: 21.96 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [01:18<02:01, 19.55it/s, est. speed input: 22435.65 toks/s, output: 21.91 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [01:20<01:59, 19.54it/s, est. speed input: 22385.71 toks/s, output: 21.86 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:22<01:57, 19.52it/s, est. speed input: 22336.97 toks/s, output: 21.81 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [01:23<01:56, 19.51it/s, est. speed input: 22290.58 toks/s, output: 21.77 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [01:25<01:54, 19.51it/s, est. speed input: 22245.88 toks/s, output: 21.72 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:27<01:53, 19.50it/s, est. speed input: 22202.34 toks/s, output: 21.68 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:28<01:51, 19.49it/s, est. speed input: 22160.68 toks/s, output: 21.64 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:30<01:50, 19.47it/s, est. speed input: 22119.39 toks/s, output: 21.60 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:32<01:48, 19.48it/s, est. speed input: 22081.08 toks/s, output: 21.56 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:33<01:46, 19.47it/s, est. speed input: 22043.11 toks/s, output: 21.53 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:35<01:45, 19.47it/s, est. speed input: 22006.96 toks/s, output: 21.49 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:37<01:43, 19.47it/s, est. speed input: 21971.51 toks/s, output: 21.46 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:38<01:41, 19.45it/s, est. speed input: 21936.80 toks/s, output: 21.42 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [01:40<01:40, 19.46it/s, est. speed input: 21903.93 toks/s, output: 21.39 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:41<01:37, 19.60it/s, est. speed input: 21880.43 toks/s, output: 21.37 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:43<01:36, 19.55it/s, est. speed input: 21848.94 toks/s, output: 21.34 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:45<01:34, 19.52it/s, est. speed input: 21818.68 toks/s, output: 21.31 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:46<01:33, 19.48it/s, est. speed input: 21788.59 toks/s, output: 21.28 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:48<01:31, 19.46it/s, est. speed input: 21759.73 toks/s, output: 21.25 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:50<01:30, 19.46it/s, est. speed input: 21732.28 toks/s, output: 21.22 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:51<01:28, 19.45it/s, est. speed input: 21705.12 toks/s, output: 21.20 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:53<01:27, 19.44it/s, est. speed input: 21678.56 toks/s, output: 21.17 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:55<01:25, 19.44it/s, est. speed input: 21653.25 toks/s, output: 21.15 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:56<01:23, 19.43it/s, est. speed input: 21628.30 toks/s, output: 21.12 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:58<01:22, 19.42it/s, est. speed input: 21603.51 toks/s, output: 21.10 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [02:00<01:20, 19.43it/s, est. speed input: 21580.60 toks/s, output: 21.07 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [02:01<01:18, 19.42it/s, est. speed input: 21557.46 toks/s, output: 21.05 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [02:03<01:17, 19.42it/s, est. speed input: 21535.14 toks/s, output: 21.03 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [02:04<01:15, 19.43it/s, est. speed input: 21513.57 toks/s, output: 21.01 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [02:06<01:14, 19.42it/s, est. speed input: 21492.23 toks/s, output: 20.99 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [02:08<01:12, 19.42it/s, est. speed input: 21471.71 toks/s, output: 20.97 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [02:09<01:10, 19.41it/s, est. speed input: 21451.26 toks/s, output: 20.95 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [02:11<01:09, 19.42it/s, est. speed input: 21431.95 toks/s, output: 20.93 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [02:13<01:07, 19.42it/s, est. speed input: 21412.85 toks/s, output: 20.91 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [02:14<01:05, 19.41it/s, est. speed input: 21393.88 toks/s, output: 20.89 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [02:16<01:04, 19.42it/s, est. speed input: 21375.82 toks/s, output: 20.87 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [02:18<01:01, 19.58it/s, est. speed input: 21365.10 toks/s, output: 20.86 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [02:19<01:00, 19.54it/s, est. speed input: 21347.76 toks/s, output: 20.85 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [02:21<00:58, 19.51it/s, est. speed input: 21331.12 toks/s, output: 20.83 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [02:23<00:57, 19.48it/s, est. speed input: 21314.31 toks/s, output: 20.81 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [02:24<00:55, 19.46it/s, est. speed input: 21298.05 toks/s, output: 20.80 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [02:26<00:54, 19.45it/s, est. speed input: 21282.39 toks/s, output: 20.78 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [02:28<00:52, 19.45it/s, est. speed input: 21266.89 toks/s, output: 20.77 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [02:29<00:50, 19.43it/s, est. speed input: 21251.56 toks/s, output: 20.75 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [02:31<00:49, 19.43it/s, est. speed input: 21236.75 toks/s, output: 20.74 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [02:32<00:47, 19.42it/s, est. speed input: 21221.97 toks/s, output: 20.72 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [02:34<00:46, 19.43it/s, est. speed input: 21208.01 toks/s, output: 20.71 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [02:36<00:44, 19.43it/s, est. speed input: 21194.13 toks/s, output: 20.70 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [02:37<00:42, 19.41it/s, est. speed input: 21179.97 toks/s, output: 20.68 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [02:39<00:41, 19.42it/s, est. speed input: 21166.96 toks/s, output: 20.67 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [02:41<00:39, 19.41it/s, est. speed input: 21153.53 toks/s, output: 20.66 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [02:42<00:37, 19.42it/s, est. speed input: 21140.69 toks/s, output: 20.65 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [02:44<00:36, 19.42it/s, est. speed input: 21128.37 toks/s, output: 20.63 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [02:46<00:34, 19.42it/s, est. speed input: 21116.08 toks/s, output: 20.62 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [02:47<00:32, 19.43it/s, est. speed input: 21104.10 toks/s, output: 20.61 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:49<00:31, 19.42it/s, est. speed input: 21092.24 toks/s, output: 20.60 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:51<00:29, 19.42it/s, est. speed input: 21080.52 toks/s, output: 20.59 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:52<00:27, 19.42it/s, est. speed input: 21069.05 toks/s, output: 20.58 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:54<00:26, 19.41it/s, est. speed input: 21057.58 toks/s, output: 20.56 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:56<00:24, 19.41it/s, est. speed input: 21046.40 toks/s, output: 20.55 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:57<00:22, 19.41it/s, est. speed input: 21035.55 toks/s, output: 20.54 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:59<00:21, 19.57it/s, est. speed input: 21030.22 toks/s, output: 20.54 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [03:00<00:19, 19.53it/s, est. speed input: 21019.85 toks/s, output: 20.53 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [03:02<00:17, 19.49it/s, est. speed input: 21009.33 toks/s, output: 20.52 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [03:04<00:16, 19.46it/s, est. speed input: 20999.01 toks/s, output: 20.51 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [03:05<00:14, 19.43it/s, est. speed input: 20988.68 toks/s, output: 20.50 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [03:07<00:13, 19.43it/s, est. speed input: 20979.20 toks/s, output: 20.49 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [03:09<00:11, 19.42it/s, est. speed input: 20969.34 toks/s, output: 20.48 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [03:10<00:09, 19.57it/s, est. speed input: 20964.75 toks/s, output: 20.47 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [03:12<00:08, 19.53it/s, est. speed input: 20955.48 toks/s, output: 20.46 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [03:14<00:06, 19.48it/s, est. speed input: 20945.95 toks/s, output: 20.46 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [03:15<00:04, 19.46it/s, est. speed input: 20937.04 toks/s, output: 20.45 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [03:17<00:03, 19.43it/s, est. speed input: 20927.77 toks/s, output: 20.44 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [03:18<00:01, 19.63it/s, est. speed input: 20925.17 toks/s, output: 20.43 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:18<00:00, 19.63it/s, est. speed input: 21079.47 toks/s, output: 20.59 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:18<00:00, 20.59it/s, est. speed input: 21079.47 toks/s, output: 20.59 toks/s]
[rank0]:[W126 15:50:26.233282751 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 15:50:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:51:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1561214) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1561214) WARNING 01-26 15:51:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.73 requests/s, 20222.64 total tokens/s, 19.73 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 15:51:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:51:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:51:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:51:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:51:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:51:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:51:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:51:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:51:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:51:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:51:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:51:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:51:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:51:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:51:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:51:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:51:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.25it/s]
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.14it/s]
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.57it/s]
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.39it/s]
(EngineCore_DP0 pid=1561214) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]
(EngineCore_DP0 pid=1561214) 
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1561214) [2026-01-26 15:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1561214) [rank0]:W0126 15:51:49.869000 1561214 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1561214) [rank0]:W0126 15:51:49.923000 1561214 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1561214) [rank0]:W0126 15:51:50.543000 1561214 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1561214) [rank0]:W0126 15:51:50.627000 1561214 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1561214) 2026-01-26 15:51:56,539 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1561214) 2026-01-26 15:51:57,456 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1561214) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:26,  1.47s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:02<00:17,  1.01s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:10,  1.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:07,  1.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:05,  2.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:02<00:02,  4.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:02,  4.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:04<00:02,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:04<00:02,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:04<00:01,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:04<00:01,  4.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:04<00:00,  6.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:04<00:00,  7.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:04<00:00,  7.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  6.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:05<00:00,  3.67it/s]
(EngineCore_DP0 pid=1561214) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:06,  1.61it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:01,  4.49it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  6.66it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  6.83it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  8.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.59it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 31/8192 [00:00<00:26, 306.93it/s]
Adding requests:   1%|          | 71/8192 [00:00<00:22, 355.24it/s]
Adding requests:   1%|▏         | 108/8192 [00:00<00:22, 359.65it/s]
Adding requests:   2%|▏         | 145/8192 [00:00<00:22, 363.23it/s]
Adding requests:   2%|▏         | 185/8192 [00:00<00:21, 375.56it/s]
Adding requests:   3%|▎         | 224/8192 [00:00<00:20, 380.12it/s]
Adding requests:   3%|▎         | 263/8192 [00:00<00:21, 375.98it/s]
Adding requests:   4%|▎         | 302/8192 [00:00<00:20, 378.23it/s]
Adding requests:   4%|▍         | 341/8192 [00:00<00:20, 381.38it/s]
Adding requests:   5%|▍         | 380/8192 [00:01<00:20, 382.24it/s]
Adding requests:   5%|▌         | 421/8192 [00:01<00:19, 389.44it/s]
Adding requests:   6%|▌         | 460/8192 [00:01<00:20, 386.16it/s]
Adding requests:   6%|▌         | 502/8192 [00:01<00:19, 395.30it/s]
Adding requests:   7%|▋         | 544/8192 [00:01<00:19, 401.44it/s]
Adding requests:   7%|▋         | 585/8192 [00:01<00:19, 395.75it/s]
Adding requests:   8%|▊         | 625/8192 [00:01<00:19, 387.24it/s]
Adding requests:   8%|▊         | 664/8192 [00:01<00:19, 380.55it/s]
Adding requests:   9%|▊         | 704/8192 [00:01<00:19, 384.71it/s]
Adding requests:   9%|▉         | 743/8192 [00:01<00:19, 379.81it/s]
Adding requests:  10%|▉         | 782/8192 [00:02<00:19, 381.62it/s]
Adding requests:  10%|█         | 821/8192 [00:02<00:19, 381.85it/s]
Adding requests:  11%|█         | 862/8192 [00:02<00:18, 388.36it/s]
Adding requests:  11%|█         | 902/8192 [00:02<00:18, 390.99it/s]
Adding requests:  11%|█▏        | 942/8192 [00:02<00:18, 383.61it/s]
Adding requests:  12%|█▏        | 981/8192 [00:02<00:18, 380.37it/s]
Adding requests:  12%|█▏        | 1020/8192 [00:02<00:19, 374.08it/s]
Adding requests:  13%|█▎        | 1058/8192 [00:02<00:19, 371.62it/s]
Adding requests:  13%|█▎        | 1096/8192 [00:02<00:19, 369.73it/s]
Adding requests:  14%|█▍        | 1136/8192 [00:02<00:18, 376.91it/s]
Adding requests:  14%|█▍        | 1174/8192 [00:03<00:18, 373.93it/s]
Adding requests:  15%|█▍        | 1213/8192 [00:03<00:18, 375.72it/s]
Adding requests:  15%|█▌        | 1252/8192 [00:03<00:18, 378.53it/s]
Adding requests:  16%|█▌        | 1290/8192 [00:03<00:18, 371.07it/s]
Adding requests:  16%|█▌        | 1329/8192 [00:03<00:18, 374.27it/s]
Adding requests:  17%|█▋        | 1368/8192 [00:03<00:18, 377.59it/s]
Adding requests:  17%|█▋        | 1406/8192 [00:03<00:18, 375.45it/s]
Adding requests:  18%|█▊        | 1444/8192 [00:03<00:17, 375.96it/s]
Adding requests:  18%|█▊        | 1483/8192 [00:03<00:17, 379.11it/s]
Adding requests:  19%|█▊        | 1522/8192 [00:04<00:17, 381.26it/s]
Adding requests:  19%|█▉        | 1561/8192 [00:04<00:17, 375.86it/s]
Adding requests:  20%|█▉        | 1599/8192 [00:04<00:17, 369.53it/s]
Adding requests:  20%|█▉        | 1636/8192 [00:04<00:17, 366.59it/s]
Adding requests:  20%|██        | 1673/8192 [00:04<00:18, 361.26it/s]
Adding requests:  21%|██        | 1712/8192 [00:04<00:17, 367.50it/s]
Adding requests:  21%|██▏       | 1751/8192 [00:04<00:17, 372.01it/s]
Adding requests:  22%|██▏       | 1789/8192 [00:04<00:17, 373.13it/s]
Adding requests:  22%|██▏       | 1827/8192 [00:04<00:17, 366.04it/s]
Adding requests:  23%|██▎       | 1865/8192 [00:04<00:17, 368.47it/s]
Adding requests:  23%|██▎       | 1903/8192 [00:05<00:16, 371.46it/s]
Adding requests:  24%|██▎       | 1943/8192 [00:05<00:16, 378.90it/s]
Adding requests:  24%|██▍       | 1982/8192 [00:05<00:16, 380.73it/s]
Adding requests:  25%|██▍       | 2021/8192 [00:05<00:16, 370.01it/s]
Adding requests:  25%|██▌       | 2059/8192 [00:05<00:16, 368.72it/s]
Adding requests:  26%|██▌       | 2096/8192 [00:05<00:16, 365.64it/s]
Adding requests:  26%|██▌       | 2134/8192 [00:05<00:16, 369.62it/s]
Adding requests:  27%|██▋       | 2171/8192 [00:05<00:16, 364.31it/s]
Adding requests:  27%|██▋       | 2208/8192 [00:05<00:16, 361.26it/s]
Adding requests:  27%|██▋       | 2246/8192 [00:05<00:16, 365.22it/s]
Adding requests:  28%|██▊       | 2286/8192 [00:06<00:15, 373.20it/s]
Adding requests:  28%|██▊       | 2325/8192 [00:06<00:15, 377.82it/s]
Adding requests:  29%|██▉       | 2364/8192 [00:06<00:15, 380.90it/s]
Adding requests:  29%|██▉       | 2404/8192 [00:06<00:15, 385.03it/s]
Adding requests:  30%|██▉       | 2443/8192 [00:06<00:14, 384.70it/s]
Adding requests:  30%|███       | 2482/8192 [00:06<00:14, 383.09it/s]
Adding requests:  31%|███       | 2522/8192 [00:06<00:14, 385.59it/s]
Adding requests:  31%|███▏      | 2564/8192 [00:06<00:14, 394.18it/s]
Adding requests:  32%|███▏      | 2604/8192 [00:06<00:14, 394.86it/s]
Adding requests:  32%|███▏      | 2644/8192 [00:07<00:14, 382.85it/s]
Adding requests:  33%|███▎      | 2683/8192 [00:07<00:14, 379.68it/s]
Adding requests:  33%|███▎      | 2722/8192 [00:07<00:14, 377.41it/s]
Adding requests:  34%|███▎      | 2762/8192 [00:07<00:14, 382.85it/s]
Adding requests:  34%|███▍      | 2803/8192 [00:07<00:13, 390.79it/s]
Adding requests:  35%|███▍      | 2843/8192 [00:07<00:13, 388.50it/s]
Adding requests:  35%|███▌      | 2882/8192 [00:07<00:13, 386.74it/s]
Adding requests:  36%|███▌      | 2921/8192 [00:07<00:13, 387.59it/s]
Adding requests:  36%|███▌      | 2963/8192 [00:07<00:13, 394.33it/s]
Adding requests:  37%|███▋      | 3003/8192 [00:07<00:13, 394.88it/s]
Adding requests:  37%|███▋      | 3044/8192 [00:08<00:12, 398.54it/s]
Adding requests:  38%|███▊      | 3084/8192 [00:08<00:12, 398.86it/s]
Adding requests:  38%|███▊      | 3126/8192 [00:08<00:12, 403.59it/s]
Adding requests:  39%|███▊      | 3167/8192 [00:08<00:13, 384.08it/s]
Adding requests:  39%|███▉      | 3206/8192 [00:08<00:13, 382.88it/s]
Adding requests:  40%|███▉      | 3246/8192 [00:08<00:12, 386.72it/s]
Adding requests:  40%|████      | 3285/8192 [00:08<00:12, 382.52it/s]
Adding requests:  41%|████      | 3324/8192 [00:08<00:12, 378.52it/s]
Adding requests:  41%|████      | 3363/8192 [00:08<00:12, 380.58it/s]
Adding requests:  42%|████▏     | 3404/8192 [00:08<00:12, 386.45it/s]
Adding requests:  42%|████▏     | 3445/8192 [00:09<00:12, 391.35it/s]
Adding requests:  43%|████▎     | 3485/8192 [00:09<00:12, 387.32it/s]
Adding requests:  43%|████▎     | 3526/8192 [00:09<00:11, 393.89it/s]
Adding requests:  44%|████▎     | 3568/8192 [00:09<00:11, 400.09it/s]
Adding requests:  44%|████▍     | 3609/8192 [00:09<00:11, 395.16it/s]
Adding requests:  45%|████▍     | 3650/8192 [00:09<00:11, 396.66it/s]
Adding requests:  45%|████▌     | 3690/8192 [00:09<00:11, 386.91it/s]
Adding requests:  46%|████▌     | 3729/8192 [00:09<00:11, 387.80it/s]
Adding requests:  46%|████▌     | 3768/8192 [00:09<00:11, 380.88it/s]
Adding requests:  46%|████▋     | 3807/8192 [00:10<00:11, 367.14it/s]
Adding requests:  47%|████▋     | 3846/8192 [00:10<00:11, 372.88it/s]
Adding requests:  47%|████▋     | 3884/8192 [00:10<00:11, 374.72it/s]
Adding requests:  48%|████▊     | 3922/8192 [00:10<00:11, 370.46it/s]
Adding requests:  48%|████▊     | 3961/8192 [00:10<00:11, 374.04it/s]
Adding requests:  49%|████▉     | 3999/8192 [00:10<00:11, 371.89it/s]
Adding requests:  49%|████▉     | 4038/8192 [00:10<00:11, 375.34it/s]
Adding requests:  50%|████▉     | 4076/8192 [00:10<00:11, 373.73it/s]
Adding requests:  50%|█████     | 4115/8192 [00:10<00:10, 375.98it/s]
Adding requests:  51%|█████     | 4153/8192 [00:10<00:10, 372.29it/s]
Adding requests:  51%|█████     | 4191/8192 [00:11<00:10, 373.18it/s]
Adding requests:  52%|█████▏    | 4229/8192 [00:11<00:10, 371.26it/s]
Adding requests:  52%|█████▏    | 4267/8192 [00:11<00:10, 373.60it/s]
Adding requests:  53%|█████▎    | 4305/8192 [00:11<00:10, 373.84it/s]
Adding requests:  53%|█████▎    | 4343/8192 [00:11<00:10, 374.19it/s]
Adding requests:  53%|█████▎    | 4382/8192 [00:11<00:10, 376.46it/s]
Adding requests:  54%|█████▍    | 4420/8192 [00:11<00:10, 376.13it/s]
Adding requests:  54%|█████▍    | 4458/8192 [00:11<00:09, 376.32it/s]
Adding requests:  55%|█████▍    | 4496/8192 [00:11<00:10, 367.23it/s]
Adding requests:  55%|█████▌    | 4535/8192 [00:11<00:09, 371.68it/s]
Adding requests:  56%|█████▌    | 4573/8192 [00:12<00:09, 368.32it/s]
Adding requests:  56%|█████▋    | 4611/8192 [00:12<00:09, 371.14it/s]
Adding requests:  57%|█████▋    | 4649/8192 [00:12<00:09, 368.77it/s]
Adding requests:  57%|█████▋    | 4686/8192 [00:12<00:09, 363.85it/s]
Adding requests:  58%|█████▊    | 4725/8192 [00:12<00:09, 369.22it/s]
Adding requests:  58%|█████▊    | 4765/8192 [00:12<00:09, 378.03it/s]
Adding requests:  59%|█████▊    | 4803/8192 [00:12<00:09, 370.99it/s]
Adding requests:  59%|█████▉    | 4841/8192 [00:12<00:09, 368.56it/s]
Adding requests:  60%|█████▉    | 4881/8192 [00:12<00:08, 375.95it/s]
Adding requests:  60%|██████    | 4919/8192 [00:12<00:08, 375.97it/s]
Adding requests:  61%|██████    | 4959/8192 [00:13<00:08, 381.58it/s]
Adding requests:  61%|██████    | 4999/8192 [00:13<00:08, 384.58it/s]
Adding requests:  62%|██████▏   | 5040/8192 [00:13<00:08, 391.12it/s]
Adding requests:  62%|██████▏   | 5080/8192 [00:13<00:07, 390.75it/s]
Adding requests:  62%|██████▎   | 5120/8192 [00:13<00:07, 388.86it/s]
Adding requests:  63%|██████▎   | 5160/8192 [00:13<00:07, 389.83it/s]
Adding requests:  63%|██████▎   | 5199/8192 [00:13<00:07, 380.67it/s]
Adding requests:  64%|██████▍   | 5238/8192 [00:13<00:07, 382.20it/s]
Adding requests:  64%|██████▍   | 5277/8192 [00:13<00:07, 381.55it/s]
Adding requests:  65%|██████▍   | 5316/8192 [00:14<00:07, 378.57it/s]
Adding requests:  65%|██████▌   | 5356/8192 [00:14<00:07, 381.81it/s]
Adding requests:  66%|██████▌   | 5395/8192 [00:14<00:07, 378.66it/s]
Adding requests:  66%|██████▋   | 5433/8192 [00:14<00:07, 376.65it/s]
Adding requests:  67%|██████▋   | 5473/8192 [00:14<00:07, 383.39it/s]
Adding requests:  67%|██████▋   | 5513/8192 [00:14<00:06, 388.06it/s]
Adding requests:  68%|██████▊   | 5552/8192 [00:14<00:06, 383.93it/s]
Adding requests:  68%|██████▊   | 5591/8192 [00:14<00:06, 380.02it/s]
Adding requests:  69%|██████▊   | 5631/8192 [00:14<00:06, 385.33it/s]
Adding requests:  69%|██████▉   | 5670/8192 [00:14<00:06, 383.54it/s]
Adding requests:  70%|██████▉   | 5709/8192 [00:15<00:06, 383.31it/s]
Adding requests:  70%|███████   | 5748/8192 [00:15<00:06, 380.94it/s]
Adding requests:  71%|███████   | 5787/8192 [00:15<00:06, 382.99it/s]
Adding requests:  71%|███████   | 5828/8192 [00:15<00:06, 388.91it/s]
Adding requests:  72%|███████▏  | 5867/8192 [00:15<00:06, 383.20it/s]
Adding requests:  72%|███████▏  | 5906/8192 [00:15<00:05, 381.71it/s]
Adding requests:  73%|███████▎  | 5947/8192 [00:15<00:05, 387.73it/s]
Adding requests:  73%|███████▎  | 5987/8192 [00:15<00:05, 389.98it/s]
Adding requests:  74%|███████▎  | 6027/8192 [00:15<00:05, 389.82it/s]
Adding requests:  74%|███████▍  | 6066/8192 [00:15<00:05, 386.66it/s]
Adding requests:  75%|███████▍  | 6105/8192 [00:16<00:05, 381.75it/s]
Adding requests:  75%|███████▌  | 6145/8192 [00:16<00:05, 386.40it/s]
Adding requests:  75%|███████▌  | 6184/8192 [00:16<00:05, 386.61it/s]
Adding requests:  76%|███████▌  | 6223/8192 [00:16<00:05, 385.40it/s]
Adding requests:  76%|███████▋  | 6262/8192 [00:16<00:05, 384.26it/s]
Adding requests:  77%|███████▋  | 6301/8192 [00:16<00:04, 385.35it/s]
Adding requests:  77%|███████▋  | 6344/8192 [00:16<00:04, 395.95it/s]
Adding requests:  78%|███████▊  | 6384/8192 [00:16<00:04, 392.88it/s]
Adding requests:  78%|███████▊  | 6424/8192 [00:16<00:04, 382.38it/s]
Adding requests:  79%|███████▉  | 6463/8192 [00:17<00:04, 375.87it/s]
Adding requests:  79%|███████▉  | 6501/8192 [00:17<00:04, 374.03it/s]
Adding requests:  80%|███████▉  | 6541/8192 [00:17<00:04, 378.98it/s]
Adding requests:  80%|████████  | 6581/8192 [00:17<00:04, 381.71it/s]
Adding requests:  81%|████████  | 6620/8192 [00:17<00:04, 381.62it/s]
Adding requests:  81%|████████▏ | 6660/8192 [00:17<00:03, 384.49it/s]
Adding requests:  82%|████████▏ | 6699/8192 [00:17<00:03, 381.78it/s]
Adding requests:  82%|████████▏ | 6739/8192 [00:17<00:03, 385.78it/s]
Adding requests:  83%|████████▎ | 6780/8192 [00:17<00:03, 391.57it/s]
Adding requests:  83%|████████▎ | 6820/8192 [00:17<00:03, 380.96it/s]
Adding requests:  84%|████████▎ | 6859/8192 [00:18<00:03, 381.79it/s]
Adding requests:  84%|████████▍ | 6898/8192 [00:18<00:03, 383.58it/s]
Adding requests:  85%|████████▍ | 6939/8192 [00:18<00:03, 388.23it/s]
Adding requests:  85%|████████▌ | 6978/8192 [00:18<00:03, 382.68it/s]
Adding requests:  86%|████████▌ | 7019/8192 [00:18<00:03, 389.35it/s]
Adding requests:  86%|████████▌ | 7058/8192 [00:18<00:02, 385.11it/s]
Adding requests:  87%|████████▋ | 7097/8192 [00:18<00:02, 381.89it/s]
Adding requests:  87%|████████▋ | 7136/8192 [00:18<00:02, 382.08it/s]
Adding requests:  88%|████████▊ | 7176/8192 [00:18<00:02, 386.24it/s]
Adding requests:  88%|████████▊ | 7218/8192 [00:18<00:02, 394.24it/s]
Adding requests:  89%|████████▊ | 7258/8192 [00:19<00:02, 378.12it/s]
Adding requests:  89%|████████▉ | 7298/8192 [00:19<00:02, 381.40it/s]
Adding requests:  90%|████████▉ | 7337/8192 [00:19<00:02, 380.87it/s]
Adding requests:  90%|█████████ | 7377/8192 [00:19<00:02, 385.21it/s]
Adding requests:  91%|█████████ | 7416/8192 [00:19<00:02, 383.64it/s]
Adding requests:  91%|█████████ | 7455/8192 [00:19<00:01, 382.10it/s]
Adding requests:  91%|█████████▏| 7494/8192 [00:19<00:01, 380.36it/s]
Adding requests:  92%|█████████▏| 7533/8192 [00:19<00:01, 382.24it/s]
Adding requests:  92%|█████████▏| 7572/8192 [00:19<00:01, 382.44it/s]
Adding requests:  93%|█████████▎| 7611/8192 [00:19<00:01, 381.94it/s]
Adding requests:  93%|█████████▎| 7651/8192 [00:20<00:01, 386.22it/s]
Adding requests:  94%|█████████▍| 7693/8192 [00:20<00:01, 394.99it/s]
Adding requests:  94%|█████████▍| 7733/8192 [00:20<00:01, 392.32it/s]
Adding requests:  95%|█████████▍| 7773/8192 [00:20<00:01, 386.67it/s]
Adding requests:  95%|█████████▌| 7812/8192 [00:20<00:00, 382.02it/s]
Adding requests:  96%|█████████▌| 7851/8192 [00:20<00:00, 378.08it/s]
Adding requests:  96%|█████████▋| 7889/8192 [00:20<00:00, 378.35it/s]
Adding requests:  97%|█████████▋| 7930/8192 [00:20<00:00, 385.76it/s]
Adding requests:  97%|█████████▋| 7971/8192 [00:20<00:00, 392.69it/s]
Adding requests:  98%|█████████▊| 8011/8192 [00:21<00:00, 391.56it/s]
Adding requests:  98%|█████████▊| 8051/8192 [00:21<00:00, 388.27it/s]
Adding requests:  99%|█████████▉| 8092/8192 [00:21<00:00, 392.91it/s]
Adding requests:  99%|█████████▉| 8132/8192 [00:21<00:00, 385.88it/s]
Adding requests: 100%|█████████▉| 8171/8192 [00:21<00:00, 379.90it/s]
Adding requests: 100%|██████████| 8192/8192 [00:21<00:00, 380.87it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 368/8192 [00:00<00:08, 920.74it/s, est. speed input: 942896.94 toks/s, output: 920.76 toks/s]
Processed prompts:   6%|▌         | 461/8192 [00:03<01:16, 100.89it/s, est. speed input: 131311.13 toks/s, output: 128.23 toks/s]
Processed prompts:   6%|▌         | 501/8192 [00:06<02:31, 50.70it/s, est. speed input: 75527.78 toks/s, output: 73.76 toks/s]   
Processed prompts:   7%|▋         | 560/8192 [00:09<03:30, 36.26it/s, est. speed input: 57414.57 toks/s, output: 56.07 toks/s]
Processed prompts:   8%|▊         | 624/8192 [00:13<04:12, 29.92it/s, est. speed input: 48458.73 toks/s, output: 47.32 toks/s]
Processed prompts:   8%|▊         | 688/8192 [00:16<04:44, 26.34it/s, est. speed input: 42973.17 toks/s, output: 41.97 toks/s]
Processed prompts:   9%|▉         | 752/8192 [00:19<05:05, 24.32it/s, est. speed input: 39391.80 toks/s, output: 38.47 toks/s]
Processed prompts:  10%|▉         | 816/8192 [00:22<05:22, 22.89it/s, est. speed input: 36720.13 toks/s, output: 35.86 toks/s]
Processed prompts:  11%|█         | 880/8192 [00:25<05:32, 21.96it/s, est. speed input: 34711.45 toks/s, output: 33.90 toks/s]
Processed prompts:  12%|█▏        | 944/8192 [00:29<05:40, 21.30it/s, est. speed input: 33124.59 toks/s, output: 32.35 toks/s]
Processed prompts:  12%|█▏        | 1008/8192 [00:32<05:44, 20.87it/s, est. speed input: 31862.68 toks/s, output: 31.12 toks/s]
Processed prompts:  13%|█▎        | 1072/8192 [00:35<05:46, 20.57it/s, est. speed input: 30820.63 toks/s, output: 30.10 toks/s]
Processed prompts:  14%|█▍        | 1136/8192 [00:38<05:46, 20.34it/s, est. speed input: 29948.11 toks/s, output: 29.25 toks/s]
Processed prompts:  15%|█▍        | 1200/8192 [00:42<05:46, 20.19it/s, est. speed input: 29207.58 toks/s, output: 28.52 toks/s]
Processed prompts:  15%|█▌        | 1264/8192 [00:45<05:45, 20.07it/s, est. speed input: 28569.43 toks/s, output: 27.90 toks/s]
Processed prompts:  16%|█▌        | 1328/8192 [00:48<05:43, 19.99it/s, est. speed input: 28017.95 toks/s, output: 27.36 toks/s]
Processed prompts:  17%|█▋        | 1392/8192 [00:51<05:41, 19.93it/s, est. speed input: 27534.28 toks/s, output: 26.89 toks/s]
Processed prompts:  18%|█▊        | 1456/8192 [00:55<05:38, 19.88it/s, est. speed input: 27104.09 toks/s, output: 26.47 toks/s]
Processed prompts:  19%|█▊        | 1520/8192 [00:58<05:36, 19.84it/s, est. speed input: 26721.87 toks/s, output: 26.10 toks/s]
Processed prompts:  19%|█▉        | 1584/8192 [01:01<05:31, 19.91it/s, est. speed input: 26401.33 toks/s, output: 25.78 toks/s]
Processed prompts:  20%|██        | 1648/8192 [01:04<05:29, 19.86it/s, est. speed input: 26092.48 toks/s, output: 25.48 toks/s]
Processed prompts:  21%|██        | 1712/8192 [01:07<05:26, 19.85it/s, est. speed input: 25815.75 toks/s, output: 25.21 toks/s]
Processed prompts:  22%|██▏       | 1776/8192 [01:11<05:23, 19.81it/s, est. speed input: 25559.40 toks/s, output: 24.96 toks/s]
Processed prompts:  22%|██▏       | 1840/8192 [01:14<05:21, 19.78it/s, est. speed input: 25325.56 toks/s, output: 24.73 toks/s]
Processed prompts:  23%|██▎       | 1904/8192 [01:17<05:18, 19.76it/s, est. speed input: 25110.86 toks/s, output: 24.52 toks/s]
Processed prompts:  24%|██▍       | 1968/8192 [01:20<05:15, 19.74it/s, est. speed input: 24912.68 toks/s, output: 24.33 toks/s]
Processed prompts:  25%|██▍       | 2032/8192 [01:24<05:12, 19.73it/s, est. speed input: 24729.96 toks/s, output: 24.15 toks/s]
Processed prompts:  26%|██▌       | 2096/8192 [01:27<05:09, 19.71it/s, est. speed input: 24558.20 toks/s, output: 23.98 toks/s]
Processed prompts:  26%|██▋       | 2160/8192 [01:30<05:04, 19.80it/s, est. speed input: 24414.21 toks/s, output: 23.84 toks/s]
Processed prompts:  27%|██▋       | 2224/8192 [01:33<05:02, 19.75it/s, est. speed input: 24265.63 toks/s, output: 23.70 toks/s]
Processed prompts:  28%|██▊       | 2288/8192 [01:37<04:59, 19.74it/s, est. speed input: 24129.06 toks/s, output: 23.56 toks/s]
Processed prompts:  29%|██▊       | 2352/8192 [01:40<04:56, 19.72it/s, est. speed input: 23999.38 toks/s, output: 23.44 toks/s]
Processed prompts:  29%|██▉       | 2416/8192 [01:43<04:53, 19.71it/s, est. speed input: 23879.38 toks/s, output: 23.32 toks/s]
Processed prompts:  30%|███       | 2480/8192 [01:46<04:49, 19.70it/s, est. speed input: 23766.26 toks/s, output: 23.21 toks/s]
Processed prompts:  31%|███       | 2544/8192 [01:50<04:46, 19.69it/s, est. speed input: 23659.24 toks/s, output: 23.10 toks/s]
Processed prompts:  32%|███▏      | 2608/8192 [01:53<04:43, 19.69it/s, est. speed input: 23558.66 toks/s, output: 23.01 toks/s]
Processed prompts:  33%|███▎      | 2672/8192 [01:56<04:40, 19.69it/s, est. speed input: 23463.43 toks/s, output: 22.91 toks/s]
Processed prompts:  33%|███▎      | 2736/8192 [01:59<04:37, 19.70it/s, est. speed input: 23374.92 toks/s, output: 22.83 toks/s]
Processed prompts:  34%|███▍      | 2800/8192 [02:03<04:33, 19.70it/s, est. speed input: 23290.40 toks/s, output: 22.74 toks/s]
Processed prompts:  35%|███▍      | 2864/8192 [02:06<04:29, 19.79it/s, est. speed input: 23219.01 toks/s, output: 22.67 toks/s]
Processed prompts:  36%|███▌      | 2928/8192 [02:09<04:26, 19.76it/s, est. speed input: 23142.21 toks/s, output: 22.60 toks/s]
Processed prompts:  37%|███▋      | 2992/8192 [02:12<04:23, 19.74it/s, est. speed input: 23069.96 toks/s, output: 22.53 toks/s]
Processed prompts:  37%|███▋      | 3056/8192 [02:16<04:20, 19.74it/s, est. speed input: 23001.39 toks/s, output: 22.46 toks/s]
Processed prompts:  38%|███▊      | 3120/8192 [02:19<04:17, 19.72it/s, est. speed input: 22934.91 toks/s, output: 22.40 toks/s]
Processed prompts:  39%|███▉      | 3184/8192 [02:22<04:14, 19.72it/s, est. speed input: 22872.12 toks/s, output: 22.34 toks/s]
Processed prompts:  40%|███▉      | 3248/8192 [02:25<04:10, 19.70it/s, est. speed input: 22811.18 toks/s, output: 22.28 toks/s]
Processed prompts:  40%|████      | 3312/8192 [02:29<04:07, 19.69it/s, est. speed input: 22752.89 toks/s, output: 22.22 toks/s]
Processed prompts:  41%|████      | 3376/8192 [02:32<04:04, 19.69it/s, est. speed input: 22697.51 toks/s, output: 22.17 toks/s]
Processed prompts:  42%|████▏     | 3440/8192 [02:35<04:01, 19.69it/s, est. speed input: 22644.60 toks/s, output: 22.11 toks/s]
Processed prompts:  43%|████▎     | 3504/8192 [02:38<03:57, 19.70it/s, est. speed input: 22594.76 toks/s, output: 22.07 toks/s]
Processed prompts:  44%|████▎     | 3568/8192 [02:42<03:54, 19.70it/s, est. speed input: 22545.68 toks/s, output: 22.02 toks/s]
Processed prompts:  44%|████▍     | 3632/8192 [02:45<03:50, 19.77it/s, est. speed input: 22504.19 toks/s, output: 21.98 toks/s]
Processed prompts:  45%|████▌     | 3696/8192 [02:48<03:47, 19.73it/s, est. speed input: 22458.01 toks/s, output: 21.93 toks/s]
Processed prompts:  46%|████▌     | 3760/8192 [02:51<03:45, 19.70it/s, est. speed input: 22413.02 toks/s, output: 21.89 toks/s]
Processed prompts:  47%|████▋     | 3824/8192 [02:55<03:42, 19.67it/s, est. speed input: 22369.70 toks/s, output: 21.85 toks/s]
Processed prompts:  47%|████▋     | 3888/8192 [02:58<03:38, 19.73it/s, est. speed input: 22333.12 toks/s, output: 21.81 toks/s]
Processed prompts:  48%|████▊     | 3952/8192 [03:01<03:35, 19.70it/s, est. speed input: 22293.06 toks/s, output: 21.77 toks/s]
Processed prompts:  49%|████▉     | 4016/8192 [03:04<03:32, 19.69it/s, est. speed input: 22254.92 toks/s, output: 21.73 toks/s]
Processed prompts:  50%|████▉     | 4080/8192 [03:07<03:27, 19.77it/s, est. speed input: 22224.24 toks/s, output: 21.70 toks/s]
Processed prompts:  51%|█████     | 4144/8192 [03:11<03:24, 19.75it/s, est. speed input: 22189.56 toks/s, output: 21.67 toks/s]
Processed prompts:  51%|█████▏    | 4208/8192 [03:14<03:21, 19.72it/s, est. speed input: 22154.96 toks/s, output: 21.64 toks/s]
Processed prompts:  52%|█████▏    | 4272/8192 [03:17<03:19, 19.70it/s, est. speed input: 22121.19 toks/s, output: 21.60 toks/s]
Processed prompts:  53%|█████▎    | 4336/8192 [03:21<03:15, 19.69it/s, est. speed input: 22089.53 toks/s, output: 21.57 toks/s]
Processed prompts:  54%|█████▎    | 4400/8192 [03:24<03:12, 19.69it/s, est. speed input: 22058.46 toks/s, output: 21.54 toks/s]
Processed prompts:  54%|█████▍    | 4464/8192 [03:27<03:09, 19.68it/s, est. speed input: 22028.26 toks/s, output: 21.51 toks/s]
Processed prompts:  55%|█████▌    | 4528/8192 [03:30<03:06, 19.69it/s, est. speed input: 21999.70 toks/s, output: 21.48 toks/s]
Processed prompts:  56%|█████▌    | 4592/8192 [03:34<03:02, 19.67it/s, est. speed input: 21970.97 toks/s, output: 21.46 toks/s]
Processed prompts:  57%|█████▋    | 4656/8192 [03:37<02:59, 19.67it/s, est. speed input: 21943.33 toks/s, output: 21.43 toks/s]
Processed prompts:  58%|█████▊    | 4720/8192 [03:40<02:56, 19.66it/s, est. speed input: 21916.51 toks/s, output: 21.40 toks/s]
Processed prompts:  58%|█████▊    | 4784/8192 [03:43<02:53, 19.67it/s, est. speed input: 21891.02 toks/s, output: 21.38 toks/s]
Processed prompts:  59%|█████▉    | 4848/8192 [03:47<02:50, 19.66it/s, est. speed input: 21865.62 toks/s, output: 21.35 toks/s]
Processed prompts:  60%|█████▉    | 4912/8192 [03:50<02:46, 19.66it/s, est. speed input: 21840.71 toks/s, output: 21.33 toks/s]
Processed prompts:  61%|██████    | 4976/8192 [03:53<02:42, 19.76it/s, est. speed input: 21822.30 toks/s, output: 21.31 toks/s]
Processed prompts:  62%|██████▏   | 5040/8192 [03:56<02:39, 19.74it/s, est. speed input: 21799.58 toks/s, output: 21.29 toks/s]
Processed prompts:  62%|██████▏   | 5104/8192 [04:00<02:36, 19.72it/s, est. speed input: 21776.90 toks/s, output: 21.27 toks/s]
Processed prompts:  63%|██████▎   | 5168/8192 [04:03<02:33, 19.71it/s, est. speed input: 21755.21 toks/s, output: 21.25 toks/s]
Processed prompts:  64%|██████▍   | 5232/8192 [04:06<02:30, 19.71it/s, est. speed input: 21734.42 toks/s, output: 21.23 toks/s]
Processed prompts:  65%|██████▍   | 5296/8192 [04:09<02:26, 19.71it/s, est. speed input: 21714.19 toks/s, output: 21.21 toks/s]
Processed prompts:  65%|██████▌   | 5360/8192 [04:12<02:23, 19.70it/s, est. speed input: 21694.41 toks/s, output: 21.19 toks/s]
Processed prompts:  66%|██████▌   | 5424/8192 [04:16<02:20, 19.69it/s, est. speed input: 21674.59 toks/s, output: 21.17 toks/s]
Processed prompts:  67%|██████▋   | 5488/8192 [04:19<02:17, 19.69it/s, est. speed input: 21655.54 toks/s, output: 21.15 toks/s]
Processed prompts:  68%|██████▊   | 5552/8192 [04:22<02:14, 19.69it/s, est. speed input: 21637.04 toks/s, output: 21.13 toks/s]
Processed prompts:  69%|██████▊   | 5616/8192 [04:26<02:10, 19.68it/s, est. speed input: 21618.68 toks/s, output: 21.11 toks/s]
Processed prompts:  69%|██████▉   | 5680/8192 [04:29<02:07, 19.70it/s, est. speed input: 21601.62 toks/s, output: 21.10 toks/s]
Processed prompts:  70%|███████   | 5744/8192 [04:32<02:04, 19.69it/s, est. speed input: 21584.16 toks/s, output: 21.08 toks/s]
Processed prompts:  71%|███████   | 5808/8192 [04:35<02:01, 19.69it/s, est. speed input: 21567.41 toks/s, output: 21.06 toks/s]
Processed prompts:  72%|███████▏  | 5872/8192 [04:38<01:57, 19.77it/s, est. speed input: 21554.62 toks/s, output: 21.05 toks/s]
Processed prompts:  72%|███████▏  | 5936/8192 [04:42<01:53, 19.84it/s, est. speed input: 21542.43 toks/s, output: 21.04 toks/s]
Processed prompts:  73%|███████▎  | 6000/8192 [04:45<01:50, 19.80it/s, est. speed input: 21527.08 toks/s, output: 21.02 toks/s]
Processed prompts:  74%|███████▍  | 6064/8192 [04:48<01:47, 19.76it/s, est. speed input: 21511.35 toks/s, output: 21.01 toks/s]
Processed prompts:  75%|███████▍  | 6128/8192 [04:51<01:44, 19.73it/s, est. speed input: 21495.94 toks/s, output: 20.99 toks/s]
Processed prompts:  76%|███████▌  | 6192/8192 [04:55<01:41, 19.71it/s, est. speed input: 21480.97 toks/s, output: 20.98 toks/s]
Processed prompts:  76%|███████▋  | 6256/8192 [04:58<01:38, 19.69it/s, est. speed input: 21466.12 toks/s, output: 20.96 toks/s]
Processed prompts:  77%|███████▋  | 6320/8192 [05:01<01:35, 19.68it/s, est. speed input: 21451.54 toks/s, output: 20.95 toks/s]
Processed prompts:  78%|███████▊  | 6384/8192 [05:04<01:31, 19.67it/s, est. speed input: 21437.30 toks/s, output: 20.93 toks/s]
Processed prompts:  79%|███████▊  | 6448/8192 [05:08<01:28, 19.66it/s, est. speed input: 21423.31 toks/s, output: 20.92 toks/s]
Processed prompts:  79%|███████▉  | 6512/8192 [05:11<01:25, 19.67it/s, est. speed input: 21410.09 toks/s, output: 20.91 toks/s]
Processed prompts:  80%|████████  | 6576/8192 [05:14<01:22, 19.66it/s, est. speed input: 21396.79 toks/s, output: 20.90 toks/s]
Processed prompts:  81%|████████  | 6640/8192 [05:17<01:18, 19.67it/s, est. speed input: 21383.99 toks/s, output: 20.88 toks/s]
Processed prompts:  82%|████████▏ | 6704/8192 [05:21<01:15, 19.67it/s, est. speed input: 21371.49 toks/s, output: 20.87 toks/s]
Processed prompts:  83%|████████▎ | 6768/8192 [05:24<01:12, 19.66it/s, est. speed input: 21358.81 toks/s, output: 20.86 toks/s]
Processed prompts:  83%|████████▎ | 6832/8192 [05:27<01:09, 19.67it/s, est. speed input: 21346.84 toks/s, output: 20.85 toks/s]
Processed prompts:  84%|████████▍ | 6896/8192 [05:30<01:05, 19.66it/s, est. speed input: 21334.85 toks/s, output: 20.83 toks/s]
Processed prompts:  85%|████████▍ | 6960/8192 [05:34<01:02, 19.67it/s, est. speed input: 21323.47 toks/s, output: 20.82 toks/s]
Processed prompts:  86%|████████▌ | 7024/8192 [05:37<00:59, 19.66it/s, est. speed input: 21311.70 toks/s, output: 20.81 toks/s]
Processed prompts:  87%|████████▋ | 7088/8192 [05:40<00:56, 19.66it/s, est. speed input: 21300.57 toks/s, output: 20.80 toks/s]
Processed prompts:  87%|████████▋ | 7152/8192 [05:44<00:52, 19.66it/s, est. speed input: 21289.40 toks/s, output: 20.79 toks/s]
Processed prompts:  88%|████████▊ | 7216/8192 [05:47<00:49, 19.65it/s, est. speed input: 21278.25 toks/s, output: 20.78 toks/s]
Processed prompts:  89%|████████▉ | 7280/8192 [05:50<00:46, 19.67it/s, est. speed input: 21268.00 toks/s, output: 20.77 toks/s]
Processed prompts:  90%|████████▉ | 7344/8192 [05:53<00:43, 19.67it/s, est. speed input: 21257.68 toks/s, output: 20.76 toks/s]
Processed prompts:  90%|█████████ | 7408/8192 [05:57<00:39, 19.67it/s, est. speed input: 21247.43 toks/s, output: 20.75 toks/s]
Processed prompts:  91%|█████████ | 7472/8192 [06:00<00:36, 19.66it/s, est. speed input: 21237.27 toks/s, output: 20.74 toks/s]
Processed prompts:  92%|█████████▏| 7536/8192 [06:03<00:33, 19.65it/s, est. speed input: 21227.01 toks/s, output: 20.73 toks/s]
Processed prompts:  93%|█████████▎| 7600/8192 [06:06<00:30, 19.66it/s, est. speed input: 21217.40 toks/s, output: 20.72 toks/s]
Processed prompts:  94%|█████████▎| 7664/8192 [06:10<00:26, 19.66it/s, est. speed input: 21207.94 toks/s, output: 20.71 toks/s]
Processed prompts:  94%|█████████▍| 7728/8192 [06:13<00:23, 19.66it/s, est. speed input: 21198.53 toks/s, output: 20.70 toks/s]
Processed prompts:  95%|█████████▌| 7792/8192 [06:16<00:20, 19.65it/s, est. speed input: 21189.02 toks/s, output: 20.69 toks/s]
Processed prompts:  96%|█████████▌| 7856/8192 [06:19<00:17, 19.67it/s, est. speed input: 21180.36 toks/s, output: 20.68 toks/s]
Processed prompts:  97%|█████████▋| 7920/8192 [06:23<00:13, 19.68it/s, est. speed input: 21171.81 toks/s, output: 20.68 toks/s]
Processed prompts:  97%|█████████▋| 7984/8192 [06:26<00:10, 19.67it/s, est. speed input: 21163.14 toks/s, output: 20.67 toks/s]
Processed prompts:  98%|█████████▊| 8048/8192 [06:29<00:07, 19.67it/s, est. speed input: 21154.50 toks/s, output: 20.66 toks/s]
Processed prompts:  99%|█████████▉| 8112/8192 [06:32<00:04, 19.67it/s, est. speed input: 21146.21 toks/s, output: 20.65 toks/s]
Processed prompts: 100%|█████████▉| 8176/8192 [06:33<00:00, 25.18it/s, est. speed input: 21265.31 toks/s, output: 20.77 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:33<00:00, 25.18it/s, est. speed input: 21306.89 toks/s, output: 20.81 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:33<00:00, 20.81it/s, est. speed input: 21306.89 toks/s, output: 20.81 toks/s]
[rank0]:[W126 15:59:02.183164745 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 09:22:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:23:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3379462) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3379462) WARNING 01-28 09:23:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.43 requests/s, 16638.63 total tokens/s, 32.43 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 09:23:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:23:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:23:04] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:23:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:23:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:23:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:23:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:23:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:23:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:23:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:23:11] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:23:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:23:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:23:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:23:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:23:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3379462) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3379462) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=3379462) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=3379462) 
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3379462) [2026-01-28 09:23:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3379462) 2026-01-28 09:23:30,895 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3379462) 2026-01-28 09:23:30,925 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3379462) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.01it/s]
(EngineCore_DP0 pid=3379462) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.48it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  50%|█████     | 64/128 [00:00<00:00, 639.66it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 736.81it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:16,  7.84it/s, est. speed input: 4015.95 toks/s, output: 7.84 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 23.29it/s, est. speed input: 10664.00 toks/s, output: 20.83 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 28.85it/s, est. speed input: 13109.08 toks/s, output: 25.60 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 31.50it/s, est. speed input: 14359.05 toks/s, output: 28.04 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 32.98it/s, est. speed input: 15116.14 toks/s, output: 29.52 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.88it/s, est. speed input: 15627.73 toks/s, output: 30.52 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.53it/s, est. speed input: 16011.20 toks/s, output: 31.27 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.92it/s, est. speed input: 16292.50 toks/s, output: 31.82 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 34.96it/s, est. speed input: 16476.92 toks/s, output: 32.18 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 34.92it/s, est. speed input: 16613.91 toks/s, output: 32.45 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 34.95it/s, est. speed input: 16733.24 toks/s, output: 32.68 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 34.97it/s, est. speed input: 16833.54 toks/s, output: 32.88 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 34.98it/s, est. speed input: 16917.47 toks/s, output: 33.04 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 34.98it/s, est. speed input: 16988.33 toks/s, output: 33.18 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 34.95it/s, est. speed input: 17046.52 toks/s, output: 33.29 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 34.92it/s, est. speed input: 17096.25 toks/s, output: 33.39 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 34.92it/s, est. speed input: 17142.20 toks/s, output: 33.48 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 34.89it/s, est. speed input: 17180.81 toks/s, output: 33.56 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 34.85it/s, est. speed input: 17213.35 toks/s, output: 33.62 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 34.82it/s, est. speed input: 17242.48 toks/s, output: 33.68 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 34.81it/s, est. speed input: 17269.54 toks/s, output: 33.73 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 34.81it/s, est. speed input: 17295.49 toks/s, output: 33.78 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 34.86it/s, est. speed input: 17321.95 toks/s, output: 33.83 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 34.84it/s, est. speed input: 17342.19 toks/s, output: 33.87 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 34.91it/s, est. speed input: 17366.57 toks/s, output: 33.92 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 34.91it/s, est. speed input: 17386.17 toks/s, output: 33.96 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 34.88it/s, est. speed input: 17402.53 toks/s, output: 33.99 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 34.89it/s, est. speed input: 17419.71 toks/s, output: 34.02 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 34.93it/s, est. speed input: 17437.11 toks/s, output: 34.06 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 34.96it/s, est. speed input: 17453.61 toks/s, output: 34.09 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 34.80it/s, est. speed input: 17459.29 toks/s, output: 34.10 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.75it/s, est. speed input: 17413.85 toks/s, output: 34.01 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.75it/s, est. speed input: 17378.24 toks/s, output: 33.94 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.94it/s, est. speed input: 17378.24 toks/s, output: 33.94 toks/s]
[rank0]:[W128 09:23:37.207374706 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 09:23:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:23:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3380597) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3380597) WARNING 01-28 09:24:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.68 requests/s, 32468.59 total tokens/s, 31.68 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 09:23:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:23:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:23:46] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:23:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:23:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:23:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:23:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:23:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:23:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:23:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:23:53] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:23:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:23:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:23:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:23:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:23:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:23:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3380597) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3380597) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=3380597) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=3380597) 
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3380597) [2026-01-28 09:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3380597) 2026-01-28 09:24:12,548 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3380597) 2026-01-28 09:24:12,576 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3380597) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 12.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 12.58it/s]
(EngineCore_DP0 pid=3380597) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.22it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|██▎       | 29/128 [00:00<00:00, 285.49it/s]
Adding requests:  63%|██████▎   | 81/128 [00:00<00:00, 421.15it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 431.62it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 50.72it/s, est. speed input: 51951.69 toks/s, output: 50.72 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:02, 39.28it/s, est. speed input: 41636.26 toks/s, output: 40.66 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 36.69it/s, est. speed input: 39189.40 toks/s, output: 38.27 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 35.59it/s, est. speed input: 38145.24 toks/s, output: 37.25 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.88it/s, est. speed input: 37456.55 toks/s, output: 36.58 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.39it/s, est. speed input: 36963.02 toks/s, output: 36.10 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 34.13it/s, est. speed input: 36627.83 toks/s, output: 35.77 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.96it/s, est. speed input: 36372.03 toks/s, output: 35.52 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.93it/s, est. speed input: 36196.88 toks/s, output: 35.35 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.92it/s, est. speed input: 36060.61 toks/s, output: 35.22 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.89it/s, est. speed input: 35937.65 toks/s, output: 35.10 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.82it/s, est. speed input: 35822.98 toks/s, output: 34.98 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.73it/s, est. speed input: 35712.98 toks/s, output: 34.88 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 33.64it/s, est. speed input: 35613.74 toks/s, output: 34.78 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 33.65it/s, est. speed input: 35541.92 toks/s, output: 34.71 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 33.73it/s, est. speed input: 35492.72 toks/s, output: 34.66 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.74it/s, est. speed input: 35442.14 toks/s, output: 34.61 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.74it/s, est. speed input: 35394.67 toks/s, output: 34.56 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.74it/s, est. speed input: 35352.23 toks/s, output: 34.52 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.74it/s, est. speed input: 35313.75 toks/s, output: 34.49 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.78it/s, est. speed input: 35285.19 toks/s, output: 34.46 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.79it/s, est. speed input: 35256.01 toks/s, output: 34.43 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 33.76it/s, est. speed input: 35224.24 toks/s, output: 34.40 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 33.74it/s, est. speed input: 35195.23 toks/s, output: 34.37 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.71it/s, est. speed input: 35165.42 toks/s, output: 34.34 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.60it/s, est. speed input: 35127.52 toks/s, output: 34.30 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.64it/s, est. speed input: 35105.91 toks/s, output: 34.28 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.62it/s, est. speed input: 35080.51 toks/s, output: 34.26 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.65it/s, est. speed input: 35062.22 toks/s, output: 34.24 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.62it/s, est. speed input: 35039.21 toks/s, output: 34.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.62it/s, est. speed input: 35023.05 toks/s, output: 34.20 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.20it/s, est. speed input: 35023.05 toks/s, output: 34.20 toks/s]
[rank0]:[W128 09:24:18.612873602 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 09:24:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:24:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3381686) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3381686) WARNING 01-28 09:24:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 66.67 requests/s, 68334.85 total tokens/s, 66.67 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 09:24:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:24:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:24:28] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:24:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:24:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:24:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:24:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:24:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:24:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:24:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:24:34] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:24:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:24:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:24:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:24:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:24:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:24:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3381686) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3381686) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=3381686) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=3381686) 
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3381686) [2026-01-28 09:24:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3381686) 2026-01-28 09:24:54,245 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3381686) 2026-01-28 09:24:54,273 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3381686) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 13.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 12.92it/s]
(EngineCore_DP0 pid=3381686) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 16.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 16.16it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█▏        | 29/256 [00:00<00:00, 288.87it/s]
Adding requests:  32%|███▏      | 81/256 [00:00<00:00, 424.50it/s]
Adding requests:  51%|█████     | 131/256 [00:00<00:00, 456.14it/s]
Adding requests:  71%|███████   | 181/256 [00:00<00:00, 470.13it/s]
Adding requests:  91%|█████████ | 233/256 [00:00<00:00, 484.56it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 464.71it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:00<00:00, 264.62it/s, est. speed input: 271006.53 toks/s, output: 264.63 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:00<00:01, 110.76it/s, est. speed input: 125638.46 toks/s, output: 122.69 toks/s]
Processed prompts:  30%|███       | 77/256 [00:00<00:01, 93.97it/s, est. speed input: 108786.82 toks/s, output: 106.23 toks/s] 
Processed prompts:  35%|███▍      | 89/256 [00:00<00:01, 86.67it/s, est. speed input: 101759.54 toks/s, output: 99.37 toks/s] 
Processed prompts:  39%|███▊      | 99/256 [00:01<00:01, 82.25it/s, est. speed input: 97660.04 toks/s, output: 95.37 toks/s] 
Processed prompts:  42%|████▏     | 108/256 [00:01<00:01, 76.97it/s, est. speed input: 93686.95 toks/s, output: 91.49 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:01<00:01, 75.39it/s, est. speed input: 91786.08 toks/s, output: 89.63 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:01<00:01, 74.06it/s, est. speed input: 90178.06 toks/s, output: 88.06 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:01<00:01, 73.05it/s, est. speed input: 88816.01 toks/s, output: 86.73 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:01<00:01, 72.29it/s, est. speed input: 87645.30 toks/s, output: 85.59 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:01<00:01, 71.82it/s, est. speed input: 86651.65 toks/s, output: 84.62 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:01<00:01, 71.35it/s, est. speed input: 85748.64 toks/s, output: 83.74 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:01<00:01, 71.08it/s, est. speed input: 84964.71 toks/s, output: 82.97 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:02<00:01, 70.77it/s, est. speed input: 84239.87 toks/s, output: 82.26 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:02<00:01, 70.57it/s, est. speed input: 83596.12 toks/s, output: 81.64 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:02<00:00, 70.44it/s, est. speed input: 83016.39 toks/s, output: 81.07 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:02<00:00, 70.44it/s, est. speed input: 82507.98 toks/s, output: 80.57 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:02<00:00, 70.39it/s, est. speed input: 82035.63 toks/s, output: 80.11 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:02<00:00, 70.25it/s, est. speed input: 81586.84 toks/s, output: 79.67 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:02<00:00, 70.17it/s, est. speed input: 81177.73 toks/s, output: 79.27 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:02<00:00, 70.08it/s, est. speed input: 80797.38 toks/s, output: 78.90 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:03<00:00, 70.09it/s, est. speed input: 80454.65 toks/s, output: 78.57 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:03<00:00, 70.14it/s, est. speed input: 80143.97 toks/s, output: 78.26 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:03<00:00, 70.25it/s, est. speed input: 79864.88 toks/s, output: 77.99 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 70.25it/s, est. speed input: 79747.67 toks/s, output: 77.88 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 77.87it/s, est. speed input: 79747.67 toks/s, output: 77.88 toks/s]
[rank0]:[W128 09:25:00.272233552 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 09:25:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:25:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3382778) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3382778) WARNING 01-28 09:25:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 78.37 requests/s, 80329.84 total tokens/s, 78.37 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 09:25:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:25:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:25:11] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:25:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:25:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:25:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:25:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:25:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:25:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:25:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:25:18] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:25:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:25:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:25:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:25:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:25:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3382778) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3382778) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=3382778) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=3382778) 
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3382778) [2026-01-28 09:25:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3382778) 2026-01-28 09:25:37,527 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3382778) 2026-01-28 09:25:37,554 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3382778) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00, 13.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.67it/s]
(EngineCore_DP0 pid=3382778) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.46it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  9.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 10.67it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 286.85it/s]
Adding requests:  16%|█▌        | 82/512 [00:00<00:01, 424.87it/s]
Adding requests:  26%|██▌       | 133/512 [00:00<00:00, 462.02it/s]
Adding requests:  36%|███▌      | 183/512 [00:00<00:00, 474.04it/s]
Adding requests:  45%|████▌     | 232/512 [00:00<00:00, 477.20it/s]
Adding requests:  55%|█████▌    | 282/512 [00:00<00:00, 482.87it/s]
Adding requests:  65%|██████▍   | 331/512 [00:00<00:00, 484.67it/s]
Adding requests:  75%|███████▍  | 382/512 [00:00<00:00, 490.82it/s]
Adding requests:  85%|████████▍ | 433/512 [00:00<00:00, 495.06it/s]
Adding requests:  94%|█████████▍| 483/512 [00:01<00:00, 493.80it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 477.31it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 54/512 [00:00<00:01, 436.13it/s, est. speed input: 446754.70 toks/s, output: 436.17 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:00<00:03, 136.78it/s, est. speed input: 158002.79 toks/s, output: 154.29 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:00<00:03, 114.50it/s, est. speed input: 134877.95 toks/s, output: 131.71 toks/s]
Processed prompts:  27%|██▋       | 139/512 [00:01<00:03, 107.95it/s, est. speed input: 127781.78 toks/s, output: 124.79 toks/s]
Processed prompts:  30%|██▉       | 153/512 [00:01<00:03, 106.23it/s, est. speed input: 124997.88 toks/s, output: 122.07 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:01<00:03, 95.37it/s, est. speed input: 118126.27 toks/s, output: 115.36 toks/s] 
Processed prompts:  35%|███▍      | 178/512 [00:01<00:03, 93.13it/s, est. speed input: 115489.95 toks/s, output: 112.78 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:01<00:03, 91.13it/s, est. speed input: 113199.22 toks/s, output: 110.54 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:01<00:03, 89.09it/s, est. speed input: 111082.54 toks/s, output: 108.48 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:02<00:03, 87.87it/s, est. speed input: 109362.38 toks/s, output: 106.80 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:02<00:03, 87.22it/s, est. speed input: 107939.91 toks/s, output: 105.41 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:02<00:03, 86.67it/s, est. speed input: 106673.42 toks/s, output: 104.17 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:02<00:03, 86.49it/s, est. speed input: 105604.91 toks/s, output: 103.13 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:02<00:02, 86.10it/s, est. speed input: 104596.05 toks/s, output: 102.14 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:02<00:02, 86.02it/s, est. speed input: 103731.56 toks/s, output: 101.30 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:02<00:02, 85.48it/s, est. speed input: 102856.46 toks/s, output: 100.44 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:02<00:02, 85.27it/s, est. speed input: 102097.21 toks/s, output: 99.70 toks/s] 
Processed prompts:  61%|██████    | 310/512 [00:03<00:02, 85.09it/s, est. speed input: 101400.55 toks/s, output: 99.02 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:03<00:02, 85.25it/s, est. speed input: 100812.51 toks/s, output: 98.45 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:03<00:02, 85.25it/s, est. speed input: 100254.70 toks/s, output: 97.90 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:03<00:01, 86.67it/s, est. speed input: 99957.59 toks/s, output: 97.61 toks/s] 
Processed prompts:  70%|██████▉   | 358/512 [00:03<00:01, 86.35it/s, est. speed input: 99490.23 toks/s, output: 97.16 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:03<00:01, 85.96it/s, est. speed input: 99033.54 toks/s, output: 96.71 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:03<00:01, 85.57it/s, est. speed input: 98593.45 toks/s, output: 96.28 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:04<00:01, 85.37it/s, est. speed input: 98193.59 toks/s, output: 95.89 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:04<00:01, 85.34it/s, est. speed input: 97831.94 toks/s, output: 95.54 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:04<00:01, 85.22it/s, est. speed input: 97483.08 toks/s, output: 95.20 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:04<00:00, 85.18it/s, est. speed input: 97160.29 toks/s, output: 94.88 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:04<00:00, 85.04it/s, est. speed input: 96845.55 toks/s, output: 94.58 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:04<00:00, 86.45it/s, est. speed input: 96713.21 toks/s, output: 94.45 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:04<00:00, 86.01it/s, est. speed input: 96436.81 toks/s, output: 94.18 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:05<00:00, 85.44it/s, est. speed input: 96149.82 toks/s, output: 93.90 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:05<00:00, 85.32it/s, est. speed input: 95904.48 toks/s, output: 93.66 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:05<00:00, 85.36it/s, est. speed input: 95685.01 toks/s, output: 93.44 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 85.36it/s, est. speed input: 96051.90 toks/s, output: 93.80 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 93.80it/s, est. speed input: 96051.90 toks/s, output: 93.80 toks/s]
[rank0]:[W128 09:25:46.572109592 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 09:25:48
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:25:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3383932) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3383932) WARNING 01-28 09:26:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 85.96 requests/s, 88112.61 total tokens/s, 85.96 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 09:25:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:25:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:25:59] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:25:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:25:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:25:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:25:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:25:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:26:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:26:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:26:06] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:26:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:26:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:26:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:26:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:26:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3383932) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3383932) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=3383932) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=3383932) 
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3383932) [2026-01-28 09:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3383932) 2026-01-28 09:26:25,921 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3383932) 2026-01-28 09:26:25,949 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3383932) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.87it/s]
(EngineCore_DP0 pid=3383932) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 15.71it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.33it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 31/1024 [00:00<00:03, 304.88it/s]
Adding requests:   8%|▊         | 83/1024 [00:00<00:02, 426.90it/s]
Adding requests:  13%|█▎        | 133/1024 [00:00<00:01, 456.24it/s]
Adding requests:  18%|█▊        | 181/1024 [00:00<00:01, 463.21it/s]
Adding requests:  23%|██▎       | 231/1024 [00:00<00:01, 475.64it/s]
Adding requests:  27%|██▋       | 280/1024 [00:00<00:01, 477.72it/s]
Adding requests:  32%|███▏      | 330/1024 [00:00<00:01, 482.45it/s]
Adding requests:  37%|███▋      | 382/1024 [00:00<00:01, 491.41it/s]
Adding requests:  42%|████▏     | 433/1024 [00:00<00:01, 496.33it/s]
Adding requests:  47%|████▋     | 483/1024 [00:01<00:01, 497.29it/s]
Adding requests:  52%|█████▏    | 533/1024 [00:01<00:01, 479.74it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:01<00:00, 488.33it/s]
Adding requests:  62%|██████▏   | 635/1024 [00:01<00:00, 492.12it/s]
Adding requests:  67%|██████▋   | 687/1024 [00:01<00:00, 498.24it/s]
Adding requests:  72%|███████▏  | 739/1024 [00:01<00:00, 502.08it/s]
Adding requests:  77%|███████▋  | 790/1024 [00:01<00:00, 497.37it/s]
Adding requests:  82%|████████▏ | 840/1024 [00:01<00:00, 490.31it/s]
Adding requests:  87%|████████▋ | 893/1024 [00:01<00:00, 500.51it/s]
Adding requests:  92%|█████████▏| 944/1024 [00:01<00:00, 501.43it/s]
Adding requests:  97%|█████████▋| 996/1024 [00:02<00:00, 503.95it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 488.07it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:00<00:00, 972.90it/s, est. speed input: 996512.13 toks/s, output: 972.97 toks/s]
Processed prompts:  25%|██▌       | 260/1024 [00:01<00:04, 176.38it/s, est. speed input: 213251.10 toks/s, output: 208.25 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:01<00:05, 140.51it/s, est. speed input: 175055.74 toks/s, output: 170.95 toks/s]
Processed prompts:  33%|███▎      | 335/1024 [00:02<00:05, 132.92it/s, est. speed input: 166251.28 toks/s, output: 162.35 toks/s]
Processed prompts:  35%|███▍      | 357/1024 [00:02<00:05, 121.38it/s, est. speed input: 157089.58 toks/s, output: 153.41 toks/s]
Processed prompts:  37%|███▋      | 374/1024 [00:02<00:05, 116.48it/s, est. speed input: 152797.72 toks/s, output: 149.22 toks/s]
Processed prompts:  38%|███▊      | 389/1024 [00:02<00:05, 109.38it/s, est. speed input: 148209.62 toks/s, output: 144.74 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:02<00:06, 100.50it/s, est. speed input: 143418.10 toks/s, output: 140.05 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:03<00:06, 97.40it/s, est. speed input: 140246.22 toks/s, output: 136.96 toks/s] 
Processed prompts:  42%|████▏     | 434/1024 [00:03<00:06, 95.08it/s, est. speed input: 137471.91 toks/s, output: 134.25 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:03<00:06, 94.64it/s, est. speed input: 135364.46 toks/s, output: 132.19 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:03<00:06, 92.93it/s, est. speed input: 133114.44 toks/s, output: 129.99 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:03<00:05, 91.43it/s, est. speed input: 131019.86 toks/s, output: 127.95 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:03<00:05, 90.40it/s, est. speed input: 129131.05 toks/s, output: 126.10 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:04<00:05, 89.79it/s, est. speed input: 127433.40 toks/s, output: 124.45 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:04<00:05, 89.51it/s, est. speed input: 125910.74 toks/s, output: 122.96 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:04<00:05, 89.35it/s, est. speed input: 124516.53 toks/s, output: 121.60 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:04<00:05, 88.98it/s, est. speed input: 123184.33 toks/s, output: 120.30 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:04<00:05, 88.68it/s, est. speed input: 121945.35 toks/s, output: 119.09 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:05<00:04, 88.48it/s, est. speed input: 120795.76 toks/s, output: 117.96 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:05<00:04, 88.39it/s, est. speed input: 119734.03 toks/s, output: 116.93 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:05<00:04, 88.54it/s, est. speed input: 118777.39 toks/s, output: 115.99 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:05<00:04, 88.46it/s, est. speed input: 117854.91 toks/s, output: 115.09 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:05<00:04, 88.42it/s, est. speed input: 116992.99 toks/s, output: 114.25 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:05<00:03, 88.15it/s, est. speed input: 116150.82 toks/s, output: 113.43 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:06<00:03, 88.31it/s, est. speed input: 115404.71 toks/s, output: 112.70 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:06<00:03, 88.38it/s, est. speed input: 114695.13 toks/s, output: 112.01 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:06<00:03, 88.38it/s, est. speed input: 114019.18 toks/s, output: 111.35 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:06<00:03, 88.34it/s, est. speed input: 113376.12 toks/s, output: 110.72 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:06<00:03, 88.20it/s, est. speed input: 112754.45 toks/s, output: 110.11 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:07<00:02, 88.18it/s, est. speed input: 112172.31 toks/s, output: 109.54 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:07<00:02, 88.44it/s, est. speed input: 111649.45 toks/s, output: 109.03 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:07<00:02, 88.53it/s, est. speed input: 111142.91 toks/s, output: 108.54 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:07<00:02, 88.48it/s, est. speed input: 110648.84 toks/s, output: 108.05 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:07<00:02, 88.39it/s, est. speed input: 110171.75 toks/s, output: 107.59 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:07<00:01, 88.11it/s, est. speed input: 109697.33 toks/s, output: 107.13 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:08<00:01, 88.11it/s, est. speed input: 109261.26 toks/s, output: 106.70 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:08<00:01, 88.18it/s, est. speed input: 108850.76 toks/s, output: 106.30 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:08<00:01, 88.12it/s, est. speed input: 108448.72 toks/s, output: 105.91 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:08<00:01, 88.13it/s, est. speed input: 108067.26 toks/s, output: 105.53 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:08<00:01, 88.07it/s, est. speed input: 107696.17 toks/s, output: 105.17 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:09<00:00, 89.45it/s, est. speed input: 107455.42 toks/s, output: 104.94 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:09<00:00, 89.10it/s, est. speed input: 107119.71 toks/s, output: 104.61 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:09<00:00, 88.75it/s, est. speed input: 106788.64 toks/s, output: 104.29 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:09<00:00, 90.12it/s, est. speed input: 106589.95 toks/s, output: 104.09 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:09<00:00, 89.47it/s, est. speed input: 106281.89 toks/s, output: 103.79 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 89.47it/s, est. speed input: 106869.06 toks/s, output: 104.36 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 104.36it/s, est. speed input: 106869.06 toks/s, output: 104.36 toks/s]
[rank0]:[W128 09:26:40.600798699 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 09:26:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:26:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3385231) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3385231) WARNING 01-28 09:27:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 91.08 requests/s, 93361.02 total tokens/s, 91.08 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 09:26:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:26:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:26:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:26:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:26:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:26:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:26:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:26:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:26:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:27:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:27:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:27:04] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:27:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:27:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:27:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:27:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:27:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:27:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3385231) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3385231) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3385231) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.07it/s]
(EngineCore_DP0 pid=3385231) 
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3385231) [2026-01-28 09:27:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3385231) 2026-01-28 09:27:24,296 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3385231) 2026-01-28 09:27:24,324 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3385231) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 12.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 10.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.38it/s]
(EngineCore_DP0 pid=3385231) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 15.56it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 16.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 16.78it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 34/2048 [00:00<00:06, 333.14it/s]
Adding requests:   4%|▍         | 85/2048 [00:00<00:04, 435.44it/s]
Adding requests:   7%|▋         | 135/2048 [00:00<00:04, 461.64it/s]
Adding requests:   9%|▉         | 184/2048 [00:00<00:03, 470.16it/s]
Adding requests:  11%|█▏        | 235/2048 [00:00<00:03, 483.84it/s]
Adding requests:  14%|█▍        | 285/2048 [00:00<00:03, 488.56it/s]
Adding requests:  16%|█▋        | 334/2048 [00:00<00:03, 488.87it/s]
Adding requests:  19%|█▉        | 385/2048 [00:00<00:03, 492.88it/s]
Adding requests:  21%|██▏       | 436/2048 [00:00<00:03, 496.89it/s]
Adding requests:  24%|██▍       | 487/2048 [00:01<00:03, 498.14it/s]
Adding requests:  26%|██▌       | 537/2048 [00:01<00:03, 487.53it/s]
Adding requests:  29%|██▉       | 590/2048 [00:01<00:02, 498.08it/s]
Adding requests:  31%|███▏      | 642/2048 [00:01<00:02, 501.12it/s]
Adding requests:  34%|███▍      | 695/2048 [00:01<00:02, 507.16it/s]
Adding requests:  36%|███▋      | 746/2048 [00:01<00:02, 499.82it/s]
Adding requests:  39%|███▉      | 797/2048 [00:01<00:02, 500.63it/s]
Adding requests:  41%|████▏     | 848/2048 [00:01<00:02, 494.77it/s]
Adding requests:  44%|████▍     | 901/2048 [00:01<00:02, 504.71it/s]
Adding requests:  46%|████▋     | 952/2048 [00:01<00:02, 504.88it/s]
Adding requests:  49%|████▉     | 1004/2048 [00:02<00:02, 508.14it/s]
Adding requests:  52%|█████▏    | 1056/2048 [00:02<00:01, 509.24it/s]
Adding requests:  54%|█████▍    | 1107/2048 [00:02<00:01, 508.61it/s]
Adding requests:  57%|█████▋    | 1159/2048 [00:02<00:01, 510.30it/s]
Adding requests:  59%|█████▉    | 1213/2048 [00:02<00:01, 518.42it/s]
Adding requests:  62%|██████▏   | 1265/2048 [00:02<00:01, 511.75it/s]
Adding requests:  64%|██████▍   | 1317/2048 [00:02<00:01, 512.36it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:02<00:01, 514.31it/s]
Adding requests:  69%|██████▉   | 1421/2048 [00:02<00:01, 514.96it/s]
Adding requests:  72%|███████▏  | 1473/2048 [00:02<00:01, 511.45it/s]
Adding requests:  74%|███████▍  | 1525/2048 [00:03<00:01, 513.61it/s]
Adding requests:  77%|███████▋  | 1578/2048 [00:03<00:00, 515.34it/s]
Adding requests:  80%|███████▉  | 1632/2048 [00:03<00:00, 520.87it/s]
Adding requests:  82%|████████▏ | 1685/2048 [00:03<00:00, 515.86it/s]
Adding requests:  85%|████████▍ | 1738/2048 [00:03<00:00, 517.43it/s]
Adding requests:  87%|████████▋ | 1790/2048 [00:03<00:00, 513.55it/s]
Adding requests:  90%|████████▉ | 1842/2048 [00:03<00:00, 515.16it/s]
Adding requests:  92%|█████████▏| 1894/2048 [00:03<00:00, 505.41it/s]
Adding requests:  95%|█████████▍| 1945/2048 [00:03<00:00, 506.70it/s]
Adding requests:  97%|█████████▋| 1996/2048 [00:03<00:00, 507.01it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 502.89it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:00<00:01, 1621.16it/s, est. speed input: 1660274.00 toks/s, output: 1621.24 toks/s]
Processed prompts:  26%|██▌       | 533/2048 [00:01<00:06, 222.29it/s, est. speed input: 277497.10 toks/s, output: 270.99 toks/s]   
Processed prompts:  30%|██▉       | 606/2048 [00:02<00:07, 181.52it/s, est. speed input: 232633.94 toks/s, output: 227.18 toks/s]
Processed prompts:  32%|███▏      | 651/2048 [00:03<00:08, 155.73it/s, est. speed input: 208862.30 toks/s, output: 203.97 toks/s]
Processed prompts:  33%|███▎      | 682/2048 [00:03<00:09, 141.98it/s, est. speed input: 197169.85 toks/s, output: 192.55 toks/s]
Processed prompts:  34%|███▍      | 705/2048 [00:03<00:09, 140.58it/s, est. speed input: 194195.52 toks/s, output: 189.64 toks/s]
Processed prompts:  35%|███▌      | 725/2048 [00:04<00:11, 118.45it/s, est. speed input: 182589.37 toks/s, output: 178.31 toks/s]
Processed prompts:  36%|███▌      | 740/2048 [00:04<00:11, 113.06it/s, est. speed input: 178616.85 toks/s, output: 174.43 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:04<00:12, 106.96it/s, est. speed input: 174804.51 toks/s, output: 170.71 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:04<00:12, 103.92it/s, est. speed input: 171779.89 toks/s, output: 167.75 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:04<00:12, 100.97it/s, est. speed input: 168891.76 toks/s, output: 164.93 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:04<00:12, 98.61it/s, est. speed input: 166227.30 toks/s, output: 162.33 toks/s] 
Processed prompts:  40%|███▉      | 818/2048 [00:05<00:12, 96.56it/s, est. speed input: 163706.57 toks/s, output: 159.87 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:05<00:12, 95.08it/s, est. speed input: 161371.67 toks/s, output: 157.59 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:05<00:12, 94.03it/s, est. speed input: 159195.91 toks/s, output: 155.46 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:05<00:12, 93.28it/s, est. speed input: 157161.13 toks/s, output: 153.48 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:05<00:12, 92.77it/s, est. speed input: 155254.06 toks/s, output: 151.61 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:05<00:12, 92.48it/s, est. speed input: 153470.78 toks/s, output: 149.87 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:06<00:12, 91.81it/s, est. speed input: 151715.54 toks/s, output: 148.16 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:06<00:12, 92.94it/s, est. speed input: 150301.06 toks/s, output: 146.78 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:06<00:11, 92.50it/s, est. speed input: 148778.61 toks/s, output: 145.29 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:06<00:11, 92.15it/s, est. speed input: 147330.83 toks/s, output: 143.88 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:06<00:11, 93.00it/s, est. speed input: 146104.58 toks/s, output: 142.68 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:07<00:11, 92.61it/s, est. speed input: 144808.99 toks/s, output: 141.41 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:07<00:11, 91.94it/s, est. speed input: 143526.01 toks/s, output: 140.16 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:07<00:11, 91.60it/s, est. speed input: 142319.37 toks/s, output: 138.98 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:07<00:10, 91.61it/s, est. speed input: 141199.48 toks/s, output: 137.89 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:07<00:10, 91.50it/s, est. speed input: 140116.30 toks/s, output: 136.83 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:07<00:10, 91.34it/s, est. speed input: 139071.10 toks/s, output: 135.81 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:08<00:10, 91.36it/s, est. speed input: 138086.38 toks/s, output: 134.85 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:08<00:10, 91.16it/s, est. speed input: 137120.56 toks/s, output: 133.91 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:08<00:10, 91.39it/s, est. speed input: 136233.44 toks/s, output: 133.04 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:08<00:09, 91.30it/s, est. speed input: 135357.38 toks/s, output: 132.18 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:08<00:09, 92.39it/s, est. speed input: 134628.10 toks/s, output: 131.47 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:08<00:09, 92.14it/s, est. speed input: 133830.50 toks/s, output: 130.69 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:09<00:09, 92.04it/s, est. speed input: 133069.63 toks/s, output: 129.95 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:09<00:09, 91.68it/s, est. speed input: 132311.58 toks/s, output: 129.21 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:09<00:09, 91.60it/s, est. speed input: 131596.57 toks/s, output: 128.51 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:09<00:08, 91.54it/s, est. speed input: 130907.61 toks/s, output: 127.84 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:09<00:08, 91.67it/s, est. speed input: 130257.25 toks/s, output: 127.20 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:09<00:08, 92.78it/s, est. speed input: 129712.24 toks/s, output: 126.67 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:10<00:08, 92.37it/s, est. speed input: 129092.07 toks/s, output: 126.07 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:10<00:08, 91.98it/s, est. speed input: 128483.52 toks/s, output: 125.47 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:10<00:08, 91.72it/s, est. speed input: 127896.08 toks/s, output: 124.90 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:10<00:07, 91.37it/s, est. speed input: 127315.47 toks/s, output: 124.33 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:10<00:07, 90.92it/s, est. speed input: 126738.37 toks/s, output: 123.77 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:11<00:07, 91.03it/s, est. speed input: 126210.74 toks/s, output: 123.25 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:11<00:07, 91.06it/s, est. speed input: 125695.90 toks/s, output: 122.75 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:11<00:07, 90.97it/s, est. speed input: 125189.90 toks/s, output: 122.26 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:11<00:07, 91.14it/s, est. speed input: 124714.72 toks/s, output: 121.79 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:11<00:06, 91.24it/s, est. speed input: 124252.90 toks/s, output: 121.34 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:11<00:06, 91.06it/s, est. speed input: 123787.47 toks/s, output: 120.89 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:12<00:06, 90.85it/s, est. speed input: 123330.56 toks/s, output: 120.44 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:12<00:06, 90.86it/s, est. speed input: 122896.34 toks/s, output: 120.02 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:12<00:06, 90.97it/s, est. speed input: 122481.61 toks/s, output: 119.61 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:12<00:05, 91.07it/s, est. speed input: 122079.14 toks/s, output: 119.22 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:12<00:05, 91.02it/s, est. speed input: 121680.96 toks/s, output: 118.83 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:12<00:05, 90.86it/s, est. speed input: 121285.91 toks/s, output: 118.44 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:13<00:05, 91.01it/s, est. speed input: 120916.89 toks/s, output: 118.08 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:13<00:05, 90.92it/s, est. speed input: 120545.79 toks/s, output: 117.72 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:13<00:05, 92.30it/s, est. speed input: 120266.71 toks/s, output: 117.45 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:13<00:04, 91.72it/s, est. speed input: 119908.21 toks/s, output: 117.10 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:13<00:04, 91.42it/s, est. speed input: 119564.65 toks/s, output: 116.76 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:14<00:04, 91.45it/s, est. speed input: 119242.28 toks/s, output: 116.45 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:14<00:04, 91.24it/s, est. speed input: 118916.18 toks/s, output: 116.13 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:14<00:04, 90.95it/s, est. speed input: 118589.91 toks/s, output: 115.81 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:14<00:04, 90.74it/s, est. speed input: 118271.35 toks/s, output: 115.50 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:14<00:03, 90.68it/s, est. speed input: 117964.71 toks/s, output: 115.20 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:14<00:03, 90.87it/s, est. speed input: 117677.71 toks/s, output: 114.92 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:15<00:03, 90.91it/s, est. speed input: 117392.34 toks/s, output: 114.64 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:15<00:03, 90.95it/s, est. speed input: 117114.38 toks/s, output: 114.37 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:15<00:03, 90.78it/s, est. speed input: 116832.69 toks/s, output: 114.09 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:15<00:02, 90.70it/s, est. speed input: 116559.70 toks/s, output: 113.83 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:15<00:02, 90.58it/s, est. speed input: 116289.12 toks/s, output: 113.56 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:15<00:02, 90.65it/s, est. speed input: 116032.40 toks/s, output: 113.31 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:16<00:02, 90.79it/s, est. speed input: 115785.21 toks/s, output: 113.07 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:16<00:02, 90.94it/s, est. speed input: 115545.65 toks/s, output: 112.84 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:16<00:02, 90.77it/s, est. speed input: 115298.96 toks/s, output: 112.60 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:16<00:01, 91.98it/s, est. speed input: 115116.07 toks/s, output: 112.42 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:16<00:01, 91.79it/s, est. speed input: 114891.69 toks/s, output: 112.20 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:17<00:01, 91.37it/s, est. speed input: 114659.78 toks/s, output: 111.97 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:17<00:01, 91.42it/s, est. speed input: 114447.24 toks/s, output: 111.76 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:17<00:01, 91.34it/s, est. speed input: 114233.66 toks/s, output: 111.56 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:17<00:01, 92.37it/s, est. speed input: 114069.29 toks/s, output: 111.40 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:17<00:00, 91.95it/s, est. speed input: 113861.76 toks/s, output: 111.19 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:17<00:00, 91.63it/s, est. speed input: 113657.32 toks/s, output: 110.99 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:18<00:00, 91.70it/s, est. speed input: 113468.53 toks/s, output: 110.81 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:18<00:00, 91.61it/s, est. speed input: 113277.75 toks/s, output: 110.62 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:18<00:00, 92.81it/s, est. speed input: 113139.24 toks/s, output: 110.49 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:18<00:00, 92.81it/s, est. speed input: 113914.53 toks/s, output: 111.24 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:18<00:00, 111.24it/s, est. speed input: 113914.53 toks/s, output: 111.24 toks/s]
[rank0]:[W128 09:27:49.685835313 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 09:27:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:28:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3386747) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3386747) WARNING 01-28 09:28:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 92.89 requests/s, 95212.79 total tokens/s, 92.89 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 09:28:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:28:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:28:15] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:28:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:28:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:28:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:28:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:28:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:28:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:28:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:28:21] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:28:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:28:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:28:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:28:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:28:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:28:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3386747) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3386747) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.08it/s]
(EngineCore_DP0 pid=3386747) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.08it/s]
(EngineCore_DP0 pid=3386747) 
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3386747) [2026-01-28 09:28:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17715200 bytes
(EngineCore_DP0 pid=3386747) [rank0]:W0128 09:28:36.437000 3386747 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3386747) [rank0]:W0128 09:28:36.519000 3386747 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3386747) [rank0]:W0128 09:28:37.770000 3386747 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3386747) [rank0]:W0128 09:28:37.927000 3386747 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3386747) 2026-01-28 09:28:41,898 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3386747) 2026-01-28 09:28:41,940 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3386747) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00, 13.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 10.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 11.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.93it/s]
(EngineCore_DP0 pid=3386747) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 15.95it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 16.69it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 16.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 16.87it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 33/4096 [00:00<00:12, 324.02it/s]
Adding requests:   2%|▏         | 84/4096 [00:00<00:09, 427.80it/s]
Adding requests:   3%|▎         | 134/4096 [00:00<00:08, 457.37it/s]
Adding requests:   4%|▍         | 182/4096 [00:00<00:08, 464.73it/s]
Adding requests:   6%|▌         | 233/4096 [00:00<00:08, 477.16it/s]
Adding requests:   7%|▋         | 283/4096 [00:00<00:07, 484.20it/s]
Adding requests:   8%|▊         | 332/4096 [00:00<00:07, 482.00it/s]
Adding requests:   9%|▉         | 381/4096 [00:00<00:07, 484.35it/s]
Adding requests:  11%|█         | 431/4096 [00:00<00:07, 488.12it/s]
Adding requests:  12%|█▏        | 481/4096 [00:01<00:07, 490.31it/s]
Adding requests:  13%|█▎        | 531/4096 [00:01<00:07, 480.10it/s]
Adding requests:  14%|█▍        | 584/4096 [00:01<00:07, 492.71it/s]
Adding requests:  16%|█▌        | 635/4096 [00:01<00:06, 496.86it/s]
Adding requests:  17%|█▋        | 687/4096 [00:01<00:06, 502.91it/s]
Adding requests:  18%|█▊        | 739/4096 [00:01<00:06, 506.40it/s]
Adding requests:  19%|█▉        | 790/4096 [00:01<00:06, 499.44it/s]
Adding requests:  21%|██        | 840/4096 [00:01<00:06, 491.08it/s]
Adding requests:  22%|██▏       | 892/4096 [00:01<00:06, 499.01it/s]
Adding requests:  23%|██▎       | 942/4096 [00:01<00:06, 498.29it/s]
Adding requests:  24%|██▍       | 993/4096 [00:02<00:06, 499.30it/s]
Adding requests:  25%|██▌       | 1044/4096 [00:02<00:06, 500.58it/s]
Adding requests:  27%|██▋       | 1095/4096 [00:02<00:06, 488.95it/s]
Adding requests:  28%|██▊       | 1144/4096 [00:02<00:06, 489.05it/s]
Adding requests:  29%|██▉       | 1197/4096 [00:02<00:05, 500.76it/s]
Adding requests:  30%|███       | 1248/4096 [00:02<00:05, 501.76it/s]
Adding requests:  32%|███▏      | 1299/4096 [00:02<00:05, 497.89it/s]
Adding requests:  33%|███▎      | 1351/4096 [00:02<00:05, 501.61it/s]
Adding requests:  34%|███▍      | 1403/4096 [00:02<00:05, 505.49it/s]
Adding requests:  35%|███▌      | 1454/4096 [00:02<00:05, 505.23it/s]
Adding requests:  37%|███▋      | 1506/4096 [00:03<00:05, 508.09it/s]
Adding requests:  38%|███▊      | 1558/4096 [00:03<00:04, 509.40it/s]
Adding requests:  39%|███▉      | 1611/4096 [00:03<00:04, 513.01it/s]
Adding requests:  41%|████      | 1663/4096 [00:03<00:04, 510.26it/s]
Adding requests:  42%|████▏     | 1715/4096 [00:03<00:04, 511.44it/s]
Adding requests:  43%|████▎     | 1767/4096 [00:03<00:04, 509.06it/s]
Adding requests:  44%|████▍     | 1820/4096 [00:03<00:04, 513.77it/s]
Adding requests:  46%|████▌     | 1872/4096 [00:03<00:04, 510.77it/s]
Adding requests:  47%|████▋     | 1924/4096 [00:03<00:04, 512.74it/s]
Adding requests:  48%|████▊     | 1976/4096 [00:03<00:04, 508.74it/s]
Adding requests:  50%|████▉     | 2029/4096 [00:04<00:04, 512.80it/s]
Adding requests:  51%|█████     | 2081/4096 [00:04<00:03, 514.19it/s]
Adding requests:  52%|█████▏    | 2133/4096 [00:04<00:03, 510.76it/s]
Adding requests:  53%|█████▎    | 2185/4096 [00:04<00:03, 502.71it/s]
Adding requests:  55%|█████▍    | 2238/4096 [00:04<00:03, 508.74it/s]
Adding requests:  56%|█████▌    | 2289/4096 [00:04<00:03, 492.86it/s]
Adding requests:  57%|█████▋    | 2340/4096 [00:04<00:03, 496.90it/s]
Adding requests:  58%|█████▊    | 2392/4096 [00:04<00:03, 501.43it/s]
Adding requests:  60%|█████▉    | 2444/4096 [00:04<00:03, 504.44it/s]
Adding requests:  61%|██████    | 2495/4096 [00:05<00:03, 504.53it/s]
Adding requests:  62%|██████▏   | 2547/4096 [00:05<00:03, 507.12it/s]
Adding requests:  63%|██████▎   | 2599/4096 [00:05<00:02, 509.20it/s]
Adding requests:  65%|██████▍   | 2651/4096 [00:05<00:02, 510.43it/s]
Adding requests:  66%|██████▌   | 2703/4096 [00:05<00:02, 508.42it/s]
Adding requests:  67%|██████▋   | 2754/4096 [00:05<00:02, 507.99it/s]
Adding requests:  69%|██████▊   | 2806/4096 [00:05<00:02, 508.74it/s]
Adding requests:  70%|██████▉   | 2858/4096 [00:05<00:02, 510.31it/s]
Adding requests:  71%|███████   | 2911/4096 [00:05<00:02, 514.82it/s]
Adding requests:  72%|███████▏  | 2963/4096 [00:05<00:02, 506.56it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:06<00:02, 509.45it/s]
Adding requests:  75%|███████▍  | 3066/4096 [00:06<00:02, 507.08it/s]
Adding requests:  76%|███████▌  | 3119/4096 [00:06<00:01, 510.40it/s]
Adding requests:  77%|███████▋  | 3171/4096 [00:06<00:01, 507.05it/s]
Adding requests:  79%|███████▊  | 3223/4096 [00:06<00:01, 509.55it/s]
Adding requests:  80%|███████▉  | 3275/4096 [00:06<00:01, 511.34it/s]
Adding requests:  81%|████████  | 3327/4096 [00:06<00:01, 511.47it/s]
Adding requests:  83%|████████▎ | 3380/4096 [00:06<00:01, 515.21it/s]
Adding requests:  84%|████████▍ | 3432/4096 [00:06<00:01, 514.88it/s]
Adding requests:  85%|████████▌ | 3484/4096 [00:06<00:01, 507.37it/s]
Adding requests:  86%|████████▋ | 3536/4096 [00:07<00:01, 508.21it/s]
Adding requests:  88%|████████▊ | 3588/4096 [00:07<00:00, 509.81it/s]
Adding requests:  89%|████████▉ | 3639/4096 [00:07<00:00, 495.23it/s]
Adding requests:  90%|█████████ | 3691/4096 [00:07<00:00, 501.57it/s]
Adding requests:  91%|█████████▏| 3742/4096 [00:07<00:00, 501.41it/s]
Adding requests:  93%|█████████▎| 3797/4096 [00:07<00:00, 514.68it/s]
Adding requests:  94%|█████████▍| 3850/4096 [00:07<00:00, 518.14it/s]
Adding requests:  95%|█████████▌| 3903/4096 [00:07<00:00, 519.51it/s]
Adding requests:  97%|█████████▋| 3955/4096 [00:07<00:00, 518.23it/s]
Adding requests:  98%|█████████▊| 4007/4096 [00:07<00:00, 516.74it/s]
Adding requests:  99%|█████████▉| 4059/4096 [00:08<00:00, 513.37it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 502.97it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 757/4096 [00:00<00:01, 1777.53it/s, est. speed input: 1820290.62 toks/s, output: 1777.56 toks/s]
Processed prompts:  23%|██▎       | 935/4096 [00:02<00:08, 352.10it/s, est. speed input: 447771.01 toks/s, output: 437.27 toks/s]   
Processed prompts:  25%|██▍       | 1015/4096 [00:03<00:13, 236.69it/s, est. speed input: 328654.17 toks/s, output: 320.95 toks/s]
Processed prompts:  26%|██▌       | 1062/4096 [00:03<00:13, 219.84it/s, est. speed input: 310118.93 toks/s, output: 302.85 toks/s]
Processed prompts:  27%|██▋       | 1096/4096 [00:03<00:15, 196.17it/s, est. speed input: 291291.78 toks/s, output: 284.46 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:04<00:17, 170.00it/s, est. speed input: 273719.03 toks/s, output: 267.30 toks/s]
Processed prompts:  28%|██▊       | 1142/4096 [00:04<00:20, 144.69it/s, est. speed input: 258125.73 toks/s, output: 252.08 toks/s]
Processed prompts:  29%|██▊       | 1173/4096 [00:04<00:22, 130.61it/s, est. speed input: 246302.20 toks/s, output: 240.53 toks/s]
Processed prompts:  29%|██▉       | 1205/4096 [00:05<00:23, 120.66it/s, est. speed input: 236366.37 toks/s, output: 230.82 toks/s]
Processed prompts:  30%|███       | 1237/4096 [00:05<00:25, 113.08it/s, est. speed input: 227654.81 toks/s, output: 222.32 toks/s]
Processed prompts:  31%|███       | 1269/4096 [00:05<00:26, 108.04it/s, est. speed input: 220207.60 toks/s, output: 215.05 toks/s]
Processed prompts:  32%|███▏      | 1301/4096 [00:06<00:26, 103.63it/s, est. speed input: 213292.46 toks/s, output: 208.29 toks/s]
Processed prompts:  33%|███▎      | 1333/4096 [00:06<00:27, 100.22it/s, est. speed input: 207013.23 toks/s, output: 202.16 toks/s]
Processed prompts:  33%|███▎      | 1365/4096 [00:06<00:27, 97.90it/s, est. speed input: 201400.11 toks/s, output: 196.68 toks/s] 
Processed prompts:  34%|███▍      | 1397/4096 [00:07<00:27, 96.43it/s, est. speed input: 196377.21 toks/s, output: 191.77 toks/s]
Processed prompts:  35%|███▍      | 1429/4096 [00:07<00:27, 95.29it/s, est. speed input: 191778.14 toks/s, output: 187.28 toks/s]
Processed prompts:  36%|███▌      | 1461/4096 [00:07<00:27, 94.42it/s, est. speed input: 187555.96 toks/s, output: 183.16 toks/s]
Processed prompts:  36%|███▋      | 1493/4096 [00:08<00:27, 93.94it/s, est. speed input: 183722.84 toks/s, output: 179.42 toks/s]
Processed prompts:  37%|███▋      | 1525/4096 [00:08<00:27, 93.56it/s, est. speed input: 180183.08 toks/s, output: 175.96 toks/s]
Processed prompts:  38%|███▊      | 1557/4096 [00:09<00:27, 93.14it/s, est. speed input: 176878.31 toks/s, output: 172.73 toks/s]
Processed prompts:  39%|███▉      | 1589/4096 [00:09<00:26, 93.99it/s, est. speed input: 174080.67 toks/s, output: 170.00 toks/s]
Processed prompts:  40%|███▉      | 1621/4096 [00:09<00:26, 93.48it/s, est. speed input: 171234.21 toks/s, output: 167.22 toks/s]
Processed prompts:  40%|████      | 1653/4096 [00:10<00:26, 93.09it/s, est. speed input: 168577.39 toks/s, output: 164.63 toks/s]
Processed prompts:  41%|████      | 1685/4096 [00:10<00:25, 92.96it/s, est. speed input: 166126.48 toks/s, output: 162.23 toks/s]
Processed prompts:  42%|████▏     | 1717/4096 [00:10<00:25, 92.83it/s, est. speed input: 163827.01 toks/s, output: 159.99 toks/s]
Processed prompts:  43%|████▎     | 1749/4096 [00:11<00:25, 92.61it/s, est. speed input: 161646.76 toks/s, output: 157.86 toks/s]
Processed prompts:  43%|████▎     | 1781/4096 [00:11<00:24, 92.65it/s, est. speed input: 159632.20 toks/s, output: 155.89 toks/s]
Processed prompts:  44%|████▍     | 1813/4096 [00:11<00:24, 92.50it/s, est. speed input: 157707.61 toks/s, output: 154.01 toks/s]
Processed prompts:  45%|████▌     | 1845/4096 [00:12<00:24, 92.37it/s, est. speed input: 155888.63 toks/s, output: 152.23 toks/s]
Processed prompts:  46%|████▌     | 1877/4096 [00:12<00:23, 93.36it/s, est. speed input: 154336.01 toks/s, output: 150.72 toks/s]
Processed prompts:  47%|████▋     | 1909/4096 [00:12<00:23, 93.18it/s, est. speed input: 152736.65 toks/s, output: 149.16 toks/s]
Processed prompts:  47%|████▋     | 1941/4096 [00:13<00:22, 93.95it/s, est. speed input: 151347.42 toks/s, output: 147.80 toks/s]
Processed prompts:  48%|████▊     | 1973/4096 [00:13<00:22, 93.71it/s, est. speed input: 149920.34 toks/s, output: 146.41 toks/s]
Processed prompts:  49%|████▉     | 2005/4096 [00:13<00:22, 93.41it/s, est. speed input: 148547.36 toks/s, output: 145.07 toks/s]
Processed prompts:  50%|████▉     | 2037/4096 [00:14<00:22, 93.25it/s, est. speed input: 147248.26 toks/s, output: 143.80 toks/s]
Processed prompts:  51%|█████     | 2069/4096 [00:14<00:21, 93.07it/s, est. speed input: 146001.44 toks/s, output: 142.58 toks/s]
Processed prompts:  51%|█████▏    | 2101/4096 [00:14<00:21, 92.97it/s, est. speed input: 144816.42 toks/s, output: 141.42 toks/s]
Processed prompts:  52%|█████▏    | 2133/4096 [00:15<00:21, 93.00it/s, est. speed input: 143695.91 toks/s, output: 140.33 toks/s]
Processed prompts:  53%|█████▎    | 2165/4096 [00:15<00:20, 93.05it/s, est. speed input: 142628.55 toks/s, output: 139.29 toks/s]
Processed prompts:  54%|█████▎    | 2197/4096 [00:15<00:20, 92.90it/s, est. speed input: 141587.18 toks/s, output: 138.27 toks/s]
Processed prompts:  54%|█████▍    | 2229/4096 [00:16<00:19, 94.42it/s, est. speed input: 140761.59 toks/s, output: 137.46 toks/s]
Processed prompts:  55%|█████▌    | 2261/4096 [00:16<00:19, 94.01it/s, est. speed input: 139818.20 toks/s, output: 136.54 toks/s]
Processed prompts:  56%|█████▌    | 2293/4096 [00:16<00:19, 94.57it/s, est. speed input: 138995.64 toks/s, output: 135.74 toks/s]
Processed prompts:  57%|█████▋    | 2325/4096 [00:17<00:18, 94.83it/s, est. speed input: 138193.19 toks/s, output: 134.95 toks/s]
Processed prompts:  58%|█████▊    | 2357/4096 [00:17<00:18, 95.03it/s, est. speed input: 137421.80 toks/s, output: 134.20 toks/s]
Processed prompts:  58%|█████▊    | 2389/4096 [00:17<00:17, 95.16it/s, est. speed input: 136679.60 toks/s, output: 133.48 toks/s]
Processed prompts:  59%|█████▉    | 2421/4096 [00:18<00:17, 94.47it/s, est. speed input: 135894.40 toks/s, output: 132.71 toks/s]
Processed prompts:  60%|█████▉    | 2453/4096 [00:18<00:17, 93.92it/s, est. speed input: 135133.01 toks/s, output: 131.97 toks/s]
Processed prompts:  61%|██████    | 2485/4096 [00:18<00:17, 94.27it/s, est. speed input: 134461.00 toks/s, output: 131.31 toks/s]
Processed prompts:  61%|██████▏   | 2517/4096 [00:19<00:16, 93.63it/s, est. speed input: 133739.46 toks/s, output: 130.60 toks/s]
Processed prompts:  62%|██████▏   | 2549/4096 [00:19<00:16, 93.38it/s, est. speed input: 133058.56 toks/s, output: 129.94 toks/s]
Processed prompts:  63%|██████▎   | 2581/4096 [00:19<00:16, 94.09it/s, est. speed input: 132472.83 toks/s, output: 129.37 toks/s]
Processed prompts:  64%|██████▍   | 2613/4096 [00:20<00:15, 93.53it/s, est. speed input: 131823.89 toks/s, output: 128.73 toks/s]
Processed prompts:  65%|██████▍   | 2645/4096 [00:20<00:15, 93.24it/s, est. speed input: 131203.85 toks/s, output: 128.13 toks/s]
Processed prompts:  65%|██████▌   | 2677/4096 [00:20<00:15, 93.02it/s, est. speed input: 130602.47 toks/s, output: 127.54 toks/s]
Processed prompts:  66%|██████▌   | 2709/4096 [00:21<00:14, 92.80it/s, est. speed input: 130015.77 toks/s, output: 126.97 toks/s]
Processed prompts:  67%|██████▋   | 2741/4096 [00:21<00:14, 92.85it/s, est. speed input: 129463.36 toks/s, output: 126.43 toks/s]
Processed prompts:  68%|██████▊   | 2773/4096 [00:22<00:14, 92.85it/s, est. speed input: 128924.93 toks/s, output: 125.90 toks/s]
Processed prompts:  68%|██████▊   | 2805/4096 [00:22<00:13, 92.53it/s, est. speed input: 128380.59 toks/s, output: 125.37 toks/s]
Processed prompts:  69%|██████▉   | 2837/4096 [00:22<00:13, 92.69it/s, est. speed input: 127879.85 toks/s, output: 124.88 toks/s]
Processed prompts:  70%|███████   | 2869/4096 [00:23<00:13, 92.77it/s, est. speed input: 127391.66 toks/s, output: 124.41 toks/s]
Processed prompts:  71%|███████   | 2901/4096 [00:23<00:12, 92.55it/s, est. speed input: 126899.64 toks/s, output: 123.93 toks/s]
Processed prompts:  72%|███████▏  | 2933/4096 [00:23<00:12, 92.59it/s, est. speed input: 126434.88 toks/s, output: 123.47 toks/s]
Processed prompts:  72%|███████▏  | 2965/4096 [00:24<00:12, 92.71it/s, est. speed input: 125989.22 toks/s, output: 123.04 toks/s]
Processed prompts:  73%|███████▎  | 2997/4096 [00:24<00:11, 92.56it/s, est. speed input: 125541.14 toks/s, output: 122.60 toks/s]
Processed prompts:  74%|███████▍  | 3029/4096 [00:24<00:11, 92.51it/s, est. speed input: 125108.94 toks/s, output: 122.18 toks/s]
Processed prompts:  75%|███████▍  | 3061/4096 [00:25<00:11, 92.52it/s, est. speed input: 124691.67 toks/s, output: 121.77 toks/s]
Processed prompts:  76%|███████▌  | 3093/4096 [00:25<00:10, 92.60it/s, est. speed input: 124289.97 toks/s, output: 121.38 toks/s]
Processed prompts:  76%|███████▋  | 3125/4096 [00:25<00:10, 93.38it/s, est. speed input: 123941.60 toks/s, output: 121.04 toks/s]
Processed prompts:  77%|███████▋  | 3157/4096 [00:26<00:10, 93.08it/s, est. speed input: 123553.55 toks/s, output: 120.66 toks/s]
Processed prompts:  78%|███████▊  | 3189/4096 [00:26<00:09, 92.96it/s, est. speed input: 123180.68 toks/s, output: 120.29 toks/s]
Processed prompts:  79%|███████▊  | 3221/4096 [00:26<00:09, 92.75it/s, est. speed input: 122809.51 toks/s, output: 119.93 toks/s]
Processed prompts:  79%|███████▉  | 3253/4096 [00:27<00:09, 92.65it/s, est. speed input: 122450.79 toks/s, output: 119.58 toks/s]
Processed prompts:  80%|████████  | 3285/4096 [00:27<00:08, 92.61it/s, est. speed input: 122103.25 toks/s, output: 119.24 toks/s]
Processed prompts:  81%|████████  | 3317/4096 [00:27<00:08, 92.51it/s, est. speed input: 121759.89 toks/s, output: 118.91 toks/s]
Processed prompts:  82%|████████▏ | 3349/4096 [00:28<00:08, 92.58it/s, est. speed input: 121432.26 toks/s, output: 118.59 toks/s]
Processed prompts:  83%|████████▎ | 3381/4096 [00:28<00:07, 92.52it/s, est. speed input: 121107.39 toks/s, output: 118.27 toks/s]
Processed prompts:  83%|████████▎ | 3413/4096 [00:28<00:07, 92.38it/s, est. speed input: 120784.89 toks/s, output: 117.95 toks/s]
Processed prompts:  84%|████████▍ | 3445/4096 [00:29<00:07, 92.44it/s, est. speed input: 120477.92 toks/s, output: 117.65 toks/s]
Processed prompts:  85%|████████▍ | 3477/4096 [00:29<00:06, 93.33it/s, est. speed input: 120221.13 toks/s, output: 117.40 toks/s]
Processed prompts:  86%|████████▌ | 3509/4096 [00:29<00:06, 93.93it/s, est. speed input: 119968.30 toks/s, output: 117.16 toks/s]
Processed prompts:  86%|████████▋ | 3541/4096 [00:30<00:05, 93.43it/s, est. speed input: 119676.69 toks/s, output: 116.87 toks/s]
Processed prompts:  87%|████████▋ | 3573/4096 [00:30<00:05, 93.19it/s, est. speed input: 119397.02 toks/s, output: 116.60 toks/s]
Processed prompts:  88%|████████▊ | 3605/4096 [00:30<00:05, 92.94it/s, est. speed input: 119119.24 toks/s, output: 116.33 toks/s]
Processed prompts:  89%|████████▉ | 3637/4096 [00:31<00:04, 92.77it/s, est. speed input: 118848.25 toks/s, output: 116.06 toks/s]
Processed prompts:  90%|████████▉ | 3669/4096 [00:31<00:04, 92.74it/s, est. speed input: 118587.27 toks/s, output: 115.81 toks/s]
Processed prompts:  90%|█████████ | 3701/4096 [00:32<00:04, 92.57it/s, est. speed input: 118324.86 toks/s, output: 115.55 toks/s]
Processed prompts:  91%|█████████ | 3733/4096 [00:32<00:03, 93.13it/s, est. speed input: 118098.78 toks/s, output: 115.33 toks/s]
Processed prompts:  92%|█████████▏| 3765/4096 [00:32<00:03, 92.96it/s, est. speed input: 117852.64 toks/s, output: 115.09 toks/s]
Processed prompts:  93%|█████████▎| 3797/4096 [00:33<00:03, 92.80it/s, est. speed input: 117609.64 toks/s, output: 114.85 toks/s]
Processed prompts:  93%|█████████▎| 3829/4096 [00:33<00:02, 93.40it/s, est. speed input: 117402.41 toks/s, output: 114.65 toks/s]
Processed prompts:  94%|█████████▍| 3861/4096 [00:33<00:02, 93.07it/s, est. speed input: 117167.50 toks/s, output: 114.42 toks/s]
Processed prompts:  95%|█████████▌| 3893/4096 [00:34<00:02, 92.77it/s, est. speed input: 116934.04 toks/s, output: 114.19 toks/s]
Processed prompts:  96%|█████████▌| 3925/4096 [00:34<00:01, 92.57it/s, est. speed input: 116706.07 toks/s, output: 113.97 toks/s]
Processed prompts:  97%|█████████▋| 3957/4096 [00:34<00:01, 92.55it/s, est. speed input: 116487.38 toks/s, output: 113.76 toks/s]
Processed prompts:  97%|█████████▋| 3989/4096 [00:35<00:01, 92.35it/s, est. speed input: 116265.29 toks/s, output: 113.54 toks/s]
Processed prompts:  98%|█████████▊| 4021/4096 [00:35<00:00, 93.13it/s, est. speed input: 116084.98 toks/s, output: 113.36 toks/s]
Processed prompts:  99%|█████████▉| 4053/4096 [00:35<00:00, 93.02it/s, est. speed input: 115882.00 toks/s, output: 113.17 toks/s]
Processed prompts: 100%|█████████▉| 4085/4096 [00:35<00:00, 114.05it/s, est. speed input: 116366.00 toks/s, output: 113.64 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 114.05it/s, est. speed input: 116677.56 toks/s, output: 113.94 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 113.94it/s, est. speed input: 116677.56 toks/s, output: 113.94 toks/s]
[rank0]:[W128 09:29:29.445836988 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

