
========== M=16 ==========
Time: 2026-01-26 07:55:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:56:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1009507) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1009507) WARNING 01-26 07:56:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.43 requests/s, 517.26 total tokens/s, 30.43 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:56:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:56:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1009507) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1009507) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.95it/s]
(EngineCore_DP0 pid=1009507) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.94it/s]
(EngineCore_DP0 pid=1009507) 
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1009507) [2026-01-26 07:56:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1009507) 2026-01-26 07:56:23,115 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1009507) 2026-01-26 07:56:23,173 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1009507) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]
(EngineCore_DP0 pid=1009507) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.31it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2535.08it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:40,  3.12it/s, est. speed input: 49.93 toks/s, output: 3.12 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 13.67it/s, est. speed input: 181.80 toks/s, output: 11.36 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 20.29it/s, est. speed input: 257.77 toks/s, output: 16.11 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 24.42it/s, est. speed input: 305.95 toks/s, output: 19.12 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 27.15it/s, est. speed input: 339.57 toks/s, output: 21.22 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.97it/s, est. speed input: 364.34 toks/s, output: 22.77 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 30.20it/s, est. speed input: 383.30 toks/s, output: 23.96 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.06it/s, est. speed input: 398.38 toks/s, output: 24.90 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 31.65it/s, est. speed input: 410.60 toks/s, output: 25.66 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.05it/s, est. speed input: 420.69 toks/s, output: 26.29 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.38it/s, est. speed input: 429.35 toks/s, output: 26.83 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.61it/s, est. speed input: 436.73 toks/s, output: 27.30 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.73it/s, est. speed input: 442.98 toks/s, output: 27.69 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.79it/s, est. speed input: 448.38 toks/s, output: 28.02 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 32.88it/s, est. speed input: 453.24 toks/s, output: 28.33 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.91it/s, est. speed input: 457.48 toks/s, output: 28.59 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.96it/s, est. speed input: 461.32 toks/s, output: 28.83 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.02it/s, est. speed input: 464.84 toks/s, output: 29.05 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.02it/s, est. speed input: 467.92 toks/s, output: 29.24 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.05it/s, est. speed input: 470.77 toks/s, output: 29.42 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.02it/s, est. speed input: 473.28 toks/s, output: 29.58 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.04it/s, est. speed input: 475.66 toks/s, output: 29.73 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.08it/s, est. speed input: 477.88 toks/s, output: 29.87 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 33.07it/s, est. speed input: 479.87 toks/s, output: 29.99 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.04it/s, est. speed input: 481.66 toks/s, output: 30.10 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.02it/s, est. speed input: 483.32 toks/s, output: 30.21 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.02it/s, est. speed input: 484.90 toks/s, output: 30.31 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.90it/s, est. speed input: 486.17 toks/s, output: 30.39 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.16it/s, est. speed input: 487.90 toks/s, output: 30.49 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.38it/s, est. speed input: 489.59 toks/s, output: 30.60 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.44it/s, est. speed input: 491.02 toks/s, output: 30.69 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.35it/s, est. speed input: 492.20 toks/s, output: 30.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.35it/s, est. speed input: 493.01 toks/s, output: 30.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.81it/s, est. speed input: 493.01 toks/s, output: 30.81 toks/s]
[rank0]:[W126 07:56:29.749203764 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 07:56:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:56:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1010571) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1010571) WARNING 01-26 07:56:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.19 requests/s, 3894.73 total tokens/s, 30.19 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 07:56:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:56:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:56:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:56:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1010571) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1010571) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.65it/s]
(EngineCore_DP0 pid=1010571) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.65it/s]
(EngineCore_DP0 pid=1010571) 
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1010571) [2026-01-26 07:56:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1010571) 2026-01-26 07:56:59,628 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1010571) 2026-01-26 07:56:59,659 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1010571) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.58it/s]
(EngineCore_DP0 pid=1010571) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1691.67it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:37,  3.35it/s, est. speed input: 428.60 toks/s, output: 3.35 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:10, 11.74it/s, est. speed input: 1264.68 toks/s, output: 9.88 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 19.38it/s, est. speed input: 1953.78 toks/s, output: 15.26 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:04, 23.95it/s, est. speed input: 2378.38 toks/s, output: 18.58 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 26.86it/s, est. speed input: 2668.64 toks/s, output: 20.85 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:03, 28.76it/s, est. speed input: 2879.05 toks/s, output: 22.49 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:03, 30.06it/s, est. speed input: 3039.45 toks/s, output: 23.74 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:03, 30.89it/s, est. speed input: 3163.70 toks/s, output: 24.72 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:03, 31.47it/s, est. speed input: 3263.99 toks/s, output: 25.50 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 31.99it/s, est. speed input: 3350.47 toks/s, output: 26.18 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 32.39it/s, est. speed input: 3423.93 toks/s, output: 26.75 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 32.49it/s, est. speed input: 3481.69 toks/s, output: 27.20 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 32.59it/s, est. speed input: 3531.95 toks/s, output: 27.59 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 32.65it/s, est. speed input: 3575.53 toks/s, output: 27.93 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:02, 32.71it/s, est. speed input: 3614.13 toks/s, output: 28.24 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:02, 32.71it/s, est. speed input: 3647.42 toks/s, output: 28.50 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:01, 32.73it/s, est. speed input: 3677.49 toks/s, output: 28.73 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:01, 32.86it/s, est. speed input: 3706.72 toks/s, output: 28.96 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:01, 33.09it/s, est. speed input: 3735.53 toks/s, output: 29.18 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 33.23it/s, est. speed input: 3761.36 toks/s, output: 29.39 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 33.25it/s, est. speed input: 3783.52 toks/s, output: 29.56 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 33.12it/s, est. speed input: 3801.48 toks/s, output: 29.70 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 33.02it/s, est. speed input: 3817.89 toks/s, output: 29.83 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 32.96it/s, est. speed input: 3833.11 toks/s, output: 29.95 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:00, 32.96it/s, est. speed input: 3847.71 toks/s, output: 30.06 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:03<00:00, 33.14it/s, est. speed input: 3863.93 toks/s, output: 30.19 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:03<00:00, 33.29it/s, est. speed input: 3879.18 toks/s, output: 30.31 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:03<00:00, 33.18it/s, est. speed input: 3890.73 toks/s, output: 30.40 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 33.14it/s, est. speed input: 3901.85 toks/s, output: 30.48 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 33.14it/s, est. speed input: 3912.69 toks/s, output: 30.57 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 33.00it/s, est. speed input: 3921.08 toks/s, output: 30.63 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:04<00:00, 32.92it/s, est. speed input: 3929.22 toks/s, output: 30.70 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.82it/s, est. speed input: 3936.41 toks/s, output: 30.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.82it/s, est. speed input: 3936.41 toks/s, output: 30.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.75it/s, est. speed input: 3936.41 toks/s, output: 30.75 toks/s]
[rank0]:[W126 07:57:06.636658236 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 07:57:08
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:57:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1011602) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1011602) WARNING 01-26 07:57:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.03 requests/s, 7717.44 total tokens/s, 30.03 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 07:57:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:57:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:57:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:57:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:57:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:57:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:57:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:57:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:57:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:57:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:57:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:57:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:57:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:57:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:57:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:57:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:57:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1011602) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1011602) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1011602) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.91it/s]
(EngineCore_DP0 pid=1011602) 
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1011602) [2026-01-26 07:57:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1011602) 2026-01-26 07:57:37,050 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1011602) 2026-01-26 07:57:37,117 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1011602) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.35it/s]
(EngineCore_DP0 pid=1011602) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 19.34it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|██████▉   | 89/128 [00:00<00:00, 887.77it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1026.41it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:36,  3.45it/s, est. speed input: 882.17 toks/s, output: 3.45 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:10, 12.02it/s, est. speed input: 2593.39 toks/s, output: 10.13 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 19.60it/s, est. speed input: 3972.14 toks/s, output: 15.52 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:04, 24.20it/s, est. speed input: 4828.63 toks/s, output: 18.86 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 27.14it/s, est. speed input: 5413.65 toks/s, output: 21.15 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:03, 29.05it/s, est. speed input: 5836.18 toks/s, output: 22.80 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:03, 30.32it/s, est. speed input: 6155.47 toks/s, output: 24.04 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:03, 31.37it/s, est. speed input: 6419.89 toks/s, output: 25.08 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:03, 31.88it/s, est. speed input: 6618.84 toks/s, output: 25.85 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:02, 32.14it/s, est. speed input: 6776.82 toks/s, output: 26.47 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 32.44it/s, est. speed input: 6915.79 toks/s, output: 27.01 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 32.63it/s, est. speed input: 7033.02 toks/s, output: 27.47 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 32.77it/s, est. speed input: 7134.03 toks/s, output: 27.87 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 33.03it/s, est. speed input: 7229.41 toks/s, output: 28.24 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:02, 33.11it/s, est. speed input: 7308.85 toks/s, output: 28.55 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:02, 33.20it/s, est. speed input: 7380.23 toks/s, output: 28.83 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:01, 33.36it/s, est. speed input: 7447.88 toks/s, output: 29.09 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:01, 33.36it/s, est. speed input: 7504.25 toks/s, output: 29.31 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:01, 33.24it/s, est. speed input: 7550.73 toks/s, output: 29.49 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 33.14it/s, est. speed input: 7592.34 toks/s, output: 29.66 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 33.12it/s, est. speed input: 7631.56 toks/s, output: 29.81 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 33.09it/s, est. speed input: 7667.14 toks/s, output: 29.95 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 33.06it/s, est. speed input: 7699.39 toks/s, output: 30.08 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 33.08it/s, est. speed input: 7730.18 toks/s, output: 30.20 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:00, 33.07it/s, est. speed input: 7758.19 toks/s, output: 30.31 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:03<00:00, 33.03it/s, est. speed input: 7783.10 toks/s, output: 30.40 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:03<00:00, 33.07it/s, est. speed input: 7807.96 toks/s, output: 30.50 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:03<00:00, 33.08it/s, est. speed input: 7830.72 toks/s, output: 30.59 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:03<00:00, 33.07it/s, est. speed input: 7851.61 toks/s, output: 30.67 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 33.08it/s, est. speed input: 7871.55 toks/s, output: 30.75 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 33.02it/s, est. speed input: 7888.51 toks/s, output: 30.81 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:04<00:00, 33.01it/s, est. speed input: 7905.40 toks/s, output: 30.88 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.07it/s, est. speed input: 7922.82 toks/s, output: 30.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.07it/s, est. speed input: 7922.82 toks/s, output: 30.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.95it/s, est. speed input: 7922.82 toks/s, output: 30.95 toks/s]
[rank0]:[W126 07:57:43.417576685 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:53:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:53:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1093026) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1093026) WARNING 01-26 08:53:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.73 requests/s, 16790.28 total tokens/s, 32.73 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:53:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:53:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:53:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:53:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:53:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:53:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:53:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:53:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:53:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:53:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:53:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:53:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:53:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:53:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:53:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:53:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:53:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1093026) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1093026) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.94it/s]
(EngineCore_DP0 pid=1093026) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.94it/s]
(EngineCore_DP0 pid=1093026) 
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1093026) [2026-01-26 08:53:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1093026) 2026-01-26 08:54:05,053 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1093026) 2026-01-26 08:54:05,088 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1093026) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.71it/s]
(EngineCore_DP0 pid=1093026) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  37%|███▋      | 47/128 [00:00<00:00, 463.97it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 664.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 70.29it/s, est. speed input: 35992.73 toks/s, output: 70.29 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:02, 42.11it/s, est. speed input: 22941.56 toks/s, output: 44.80 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 38.70it/s, est. speed input: 21242.71 toks/s, output: 41.49 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 36.88it/s, est. speed input: 20331.33 toks/s, output: 39.71 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 35.88it/s, est. speed input: 19841.03 toks/s, output: 38.75 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 35.17it/s, est. speed input: 19478.02 toks/s, output: 38.04 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 34.69it/s, est. speed input: 19206.93 toks/s, output: 37.51 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 34.39it/s, est. speed input: 19000.60 toks/s, output: 37.11 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 34.08it/s, est. speed input: 18817.43 toks/s, output: 36.75 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 33.71it/s, est. speed input: 18640.27 toks/s, output: 36.41 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 33.71it/s, est. speed input: 18529.90 toks/s, output: 36.19 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:02, 33.69it/s, est. speed input: 18433.88 toks/s, output: 36.00 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 33.66it/s, est. speed input: 18349.18 toks/s, output: 35.84 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 33.64it/s, est. speed input: 18275.26 toks/s, output: 35.69 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 33.64it/s, est. speed input: 18211.53 toks/s, output: 35.57 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 33.37it/s, est. speed input: 18127.16 toks/s, output: 35.40 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 33.41it/s, est. speed input: 18074.36 toks/s, output: 35.30 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 33.26it/s, est. speed input: 18010.74 toks/s, output: 35.18 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 33.35it/s, est. speed input: 17970.61 toks/s, output: 35.10 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 33.16it/s, est. speed input: 17913.08 toks/s, output: 34.99 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:01, 33.30it/s, est. speed input: 17882.08 toks/s, output: 34.93 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 33.39it/s, est. speed input: 17853.69 toks/s, output: 34.87 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 33.49it/s, est. speed input: 17829.86 toks/s, output: 34.82 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:03<00:00, 33.30it/s, est. speed input: 17790.10 toks/s, output: 34.75 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 33.27it/s, est. speed input: 17760.21 toks/s, output: 34.69 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 33.16it/s, est. speed input: 17726.48 toks/s, output: 34.62 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 33.05it/s, est. speed input: 17692.99 toks/s, output: 34.56 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 32.99it/s, est. speed input: 17662.99 toks/s, output: 34.50 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 33.04it/s, est. speed input: 17640.13 toks/s, output: 34.45 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.04it/s, est. speed input: 17634.07 toks/s, output: 34.44 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.44it/s, est. speed input: 17634.07 toks/s, output: 34.44 toks/s]
[rank0]:[W126 08:54:11.227967901 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:54:13
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:54:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1094040) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1094040) WARNING 01-26 08:54:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.68 requests/s, 32468.77 total tokens/s, 31.68 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:54:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:54:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:54:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:54:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:54:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:54:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:54:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:54:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:54:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:54:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:54:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:54:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1094040) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1094040) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1094040) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1094040) 
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1094040) [2026-01-26 08:54:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1094040) 2026-01-26 08:54:41,186 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1094040) 2026-01-26 08:54:41,233 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1094040) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.18it/s]
(EngineCore_DP0 pid=1094040) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.67it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  22%|██▏       | 28/128 [00:00<00:00, 278.46it/s]
Adding requests:  62%|██████▏   | 79/128 [00:00<00:00, 414.15it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 426.44it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 69.92it/s, est. speed input: 71617.25 toks/s, output: 69.92 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:02, 43.22it/s, est. speed input: 47144.12 toks/s, output: 46.03 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:02, 38.90it/s, est. speed input: 42937.80 toks/s, output: 41.93 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 36.70it/s, est. speed input: 40753.11 toks/s, output: 39.80 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 35.60it/s, est. speed input: 39638.95 toks/s, output: 38.71 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 34.84it/s, est. speed input: 38839.63 toks/s, output: 37.93 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:00<00:02, 34.33it/s, est. speed input: 38240.08 toks/s, output: 37.34 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.96it/s, est. speed input: 37767.12 toks/s, output: 36.88 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.69it/s, est. speed input: 37383.13 toks/s, output: 36.51 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.47it/s, est. speed input: 37059.01 toks/s, output: 36.19 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.37it/s, est. speed input: 36801.93 toks/s, output: 35.94 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.28it/s, est. speed input: 36579.58 toks/s, output: 35.72 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 33.21it/s, est. speed input: 36386.27 toks/s, output: 35.53 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 33.11it/s, est. speed input: 36207.12 toks/s, output: 35.36 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 33.09it/s, est. speed input: 36060.48 toks/s, output: 35.21 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.09it/s, est. speed input: 35934.27 toks/s, output: 35.09 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.08it/s, est. speed input: 35819.84 toks/s, output: 34.98 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.05it/s, est. speed input: 35713.00 toks/s, output: 34.88 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.09it/s, est. speed input: 35626.63 toks/s, output: 34.79 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.13it/s, est. speed input: 35552.07 toks/s, output: 34.72 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.10it/s, est. speed input: 35474.02 toks/s, output: 34.64 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 33.10it/s, est. speed input: 35406.04 toks/s, output: 34.58 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 33.10it/s, est. speed input: 35343.14 toks/s, output: 34.51 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.17it/s, est. speed input: 35296.11 toks/s, output: 34.47 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.37it/s, est. speed input: 35272.61 toks/s, output: 34.45 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.33it/s, est. speed input: 35226.31 toks/s, output: 34.40 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.26it/s, est. speed input: 35179.01 toks/s, output: 34.35 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.17it/s, est. speed input: 35130.23 toks/s, output: 34.31 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.11it/s, est. speed input: 35084.15 toks/s, output: 34.26 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.11it/s, est. speed input: 35056.21 toks/s, output: 34.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.23it/s, est. speed input: 35056.21 toks/s, output: 34.23 toks/s]
[rank0]:[W126 08:54:47.461213646 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:54:49
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:54:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1095049) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1095049) WARNING 01-26 08:55:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 63.08 requests/s, 64654.39 total tokens/s, 63.08 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:54:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:54:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:54:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:54:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:54:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:54:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:54:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:54:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:55:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:55:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:55:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:55:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:55:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:55:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1095049) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1095049) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.94it/s]
(EngineCore_DP0 pid=1095049) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.94it/s]
(EngineCore_DP0 pid=1095049) 
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1095049) [2026-01-26 08:55:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1095049) 2026-01-26 08:55:17,651 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1095049) 2026-01-26 08:55:17,702 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1095049) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 14.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.73it/s]
(EngineCore_DP0 pid=1095049) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.60it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 249.59it/s]
Adding requests:  30%|██▉       | 76/256 [00:00<00:00, 401.50it/s]
Adding requests:  49%|████▉     | 126/256 [00:00<00:00, 442.95it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 457.72it/s]
Adding requests:  88%|████████▊ | 226/256 [00:00<00:00, 473.18it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 452.51it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 189.14it/s, est. speed input: 193736.07 toks/s, output: 189.15 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:00<00:02, 102.98it/s, est. speed input: 114163.74 toks/s, output: 111.48 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:00<00:02, 85.68it/s, est. speed input: 97764.74 toks/s, output: 95.47 toks/s]   
Processed prompts:  26%|██▌       | 66/256 [00:00<00:02, 80.67it/s, est. speed input: 92605.35 toks/s, output: 90.43 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:00<00:02, 80.05it/s, est. speed input: 90918.82 toks/s, output: 88.79 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:00<00:02, 74.48it/s, est. speed input: 87042.95 toks/s, output: 85.00 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:01<00:02, 73.24it/s, est. speed input: 85431.76 toks/s, output: 83.43 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:01<00:02, 72.14it/s, est. speed input: 84059.63 toks/s, output: 82.09 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:01<00:02, 71.25it/s, est. speed input: 82898.99 toks/s, output: 80.95 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:01<00:01, 70.29it/s, est. speed input: 81821.60 toks/s, output: 79.90 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:01<00:01, 69.62it/s, est. speed input: 80908.78 toks/s, output: 79.01 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:01<00:01, 69.13it/s, est. speed input: 80118.31 toks/s, output: 78.24 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:01<00:01, 68.75it/s, est. speed input: 79424.00 toks/s, output: 77.56 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:01<00:01, 68.42it/s, est. speed input: 78800.10 toks/s, output: 76.95 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:02<00:01, 68.30it/s, est. speed input: 78272.20 toks/s, output: 76.44 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:02<00:01, 68.22it/s, est. speed input: 77805.41 toks/s, output: 75.98 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:02<00:01, 68.07it/s, est. speed input: 77363.92 toks/s, output: 75.55 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:02<00:01, 68.59it/s, est. speed input: 77084.92 toks/s, output: 75.28 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:02<00:00, 69.01it/s, est. speed input: 76839.01 toks/s, output: 75.04 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:02<00:00, 69.24it/s, est. speed input: 76602.37 toks/s, output: 74.81 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:02<00:00, 69.40it/s, est. speed input: 76386.71 toks/s, output: 74.60 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:02<00:00, 69.51it/s, est. speed input: 76187.51 toks/s, output: 74.40 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:02<00:00, 68.93it/s, est. speed input: 75910.55 toks/s, output: 74.13 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:03<00:00, 69.15it/s, est. speed input: 75740.57 toks/s, output: 73.97 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:03<00:00, 69.32it/s, est. speed input: 75584.05 toks/s, output: 73.81 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:03<00:00, 68.95it/s, est. speed input: 75377.07 toks/s, output: 73.61 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:03<00:00, 68.62it/s, est. speed input: 75174.57 toks/s, output: 73.41 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 68.62it/s, est. speed input: 75090.15 toks/s, output: 73.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 73.33it/s, est. speed input: 75090.15 toks/s, output: 73.33 toks/s]
[rank0]:[W126 08:55:24.044689530 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:55:26
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:55:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1096093) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1096093) WARNING 01-26 08:55:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 114.55 requests/s, 117409.86 total tokens/s, 114.55 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:55:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:55:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:55:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:55:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:55:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:55:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:55:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:55:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:55:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:55:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:55:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:55:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:55:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:55:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1096093) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1096093) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.25it/s]
(EngineCore_DP0 pid=1096093) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.24it/s]
(EngineCore_DP0 pid=1096093) 
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1096093) [2026-01-26 08:55:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1096093) 2026-01-26 08:55:56,570 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1096093) 2026-01-26 08:55:56,601 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1096093) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  5.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  5.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  5.44it/s]
(EngineCore_DP0 pid=1096093) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  9.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  9.07it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   7%|▋         | 37/512 [00:00<00:01, 369.38it/s]
Adding requests:  17%|█▋        | 87/512 [00:00<00:00, 443.15it/s]
Adding requests:  27%|██▋       | 137/512 [00:00<00:00, 465.50it/s]
Adding requests:  36%|███▌      | 185/512 [00:00<00:00, 470.02it/s]
Adding requests:  46%|████▌     | 236/512 [00:00<00:00, 483.94it/s]
Adding requests:  56%|█████▌    | 285/512 [00:00<00:00, 449.71it/s]
Adding requests:  65%|██████▌   | 334/512 [00:00<00:00, 460.21it/s]
Adding requests:  75%|███████▌  | 384/512 [00:00<00:00, 470.94it/s]
Adding requests:  85%|████████▍ | 434/512 [00:00<00:00, 477.38it/s]
Adding requests:  94%|█████████▍| 482/512 [00:01<00:00, 476.86it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 466.87it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:00<00:00, 721.60it/s, est. speed input: 739020.55 toks/s, output: 721.63 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:00<00:01, 215.00it/s, est. speed input: 249773.84 toks/s, output: 243.92 toks/s]
Processed prompts:  40%|████      | 205/512 [00:00<00:01, 184.11it/s, est. speed input: 217112.35 toks/s, output: 212.02 toks/s]
Processed prompts:  45%|████▌     | 232/512 [00:01<00:01, 166.20it/s, est. speed input: 200527.39 toks/s, output: 195.83 toks/s]
Processed prompts:  49%|████▉     | 253/512 [00:01<00:01, 159.35it/s, est. speed input: 193550.87 toks/s, output: 189.01 toks/s]
Processed prompts:  53%|█████▎    | 272/512 [00:01<00:01, 150.46it/s, est. speed input: 186640.72 toks/s, output: 182.26 toks/s]
Processed prompts:  56%|█████▋    | 289/512 [00:01<00:01, 147.77it/s, est. speed input: 183210.30 toks/s, output: 178.92 toks/s]
Processed prompts:  60%|█████▉    | 305/512 [00:01<00:01, 142.99it/s, est. speed input: 179473.50 toks/s, output: 175.27 toks/s]
Processed prompts:  62%|██████▎   | 320/512 [00:01<00:01, 137.16it/s, est. speed input: 175711.37 toks/s, output: 171.59 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:01<00:01, 130.45it/s, est. speed input: 171899.63 toks/s, output: 167.87 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:02<00:01, 128.83it/s, est. speed input: 169222.05 toks/s, output: 165.25 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:02<00:01, 128.54it/s, est. speed input: 167080.75 toks/s, output: 163.16 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:02<00:01, 128.63it/s, est. speed input: 165238.70 toks/s, output: 161.36 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:02<00:00, 128.07it/s, est. speed input: 163442.70 toks/s, output: 159.61 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:02<00:00, 127.51it/s, est. speed input: 161785.97 toks/s, output: 157.99 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:02<00:00, 128.46it/s, est. speed input: 160543.47 toks/s, output: 156.78 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:02<00:00, 129.01it/s, est. speed input: 159383.74 toks/s, output: 155.65 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:02<00:00, 128.85it/s, est. speed input: 158225.03 toks/s, output: 154.51 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:03<00:00, 128.60it/s, est. speed input: 157134.95 toks/s, output: 153.45 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:03<00:00, 127.91it/s, est. speed input: 156050.05 toks/s, output: 152.39 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:03<00:00, 126.55it/s, est. speed input: 154911.27 toks/s, output: 151.28 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 126.55it/s, est. speed input: 155505.13 toks/s, output: 151.86 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 151.85it/s, est. speed input: 155505.13 toks/s, output: 151.86 toks/s]
[rank0]:[W126 08:56:03.982198507 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:56:05
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:56:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1097179) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1097179) WARNING 01-26 08:56:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 159.24 requests/s, 163221.94 total tokens/s, 159.24 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:56:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:56:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:56:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:56:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:56:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:56:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:56:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:56:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:56:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:56:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:56:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:56:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:56:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:56:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:56:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:56:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:56:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1097179) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1097179) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1097179) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1097179) 
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1097179) [2026-01-26 08:56:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1097179) 2026-01-26 08:56:37,165 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1097179) 2026-01-26 08:56:37,480 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1097179) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 14.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 16.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 16.36it/s]
(EngineCore_DP0 pid=1097179) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.94it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  6.28it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 10.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.15it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 30/1024 [00:00<00:03, 298.78it/s]
Adding requests:   8%|▊         | 81/1024 [00:00<00:02, 419.13it/s]
Adding requests:  13%|█▎        | 130/1024 [00:00<00:01, 451.00it/s]
Adding requests:  17%|█▋        | 178/1024 [00:00<00:01, 458.71it/s]
Adding requests:  22%|██▏       | 228/1024 [00:00<00:01, 472.92it/s]
Adding requests:  27%|██▋       | 277/1024 [00:00<00:01, 478.19it/s]
Adding requests:  32%|███▏      | 325/1024 [00:00<00:01, 478.65it/s]
Adding requests:  37%|███▋      | 375/1024 [00:00<00:01, 484.03it/s]
Adding requests:  42%|████▏     | 425/1024 [00:00<00:01, 487.67it/s]
Adding requests:  46%|████▋     | 474/1024 [00:01<00:01, 486.12it/s]
Adding requests:  51%|█████     | 523/1024 [00:01<00:01, 471.65it/s]
Adding requests:  56%|█████▌    | 573/1024 [00:01<00:00, 478.99it/s]
Adding requests:  61%|██████    | 623/1024 [00:01<00:00, 483.04it/s]
Adding requests:  66%|██████▌   | 673/1024 [00:01<00:00, 485.84it/s]
Adding requests:  71%|███████   | 724/1024 [00:01<00:00, 490.46it/s]
Adding requests:  76%|███████▌  | 774/1024 [00:01<00:00, 487.03it/s]
Adding requests:  80%|████████  | 823/1024 [00:01<00:00, 479.32it/s]
Adding requests:  85%|████████▌ | 873/1024 [00:01<00:00, 483.17it/s]
Adding requests:  90%|█████████ | 924/1024 [00:01<00:00, 488.32it/s]
Adding requests:  95%|█████████▌| 974/1024 [00:02<00:00, 490.23it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 478.60it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:00<00:00, 2957.08it/s, est. speed input: 3028640.04 toks/s, output: 2957.24 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:01<00:01, 263.05it/s, est. speed input: 312172.79 toks/s, output: 304.85 toks/s]   
Processed prompts:  71%|███████   | 726/1024 [00:02<00:01, 236.17it/s, est. speed input: 279454.39 toks/s, output: 272.90 toks/s]
Processed prompts:  79%|███████▊  | 806/1024 [00:03<00:00, 223.15it/s, est. speed input: 266011.52 toks/s, output: 259.78 toks/s]
Processed prompts:  84%|████████▍ | 862/1024 [00:03<00:00, 214.97it/s, est. speed input: 258607.35 toks/s, output: 252.55 toks/s]
Processed prompts:  88%|████████▊ | 904/1024 [00:03<00:00, 210.75it/s, est. speed input: 254635.89 toks/s, output: 248.67 toks/s]
Processed prompts:  92%|█████████▏| 939/1024 [00:03<00:00, 201.33it/s, est. speed input: 249504.42 toks/s, output: 243.66 toks/s]
Processed prompts:  95%|█████████▍| 968/1024 [00:03<00:00, 203.67it/s, est. speed input: 248632.82 toks/s, output: 242.80 toks/s]
Processed prompts:  97%|█████████▋| 995/1024 [00:04<00:00, 193.86it/s, est. speed input: 244937.95 toks/s, output: 239.20 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:04<00:00, 191.11it/s, est. speed input: 243073.41 toks/s, output: 237.37 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 191.11it/s, est. speed input: 244485.68 toks/s, output: 238.75 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 238.75it/s, est. speed input: 244485.68 toks/s, output: 238.75 toks/s]
[rank0]:[W126 08:56:46.793204648 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:56:48
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:57:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1098405) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1098405) WARNING 01-26 08:57:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 180.12 requests/s, 184624.46 total tokens/s, 180.12 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:57:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:57:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:57:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:57:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:57:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:57:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:57:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:57:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:57:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:57:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:57:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:57:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:57:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:57:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:57:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:57:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:57:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1098405) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1098405) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.95it/s]
(EngineCore_DP0 pid=1098405) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.95it/s]
(EngineCore_DP0 pid=1098405) 
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1098405) [2026-01-26 08:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1098405) 2026-01-26 08:57:24,485 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1098405) 2026-01-26 08:57:24,517 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1098405) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 13.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 17.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 11.83it/s]
(EngineCore_DP0 pid=1098405) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:01,  2.81it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  5.67it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  6.02it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 33/2048 [00:00<00:06, 327.59it/s]
Adding requests:   4%|▍         | 84/2048 [00:00<00:04, 430.97it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:04, 457.70it/s]
Adding requests:   9%|▉         | 181/2048 [00:00<00:04, 463.07it/s]
Adding requests:  11%|█▏        | 232/2048 [00:00<00:03, 477.73it/s]
Adding requests:  14%|█▎        | 280/2048 [00:00<00:03, 472.41it/s]
Adding requests:  16%|█▌        | 328/2048 [00:00<00:03, 473.94it/s]
Adding requests:  18%|█▊        | 378/2048 [00:00<00:03, 481.55it/s]
Adding requests:  21%|██        | 428/2048 [00:00<00:03, 487.22it/s]
Adding requests:  23%|██▎       | 478/2048 [00:01<00:03, 488.31it/s]
Adding requests:  26%|██▌       | 527/2048 [00:01<00:03, 477.28it/s]
Adding requests:  28%|██▊       | 578/2048 [00:01<00:03, 486.84it/s]
Adding requests:  31%|███       | 629/2048 [00:01<00:02, 493.38it/s]
Adding requests:  33%|███▎      | 681/2048 [00:01<00:02, 498.91it/s]
Adding requests:  36%|███▌      | 731/2048 [00:01<00:02, 497.51it/s]
Adding requests:  38%|███▊      | 781/2048 [00:01<00:02, 492.42it/s]
Adding requests:  41%|████      | 831/2048 [00:01<00:02, 483.97it/s]
Adding requests:  43%|████▎     | 882/2048 [00:01<00:02, 489.94it/s]
Adding requests:  46%|████▌     | 933/2048 [00:01<00:02, 494.94it/s]
Adding requests:  48%|████▊     | 983/2048 [00:02<00:02, 496.12it/s]
Adding requests:  50%|█████     | 1034/2048 [00:02<00:02, 498.88it/s]
Adding requests:  53%|█████▎    | 1084/2048 [00:02<00:01, 497.75it/s]
Adding requests:  55%|█████▌    | 1134/2048 [00:02<00:01, 493.27it/s]
Adding requests:  58%|█████▊    | 1188/2048 [00:02<00:01, 504.71it/s]
Adding requests:  61%|██████    | 1240/2048 [00:02<00:01, 506.60it/s]
Adding requests:  63%|██████▎   | 1291/2048 [00:02<00:01, 503.14it/s]
Adding requests:  66%|██████▌   | 1343/2048 [00:02<00:01, 506.65it/s]
Adding requests:  68%|██████▊   | 1394/2048 [00:02<00:01, 507.48it/s]
Adding requests:  71%|███████   | 1445/2048 [00:02<00:01, 505.46it/s]
Adding requests:  73%|███████▎  | 1497/2048 [00:03<00:01, 508.83it/s]
Adding requests:  76%|███████▌  | 1549/2048 [00:03<00:00, 509.36it/s]
Adding requests:  78%|███████▊  | 1602/2048 [00:03<00:00, 513.90it/s]
Adding requests:  81%|████████  | 1654/2048 [00:03<00:00, 511.13it/s]
Adding requests:  83%|████████▎ | 1706/2048 [00:03<00:00, 506.98it/s]
Adding requests:  86%|████████▌ | 1757/2048 [00:03<00:00, 507.29it/s]
Adding requests:  88%|████████▊ | 1808/2048 [00:03<00:00, 506.68it/s]
Adding requests:  91%|█████████ | 1859/2048 [00:03<00:00, 497.84it/s]
Adding requests:  93%|█████████▎| 1909/2048 [00:03<00:00, 495.66it/s]
Adding requests:  96%|█████████▌| 1961/2048 [00:03<00:00, 500.97it/s]
Adding requests:  98%|█████████▊| 2013/2048 [00:04<00:00, 505.71it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 494.29it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:00<00:00, 4404.14it/s, est. speed input: 4511037.02 toks/s, output: 4404.45 toks/s]
Processed prompts:  56%|█████▌    | 1147/2048 [00:02<00:02, 387.10it/s, est. speed input: 476675.70 toks/s, output: 465.50 toks/s]  
Processed prompts:  65%|██████▌   | 1340/2048 [00:03<00:02, 313.17it/s, est. speed input: 394355.40 toks/s, output: 385.11 toks/s]
Processed prompts:  71%|███████   | 1454/2048 [00:04<00:02, 283.56it/s, est. speed input: 364979.99 toks/s, output: 356.42 toks/s]
Processed prompts:  75%|███████▍  | 1531/2048 [00:04<00:01, 262.95it/s, est. speed input: 347685.70 toks/s, output: 339.54 toks/s]
Processed prompts:  77%|███████▋  | 1587/2048 [00:04<00:01, 245.16it/s, est. speed input: 335206.50 toks/s, output: 327.35 toks/s]
Processed prompts:  80%|███████▉  | 1629/2048 [00:05<00:01, 245.10it/s, est. speed input: 332308.70 toks/s, output: 324.52 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:05<00:01, 225.86it/s, est. speed input: 323627.10 toks/s, output: 316.04 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:05<00:01, 219.42it/s, est. speed input: 319408.84 toks/s, output: 311.92 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:05<00:01, 213.39it/s, est. speed input: 315508.14 toks/s, output: 308.11 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:05<00:01, 207.71it/s, est. speed input: 311808.46 toks/s, output: 304.50 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:05<00:01, 202.68it/s, est. speed input: 308303.86 toks/s, output: 301.08 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:06<00:01, 198.66it/s, est. speed input: 305017.83 toks/s, output: 297.87 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:06<00:00, 195.36it/s, est. speed input: 301894.54 toks/s, output: 294.82 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:06<00:00, 194.43it/s, est. speed input: 299177.14 toks/s, output: 292.16 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:06<00:00, 192.15it/s, est. speed input: 296372.53 toks/s, output: 289.42 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:06<00:00, 191.88it/s, est. speed input: 293900.21 toks/s, output: 287.01 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:06<00:00, 191.62it/s, est. speed input: 291537.58 toks/s, output: 284.70 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:07<00:00, 191.50it/s, est. speed input: 289294.53 toks/s, output: 282.51 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:07<00:00, 191.50it/s, est. speed input: 290299.78 toks/s, output: 283.50 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:07<00:00, 283.49it/s, est. speed input: 290299.78 toks/s, output: 283.50 toks/s]
[rank0]:[W126 08:57:39.233043343 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:57:41
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:58:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1099736) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1099736) WARNING 01-26 08:58:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 188.96 requests/s, 193686.02 total tokens/s, 188.96 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:58:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:58:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:58:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:58:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:58:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:58:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:58:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:58:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:58:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:58:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:58:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:58:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:58:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:58:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:58:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:58:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:58:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1099736) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1099736) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.93it/s]
(EngineCore_DP0 pid=1099736) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.92it/s]
(EngineCore_DP0 pid=1099736) 
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1099736) [2026-01-26 08:58:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1099736) [rank0]:W0126 08:58:22.774000 1099736 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1099736) [rank0]:W0126 08:58:22.828000 1099736 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1099736) [rank0]:W0126 08:58:23.466000 1099736 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1099736) [rank0]:W0126 08:58:23.542000 1099736 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1099736) 2026-01-26 08:58:26,445 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1099736) 2026-01-26 08:58:26,478 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1099736) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 13.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 16.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00, 10.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  5.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  6.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.22it/s]
(EngineCore_DP0 pid=1099736) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:01,  5.94it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 12.00it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 16.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 14.85it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 40/4096 [00:00<00:10, 399.94it/s]
Adding requests:   2%|▏         | 90/4096 [00:00<00:08, 458.17it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:08, 472.05it/s]
Adding requests:   5%|▍         | 188/4096 [00:00<00:08, 474.46it/s]
Adding requests:   6%|▌         | 239/4096 [00:00<00:07, 483.97it/s]
Adding requests:   7%|▋         | 288/4096 [00:00<00:07, 485.13it/s]
Adding requests:   8%|▊         | 337/4096 [00:00<00:07, 484.27it/s]
Adding requests:   9%|▉         | 387/4096 [00:00<00:07, 488.57it/s]
Adding requests:  11%|█         | 437/4096 [00:00<00:07, 489.96it/s]
Adding requests:  12%|█▏        | 487/4096 [00:01<00:07, 491.97it/s]
Adding requests:  13%|█▎        | 537/4096 [00:01<00:07, 480.31it/s]
Adding requests:  14%|█▍        | 588/4096 [00:01<00:07, 488.95it/s]
Adding requests:  16%|█▌        | 638/4096 [00:01<00:07, 490.73it/s]
Adding requests:  17%|█▋        | 689/4096 [00:01<00:06, 495.89it/s]
Adding requests:  18%|█▊        | 740/4096 [00:01<00:06, 497.75it/s]
Adding requests:  19%|█▉        | 790/4096 [00:01<00:06, 493.23it/s]
Adding requests:  21%|██        | 840/4096 [00:01<00:06, 485.16it/s]
Adding requests:  22%|██▏       | 892/4096 [00:01<00:06, 494.52it/s]
Adding requests:  23%|██▎       | 943/4096 [00:01<00:06, 496.67it/s]
Adding requests:  24%|██▍       | 994/4096 [00:02<00:06, 498.71it/s]
Adding requests:  26%|██▌       | 1045/4096 [00:02<00:06, 501.61it/s]
Adding requests:  27%|██▋       | 1096/4096 [00:02<00:06, 485.85it/s]
Adding requests:  28%|██▊       | 1146/4096 [00:02<00:06, 487.61it/s]
Adding requests:  29%|██▉       | 1199/4096 [00:02<00:05, 499.13it/s]
Adding requests:  31%|███       | 1250/4096 [00:02<00:05, 501.81it/s]
Adding requests:  32%|███▏      | 1301/4096 [00:02<00:05, 500.07it/s]
Adding requests:  33%|███▎      | 1353/4096 [00:02<00:05, 503.87it/s]
Adding requests:  34%|███▍      | 1406/4096 [00:02<00:05, 510.00it/s]
Adding requests:  36%|███▌      | 1458/4096 [00:02<00:05, 507.94it/s]
Adding requests:  37%|███▋      | 1511/4096 [00:03<00:05, 513.56it/s]
Adding requests:  38%|███▊      | 1563/4096 [00:03<00:04, 512.26it/s]
Adding requests:  39%|███▉      | 1615/4096 [00:03<00:04, 513.27it/s]
Adding requests:  41%|████      | 1667/4096 [00:03<00:04, 511.30it/s]
Adding requests:  42%|████▏     | 1719/4096 [00:03<00:04, 511.17it/s]
Adding requests:  43%|████▎     | 1771/4096 [00:03<00:04, 509.96it/s]
Adding requests:  45%|████▍     | 1823/4096 [00:03<00:04, 510.99it/s]
Adding requests:  46%|████▌     | 1875/4096 [00:03<00:04, 508.38it/s]
Adding requests:  47%|████▋     | 1926/4096 [00:03<00:04, 507.10it/s]
Adding requests:  48%|████▊     | 1977/4096 [00:03<00:04, 505.60it/s]
Adding requests:  50%|████▉     | 2029/4096 [00:04<00:04, 508.17it/s]
Adding requests:  51%|█████     | 2082/4096 [00:04<00:03, 512.42it/s]
Adding requests:  52%|█████▏    | 2134/4096 [00:04<00:03, 505.84it/s]
Adding requests:  53%|█████▎    | 2185/4096 [00:04<00:03, 500.41it/s]
Adding requests:  55%|█████▍    | 2236/4096 [00:04<00:03, 487.51it/s]
Adding requests:  56%|█████▌    | 2286/4096 [00:04<00:03, 489.95it/s]
Adding requests:  57%|█████▋    | 2337/4096 [00:04<00:03, 495.18it/s]
Adding requests:  58%|█████▊    | 2389/4096 [00:04<00:03, 500.83it/s]
Adding requests:  60%|█████▉    | 2440/4096 [00:04<00:03, 502.46it/s]
Adding requests:  61%|██████    | 2492/4096 [00:05<00:03, 505.38it/s]
Adding requests:  62%|██████▏   | 2543/4096 [00:05<00:03, 502.49it/s]
Adding requests:  63%|██████▎   | 2595/4096 [00:05<00:02, 507.55it/s]
Adding requests:  65%|██████▍   | 2647/4096 [00:05<00:02, 508.94it/s]
Adding requests:  66%|██████▌   | 2698/4096 [00:05<00:02, 506.98it/s]
Adding requests:  67%|██████▋   | 2749/4096 [00:05<00:02, 503.31it/s]
Adding requests:  68%|██████▊   | 2800/4096 [00:05<00:02, 501.90it/s]
Adding requests:  70%|██████▉   | 2851/4096 [00:05<00:02, 504.22it/s]
Adding requests:  71%|███████   | 2903/4096 [00:05<00:02, 507.22it/s]
Adding requests:  72%|███████▏  | 2954/4096 [00:05<00:02, 504.68it/s]
Adding requests:  73%|███████▎  | 3005/4096 [00:06<00:02, 504.91it/s]
Adding requests:  75%|███████▍  | 3057/4096 [00:06<00:02, 507.36it/s]
Adding requests:  76%|███████▌  | 3108/4096 [00:06<00:01, 504.07it/s]
Adding requests:  77%|███████▋  | 3159/4096 [00:06<00:01, 505.76it/s]
Adding requests:  78%|███████▊  | 3210/4096 [00:06<00:01, 505.31it/s]
Adding requests:  80%|███████▉  | 3263/4096 [00:06<00:01, 510.70it/s]
Adding requests:  81%|████████  | 3315/4096 [00:06<00:01, 510.48it/s]
Adding requests:  82%|████████▏ | 3368/4096 [00:06<00:01, 513.36it/s]
Adding requests:  83%|████████▎ | 3420/4096 [00:06<00:01, 513.21it/s]
Adding requests:  85%|████████▍ | 3472/4096 [00:06<00:01, 503.46it/s]
Adding requests:  86%|████████▌ | 3523/4096 [00:07<00:01, 487.21it/s]
Adding requests:  87%|████████▋ | 3574/4096 [00:07<00:01, 491.77it/s]
Adding requests:  88%|████████▊ | 3624/4096 [00:07<00:00, 492.82it/s]
Adding requests:  90%|████████▉ | 3676/4096 [00:07<00:00, 497.90it/s]
Adding requests:  91%|█████████ | 3727/4096 [00:07<00:00, 500.48it/s]
Adding requests:  92%|█████████▏| 3780/4096 [00:07<00:00, 508.06it/s]
Adding requests:  94%|█████████▎| 3831/4096 [00:07<00:00, 508.06it/s]
Adding requests:  95%|█████████▍| 3883/4096 [00:07<00:00, 511.13it/s]
Adding requests:  96%|█████████▌| 3935/4096 [00:07<00:00, 507.40it/s]
Adding requests:  97%|█████████▋| 3986/4096 [00:07<00:00, 506.46it/s]
Adding requests:  99%|█████████▊| 4037/4096 [00:08<00:00, 504.61it/s]
Adding requests: 100%|█████████▉| 4088/4096 [00:08<00:00, 505.04it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 500.41it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  37%|███▋      | 1503/4096 [00:00<00:00, 13000.06it/s, est. speed input: 13314775.12 toks/s, output: 13000.89 toks/s]
Processed prompts:  68%|██████▊   | 2804/4096 [00:06<00:03, 350.00it/s, est. speed input: 424888.63 toks/s, output: 414.93 toks/s]      
Processed prompts:  82%|████████▏ | 3351/4096 [00:09<00:02, 291.09it/s, est. speed input: 357839.16 toks/s, output: 349.45 toks/s]
Processed prompts:  89%|████████▉ | 3657/4096 [00:11<00:01, 265.28it/s, est. speed input: 332687.41 toks/s, output: 324.89 toks/s]
Processed prompts:  94%|█████████▍| 3850/4096 [00:12<00:00, 252.94it/s, est. speed input: 321664.49 toks/s, output: 314.13 toks/s]
Processed prompts:  97%|█████████▋| 3980/4096 [00:12<00:00, 244.35it/s, est. speed input: 315137.61 toks/s, output: 307.75 toks/s]
Processed prompts:  99%|█████████▉| 4073/4096 [00:13<00:00, 237.53it/s, est. speed input: 310785.58 toks/s, output: 303.50 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:13<00:00, 237.53it/s, est. speed input: 310966.40 toks/s, output: 303.68 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:13<00:00, 303.67it/s, est. speed input: 310966.40 toks/s, output: 303.68 toks/s]
[rank0]:[W126 08:58:51.908835901 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:58:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:59:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1101489) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1101489) WARNING 01-26 08:59:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 193.21 requests/s, 198042.08 total tokens/s, 193.21 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:59:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:59:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:59:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:59:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:59:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:59:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:59:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:59:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:59:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:59:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:59:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:59:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:59:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:59:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:59:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:59:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:59:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1101489) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1101489) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.98it/s]
(EngineCore_DP0 pid=1101489) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.98it/s]
(EngineCore_DP0 pid=1101489) 
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5283840 bytes
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3522560 bytes
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28180480 bytes
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1101489) [2026-01-26 08:59:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14008320 bytes
(EngineCore_DP0 pid=1101489) [rank0]:W0126 08:59:51.926000 1101489 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1101489) [rank0]:W0126 08:59:51.980000 1101489 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1101489) [rank0]:W0126 08:59:52.826000 1101489 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1101489) [rank0]:W0126 08:59:52.903000 1101489 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1101489) 2026-01-26 08:59:55,653 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1101489) 2026-01-26 08:59:55,764 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1101489) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:09,  1.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:03,  4.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:02,  5.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:01,  8.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:00, 11.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00, 10.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00, 12.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00, 10.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00,  6.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:02<00:00,  6.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  7.61it/s]
(EngineCore_DP0 pid=1101489) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 19.16it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 19.70it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 19.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 20.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 19.90it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 48/8192 [00:00<00:17, 477.20it/s]
Adding requests:   1%|          | 97/8192 [00:00<00:16, 484.56it/s]
Adding requests:   2%|▏         | 146/8192 [00:00<00:16, 485.88it/s]
Adding requests:   2%|▏         | 195/8192 [00:00<00:16, 481.93it/s]
Adding requests:   3%|▎         | 245/8192 [00:00<00:16, 488.38it/s]
Adding requests:   4%|▎         | 295/8192 [00:00<00:16, 489.15it/s]
Adding requests:   4%|▍         | 344/8192 [00:00<00:16, 487.39it/s]
Adding requests:   5%|▍         | 395/8192 [00:00<00:15, 491.52it/s]
Adding requests:   5%|▌         | 445/8192 [00:00<00:15, 489.14it/s]
Adding requests:   6%|▌         | 495/8192 [00:01<00:15, 490.00it/s]
Adding requests:   7%|▋         | 545/8192 [00:01<00:15, 483.40it/s]
Adding requests:   7%|▋         | 595/8192 [00:01<00:15, 485.45it/s]
Adding requests:   8%|▊         | 646/8192 [00:01<00:15, 489.73it/s]
Adding requests:   9%|▊         | 698/8192 [00:01<00:15, 497.86it/s]
Adding requests:   9%|▉         | 748/8192 [00:01<00:14, 496.72it/s]
Adding requests:  10%|▉         | 798/8192 [00:01<00:14, 494.40it/s]
Adding requests:  10%|█         | 848/8192 [00:01<00:15, 487.77it/s]
Adding requests:  11%|█         | 900/8192 [00:01<00:14, 495.29it/s]
Adding requests:  12%|█▏        | 951/8192 [00:01<00:14, 497.91it/s]
Adding requests:  12%|█▏        | 1002/8192 [00:02<00:14, 500.47it/s]
Adding requests:  13%|█▎        | 1053/8192 [00:02<00:14, 501.87it/s]
Adding requests:  13%|█▎        | 1104/8192 [00:02<00:14, 497.28it/s]
Adding requests:  14%|█▍        | 1154/8192 [00:02<00:14, 495.99it/s]
Adding requests:  15%|█▍        | 1208/8192 [00:02<00:13, 506.63it/s]
Adding requests:  15%|█▌        | 1259/8192 [00:02<00:13, 499.82it/s]
Adding requests:  16%|█▌        | 1310/8192 [00:02<00:13, 501.15it/s]
Adding requests:  17%|█▋        | 1361/8192 [00:02<00:13, 503.44it/s]
Adding requests:  17%|█▋        | 1414/8192 [00:02<00:13, 508.23it/s]
Adding requests:  18%|█▊        | 1465/8192 [00:02<00:13, 506.76it/s]
Adding requests:  19%|█▊        | 1516/8192 [00:03<00:13, 507.50it/s]
Adding requests:  19%|█▉        | 1567/8192 [00:03<00:13, 506.36it/s]
Adding requests:  20%|█▉        | 1619/8192 [00:03<00:12, 509.32it/s]
Adding requests:  20%|██        | 1670/8192 [00:03<00:12, 506.21it/s]
Adding requests:  21%|██        | 1721/8192 [00:03<00:13, 495.69it/s]
Adding requests:  22%|██▏       | 1771/8192 [00:03<00:13, 493.51it/s]
Adding requests:  22%|██▏       | 1822/8192 [00:03<00:12, 497.84it/s]
Adding requests:  23%|██▎       | 1872/8192 [00:03<00:12, 498.10it/s]
Adding requests:  23%|██▎       | 1923/8192 [00:03<00:12, 500.62it/s]
Adding requests:  24%|██▍       | 1974/8192 [00:03<00:12, 499.86it/s]
Adding requests:  25%|██▍       | 2026/8192 [00:04<00:12, 502.70it/s]
Adding requests:  25%|██▌       | 2078/8192 [00:04<00:12, 506.77it/s]
Adding requests:  26%|██▌       | 2129/8192 [00:04<00:12, 500.33it/s]
Adding requests:  27%|██▋       | 2180/8192 [00:04<00:12, 496.87it/s]
Adding requests:  27%|██▋       | 2231/8192 [00:04<00:11, 500.52it/s]
Adding requests:  28%|██▊       | 2282/8192 [00:04<00:11, 501.10it/s]
Adding requests:  28%|██▊       | 2333/8192 [00:04<00:11, 501.68it/s]
Adding requests:  29%|██▉       | 2384/8192 [00:04<00:11, 502.10it/s]
Adding requests:  30%|██▉       | 2435/8192 [00:04<00:11, 502.06it/s]
Adding requests:  30%|███       | 2486/8192 [00:04<00:11, 502.08it/s]
Adding requests:  31%|███       | 2537/8192 [00:05<00:11, 502.69it/s]
Adding requests:  32%|███▏      | 2589/8192 [00:05<00:11, 505.83it/s]
Adding requests:  32%|███▏      | 2640/8192 [00:05<00:10, 505.21it/s]
Adding requests:  33%|███▎      | 2691/8192 [00:05<00:10, 504.11it/s]
Adding requests:  33%|███▎      | 2742/8192 [00:05<00:10, 504.38it/s]
Adding requests:  34%|███▍      | 2793/8192 [00:05<00:10, 501.50it/s]
Adding requests:  35%|███▍      | 2844/8192 [00:05<00:10, 503.94it/s]
Adding requests:  35%|███▌      | 2895/8192 [00:05<00:10, 505.45it/s]
Adding requests:  36%|███▌      | 2946/8192 [00:05<00:10, 499.93it/s]
Adding requests:  37%|███▋      | 2997/8192 [00:06<00:10, 483.62it/s]
Adding requests:  37%|███▋      | 3047/8192 [00:06<00:10, 487.80it/s]
Adding requests:  38%|███▊      | 3097/8192 [00:06<00:10, 489.10it/s]
Adding requests:  38%|███▊      | 3147/8192 [00:06<00:10, 491.37it/s]
Adding requests:  39%|███▉      | 3198/8192 [00:06<00:10, 494.72it/s]
Adding requests:  40%|███▉      | 3250/8192 [00:06<00:09, 500.65it/s]
Adding requests:  40%|████      | 3301/8192 [00:06<00:09, 500.69it/s]
Adding requests:  41%|████      | 3353/8192 [00:06<00:09, 506.05it/s]
Adding requests:  42%|████▏     | 3404/8192 [00:06<00:09, 505.37it/s]
Adding requests:  42%|████▏     | 3455/8192 [00:06<00:09, 504.43it/s]
Adding requests:  43%|████▎     | 3506/8192 [00:07<00:09, 500.42it/s]
Adding requests:  43%|████▎     | 3558/8192 [00:07<00:09, 503.51it/s]
Adding requests:  44%|████▍     | 3609/8192 [00:07<00:09, 502.89it/s]
Adding requests:  45%|████▍     | 3660/8192 [00:07<00:09, 499.66it/s]
Adding requests:  45%|████▌     | 3712/8192 [00:07<00:08, 505.45it/s]
Adding requests:  46%|████▌     | 3763/8192 [00:07<00:08, 502.67it/s]
Adding requests:  47%|████▋     | 3816/8192 [00:07<00:08, 507.66it/s]
Adding requests:  47%|████▋     | 3869/8192 [00:07<00:08, 511.59it/s]
Adding requests:  48%|████▊     | 3921/8192 [00:07<00:08, 509.82it/s]
Adding requests:  48%|████▊     | 3972/8192 [00:07<00:08, 508.04it/s]
Adding requests:  49%|████▉     | 4024/8192 [00:08<00:08, 507.06it/s]
Adding requests:  50%|████▉     | 4075/8192 [00:08<00:08, 501.43it/s]
Adding requests:  50%|█████     | 4127/8192 [00:08<00:08, 506.62it/s]
Adding requests:  51%|█████     | 4178/8192 [00:08<00:07, 507.09it/s]
Adding requests:  52%|█████▏    | 4230/8192 [00:08<00:07, 507.98it/s]
Adding requests:  52%|█████▏    | 4281/8192 [00:08<00:07, 490.59it/s]
Adding requests:  53%|█████▎    | 4333/8192 [00:08<00:07, 497.75it/s]
Adding requests:  54%|█████▎    | 4385/8192 [00:08<00:07, 503.50it/s]
Adding requests:  54%|█████▍    | 4436/8192 [00:08<00:07, 504.67it/s]
Adding requests:  55%|█████▍    | 4487/8192 [00:08<00:07, 502.85it/s]
Adding requests:  55%|█████▌    | 4538/8192 [00:09<00:07, 501.30it/s]
Adding requests:  56%|█████▌    | 4589/8192 [00:09<00:07, 503.85it/s]
Adding requests:  57%|█████▋    | 4641/8192 [00:09<00:06, 508.52it/s]
Adding requests:  57%|█████▋    | 4692/8192 [00:09<00:06, 503.05it/s]
Adding requests:  58%|█████▊    | 4744/8192 [00:09<00:06, 506.47it/s]
Adding requests:  59%|█████▊    | 4795/8192 [00:09<00:06, 504.70it/s]
Adding requests:  59%|█████▉    | 4846/8192 [00:09<00:06, 504.07it/s]
Adding requests:  60%|█████▉    | 4897/8192 [00:09<00:06, 497.43it/s]
Adding requests:  60%|██████    | 4949/8192 [00:09<00:06, 501.05it/s]
Adding requests:  61%|██████    | 5000/8192 [00:10<00:06, 501.62it/s]
Adding requests:  62%|██████▏   | 5051/8192 [00:10<00:06, 503.98it/s]
Adding requests:  62%|██████▏   | 5104/8192 [00:10<00:06, 509.71it/s]
Adding requests:  63%|██████▎   | 5155/8192 [00:10<00:05, 508.98it/s]
Adding requests:  64%|██████▎   | 5206/8192 [00:10<00:05, 508.79it/s]
Adding requests:  64%|██████▍   | 5257/8192 [00:10<00:05, 502.32it/s]
Adding requests:  65%|██████▍   | 5309/8192 [00:10<00:05, 507.54it/s]
Adding requests:  65%|██████▌   | 5361/8192 [00:10<00:05, 509.41it/s]
Adding requests:  66%|██████▌   | 5413/8192 [00:10<00:05, 510.07it/s]
Adding requests:  67%|██████▋   | 5465/8192 [00:10<00:05, 506.49it/s]
Adding requests:  67%|██████▋   | 5516/8192 [00:11<00:05, 502.17it/s]
Adding requests:  68%|██████▊   | 5567/8192 [00:11<00:05, 489.84it/s]
Adding requests:  69%|██████▊   | 5617/8192 [00:11<00:05, 488.99it/s]
Adding requests:  69%|██████▉   | 5666/8192 [00:11<00:05, 488.47it/s]
Adding requests:  70%|██████▉   | 5718/8192 [00:11<00:04, 496.28it/s]
Adding requests:  70%|███████   | 5770/8192 [00:11<00:04, 503.03it/s]
Adding requests:  71%|███████   | 5821/8192 [00:11<00:04, 497.35it/s]
Adding requests:  72%|███████▏  | 5873/8192 [00:11<00:04, 502.07it/s]
Adding requests:  72%|███████▏  | 5925/8192 [00:11<00:04, 505.14it/s]
Adding requests:  73%|███████▎  | 5976/8192 [00:11<00:04, 505.80it/s]
Adding requests:  74%|███████▎  | 6028/8192 [00:12<00:04, 509.16it/s]
Adding requests:  74%|███████▍  | 6080/8192 [00:12<00:04, 510.37it/s]
Adding requests:  75%|███████▍  | 6132/8192 [00:12<00:04, 508.72it/s]
Adding requests:  75%|███████▌  | 6184/8192 [00:12<00:03, 510.17it/s]
Adding requests:  76%|███████▌  | 6237/8192 [00:12<00:03, 515.68it/s]
Adding requests:  77%|███████▋  | 6290/8192 [00:12<00:03, 517.81it/s]
Adding requests:  77%|███████▋  | 6343/8192 [00:12<00:03, 518.61it/s]
Adding requests:  78%|███████▊  | 6396/8192 [00:12<00:03, 519.88it/s]
Adding requests:  79%|███████▊  | 6449/8192 [00:12<00:03, 522.13it/s]
Adding requests:  79%|███████▉  | 6502/8192 [00:12<00:03, 522.24it/s]
Adding requests:  80%|████████  | 6555/8192 [00:13<00:03, 522.34it/s]
Adding requests:  81%|████████  | 6608/8192 [00:13<00:03, 517.53it/s]
Adding requests:  81%|████████▏ | 6661/8192 [00:13<00:02, 518.14it/s]
Adding requests:  82%|████████▏ | 6713/8192 [00:13<00:02, 512.98it/s]
Adding requests:  83%|████████▎ | 6765/8192 [00:13<00:02, 511.87it/s]
Adding requests:  83%|████████▎ | 6818/8192 [00:13<00:02, 515.39it/s]
Adding requests:  84%|████████▍ | 6870/8192 [00:13<00:02, 508.11it/s]
Adding requests:  84%|████████▍ | 6921/8192 [00:13<00:02, 502.31it/s]
Adding requests:  85%|████████▌ | 6975/8192 [00:13<00:02, 511.05it/s]
Adding requests:  86%|████████▌ | 7027/8192 [00:13<00:02, 505.11it/s]
Adding requests:  86%|████████▋ | 7078/8192 [00:14<00:02, 505.77it/s]
Adding requests:  87%|████████▋ | 7131/8192 [00:14<00:02, 510.08it/s]
Adding requests:  88%|████████▊ | 7183/8192 [00:14<00:01, 505.97it/s]
Adding requests:  88%|████████▊ | 7234/8192 [00:14<00:01, 507.12it/s]
Adding requests:  89%|████████▉ | 7287/8192 [00:14<00:01, 513.09it/s]
Adding requests:  90%|████████▉ | 7339/8192 [00:14<00:01, 511.66it/s]
Adding requests:  90%|█████████ | 7391/8192 [00:14<00:01, 511.45it/s]
Adding requests:  91%|█████████ | 7445/8192 [00:14<00:01, 519.68it/s]
Adding requests:  92%|█████████▏| 7497/8192 [00:14<00:01, 518.67it/s]
Adding requests:  92%|█████████▏| 7549/8192 [00:15<00:01, 516.93it/s]
Adding requests:  93%|█████████▎| 7601/8192 [00:15<00:01, 513.93it/s]
Adding requests:  93%|█████████▎| 7654/8192 [00:15<00:01, 516.87it/s]
Adding requests:  94%|█████████▍| 7706/8192 [00:15<00:00, 517.41it/s]
Adding requests:  95%|█████████▍| 7758/8192 [00:15<00:00, 512.00it/s]
Adding requests:  95%|█████████▌| 7810/8192 [00:15<00:00, 510.09it/s]
Adding requests:  96%|█████████▌| 7863/8192 [00:15<00:00, 513.27it/s]
Adding requests:  97%|█████████▋| 7915/8192 [00:15<00:00, 508.15it/s]
Adding requests:  97%|█████████▋| 7966/8192 [00:15<00:00, 508.14it/s]
Adding requests:  98%|█████████▊| 8017/8192 [00:15<00:00, 505.48it/s]
Adding requests:  98%|█████████▊| 8069/8192 [00:16<00:00, 507.48it/s]
Adding requests:  99%|█████████▉| 8122/8192 [00:16<00:00, 512.30it/s]
Adding requests: 100%|█████████▉| 8174/8192 [00:16<00:00, 513.03it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 503.48it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  38%|███▊      | 3111/8192 [00:00<00:00, 9581.54it/s, est. speed input: 9812227.10 toks/s, output: 9581.75 toks/s]
Processed prompts:  50%|████▉     | 4070/8192 [00:04<00:06, 650.16it/s, est. speed input: 846759.55 toks/s, output: 826.91 toks/s]   
Processed prompts:  55%|█████▍    | 4477/8192 [00:07<00:08, 458.30it/s, est. speed input: 634637.20 toks/s, output: 619.76 toks/s]
Processed prompts:  57%|█████▋    | 4707/8192 [00:08<00:08, 413.13it/s, est. speed input: 586719.61 toks/s, output: 572.97 toks/s]
Processed prompts:  59%|█████▉    | 4855/8192 [00:09<00:09, 354.96it/s, est. speed input: 540272.72 toks/s, output: 527.61 toks/s]
Processed prompts:  60%|██████    | 4955/8192 [00:09<00:09, 349.62it/s, est. speed input: 532105.56 toks/s, output: 519.63 toks/s]
Processed prompts:  61%|██████▏   | 5032/8192 [00:10<00:10, 300.04it/s, est. speed input: 505558.44 toks/s, output: 493.71 toks/s]
Processed prompts:  62%|██████▏   | 5095/8192 [00:10<00:10, 285.60it/s, est. speed input: 495860.15 toks/s, output: 484.24 toks/s]
Processed prompts:  63%|██████▎   | 5159/8192 [00:10<00:11, 270.88it/s, est. speed input: 486786.90 toks/s, output: 475.38 toks/s]
Processed prompts:  64%|██████▍   | 5223/8192 [00:11<00:11, 258.37it/s, est. speed input: 478802.96 toks/s, output: 467.58 toks/s]
Processed prompts:  65%|██████▍   | 5287/8192 [00:11<00:11, 246.18it/s, est. speed input: 471122.88 toks/s, output: 460.08 toks/s]
Processed prompts:  65%|██████▌   | 5351/8192 [00:11<00:12, 233.52it/s, est. speed input: 463391.00 toks/s, output: 452.53 toks/s]
Processed prompts:  66%|██████▌   | 5415/8192 [00:12<00:12, 224.15it/s, est. speed input: 456308.19 toks/s, output: 445.61 toks/s]
Processed prompts:  67%|██████▋   | 5479/8192 [00:12<00:12, 216.47it/s, est. speed input: 449546.94 toks/s, output: 439.01 toks/s]
Processed prompts:  68%|██████▊   | 5543/8192 [00:12<00:12, 209.99it/s, est. speed input: 443016.18 toks/s, output: 432.63 toks/s]
Processed prompts:  68%|██████▊   | 5607/8192 [00:13<00:12, 205.53it/s, est. speed input: 436887.19 toks/s, output: 426.65 toks/s]
Processed prompts:  69%|██████▉   | 5671/8192 [00:13<00:12, 202.50it/s, est. speed input: 431101.05 toks/s, output: 421.00 toks/s]
Processed prompts:  70%|███████   | 5735/8192 [00:13<00:12, 199.31it/s, est. speed input: 425418.73 toks/s, output: 415.45 toks/s]
Processed prompts:  71%|███████   | 5799/8192 [00:14<00:12, 197.86it/s, est. speed input: 420141.77 toks/s, output: 410.29 toks/s]
Processed prompts:  72%|███████▏  | 5863/8192 [00:14<00:11, 196.63it/s, est. speed input: 415075.54 toks/s, output: 405.35 toks/s]
Processed prompts:  72%|███████▏  | 5927/8192 [00:14<00:11, 196.23it/s, est. speed input: 410308.56 toks/s, output: 400.69 toks/s]
Processed prompts:  73%|███████▎  | 5991/8192 [00:15<00:11, 195.77it/s, est. speed input: 405722.99 toks/s, output: 396.21 toks/s]
Processed prompts:  74%|███████▍  | 6055/8192 [00:15<00:10, 194.55it/s, est. speed input: 401199.85 toks/s, output: 391.80 toks/s]
Processed prompts:  75%|███████▍  | 6119/8192 [00:15<00:10, 194.48it/s, est. speed input: 396979.60 toks/s, output: 387.67 toks/s]
Processed prompts:  75%|███████▌  | 6183/8192 [00:16<00:10, 194.70it/s, est. speed input: 392969.13 toks/s, output: 383.76 toks/s]
Processed prompts:  76%|███████▋  | 6247/8192 [00:16<00:10, 194.38it/s, est. speed input: 389056.04 toks/s, output: 379.94 toks/s]
Processed prompts:  77%|███████▋  | 6311/8192 [00:16<00:09, 193.72it/s, est. speed input: 385239.19 toks/s, output: 376.21 toks/s]
Processed prompts:  78%|███████▊  | 6375/8192 [00:17<00:09, 194.92it/s, est. speed input: 381781.95 toks/s, output: 372.83 toks/s]
Processed prompts:  79%|███████▊  | 6439/8192 [00:17<00:09, 193.31it/s, est. speed input: 378150.81 toks/s, output: 369.29 toks/s]
Processed prompts:  79%|███████▉  | 6503/8192 [00:17<00:08, 193.65it/s, est. speed input: 374834.73 toks/s, output: 366.05 toks/s]
Processed prompts:  80%|████████  | 6567/8192 [00:18<00:08, 194.55it/s, est. speed input: 371714.74 toks/s, output: 363.00 toks/s]
Processed prompts:  81%|████████  | 6631/8192 [00:18<00:08, 194.57it/s, est. speed input: 368635.80 toks/s, output: 360.00 toks/s]
Processed prompts:  82%|████████▏ | 6695/8192 [00:18<00:07, 193.43it/s, est. speed input: 365538.37 toks/s, output: 356.97 toks/s]
Processed prompts:  83%|████████▎ | 6759/8192 [00:19<00:07, 193.89it/s, est. speed input: 362684.79 toks/s, output: 354.18 toks/s]
Processed prompts:  83%|████████▎ | 6823/8192 [00:19<00:07, 193.92it/s, est. speed input: 359897.55 toks/s, output: 351.46 toks/s]
Processed prompts:  84%|████████▍ | 6887/8192 [00:19<00:06, 193.67it/s, est. speed input: 357175.17 toks/s, output: 348.80 toks/s]
Processed prompts:  85%|████████▍ | 6951/8192 [00:20<00:06, 194.02it/s, est. speed input: 354594.95 toks/s, output: 346.28 toks/s]
Processed prompts:  86%|████████▌ | 7015/8192 [00:20<00:06, 193.91it/s, est. speed input: 352063.67 toks/s, output: 343.81 toks/s]
Processed prompts:  86%|████████▋ | 7079/8192 [00:20<00:05, 194.16it/s, est. speed input: 349644.29 toks/s, output: 341.45 toks/s]
Processed prompts:  87%|████████▋ | 7143/8192 [00:21<00:05, 195.45it/s, est. speed input: 347403.36 toks/s, output: 339.26 toks/s]
Processed prompts:  88%|████████▊ | 7207/8192 [00:21<00:05, 195.14it/s, est. speed input: 345120.25 toks/s, output: 337.03 toks/s]
Processed prompts:  89%|████████▉ | 7271/8192 [00:21<00:04, 196.23it/s, est. speed input: 343020.86 toks/s, output: 334.98 toks/s]
Processed prompts:  90%|████████▉ | 7335/8192 [00:22<00:04, 195.97it/s, est. speed input: 340895.37 toks/s, output: 332.91 toks/s]
Processed prompts:  90%|█████████ | 7399/8192 [00:22<00:04, 195.44it/s, est. speed input: 338802.89 toks/s, output: 330.86 toks/s]
Processed prompts:  91%|█████████ | 7463/8192 [00:22<00:03, 194.63it/s, est. speed input: 336733.54 toks/s, output: 328.84 toks/s]
Processed prompts:  92%|█████████▏| 7527/8192 [00:23<00:03, 194.78it/s, est. speed input: 334783.22 toks/s, output: 326.94 toks/s]
Processed prompts:  93%|█████████▎| 7591/8192 [00:23<00:03, 194.97it/s, est. speed input: 332894.02 toks/s, output: 325.09 toks/s]
Processed prompts:  93%|█████████▎| 7655/8192 [00:23<00:02, 194.01it/s, est. speed input: 330970.76 toks/s, output: 323.21 toks/s]
Processed prompts:  94%|█████████▍| 7719/8192 [00:24<00:02, 194.23it/s, est. speed input: 329170.58 toks/s, output: 321.46 toks/s]
Processed prompts:  95%|█████████▌| 7783/8192 [00:24<00:02, 193.82it/s, est. speed input: 327375.87 toks/s, output: 319.70 toks/s]
Processed prompts:  96%|█████████▌| 7847/8192 [00:24<00:01, 193.70it/s, est. speed input: 325642.15 toks/s, output: 318.01 toks/s]
Processed prompts:  97%|█████████▋| 7911/8192 [00:25<00:01, 194.12it/s, est. speed input: 323991.13 toks/s, output: 316.40 toks/s]
Processed prompts:  97%|█████████▋| 7975/8192 [00:25<00:01, 193.79it/s, est. speed input: 322337.77 toks/s, output: 314.78 toks/s]
Processed prompts:  98%|█████████▊| 8039/8192 [00:25<00:00, 194.02it/s, est. speed input: 320759.51 toks/s, output: 313.24 toks/s]
Processed prompts:  99%|█████████▉| 8103/8192 [00:25<00:00, 194.57it/s, est. speed input: 319248.28 toks/s, output: 311.77 toks/s]
Processed prompts: 100%|█████████▉| 8167/8192 [00:26<00:00, 237.20it/s, est. speed input: 320145.19 toks/s, output: 312.64 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:26<00:00, 237.20it/s, est. speed input: 321118.36 toks/s, output: 313.59 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:26<00:00, 313.59it/s, est. speed input: 321118.36 toks/s, output: 313.59 toks/s]
[rank0]:[W126 09:00:43.449389080 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:22:46
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:22:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1206409) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1206409) WARNING 01-26 10:23:10 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.11 requests/s, 16987.13 total tokens/s, 33.11 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 10:22:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:22:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:22:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:22:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:22:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:22:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:22:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:22:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:22:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:23:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:23:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:23:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:23:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:23:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:23:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1206409) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1206409) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1206409) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1206409) 
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1206409) [2026-01-26 10:23:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1206409) 2026-01-26 10:23:20,652 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1206409) 2026-01-26 10:23:20,675 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1206409) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]
(EngineCore_DP0 pid=1206409) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  52%|█████▏    | 67/128 [00:00<00:00, 665.97it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 765.27it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:33,  3.84it/s, est. speed input: 1964.84 toks/s, output: 3.84 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 16.19it/s, est. speed input: 6947.29 toks/s, output: 13.57 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 23.51it/s, est. speed input: 9695.56 toks/s, output: 18.94 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 28.12it/s, est. speed input: 11436.48 toks/s, output: 22.34 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 31.14it/s, est. speed input: 12642.25 toks/s, output: 24.69 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.14it/s, est. speed input: 13523.25 toks/s, output: 26.41 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 34.48it/s, est. speed input: 14193.22 toks/s, output: 27.72 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:02, 35.43it/s, est. speed input: 14725.64 toks/s, output: 28.76 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 36.06it/s, est. speed input: 15154.17 toks/s, output: 29.60 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 36.56it/s, est. speed input: 15514.56 toks/s, output: 30.30 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 36.85it/s, est. speed input: 15811.76 toks/s, output: 30.88 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 37.09it/s, est. speed input: 16068.33 toks/s, output: 31.38 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 37.18it/s, est. speed input: 16281.66 toks/s, output: 31.80 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 37.33it/s, est. speed input: 16475.85 toks/s, output: 32.18 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 37.22it/s, est. speed input: 16627.02 toks/s, output: 32.47 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 37.03it/s, est. speed input: 16750.29 toks/s, output: 32.71 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 36.89it/s, est. speed input: 16859.72 toks/s, output: 32.93 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 36.80it/s, est. speed input: 16958.36 toks/s, output: 33.12 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 36.75it/s, est. speed input: 17047.91 toks/s, output: 33.30 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 36.74it/s, est. speed input: 17130.76 toks/s, output: 33.46 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 36.69it/s, est. speed input: 17203.18 toks/s, output: 33.60 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 36.68it/s, est. speed input: 17270.69 toks/s, output: 33.73 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 36.69it/s, est. speed input: 17334.21 toks/s, output: 33.86 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 36.70it/s, est. speed input: 17392.72 toks/s, output: 33.97 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 36.67it/s, est. speed input: 17444.04 toks/s, output: 34.07 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 36.67it/s, est. speed input: 17493.19 toks/s, output: 34.17 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 36.64it/s, est. speed input: 17537.14 toks/s, output: 34.25 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 36.65it/s, est. speed input: 17579.65 toks/s, output: 34.33 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 36.66it/s, est. speed input: 17619.40 toks/s, output: 34.41 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 36.66it/s, est. speed input: 17656.77 toks/s, output: 34.49 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 36.33it/s, est. speed input: 17674.66 toks/s, output: 34.52 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 36.39it/s, est. speed input: 17705.68 toks/s, output: 34.58 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.39it/s, est. speed input: 17728.89 toks/s, output: 34.63 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.62it/s, est. speed input: 17728.89 toks/s, output: 34.63 toks/s]
[rank0]:[W126 10:23:27.565387449 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 10:23:29
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:23:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1207563) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1207563) WARNING 01-26 10:23:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.84 requests/s, 35712.67 total tokens/s, 34.84 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 10:23:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:23:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:23:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:23:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:23:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:23:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:23:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:23:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:23:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:23:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:23:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:23:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:23:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:23:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1207563) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1207563) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1207563) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1207563) 
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1207563) [2026-01-26 10:23:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1207563) 2026-01-26 10:24:03,658 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1207563) 2026-01-26 10:24:03,682 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1207563) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.34it/s]
(EngineCore_DP0 pid=1207563) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.72it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  22%|██▏       | 28/128 [00:00<00:00, 275.54it/s]
Adding requests:  62%|██████▎   | 80/128 [00:00<00:00, 414.30it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 427.23it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:03, 32.91it/s, est. speed input: 33706.57 toks/s, output: 32.91 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:03, 35.80it/s, est. speed input: 36187.27 toks/s, output: 35.33 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:03, 36.80it/s, est. speed input: 37076.05 toks/s, output: 36.20 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:02, 37.34it/s, est. speed input: 37566.20 toks/s, output: 36.68 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:02, 37.60it/s, est. speed input: 37837.94 toks/s, output: 36.95 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:02, 37.82it/s, est. speed input: 38052.89 toks/s, output: 37.16 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:00<00:02, 37.93it/s, est. speed input: 38195.53 toks/s, output: 37.30 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:02, 37.92it/s, est. speed input: 38272.48 toks/s, output: 37.37 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:00<00:02, 38.01it/s, est. speed input: 38365.94 toks/s, output: 37.47 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:02, 38.04it/s, est. speed input: 38428.84 toks/s, output: 37.53 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 38.06it/s, est. speed input: 38483.38 toks/s, output: 37.58 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:02, 38.10it/s, est. speed input: 38535.09 toks/s, output: 37.63 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:01, 38.09it/s, est. speed input: 38568.17 toks/s, output: 37.66 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 38.09it/s, est. speed input: 38597.90 toks/s, output: 37.69 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:01<00:01, 38.11it/s, est. speed input: 38631.13 toks/s, output: 37.72 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:01<00:01, 38.10it/s, est. speed input: 38651.77 toks/s, output: 37.75 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:01<00:01, 38.10it/s, est. speed input: 38672.83 toks/s, output: 37.77 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:01<00:01, 38.11it/s, est. speed input: 38694.48 toks/s, output: 37.79 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:01, 38.16it/s, est. speed input: 38720.31 toks/s, output: 37.81 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:02<00:01, 38.16it/s, est. speed input: 38737.87 toks/s, output: 37.83 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:02<00:01, 38.16it/s, est. speed input: 38752.95 toks/s, output: 37.84 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:02<00:01, 38.15it/s, est. speed input: 38766.30 toks/s, output: 37.86 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:02<00:00, 38.17it/s, est. speed input: 38781.76 toks/s, output: 37.87 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 38.16it/s, est. speed input: 38793.31 toks/s, output: 37.88 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:02<00:00, 38.16it/s, est. speed input: 38805.09 toks/s, output: 37.90 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:02<00:00, 38.01it/s, est. speed input: 38795.81 toks/s, output: 37.89 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:02<00:00, 38.05it/s, est. speed input: 38805.78 toks/s, output: 37.90 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:02<00:00, 38.08it/s, est. speed input: 38814.51 toks/s, output: 37.90 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:03<00:00, 38.12it/s, est. speed input: 38825.41 toks/s, output: 37.91 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:03<00:00, 38.19it/s, est. speed input: 38840.37 toks/s, output: 37.93 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:03<00:00, 38.25it/s, est. speed input: 38855.36 toks/s, output: 37.94 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 38.27it/s, est. speed input: 38867.34 toks/s, output: 37.96 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 38.27it/s, est. speed input: 38867.34 toks/s, output: 37.96 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.95it/s, est. speed input: 38867.34 toks/s, output: 37.96 toks/s]
[rank0]:[W126 10:24:09.437417380 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 10:24:11
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:24:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1208659) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1208659) WARNING 01-26 10:24:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 64.98 requests/s, 66609.20 total tokens/s, 64.98 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 10:24:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:24:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:24:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:24:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:24:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:24:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:24:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:24:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:24:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:24:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:24:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:24:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:24:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:24:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:24:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:24:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:24:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1208659) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1208659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=1208659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.02it/s]
(EngineCore_DP0 pid=1208659) 
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1208659) [2026-01-26 10:24:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1208659) 2026-01-26 10:24:47,184 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1208659) 2026-01-26 10:24:47,229 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1208659) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 14.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 14.49it/s]
(EngineCore_DP0 pid=1208659) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.07it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.04it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█▏        | 29/256 [00:00<00:00, 284.19it/s]
Adding requests:  32%|███▏      | 81/256 [00:00<00:00, 417.83it/s]
Adding requests:  51%|█████     | 131/256 [00:00<00:00, 451.30it/s]
Adding requests:  70%|███████   | 180/256 [00:00<00:00, 464.47it/s]
Adding requests:  90%|█████████ | 231/256 [00:00<00:00, 479.33it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 459.36it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 208.62it/s, est. speed input: 213664.02 toks/s, output: 208.63 toks/s]
Processed prompts:  18%|█▊        | 45/256 [00:00<00:02, 104.47it/s, est. speed input: 116274.97 toks/s, output: 113.55 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:00<00:02, 87.61it/s, est. speed input: 100081.36 toks/s, output: 97.73 toks/s]  
Processed prompts:  27%|██▋       | 69/256 [00:00<00:02, 84.71it/s, est. speed input: 96252.08 toks/s, output: 93.99 toks/s] 
Processed prompts:  31%|███       | 79/256 [00:00<00:02, 80.51it/s, est. speed input: 92455.54 toks/s, output: 90.29 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:01<00:02, 75.48it/s, est. speed input: 88727.06 toks/s, output: 86.64 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:01<00:02, 74.29it/s, est. speed input: 87109.46 toks/s, output: 85.07 toks/s]
Processed prompts:  41%|████      | 104/256 [00:01<00:02, 73.36it/s, est. speed input: 85784.25 toks/s, output: 83.77 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:01<00:01, 72.70it/s, est. speed input: 84693.55 toks/s, output: 82.71 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:01<00:01, 72.34it/s, est. speed input: 83812.76 toks/s, output: 81.85 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:01<00:01, 71.90it/s, est. speed input: 83003.52 toks/s, output: 81.06 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:01<00:01, 71.73it/s, est. speed input: 82342.29 toks/s, output: 80.41 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:01<00:01, 71.56it/s, est. speed input: 81750.80 toks/s, output: 79.83 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:01<00:01, 71.38it/s, est. speed input: 81217.21 toks/s, output: 79.31 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:02<00:01, 71.33it/s, est. speed input: 80756.45 toks/s, output: 78.86 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:02<00:01, 71.15it/s, est. speed input: 80317.20 toks/s, output: 78.43 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:02<00:01, 71.17it/s, est. speed input: 79949.82 toks/s, output: 78.07 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:02<00:01, 71.18it/s, est. speed input: 79613.75 toks/s, output: 77.75 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:02<00:00, 71.00it/s, est. speed input: 79279.45 toks/s, output: 77.42 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:02<00:00, 71.01it/s, est. speed input: 78994.98 toks/s, output: 77.14 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:02<00:00, 71.05it/s, est. speed input: 78739.10 toks/s, output: 76.89 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:02<00:00, 71.08it/s, est. speed input: 78505.16 toks/s, output: 76.66 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:02<00:00, 71.11it/s, est. speed input: 78289.82 toks/s, output: 76.45 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:03<00:00, 71.08it/s, est. speed input: 78082.61 toks/s, output: 76.25 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:03<00:00, 70.93it/s, est. speed input: 77874.95 toks/s, output: 76.05 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:03<00:00, 70.88it/s, est. speed input: 77687.63 toks/s, output: 75.87 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.21it/s, est. speed input: 77557.40 toks/s, output: 75.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 71.21it/s, est. speed input: 77557.40 toks/s, output: 75.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 75.73it/s, est. speed input: 77557.40 toks/s, output: 75.74 toks/s]
[rank0]:[W126 10:24:53.526394674 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 10:24:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:25:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1209791) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1209791) WARNING 01-26 10:25:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 73.37 requests/s, 75200.33 total tokens/s, 73.37 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 10:25:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:25:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:25:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:25:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:25:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:25:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:25:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:25:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:25:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:25:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:25:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:25:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1209791) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1209791) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1209791) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1209791) 
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1209791) [2026-01-26 10:25:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1209791) 2026-01-26 10:25:31,109 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1209791) 2026-01-26 10:25:31,158 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1209791) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  7.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.82it/s]
(EngineCore_DP0 pid=1209791) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 18.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 12.17it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|▌         | 29/512 [00:00<00:01, 288.34it/s]
Adding requests:  16%|█▌        | 80/512 [00:00<00:01, 418.04it/s]
Adding requests:  25%|██▌       | 130/512 [00:00<00:00, 454.14it/s]
Adding requests:  35%|███▍      | 178/512 [00:00<00:00, 462.84it/s]
Adding requests:  45%|████▍     | 229/512 [00:00<00:00, 477.65it/s]
Adding requests:  54%|█████▍    | 279/512 [00:00<00:00, 482.42it/s]
Adding requests:  64%|██████▍   | 328/512 [00:00<00:00, 483.09it/s]
Adding requests:  74%|███████▍  | 379/512 [00:00<00:00, 489.04it/s]
Adding requests:  84%|████████▍ | 429/512 [00:00<00:00, 492.27it/s]
Adding requests:  94%|█████████▎| 479/512 [00:01<00:00, 492.23it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 474.64it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:00<00:00, 590.24it/s, est. speed input: 604503.87 toks/s, output: 590.27 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:00<00:02, 126.15it/s, est. speed input: 148529.83 toks/s, output: 145.04 toks/s]
Processed prompts:  32%|███▏      | 163/512 [00:01<00:03, 108.36it/s, est. speed input: 129060.81 toks/s, output: 126.03 toks/s]
Processed prompts:  36%|███▌      | 183/512 [00:01<00:03, 99.14it/s, est. speed input: 120159.20 toks/s, output: 117.34 toks/s] 
Processed prompts:  39%|███▊      | 198/512 [00:01<00:03, 92.05it/s, est. speed input: 114286.73 toks/s, output: 111.60 toks/s]
Processed prompts:  41%|████      | 210/512 [00:01<00:03, 88.58it/s, est. speed input: 111194.81 toks/s, output: 108.59 toks/s]
Processed prompts:  43%|████▎     | 221/512 [00:02<00:03, 91.13it/s, est. speed input: 110968.22 toks/s, output: 108.37 toks/s]
Processed prompts:  45%|████▌     | 232/512 [00:02<00:03, 85.53it/s, est. speed input: 108092.79 toks/s, output: 105.56 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:02<00:03, 79.40it/s, est. speed input: 105141.02 toks/s, output: 102.68 toks/s]
Processed prompts:  49%|████▉     | 251/512 [00:02<00:03, 80.50it/s, est. speed input: 104349.29 toks/s, output: 101.90 toks/s]
Processed prompts:  51%|█████     | 260/512 [00:02<00:03, 81.41it/s, est. speed input: 103610.59 toks/s, output: 101.18 toks/s]
Processed prompts:  53%|█████▎    | 269/512 [00:02<00:02, 82.07it/s, est. speed input: 102911.33 toks/s, output: 100.50 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:02<00:03, 73.18it/s, est. speed input: 100356.01 toks/s, output: 98.00 toks/s] 
Processed prompts:  56%|█████▌    | 286/512 [00:02<00:03, 73.74it/s, est. speed input: 99523.48 toks/s, output: 97.19 toks/s] 
Processed prompts:  57%|█████▋    | 294/512 [00:03<00:02, 74.26it/s, est. speed input: 98762.50 toks/s, output: 96.45 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:03<00:02, 74.58it/s, est. speed input: 98039.64 toks/s, output: 95.74 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:03<00:02, 74.86it/s, est. speed input: 97369.73 toks/s, output: 95.09 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:03<00:02, 75.09it/s, est. speed input: 96745.64 toks/s, output: 94.48 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:03<00:02, 75.03it/s, est. speed input: 96127.63 toks/s, output: 93.87 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:03<00:02, 75.06it/s, est. speed input: 95557.06 toks/s, output: 93.32 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:03<00:02, 76.36it/s, est. speed input: 95174.53 toks/s, output: 92.94 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:03<00:02, 76.13it/s, est. speed input: 94677.94 toks/s, output: 92.46 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:03<00:02, 75.79it/s, est. speed input: 94187.42 toks/s, output: 91.98 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:03<00:01, 75.61it/s, est. speed input: 93729.84 toks/s, output: 91.53 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:04<00:01, 75.44it/s, est. speed input: 93292.19 toks/s, output: 91.10 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:04<00:01, 75.42it/s, est. speed input: 92886.32 toks/s, output: 90.71 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:04<00:01, 75.43it/s, est. speed input: 92502.30 toks/s, output: 90.33 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:04<00:01, 75.39it/s, est. speed input: 92132.33 toks/s, output: 89.97 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:04<00:01, 75.33it/s, est. speed input: 91777.27 toks/s, output: 89.63 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:04<00:01, 75.10it/s, est. speed input: 91420.21 toks/s, output: 89.28 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:04<00:01, 75.14it/s, est. speed input: 91097.47 toks/s, output: 88.96 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:04<00:01, 75.12it/s, est. speed input: 90786.28 toks/s, output: 88.66 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:04<00:00, 75.11it/s, est. speed input: 90486.56 toks/s, output: 88.37 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:05<00:00, 74.96it/s, est. speed input: 90187.94 toks/s, output: 88.07 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:05<00:00, 76.73it/s, est. speed input: 89939.13 toks/s, output: 87.83 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:05<00:00, 76.47it/s, est. speed input: 89694.39 toks/s, output: 87.59 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:05<00:00, 76.09it/s, est. speed input: 89443.46 toks/s, output: 87.35 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:05<00:00, 75.68it/s, est. speed input: 89192.77 toks/s, output: 87.10 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:05<00:00, 75.52it/s, est. speed input: 88960.94 toks/s, output: 86.88 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:05<00:00, 75.36it/s, est. speed input: 88734.78 toks/s, output: 86.65 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:05<00:00, 75.17it/s, est. speed input: 88511.07 toks/s, output: 86.44 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 75.17it/s, est. speed input: 88892.76 toks/s, output: 86.81 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 86.81it/s, est. speed input: 88892.76 toks/s, output: 86.81 toks/s]
[rank0]:[W126 10:25:40.895855934 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 10:25:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:25:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1210962) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1210962) WARNING 01-26 10:26:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 77.14 requests/s, 79065.41 total tokens/s, 77.14 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 10:25:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:25:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:25:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:25:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:25:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:25:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:25:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:25:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:26:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:26:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:26:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:26:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:26:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:26:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:26:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:26:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1210962) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1210962) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1210962) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1210962) 
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1210962) [2026-01-26 10:26:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1210962) 2026-01-26 10:26:20,122 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1210962) 2026-01-26 10:26:20,146 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1210962) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 11.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  9.24it/s]
(EngineCore_DP0 pid=1210962) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  5.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  5.40it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 31/1024 [00:00<00:03, 307.50it/s]
Adding requests:   8%|▊         | 83/1024 [00:00<00:02, 428.77it/s]
Adding requests:  13%|█▎        | 134/1024 [00:00<00:01, 462.83it/s]
Adding requests:  18%|█▊        | 183/1024 [00:00<00:01, 471.74it/s]
Adding requests:  23%|██▎       | 234/1024 [00:00<00:01, 484.31it/s]
Adding requests:  28%|██▊       | 285/1024 [00:00<00:01, 491.41it/s]
Adding requests:  33%|███▎      | 335/1024 [00:00<00:01, 488.99it/s]
Adding requests:  38%|███▊      | 386/1024 [00:00<00:01, 494.94it/s]
Adding requests:  43%|████▎     | 437/1024 [00:00<00:01, 497.43it/s]
Adding requests:  48%|████▊     | 488/1024 [00:01<00:01, 499.47it/s]
Adding requests:  53%|█████▎    | 538/1024 [00:01<00:00, 487.71it/s]
Adding requests:  58%|█████▊    | 591/1024 [00:01<00:00, 499.01it/s]
Adding requests:  63%|██████▎   | 641/1024 [00:01<00:00, 494.26it/s]
Adding requests:  68%|██████▊   | 694/1024 [00:01<00:00, 502.36it/s]
Adding requests:  73%|███████▎  | 745/1024 [00:01<00:00, 500.37it/s]
Adding requests:  78%|███████▊  | 796/1024 [00:01<00:00, 499.52it/s]
Adding requests:  83%|████████▎ | 846/1024 [00:01<00:00, 488.52it/s]
Adding requests:  88%|████████▊ | 899/1024 [00:01<00:00, 499.43it/s]
Adding requests:  93%|█████████▎| 950/1024 [00:01<00:00, 500.81it/s]
Adding requests:  98%|█████████▊| 1002/1024 [00:02<00:00, 505.09it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 491.15it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:00<00:00, 933.61it/s, est. speed input: 956148.80 toks/s, output: 933.65 toks/s]
Processed prompts:  25%|██▌       | 256/1024 [00:01<00:04, 164.90it/s, est. speed input: 200150.44 toks/s, output: 195.46 toks/s]
Processed prompts:  29%|██▉       | 300/1024 [00:01<00:05, 126.30it/s, est. speed input: 159402.77 toks/s, output: 155.67 toks/s]
Processed prompts:  32%|███▏      | 327/1024 [00:02<00:05, 117.27it/s, est. speed input: 149609.75 toks/s, output: 146.10 toks/s]
Processed prompts:  34%|███▍      | 347/1024 [00:02<00:06, 105.17it/s, est. speed input: 140012.10 toks/s, output: 136.73 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:02<00:06, 99.06it/s, est. speed input: 135127.52 toks/s, output: 131.96 toks/s] 
Processed prompts:  37%|███▋      | 375/1024 [00:02<00:06, 102.22it/s, est. speed input: 134876.91 toks/s, output: 131.72 toks/s]
Processed prompts:  38%|███▊      | 388/1024 [00:03<00:06, 92.10it/s, est. speed input: 130077.94 toks/s, output: 127.03 toks/s] 
Processed prompts:  39%|███▉      | 399/1024 [00:03<00:06, 94.20it/s, est. speed input: 129355.63 toks/s, output: 126.32 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:03<00:07, 81.86it/s, est. speed input: 124815.38 toks/s, output: 121.89 toks/s]
Processed prompts:  41%|████      | 419/1024 [00:03<00:07, 82.77it/s, est. speed input: 123743.60 toks/s, output: 120.84 toks/s]
Processed prompts:  42%|████▏     | 428/1024 [00:03<00:07, 83.59it/s, est. speed input: 122731.57 toks/s, output: 119.85 toks/s]
Processed prompts:  43%|████▎     | 437/1024 [00:03<00:06, 84.39it/s, est. speed input: 121789.33 toks/s, output: 118.93 toks/s]
Processed prompts:  44%|████▎     | 446/1024 [00:03<00:06, 85.11it/s, est. speed input: 120906.70 toks/s, output: 118.07 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:03<00:07, 75.73it/s, est. speed input: 118061.38 toks/s, output: 115.29 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:04<00:07, 75.99it/s, est. speed input: 117054.54 toks/s, output: 114.31 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:04<00:07, 76.37it/s, est. speed input: 116124.81 toks/s, output: 113.40 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:04<00:07, 76.72it/s, est. speed input: 115245.99 toks/s, output: 112.54 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:04<00:06, 76.94it/s, est. speed input: 114402.36 toks/s, output: 111.72 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:04<00:06, 77.02it/s, est. speed input: 113587.58 toks/s, output: 110.92 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:04<00:06, 77.11it/s, est. speed input: 112812.88 toks/s, output: 110.17 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:04<00:06, 77.23it/s, est. speed input: 112077.83 toks/s, output: 109.45 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:04<00:06, 77.25it/s, est. speed input: 111368.53 toks/s, output: 108.76 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:04<00:06, 77.46it/s, est. speed input: 110708.02 toks/s, output: 108.11 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:05<00:06, 77.26it/s, est. speed input: 110041.16 toks/s, output: 107.46 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:05<00:06, 77.04it/s, est. speed input: 109392.78 toks/s, output: 106.83 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:05<00:06, 77.15it/s, est. speed input: 108795.18 toks/s, output: 106.24 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:05<00:05, 77.20it/s, est. speed input: 108218.96 toks/s, output: 105.68 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:05<00:05, 77.44it/s, est. speed input: 107682.57 toks/s, output: 105.16 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:05<00:05, 77.30it/s, est. speed input: 107139.73 toks/s, output: 104.63 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:05<00:05, 77.30it/s, est. speed input: 106625.24 toks/s, output: 104.13 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:05<00:05, 77.16it/s, est. speed input: 106117.55 toks/s, output: 103.63 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:05<00:05, 77.27it/s, est. speed input: 105644.91 toks/s, output: 103.17 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:05<00:05, 77.32it/s, est. speed input: 105186.70 toks/s, output: 102.72 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:06<00:05, 77.38it/s, est. speed input: 104746.06 toks/s, output: 102.29 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:06<00:05, 77.33it/s, est. speed input: 104312.66 toks/s, output: 101.87 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:06<00:05, 77.20it/s, est. speed input: 103887.29 toks/s, output: 101.45 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:06<00:04, 77.20it/s, est. speed input: 103482.48 toks/s, output: 101.06 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:06<00:04, 77.10it/s, est. speed input: 103082.70 toks/s, output: 100.67 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:06<00:04, 77.31it/s, est. speed input: 102715.85 toks/s, output: 100.31 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:06<00:04, 77.43it/s, est. speed input: 102358.61 toks/s, output: 99.96 toks/s] 
Processed prompts:  66%|██████▌   | 674/1024 [00:06<00:04, 77.29it/s, est. speed input: 101996.90 toks/s, output: 99.61 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:06<00:04, 77.29it/s, est. speed input: 101652.59 toks/s, output: 99.27 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:06<00:04, 77.32it/s, est. speed input: 101320.64 toks/s, output: 98.95 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:07<00:04, 77.28it/s, est. speed input: 100993.99 toks/s, output: 98.63 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:07<00:04, 77.39it/s, est. speed input: 100685.73 toks/s, output: 98.33 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:07<00:04, 77.35it/s, est. speed input: 100378.87 toks/s, output: 98.03 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:07<00:03, 77.17it/s, est. speed input: 100071.52 toks/s, output: 97.73 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:07<00:03, 77.17it/s, est. speed input: 99780.14 toks/s, output: 97.44 toks/s] 
Processed prompts:  72%|███████▏  | 738/1024 [00:07<00:03, 77.23it/s, est. speed input: 99500.39 toks/s, output: 97.17 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:07<00:03, 77.38it/s, est. speed input: 99234.20 toks/s, output: 96.91 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:07<00:03, 77.45it/s, est. speed input: 98973.33 toks/s, output: 96.65 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:07<00:03, 77.30it/s, est. speed input: 98708.12 toks/s, output: 96.39 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:08<00:03, 77.15it/s, est. speed input: 98447.13 toks/s, output: 96.14 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:08<00:03, 77.11it/s, est. speed input: 98196.41 toks/s, output: 95.89 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:08<00:03, 77.25it/s, est. speed input: 97960.80 toks/s, output: 95.66 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:08<00:02, 77.27it/s, est. speed input: 97727.29 toks/s, output: 95.44 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:08<00:02, 77.41it/s, est. speed input: 97505.66 toks/s, output: 95.22 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:08<00:02, 77.15it/s, est. speed input: 97271.29 toks/s, output: 94.99 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:08<00:02, 77.08it/s, est. speed input: 97048.21 toks/s, output: 94.77 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:08<00:02, 77.13it/s, est. speed input: 96835.76 toks/s, output: 94.57 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:08<00:02, 77.19it/s, est. speed input: 96629.02 toks/s, output: 94.36 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:08<00:02, 77.19it/s, est. speed input: 96425.40 toks/s, output: 94.16 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:09<00:02, 77.08it/s, est. speed input: 96221.00 toks/s, output: 93.97 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:09<00:02, 77.04it/s, est. speed input: 96022.80 toks/s, output: 93.77 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:09<00:02, 76.96it/s, est. speed input: 95826.90 toks/s, output: 93.58 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:09<00:01, 77.19it/s, est. speed input: 95648.21 toks/s, output: 93.41 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:09<00:01, 77.25it/s, est. speed input: 95469.19 toks/s, output: 93.23 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:09<00:01, 77.27it/s, est. speed input: 95292.94 toks/s, output: 93.06 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:09<00:01, 77.14it/s, est. speed input: 95114.18 toks/s, output: 92.88 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:09<00:01, 77.10it/s, est. speed input: 94941.03 toks/s, output: 92.72 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:09<00:01, 77.22it/s, est. speed input: 94778.08 toks/s, output: 92.56 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:09<00:01, 77.18it/s, est. speed input: 94613.60 toks/s, output: 92.40 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:10<00:01, 77.23it/s, est. speed input: 94455.30 toks/s, output: 92.24 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:10<00:00, 79.02it/s, est. speed input: 94238.84 toks/s, output: 92.03 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:10<00:00, 78.61it/s, est. speed input: 94089.54 toks/s, output: 91.88 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:10<00:00, 78.16it/s, est. speed input: 93937.62 toks/s, output: 91.74 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:10<00:00, 77.97it/s, est. speed input: 93794.99 toks/s, output: 91.60 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:10<00:00, 77.67it/s, est. speed input: 93648.85 toks/s, output: 91.45 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:10<00:00, 79.33it/s, est. speed input: 93465.01 toks/s, output: 91.27 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:10<00:00, 78.91it/s, est. speed input: 93333.98 toks/s, output: 91.15 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:11<00:00, 78.51it/s, est. speed input: 93202.36 toks/s, output: 91.02 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:11<00:00, 78.51it/s, est. speed input: 93723.94 toks/s, output: 91.53 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:11<00:00, 91.53it/s, est. speed input: 93723.94 toks/s, output: 91.53 toks/s]
[rank0]:[W126 10:26:36.596527409 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 10:26:38
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:26:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1212281) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1212281) WARNING 01-26 10:27:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 80.66 requests/s, 82673.77 total tokens/s, 80.66 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 10:26:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:26:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:26:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:26:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:26:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:26:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:26:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:26:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:26:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:27:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:27:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:27:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:27:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:27:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:27:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:27:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:27:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:27:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1212281) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1212281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1212281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1212281) 
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1212281) [2026-01-26 10:27:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1212281) 2026-01-26 10:27:20,292 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1212281) 2026-01-26 10:27:20,316 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1212281) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  4.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  7.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]
(EngineCore_DP0 pid=1212281) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  8.72it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 11.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.51it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 30/2048 [00:00<00:06, 299.36it/s]
Adding requests:   4%|▍         | 80/2048 [00:00<00:04, 416.83it/s]
Adding requests:   6%|▋         | 129/2048 [00:00<00:04, 448.23it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:04, 458.92it/s]
Adding requests:  11%|█         | 227/2048 [00:00<00:03, 473.45it/s]
Adding requests:  14%|█▎        | 277/2048 [00:00<00:03, 480.88it/s]
Adding requests:  16%|█▌        | 326/2048 [00:00<00:03, 481.20it/s]
Adding requests:  18%|█▊        | 377/2048 [00:00<00:03, 487.46it/s]
Adding requests:  21%|██        | 427/2048 [00:00<00:03, 490.03it/s]
Adding requests:  23%|██▎       | 477/2048 [00:01<00:03, 491.44it/s]
Adding requests:  26%|██▌       | 527/2048 [00:01<00:03, 480.91it/s]
Adding requests:  28%|██▊       | 578/2048 [00:01<00:03, 488.04it/s]
Adding requests:  31%|███       | 629/2048 [00:01<00:02, 492.57it/s]
Adding requests:  33%|███▎      | 680/2048 [00:01<00:02, 496.34it/s]
Adding requests:  36%|███▌      | 732/2048 [00:01<00:02, 501.27it/s]
Adding requests:  38%|███▊      | 783/2048 [00:01<00:02, 494.24it/s]
Adding requests:  41%|████      | 833/2048 [00:01<00:02, 487.03it/s]
Adding requests:  43%|████▎     | 882/2048 [00:01<00:02, 477.40it/s]
Adding requests:  46%|████▌     | 933/2048 [00:01<00:02, 486.57it/s]
Adding requests:  48%|████▊     | 983/2048 [00:02<00:02, 489.43it/s]
Adding requests:  50%|█████     | 1034/2048 [00:02<00:02, 493.77it/s]
Adding requests:  53%|█████▎    | 1084/2048 [00:02<00:01, 492.32it/s]
Adding requests:  55%|█████▌    | 1134/2048 [00:02<00:01, 489.84it/s]
Adding requests:  58%|█████▊    | 1187/2048 [00:02<00:01, 500.11it/s]
Adding requests:  60%|██████    | 1238/2048 [00:02<00:01, 501.20it/s]
Adding requests:  63%|██████▎   | 1289/2048 [00:02<00:01, 496.61it/s]
Adding requests:  65%|██████▌   | 1340/2048 [00:02<00:01, 499.20it/s]
Adding requests:  68%|██████▊   | 1391/2048 [00:02<00:01, 501.29it/s]
Adding requests:  70%|███████   | 1442/2048 [00:02<00:01, 499.35it/s]
Adding requests:  73%|███████▎  | 1494/2048 [00:03<00:01, 502.82it/s]
Adding requests:  75%|███████▌  | 1545/2048 [00:03<00:00, 503.37it/s]
Adding requests:  78%|███████▊  | 1597/2048 [00:03<00:00, 506.97it/s]
Adding requests:  80%|████████  | 1648/2048 [00:03<00:00, 506.40it/s]
Adding requests:  83%|████████▎ | 1699/2048 [00:03<00:00, 501.25it/s]
Adding requests:  85%|████████▌ | 1750/2048 [00:03<00:00, 502.09it/s]
Adding requests:  88%|████████▊ | 1801/2048 [00:03<00:00, 498.90it/s]
Adding requests:  90%|█████████ | 1851/2048 [00:03<00:00, 498.66it/s]
Adding requests:  93%|█████████▎| 1902/2048 [00:03<00:00, 498.28it/s]
Adding requests:  95%|█████████▌| 1952/2048 [00:03<00:00, 498.13it/s]
Adding requests:  98%|█████████▊| 2002/2048 [00:04<00:00, 485.36it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 489.80it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:00<00:01, 1335.28it/s, est. speed input: 1367461.92 toks/s, output: 1335.32 toks/s]
Processed prompts:  23%|██▎       | 472/2048 [00:01<00:07, 212.04it/s, est. speed input: 265025.67 toks/s, output: 258.81 toks/s]   
Processed prompts:  26%|██▌       | 533/2048 [00:02<00:09, 158.69it/s, est. speed input: 208367.49 toks/s, output: 203.48 toks/s]
Processed prompts:  28%|██▊       | 570/2048 [00:03<00:10, 144.37it/s, est. speed input: 193535.99 toks/s, output: 189.00 toks/s]
Processed prompts:  29%|██▉       | 596/2048 [00:03<00:11, 125.58it/s, est. speed input: 178842.39 toks/s, output: 174.65 toks/s]
Processed prompts:  30%|███       | 615/2048 [00:03<00:11, 121.35it/s, est. speed input: 174464.45 toks/s, output: 170.38 toks/s]
Processed prompts:  31%|███       | 631/2048 [00:03<00:12, 114.10it/s, est. speed input: 169572.69 toks/s, output: 165.60 toks/s]
Processed prompts:  31%|███▏      | 645/2048 [00:04<00:13, 105.52it/s, est. speed input: 164758.76 toks/s, output: 160.90 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:04<00:14, 96.59it/s, est. speed input: 160102.06 toks/s, output: 156.35 toks/s] 
Processed prompts:  33%|███▎      | 674/2048 [00:04<00:14, 92.79it/s, est. speed input: 156615.45 toks/s, output: 152.94 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:04<00:15, 89.62it/s, est. speed input: 153402.36 toks/s, output: 149.81 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:04<00:15, 87.18it/s, est. speed input: 150464.06 toks/s, output: 146.94 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:05<00:15, 85.31it/s, est. speed input: 147755.11 toks/s, output: 144.29 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:05<00:15, 83.88it/s, est. speed input: 145242.68 toks/s, output: 141.84 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:05<00:15, 82.82it/s, est. speed input: 142912.56 toks/s, output: 139.56 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:05<00:15, 82.15it/s, est. speed input: 140767.35 toks/s, output: 137.47 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:05<00:15, 81.59it/s, est. speed input: 138753.91 toks/s, output: 135.50 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:06<00:15, 81.17it/s, est. speed input: 136868.64 toks/s, output: 133.66 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:06<00:15, 80.86it/s, est. speed input: 135102.75 toks/s, output: 131.94 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:06<00:15, 80.76it/s, est. speed input: 133468.04 toks/s, output: 130.34 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:06<00:14, 80.71it/s, est. speed input: 131935.55 toks/s, output: 128.84 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:06<00:14, 80.60it/s, est. speed input: 130479.15 toks/s, output: 127.42 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:06<00:14, 80.58it/s, est. speed input: 129116.06 toks/s, output: 126.09 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:07<00:14, 80.54it/s, est. speed input: 127823.96 toks/s, output: 124.83 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:07<00:14, 80.64it/s, est. speed input: 126619.69 toks/s, output: 123.65 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:07<00:13, 82.19it/s, est. speed input: 125674.94 toks/s, output: 122.73 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:07<00:13, 81.62it/s, est. speed input: 124562.50 toks/s, output: 121.64 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:07<00:13, 81.28it/s, est. speed input: 123511.92 toks/s, output: 120.62 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:08<00:12, 82.47it/s, est. speed input: 122684.40 toks/s, output: 119.81 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:08<00:12, 81.81it/s, est. speed input: 121720.29 toks/s, output: 118.87 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:08<00:12, 81.37it/s, est. speed input: 120803.95 toks/s, output: 117.97 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:08<00:12, 81.00it/s, est. speed input: 119921.25 toks/s, output: 117.11 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:08<00:12, 80.69it/s, est. speed input: 119071.78 toks/s, output: 116.28 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:09<00:12, 80.47it/s, est. speed input: 118259.86 toks/s, output: 115.49 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:09<00:12, 80.39it/s, est. speed input: 117489.49 toks/s, output: 114.74 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:09<00:11, 80.31it/s, est. speed input: 116749.77 toks/s, output: 114.01 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:09<00:11, 80.19it/s, est. speed input: 116032.75 toks/s, output: 113.31 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:09<00:11, 80.07it/s, est. speed input: 115342.13 toks/s, output: 112.64 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:10<00:11, 80.21it/s, est. speed input: 114699.67 toks/s, output: 112.01 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:10<00:10, 81.94it/s, est. speed input: 114227.16 toks/s, output: 111.55 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:10<00:10, 81.64it/s, est. speed input: 113639.49 toks/s, output: 110.98 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:10<00:10, 81.20it/s, est. speed input: 113053.98 toks/s, output: 110.40 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:10<00:10, 81.09it/s, est. speed input: 112505.93 toks/s, output: 109.87 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:11<00:10, 80.93it/s, est. speed input: 111970.92 toks/s, output: 109.35 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:11<00:10, 81.05it/s, est. speed input: 111473.05 toks/s, output: 108.86 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:11<00:09, 81.10it/s, est. speed input: 110989.26 toks/s, output: 108.39 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:11<00:09, 81.05it/s, est. speed input: 110515.66 toks/s, output: 107.93 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:11<00:09, 80.97it/s, est. speed input: 110054.11 toks/s, output: 107.47 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:12<00:09, 80.90it/s, est. speed input: 109606.74 toks/s, output: 107.04 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:12<00:09, 80.90it/s, est. speed input: 109177.09 toks/s, output: 106.62 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:12<00:08, 80.88it/s, est. speed input: 108760.07 toks/s, output: 106.21 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:12<00:08, 80.83it/s, est. speed input: 108353.13 toks/s, output: 105.81 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:12<00:08, 80.68it/s, est. speed input: 107950.59 toks/s, output: 105.42 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:13<00:08, 80.60it/s, est. speed input: 107562.27 toks/s, output: 105.04 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:13<00:08, 80.77it/s, est. speed input: 107200.63 toks/s, output: 104.69 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:13<00:07, 80.89it/s, est. speed input: 106848.99 toks/s, output: 104.34 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:13<00:07, 80.98it/s, est. speed input: 106508.54 toks/s, output: 104.01 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:13<00:07, 80.84it/s, est. speed input: 106164.32 toks/s, output: 103.68 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:14<00:07, 80.74it/s, est. speed input: 105830.03 toks/s, output: 103.35 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:14<00:07, 80.65it/s, est. speed input: 105503.92 toks/s, output: 103.03 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:14<00:06, 80.73it/s, est. speed input: 105195.24 toks/s, output: 102.73 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:14<00:06, 80.77it/s, est. speed input: 104894.09 toks/s, output: 102.44 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:14<00:06, 80.69it/s, est. speed input: 104594.38 toks/s, output: 102.14 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:15<00:06, 80.48it/s, est. speed input: 104293.75 toks/s, output: 101.85 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:15<00:06, 80.44it/s, est. speed input: 104007.45 toks/s, output: 101.57 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:15<00:05, 80.47it/s, est. speed input: 103731.50 toks/s, output: 101.30 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:15<00:05, 82.24it/s, est. speed input: 103555.30 toks/s, output: 101.13 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:15<00:05, 81.76it/s, est. speed input: 103293.30 toks/s, output: 100.87 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:16<00:05, 81.31it/s, est. speed input: 103032.26 toks/s, output: 100.62 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:16<00:05, 80.86it/s, est. speed input: 102770.26 toks/s, output: 100.36 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:16<00:04, 80.74it/s, est. speed input: 102524.25 toks/s, output: 100.12 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:16<00:04, 80.80it/s, est. speed input: 102291.32 toks/s, output: 99.89 toks/s] 
Processed prompts:  82%|████████▏ | 1682/2048 [00:16<00:04, 80.80it/s, est. speed input: 102061.84 toks/s, output: 99.67 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:17<00:04, 80.84it/s, est. speed input: 101839.92 toks/s, output: 99.45 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:17<00:04, 80.72it/s, est. speed input: 101615.60 toks/s, output: 99.23 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:17<00:03, 80.83it/s, est. speed input: 101405.92 toks/s, output: 99.03 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:17<00:03, 80.89it/s, est. speed input: 101199.74 toks/s, output: 98.83 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:17<00:03, 80.83it/s, est. speed input: 100993.72 toks/s, output: 98.63 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:18<00:03, 80.76it/s, est. speed input: 100790.67 toks/s, output: 98.43 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:18<00:03, 80.65it/s, est. speed input: 100589.69 toks/s, output: 98.23 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:18<00:02, 80.50it/s, est. speed input: 100389.18 toks/s, output: 98.04 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:18<00:02, 80.58it/s, est. speed input: 100201.63 toks/s, output: 97.85 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:18<00:02, 80.45it/s, est. speed input: 100010.03 toks/s, output: 97.67 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:19<00:02, 80.52it/s, est. speed input: 99828.70 toks/s, output: 97.49 toks/s] 
Processed prompts:  92%|█████████▏| 1874/2048 [00:19<00:02, 82.05it/s, est. speed input: 99713.52 toks/s, output: 97.38 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:19<00:01, 81.49it/s, est. speed input: 99533.24 toks/s, output: 97.20 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:19<00:01, 81.36it/s, est. speed input: 99366.88 toks/s, output: 97.04 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:19<00:01, 81.04it/s, est. speed input: 99194.95 toks/s, output: 96.87 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:20<00:01, 80.75it/s, est. speed input: 99023.42 toks/s, output: 96.70 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:20<00:01, 82.08it/s, est. speed input: 98915.78 toks/s, output: 96.60 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:20<00:00, 81.57it/s, est. speed input: 98754.17 toks/s, output: 96.44 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:20<00:00, 81.25it/s, est. speed input: 98597.26 toks/s, output: 96.29 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:20<00:00, 81.11it/s, est. speed input: 98446.17 toks/s, output: 96.14 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:21<00:00, 80.94it/s, est. speed input: 98295.26 toks/s, output: 95.99 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:21<00:00, 82.50it/s, est. speed input: 98209.31 toks/s, output: 95.91 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:21<00:00, 82.50it/s, est. speed input: 98883.93 toks/s, output: 96.57 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:21<00:00, 96.57it/s, est. speed input: 98883.93 toks/s, output: 96.57 toks/s]
[rank0]:[W126 10:27:49.384697178 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 10:27:51
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:28:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1213855) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1213855) WARNING 01-26 10:28:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 82.04 requests/s, 84088.41 total tokens/s, 82.04 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 10:28:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:28:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:28:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:28:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:28:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:28:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:28:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:28:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:28:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:28:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:28:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:28:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:28:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:28:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:28:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:28:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:28:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1213855) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1213855) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=1213855) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.09it/s]
(EngineCore_DP0 pid=1213855) 
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1213855) [2026-01-26 10:28:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1213855) [rank0]:W0126 10:28:38.012000 1213855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1213855) [rank0]:W0126 10:28:38.098000 1213855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1213855) [rank0]:W0126 10:28:39.046000 1213855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1213855) [rank0]:W0126 10:28:39.174000 1213855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1213855) 2026-01-26 10:28:43,318 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1213855) 2026-01-26 10:28:43,344 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1213855) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 13.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 16.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  6.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  5.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  7.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.63it/s]
(EngineCore_DP0 pid=1213855) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 18.67it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 12.15it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 13.71it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 14.42it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 35/4096 [00:00<00:11, 344.90it/s]
Adding requests:   2%|▏         | 86/4096 [00:00<00:09, 436.96it/s]
Adding requests:   3%|▎         | 136/4096 [00:00<00:08, 464.43it/s]
Adding requests:   5%|▍         | 185/4096 [00:00<00:08, 473.38it/s]
Adding requests:   6%|▌         | 236/4096 [00:00<00:07, 485.36it/s]
Adding requests:   7%|▋         | 287/4096 [00:00<00:07, 489.16it/s]
Adding requests:   8%|▊         | 337/4096 [00:00<00:07, 489.75it/s]
Adding requests:   9%|▉         | 389/4096 [00:00<00:07, 497.01it/s]
Adding requests:  11%|█         | 439/4096 [00:00<00:07, 496.92it/s]
Adding requests:  12%|█▏        | 489/4096 [00:01<00:07, 497.80it/s]
Adding requests:  13%|█▎        | 539/4096 [00:01<00:07, 488.50it/s]
Adding requests:  14%|█▍        | 592/4096 [00:01<00:07, 498.89it/s]
Adding requests:  16%|█▌        | 643/4096 [00:01<00:06, 499.85it/s]
Adding requests:  17%|█▋        | 695/4096 [00:01<00:06, 504.61it/s]
Adding requests:  18%|█▊        | 746/4096 [00:01<00:06, 504.37it/s]
Adding requests:  19%|█▉        | 797/4096 [00:01<00:06, 502.27it/s]
Adding requests:  21%|██        | 848/4096 [00:01<00:06, 495.28it/s]
Adding requests:  22%|██▏       | 901/4096 [00:01<00:06, 503.18it/s]
Adding requests:  23%|██▎       | 952/4096 [00:01<00:06, 503.61it/s]
Adding requests:  25%|██▍       | 1004/4096 [00:02<00:06, 506.38it/s]
Adding requests:  26%|██▌       | 1055/4096 [00:02<00:05, 507.43it/s]
Adding requests:  27%|██▋       | 1106/4096 [00:02<00:06, 488.52it/s]
Adding requests:  28%|██▊       | 1157/4096 [00:02<00:05, 493.31it/s]
Adding requests:  30%|██▉       | 1211/4096 [00:02<00:05, 504.22it/s]
Adding requests:  31%|███       | 1262/4096 [00:02<00:05, 501.43it/s]
Adding requests:  32%|███▏      | 1313/4096 [00:02<00:05, 502.18it/s]
Adding requests:  33%|███▎      | 1366/4096 [00:02<00:05, 508.22it/s]
Adding requests:  35%|███▍      | 1418/4096 [00:02<00:05, 509.07it/s]
Adding requests:  36%|███▌      | 1470/4096 [00:02<00:05, 510.82it/s]
Adding requests:  37%|███▋      | 1523/4096 [00:03<00:05, 514.34it/s]
Adding requests:  38%|███▊      | 1575/4096 [00:03<00:04, 515.17it/s]
Adding requests:  40%|███▉      | 1629/4096 [00:03<00:04, 519.92it/s]
Adding requests:  41%|████      | 1681/4096 [00:03<00:04, 512.98it/s]
Adding requests:  42%|████▏     | 1734/4096 [00:03<00:04, 515.60it/s]
Adding requests:  44%|████▎     | 1786/4096 [00:03<00:04, 511.20it/s]
Adding requests:  45%|████▍     | 1838/4096 [00:03<00:04, 512.29it/s]
Adding requests:  46%|████▌     | 1890/4096 [00:03<00:04, 512.32it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:03<00:04, 510.79it/s]
Adding requests:  49%|████▊     | 1994/4096 [00:03<00:04, 509.07it/s]
Adding requests:  50%|████▉     | 2047/4096 [00:04<00:03, 512.31it/s]
Adding requests:  51%|█████     | 2099/4096 [00:04<00:03, 513.81it/s]
Adding requests:  53%|█████▎    | 2151/4096 [00:04<00:03, 508.01it/s]
Adding requests:  54%|█████▍    | 2202/4096 [00:04<00:03, 502.47it/s]
Adding requests:  55%|█████▌    | 2255/4096 [00:04<00:03, 509.79it/s]
Adding requests:  56%|█████▋    | 2307/4096 [00:04<00:03, 492.46it/s]
Adding requests:  58%|█████▊    | 2358/4096 [00:04<00:03, 495.91it/s]
Adding requests:  59%|█████▉    | 2409/4096 [00:04<00:03, 497.53it/s]
Adding requests:  60%|██████    | 2461/4096 [00:04<00:03, 503.47it/s]
Adding requests:  61%|██████▏   | 2512/4096 [00:05<00:03, 504.26it/s]
Adding requests:  63%|██████▎   | 2565/4096 [00:05<00:03, 509.27it/s]
Adding requests:  64%|██████▍   | 2617/4096 [00:05<00:02, 509.59it/s]
Adding requests:  65%|██████▌   | 2670/4096 [00:05<00:02, 513.35it/s]
Adding requests:  66%|██████▋   | 2722/4096 [00:05<00:02, 509.11it/s]
Adding requests:  68%|██████▊   | 2773/4096 [00:05<00:02, 508.85it/s]
Adding requests:  69%|██████▉   | 2824/4096 [00:05<00:02, 504.35it/s]
Adding requests:  70%|███████   | 2876/4096 [00:05<00:02, 507.81it/s]
Adding requests:  71%|███████▏  | 2927/4096 [00:05<00:02, 506.63it/s]
Adding requests:  73%|███████▎  | 2979/4096 [00:05<00:02, 508.81it/s]
Adding requests:  74%|███████▍  | 3030/4096 [00:06<00:02, 506.90it/s]
Adding requests:  75%|███████▌  | 3081/4096 [00:06<00:02, 504.28it/s]
Adding requests:  76%|███████▋  | 3133/4096 [00:06<00:01, 507.34it/s]
Adding requests:  78%|███████▊  | 3184/4096 [00:06<00:01, 506.18it/s]
Adding requests:  79%|███████▉  | 3236/4096 [00:06<00:01, 508.28it/s]
Adding requests:  80%|████████  | 3288/4096 [00:06<00:01, 510.83it/s]
Adding requests:  82%|████████▏ | 3340/4096 [00:06<00:01, 510.27it/s]
Adding requests:  83%|████████▎ | 3392/4096 [00:06<00:01, 509.04it/s]
Adding requests:  84%|████████▍ | 3444/4096 [00:06<00:01, 510.99it/s]
Adding requests:  85%|████████▌ | 3496/4096 [00:06<00:01, 505.36it/s]
Adding requests:  87%|████████▋ | 3547/4096 [00:07<00:01, 505.72it/s]
Adding requests:  88%|████████▊ | 3598/4096 [00:07<00:00, 505.76it/s]
Adding requests:  89%|████████▉ | 3649/4096 [00:07<00:00, 485.66it/s]
Adding requests:  90%|█████████ | 3700/4096 [00:07<00:00, 492.26it/s]
Adding requests:  92%|█████████▏| 3751/4096 [00:07<00:00, 495.20it/s]
Adding requests:  93%|█████████▎| 3804/4096 [00:07<00:00, 504.70it/s]
Adding requests:  94%|█████████▍| 3856/4096 [00:07<00:00, 508.94it/s]
Adding requests:  95%|█████████▌| 3907/4096 [00:07<00:00, 509.02it/s]
Adding requests:  97%|█████████▋| 3959/4096 [00:07<00:00, 511.49it/s]
Adding requests:  98%|█████████▊| 4011/4096 [00:07<00:00, 509.92it/s]
Adding requests:  99%|█████████▉| 4063/4096 [00:08<00:00, 504.50it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 503.19it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 665/4096 [00:00<00:02, 1390.89it/s, est. speed input: 1424342.00 toks/s, output: 1390.91 toks/s]
Processed prompts:  20%|█▉        | 805/4096 [00:02<00:10, 319.73it/s, est. speed input: 404628.42 toks/s, output: 395.14 toks/s]   
Processed prompts:  21%|██        | 868/4096 [00:02<00:13, 231.26it/s, est. speed input: 315546.15 toks/s, output: 308.15 toks/s]
Processed prompts:  22%|██▏       | 906/4096 [00:03<00:15, 203.34it/s, est. speed input: 289378.94 toks/s, output: 282.60 toks/s]
Processed prompts:  23%|██▎       | 933/4096 [00:03<00:18, 173.26it/s, est. speed input: 266258.00 toks/s, output: 260.02 toks/s]
Processed prompts:  23%|██▎       | 953/4096 [00:03<00:21, 143.30it/s, est. speed input: 245533.18 toks/s, output: 239.78 toks/s]
Processed prompts:  24%|██▍       | 985/4096 [00:04<00:24, 128.27it/s, est. speed input: 231736.01 toks/s, output: 226.30 toks/s]
Processed prompts:  25%|██▍       | 1017/4096 [00:04<00:26, 115.76it/s, est. speed input: 219683.65 toks/s, output: 214.53 toks/s]
Processed prompts:  26%|██▌       | 1049/4096 [00:05<00:28, 106.53it/s, est. speed input: 209515.06 toks/s, output: 204.60 toks/s]
Processed prompts:  26%|██▋       | 1081/4096 [00:05<00:30, 99.60it/s, est. speed input: 200694.71 toks/s, output: 195.99 toks/s] 
Processed prompts:  27%|██▋       | 1113/4096 [00:05<00:31, 94.68it/s, est. speed input: 193078.03 toks/s, output: 188.55 toks/s]
Processed prompts:  28%|██▊       | 1145/4096 [00:06<00:32, 91.85it/s, est. speed input: 186698.73 toks/s, output: 182.32 toks/s]
Processed prompts:  29%|██▊       | 1177/4096 [00:06<00:32, 88.91it/s, est. speed input: 180686.08 toks/s, output: 176.45 toks/s]
Processed prompts:  30%|██▉       | 1209/4096 [00:07<00:33, 87.08it/s, est. speed input: 175429.97 toks/s, output: 171.32 toks/s]
Processed prompts:  30%|███       | 1241/4096 [00:07<00:33, 85.89it/s, est. speed input: 170752.27 toks/s, output: 166.75 toks/s]
Processed prompts:  31%|███       | 1273/4096 [00:07<00:33, 84.84it/s, est. speed input: 166467.40 toks/s, output: 162.56 toks/s]
Processed prompts:  32%|███▏      | 1305/4096 [00:08<00:33, 84.25it/s, est. speed input: 162631.41 toks/s, output: 158.82 toks/s]
Processed prompts:  33%|███▎      | 1337/4096 [00:08<00:32, 83.69it/s, est. speed input: 159098.19 toks/s, output: 155.37 toks/s]
Processed prompts:  33%|███▎      | 1369/4096 [00:08<00:32, 83.25it/s, est. speed input: 155856.95 toks/s, output: 152.20 toks/s]
Processed prompts:  34%|███▍      | 1401/4096 [00:09<00:32, 83.16it/s, est. speed input: 152939.93 toks/s, output: 149.35 toks/s]
Processed prompts:  35%|███▍      | 1433/4096 [00:09<00:32, 82.70it/s, est. speed input: 150159.56 toks/s, output: 146.64 toks/s]
Processed prompts:  36%|███▌      | 1465/4096 [00:10<00:31, 82.61it/s, est. speed input: 147643.87 toks/s, output: 144.18 toks/s]
Processed prompts:  37%|███▋      | 1497/4096 [00:10<00:31, 82.56it/s, est. speed input: 145317.59 toks/s, output: 141.91 toks/s]
Processed prompts:  37%|███▋      | 1529/4096 [00:10<00:31, 82.43it/s, est. speed input: 143137.56 toks/s, output: 139.78 toks/s]
Processed prompts:  38%|███▊      | 1561/4096 [00:11<00:30, 82.46it/s, est. speed input: 141131.36 toks/s, output: 137.82 toks/s]
Processed prompts:  39%|███▉      | 1593/4096 [00:11<00:30, 82.36it/s, est. speed input: 139234.39 toks/s, output: 135.97 toks/s]
Processed prompts:  40%|███▉      | 1625/4096 [00:12<00:29, 82.41it/s, est. speed input: 137480.03 toks/s, output: 134.26 toks/s]
Processed prompts:  40%|████      | 1657/4096 [00:12<00:29, 82.41it/s, est. speed input: 135829.97 toks/s, output: 132.65 toks/s]
Processed prompts:  41%|████      | 1689/4096 [00:12<00:29, 82.27it/s, est. speed input: 134255.56 toks/s, output: 131.11 toks/s]
Processed prompts:  42%|████▏     | 1721/4096 [00:13<00:28, 82.28it/s, est. speed input: 132792.28 toks/s, output: 129.68 toks/s]
Processed prompts:  43%|████▎     | 1753/4096 [00:13<00:28, 82.27it/s, est. speed input: 131408.63 toks/s, output: 128.33 toks/s]
Processed prompts:  44%|████▎     | 1785/4096 [00:14<00:28, 82.31it/s, est. speed input: 130107.93 toks/s, output: 127.06 toks/s]
Processed prompts:  44%|████▍     | 1817/4096 [00:14<00:27, 82.04it/s, est. speed input: 128836.39 toks/s, output: 125.82 toks/s]
Processed prompts:  45%|████▌     | 1849/4096 [00:14<00:27, 82.22it/s, est. speed input: 127682.59 toks/s, output: 124.69 toks/s]
Processed prompts:  46%|████▌     | 1881/4096 [00:15<00:26, 82.87it/s, est. speed input: 126654.67 toks/s, output: 123.69 toks/s]
Processed prompts:  47%|████▋     | 1913/4096 [00:15<00:26, 82.64it/s, est. speed input: 125590.91 toks/s, output: 122.65 toks/s]
Processed prompts:  47%|████▋     | 1945/4096 [00:15<00:25, 83.31it/s, est. speed input: 124679.26 toks/s, output: 121.76 toks/s]
Processed prompts:  48%|████▊     | 1977/4096 [00:16<00:25, 82.94it/s, est. speed input: 123711.98 toks/s, output: 120.81 toks/s]
Processed prompts:  49%|████▉     | 2009/4096 [00:16<00:25, 82.63it/s, est. speed input: 122782.62 toks/s, output: 119.90 toks/s]
Processed prompts:  50%|████▉     | 2041/4096 [00:17<00:24, 82.55it/s, est. speed input: 121911.90 toks/s, output: 119.05 toks/s]
Processed prompts:  51%|█████     | 2073/4096 [00:17<00:24, 82.33it/s, est. speed input: 121061.72 toks/s, output: 118.22 toks/s]
Processed prompts:  51%|█████▏    | 2105/4096 [00:17<00:24, 82.34it/s, est. speed input: 120265.74 toks/s, output: 117.45 toks/s]
Processed prompts:  52%|█████▏    | 2137/4096 [00:18<00:23, 82.34it/s, est. speed input: 119502.32 toks/s, output: 116.70 toks/s]
Processed prompts:  53%|█████▎    | 2169/4096 [00:18<00:23, 82.24it/s, est. speed input: 118761.35 toks/s, output: 115.98 toks/s]
Processed prompts:  54%|█████▎    | 2201/4096 [00:19<00:23, 82.23it/s, est. speed input: 118056.22 toks/s, output: 115.29 toks/s]
Processed prompts:  55%|█████▍    | 2233/4096 [00:19<00:22, 83.57it/s, est. speed input: 117505.78 toks/s, output: 114.75 toks/s]
Processed prompts:  55%|█████▌    | 2265/4096 [00:19<00:22, 83.11it/s, est. speed input: 116847.66 toks/s, output: 114.11 toks/s]
Processed prompts:  56%|█████▌    | 2297/4096 [00:20<00:21, 83.52it/s, est. speed input: 116279.83 toks/s, output: 113.55 toks/s]
Processed prompts:  57%|█████▋    | 2329/4096 [00:20<00:21, 83.74it/s, est. speed input: 115727.44 toks/s, output: 113.01 toks/s]
Processed prompts:  58%|█████▊    | 2361/4096 [00:20<00:20, 83.28it/s, est. speed input: 115142.83 toks/s, output: 112.44 toks/s]
Processed prompts:  58%|█████▊    | 2393/4096 [00:21<00:20, 82.88it/s, est. speed input: 114572.81 toks/s, output: 111.89 toks/s]
Processed prompts:  59%|█████▉    | 2425/4096 [00:21<00:20, 82.68it/s, est. speed input: 114029.89 toks/s, output: 111.36 toks/s]
Processed prompts:  60%|█████▉    | 2457/4096 [00:22<00:19, 82.64it/s, est. speed input: 113514.04 toks/s, output: 110.85 toks/s]
Processed prompts:  61%|██████    | 2489/4096 [00:22<00:19, 83.27it/s, est. speed input: 113066.70 toks/s, output: 110.42 toks/s]
Processed prompts:  62%|██████▏   | 2521/4096 [00:22<00:18, 82.94it/s, est. speed input: 112575.44 toks/s, output: 109.94 toks/s]
Processed prompts:  62%|██████▏   | 2553/4096 [00:23<00:18, 82.60it/s, est. speed input: 112093.01 toks/s, output: 109.47 toks/s]
Processed prompts:  63%|██████▎   | 2585/4096 [00:23<00:18, 83.09it/s, est. speed input: 111678.88 toks/s, output: 109.06 toks/s]
Processed prompts:  64%|██████▍   | 2617/4096 [00:24<00:17, 82.65it/s, est. speed input: 111222.24 toks/s, output: 108.62 toks/s]
Processed prompts:  65%|██████▍   | 2649/4096 [00:24<00:17, 82.54it/s, est. speed input: 110793.81 toks/s, output: 108.20 toks/s]
Processed prompts:  65%|██████▌   | 2681/4096 [00:24<00:17, 82.23it/s, est. speed input: 110363.04 toks/s, output: 107.78 toks/s]
Processed prompts:  66%|██████▌   | 2713/4096 [00:25<00:16, 82.26it/s, est. speed input: 109962.31 toks/s, output: 107.38 toks/s]
Processed prompts:  67%|██████▋   | 2745/4096 [00:25<00:16, 82.07it/s, est. speed input: 109558.82 toks/s, output: 106.99 toks/s]
Processed prompts:  68%|██████▊   | 2777/4096 [00:26<00:16, 82.08it/s, est. speed input: 109177.47 toks/s, output: 106.62 toks/s]
Processed prompts:  69%|██████▊   | 2809/4096 [00:26<00:15, 82.08it/s, est. speed input: 108807.23 toks/s, output: 106.26 toks/s]
Processed prompts:  69%|██████▉   | 2841/4096 [00:26<00:15, 82.03it/s, est. speed input: 108443.93 toks/s, output: 105.90 toks/s]
Processed prompts:  70%|███████   | 2873/4096 [00:27<00:14, 81.99it/s, est. speed input: 108091.34 toks/s, output: 105.56 toks/s]
Processed prompts:  71%|███████   | 2905/4096 [00:27<00:14, 81.99it/s, est. speed input: 107749.85 toks/s, output: 105.22 toks/s]
Processed prompts:  72%|███████▏  | 2937/4096 [00:27<00:14, 82.00it/s, est. speed input: 107419.13 toks/s, output: 104.90 toks/s]
Processed prompts:  72%|███████▏  | 2969/4096 [00:28<00:13, 81.87it/s, est. speed input: 107088.88 toks/s, output: 104.58 toks/s]
Processed prompts:  73%|███████▎  | 3001/4096 [00:28<00:13, 81.98it/s, est. speed input: 106779.24 toks/s, output: 104.28 toks/s]
Processed prompts:  74%|███████▍  | 3033/4096 [00:29<00:12, 81.92it/s, est. speed input: 106470.48 toks/s, output: 103.97 toks/s]
Processed prompts:  75%|███████▍  | 3065/4096 [00:29<00:12, 81.80it/s, est. speed input: 106165.39 toks/s, output: 103.68 toks/s]
Processed prompts:  76%|███████▌  | 3097/4096 [00:29<00:12, 81.84it/s, est. speed input: 105874.82 toks/s, output: 103.39 toks/s]
Processed prompts:  76%|███████▋  | 3129/4096 [00:30<00:11, 82.43it/s, est. speed input: 105623.16 toks/s, output: 103.15 toks/s]
Processed prompts:  77%|███████▋  | 3161/4096 [00:30<00:11, 82.36it/s, est. speed input: 105351.00 toks/s, output: 102.88 toks/s]
Processed prompts:  78%|███████▊  | 3193/4096 [00:31<00:11, 82.02it/s, est. speed input: 105070.33 toks/s, output: 102.61 toks/s]
Processed prompts:  79%|███████▊  | 3225/4096 [00:31<00:10, 81.90it/s, est. speed input: 104803.11 toks/s, output: 102.35 toks/s]
Processed prompts:  80%|███████▉  | 3257/4096 [00:31<00:10, 81.95it/s, est. speed input: 104549.04 toks/s, output: 102.10 toks/s]
Processed prompts:  80%|████████  | 3289/4096 [00:32<00:09, 81.77it/s, est. speed input: 104290.35 toks/s, output: 101.85 toks/s]
Processed prompts:  81%|████████  | 3321/4096 [00:32<00:09, 81.86it/s, est. speed input: 104049.01 toks/s, output: 101.61 toks/s]
Processed prompts:  82%|████████▏ | 3353/4096 [00:33<00:09, 81.79it/s, est. speed input: 103806.19 toks/s, output: 101.37 toks/s]
Processed prompts:  83%|████████▎ | 3385/4096 [00:33<00:08, 81.77it/s, est. speed input: 103570.80 toks/s, output: 101.14 toks/s]
Processed prompts:  83%|████████▎ | 3417/4096 [00:33<00:08, 81.83it/s, est. speed input: 103344.28 toks/s, output: 100.92 toks/s]
Processed prompts:  84%|████████▍ | 3449/4096 [00:34<00:07, 81.67it/s, est. speed input: 103113.52 toks/s, output: 100.70 toks/s]
Processed prompts:  85%|████████▍ | 3481/4096 [00:34<00:07, 81.74it/s, est. speed input: 102896.33 toks/s, output: 100.48 toks/s]
Processed prompts:  86%|████████▌ | 3513/4096 [00:35<00:07, 81.60it/s, est. speed input: 102675.27 toks/s, output: 100.27 toks/s]
Processed prompts:  87%|████████▋ | 3545/4096 [00:35<00:06, 81.64it/s, est. speed input: 102465.71 toks/s, output: 100.06 toks/s]
Processed prompts:  87%|████████▋ | 3577/4096 [00:35<00:06, 81.75it/s, est. speed input: 102264.05 toks/s, output: 99.87 toks/s] 
Processed prompts:  88%|████████▊ | 3609/4096 [00:36<00:05, 81.58it/s, est. speed input: 102055.95 toks/s, output: 99.66 toks/s]
Processed prompts:  89%|████████▉ | 3641/4096 [00:36<00:05, 81.57it/s, est. speed input: 101857.03 toks/s, output: 99.47 toks/s]
Processed prompts:  90%|████████▉ | 3673/4096 [00:36<00:05, 81.58it/s, est. speed input: 101663.27 toks/s, output: 99.28 toks/s]
Processed prompts:  90%|█████████ | 3705/4096 [00:37<00:04, 81.60it/s, est. speed input: 101473.69 toks/s, output: 99.10 toks/s]
Processed prompts:  91%|█████████ | 3737/4096 [00:37<00:04, 82.34it/s, est. speed input: 101319.45 toks/s, output: 98.94 toks/s]
Processed prompts:  92%|█████████▏| 3769/4096 [00:38<00:03, 82.27it/s, est. speed input: 101143.26 toks/s, output: 98.77 toks/s]
Processed prompts:  93%|█████████▎| 3801/4096 [00:38<00:03, 81.93it/s, est. speed input: 100958.64 toks/s, output: 98.59 toks/s]
Processed prompts:  94%|█████████▎| 3833/4096 [00:38<00:03, 81.90it/s, est. speed input: 100786.33 toks/s, output: 98.42 toks/s]
Processed prompts:  94%|█████████▍| 3865/4096 [00:39<00:02, 81.68it/s, est. speed input: 100609.17 toks/s, output: 98.25 toks/s]
Processed prompts:  95%|█████████▌| 3897/4096 [00:39<00:02, 81.55it/s, est. speed input: 100436.48 toks/s, output: 98.08 toks/s]
Processed prompts:  96%|█████████▌| 3929/4096 [00:40<00:02, 81.66it/s, est. speed input: 100275.53 toks/s, output: 97.93 toks/s]
Processed prompts:  97%|█████████▋| 3961/4096 [00:40<00:01, 81.58it/s, est. speed input: 100111.24 toks/s, output: 97.76 toks/s]
Processed prompts:  97%|█████████▋| 3993/4096 [00:40<00:01, 81.64it/s, est. speed input: 99954.45 toks/s, output: 97.61 toks/s] 
Processed prompts:  98%|█████████▊| 4025/4096 [00:41<00:00, 82.24it/s, est. speed input: 99822.59 toks/s, output: 97.48 toks/s]
Processed prompts:  99%|█████████▉| 4057/4096 [00:41<00:00, 82.17it/s, est. speed input: 99674.10 toks/s, output: 97.34 toks/s]
Processed prompts: 100%|█████████▉| 4089/4096 [00:41<00:00, 105.23it/s, est. speed input: 100207.90 toks/s, output: 97.86 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:41<00:00, 105.23it/s, est. speed input: 100378.49 toks/s, output: 98.03 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:41<00:00, 98.03it/s, est. speed input: 100378.49 toks/s, output: 98.03 toks/s] 
[rank0]:[W126 10:29:37.219008232 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:29:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:30:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1216010) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1216010) WARNING 01-26 10:30:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 82.02 requests/s, 84072.51 total tokens/s, 82.02 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:30:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:30:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:30:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:30:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:30:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:30:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:30:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:30:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:30:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:30:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:30:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:30:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:30:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:30:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:30:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:30:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:30:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1216010) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1216010) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1216010) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=1216010) 
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1216010) [2026-01-26 10:30:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21012480 bytes
(EngineCore_DP0 pid=1216010) [rank0]:W0126 10:30:41.884000 1216010 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1216010) [rank0]:W0126 10:30:41.970000 1216010 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1216010) [rank0]:W0126 10:30:42.846000 1216010 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1216010) [rank0]:W0126 10:30:42.976000 1216010 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1216010) 2026-01-26 10:30:46,966 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1216010) 2026-01-26 10:30:46,993 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1216010) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:18,  1.03s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:10,  1.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:04,  3.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  5.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  7.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:00,  9.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:00, 11.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:02<00:00,  8.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:03<00:00,  5.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:03<00:00,  6.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.92it/s]
(EngineCore_DP0 pid=1216010) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 18.78it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 12.79it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 14.45it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 10.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 10.94it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 11.62it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 48/8192 [00:00<00:17, 475.10it/s]
Adding requests:   1%|          | 97/8192 [00:00<00:16, 482.94it/s]
Adding requests:   2%|▏         | 146/8192 [00:00<00:16, 484.18it/s]
Adding requests:   2%|▏         | 195/8192 [00:00<00:16, 482.08it/s]
Adding requests:   3%|▎         | 246/8192 [00:00<00:16, 489.54it/s]
Adding requests:   4%|▎         | 296/8192 [00:00<00:16, 490.57it/s]
Adding requests:   4%|▍         | 346/8192 [00:00<00:16, 487.41it/s]
Adding requests:   5%|▍         | 397/8192 [00:00<00:15, 493.28it/s]
Adding requests:   5%|▌         | 447/8192 [00:00<00:15, 492.15it/s]
Adding requests:   6%|▌         | 497/8192 [00:01<00:15, 492.53it/s]
Adding requests:   7%|▋         | 547/8192 [00:01<00:15, 484.79it/s]
Adding requests:   7%|▋         | 598/8192 [00:01<00:15, 491.64it/s]
Adding requests:   8%|▊         | 648/8192 [00:01<00:15, 488.87it/s]
Adding requests:   9%|▊         | 700/8192 [00:01<00:15, 496.84it/s]
Adding requests:   9%|▉         | 750/8192 [00:01<00:14, 496.23it/s]
Adding requests:  10%|▉         | 800/8192 [00:01<00:14, 494.54it/s]
Adding requests:  10%|█         | 850/8192 [00:01<00:15, 487.23it/s]
Adding requests:  11%|█         | 902/8192 [00:01<00:14, 495.77it/s]
Adding requests:  12%|█▏        | 952/8192 [00:01<00:14, 496.49it/s]
Adding requests:  12%|█▏        | 1003/8192 [00:02<00:14, 499.35it/s]
Adding requests:  13%|█▎        | 1054/8192 [00:02<00:14, 501.78it/s]
Adding requests:  13%|█▎        | 1105/8192 [00:02<00:14, 497.41it/s]
Adding requests:  14%|█▍        | 1155/8192 [00:02<00:14, 497.96it/s]
Adding requests:  15%|█▍        | 1208/8192 [00:02<00:13, 507.22it/s]
Adding requests:  15%|█▌        | 1259/8192 [00:02<00:13, 502.06it/s]
Adding requests:  16%|█▌        | 1310/8192 [00:02<00:13, 502.13it/s]
Adding requests:  17%|█▋        | 1362/8192 [00:02<00:13, 504.65it/s]
Adding requests:  17%|█▋        | 1414/8192 [00:02<00:13, 509.16it/s]
Adding requests:  18%|█▊        | 1465/8192 [00:02<00:13, 509.13it/s]
Adding requests:  19%|█▊        | 1516/8192 [00:03<00:13, 509.03it/s]
Adding requests:  19%|█▉        | 1568/8192 [00:03<00:13, 509.48it/s]
Adding requests:  20%|█▉        | 1620/8192 [00:03<00:12, 512.00it/s]
Adding requests:  20%|██        | 1672/8192 [00:03<00:12, 507.74it/s]
Adding requests:  21%|██        | 1724/8192 [00:03<00:12, 510.95it/s]
Adding requests:  22%|██▏       | 1776/8192 [00:03<00:12, 496.49it/s]
Adding requests:  22%|██▏       | 1827/8192 [00:03<00:12, 499.84it/s]
Adding requests:  23%|██▎       | 1878/8192 [00:03<00:12, 500.81it/s]
Adding requests:  24%|██▎       | 1929/8192 [00:03<00:12, 501.41it/s]
Adding requests:  24%|██▍       | 1980/8192 [00:03<00:12, 502.38it/s]
Adding requests:  25%|██▍       | 2032/8192 [00:04<00:12, 506.76it/s]
Adding requests:  25%|██▌       | 2084/8192 [00:04<00:12, 508.26it/s]
Adding requests:  26%|██▌       | 2135/8192 [00:04<00:12, 503.79it/s]
Adding requests:  27%|██▋       | 2186/8192 [00:04<00:12, 498.11it/s]
Adding requests:  27%|██▋       | 2238/8192 [00:04<00:11, 504.38it/s]
Adding requests:  28%|██▊       | 2289/8192 [00:04<00:11, 501.66it/s]
Adding requests:  29%|██▊       | 2340/8192 [00:04<00:11, 503.12it/s]
Adding requests:  29%|██▉       | 2392/8192 [00:04<00:11, 505.78it/s]
Adding requests:  30%|██▉       | 2443/8192 [00:04<00:11, 505.69it/s]
Adding requests:  30%|███       | 2494/8192 [00:04<00:11, 506.16it/s]
Adding requests:  31%|███       | 2545/8192 [00:05<00:11, 505.61it/s]
Adding requests:  32%|███▏      | 2597/8192 [00:05<00:11, 508.62it/s]
Adding requests:  32%|███▏      | 2648/8192 [00:05<00:10, 508.99it/s]
Adding requests:  33%|███▎      | 2699/8192 [00:05<00:10, 507.00it/s]
Adding requests:  34%|███▎      | 2750/8192 [00:05<00:10, 504.65it/s]
Adding requests:  34%|███▍      | 2801/8192 [00:05<00:10, 503.06it/s]
Adding requests:  35%|███▍      | 2852/8192 [00:05<00:10, 504.16it/s]
Adding requests:  35%|███▌      | 2904/8192 [00:05<00:10, 506.79it/s]
Adding requests:  36%|███▌      | 2955/8192 [00:05<00:10, 501.14it/s]
Adding requests:  37%|███▋      | 3006/8192 [00:06<00:10, 502.75it/s]
Adding requests:  37%|███▋      | 3057/8192 [00:06<00:10, 503.82it/s]
Adding requests:  38%|███▊      | 3108/8192 [00:06<00:10, 487.96it/s]
Adding requests:  39%|███▊      | 3159/8192 [00:06<00:10, 492.88it/s]
Adding requests:  39%|███▉      | 3209/8192 [00:06<00:10, 494.50it/s]
Adding requests:  40%|███▉      | 3261/8192 [00:06<00:09, 500.29it/s]
Adding requests:  40%|████      | 3312/8192 [00:06<00:09, 502.44it/s]
Adding requests:  41%|████      | 3365/8192 [00:06<00:09, 507.66it/s]
Adding requests:  42%|████▏     | 3416/8192 [00:06<00:09, 507.26it/s]
Adding requests:  42%|████▏     | 3467/8192 [00:06<00:09, 501.13it/s]
Adding requests:  43%|████▎     | 3518/8192 [00:07<00:09, 500.50it/s]
Adding requests:  44%|████▎     | 3569/8192 [00:07<00:09, 497.71it/s]
Adding requests:  44%|████▍     | 3619/8192 [00:07<00:09, 498.24it/s]
Adding requests:  45%|████▍     | 3670/8192 [00:07<00:09, 499.53it/s]
Adding requests:  45%|████▌     | 3720/8192 [00:07<00:08, 498.80it/s]
Adding requests:  46%|████▌     | 3772/8192 [00:07<00:08, 503.89it/s]
Adding requests:  47%|████▋     | 3824/8192 [00:07<00:08, 507.08it/s]
Adding requests:  47%|████▋     | 3876/8192 [00:07<00:08, 509.77it/s]
Adding requests:  48%|████▊     | 3927/8192 [00:07<00:08, 508.03it/s]
Adding requests:  49%|████▊     | 3978/8192 [00:07<00:08, 507.17it/s]
Adding requests:  49%|████▉     | 4029/8192 [00:08<00:08, 504.83it/s]
Adding requests:  50%|████▉     | 4080/8192 [00:08<00:08, 499.81it/s]
Adding requests:  50%|█████     | 4132/8192 [00:08<00:08, 505.48it/s]
Adding requests:  51%|█████     | 4183/8192 [00:08<00:07, 506.48it/s]
Adding requests:  52%|█████▏    | 4234/8192 [00:08<00:07, 506.24it/s]
Adding requests:  52%|█████▏    | 4285/8192 [00:08<00:07, 506.04it/s]
Adding requests:  53%|█████▎    | 4337/8192 [00:08<00:07, 509.43it/s]
Adding requests:  54%|█████▎    | 4389/8192 [00:08<00:07, 511.71it/s]
Adding requests:  54%|█████▍    | 4441/8192 [00:08<00:07, 497.64it/s]
Adding requests:  55%|█████▍    | 4491/8192 [00:08<00:07, 496.97it/s]
Adding requests:  55%|█████▌    | 4541/8192 [00:09<00:07, 497.08it/s]
Adding requests:  56%|█████▌    | 4593/8192 [00:09<00:07, 501.53it/s]
Adding requests:  57%|█████▋    | 4645/8192 [00:09<00:07, 506.64it/s]
Adding requests:  57%|█████▋    | 4696/8192 [00:09<00:06, 501.62it/s]
Adding requests:  58%|█████▊    | 4748/8192 [00:09<00:06, 506.07it/s]
Adding requests:  59%|█████▊    | 4799/8192 [00:09<00:06, 503.35it/s]
Adding requests:  59%|█████▉    | 4850/8192 [00:09<00:06, 504.66it/s]
Adding requests:  60%|█████▉    | 4901/8192 [00:09<00:06, 499.77it/s]
Adding requests:  60%|██████    | 4953/8192 [00:09<00:06, 503.68it/s]
Adding requests:  61%|██████    | 5004/8192 [00:09<00:06, 502.84it/s]
Adding requests:  62%|██████▏   | 5056/8192 [00:10<00:06, 507.17it/s]
Adding requests:  62%|██████▏   | 5109/8192 [00:10<00:06, 510.95it/s]
Adding requests:  63%|██████▎   | 5161/8192 [00:10<00:05, 511.61it/s]
Adding requests:  64%|██████▎   | 5213/8192 [00:10<00:05, 508.52it/s]
Adding requests:  64%|██████▍   | 5264/8192 [00:10<00:05, 504.58it/s]
Adding requests:  65%|██████▍   | 5316/8192 [00:10<00:05, 507.30it/s]
Adding requests:  66%|██████▌   | 5368/8192 [00:10<00:05, 509.65it/s]
Adding requests:  66%|██████▌   | 5419/8192 [00:10<00:05, 507.38it/s]
Adding requests:  67%|██████▋   | 5470/8192 [00:10<00:05, 503.80it/s]
Adding requests:  67%|██████▋   | 5521/8192 [00:11<00:05, 501.17it/s]
Adding requests:  68%|██████▊   | 5572/8192 [00:11<00:05, 500.15it/s]
Adding requests:  69%|██████▊   | 5623/8192 [00:11<00:05, 499.95it/s]
Adding requests:  69%|██████▉   | 5673/8192 [00:11<00:05, 497.42it/s]
Adding requests:  70%|██████▉   | 5725/8192 [00:11<00:04, 503.03it/s]
Adding requests:  71%|███████   | 5776/8192 [00:11<00:04, 493.54it/s]
Adding requests:  71%|███████   | 5826/8192 [00:11<00:04, 491.05it/s]
Adding requests:  72%|███████▏  | 5878/8192 [00:11<00:04, 496.67it/s]
Adding requests:  72%|███████▏  | 5929/8192 [00:11<00:04, 500.18it/s]
Adding requests:  73%|███████▎  | 5980/8192 [00:11<00:04, 502.41it/s]
Adding requests:  74%|███████▎  | 6032/8192 [00:12<00:04, 505.44it/s]
Adding requests:  74%|███████▍  | 6083/8192 [00:12<00:04, 504.76it/s]
Adding requests:  75%|███████▍  | 6134/8192 [00:12<00:04, 504.89it/s]
Adding requests:  76%|███████▌  | 6185/8192 [00:12<00:03, 505.59it/s]
Adding requests:  76%|███████▌  | 6238/8192 [00:12<00:03, 510.93it/s]
Adding requests:  77%|███████▋  | 6290/8192 [00:12<00:03, 513.62it/s]
Adding requests:  77%|███████▋  | 6342/8192 [00:12<00:03, 514.77it/s]
Adding requests:  78%|███████▊  | 6394/8192 [00:12<00:03, 514.55it/s]
Adding requests:  79%|███████▊  | 6447/8192 [00:12<00:03, 517.38it/s]
Adding requests:  79%|███████▉  | 6500/8192 [00:12<00:03, 518.69it/s]
Adding requests:  80%|███████▉  | 6552/8192 [00:13<00:03, 517.20it/s]
Adding requests:  81%|████████  | 6604/8192 [00:13<00:03, 513.61it/s]
Adding requests:  81%|████████▏ | 6656/8192 [00:13<00:02, 513.20it/s]
Adding requests:  82%|████████▏ | 6708/8192 [00:13<00:02, 511.04it/s]
Adding requests:  83%|████████▎ | 6760/8192 [00:13<00:02, 508.42it/s]
Adding requests:  83%|████████▎ | 6812/8192 [00:13<00:02, 511.50it/s]
Adding requests:  84%|████████▍ | 6864/8192 [00:13<00:02, 513.85it/s]
Adding requests:  84%|████████▍ | 6917/8192 [00:13<00:02, 515.69it/s]
Adding requests:  85%|████████▌ | 6970/8192 [00:13<00:02, 518.46it/s]
Adding requests:  86%|████████▌ | 7022/8192 [00:13<00:02, 510.24it/s]
Adding requests:  86%|████████▋ | 7074/8192 [00:14<00:02, 509.53it/s]
Adding requests:  87%|████████▋ | 7125/8192 [00:14<00:02, 498.58it/s]
Adding requests:  88%|████████▊ | 7175/8192 [00:14<00:02, 497.19it/s]
Adding requests:  88%|████████▊ | 7227/8192 [00:14<00:01, 501.59it/s]
Adding requests:  89%|████████▉ | 7279/8192 [00:14<00:01, 505.87it/s]
Adding requests:  89%|████████▉ | 7331/8192 [00:14<00:01, 508.43it/s]
Adding requests:  90%|█████████ | 7382/8192 [00:14<00:01, 507.61it/s]
Adding requests:  91%|█████████ | 7436/8192 [00:14<00:01, 516.55it/s]
Adding requests:  91%|█████████▏| 7488/8192 [00:14<00:01, 515.88it/s]
Adding requests:  92%|█████████▏| 7540/8192 [00:14<00:01, 513.96it/s]
Adding requests:  93%|█████████▎| 7592/8192 [00:15<00:01, 510.97it/s]
Adding requests:  93%|█████████▎| 7644/8192 [00:15<00:01, 511.49it/s]
Adding requests:  94%|█████████▍| 7697/8192 [00:15<00:00, 514.89it/s]
Adding requests:  95%|█████████▍| 7749/8192 [00:15<00:00, 512.52it/s]
Adding requests:  95%|█████████▌| 7801/8192 [00:15<00:00, 505.06it/s]
Adding requests:  96%|█████████▌| 7853/8192 [00:15<00:00, 509.19it/s]
Adding requests:  96%|█████████▋| 7904/8192 [00:15<00:00, 504.44it/s]
Adding requests:  97%|█████████▋| 7955/8192 [00:15<00:00, 502.52it/s]
Adding requests:  98%|█████████▊| 8006/8192 [00:15<00:00, 502.48it/s]
Adding requests:  98%|█████████▊| 8057/8192 [00:15<00:00, 503.29it/s]
Adding requests:  99%|█████████▉| 8109/8192 [00:16<00:00, 507.15it/s]
Adding requests: 100%|█████████▉| 8160/8192 [00:16<00:00, 507.60it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 503.86it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 1271/8192 [00:00<00:02, 3220.92it/s, est. speed input: 3298421.11 toks/s, output: 3220.98 toks/s]
Processed prompts:  19%|█▉        | 1594/8192 [00:04<00:22, 293.63it/s, est. speed input: 384204.84 toks/s, output: 375.20 toks/s]   
Processed prompts:  21%|██        | 1732/8192 [00:05<00:29, 222.48it/s, est. speed input: 306146.60 toks/s, output: 298.97 toks/s]
Processed prompts:  22%|██▏       | 1811/8192 [00:06<00:32, 198.55it/s, est. speed input: 282459.63 toks/s, output: 275.84 toks/s]
Processed prompts:  23%|██▎       | 1863/8192 [00:07<00:37, 170.13it/s, est. speed input: 260461.61 toks/s, output: 254.36 toks/s]
Processed prompts:  23%|██▎       | 1911/8192 [00:08<00:43, 144.58it/s, est. speed input: 242006.56 toks/s, output: 236.33 toks/s]
Processed prompts:  24%|██▍       | 1975/8192 [00:08<00:48, 128.76it/s, est. speed input: 228320.64 toks/s, output: 222.97 toks/s]
Processed prompts:  25%|██▍       | 2039/8192 [00:09<00:52, 116.52it/s, est. speed input: 216862.22 toks/s, output: 211.78 toks/s]
Processed prompts:  26%|██▌       | 2103/8192 [00:10<00:56, 107.06it/s, est. speed input: 206992.00 toks/s, output: 202.14 toks/s]
Processed prompts:  26%|██▋       | 2167/8192 [00:11<01:00, 100.28it/s, est. speed input: 198588.49 toks/s, output: 193.93 toks/s]
Processed prompts:  27%|██▋       | 2231/8192 [00:11<01:02, 95.82it/s, est. speed input: 191486.75 toks/s, output: 187.00 toks/s] 
Processed prompts:  28%|██▊       | 2295/8192 [00:12<01:03, 92.77it/s, est. speed input: 185315.50 toks/s, output: 180.97 toks/s]
Processed prompts:  29%|██▉       | 2359/8192 [00:13<01:05, 89.71it/s, est. speed input: 179500.08 toks/s, output: 175.29 toks/s]
Processed prompts:  30%|██▉       | 2423/8192 [00:14<01:05, 87.64it/s, est. speed input: 174351.47 toks/s, output: 170.26 toks/s]
Processed prompts:  30%|███       | 2487/8192 [00:14<01:05, 86.54it/s, est. speed input: 169853.80 toks/s, output: 165.87 toks/s]
Processed prompts:  31%|███       | 2551/8192 [00:15<01:05, 85.84it/s, est. speed input: 165815.31 toks/s, output: 161.93 toks/s]
Processed prompts:  32%|███▏      | 2615/8192 [00:16<01:05, 84.82it/s, est. speed input: 161996.04 toks/s, output: 158.20 toks/s]
Processed prompts:  33%|███▎      | 2679/8192 [00:17<01:05, 84.18it/s, est. speed input: 158537.21 toks/s, output: 154.82 toks/s]
Processed prompts:  33%|███▎      | 2743/8192 [00:18<01:05, 83.72it/s, est. speed input: 155371.88 toks/s, output: 151.73 toks/s]
Processed prompts:  34%|███▍      | 2807/8192 [00:18<01:04, 83.35it/s, est. speed input: 152454.95 toks/s, output: 148.88 toks/s]
Processed prompts:  35%|███▌      | 2871/8192 [00:19<01:03, 83.14it/s, est. speed input: 149779.52 toks/s, output: 146.27 toks/s]
Processed prompts:  36%|███▌      | 2935/8192 [00:20<01:03, 82.92it/s, est. speed input: 147290.93 toks/s, output: 143.84 toks/s]
Processed prompts:  37%|███▋      | 2999/8192 [00:21<01:02, 82.73it/s, est. speed input: 144976.21 toks/s, output: 141.58 toks/s]
Processed prompts:  37%|███▋      | 3063/8192 [00:21<01:01, 82.73it/s, est. speed input: 142853.54 toks/s, output: 139.51 toks/s]
Processed prompts:  38%|███▊      | 3127/8192 [00:22<01:01, 82.99it/s, est. speed input: 140924.96 toks/s, output: 137.62 toks/s]
Processed prompts:  39%|███▉      | 3191/8192 [00:23<01:00, 82.85it/s, est. speed input: 139062.30 toks/s, output: 135.80 toks/s]
Processed prompts:  40%|███▉      | 3255/8192 [00:24<00:59, 82.66it/s, est. speed input: 137302.24 toks/s, output: 134.08 toks/s]
Processed prompts:  41%|████      | 3319/8192 [00:25<00:58, 82.62it/s, est. speed input: 135668.32 toks/s, output: 132.49 toks/s]
Processed prompts:  41%|████▏     | 3383/8192 [00:25<00:58, 82.57it/s, est. speed input: 134128.00 toks/s, output: 130.98 toks/s]
Processed prompts:  42%|████▏     | 3447/8192 [00:26<00:57, 82.48it/s, est. speed input: 132669.65 toks/s, output: 129.56 toks/s]
Processed prompts:  43%|████▎     | 3511/8192 [00:27<00:56, 82.45it/s, est. speed input: 131298.99 toks/s, output: 128.22 toks/s]
Processed prompts:  44%|████▎     | 3575/8192 [00:28<00:56, 82.41it/s, est. speed input: 130001.65 toks/s, output: 126.95 toks/s]
Processed prompts:  44%|████▍     | 3639/8192 [00:28<00:55, 82.41it/s, est. speed input: 128777.07 toks/s, output: 125.76 toks/s]
Processed prompts:  45%|████▌     | 3703/8192 [00:29<00:54, 82.69it/s, est. speed input: 127654.70 toks/s, output: 124.66 toks/s]
Processed prompts:  46%|████▌     | 3767/8192 [00:30<00:53, 82.58it/s, est. speed input: 126548.84 toks/s, output: 123.58 toks/s]
Processed prompts:  47%|████▋     | 3831/8192 [00:31<00:52, 82.55it/s, est. speed input: 125503.80 toks/s, output: 122.56 toks/s]
Processed prompts:  48%|████▊     | 3895/8192 [00:32<00:52, 82.46it/s, est. speed input: 124501.30 toks/s, output: 121.58 toks/s]
Processed prompts:  48%|████▊     | 3959/8192 [00:32<00:51, 82.44it/s, est. speed input: 123550.81 toks/s, output: 120.65 toks/s]
Processed prompts:  49%|████▉     | 4023/8192 [00:33<00:50, 82.73it/s, est. speed input: 122680.19 toks/s, output: 119.80 toks/s]
Processed prompts:  50%|████▉     | 4087/8192 [00:34<00:49, 82.52it/s, est. speed input: 121801.30 toks/s, output: 118.95 toks/s]
Processed prompts:  51%|█████     | 4151/8192 [00:35<00:49, 82.39it/s, est. speed input: 120963.99 toks/s, output: 118.13 toks/s]
Processed prompts:  51%|█████▏    | 4215/8192 [00:35<00:47, 83.02it/s, est. speed input: 120238.47 toks/s, output: 117.42 toks/s]
Processed prompts:  52%|█████▏    | 4279/8192 [00:36<00:47, 83.17it/s, est. speed input: 119513.37 toks/s, output: 116.71 toks/s]
Processed prompts:  53%|█████▎    | 4343/8192 [00:37<00:46, 82.88it/s, est. speed input: 118778.34 toks/s, output: 115.99 toks/s]
Processed prompts:  54%|█████▍    | 4407/8192 [00:38<00:45, 82.64it/s, est. speed input: 118070.13 toks/s, output: 115.30 toks/s]
Processed prompts:  55%|█████▍    | 4471/8192 [00:39<00:45, 82.49it/s, est. speed input: 117391.73 toks/s, output: 114.64 toks/s]
Processed prompts:  55%|█████▌    | 4535/8192 [00:39<00:44, 82.36it/s, est. speed input: 116737.59 toks/s, output: 114.00 toks/s]
Processed prompts:  56%|█████▌    | 4599/8192 [00:40<00:43, 82.27it/s, est. speed input: 116108.25 toks/s, output: 113.39 toks/s]
Processed prompts:  57%|█████▋    | 4663/8192 [00:41<00:42, 82.20it/s, est. speed input: 115502.37 toks/s, output: 112.80 toks/s]
Processed prompts:  58%|█████▊    | 4727/8192 [00:42<00:41, 82.51it/s, est. speed input: 114949.76 toks/s, output: 112.26 toks/s]
Processed prompts:  58%|█████▊    | 4791/8192 [00:42<00:41, 82.33it/s, est. speed input: 114383.76 toks/s, output: 111.70 toks/s]
Processed prompts:  59%|█████▉    | 4855/8192 [00:43<00:40, 82.73it/s, est. speed input: 113880.76 toks/s, output: 111.21 toks/s]
Processed prompts:  60%|██████    | 4919/8192 [00:44<00:39, 82.36it/s, est. speed input: 113343.42 toks/s, output: 110.69 toks/s]
Processed prompts:  61%|██████    | 4983/8192 [00:45<00:38, 82.62it/s, est. speed input: 112865.14 toks/s, output: 110.22 toks/s]
Processed prompts:  62%|██████▏   | 5047/8192 [00:45<00:38, 82.43it/s, est. speed input: 112375.05 toks/s, output: 109.74 toks/s]
Processed prompts:  62%|██████▏   | 5111/8192 [00:46<00:37, 82.34it/s, est. speed input: 111904.00 toks/s, output: 109.28 toks/s]
Processed prompts:  63%|██████▎   | 5175/8192 [00:47<00:36, 82.21it/s, est. speed input: 111443.56 toks/s, output: 108.83 toks/s]
Processed prompts:  64%|██████▍   | 5239/8192 [00:48<00:35, 82.20it/s, est. speed input: 111003.78 toks/s, output: 108.40 toks/s]
Processed prompts:  65%|██████▍   | 5303/8192 [00:49<00:35, 82.04it/s, est. speed input: 110566.95 toks/s, output: 107.98 toks/s]
Processed prompts:  66%|██████▌   | 5367/8192 [00:49<00:34, 82.00it/s, est. speed input: 110148.96 toks/s, output: 107.57 toks/s]
Processed prompts:  66%|██████▋   | 5431/8192 [00:50<00:33, 81.96it/s, est. speed input: 109742.70 toks/s, output: 107.17 toks/s]
Processed prompts:  67%|██████▋   | 5495/8192 [00:51<00:32, 81.92it/s, est. speed input: 109348.36 toks/s, output: 106.79 toks/s]
Processed prompts:  68%|██████▊   | 5559/8192 [00:52<00:32, 82.24it/s, est. speed input: 108988.83 toks/s, output: 106.43 toks/s]
Processed prompts:  69%|██████▊   | 5623/8192 [00:53<00:31, 82.17it/s, est. speed input: 108620.37 toks/s, output: 106.07 toks/s]
Processed prompts:  69%|██████▉   | 5687/8192 [00:53<00:30, 82.21it/s, est. speed input: 108268.47 toks/s, output: 105.73 toks/s]
Processed prompts:  70%|███████   | 5751/8192 [00:54<00:29, 82.10it/s, est. speed input: 107918.08 toks/s, output: 105.39 toks/s]
Processed prompts:  71%|███████   | 5815/8192 [00:55<00:29, 81.95it/s, est. speed input: 107573.14 toks/s, output: 105.05 toks/s]
Processed prompts:  72%|███████▏  | 5879/8192 [00:56<00:28, 81.88it/s, est. speed input: 107239.45 toks/s, output: 104.73 toks/s]
Processed prompts:  73%|███████▎  | 5943/8192 [00:56<00:27, 81.81it/s, est. speed input: 106913.82 toks/s, output: 104.41 toks/s]
Processed prompts:  73%|███████▎  | 6007/8192 [00:57<00:26, 81.83it/s, est. speed input: 106601.52 toks/s, output: 104.10 toks/s]
Processed prompts:  74%|███████▍  | 6071/8192 [00:58<00:25, 81.86it/s, est. speed input: 106298.33 toks/s, output: 103.81 toks/s]
Processed prompts:  75%|███████▍  | 6135/8192 [00:59<00:25, 81.85it/s, est. speed input: 106001.21 toks/s, output: 103.52 toks/s]
Processed prompts:  76%|███████▌  | 6199/8192 [01:00<00:24, 81.82it/s, est. speed input: 105710.50 toks/s, output: 103.23 toks/s]
Processed prompts:  76%|███████▋  | 6263/8192 [01:00<00:23, 81.74it/s, est. speed input: 105424.32 toks/s, output: 102.95 toks/s]
Processed prompts:  77%|███████▋  | 6327/8192 [01:01<00:22, 81.75it/s, est. speed input: 105148.58 toks/s, output: 102.68 toks/s]
Processed prompts:  78%|███████▊  | 6391/8192 [01:02<00:22, 81.70it/s, est. speed input: 104877.17 toks/s, output: 102.42 toks/s]
Processed prompts:  79%|███████▉  | 6455/8192 [01:03<00:21, 81.67it/s, est. speed input: 104612.38 toks/s, output: 102.16 toks/s]
Processed prompts:  80%|███████▉  | 6519/8192 [01:03<00:20, 81.71it/s, est. speed input: 104357.47 toks/s, output: 101.91 toks/s]
Processed prompts:  80%|████████  | 6583/8192 [01:04<00:19, 82.15it/s, est. speed input: 104129.73 toks/s, output: 101.69 toks/s]
Processed prompts:  81%|████████  | 6647/8192 [01:05<00:18, 82.22it/s, est. speed input: 103895.13 toks/s, output: 101.46 toks/s]
Processed prompts:  82%|████████▏ | 6711/8192 [01:06<00:18, 82.04it/s, est. speed input: 103654.89 toks/s, output: 101.23 toks/s]
Processed prompts:  83%|████████▎ | 6775/8192 [01:07<00:17, 81.96it/s, est. speed input: 103422.79 toks/s, output: 101.00 toks/s]
Processed prompts:  83%|████████▎ | 6839/8192 [01:07<00:16, 81.88it/s, est. speed input: 103194.50 toks/s, output: 100.78 toks/s]
Processed prompts:  84%|████████▍ | 6903/8192 [01:08<00:15, 81.81it/s, est. speed input: 102970.64 toks/s, output: 100.56 toks/s]
Processed prompts:  85%|████████▌ | 6967/8192 [01:09<00:14, 81.74it/s, est. speed input: 102751.20 toks/s, output: 100.34 toks/s]
Processed prompts:  86%|████████▌ | 7031/8192 [01:10<00:14, 81.72it/s, est. speed input: 102537.98 toks/s, output: 100.13 toks/s]
Processed prompts:  87%|████████▋ | 7095/8192 [01:10<00:13, 82.05it/s, est. speed input: 102345.06 toks/s, output: 99.95 toks/s] 
Processed prompts:  87%|████████▋ | 7159/8192 [01:11<00:12, 81.94it/s, est. speed input: 102141.00 toks/s, output: 99.75 toks/s]
Processed prompts:  88%|████████▊ | 7223/8192 [01:12<00:11, 81.86it/s, est. speed input: 101941.15 toks/s, output: 99.55 toks/s]
Processed prompts:  89%|████████▉ | 7287/8192 [01:13<00:11, 82.12it/s, est. speed input: 101759.29 toks/s, output: 99.37 toks/s]
Processed prompts:  90%|████████▉ | 7351/8192 [01:14<00:10, 81.94it/s, est. speed input: 101565.84 toks/s, output: 99.19 toks/s]
Processed prompts:  91%|█████████ | 7415/8192 [01:14<00:09, 82.21it/s, est. speed input: 101393.10 toks/s, output: 99.02 toks/s]
Processed prompts:  91%|█████████▏| 7479/8192 [01:15<00:08, 81.98it/s, est. speed input: 101206.36 toks/s, output: 98.83 toks/s]
Processed prompts:  92%|█████████▏| 7543/8192 [01:16<00:07, 81.87it/s, est. speed input: 101025.30 toks/s, output: 98.66 toks/s]
Processed prompts:  93%|█████████▎| 7607/8192 [01:17<00:07, 81.85it/s, est. speed input: 100850.40 toks/s, output: 98.49 toks/s]
Processed prompts:  94%|█████████▎| 7671/8192 [01:18<00:06, 81.78it/s, est. speed input: 100676.77 toks/s, output: 98.32 toks/s]
Processed prompts:  94%|█████████▍| 7735/8192 [01:18<00:05, 81.74it/s, est. speed input: 100507.17 toks/s, output: 98.15 toks/s]
Processed prompts:  95%|█████████▌| 7799/8192 [01:19<00:04, 81.66it/s, est. speed input: 100338.40 toks/s, output: 97.99 toks/s]
Processed prompts:  96%|█████████▌| 7863/8192 [01:20<00:04, 81.69it/s, est. speed input: 100176.87 toks/s, output: 97.83 toks/s]
Processed prompts:  97%|█████████▋| 7927/8192 [01:21<00:03, 81.59it/s, est. speed input: 100013.18 toks/s, output: 97.67 toks/s]
Processed prompts:  98%|█████████▊| 7991/8192 [01:21<00:02, 81.64it/s, est. speed input: 99857.73 toks/s, output: 97.52 toks/s] 
Processed prompts:  98%|█████████▊| 8055/8192 [01:22<00:01, 82.00it/s, est. speed input: 99717.49 toks/s, output: 97.38 toks/s]
Processed prompts:  99%|█████████▉| 8119/8192 [01:23<00:00, 82.04it/s, est. speed input: 99571.53 toks/s, output: 97.24 toks/s]
Processed prompts: 100%|█████████▉| 8183/8192 [01:23<00:00, 110.10it/s, est. speed input: 100215.59 toks/s, output: 97.87 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:23<00:00, 110.10it/s, est. speed input: 100325.55 toks/s, output: 97.97 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:23<00:00, 97.97it/s, est. speed input: 100325.55 toks/s, output: 97.97 toks/s] 
[rank0]:[W126 10:32:33.295248643 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 12:02:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:03:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1328550) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1328550) WARNING 01-26 12:03:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.14 requests/s, 18028.62 total tokens/s, 35.14 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 12:02:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:03:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:03:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:03:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:03:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:03:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:03:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:03:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:03:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:03:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:03:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:03:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1328550) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1328550) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=1328550) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1328550) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1328550) 
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1328550) [2026-01-26 12:03:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1328550) 2026-01-26 12:03:28,232 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1328550) 2026-01-26 12:03:28,255 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1328550) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1328550) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  31%|███▏      | 40/128 [00:00<00:00, 393.99it/s]
Adding requests:  87%|████████▋ | 111/128 [00:00<00:00, 578.66it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 566.86it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:28,  4.50it/s, est. speed input: 2303.33 toks/s, output: 4.50 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 20.35it/s, est. speed input: 8858.71 toks/s, output: 17.30 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:04, 26.94it/s, est. speed input: 11448.21 toks/s, output: 22.36 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 31.85it/s, est. speed input: 13421.10 toks/s, output: 26.21 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:03, 34.19it/s, est. speed input: 14447.55 toks/s, output: 28.22 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:02, 35.87it/s, est. speed input: 15216.98 toks/s, output: 29.72 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 37.04it/s, est. speed input: 15809.05 toks/s, output: 30.88 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 37.88it/s, est. speed input: 16280.54 toks/s, output: 31.80 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:02, 38.42it/s, est. speed input: 16659.33 toks/s, output: 32.54 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 38.85it/s, est. speed input: 16979.01 toks/s, output: 33.16 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 39.11it/s, est. speed input: 17243.63 toks/s, output: 33.68 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 39.28it/s, est. speed input: 17467.90 toks/s, output: 34.12 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 39.43it/s, est. speed input: 17665.75 toks/s, output: 34.50 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:01, 39.51it/s, est. speed input: 17835.07 toks/s, output: 34.83 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:01, 39.59it/s, est. speed input: 17986.86 toks/s, output: 35.13 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 39.60it/s, est. speed input: 18116.89 toks/s, output: 35.38 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 39.66it/s, est. speed input: 18237.87 toks/s, output: 35.62 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 39.75it/s, est. speed input: 18350.46 toks/s, output: 35.84 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 39.73it/s, est. speed input: 18445.84 toks/s, output: 36.03 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 39.74it/s, est. speed input: 18533.51 toks/s, output: 36.20 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 39.77it/s, est. speed input: 18615.40 toks/s, output: 36.36 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 39.81it/s, est. speed input: 18692.22 toks/s, output: 36.51 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 39.80it/s, est. speed input: 18759.69 toks/s, output: 36.64 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:00, 39.80it/s, est. speed input: 18822.42 toks/s, output: 36.76 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 39.78it/s, est. speed input: 18879.83 toks/s, output: 36.87 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:02<00:00, 39.78it/s, est. speed input: 18933.40 toks/s, output: 36.98 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:02<00:00, 39.78it/s, est. speed input: 18983.34 toks/s, output: 37.08 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:02<00:00, 39.82it/s, est. speed input: 19031.97 toks/s, output: 37.17 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 39.79it/s, est. speed input: 19074.42 toks/s, output: 37.25 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 39.74it/s, est. speed input: 19112.99 toks/s, output: 37.33 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 39.71it/s, est. speed input: 19149.28 toks/s, output: 37.40 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 39.72it/s, est. speed input: 19184.79 toks/s, output: 37.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.72it/s, est. speed input: 19192.71 toks/s, output: 37.49 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.48it/s, est. speed input: 19192.71 toks/s, output: 37.49 toks/s]
[rank0]:[W126 12:03:34.643286835 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 12:03:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:03:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1329713) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1329713) WARNING 01-26 12:04:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.52 requests/s, 33337.23 total tokens/s, 32.52 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:03:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:03:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:03:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:03:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:03:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:03:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:03:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:03:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:03:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:03:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:03:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:03:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:03:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:03:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1329713) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1329713) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.15it/s]
(EngineCore_DP0 pid=1329713) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.55it/s]
(EngineCore_DP0 pid=1329713) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.62it/s]
(EngineCore_DP0 pid=1329713) 
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1329713) [2026-01-26 12:03:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1329713) 2026-01-26 12:04:12,690 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1329713) 2026-01-26 12:04:12,713 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1329713) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.19it/s]
(EngineCore_DP0 pid=1329713) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▌        | 20/128 [00:00<00:00, 199.46it/s]
Adding requests:  48%|████▊     | 61/128 [00:00<00:00, 319.57it/s]
Adding requests:  77%|███████▋  | 98/128 [00:00<00:00, 339.00it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 333.12it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 52.59it/s, est. speed input: 53857.08 toks/s, output: 52.59 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:02, 41.09it/s, est. speed input: 43510.78 toks/s, output: 42.49 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:02, 38.62it/s, est. speed input: 41150.55 toks/s, output: 40.18 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 37.65it/s, est. speed input: 40197.77 toks/s, output: 39.25 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 36.96it/s, est. speed input: 39537.27 toks/s, output: 38.61 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 36.52it/s, est. speed input: 39078.16 toks/s, output: 38.16 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:00<00:02, 36.24it/s, est. speed input: 38744.22 toks/s, output: 37.83 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:00<00:02, 36.04it/s, est. speed input: 38479.40 toks/s, output: 37.58 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 35.83it/s, est. speed input: 38246.68 toks/s, output: 37.35 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 35.77it/s, est. speed input: 38082.65 toks/s, output: 37.19 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 35.68it/s, est. speed input: 37933.47 toks/s, output: 37.04 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 35.62it/s, est. speed input: 37808.34 toks/s, output: 36.92 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 35.58it/s, est. speed input: 37701.35 toks/s, output: 36.82 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 35.58it/s, est. speed input: 37615.69 toks/s, output: 36.73 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 35.53it/s, est. speed input: 37528.36 toks/s, output: 36.65 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:01<00:01, 35.49it/s, est. speed input: 37453.17 toks/s, output: 36.57 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:01<00:01, 35.48it/s, est. speed input: 37388.05 toks/s, output: 36.51 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 35.51it/s, est. speed input: 37337.94 toks/s, output: 36.46 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 35.51it/s, est. speed input: 37288.09 toks/s, output: 36.41 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 35.50it/s, est. speed input: 37241.16 toks/s, output: 36.37 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 35.51it/s, est. speed input: 37201.75 toks/s, output: 36.33 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 35.49it/s, est. speed input: 37162.51 toks/s, output: 36.29 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 35.46it/s, est. speed input: 37122.52 toks/s, output: 36.25 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 35.45it/s, est. speed input: 37088.19 toks/s, output: 36.22 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 35.44it/s, est. speed input: 37056.83 toks/s, output: 36.19 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 35.48it/s, est. speed input: 37033.03 toks/s, output: 36.16 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 35.46it/s, est. speed input: 37005.23 toks/s, output: 36.14 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 35.51it/s, est. speed input: 36987.37 toks/s, output: 36.12 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 35.51it/s, est. speed input: 36966.78 toks/s, output: 36.10 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 35.48it/s, est. speed input: 36943.54 toks/s, output: 36.08 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.48it/s, est. speed input: 36925.87 toks/s, output: 36.06 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.06it/s, est. speed input: 36925.87 toks/s, output: 36.06 toks/s]
[rank0]:[W126 12:04:19.395041879 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:04:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:04:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1330821) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1330821) WARNING 01-26 12:04:45 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.33 requests/s, 38267.89 total tokens/s, 37.33 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:04:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:04:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:04:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:04:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:04:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:04:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:04:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:04:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:04:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:04:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:04:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:04:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:04:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:04:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:04:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:04:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:04:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1330821) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1330821) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.15it/s]
(EngineCore_DP0 pid=1330821) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1330821) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1330821) 
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1330821) [2026-01-26 12:04:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1330821) 2026-01-26 12:04:56,346 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1330821) 2026-01-26 12:04:56,369 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1330821) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  2.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  3.54it/s]
(EngineCore_DP0 pid=1330821) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 18.45it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   7%|▋         | 19/256 [00:00<00:01, 185.69it/s]
Adding requests:  23%|██▎       | 59/256 [00:00<00:00, 308.83it/s]
Adding requests:  38%|███▊      | 96/256 [00:00<00:00, 334.31it/s]
Adding requests:  52%|█████▏    | 134/256 [00:00<00:00, 350.63it/s]
Adding requests:  68%|██████▊   | 174/256 [00:00<00:00, 367.23it/s]
Adding requests:  84%|████████▎ | 214/256 [00:00<00:00, 376.29it/s]
Adding requests:  99%|█████████▉| 253/256 [00:00<00:00, 378.49it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 356.14it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 183.72it/s, est. speed input: 188167.37 toks/s, output: 183.73 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:00<00:03, 61.66it/s, est. speed input: 70335.95 toks/s, output: 68.69 toks/s]   
Processed prompts:  20%|█▉        | 50/256 [00:00<00:04, 49.81it/s, est. speed input: 58334.39 toks/s, output: 56.96 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:01<00:04, 46.40it/s, est. speed input: 54717.51 toks/s, output: 53.43 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:01<00:04, 44.71it/s, est. speed input: 52947.76 toks/s, output: 51.71 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:04, 43.27it/s, est. speed input: 51524.66 toks/s, output: 50.32 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:01<00:04, 44.39it/s, est. speed input: 51430.57 toks/s, output: 50.22 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:01<00:04, 40.82it/s, est. speed input: 49723.00 toks/s, output: 48.56 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:01<00:04, 42.60it/s, est. speed input: 49742.73 toks/s, output: 48.58 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:01<00:04, 39.17it/s, est. speed input: 48353.37 toks/s, output: 47.22 toks/s]
Processed prompts:  37%|███▋      | 95/256 [00:02<00:03, 41.22it/s, est. speed input: 48385.80 toks/s, output: 47.25 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:02<00:04, 38.31it/s, est. speed input: 47310.66 toks/s, output: 46.20 toks/s]
Processed prompts:  41%|████      | 104/256 [00:02<00:03, 38.52it/s, est. speed input: 46986.57 toks/s, output: 45.88 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:02<00:03, 38.61it/s, est. speed input: 46675.23 toks/s, output: 45.58 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:02<00:03, 38.80it/s, est. speed input: 46411.41 toks/s, output: 45.32 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:02<00:03, 38.91it/s, est. speed input: 46162.25 toks/s, output: 45.08 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:02<00:03, 38.92it/s, est. speed input: 45921.35 toks/s, output: 44.84 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:02<00:03, 38.89it/s, est. speed input: 45692.75 toks/s, output: 44.62 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:02<00:03, 38.86it/s, est. speed input: 45479.24 toks/s, output: 44.41 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:02<00:03, 38.57it/s, est. speed input: 45242.25 toks/s, output: 44.18 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:03<00:03, 38.63it/s, est. speed input: 45057.57 toks/s, output: 44.00 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:03<00:02, 38.83it/s, est. speed input: 44904.86 toks/s, output: 43.85 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:03<00:02, 38.80it/s, est. speed input: 44740.06 toks/s, output: 43.69 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:03<00:02, 38.92it/s, est. speed input: 44601.81 toks/s, output: 43.56 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:03<00:02, 39.00it/s, est. speed input: 44472.05 toks/s, output: 43.43 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:03<00:02, 39.01it/s, est. speed input: 44344.21 toks/s, output: 43.30 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:03<00:02, 38.97it/s, est. speed input: 44217.82 toks/s, output: 43.18 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:03<00:02, 39.06it/s, est. speed input: 44111.16 toks/s, output: 43.08 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:03<00:02, 38.85it/s, est. speed input: 43982.82 toks/s, output: 42.95 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:04<00:02, 38.75it/s, est. speed input: 43865.10 toks/s, output: 42.84 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:04<00:02, 38.77it/s, est. speed input: 43762.37 toks/s, output: 42.74 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:04<00:01, 38.89it/s, est. speed input: 43674.01 toks/s, output: 42.65 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:04<00:01, 38.88it/s, est. speed input: 43581.00 toks/s, output: 42.56 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:04<00:01, 38.89it/s, est. speed input: 43494.62 toks/s, output: 42.47 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:04<00:01, 38.92it/s, est. speed input: 43414.08 toks/s, output: 42.40 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:04<00:01, 38.96it/s, est. speed input: 43338.23 toks/s, output: 42.32 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:04<00:01, 39.00it/s, est. speed input: 43266.85 toks/s, output: 42.25 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:04<00:01, 40.59it/s, est. speed input: 43298.37 toks/s, output: 42.28 toks/s]
Processed prompts:  82%|████████▏ | 211/256 [00:04<00:01, 42.76it/s, est. speed input: 43426.10 toks/s, output: 42.41 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:05<00:01, 38.88it/s, est. speed input: 43117.95 toks/s, output: 42.11 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:05<00:00, 38.89it/s, est. speed input: 43053.79 toks/s, output: 42.04 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:05<00:00, 38.89it/s, est. speed input: 42991.73 toks/s, output: 41.98 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:05<00:00, 38.89it/s, est. speed input: 42931.95 toks/s, output: 41.93 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:05<00:00, 38.94it/s, est. speed input: 42877.49 toks/s, output: 41.87 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:05<00:00, 38.92it/s, est. speed input: 42821.29 toks/s, output: 41.82 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:05<00:00, 38.79it/s, est. speed input: 42759.99 toks/s, output: 41.76 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:05<00:00, 38.85it/s, est. speed input: 42709.86 toks/s, output: 41.71 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:05<00:00, 38.91it/s, est. speed input: 42663.00 toks/s, output: 41.66 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:06<00:00, 38.84it/s, est. speed input: 42611.03 toks/s, output: 41.61 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 38.84it/s, est. speed input: 42721.21 toks/s, output: 41.72 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 41.72it/s, est. speed input: 42721.21 toks/s, output: 41.72 toks/s]
[rank0]:[W126 12:05:05.980921243 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:05:08
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:05:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1331991) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1331991) WARNING 01-26 12:05:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.01 requests/s, 41010.45 total tokens/s, 40.01 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:05:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:05:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:05:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:05:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:05:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:05:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:05:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:05:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:05:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:05:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:05:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:05:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:05:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:05:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:05:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:05:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:05:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1331991) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1331991) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.15it/s]
(EngineCore_DP0 pid=1331991) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1331991) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1331991) 
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1331991) [2026-01-26 12:05:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1331991) 2026-01-26 12:05:46,217 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1331991) 2026-01-26 12:05:46,254 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1331991) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00, 14.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 15.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 15.39it/s]
(EngineCore_DP0 pid=1331991) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 19.16it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 19.57it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 21/512 [00:00<00:02, 209.03it/s]
Adding requests:  12%|█▏        | 62/512 [00:00<00:01, 325.77it/s]
Adding requests:  19%|█▉        | 98/512 [00:00<00:01, 340.63it/s]
Adding requests:  27%|██▋       | 136/512 [00:00<00:01, 356.08it/s]
Adding requests:  34%|███▍      | 176/512 [00:00<00:00, 368.99it/s]
Adding requests:  42%|████▏     | 217/512 [00:00<00:00, 381.53it/s]
Adding requests:  50%|█████     | 256/512 [00:00<00:00, 381.40it/s]
Adding requests:  58%|█████▊    | 296/512 [00:00<00:00, 385.59it/s]
Adding requests:  66%|██████▌   | 338/512 [00:00<00:00, 392.88it/s]
Adding requests:  74%|███████▍  | 378/512 [00:01<00:00, 394.33it/s]
Adding requests:  82%|████████▏ | 421/512 [00:01<00:00, 401.89it/s]
Adding requests:  90%|█████████ | 462/512 [00:01<00:00, 397.72it/s]
Adding requests:  99%|█████████▊| 505/512 [00:01<00:00, 404.92it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 382.37it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 54/512 [00:00<00:01, 379.35it/s, est. speed input: 388533.11 toks/s, output: 379.37 toks/s]
Processed prompts:  18%|█▊        | 92/512 [00:01<00:05, 76.09it/s, est. speed input: 90681.43 toks/s, output: 88.56 toks/s]   
Processed prompts:  22%|██▏       | 111/512 [00:01<00:06, 60.50it/s, est. speed input: 74164.41 toks/s, output: 72.43 toks/s]
Processed prompts:  24%|██▍       | 123/512 [00:01<00:07, 54.97it/s, est. speed input: 68649.60 toks/s, output: 67.04 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:02<00:07, 52.89it/s, est. speed input: 66382.84 toks/s, output: 64.83 toks/s]
Processed prompts:  27%|██▋       | 140/512 [00:02<00:07, 50.14it/s, est. speed input: 64172.62 toks/s, output: 62.67 toks/s]
Processed prompts:  29%|██▊       | 147/512 [00:02<00:07, 46.61it/s, est. speed input: 61901.55 toks/s, output: 60.45 toks/s]
Processed prompts:  30%|███       | 154/512 [00:02<00:08, 43.63it/s, est. speed input: 59926.29 toks/s, output: 58.52 toks/s]
Processed prompts:  31%|███       | 159/512 [00:02<00:07, 44.57it/s, est. speed input: 59590.40 toks/s, output: 58.19 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:02<00:07, 45.48it/s, est. speed input: 59275.56 toks/s, output: 57.89 toks/s]
Processed prompts:  33%|███▎      | 169/512 [00:02<00:07, 46.33it/s, est. speed input: 58982.55 toks/s, output: 57.60 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:03<00:08, 38.46it/s, est. speed input: 56857.57 toks/s, output: 55.52 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:03<00:08, 39.17it/s, est. speed input: 55946.56 toks/s, output: 54.63 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:03<00:08, 39.52it/s, est. speed input: 55115.82 toks/s, output: 53.82 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:03<00:07, 41.50it/s, est. speed input: 55002.79 toks/s, output: 53.71 toks/s]
Processed prompts:  39%|███▉      | 200/512 [00:03<00:07, 43.25it/s, est. speed input: 54888.80 toks/s, output: 53.60 toks/s]
Processed prompts:  40%|████      | 206/512 [00:03<00:07, 39.31it/s, est. speed input: 53859.88 toks/s, output: 52.60 toks/s]
Processed prompts:  41%|████      | 211/512 [00:04<00:07, 41.63it/s, est. speed input: 53790.83 toks/s, output: 52.53 toks/s]
Processed prompts:  42%|████▏     | 216/512 [00:04<00:06, 43.53it/s, est. speed input: 53717.42 toks/s, output: 52.46 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:04<00:07, 38.19it/s, est. speed input: 52672.38 toks/s, output: 51.44 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:04<00:07, 38.94it/s, est. speed input: 52167.88 toks/s, output: 50.94 toks/s]
Processed prompts:  46%|████▌     | 235/512 [00:04<00:06, 41.24it/s, est. speed input: 52146.26 toks/s, output: 50.92 toks/s]
Processed prompts:  47%|████▋     | 240/512 [00:04<00:06, 43.21it/s, est. speed input: 52121.81 toks/s, output: 50.90 toks/s]
Processed prompts:  48%|████▊     | 245/512 [00:04<00:05, 44.82it/s, est. speed input: 52096.65 toks/s, output: 50.88 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:05<00:07, 36.60it/s, est. speed input: 51035.68 toks/s, output: 49.84 toks/s]
Processed prompts:  50%|████▉     | 255/512 [00:05<00:06, 39.62it/s, est. speed input: 51034.82 toks/s, output: 49.84 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:05<00:06, 37.92it/s, est. speed input: 50479.71 toks/s, output: 49.30 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:05<00:06, 38.71it/s, est. speed input: 50139.19 toks/s, output: 48.96 toks/s]
Processed prompts:  54%|█████▎    | 275/512 [00:05<00:05, 41.00it/s, est. speed input: 50155.07 toks/s, output: 48.98 toks/s]
Processed prompts:  55%|█████▍    | 280/512 [00:05<00:05, 43.01it/s, est. speed input: 50171.06 toks/s, output: 49.00 toks/s]
Processed prompts:  56%|█████▌    | 285/512 [00:05<00:05, 44.68it/s, est. speed input: 50185.31 toks/s, output: 49.01 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:06<00:06, 36.58it/s, est. speed input: 49366.94 toks/s, output: 48.21 toks/s]
Processed prompts:  58%|█████▊    | 295/512 [00:06<00:05, 39.55it/s, est. speed input: 49389.84 toks/s, output: 48.23 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:06<00:05, 37.85it/s, est. speed input: 48969.76 toks/s, output: 47.82 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:06<00:05, 40.00it/s, est. speed input: 48867.70 toks/s, output: 47.72 toks/s]
Processed prompts:  62%|██████▏   | 315/512 [00:06<00:04, 42.07it/s, est. speed input: 48899.92 toks/s, output: 47.75 toks/s]
Processed prompts:  62%|██████▎   | 320/512 [00:06<00:04, 43.82it/s, est. speed input: 48928.21 toks/s, output: 47.78 toks/s]
Processed prompts:  63%|██████▎   | 325/512 [00:06<00:04, 45.35it/s, est. speed input: 48961.65 toks/s, output: 47.81 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:06<00:04, 36.94it/s, est. speed input: 48296.55 toks/s, output: 47.16 toks/s]
Processed prompts:  65%|██████▌   | 335/512 [00:07<00:04, 39.85it/s, est. speed input: 48331.12 toks/s, output: 47.20 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:07<00:04, 37.98it/s, est. speed input: 47993.29 toks/s, output: 46.87 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:07<00:04, 38.77it/s, est. speed input: 47811.42 toks/s, output: 46.69 toks/s]
Processed prompts:  69%|██████▉   | 355/512 [00:07<00:03, 41.05it/s, est. speed input: 47853.76 toks/s, output: 46.73 toks/s]
Processed prompts:  70%|███████   | 360/512 [00:07<00:03, 43.02it/s, est. speed input: 47893.75 toks/s, output: 46.77 toks/s]
Processed prompts:  71%|███████▏  | 365/512 [00:07<00:03, 44.72it/s, est. speed input: 47935.48 toks/s, output: 46.81 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:07<00:03, 36.60it/s, est. speed input: 47376.08 toks/s, output: 46.27 toks/s]
Processed prompts:  73%|███████▎  | 375/512 [00:08<00:03, 39.63it/s, est. speed input: 47422.43 toks/s, output: 46.31 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:08<00:03, 37.87it/s, est. speed input: 47148.25 toks/s, output: 46.04 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:08<00:03, 38.68it/s, est. speed input: 47005.55 toks/s, output: 45.90 toks/s]
Processed prompts:  77%|███████▋  | 396/512 [00:08<00:02, 43.04it/s, est. speed input: 47173.28 toks/s, output: 46.07 toks/s]
Processed prompts:  78%|███████▊  | 401/512 [00:08<00:02, 44.55it/s, est. speed input: 47216.20 toks/s, output: 46.11 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:08<00:02, 36.83it/s, est. speed input: 46726.41 toks/s, output: 45.63 toks/s]
Processed prompts:  80%|████████  | 411/512 [00:08<00:02, 39.67it/s, est. speed input: 46773.58 toks/s, output: 45.68 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:09<00:02, 37.89it/s, est. speed input: 46536.99 toks/s, output: 45.45 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:09<00:02, 38.68it/s, est. speed input: 46421.20 toks/s, output: 45.33 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:09<00:01, 40.32it/s, est. speed input: 46393.01 toks/s, output: 45.31 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:09<00:01, 40.29it/s, est. speed input: 46287.35 toks/s, output: 45.20 toks/s]
Processed prompts:  87%|████████▋ | 447/512 [00:09<00:01, 42.12it/s, est. speed input: 46335.00 toks/s, output: 45.25 toks/s]
Processed prompts:  88%|████████▊ | 452/512 [00:09<00:01, 43.78it/s, est. speed input: 46382.02 toks/s, output: 45.29 toks/s]
Processed prompts:  89%|████████▉ | 457/512 [00:10<00:01, 45.22it/s, est. speed input: 46428.83 toks/s, output: 45.34 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:10<00:01, 37.17it/s, est. speed input: 46027.41 toks/s, output: 44.95 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:10<00:01, 38.21it/s, est. speed input: 45931.20 toks/s, output: 44.85 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:10<00:00, 38.85it/s, est. speed input: 45839.85 toks/s, output: 44.77 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:10<00:00, 39.21it/s, est. speed input: 45748.78 toks/s, output: 44.68 toks/s]
Processed prompts:  96%|█████████▌| 491/512 [00:10<00:00, 41.17it/s, est. speed input: 45793.33 toks/s, output: 44.72 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:11<00:00, 39.02it/s, est. speed input: 45616.56 toks/s, output: 44.55 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:11<00:00, 39.39it/s, est. speed input: 45537.22 toks/s, output: 44.47 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:11<00:00, 39.39it/s, est. speed input: 45766.34 toks/s, output: 44.69 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:11<00:00, 44.69it/s, est. speed input: 45766.34 toks/s, output: 44.69 toks/s]
[rank0]:[W126 12:06:01.248992537 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:06:03
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:06:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1333276) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1333276) WARNING 01-26 12:06:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 41.02 requests/s, 42047.93 total tokens/s, 41.02 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:06:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:06:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:06:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:06:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:06:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:06:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:06:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:06:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:06:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:06:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:06:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:06:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:06:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:06:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:06:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:06:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:06:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1333276) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1333276) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=1333276) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1333276) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1333276) 
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1333276) [2026-01-26 12:06:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1333276) 2026-01-26 12:06:43,138 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1333276) 2026-01-26 12:06:43,163 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1333276) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  4.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  4.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  2.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  3.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.41it/s]
(EngineCore_DP0 pid=1333276) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.76it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00, 12.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.78it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 23/1024 [00:00<00:04, 227.33it/s]
Adding requests:   6%|▋         | 64/1024 [00:00<00:02, 328.67it/s]
Adding requests:  10%|▉         | 100/1024 [00:00<00:02, 341.60it/s]
Adding requests:  13%|█▎        | 138/1024 [00:00<00:02, 354.19it/s]
Adding requests:  17%|█▋        | 177/1024 [00:00<00:02, 366.81it/s]
Adding requests:  21%|██▏       | 219/1024 [00:00<00:02, 382.69it/s]
Adding requests:  25%|██▌       | 258/1024 [00:00<00:02, 378.75it/s]
Adding requests:  29%|██▉       | 299/1024 [00:00<00:01, 385.38it/s]
Adding requests:  33%|███▎      | 339/1024 [00:00<00:01, 389.79it/s]
Adding requests:  37%|███▋      | 380/1024 [00:01<00:01, 392.62it/s]
Adding requests:  41%|████      | 422/1024 [00:01<00:01, 399.64it/s]
Adding requests:  45%|████▌     | 462/1024 [00:01<00:01, 395.59it/s]
Adding requests:  49%|████▉     | 505/1024 [00:01<00:01, 403.62it/s]
Adding requests:  53%|█████▎    | 546/1024 [00:01<00:01, 403.27it/s]
Adding requests:  57%|█████▋    | 587/1024 [00:01<00:01, 398.49it/s]
Adding requests:  61%|██████    | 627/1024 [00:01<00:01, 396.09it/s]
Adding requests:  65%|██████▌   | 667/1024 [00:01<00:00, 385.62it/s]
Adding requests:  69%|██████▉   | 708/1024 [00:01<00:00, 391.10it/s]
Adding requests:  73%|███████▎  | 748/1024 [00:01<00:00, 384.16it/s]
Adding requests:  77%|███████▋  | 788/1024 [00:02<00:00, 386.56it/s]
Adding requests:  81%|████████  | 828/1024 [00:02<00:00, 387.97it/s]
Adding requests:  85%|████████▍ | 868/1024 [00:02<00:00, 389.06it/s]
Adding requests:  89%|████████▉ | 909/1024 [00:02<00:00, 393.19it/s]
Adding requests:  93%|█████████▎| 949/1024 [00:02<00:00, 384.12it/s]
Adding requests:  97%|█████████▋| 989/1024 [00:02<00:00, 386.61it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 383.61it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:00<00:01, 872.61it/s, est. speed input: 893723.91 toks/s, output: 872.66 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:02<00:11, 72.67it/s, est. speed input: 87575.63 toks/s, output: 85.52 toks/s]   
Processed prompts:  23%|██▎       | 233/1024 [00:03<00:12, 65.62it/s, est. speed input: 78723.76 toks/s, output: 76.88 toks/s]
Processed prompts:  25%|██▌       | 257/1024 [00:03<00:12, 59.10it/s, est. speed input: 72769.76 toks/s, output: 71.06 toks/s]
Processed prompts:  27%|██▋       | 273/1024 [00:04<00:13, 55.47it/s, est. speed input: 69782.19 toks/s, output: 68.15 toks/s]
Processed prompts:  28%|██▊       | 285/1024 [00:04<00:14, 50.01it/s, est. speed input: 66415.85 toks/s, output: 64.86 toks/s]
Processed prompts:  29%|██▊       | 294/1024 [00:04<00:14, 49.41it/s, est. speed input: 65572.87 toks/s, output: 64.04 toks/s]
Processed prompts:  29%|██▉       | 302/1024 [00:04<00:15, 47.99it/s, est. speed input: 64596.48 toks/s, output: 63.08 toks/s]
Processed prompts:  30%|███       | 309/1024 [00:04<00:15, 46.65it/s, est. speed input: 63776.06 toks/s, output: 62.28 toks/s]
Processed prompts:  31%|███       | 315/1024 [00:05<00:16, 43.28it/s, est. speed input: 62573.73 toks/s, output: 61.11 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:05<00:16, 41.53it/s, est. speed input: 61633.15 toks/s, output: 60.19 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:05<00:16, 41.38it/s, est. speed input: 60938.09 toks/s, output: 59.51 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:05<00:16, 41.22it/s, est. speed input: 60284.03 toks/s, output: 58.87 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:05<00:16, 41.16it/s, est. speed input: 59682.63 toks/s, output: 58.28 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:06<00:16, 41.19it/s, est. speed input: 59131.47 toks/s, output: 57.75 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:06<00:16, 41.11it/s, est. speed input: 58598.95 toks/s, output: 57.23 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:06<00:15, 41.12it/s, est. speed input: 58107.13 toks/s, output: 56.74 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:06<00:15, 40.94it/s, est. speed input: 57619.34 toks/s, output: 56.27 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:06<00:15, 40.97it/s, est. speed input: 57180.06 toks/s, output: 55.84 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:07<00:15, 40.97it/s, est. speed input: 56761.39 toks/s, output: 55.43 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:07<00:15, 41.00it/s, est. speed input: 56368.41 toks/s, output: 55.05 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:07<00:14, 41.03it/s, est. speed input: 55998.25 toks/s, output: 54.69 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:07<00:14, 40.84it/s, est. speed input: 55621.79 toks/s, output: 54.32 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:07<00:14, 40.91it/s, est. speed input: 55287.05 toks/s, output: 53.99 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:08<00:13, 42.33it/s, est. speed input: 55112.70 toks/s, output: 53.82 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:08<00:13, 42.02it/s, est. speed input: 54811.87 toks/s, output: 53.53 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:08<00:13, 41.67it/s, est. speed input: 54511.93 toks/s, output: 53.23 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:08<00:13, 41.30it/s, est. speed input: 54213.48 toks/s, output: 52.94 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:08<00:13, 41.14it/s, est. speed input: 53936.51 toks/s, output: 52.67 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:09<00:13, 41.16it/s, est. speed input: 53684.54 toks/s, output: 52.43 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:09<00:13, 41.12it/s, est. speed input: 53438.51 toks/s, output: 52.19 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:09<00:13, 41.05it/s, est. speed input: 53197.99 toks/s, output: 51.95 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:09<00:12, 40.89it/s, est. speed input: 52958.47 toks/s, output: 51.72 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:09<00:12, 40.84it/s, est. speed input: 52733.08 toks/s, output: 51.50 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:10<00:12, 40.95it/s, est. speed input: 52528.63 toks/s, output: 51.30 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:10<00:12, 40.99it/s, est. speed input: 52329.35 toks/s, output: 51.10 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:10<00:12, 40.95it/s, est. speed input: 52132.05 toks/s, output: 50.91 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:10<00:11, 40.80it/s, est. speed input: 51932.31 toks/s, output: 50.71 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:10<00:11, 40.81it/s, est. speed input: 51748.80 toks/s, output: 50.54 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:10<00:11, 40.91it/s, est. speed input: 51578.99 toks/s, output: 50.37 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:11<00:11, 40.90it/s, est. speed input: 51408.51 toks/s, output: 50.20 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:11<00:11, 40.89it/s, est. speed input: 51244.80 toks/s, output: 50.04 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:11<00:10, 40.75it/s, est. speed input: 51076.60 toks/s, output: 49.88 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:11<00:10, 40.69it/s, est. speed input: 50916.67 toks/s, output: 49.72 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:11<00:10, 40.86it/s, est. speed input: 50776.04 toks/s, output: 49.59 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:12<00:10, 40.81it/s, est. speed input: 50629.25 toks/s, output: 49.44 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:12<00:10, 40.84it/s, est. speed input: 50490.97 toks/s, output: 49.31 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:12<00:09, 40.79it/s, est. speed input: 50352.98 toks/s, output: 49.17 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:12<00:09, 40.74it/s, est. speed input: 50217.56 toks/s, output: 49.04 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:12<00:09, 40.91it/s, est. speed input: 50099.36 toks/s, output: 48.93 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:13<00:09, 40.85it/s, est. speed input: 49974.01 toks/s, output: 48.80 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:13<00:09, 40.86it/s, est. speed input: 49855.05 toks/s, output: 48.69 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:13<00:08, 40.77it/s, est. speed input: 49733.92 toks/s, output: 48.57 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:13<00:08, 40.62it/s, est. speed input: 49611.29 toks/s, output: 48.45 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:13<00:08, 40.75it/s, est. speed input: 49505.34 toks/s, output: 48.34 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:14<00:08, 40.78it/s, est. speed input: 49399.16 toks/s, output: 48.24 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:14<00:08, 40.89it/s, est. speed input: 49300.33 toks/s, output: 48.14 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:14<00:07, 40.90it/s, est. speed input: 49200.99 toks/s, output: 48.05 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:14<00:07, 40.79it/s, est. speed input: 49098.11 toks/s, output: 47.95 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:14<00:07, 40.92it/s, est. speed input: 49008.65 toks/s, output: 47.86 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:15<00:07, 41.04it/s, est. speed input: 48922.70 toks/s, output: 47.78 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:15<00:07, 41.05it/s, est. speed input: 48835.43 toks/s, output: 47.69 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:15<00:06, 41.07it/s, est. speed input: 48750.97 toks/s, output: 47.61 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:15<00:06, 40.89it/s, est. speed input: 48658.77 toks/s, output: 47.52 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:15<00:06, 40.96it/s, est. speed input: 48579.06 toks/s, output: 47.44 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:16<00:06, 41.02it/s, est. speed input: 48501.34 toks/s, output: 47.36 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:16<00:06, 41.13it/s, est. speed input: 48428.62 toks/s, output: 47.29 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:16<00:05, 41.06it/s, est. speed input: 48350.97 toks/s, output: 47.22 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:16<00:05, 42.37it/s, est. speed input: 48335.23 toks/s, output: 47.20 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:16<00:05, 41.87it/s, est. speed input: 48258.20 toks/s, output: 47.13 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:17<00:05, 41.65it/s, est. speed input: 48188.39 toks/s, output: 47.06 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:17<00:05, 41.57it/s, est. speed input: 48123.33 toks/s, output: 47.00 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:17<00:04, 41.45it/s, est. speed input: 48057.00 toks/s, output: 46.93 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:17<00:04, 41.19it/s, est. speed input: 47984.29 toks/s, output: 46.86 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:17<00:04, 41.01it/s, est. speed input: 47913.51 toks/s, output: 46.79 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:18<00:04, 41.09it/s, est. speed input: 47852.73 toks/s, output: 46.73 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:18<00:04, 41.16it/s, est. speed input: 47794.03 toks/s, output: 46.67 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:18<00:04, 41.20it/s, est. speed input: 47735.88 toks/s, output: 46.62 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:18<00:03, 41.09it/s, est. speed input: 47673.58 toks/s, output: 46.56 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:18<00:03, 40.96it/s, est. speed input: 47610.22 toks/s, output: 46.49 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:18<00:03, 40.88it/s, est. speed input: 47548.98 toks/s, output: 46.43 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:19<00:03, 41.00it/s, est. speed input: 47495.60 toks/s, output: 46.38 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:19<00:03, 41.06it/s, est. speed input: 47442.33 toks/s, output: 46.33 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:19<00:02, 41.01it/s, est. speed input: 47386.73 toks/s, output: 46.28 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:19<00:02, 40.85it/s, est. speed input: 47327.36 toks/s, output: 46.22 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:19<00:02, 40.81it/s, est. speed input: 47272.12 toks/s, output: 46.16 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:20<00:02, 40.93it/s, est. speed input: 47223.31 toks/s, output: 46.12 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:20<00:02, 41.06it/s, est. speed input: 47177.09 toks/s, output: 46.07 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:20<00:01, 41.03it/s, est. speed input: 47127.25 toks/s, output: 46.02 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:20<00:01, 40.93it/s, est. speed input: 47075.50 toks/s, output: 45.97 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:20<00:01, 40.91it/s, est. speed input: 47026.81 toks/s, output: 45.92 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:21<00:01, 40.95it/s, est. speed input: 46980.69 toks/s, output: 45.88 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:21<00:01, 41.05it/s, est. speed input: 46937.80 toks/s, output: 45.84 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:21<00:00, 41.05it/s, est. speed input: 46893.45 toks/s, output: 45.79 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:21<00:00, 40.89it/s, est. speed input: 46844.55 toks/s, output: 45.75 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:21<00:00, 40.83it/s, est. speed input: 46798.01 toks/s, output: 45.70 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:22<00:00, 40.96it/s, est. speed input: 46758.37 toks/s, output: 45.66 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:22<00:00, 42.52it/s, est. speed input: 46766.05 toks/s, output: 45.67 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:22<00:00, 42.52it/s, est. speed input: 47041.11 toks/s, output: 45.94 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:22<00:00, 45.94it/s, est. speed input: 47041.11 toks/s, output: 45.94 toks/s]
[rank0]:[W126 12:07:11.378420596 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 12:07:13
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:07:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1334794) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1334794) WARNING 01-26 12:07:48 [backends.py:609] Failed to read file <frozen os>
Throughput: 42.02 requests/s, 43075.10 total tokens/s, 42.02 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 12:07:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:07:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:07:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:07:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:07:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:07:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:07:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:07:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:07:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:07:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:07:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:07:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:07:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:07:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:07:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:07:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:07:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1334794) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1334794) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.13it/s]
(EngineCore_DP0 pid=1334794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.53it/s]
(EngineCore_DP0 pid=1334794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.60it/s]
(EngineCore_DP0 pid=1334794) 
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1334794) [2026-01-26 12:07:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1334794) [rank0]:W0126 12:07:53.672000 1334794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1334794) [rank0]:W0126 12:07:53.750000 1334794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1334794) [rank0]:W0126 12:07:54.970000 1334794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1334794) [rank0]:W0126 12:07:55.102000 1334794 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1334794) 2026-01-26 12:07:58,800 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1334794) 2026-01-26 12:07:58,825 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1334794) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:03,  1.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  2.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  6.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]
(EngineCore_DP0 pid=1334794) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 18.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 20.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 19.87it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/2048 [00:00<00:08, 227.98it/s]
Adding requests:   3%|▎         | 63/2048 [00:00<00:06, 325.07it/s]
Adding requests:   5%|▍         | 97/2048 [00:00<00:05, 328.26it/s]
Adding requests:   7%|▋         | 135/2048 [00:00<00:05, 347.29it/s]
Adding requests:   8%|▊         | 174/2048 [00:00<00:05, 361.49it/s]
Adding requests:  10%|█         | 214/2048 [00:00<00:04, 371.94it/s]
Adding requests:  12%|█▏        | 252/2048 [00:00<00:04, 372.88it/s]
Adding requests:  14%|█▍        | 290/2048 [00:00<00:04, 373.79it/s]
Adding requests:  16%|█▌        | 330/2048 [00:00<00:04, 380.10it/s]
Adding requests:  18%|█▊        | 370/2048 [00:01<00:04, 384.93it/s]
Adding requests:  20%|██        | 411/2048 [00:01<00:04, 388.97it/s]
Adding requests:  22%|██▏       | 450/2048 [00:01<00:04, 384.97it/s]
Adding requests:  24%|██▍       | 493/2048 [00:01<00:03, 396.14it/s]
Adding requests:  26%|██▌       | 535/2048 [00:01<00:03, 401.33it/s]
Adding requests:  28%|██▊       | 576/2048 [00:01<00:03, 397.77it/s]
Adding requests:  30%|███       | 616/2048 [00:01<00:03, 386.11it/s]
Adding requests:  32%|███▏      | 655/2048 [00:01<00:03, 378.85it/s]
Adding requests:  34%|███▍      | 695/2048 [00:01<00:03, 382.42it/s]
Adding requests:  36%|███▌      | 734/2048 [00:01<00:03, 376.59it/s]
Adding requests:  38%|███▊      | 772/2048 [00:02<00:03, 369.18it/s]
Adding requests:  40%|███▉      | 810/2048 [00:02<00:03, 371.64it/s]
Adding requests:  42%|████▏     | 850/2048 [00:02<00:03, 379.24it/s]
Adding requests:  43%|████▎     | 890/2048 [00:02<00:03, 383.54it/s]
Adding requests:  45%|████▌     | 929/2048 [00:02<00:02, 375.41it/s]
Adding requests:  47%|████▋     | 969/2048 [00:02<00:02, 379.20it/s]
Adding requests:  49%|████▉     | 1007/2048 [00:02<00:02, 372.43it/s]
Adding requests:  51%|█████     | 1045/2048 [00:02<00:02, 372.78it/s]
Adding requests:  53%|█████▎    | 1083/2048 [00:02<00:02, 372.45it/s]
Adding requests:  55%|█████▍    | 1121/2048 [00:02<00:02, 371.68it/s]
Adding requests:  57%|█████▋    | 1159/2048 [00:03<00:02, 371.22it/s]
Adding requests:  58%|█████▊    | 1198/2048 [00:03<00:02, 374.16it/s]
Adding requests:  60%|██████    | 1238/2048 [00:03<00:02, 380.46it/s]
Adding requests:  62%|██████▏   | 1277/2048 [00:03<00:02, 376.23it/s]
Adding requests:  64%|██████▍   | 1315/2048 [00:03<00:01, 376.22it/s]
Adding requests:  66%|██████▌   | 1355/2048 [00:03<00:01, 381.10it/s]
Adding requests:  68%|██████▊   | 1394/2048 [00:03<00:01, 380.58it/s]
Adding requests:  70%|██████▉   | 1433/2048 [00:03<00:01, 377.54it/s]
Adding requests:  72%|███████▏  | 1472/2048 [00:03<00:01, 378.02it/s]
Adding requests:  74%|███████▍  | 1513/2048 [00:04<00:01, 384.86it/s]
Adding requests:  76%|███████▌  | 1552/2048 [00:04<00:01, 380.04it/s]
Adding requests:  78%|███████▊  | 1591/2048 [00:04<00:01, 374.69it/s]
Adding requests:  80%|███████▉  | 1629/2048 [00:04<00:01, 367.88it/s]
Adding requests:  81%|████████▏ | 1666/2048 [00:04<00:01, 359.99it/s]
Adding requests:  83%|████████▎ | 1705/2048 [00:04<00:00, 366.81it/s]
Adding requests:  85%|████████▌ | 1743/2048 [00:04<00:00, 369.64it/s]
Adding requests:  87%|████████▋ | 1783/2048 [00:04<00:00, 377.42it/s]
Adding requests:  89%|████████▉ | 1821/2048 [00:04<00:00, 372.90it/s]
Adding requests:  91%|█████████ | 1860/2048 [00:04<00:00, 377.81it/s]
Adding requests:  93%|█████████▎| 1898/2048 [00:05<00:00, 377.16it/s]
Adding requests:  95%|█████████▍| 1936/2048 [00:05<00:00, 373.44it/s]
Adding requests:  96%|█████████▋| 1975/2048 [00:05<00:00, 377.11it/s]
Adding requests:  98%|█████████▊| 2013/2048 [00:05<00:00, 373.82it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 374.61it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:00<00:02, 677.13it/s, est. speed input: 693433.95 toks/s, output: 677.15 toks/s]
Processed prompts:  14%|█▍        | 294/2048 [00:01<00:13, 127.96it/s, est. speed input: 161179.88 toks/s, output: 157.40 toks/s]
Processed prompts:  16%|█▌        | 325/2048 [00:02<00:17, 95.87it/s, est. speed input: 127733.50 toks/s, output: 124.74 toks/s] 
Processed prompts:  17%|█▋        | 344/2048 [00:02<00:19, 85.81it/s, est. speed input: 117851.91 toks/s, output: 115.09 toks/s]
Processed prompts:  17%|█▋        | 358/2048 [00:03<00:22, 74.28it/s, est. speed input: 108802.81 toks/s, output: 106.25 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:03<00:26, 63.49it/s, est. speed input: 101021.49 toks/s, output: 98.65 toks/s] 
Processed prompts:  19%|█▉        | 386/2048 [00:04<00:28, 57.70it/s, est. speed input: 95612.87 toks/s, output: 93.37 toks/s] 
Processed prompts:  20%|█▉        | 402/2048 [00:04<00:30, 53.38it/s, est. speed input: 91163.78 toks/s, output: 89.03 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:04<00:32, 50.01it/s, est. speed input: 87333.80 toks/s, output: 85.29 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:05<00:33, 48.40it/s, est. speed input: 84435.32 toks/s, output: 82.46 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:05<00:34, 46.55it/s, est. speed input: 81651.69 toks/s, output: 79.74 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:06<00:35, 45.09it/s, est. speed input: 79164.42 toks/s, output: 77.31 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:06<00:35, 44.09it/s, est. speed input: 76984.26 toks/s, output: 75.18 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:06<00:35, 43.51it/s, est. speed input: 75092.61 toks/s, output: 73.33 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:07<00:35, 43.09it/s, est. speed input: 73397.18 toks/s, output: 71.68 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:07<00:35, 42.85it/s, est. speed input: 71888.74 toks/s, output: 70.20 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:07<00:35, 42.62it/s, est. speed input: 70508.41 toks/s, output: 68.86 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:08<00:34, 42.48it/s, est. speed input: 69257.91 toks/s, output: 67.63 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:08<00:34, 42.40it/s, est. speed input: 68122.23 toks/s, output: 66.53 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:09<00:34, 42.28it/s, est. speed input: 67066.89 toks/s, output: 65.49 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:09<00:34, 42.24it/s, est. speed input: 66105.84 toks/s, output: 64.56 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:09<00:33, 42.20it/s, est. speed input: 65217.32 toks/s, output: 63.69 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:10<00:33, 42.17it/s, est. speed input: 64395.22 toks/s, output: 62.89 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:10<00:32, 42.13it/s, est. speed input: 63628.16 toks/s, output: 62.14 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:10<00:32, 42.12it/s, est. speed input: 62916.50 toks/s, output: 61.44 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:11<00:32, 42.12it/s, est. speed input: 62254.25 toks/s, output: 60.79 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:11<00:31, 42.10it/s, est. speed input: 61631.64 toks/s, output: 60.19 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:12<00:31, 42.10it/s, est. speed input: 61050.12 toks/s, output: 59.62 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:12<00:31, 42.11it/s, est. speed input: 60506.64 toks/s, output: 59.09 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:12<00:30, 42.05it/s, est. speed input: 59984.46 toks/s, output: 58.58 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:13<00:30, 42.09it/s, est. speed input: 59503.28 toks/s, output: 58.11 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:13<00:29, 42.71it/s, est. speed input: 59125.77 toks/s, output: 57.74 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:13<00:29, 42.41it/s, est. speed input: 58676.80 toks/s, output: 57.30 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:14<00:29, 42.34it/s, est. speed input: 58268.24 toks/s, output: 56.90 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:14<00:28, 42.23it/s, est. speed input: 57872.94 toks/s, output: 56.52 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:15<00:28, 42.15it/s, est. speed input: 57497.40 toks/s, output: 56.15 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:15<00:28, 42.14it/s, est. speed input: 57146.19 toks/s, output: 55.81 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:15<00:27, 42.09it/s, est. speed input: 56805.97 toks/s, output: 55.47 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:16<00:27, 42.01it/s, est. speed input: 56477.46 toks/s, output: 55.15 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:16<00:27, 41.97it/s, est. speed input: 56165.65 toks/s, output: 54.85 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:17<00:26, 41.99it/s, est. speed input: 55872.77 toks/s, output: 54.56 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:17<00:26, 41.91it/s, est. speed input: 55583.35 toks/s, output: 54.28 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:17<00:25, 41.91it/s, est. speed input: 55312.41 toks/s, output: 54.02 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:18<00:25, 41.92it/s, est. speed input: 55052.79 toks/s, output: 53.76 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:18<00:25, 41.85it/s, est. speed input: 54797.08 toks/s, output: 53.51 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:18<00:24, 41.87it/s, est. speed input: 54557.91 toks/s, output: 53.28 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:19<00:24, 41.80it/s, est. speed input: 54321.40 toks/s, output: 53.05 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:19<00:24, 41.81it/s, est. speed input: 54098.46 toks/s, output: 52.83 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:20<00:23, 41.74it/s, est. speed input: 53878.17 toks/s, output: 52.62 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:20<00:23, 41.79it/s, est. speed input: 53673.58 toks/s, output: 52.42 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:20<00:22, 41.77it/s, est. speed input: 53472.35 toks/s, output: 52.22 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:21<00:22, 41.74it/s, est. speed input: 53277.37 toks/s, output: 52.03 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:21<00:22, 41.84it/s, est. speed input: 53097.94 toks/s, output: 51.85 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:22<00:21, 41.88it/s, est. speed input: 52922.83 toks/s, output: 51.68 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:22<00:21, 41.83it/s, est. speed input: 52748.10 toks/s, output: 51.51 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:22<00:20, 41.87it/s, est. speed input: 52584.41 toks/s, output: 51.35 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:23<00:20, 41.89it/s, est. speed input: 52425.68 toks/s, output: 51.20 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:23<00:19, 42.54it/s, est. speed input: 52314.44 toks/s, output: 51.09 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:23<00:19, 42.31it/s, est. speed input: 52162.01 toks/s, output: 50.94 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:24<00:18, 42.87it/s, est. speed input: 52059.69 toks/s, output: 50.84 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:24<00:18, 42.51it/s, est. speed input: 51913.74 toks/s, output: 50.70 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:25<00:18, 42.33it/s, est. speed input: 51776.92 toks/s, output: 50.56 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:25<00:18, 42.21it/s, est. speed input: 51643.81 toks/s, output: 50.43 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:25<00:17, 42.06it/s, est. speed input: 51511.53 toks/s, output: 50.30 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:26<00:17, 42.02it/s, est. speed input: 51386.31 toks/s, output: 50.18 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:26<00:16, 42.63it/s, est. speed input: 51301.68 toks/s, output: 50.10 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:26<00:16, 42.35it/s, est. speed input: 51179.39 toks/s, output: 49.98 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:27<00:16, 42.26it/s, est. speed input: 51066.10 toks/s, output: 49.87 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:27<00:15, 42.11it/s, est. speed input: 50951.13 toks/s, output: 49.76 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:28<00:15, 41.95it/s, est. speed input: 50836.79 toks/s, output: 49.65 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:28<00:15, 41.85it/s, est. speed input: 50725.78 toks/s, output: 49.54 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:28<00:14, 41.87it/s, est. speed input: 50622.39 toks/s, output: 49.44 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:29<00:14, 41.83it/s, est. speed input: 50518.86 toks/s, output: 49.33 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:29<00:13, 42.49it/s, est. speed input: 50453.63 toks/s, output: 49.27 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:29<00:13, 42.39it/s, est. speed input: 50361.20 toks/s, output: 49.18 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:30<00:13, 42.14it/s, est. speed input: 50262.21 toks/s, output: 49.08 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:30<00:12, 42.04it/s, est. speed input: 50169.41 toks/s, output: 48.99 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:31<00:12, 42.60it/s, est. speed input: 50109.05 toks/s, output: 48.93 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:31<00:12, 42.31it/s, est. speed input: 50018.43 toks/s, output: 48.85 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:31<00:11, 42.86it/s, est. speed input: 49964.37 toks/s, output: 48.79 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:32<00:11, 42.53it/s, est. speed input: 49879.11 toks/s, output: 48.71 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:32<00:10, 42.25it/s, est. speed input: 49793.14 toks/s, output: 48.63 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:32<00:10, 42.13it/s, est. speed input: 49713.05 toks/s, output: 48.55 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:33<00:10, 42.61it/s, est. speed input: 49659.40 toks/s, output: 48.50 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:33<00:09, 42.34it/s, est. speed input: 49580.44 toks/s, output: 48.42 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:34<00:09, 42.13it/s, est. speed input: 49502.61 toks/s, output: 48.34 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:34<00:09, 41.97it/s, est. speed input: 49425.73 toks/s, output: 48.27 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:34<00:08, 41.82it/s, est. speed input: 49348.83 toks/s, output: 48.19 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:35<00:08, 41.81it/s, est. speed input: 49277.49 toks/s, output: 48.12 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:35<00:08, 41.73it/s, est. speed input: 49205.00 toks/s, output: 48.05 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:36<00:07, 42.40it/s, est. speed input: 49163.59 toks/s, output: 48.01 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:36<00:07, 42.85it/s, est. speed input: 49121.99 toks/s, output: 47.97 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:36<00:06, 42.43it/s, est. speed input: 49052.25 toks/s, output: 47.90 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:37<00:06, 42.18it/s, est. speed input: 48985.57 toks/s, output: 47.84 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:37<00:06, 42.04it/s, est. speed input: 48921.45 toks/s, output: 47.77 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:37<00:05, 41.86it/s, est. speed input: 48855.57 toks/s, output: 47.71 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:38<00:05, 41.78it/s, est. speed input: 48792.61 toks/s, output: 47.65 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:38<00:04, 41.67it/s, est. speed input: 48728.88 toks/s, output: 47.59 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:39<00:04, 41.65it/s, est. speed input: 48668.50 toks/s, output: 47.53 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:39<00:04, 41.61it/s, est. speed input: 48608.50 toks/s, output: 47.47 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:39<00:03, 42.31it/s, est. speed input: 48576.53 toks/s, output: 47.44 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:40<00:03, 42.10it/s, est. speed input: 48519.64 toks/s, output: 47.38 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:40<00:03, 41.93it/s, est. speed input: 48462.77 toks/s, output: 47.33 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:40<00:02, 41.92it/s, est. speed input: 48410.97 toks/s, output: 47.28 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:41<00:02, 41.78it/s, est. speed input: 48355.37 toks/s, output: 47.22 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:41<00:01, 41.70it/s, est. speed input: 48301.46 toks/s, output: 47.17 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:42<00:01, 42.37it/s, est. speed input: 48273.54 toks/s, output: 47.14 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:42<00:01, 42.06it/s, est. speed input: 48219.83 toks/s, output: 47.09 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:42<00:00, 41.87it/s, est. speed input: 48167.49 toks/s, output: 47.04 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:43<00:00, 42.50it/s, est. speed input: 48141.88 toks/s, output: 47.01 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:43<00:00, 42.50it/s, est. speed input: 48472.85 toks/s, output: 47.34 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:43<00:00, 47.34it/s, est. speed input: 48472.85 toks/s, output: 47.34 toks/s]
[rank0]:[W126 12:08:50.738870472 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 12:08:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:09:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1336757) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1336757) WARNING 01-26 12:09:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 41.43 requests/s, 42463.70 total tokens/s, 41.43 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 12:09:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:09:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:09:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:09:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:09:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:09:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:09:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:09:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:09:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:09:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:09:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:09:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:09:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:09:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:09:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:09:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:09:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1336757) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1336757) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.15it/s]
(EngineCore_DP0 pid=1336757) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.55it/s]
(EngineCore_DP0 pid=1336757) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1336757) 
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1336757) [2026-01-26 12:09:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1336757) [rank0]:W0126 12:09:43.632000 1336757 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1336757) [rank0]:W0126 12:09:43.710000 1336757 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1336757) [rank0]:W0126 12:09:44.683000 1336757 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1336757) [rank0]:W0126 12:09:44.811000 1336757 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1336757) 2026-01-26 12:09:48,564 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1336757) 2026-01-26 12:09:48,590 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1336757) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:07,  1.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  1.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:01<00:02,  2.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:01<00:01,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  8.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00, 10.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 12.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.49it/s]
(EngineCore_DP0 pid=1336757) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  9.77it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  6.02it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  4.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  6.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:16, 253.07it/s]
Adding requests:   2%|▏         | 66/4096 [00:00<00:11, 337.74it/s]
Adding requests:   2%|▏         | 102/4096 [00:00<00:11, 346.90it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:11, 353.63it/s]
Adding requests:   4%|▍         | 177/4096 [00:00<00:10, 362.83it/s]
Adding requests:   5%|▌         | 216/4096 [00:00<00:10, 371.85it/s]
Adding requests:   6%|▌         | 254/4096 [00:00<00:10, 370.76it/s]
Adding requests:   7%|▋         | 292/4096 [00:00<00:10, 373.03it/s]
Adding requests:   8%|▊         | 331/4096 [00:00<00:09, 376.95it/s]
Adding requests:   9%|▉         | 371/4096 [00:01<00:09, 381.66it/s]
Adding requests:  10%|█         | 411/4096 [00:01<00:09, 385.84it/s]
Adding requests:  11%|█         | 450/4096 [00:01<00:09, 381.92it/s]
Adding requests:  12%|█▏        | 492/4096 [00:01<00:09, 393.02it/s]
Adding requests:  13%|█▎        | 533/4096 [00:01<00:08, 398.04it/s]
Adding requests:  14%|█▍        | 573/4096 [00:01<00:08, 394.82it/s]
Adding requests:  15%|█▍        | 613/4096 [00:01<00:09, 381.79it/s]
Adding requests:  16%|█▌        | 652/4096 [00:01<00:09, 374.48it/s]
Adding requests:  17%|█▋        | 691/4096 [00:01<00:08, 378.80it/s]
Adding requests:  18%|█▊        | 729/4096 [00:01<00:09, 370.41it/s]
Adding requests:  19%|█▊        | 767/4096 [00:02<00:08, 369.96it/s]
Adding requests:  20%|█▉        | 805/4096 [00:02<00:08, 371.74it/s]
Adding requests:  21%|██        | 844/4096 [00:02<00:08, 377.03it/s]
Adding requests:  22%|██▏       | 884/4096 [00:02<00:08, 382.20it/s]
Adding requests:  23%|██▎       | 923/4096 [00:02<00:08, 376.81it/s]
Adding requests:  23%|██▎       | 962/4096 [00:02<00:08, 379.40it/s]
Adding requests:  24%|██▍       | 1000/4096 [00:02<00:08, 375.31it/s]
Adding requests:  25%|██▌       | 1038/4096 [00:02<00:08, 375.77it/s]
Adding requests:  26%|██▋       | 1076/4096 [00:02<00:08, 372.84it/s]
Adding requests:  27%|██▋       | 1114/4096 [00:02<00:07, 373.47it/s]
Adding requests:  28%|██▊       | 1152/4096 [00:03<00:07, 375.15it/s]
Adding requests:  29%|██▉       | 1190/4096 [00:03<00:07, 366.52it/s]
Adding requests:  30%|███       | 1229/4096 [00:03<00:07, 373.27it/s]
Adding requests:  31%|███       | 1268/4096 [00:03<00:07, 375.25it/s]
Adding requests:  32%|███▏      | 1306/4096 [00:03<00:07, 376.56it/s]
Adding requests:  33%|███▎      | 1345/4096 [00:03<00:07, 380.31it/s]
Adding requests:  34%|███▍      | 1385/4096 [00:03<00:07, 385.14it/s]
Adding requests:  35%|███▍      | 1424/4096 [00:03<00:07, 381.51it/s]
Adding requests:  36%|███▌      | 1464/4096 [00:03<00:06, 384.36it/s]
Adding requests:  37%|███▋      | 1503/4096 [00:03<00:06, 385.66it/s]
Adding requests:  38%|███▊      | 1542/4096 [00:04<00:06, 386.79it/s]
Adding requests:  39%|███▊      | 1581/4096 [00:04<00:06, 376.69it/s]
Adding requests:  40%|███▉      | 1619/4096 [00:04<00:06, 371.95it/s]
Adding requests:  40%|████      | 1657/4096 [00:04<00:06, 366.75it/s]
Adding requests:  41%|████▏     | 1694/4096 [00:04<00:06, 367.14it/s]
Adding requests:  42%|████▏     | 1733/4096 [00:04<00:06, 372.97it/s]
Adding requests:  43%|████▎     | 1773/4096 [00:04<00:06, 380.10it/s]
Adding requests:  44%|████▍     | 1812/4096 [00:04<00:06, 377.96it/s]
Adding requests:  45%|████▌     | 1850/4096 [00:04<00:05, 375.24it/s]
Adding requests:  46%|████▌     | 1889/4096 [00:05<00:05, 377.67it/s]
Adding requests:  47%|████▋     | 1928/4096 [00:05<00:05, 380.40it/s]
Adding requests:  48%|████▊     | 1967/4096 [00:05<00:05, 379.68it/s]
Adding requests:  49%|████▉     | 2005/4096 [00:05<00:05, 375.36it/s]
Adding requests:  50%|████▉     | 2043/4096 [00:05<00:05, 369.62it/s]
Adding requests:  51%|█████     | 2080/4096 [00:05<00:05, 358.23it/s]
Adding requests:  52%|█████▏    | 2119/4096 [00:05<00:05, 365.56it/s]
Adding requests:  53%|█████▎    | 2156/4096 [00:05<00:05, 363.96it/s]
Adding requests:  54%|█████▎    | 2193/4096 [00:05<00:05, 359.62it/s]
Adding requests:  54%|█████▍    | 2229/4096 [00:05<00:05, 359.40it/s]
Adding requests:  55%|█████▌    | 2268/4096 [00:06<00:04, 367.64it/s]
Adding requests:  56%|█████▋    | 2306/4096 [00:06<00:04, 370.57it/s]
Adding requests:  57%|█████▋    | 2346/4096 [00:06<00:04, 375.90it/s]
Adding requests:  58%|█████▊    | 2386/4096 [00:06<00:04, 382.29it/s]
Adding requests:  59%|█████▉    | 2425/4096 [00:06<00:04, 371.65it/s]
Adding requests:  60%|██████    | 2463/4096 [00:06<00:04, 368.53it/s]
Adding requests:  61%|██████    | 2503/4096 [00:06<00:04, 374.74it/s]
Adding requests:  62%|██████▏   | 2543/4096 [00:06<00:04, 380.86it/s]
Adding requests:  63%|██████▎   | 2584/4096 [00:06<00:03, 388.95it/s]
Adding requests:  64%|██████▍   | 2623/4096 [00:06<00:03, 382.08it/s]
Adding requests:  65%|██████▍   | 2662/4096 [00:07<00:03, 374.33it/s]
Adding requests:  66%|██████▌   | 2700/4096 [00:07<00:03, 371.96it/s]
Adding requests:  67%|██████▋   | 2738/4096 [00:07<00:03, 370.80it/s]
Adding requests:  68%|██████▊   | 2777/4096 [00:07<00:03, 375.45it/s]
Adding requests:  69%|██████▉   | 2818/4096 [00:07<00:03, 384.87it/s]
Adding requests:  70%|██████▉   | 2857/4096 [00:07<00:03, 382.35it/s]
Adding requests:  71%|███████   | 2896/4096 [00:07<00:03, 380.87it/s]
Adding requests:  72%|███████▏  | 2935/4096 [00:07<00:03, 381.73it/s]
Adding requests:  73%|███████▎  | 2974/4096 [00:07<00:02, 380.14it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:08<00:02, 385.43it/s]
Adding requests:  75%|███████▍  | 3055/4096 [00:08<00:02, 386.98it/s]
Adding requests:  76%|███████▌  | 3094/4096 [00:08<00:02, 385.13it/s]
Adding requests:  77%|███████▋  | 3134/4096 [00:08<00:02, 388.80it/s]
Adding requests:  77%|███████▋  | 3173/4096 [00:08<00:02, 380.29it/s]
Adding requests:  78%|███████▊  | 3212/4096 [00:08<00:02, 375.99it/s]
Adding requests:  79%|███████▉  | 3253/4096 [00:08<00:02, 383.73it/s]
Adding requests:  80%|████████  | 3292/4096 [00:08<00:02, 368.36it/s]
Adding requests:  81%|████████▏ | 3329/4096 [00:08<00:02, 364.89it/s]
Adding requests:  82%|████████▏ | 3368/4096 [00:08<00:01, 369.64it/s]
Adding requests:  83%|████████▎ | 3407/4096 [00:09<00:01, 374.04it/s]
Adding requests:  84%|████████▍ | 3446/4096 [00:09<00:01, 377.95it/s]
Adding requests:  85%|████████▌ | 3484/4096 [00:09<00:01, 376.32it/s]
Adding requests:  86%|████████▌ | 3523/4096 [00:09<00:01, 378.63it/s]
Adding requests:  87%|████████▋ | 3564/4096 [00:09<00:01, 387.17it/s]
Adding requests:  88%|████████▊ | 3603/4096 [00:09<00:01, 380.79it/s]
Adding requests:  89%|████████▉ | 3642/4096 [00:09<00:01, 381.67it/s]
Adding requests:  90%|████████▉ | 3681/4096 [00:09<00:01, 373.62it/s]
Adding requests:  91%|█████████ | 3721/4096 [00:09<00:00, 378.23it/s]
Adding requests:  92%|█████████▏| 3759/4096 [00:10<00:00, 368.69it/s]
Adding requests:  93%|█████████▎| 3796/4096 [00:10<00:00, 348.30it/s]
Adding requests:  94%|█████████▎| 3832/4096 [00:10<00:00, 348.68it/s]
Adding requests:  95%|█████████▍| 3871/4096 [00:10<00:00, 357.41it/s]
Adding requests:  95%|█████████▌| 3907/4096 [00:10<00:00, 353.59it/s]
Adding requests:  96%|█████████▋| 3943/4096 [00:10<00:00, 355.32it/s]
Adding requests:  97%|█████████▋| 3979/4096 [00:10<00:00, 356.44it/s]
Adding requests:  98%|█████████▊| 4017/4096 [00:10<00:00, 362.86it/s]
Adding requests:  99%|█████████▉| 4054/4096 [00:10<00:00, 361.59it/s]
Adding requests: 100%|█████████▉| 4091/4096 [00:10<00:00, 363.16it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 373.76it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█         | 437/4096 [00:00<00:04, 855.77it/s, est. speed input: 876352.87 toks/s, output: 855.78 toks/s]
Processed prompts:  13%|█▎        | 523/4096 [00:02<00:17, 207.86it/s, est. speed input: 262708.21 toks/s, output: 256.55 toks/s]
Processed prompts:  14%|█▎        | 562/4096 [00:02<00:23, 150.33it/s, est. speed input: 205303.93 toks/s, output: 200.49 toks/s]
Processed prompts:  14%|█▍        | 586/4096 [00:03<00:32, 109.38it/s, est. speed input: 168146.94 toks/s, output: 164.21 toks/s]
Processed prompts:  15%|█▍        | 602/4096 [00:04<00:43, 80.28it/s, est. speed input: 142286.50 toks/s, output: 138.95 toks/s] 
Processed prompts:  15%|█▌        | 629/4096 [00:05<00:52, 65.85it/s, est. speed input: 126326.50 toks/s, output: 123.36 toks/s]
Processed prompts:  16%|█▌        | 661/4096 [00:05<00:58, 58.29it/s, est. speed input: 115411.67 toks/s, output: 112.71 toks/s]
Processed prompts:  17%|█▋        | 693/4096 [00:06<01:03, 53.17it/s, est. speed input: 107021.38 toks/s, output: 104.51 toks/s]
Processed prompts:  18%|█▊        | 725/4096 [00:07<01:07, 49.69it/s, est. speed input: 100378.83 toks/s, output: 98.03 toks/s] 
Processed prompts:  18%|█▊        | 757/4096 [00:08<01:10, 47.59it/s, est. speed input: 95163.81 toks/s, output: 92.93 toks/s] 
Processed prompts:  19%|█▉        | 789/4096 [00:08<01:12, 45.79it/s, est. speed input: 90645.57 toks/s, output: 88.52 toks/s]
Processed prompts:  20%|██        | 821/4096 [00:09<01:13, 44.51it/s, est. speed input: 86825.39 toks/s, output: 84.79 toks/s]
Processed prompts:  21%|██        | 853/4096 [00:10<01:14, 43.67it/s, est. speed input: 83590.74 toks/s, output: 81.63 toks/s]
Processed prompts:  22%|██▏       | 885/4096 [00:11<01:14, 43.10it/s, est. speed input: 80800.50 toks/s, output: 78.91 toks/s]
Processed prompts:  22%|██▏       | 917/4096 [00:11<01:14, 42.65it/s, est. speed input: 78352.51 toks/s, output: 76.52 toks/s]
Processed prompts:  23%|██▎       | 949/4096 [00:12<01:14, 42.34it/s, est. speed input: 76195.77 toks/s, output: 74.41 toks/s]
Processed prompts:  24%|██▍       | 981/4096 [00:13<01:13, 42.11it/s, est. speed input: 74284.62 toks/s, output: 72.54 toks/s]
Processed prompts:  25%|██▍       | 1013/4096 [00:14<01:13, 41.98it/s, est. speed input: 72584.37 toks/s, output: 70.88 toks/s]
Processed prompts:  26%|██▌       | 1045/4096 [00:15<01:12, 41.83it/s, est. speed input: 71044.56 toks/s, output: 69.38 toks/s]
Processed prompts:  26%|██▋       | 1077/4096 [00:15<01:12, 41.75it/s, est. speed input: 69658.54 toks/s, output: 68.03 toks/s]
Processed prompts:  27%|██▋       | 1109/4096 [00:16<01:11, 41.69it/s, est. speed input: 68401.87 toks/s, output: 66.80 toks/s]
Processed prompts:  28%|██▊       | 1141/4096 [00:17<01:10, 41.70it/s, est. speed input: 67267.20 toks/s, output: 65.69 toks/s]
Processed prompts:  29%|██▊       | 1173/4096 [00:18<01:10, 41.67it/s, est. speed input: 66220.39 toks/s, output: 64.67 toks/s]
Processed prompts:  29%|██▉       | 1205/4096 [00:18<01:08, 41.96it/s, est. speed input: 65325.87 toks/s, output: 63.79 toks/s]
Processed prompts:  30%|███       | 1237/4096 [00:19<01:07, 42.13it/s, est. speed input: 64490.92 toks/s, output: 62.98 toks/s]
Processed prompts:  31%|███       | 1269/4096 [00:20<01:07, 41.96it/s, est. speed input: 63664.66 toks/s, output: 62.17 toks/s]
Processed prompts:  32%|███▏      | 1301/4096 [00:21<01:06, 41.83it/s, est. speed input: 62896.46 toks/s, output: 61.42 toks/s]
Processed prompts:  33%|███▎      | 1333/4096 [00:21<01:05, 42.03it/s, est. speed input: 62230.99 toks/s, output: 60.77 toks/s]
Processed prompts:  33%|███▎      | 1365/4096 [00:22<01:05, 41.82it/s, est. speed input: 61553.21 toks/s, output: 60.11 toks/s]
Processed prompts:  34%|███▍      | 1397/4096 [00:23<01:04, 41.73it/s, est. speed input: 60928.32 toks/s, output: 59.50 toks/s]
Processed prompts:  35%|███▍      | 1429/4096 [00:24<01:03, 41.94it/s, est. speed input: 60383.80 toks/s, output: 58.97 toks/s]
Processed prompts:  36%|███▌      | 1461/4096 [00:25<01:03, 41.77it/s, est. speed input: 59827.78 toks/s, output: 58.43 toks/s]
Processed prompts:  36%|███▋      | 1493/4096 [00:25<01:02, 41.70it/s, est. speed input: 59310.85 toks/s, output: 57.92 toks/s]
Processed prompts:  37%|███▋      | 1525/4096 [00:26<01:01, 41.88it/s, est. speed input: 58854.74 toks/s, output: 57.48 toks/s]
Processed prompts:  38%|███▊      | 1557/4096 [00:27<01:00, 42.03it/s, est. speed input: 58427.61 toks/s, output: 57.06 toks/s]
Processed prompts:  39%|███▉      | 1589/4096 [00:28<00:59, 41.85it/s, est. speed input: 57986.92 toks/s, output: 56.63 toks/s]
Processed prompts:  40%|███▉      | 1621/4096 [00:28<00:58, 41.98it/s, est. speed input: 57601.53 toks/s, output: 56.25 toks/s]
Processed prompts:  40%|████      | 1653/4096 [00:29<00:58, 41.78it/s, est. speed input: 57201.01 toks/s, output: 55.86 toks/s]
Processed prompts:  41%|████      | 1685/4096 [00:30<00:57, 41.67it/s, est. speed input: 56824.57 toks/s, output: 55.49 toks/s]
Processed prompts:  42%|████▏     | 1717/4096 [00:31<00:56, 41.84it/s, est. speed input: 56494.77 toks/s, output: 55.17 toks/s]
Processed prompts:  43%|████▎     | 1749/4096 [00:31<00:55, 41.97it/s, est. speed input: 56180.68 toks/s, output: 54.86 toks/s]
Processed prompts:  43%|████▎     | 1781/4096 [00:32<00:55, 41.79it/s, est. speed input: 55853.72 toks/s, output: 54.54 toks/s]
Processed prompts:  44%|████▍     | 1813/4096 [00:33<00:54, 41.65it/s, est. speed input: 55540.28 toks/s, output: 54.24 toks/s]
Processed prompts:  45%|████▌     | 1845/4096 [00:34<00:54, 41.53it/s, est. speed input: 55239.05 toks/s, output: 53.94 toks/s]
Processed prompts:  46%|████▌     | 1877/4096 [00:34<00:53, 41.79it/s, est. speed input: 54983.43 toks/s, output: 53.69 toks/s]
Processed prompts:  47%|████▋     | 1909/4096 [00:35<00:52, 41.66it/s, est. speed input: 54710.62 toks/s, output: 53.43 toks/s]
Processed prompts:  47%|████▋     | 1941/4096 [00:36<00:51, 41.52it/s, est. speed input: 54444.04 toks/s, output: 53.17 toks/s]
Processed prompts:  48%|████▊     | 1973/4096 [00:37<00:50, 41.76it/s, est. speed input: 54218.76 toks/s, output: 52.95 toks/s]
Processed prompts:  49%|████▉     | 2005/4096 [00:38<00:50, 41.61it/s, est. speed input: 53974.74 toks/s, output: 52.71 toks/s]
Processed prompts:  50%|████▉     | 2037/4096 [00:38<00:49, 41.52it/s, est. speed input: 53741.57 toks/s, output: 52.48 toks/s]
Processed prompts:  51%|█████     | 2069/4096 [00:39<00:48, 41.67it/s, est. speed input: 53535.51 toks/s, output: 52.28 toks/s]
Processed prompts:  51%|█████▏    | 2101/4096 [00:40<00:48, 41.51it/s, est. speed input: 53315.45 toks/s, output: 52.07 toks/s]
Processed prompts:  52%|█████▏    | 2133/4096 [00:41<00:47, 41.43it/s, est. speed input: 53106.61 toks/s, output: 51.86 toks/s]
Processed prompts:  53%|█████▎    | 2165/4096 [00:41<00:46, 41.65it/s, est. speed input: 52927.21 toks/s, output: 51.69 toks/s]
Processed prompts:  54%|█████▎    | 2197/4096 [00:42<00:45, 41.52it/s, est. speed input: 52731.70 toks/s, output: 51.50 toks/s]
Processed prompts:  54%|█████▍    | 2229/4096 [00:43<00:45, 41.43it/s, est. speed input: 52544.19 toks/s, output: 51.31 toks/s]
Processed prompts:  55%|█████▌    | 2261/4096 [00:44<00:44, 41.39it/s, est. speed input: 52364.56 toks/s, output: 51.14 toks/s]
Processed prompts:  56%|█████▌    | 2293/4096 [00:44<00:43, 41.34it/s, est. speed input: 52189.44 toks/s, output: 50.97 toks/s]
Processed prompts:  57%|█████▋    | 2325/4096 [00:45<00:42, 41.28it/s, est. speed input: 52018.12 toks/s, output: 50.80 toks/s]
Processed prompts:  58%|█████▊    | 2357/4096 [00:46<00:42, 41.26it/s, est. speed input: 51854.38 toks/s, output: 50.64 toks/s]
Processed prompts:  58%|█████▊    | 2389/4096 [00:47<00:41, 41.25it/s, est. speed input: 51696.20 toks/s, output: 50.48 toks/s]
Processed prompts:  59%|█████▉    | 2421/4096 [00:48<00:40, 41.25it/s, est. speed input: 51543.60 toks/s, output: 50.34 toks/s]
Processed prompts:  60%|█████▉    | 2453/4096 [00:48<00:39, 41.21it/s, est. speed input: 51393.36 toks/s, output: 50.19 toks/s]
Processed prompts:  61%|██████    | 2485/4096 [00:49<00:39, 41.22it/s, est. speed input: 51250.16 toks/s, output: 50.05 toks/s]
Processed prompts:  61%|██████▏   | 2517/4096 [00:50<00:38, 41.45it/s, est. speed input: 51125.32 toks/s, output: 49.93 toks/s]
Processed prompts:  62%|██████▏   | 2549/4096 [00:51<00:37, 41.36it/s, est. speed input: 50988.73 toks/s, output: 49.79 toks/s]
Processed prompts:  63%|██████▎   | 2581/4096 [00:51<00:36, 41.53it/s, est. speed input: 50870.93 toks/s, output: 49.68 toks/s]
Processed prompts:  64%|██████▍   | 2613/4096 [00:52<00:35, 41.42it/s, est. speed input: 50742.52 toks/s, output: 49.55 toks/s]
Processed prompts:  65%|██████▍   | 2645/4096 [00:53<00:35, 41.33it/s, est. speed input: 50616.69 toks/s, output: 49.43 toks/s]
Processed prompts:  65%|██████▌   | 2677/4096 [00:54<00:34, 41.28it/s, est. speed input: 50495.66 toks/s, output: 49.31 toks/s]
Processed prompts:  66%|██████▌   | 2709/4096 [00:55<00:33, 41.28it/s, est. speed input: 50379.63 toks/s, output: 49.20 toks/s]
Processed prompts:  67%|██████▋   | 2741/4096 [00:55<00:32, 41.52it/s, est. speed input: 50280.80 toks/s, output: 49.10 toks/s]
Processed prompts:  68%|██████▊   | 2773/4096 [00:56<00:31, 41.40it/s, est. speed input: 50168.10 toks/s, output: 48.99 toks/s]
Processed prompts:  68%|██████▊   | 2805/4096 [00:57<00:31, 41.32it/s, est. speed input: 50059.07 toks/s, output: 48.89 toks/s]
Processed prompts:  69%|██████▉   | 2837/4096 [00:58<00:30, 41.27it/s, est. speed input: 49953.40 toks/s, output: 48.78 toks/s]
Processed prompts:  70%|███████   | 2869/4096 [00:58<00:29, 41.21it/s, est. speed input: 49849.07 toks/s, output: 48.68 toks/s]
Processed prompts:  71%|███████   | 2901/4096 [00:59<00:28, 42.26it/s, est. speed input: 49803.07 toks/s, output: 48.64 toks/s]
Processed prompts:  72%|███████▏  | 2933/4096 [01:00<00:27, 41.91it/s, est. speed input: 49703.93 toks/s, output: 48.54 toks/s]
Processed prompts:  72%|███████▏  | 2965/4096 [01:01<00:27, 41.67it/s, est. speed input: 49607.27 toks/s, output: 48.44 toks/s]
Processed prompts:  73%|███████▎  | 2997/4096 [01:01<00:26, 41.49it/s, est. speed input: 49512.69 toks/s, output: 48.35 toks/s]
Processed prompts:  74%|███████▍  | 3029/4096 [01:02<00:25, 41.39it/s, est. speed input: 49421.08 toks/s, output: 48.26 toks/s]
Processed prompts:  75%|███████▍  | 3061/4096 [01:03<00:25, 41.28it/s, est. speed input: 49330.25 toks/s, output: 48.17 toks/s]
Processed prompts:  76%|███████▌  | 3093/4096 [01:04<00:24, 41.23it/s, est. speed input: 49242.98 toks/s, output: 48.09 toks/s]
Processed prompts:  76%|███████▋  | 3125/4096 [01:05<00:23, 41.16it/s, est. speed input: 49155.54 toks/s, output: 48.00 toks/s]
Processed prompts:  77%|███████▋  | 3157/4096 [01:05<00:22, 41.13it/s, est. speed input: 49071.75 toks/s, output: 47.92 toks/s]
Processed prompts:  78%|███████▊  | 3189/4096 [01:06<00:22, 41.09it/s, est. speed input: 48988.81 toks/s, output: 47.84 toks/s]
Processed prompts:  79%|███████▊  | 3221/4096 [01:07<00:21, 41.07it/s, est. speed input: 48907.74 toks/s, output: 47.76 toks/s]
Processed prompts:  79%|███████▉  | 3253/4096 [01:08<00:20, 41.03it/s, est. speed input: 48828.00 toks/s, output: 47.68 toks/s]
Processed prompts:  80%|████████  | 3285/4096 [01:08<00:19, 41.05it/s, est. speed input: 48751.62 toks/s, output: 47.61 toks/s]
Processed prompts:  81%|████████  | 3317/4096 [01:09<00:18, 41.03it/s, est. speed input: 48675.74 toks/s, output: 47.53 toks/s]
Processed prompts:  82%|████████▏ | 3349/4096 [01:10<00:18, 41.03it/s, est. speed input: 48602.04 toks/s, output: 47.46 toks/s]
Processed prompts:  83%|████████▎ | 3381/4096 [01:11<00:17, 41.02it/s, est. speed input: 48529.72 toks/s, output: 47.39 toks/s]
Processed prompts:  83%|████████▎ | 3413/4096 [01:12<00:16, 41.02it/s, est. speed input: 48459.16 toks/s, output: 47.32 toks/s]
Processed prompts:  84%|████████▍ | 3445/4096 [01:12<00:15, 41.00it/s, est. speed input: 48389.26 toks/s, output: 47.26 toks/s]
Processed prompts:  85%|████████▍ | 3477/4096 [01:13<00:15, 41.00it/s, est. speed input: 48321.22 toks/s, output: 47.19 toks/s]
Processed prompts:  86%|████████▌ | 3509/4096 [01:14<00:14, 41.01it/s, est. speed input: 48255.43 toks/s, output: 47.12 toks/s]
Processed prompts:  86%|████████▋ | 3541/4096 [01:15<00:13, 41.26it/s, est. speed input: 48200.39 toks/s, output: 47.07 toks/s]
Processed prompts:  87%|████████▋ | 3573/4096 [01:16<00:12, 41.18it/s, est. speed input: 48136.76 toks/s, output: 47.01 toks/s]
Processed prompts:  88%|████████▊ | 3605/4096 [01:16<00:11, 41.12it/s, est. speed input: 48073.94 toks/s, output: 46.95 toks/s]
Processed prompts:  89%|████████▉ | 3637/4096 [01:17<00:11, 41.07it/s, est. speed input: 48012.04 toks/s, output: 46.89 toks/s]
Processed prompts:  90%|████████▉ | 3669/4096 [01:18<00:10, 41.28it/s, est. speed input: 47960.77 toks/s, output: 46.84 toks/s]
Processed prompts:  90%|█████████ | 3701/4096 [01:19<00:09, 41.18it/s, est. speed input: 47901.32 toks/s, output: 46.78 toks/s]
Processed prompts:  91%|█████████ | 3733/4096 [01:19<00:08, 41.11it/s, est. speed input: 47842.81 toks/s, output: 46.72 toks/s]
Processed prompts:  92%|█████████▏| 3765/4096 [01:20<00:08, 41.03it/s, est. speed input: 47784.50 toks/s, output: 46.66 toks/s]
Processed prompts:  93%|█████████▎| 3797/4096 [01:21<00:07, 41.00it/s, est. speed input: 47728.19 toks/s, output: 46.61 toks/s]
Processed prompts:  93%|█████████▎| 3829/4096 [01:22<00:06, 41.00it/s, est. speed input: 47673.70 toks/s, output: 46.56 toks/s]
Processed prompts:  94%|█████████▍| 3861/4096 [01:23<00:05, 40.98it/s, est. speed input: 47619.42 toks/s, output: 46.50 toks/s]
Processed prompts:  95%|█████████▌| 3893/4096 [01:23<00:04, 40.94it/s, est. speed input: 47565.26 toks/s, output: 46.45 toks/s]
Processed prompts:  96%|█████████▌| 3925/4096 [01:24<00:04, 41.68it/s, est. speed input: 47539.16 toks/s, output: 46.42 toks/s]
Processed prompts:  97%|█████████▋| 3957/4096 [01:25<00:03, 41.44it/s, est. speed input: 47487.16 toks/s, output: 46.37 toks/s]
Processed prompts:  97%|█████████▋| 3989/4096 [01:26<00:02, 41.60it/s, est. speed input: 47447.28 toks/s, output: 46.34 toks/s]
Processed prompts:  98%|█████████▊| 4021/4096 [01:26<00:01, 41.39it/s, est. speed input: 47397.15 toks/s, output: 46.29 toks/s]
Processed prompts:  99%|█████████▉| 4053/4096 [01:27<00:01, 41.54it/s, est. speed input: 47358.18 toks/s, output: 46.25 toks/s]
Processed prompts: 100%|█████████▉| 4085/4096 [01:27<00:00, 51.57it/s, est. speed input: 47584.82 toks/s, output: 46.47 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:27<00:00, 51.57it/s, est. speed input: 47712.63 toks/s, output: 46.59 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:27<00:00, 46.59it/s, est. speed input: 47712.63 toks/s, output: 46.59 toks/s]
[rank0]:[W126 12:11:32.179980932 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 12:11:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:12:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1339655) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1339655) WARNING 01-26 12:12:42 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     def forward(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     raise e
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/tmp/torchinductor_root/y5/cy5qjxhrsxksh4kah7hlt7wnw7gzmouaejj2p54lihbs2v3ejlob.py", line 1093, in call
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 6)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 233, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) ERROR 01-26 12:12:51 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered

STDERR:
[2026-01-26 12:12:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:12:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:12:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:12:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:12:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:12:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:12:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:12:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:12:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:12:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:12:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:12:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:12:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:12:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:12:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:12:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:12:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1339655) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1339655) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=1339655) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]
(EngineCore_DP0 pid=1339655) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]
(EngineCore_DP0 pid=1339655) 
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13824000 bytes
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10752000 bytes
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113664000 bytes
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1339655) [2026-01-26 12:12:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56627200 bytes
(EngineCore_DP0 pid=1339655) [rank0]:W0126 12:12:48.466000 1339655 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1339655) [rank0]:W0126 12:12:48.546000 1339655 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1339655) [rank0]:W0126 12:12:49.989000 1339655 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1339655) [rank0]:W0126 12:12:50.112000 1339655 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1339655) Process EngineCore_DP0:
(EngineCore_DP0 pid=1339655) Traceback (most recent call last):
(EngineCore_DP0 pid=1339655)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1339655)     self.run()
(EngineCore_DP0 pid=1339655)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1339655)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1339655)     raise e
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1339655)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1339655)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1339655)     super().__init__(
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1339655)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1339655)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1339655)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1339655)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1339655)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1339655)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1339655)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1339655)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1339655)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1339655)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1339655)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1339655)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1339655)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1339655)     outputs = self.model(
(EngineCore_DP0 pid=1339655)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1339655)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1339655)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1339655)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1339655)     hidden_states = self.model(
(EngineCore_DP0 pid=1339655)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1339655)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1339655)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1339655)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1339655)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1339655)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1339655)     def forward(
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1339655)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1339655)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1339655)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1339655)     raise e
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1339655)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1339655)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1339655)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1339655)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1339655)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1339655)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1339655)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1339655)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1339655)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1339655)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1339655)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1339655)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1339655)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1339655)                             ^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1339655)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1339655)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1339655)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1339655)     out = model(new_inputs)
(EngineCore_DP0 pid=1339655)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/tmp/torchinductor_root/y5/cy5qjxhrsxksh4kah7hlt7wnw7gzmouaejj2p54lihbs2v3ejlob.py", line 1093, in call
(EngineCore_DP0 pid=1339655)     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 6)
(EngineCore_DP0 pid=1339655)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=1339655)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1339655)     return fn(input, L)
(EngineCore_DP0 pid=1339655)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/H100_cc90_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 233, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1339655)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=1339655)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=1339655)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=1339655)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=1339655)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=1339655)     self._init_handles()
(EngineCore_DP0 pid=1339655)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=1339655)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=1339655)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1339655) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 12:12:51.907742918 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 14:55:08
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:55:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1505540) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1505540) WARNING 01-26 14:55:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.25 requests/s, 11415.91 total tokens/s, 22.25 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 14:55:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:55:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:55:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:55:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:55:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:55:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:55:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:55:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:55:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:55:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:55:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:55:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:55:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:55:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:55:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:55:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:55:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.38it/s]
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.27it/s]
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.71it/s]
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.53it/s]
(EngineCore_DP0 pid=1505540) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.51it/s]
(EngineCore_DP0 pid=1505540) 
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1505540) [2026-01-26 14:55:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1505540) 2026-01-26 14:55:52,135 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1505540) 2026-01-26 14:55:52,186 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1505540) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]
(EngineCore_DP0 pid=1505540) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.62it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  30%|███       | 39/128 [00:00<00:00, 385.22it/s]
Adding requests:  87%|████████▋ | 111/128 [00:00<00:00, 577.39it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 564.85it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:08, 15.33it/s, est. speed input: 7849.62 toks/s, output: 15.33 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 20.43it/s, est. speed input: 10057.85 toks/s, output: 19.64 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:05, 22.20it/s, est. speed input: 10846.34 toks/s, output: 21.18 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 23.06it/s, est. speed input: 11250.89 toks/s, output: 21.97 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:04, 23.17it/s, est. speed input: 11396.45 toks/s, output: 22.26 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 23.18it/s, est. speed input: 11477.94 toks/s, output: 22.42 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:04, 23.16it/s, est. speed input: 11530.59 toks/s, output: 22.52 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:04, 23.18it/s, est. speed input: 11576.41 toks/s, output: 22.61 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:04, 23.17it/s, est. speed input: 11607.91 toks/s, output: 22.67 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:04, 23.18it/s, est. speed input: 11634.83 toks/s, output: 22.72 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:04, 23.20it/s, est. speed input: 11659.81 toks/s, output: 22.77 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:04, 23.23it/s, est. speed input: 11682.10 toks/s, output: 22.82 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:03, 23.28it/s, est. speed input: 11704.51 toks/s, output: 22.86 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:03, 23.26it/s, est. speed input: 11717.89 toks/s, output: 22.89 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:03, 23.27it/s, est. speed input: 11732.12 toks/s, output: 22.91 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:03, 23.27it/s, est. speed input: 11743.58 toks/s, output: 22.94 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:03, 23.23it/s, est. speed input: 11749.23 toks/s, output: 22.95 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 23.25it/s, est. speed input: 11758.96 toks/s, output: 22.97 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 23.28it/s, est. speed input: 11769.48 toks/s, output: 22.99 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:02, 23.31it/s, est. speed input: 11779.36 toks/s, output: 23.01 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:02<00:02, 23.28it/s, est. speed input: 11784.39 toks/s, output: 23.02 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:02, 23.29it/s, est. speed input: 11791.25 toks/s, output: 23.03 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:02, 23.28it/s, est. speed input: 11796.45 toks/s, output: 23.04 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:02, 23.31it/s, est. speed input: 11803.38 toks/s, output: 23.05 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 23.31it/s, est. speed input: 11809.07 toks/s, output: 23.06 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 23.33it/s, est. speed input: 11814.95 toks/s, output: 23.08 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:03<00:02, 23.33it/s, est. speed input: 11819.58 toks/s, output: 23.08 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:01, 23.34it/s, est. speed input: 11825.08 toks/s, output: 23.10 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:03<00:01, 23.30it/s, est. speed input: 11826.99 toks/s, output: 23.10 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 23.31it/s, est. speed input: 11831.10 toks/s, output: 23.11 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 23.28it/s, est. speed input: 11832.73 toks/s, output: 23.11 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:01, 23.31it/s, est. speed input: 11837.14 toks/s, output: 23.12 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:04<00:01, 23.33it/s, est. speed input: 11840.93 toks/s, output: 23.13 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 23.33it/s, est. speed input: 11844.04 toks/s, output: 23.13 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:04<00:01, 23.33it/s, est. speed input: 11847.04 toks/s, output: 23.14 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:04<00:00, 23.35it/s, est. speed input: 11850.41 toks/s, output: 23.15 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:04<00:00, 23.35it/s, est. speed input: 11853.39 toks/s, output: 23.15 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:04<00:00, 23.33it/s, est. speed input: 11855.14 toks/s, output: 23.15 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:05<00:00, 23.34it/s, est. speed input: 11857.81 toks/s, output: 23.16 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 23.30it/s, est. speed input: 11858.53 toks/s, output: 23.16 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 23.32it/s, est. speed input: 11861.19 toks/s, output: 23.17 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:05<00:00, 23.33it/s, est. speed input: 11863.56 toks/s, output: 23.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.32it/s, est. speed input: 11864.97 toks/s, output: 23.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.32it/s, est. speed input: 11864.97 toks/s, output: 23.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.17it/s, est. speed input: 11864.97 toks/s, output: 23.17 toks/s]
[rank0]:[W126 14:56:01.225972272 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 14:56:03
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:56:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1506856) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1506856) WARNING 01-26 14:56:31 [backends.py:609] Failed to read file <frozen os>
Throughput: 18.16 requests/s, 18612.78 total tokens/s, 18.16 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 14:56:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:56:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:56:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:56:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:56:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:56:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:56:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:56:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:56:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:56:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:56:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:56:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:56:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:56:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:56:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:56:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:56:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:18] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.42it/s]
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.57it/s]
(EngineCore_DP0 pid=1506856) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.54it/s]
(EngineCore_DP0 pid=1506856) 
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1506856) [2026-01-26 14:56:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1506856) 2026-01-26 14:56:46,016 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1506856) 2026-01-26 14:56:46,079 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1506856) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.52it/s]
(EngineCore_DP0 pid=1506856) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.90it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  15%|█▍        | 19/128 [00:00<00:00, 184.55it/s]
Adding requests:  45%|████▌     | 58/128 [00:00<00:00, 303.68it/s]
Adding requests:  75%|███████▌  | 96/128 [00:00<00:00, 334.44it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 327.49it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:06, 19.57it/s, est. speed input: 20046.19 toks/s, output: 19.57 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:06, 19.75it/s, est. speed input: 20198.75 toks/s, output: 19.72 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:06, 19.51it/s, est. speed input: 20031.98 toks/s, output: 19.56 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:06, 19.50it/s, est. speed input: 20008.69 toks/s, output: 19.54 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:06, 19.44it/s, est. speed input: 19966.29 toks/s, output: 19.50 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:05, 19.39it/s, est. speed input: 19933.96 toks/s, output: 19.47 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 19.36it/s, est. speed input: 19907.86 toks/s, output: 19.44 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 19.34it/s, est. speed input: 19889.37 toks/s, output: 19.42 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 19.24it/s, est. speed input: 19842.20 toks/s, output: 19.38 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:05, 19.13it/s, est. speed input: 19793.11 toks/s, output: 19.33 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 19.18it/s, est. speed input: 19790.23 toks/s, output: 19.33 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 19.17it/s, est. speed input: 19775.22 toks/s, output: 19.31 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 19.19it/s, est. speed input: 19767.27 toks/s, output: 19.30 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 19.24it/s, est. speed input: 19772.06 toks/s, output: 19.31 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 19.25it/s, est. speed input: 19769.96 toks/s, output: 19.31 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:04, 19.23it/s, est. speed input: 19762.10 toks/s, output: 19.30 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:04, 19.22it/s, est. speed input: 19757.08 toks/s, output: 19.29 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:04, 19.25it/s, est. speed input: 19756.76 toks/s, output: 19.29 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:04, 19.17it/s, est. speed input: 19740.68 toks/s, output: 19.28 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:04, 19.13it/s, est. speed input: 19727.68 toks/s, output: 19.26 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 19.12it/s, est. speed input: 19720.11 toks/s, output: 19.26 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 19.16it/s, est. speed input: 19719.45 toks/s, output: 19.26 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 19.19it/s, est. speed input: 19719.97 toks/s, output: 19.26 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 19.19it/s, est. speed input: 19717.55 toks/s, output: 19.26 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 19.24it/s, est. speed input: 19720.76 toks/s, output: 19.26 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 19.26it/s, est. speed input: 19722.95 toks/s, output: 19.26 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:03, 19.22it/s, est. speed input: 19717.76 toks/s, output: 19.26 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 19.19it/s, est. speed input: 19713.00 toks/s, output: 19.25 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:03, 19.15it/s, est. speed input: 19705.63 toks/s, output: 19.24 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 19.18it/s, est. speed input: 19706.11 toks/s, output: 19.24 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 19.19it/s, est. speed input: 19704.97 toks/s, output: 19.24 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 19.20it/s, est. speed input: 19704.65 toks/s, output: 19.24 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 19.21it/s, est. speed input: 19703.97 toks/s, output: 19.24 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 19.22it/s, est. speed input: 19703.81 toks/s, output: 19.24 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 19.24it/s, est. speed input: 19705.06 toks/s, output: 19.24 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:02, 19.25it/s, est. speed input: 19705.96 toks/s, output: 19.24 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 19.17it/s, est. speed input: 19699.00 toks/s, output: 19.24 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 19.14it/s, est. speed input: 19694.54 toks/s, output: 19.23 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 19.15it/s, est. speed input: 19692.61 toks/s, output: 19.23 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 19.17it/s, est. speed input: 19692.14 toks/s, output: 19.23 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 19.14it/s, est. speed input: 19688.20 toks/s, output: 19.23 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 19.14it/s, est. speed input: 19685.81 toks/s, output: 19.22 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 19.18it/s, est. speed input: 19687.19 toks/s, output: 19.23 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 19.21it/s, est. speed input: 19688.14 toks/s, output: 19.23 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:01, 19.24it/s, est. speed input: 19690.00 toks/s, output: 19.23 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:01, 19.19it/s, est. speed input: 19686.89 toks/s, output: 19.23 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 19.18it/s, est. speed input: 19685.28 toks/s, output: 19.22 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:04<00:01, 19.12it/s, est. speed input: 19680.33 toks/s, output: 19.22 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 19.12it/s, est. speed input: 19678.33 toks/s, output: 19.22 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 19.14it/s, est. speed input: 19677.38 toks/s, output: 19.22 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 19.14it/s, est. speed input: 19676.24 toks/s, output: 19.21 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 19.17it/s, est. speed input: 19676.70 toks/s, output: 19.22 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 19.21it/s, est. speed input: 19678.34 toks/s, output: 19.22 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:01, 19.23it/s, est. speed input: 19679.63 toks/s, output: 19.22 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:05<00:00, 19.24it/s, est. speed input: 19680.04 toks/s, output: 19.22 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 19.24it/s, est. speed input: 19680.43 toks/s, output: 19.22 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 19.26it/s, est. speed input: 19682.31 toks/s, output: 19.22 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 19.26it/s, est. speed input: 19682.82 toks/s, output: 19.22 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 19.23it/s, est. speed input: 19681.84 toks/s, output: 19.22 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 19.22it/s, est. speed input: 19681.46 toks/s, output: 19.22 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 19.26it/s, est. speed input: 19683.55 toks/s, output: 19.22 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 19.30it/s, est. speed input: 19686.23 toks/s, output: 19.22 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 19.27it/s, est. speed input: 19685.84 toks/s, output: 19.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.36it/s, est. speed input: 19691.47 toks/s, output: 19.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.36it/s, est. speed input: 19691.47 toks/s, output: 19.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.23it/s, est. speed input: 19691.47 toks/s, output: 19.23 toks/s]
[rank0]:[W126 14:56:55.406991652 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 14:56:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:57:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1508110) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1508110) WARNING 01-26 14:57:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.48 requests/s, 20995.55 total tokens/s, 20.48 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 14:57:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:57:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:57:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:57:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:57:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:57:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:57:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:57:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:57:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:57:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:57:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:57:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:57:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:57:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:57:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:57:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:57:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.45it/s]
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.75it/s]
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.57it/s]
(EngineCore_DP0 pid=1508110) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1508110) 
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1508110) [2026-01-26 14:57:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1508110) 2026-01-26 14:57:40,283 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1508110) 2026-01-26 14:57:40,346 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1508110) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  4.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  6.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.20it/s]
(EngineCore_DP0 pid=1508110) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  6.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.84it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  14%|█▍        | 36/256 [00:00<00:00, 356.18it/s]
Adding requests:  29%|██▉       | 74/256 [00:00<00:00, 370.02it/s]
Adding requests:  44%|████▍     | 112/256 [00:00<00:00, 368.89it/s]
Adding requests:  59%|█████▊    | 150/256 [00:00<00:00, 372.74it/s]
Adding requests:  75%|███████▍  | 191/256 [00:00<00:00, 383.82it/s]
Adding requests:  90%|████████▉ | 230/256 [00:00<00:00, 384.35it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 377.06it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 12/256 [00:00<00:03, 78.24it/s, est. speed input: 80138.83 toks/s, output: 78.24 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:07, 33.57it/s, est. speed input: 38320.64 toks/s, output: 37.42 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:00<00:07, 30.52it/s, est. speed input: 34946.52 toks/s, output: 34.13 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:00<00:08, 27.16it/s, est. speed input: 32049.95 toks/s, output: 31.30 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:01<00:09, 23.54it/s, est. speed input: 29374.60 toks/s, output: 28.69 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:09, 22.77it/s, est. speed input: 28243.86 toks/s, output: 27.58 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:09, 22.18it/s, est. speed input: 27364.98 toks/s, output: 26.72 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:09, 21.63it/s, est. speed input: 26620.49 toks/s, output: 26.00 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:09, 21.29it/s, est. speed input: 26041.18 toks/s, output: 25.43 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:09, 21.18it/s, est. speed input: 25618.62 toks/s, output: 25.02 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:09, 21.14it/s, est. speed input: 25277.71 toks/s, output: 24.68 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:09, 21.04it/s, est. speed input: 24965.77 toks/s, output: 24.38 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:09, 20.94it/s, est. speed input: 24693.51 toks/s, output: 24.11 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:09, 20.79it/s, est. speed input: 24435.91 toks/s, output: 23.86 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:03<00:08, 20.81it/s, est. speed input: 24241.27 toks/s, output: 23.67 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:08, 20.88it/s, est. speed input: 24083.16 toks/s, output: 23.52 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:08, 20.84it/s, est. speed input: 23922.58 toks/s, output: 23.36 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:08, 20.80it/s, est. speed input: 23778.43 toks/s, output: 23.22 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:08, 20.70it/s, est. speed input: 23634.02 toks/s, output: 23.08 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:04<00:07, 20.75it/s, est. speed input: 23524.69 toks/s, output: 22.97 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:07, 20.79it/s, est. speed input: 23426.75 toks/s, output: 22.88 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:07, 20.83it/s, est. speed input: 23339.77 toks/s, output: 22.79 toks/s]
Processed prompts:  41%|████      | 104/256 [00:04<00:07, 20.80it/s, est. speed input: 23250.40 toks/s, output: 22.71 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:07, 20.71it/s, est. speed input: 23159.32 toks/s, output: 22.62 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:06, 20.74it/s, est. speed input: 23087.54 toks/s, output: 22.55 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:05<00:06, 20.75it/s, est. speed input: 23020.25 toks/s, output: 22.48 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:06, 20.79it/s, est. speed input: 22961.34 toks/s, output: 22.42 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:06, 20.77it/s, est. speed input: 22900.47 toks/s, output: 22.36 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:05<00:06, 20.73it/s, est. speed input: 22841.13 toks/s, output: 22.31 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:05, 20.73it/s, est. speed input: 22788.86 toks/s, output: 22.25 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:05, 20.74it/s, est. speed input: 22740.21 toks/s, output: 22.21 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:06<00:05, 20.80it/s, est. speed input: 22700.86 toks/s, output: 22.17 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:05, 20.77it/s, est. speed input: 22656.84 toks/s, output: 22.13 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:06<00:05, 20.72it/s, est. speed input: 22611.30 toks/s, output: 22.08 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:06<00:05, 20.73it/s, est. speed input: 22573.15 toks/s, output: 22.04 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:04, 20.75it/s, est. speed input: 22538.68 toks/s, output: 22.01 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:07<00:04, 20.75it/s, est. speed input: 22504.93 toks/s, output: 21.98 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:07<00:04, 20.77it/s, est. speed input: 22473.65 toks/s, output: 21.95 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:07<00:04, 20.73it/s, est. speed input: 22440.04 toks/s, output: 21.91 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:07<00:04, 20.68it/s, est. speed input: 22405.72 toks/s, output: 21.88 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:08<00:03, 20.72it/s, est. speed input: 22379.64 toks/s, output: 21.86 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:08<00:03, 20.73it/s, est. speed input: 22352.90 toks/s, output: 21.83 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:08<00:03, 20.76it/s, est. speed input: 22330.32 toks/s, output: 21.81 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:08<00:03, 20.76it/s, est. speed input: 22306.12 toks/s, output: 21.78 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:08<00:03, 20.71it/s, est. speed input: 22279.46 toks/s, output: 21.76 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:09<00:02, 20.70it/s, est. speed input: 22255.46 toks/s, output: 21.73 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:09<00:02, 20.74it/s, est. speed input: 22236.36 toks/s, output: 21.72 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:09<00:02, 22.03it/s, est. speed input: 22305.22 toks/s, output: 21.78 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:09<00:02, 21.72it/s, est. speed input: 22289.90 toks/s, output: 21.77 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:09<00:02, 21.48it/s, est. speed input: 22273.29 toks/s, output: 21.75 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:09<00:01, 21.24it/s, est. speed input: 22252.18 toks/s, output: 21.73 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:10<00:01, 21.12it/s, est. speed input: 22235.27 toks/s, output: 21.71 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:10<00:01, 20.99it/s, est. speed input: 22215.41 toks/s, output: 21.69 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:10<00:01, 20.97it/s, est. speed input: 22200.88 toks/s, output: 21.68 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:10<00:01, 20.95it/s, est. speed input: 22186.93 toks/s, output: 21.67 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:10<00:00, 20.90it/s, est. speed input: 22171.17 toks/s, output: 21.65 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:11<00:00, 20.87it/s, est. speed input: 22155.93 toks/s, output: 21.64 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:11<00:00, 20.87it/s, est. speed input: 22142.61 toks/s, output: 21.62 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:11<00:00, 20.87it/s, est. speed input: 22129.56 toks/s, output: 21.61 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:11<00:00, 20.85it/s, est. speed input: 22116.02 toks/s, output: 21.60 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.33it/s, est. speed input: 22183.00 toks/s, output: 21.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.33it/s, est. speed input: 22183.00 toks/s, output: 21.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 21.66it/s, est. speed input: 22183.00 toks/s, output: 21.66 toks/s]
[rank0]:[W126 14:57:55.434818099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 14:57:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:58:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1509459) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1509459) WARNING 01-26 14:58:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.26 requests/s, 21788.93 total tokens/s, 21.26 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 14:58:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:58:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:58:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:58:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:58:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:58:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:58:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:58:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:58:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:58:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:58:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:58:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:58:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:58:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:58:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:58:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:58:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.44it/s]
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1509459) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1509459) 
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1509459) [2026-01-26 14:58:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1509459) 2026-01-26 14:58:41,536 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1509459) 2026-01-26 14:58:41,598 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1509459) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 10.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.06it/s]
(EngineCore_DP0 pid=1509459) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  5.06it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  4.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.94it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 22/512 [00:00<00:02, 217.92it/s]
Adding requests:  12%|█▏        | 63/512 [00:00<00:01, 329.27it/s]
Adding requests:  19%|█▉        | 99/512 [00:00<00:01, 340.60it/s]
Adding requests:  27%|██▋       | 138/512 [00:00<00:01, 356.25it/s]
Adding requests:  35%|███▍      | 178/512 [00:00<00:00, 368.95it/s]
Adding requests:  43%|████▎     | 220/512 [00:00<00:00, 385.22it/s]
Adding requests:  51%|█████     | 259/512 [00:00<00:00, 381.91it/s]
Adding requests:  58%|█████▊    | 299/512 [00:00<00:00, 385.97it/s]
Adding requests:  66%|██████▋   | 340/512 [00:00<00:00, 392.24it/s]
Adding requests:  74%|███████▍  | 380/512 [00:01<00:00, 393.95it/s]
Adding requests:  82%|████████▏ | 422/512 [00:01<00:00, 400.99it/s]
Adding requests:  90%|█████████ | 463/512 [00:01<00:00, 397.18it/s]
Adding requests:  99%|█████████▊| 505/512 [00:01<00:00, 403.66it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 382.37it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 26/512 [00:00<00:03, 123.83it/s, est. speed input: 126819.80 toks/s, output: 123.84 toks/s]
Processed prompts:   8%|▊         | 39/512 [00:00<00:10, 44.42it/s, est. speed input: 52174.87 toks/s, output: 50.95 toks/s]   
Processed prompts:   9%|▉         | 46/512 [00:01<00:14, 33.23it/s, est. speed input: 41267.42 toks/s, output: 40.30 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:01<00:14, 31.60it/s, est. speed input: 39235.52 toks/s, output: 38.32 toks/s]
Processed prompts:  11%|█         | 55/512 [00:01<00:15, 29.10it/s, est. speed input: 37135.34 toks/s, output: 36.26 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:01<00:16, 27.14it/s, est. speed input: 35510.28 toks/s, output: 34.68 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:01<00:18, 24.20it/s, est. speed input: 33675.38 toks/s, output: 32.89 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:02<00:19, 23.35it/s, est. speed input: 32588.46 toks/s, output: 31.82 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:02<00:19, 22.73it/s, est. speed input: 31681.87 toks/s, output: 30.94 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:19, 22.32it/s, est. speed input: 30928.72 toks/s, output: 30.20 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:19, 22.06it/s, est. speed input: 30290.37 toks/s, output: 29.58 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:19, 22.00it/s, est. speed input: 29777.78 toks/s, output: 29.08 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:03<00:19, 21.83it/s, est. speed input: 29290.76 toks/s, output: 28.60 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:03<00:19, 21.60it/s, est. speed input: 28831.93 toks/s, output: 28.16 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:19, 21.55it/s, est. speed input: 28452.64 toks/s, output: 27.79 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:19, 21.47it/s, est. speed input: 28101.58 toks/s, output: 27.44 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:19, 21.50it/s, est. speed input: 27804.41 toks/s, output: 27.15 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:18, 21.52it/s, est. speed input: 27536.60 toks/s, output: 26.89 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:04<00:18, 21.44it/s, est. speed input: 27272.84 toks/s, output: 26.63 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:18, 21.43it/s, est. speed input: 27041.17 toks/s, output: 26.41 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:18, 21.41it/s, est. speed input: 26826.86 toks/s, output: 26.20 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:18, 21.37it/s, est. speed input: 26624.88 toks/s, output: 26.00 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:17, 21.46it/s, est. speed input: 26456.98 toks/s, output: 25.84 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:05<00:17, 21.46it/s, est. speed input: 26292.37 toks/s, output: 25.68 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:17, 21.41it/s, est. speed input: 26131.46 toks/s, output: 25.52 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:17, 21.37it/s, est. speed input: 25981.78 toks/s, output: 25.37 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:17, 21.35it/s, est. speed input: 25842.58 toks/s, output: 25.24 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:17, 21.36it/s, est. speed input: 25715.80 toks/s, output: 25.11 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:16, 21.41it/s, est. speed input: 25602.28 toks/s, output: 25.00 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:16, 21.39it/s, est. speed input: 25488.96 toks/s, output: 24.89 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:16, 21.38it/s, est. speed input: 25382.66 toks/s, output: 24.79 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:16, 21.37it/s, est. speed input: 25282.06 toks/s, output: 24.69 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:16, 21.34it/s, est. speed input: 25184.81 toks/s, output: 24.59 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:16, 21.35it/s, est. speed input: 25095.24 toks/s, output: 24.51 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:15, 21.35it/s, est. speed input: 25010.08 toks/s, output: 24.42 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:15, 21.33it/s, est. speed input: 24927.44 toks/s, output: 24.34 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:15, 21.35it/s, est. speed input: 24852.15 toks/s, output: 24.27 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:07<00:15, 21.38it/s, est. speed input: 24782.56 toks/s, output: 24.20 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:15, 21.37it/s, est. speed input: 24712.59 toks/s, output: 24.13 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:14, 21.35it/s, est. speed input: 24645.10 toks/s, output: 24.07 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:14, 21.32it/s, est. speed input: 24578.97 toks/s, output: 24.00 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:13, 22.66it/s, est. speed input: 24626.40 toks/s, output: 24.05 toks/s]
Processed prompts:  40%|████      | 206/512 [00:08<00:13, 22.31it/s, est. speed input: 24570.04 toks/s, output: 23.99 toks/s]
Processed prompts:  41%|████      | 210/512 [00:08<00:13, 22.01it/s, est. speed input: 24512.07 toks/s, output: 23.94 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:13, 21.79it/s, est. speed input: 24455.24 toks/s, output: 23.88 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:13, 21.63it/s, est. speed input: 24400.48 toks/s, output: 23.83 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:13, 21.54it/s, est. speed input: 24349.16 toks/s, output: 23.78 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:09<00:13, 21.57it/s, est. speed input: 24306.48 toks/s, output: 23.74 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:09<00:13, 21.49it/s, est. speed input: 24258.09 toks/s, output: 23.69 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:12, 21.45it/s, est. speed input: 24213.24 toks/s, output: 23.65 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:12, 21.48it/s, est. speed input: 24173.44 toks/s, output: 23.61 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:12, 21.47it/s, est. speed input: 24133.61 toks/s, output: 23.57 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:10<00:12, 21.48it/s, est. speed input: 24096.14 toks/s, output: 23.53 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:10<00:12, 21.46it/s, est. speed input: 24057.96 toks/s, output: 23.49 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:10<00:12, 21.43it/s, est. speed input: 24019.87 toks/s, output: 23.46 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:11, 21.44it/s, est. speed input: 23985.19 toks/s, output: 23.42 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:11, 21.44it/s, est. speed input: 23951.53 toks/s, output: 23.39 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:11<00:11, 21.41it/s, est. speed input: 23917.02 toks/s, output: 23.36 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:11<00:11, 21.43it/s, est. speed input: 23886.13 toks/s, output: 23.33 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:11<00:11, 21.43it/s, est. speed input: 23854.98 toks/s, output: 23.30 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:11<00:10, 21.43it/s, est. speed input: 23825.53 toks/s, output: 23.27 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:10, 21.44it/s, est. speed input: 23797.16 toks/s, output: 23.24 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:12<00:10, 21.47it/s, est. speed input: 23770.66 toks/s, output: 23.21 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:12<00:10, 21.42it/s, est. speed input: 23741.52 toks/s, output: 23.19 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:12<00:10, 21.40it/s, est. speed input: 23713.98 toks/s, output: 23.16 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:12<00:09, 21.47it/s, est. speed input: 23691.31 toks/s, output: 23.14 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:09, 21.43it/s, est. speed input: 23664.86 toks/s, output: 23.11 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:13<00:09, 21.45it/s, est. speed input: 23641.66 toks/s, output: 23.09 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:13<00:09, 21.44it/s, est. speed input: 23617.90 toks/s, output: 23.06 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:13<00:09, 21.40it/s, est. speed input: 23593.20 toks/s, output: 23.04 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:13<00:09, 21.47it/s, est. speed input: 23573.82 toks/s, output: 23.02 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:08, 21.43it/s, est. speed input: 23550.68 toks/s, output: 23.00 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:14<00:08, 21.39it/s, est. speed input: 23527.86 toks/s, output: 22.98 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:14<00:08, 21.40it/s, est. speed input: 23507.23 toks/s, output: 22.96 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:14<00:08, 21.39it/s, est. speed input: 23486.39 toks/s, output: 22.94 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:14<00:08, 21.45it/s, est. speed input: 23468.74 toks/s, output: 22.92 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:14<00:07, 21.43it/s, est. speed input: 23449.12 toks/s, output: 22.90 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:15<00:07, 21.42it/s, est. speed input: 23430.03 toks/s, output: 22.88 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:15<00:07, 21.40it/s, est. speed input: 23411.05 toks/s, output: 22.86 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:15<00:07, 21.38it/s, est. speed input: 23391.99 toks/s, output: 22.84 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:15<00:07, 21.45it/s, est. speed input: 23377.20 toks/s, output: 22.83 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:15<00:07, 21.41it/s, est. speed input: 23358.71 toks/s, output: 22.81 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:16<00:06, 21.38it/s, est. speed input: 23340.87 toks/s, output: 22.79 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:16<00:06, 21.44it/s, est. speed input: 23326.55 toks/s, output: 22.78 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:16<00:06, 21.37it/s, est. speed input: 23308.01 toks/s, output: 22.76 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:16<00:06, 21.36it/s, est. speed input: 23291.54 toks/s, output: 22.75 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:16<00:06, 21.42it/s, est. speed input: 23278.36 toks/s, output: 22.73 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:16<00:05, 21.45it/s, est. speed input: 23264.70 toks/s, output: 22.72 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:17<00:05, 21.43it/s, est. speed input: 23249.64 toks/s, output: 22.70 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:17<00:05, 21.46it/s, est. speed input: 23237.01 toks/s, output: 22.69 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:17<00:05, 21.41it/s, est. speed input: 23221.41 toks/s, output: 22.68 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:17<00:05, 21.41it/s, est. speed input: 23207.78 toks/s, output: 22.66 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:17<00:04, 21.43it/s, est. speed input: 23195.08 toks/s, output: 22.65 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:18<00:04, 21.39it/s, est. speed input: 23180.60 toks/s, output: 22.64 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:18<00:04, 21.38it/s, est. speed input: 23167.20 toks/s, output: 22.62 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:18<00:04, 21.40it/s, est. speed input: 23155.06 toks/s, output: 22.61 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:18<00:04, 21.37it/s, est. speed input: 23141.64 toks/s, output: 22.60 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:18<00:04, 21.41it/s, est. speed input: 23130.49 toks/s, output: 22.59 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:19<00:03, 21.40it/s, est. speed input: 23118.15 toks/s, output: 22.58 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:19<00:03, 21.38it/s, est. speed input: 23105.99 toks/s, output: 22.56 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:19<00:03, 21.40it/s, est. speed input: 23094.93 toks/s, output: 22.55 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:19<00:03, 21.36it/s, est. speed input: 23082.29 toks/s, output: 22.54 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:19<00:03, 21.31it/s, est. speed input: 23069.19 toks/s, output: 22.53 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:19<00:02, 21.40it/s, est. speed input: 23060.53 toks/s, output: 22.52 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:20<00:02, 21.38it/s, est. speed input: 23049.31 toks/s, output: 22.51 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:20<00:02, 21.41it/s, est. speed input: 23039.58 toks/s, output: 22.50 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:20<00:02, 21.43it/s, est. speed input: 23029.92 toks/s, output: 22.49 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:20<00:02, 21.36it/s, est. speed input: 23017.88 toks/s, output: 22.48 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:20<00:01, 21.35it/s, est. speed input: 23007.50 toks/s, output: 22.47 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:21<00:01, 21.40it/s, est. speed input: 22998.70 toks/s, output: 22.46 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:21<00:01, 21.41it/s, est. speed input: 22989.67 toks/s, output: 22.45 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:21<00:01, 21.43it/s, est. speed input: 22981.02 toks/s, output: 22.44 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:21<00:01, 21.40it/s, est. speed input: 22971.19 toks/s, output: 22.43 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:21<00:01, 21.37it/s, est. speed input: 22961.04 toks/s, output: 22.42 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:22<00:00, 21.38it/s, est. speed input: 22952.28 toks/s, output: 22.41 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:22<00:00, 21.40it/s, est. speed input: 22944.08 toks/s, output: 22.41 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:22<00:00, 21.40it/s, est. speed input: 22935.36 toks/s, output: 22.40 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:22<00:00, 21.41it/s, est. speed input: 22927.26 toks/s, output: 22.39 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:22<00:00, 22.95it/s, est. speed input: 22961.09 toks/s, output: 22.42 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 22.95it/s, est. speed input: 23050.85 toks/s, output: 22.51 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 22.51it/s, est. speed input: 23050.85 toks/s, output: 22.51 toks/s]
[rank0]:[W126 14:59:08.652941192 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 14:59:11
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:59:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1510959) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1510959) WARNING 01-26 14:59:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.96 requests/s, 22507.39 total tokens/s, 21.96 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 14:59:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:59:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:59:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:59:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:59:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:59:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:59:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:59:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:59:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:59:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:59:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:59:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:59:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:59:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:59:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:59:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:59:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:31] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.44it/s]
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.57it/s]
(EngineCore_DP0 pid=1510959) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1510959) 
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1510959) [2026-01-26 14:59:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1510959) 2026-01-26 14:59:58,385 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1510959) 2026-01-26 14:59:58,480 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1510959) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  6.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  3.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.36it/s]
(EngineCore_DP0 pid=1510959) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  3.49it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  7.02it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 217.79it/s]
Adding requests:   6%|▌         | 63/1024 [00:00<00:02, 326.68it/s]
Adding requests:  10%|▉         | 98/1024 [00:00<00:02, 336.65it/s]
Adding requests:  13%|█▎        | 136/1024 [00:00<00:02, 349.84it/s]
Adding requests:  17%|█▋        | 175/1024 [00:00<00:02, 362.71it/s]
Adding requests:  21%|██        | 216/1024 [00:00<00:02, 374.82it/s]
Adding requests:  25%|██▍       | 255/1024 [00:00<00:02, 377.06it/s]
Adding requests:  29%|██▉       | 295/1024 [00:00<00:01, 381.19it/s]
Adding requests:  33%|███▎      | 336/1024 [00:00<00:01, 389.93it/s]
Adding requests:  37%|███▋      | 376/1024 [00:01<00:01, 392.96it/s]
Adding requests:  41%|████      | 418/1024 [00:01<00:01, 399.80it/s]
Adding requests:  45%|████▍     | 458/1024 [00:01<00:01, 395.61it/s]
Adding requests:  49%|████▉     | 501/1024 [00:01<00:01, 402.81it/s]
Adding requests:  53%|█████▎    | 543/1024 [00:01<00:01, 407.54it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:01<00:01, 402.32it/s]
Adding requests:  61%|██████    | 625/1024 [00:01<00:01, 396.07it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:01<00:00, 382.72it/s]
Adding requests:  69%|██████▉   | 705/1024 [00:01<00:00, 386.35it/s]
Adding requests:  73%|███████▎  | 744/1024 [00:01<00:00, 381.85it/s]
Adding requests:  77%|███████▋  | 784/1024 [00:02<00:00, 385.57it/s]
Adding requests:  80%|████████  | 823/1024 [00:02<00:00, 384.68it/s]
Adding requests:  84%|████████▍ | 863/1024 [00:02<00:00, 387.04it/s]
Adding requests:  88%|████████▊ | 904/1024 [00:02<00:00, 393.57it/s]
Adding requests:  92%|█████████▏| 944/1024 [00:02<00:00, 384.14it/s]
Adding requests:  96%|█████████▌| 983/1024 [00:02<00:00, 385.14it/s]
Adding requests: 100%|█████████▉| 1022/1024 [00:02<00:00, 381.64it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 382.03it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:00<00:04, 205.25it/s, est. speed input: 210211.25 toks/s, output: 205.26 toks/s]
Processed prompts:   8%|▊         | 79/1024 [00:01<00:14, 66.58it/s, est. speed input: 80099.72 toks/s, output: 78.22 toks/s]   
Processed prompts:   9%|▉         | 90/1024 [00:01<00:23, 39.28it/s, est. speed input: 52958.43 toks/s, output: 51.72 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:02<00:26, 34.64it/s, est. speed input: 47783.68 toks/s, output: 46.66 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:02<00:29, 31.04it/s, est. speed input: 44024.95 toks/s, output: 42.99 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:02<00:32, 28.38it/s, est. speed input: 41218.71 toks/s, output: 40.25 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:03<00:33, 26.56it/s, est. speed input: 39108.34 toks/s, output: 38.19 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:35, 25.19it/s, est. speed input: 37398.94 toks/s, output: 36.52 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:03<00:36, 24.19it/s, est. speed input: 35990.65 toks/s, output: 35.15 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:04<00:37, 23.69it/s, est. speed input: 34912.82 toks/s, output: 34.09 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:37, 23.20it/s, est. speed input: 33950.42 toks/s, output: 33.15 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:05<00:37, 22.87it/s, est. speed input: 33130.74 toks/s, output: 32.35 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:05<00:37, 22.67it/s, est. speed input: 32433.73 toks/s, output: 31.67 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:37, 22.46it/s, est. speed input: 31800.99 toks/s, output: 31.06 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:06<00:37, 22.37it/s, est. speed input: 31262.72 toks/s, output: 30.53 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:06<00:37, 22.33it/s, est. speed input: 30787.94 toks/s, output: 30.07 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:35, 22.93it/s, est. speed input: 30511.43 toks/s, output: 29.80 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:07<00:35, 22.70it/s, est. speed input: 30117.96 toks/s, output: 29.41 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:35, 22.48it/s, est. speed input: 29748.97 toks/s, output: 29.05 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:35, 22.29it/s, est. speed input: 29406.78 toks/s, output: 28.72 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:08<00:35, 22.32it/s, est. speed input: 29124.24 toks/s, output: 28.44 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:35, 22.24it/s, est. speed input: 28849.28 toks/s, output: 28.17 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:08<00:34, 22.18it/s, est. speed input: 28593.86 toks/s, output: 27.92 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:09<00:34, 22.14it/s, est. speed input: 28360.12 toks/s, output: 27.70 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:34, 22.10it/s, est. speed input: 28141.60 toks/s, output: 27.48 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:10<00:33, 22.08it/s, est. speed input: 27939.92 toks/s, output: 27.28 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:10<00:33, 22.07it/s, est. speed input: 27753.30 toks/s, output: 27.10 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:10<00:33, 22.03it/s, est. speed input: 27574.18 toks/s, output: 26.93 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:11<00:32, 22.11it/s, est. speed input: 27421.40 toks/s, output: 26.78 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:32, 22.11it/s, est. speed input: 27270.64 toks/s, output: 26.63 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:11<00:32, 22.07it/s, est. speed input: 27124.45 toks/s, output: 26.49 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:12<00:31, 22.06it/s, est. speed input: 26988.65 toks/s, output: 26.36 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:31, 22.01it/s, est. speed input: 26856.20 toks/s, output: 26.23 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:12<00:31, 21.99it/s, est. speed input: 26733.00 toks/s, output: 26.11 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:13<00:30, 22.00it/s, est. speed input: 26618.98 toks/s, output: 26.00 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:13<00:30, 21.99it/s, est. speed input: 26509.16 toks/s, output: 25.89 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:14<00:30, 21.97it/s, est. speed input: 26403.14 toks/s, output: 25.78 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:14<00:29, 21.96it/s, est. speed input: 26303.92 toks/s, output: 25.69 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:14<00:29, 21.96it/s, est. speed input: 26209.64 toks/s, output: 25.60 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:15<00:29, 21.97it/s, est. speed input: 26120.46 toks/s, output: 25.51 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:15<00:28, 21.97it/s, est. speed input: 26035.94 toks/s, output: 25.43 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:15<00:28, 21.96it/s, est. speed input: 25953.17 toks/s, output: 25.34 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:16<00:27, 21.96it/s, est. speed input: 25876.02 toks/s, output: 25.27 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:16<00:27, 21.94it/s, est. speed input: 25799.75 toks/s, output: 25.20 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:16<00:27, 21.97it/s, est. speed input: 25730.48 toks/s, output: 25.13 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:17<00:26, 21.94it/s, est. speed input: 25659.92 toks/s, output: 25.06 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:17<00:26, 21.92it/s, est. speed input: 25592.89 toks/s, output: 24.99 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:18<00:26, 21.96it/s, est. speed input: 25532.25 toks/s, output: 24.93 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:18<00:25, 21.94it/s, est. speed input: 25470.44 toks/s, output: 24.87 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:18<00:25, 21.96it/s, est. speed input: 25413.39 toks/s, output: 24.82 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:19<00:25, 21.93it/s, est. speed input: 25355.85 toks/s, output: 24.76 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:19<00:24, 21.94it/s, est. speed input: 25301.93 toks/s, output: 24.71 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:19<00:24, 21.93it/s, est. speed input: 25249.36 toks/s, output: 24.66 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:20<00:23, 21.94it/s, est. speed input: 25199.53 toks/s, output: 24.61 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:20<00:23, 21.95it/s, est. speed input: 25152.11 toks/s, output: 24.56 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:20<00:23, 21.95it/s, est. speed input: 25105.37 toks/s, output: 24.52 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:21<00:22, 21.94it/s, est. speed input: 25059.86 toks/s, output: 24.47 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:21<00:22, 21.97it/s, est. speed input: 25018.45 toks/s, output: 24.43 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:22<00:22, 21.98it/s, est. speed input: 24977.59 toks/s, output: 24.39 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:22<00:21, 21.95it/s, est. speed input: 24935.72 toks/s, output: 24.35 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:22<00:21, 21.95it/s, est. speed input: 24895.94 toks/s, output: 24.31 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:23<00:21, 21.93it/s, est. speed input: 24856.86 toks/s, output: 24.27 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:23<00:20, 21.97it/s, est. speed input: 24822.10 toks/s, output: 24.24 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:23<00:20, 21.91it/s, est. speed input: 24782.91 toks/s, output: 24.20 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:24<00:19, 21.90it/s, est. speed input: 24747.17 toks/s, output: 24.17 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:24<00:19, 21.91it/s, est. speed input: 24713.32 toks/s, output: 24.13 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:24<00:19, 21.93it/s, est. speed input: 24680.82 toks/s, output: 24.10 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:25<00:18, 21.90it/s, est. speed input: 24647.50 toks/s, output: 24.07 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:25<00:18, 21.88it/s, est. speed input: 24614.89 toks/s, output: 24.04 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:26<00:18, 21.91it/s, est. speed input: 24585.57 toks/s, output: 24.01 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:26<00:17, 21.90it/s, est. speed input: 24555.11 toks/s, output: 23.98 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:26<00:17, 21.94it/s, est. speed input: 24528.00 toks/s, output: 23.95 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:27<00:17, 21.89it/s, est. speed input: 24497.77 toks/s, output: 23.92 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:27<00:16, 21.88it/s, est. speed input: 24469.72 toks/s, output: 23.90 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:27<00:16, 21.88it/s, est. speed input: 24442.60 toks/s, output: 23.87 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:28<00:15, 21.88it/s, est. speed input: 24416.42 toks/s, output: 23.84 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:28<00:15, 21.86it/s, est. speed input: 24389.81 toks/s, output: 23.82 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:28<00:15, 21.94it/s, est. speed input: 24367.95 toks/s, output: 23.80 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:29<00:14, 21.90it/s, est. speed input: 24342.44 toks/s, output: 23.77 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:29<00:14, 21.87it/s, est. speed input: 24317.59 toks/s, output: 23.75 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:30<00:14, 21.87it/s, est. speed input: 24294.45 toks/s, output: 23.73 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:30<00:13, 21.85it/s, est. speed input: 24270.68 toks/s, output: 23.70 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:30<00:13, 21.84it/s, est. speed input: 24247.46 toks/s, output: 23.68 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:31<00:13, 21.87it/s, est. speed input: 24226.80 toks/s, output: 23.66 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:31<00:12, 21.85it/s, est. speed input: 24204.67 toks/s, output: 23.64 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:31<00:12, 21.85it/s, est. speed input: 24183.65 toks/s, output: 23.62 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:32<00:11, 21.85it/s, est. speed input: 24163.01 toks/s, output: 23.60 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:32<00:11, 21.82it/s, est. speed input: 24141.75 toks/s, output: 23.58 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:33<00:11, 21.83it/s, est. speed input: 24122.37 toks/s, output: 23.56 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:33<00:10, 22.54it/s, est. speed input: 24130.69 toks/s, output: 23.57 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:33<00:10, 22.31it/s, est. speed input: 24110.88 toks/s, output: 23.55 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:34<00:10, 22.14it/s, est. speed input: 24091.02 toks/s, output: 23.53 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:34<00:09, 22.11it/s, est. speed input: 24075.07 toks/s, output: 23.51 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:34<00:09, 22.04it/s, est. speed input: 24057.35 toks/s, output: 23.49 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:35<00:09, 21.97it/s, est. speed input: 24039.48 toks/s, output: 23.48 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:35<00:08, 21.95it/s, est. speed input: 24022.79 toks/s, output: 23.46 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:35<00:08, 21.92it/s, est. speed input: 24006.02 toks/s, output: 23.44 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:36<00:07, 21.89it/s, est. speed input: 23989.18 toks/s, output: 23.43 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:36<00:07, 21.84it/s, est. speed input: 23971.88 toks/s, output: 23.41 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:37<00:07, 21.89it/s, est. speed input: 23957.70 toks/s, output: 23.40 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:37<00:06, 21.86it/s, est. speed input: 23941.44 toks/s, output: 23.38 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:37<00:06, 21.82it/s, est. speed input: 23924.91 toks/s, output: 23.36 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:38<00:06, 21.84it/s, est. speed input: 23910.36 toks/s, output: 23.35 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:38<00:05, 21.81it/s, est. speed input: 23894.54 toks/s, output: 23.33 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:38<00:05, 21.79it/s, est. speed input: 23879.02 toks/s, output: 23.32 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:39<00:05, 21.81it/s, est. speed input: 23865.33 toks/s, output: 23.31 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:39<00:04, 21.76it/s, est. speed input: 23849.35 toks/s, output: 23.29 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:39<00:04, 21.78it/s, est. speed input: 23835.59 toks/s, output: 23.28 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:40<00:03, 21.81it/s, est. speed input: 23822.55 toks/s, output: 23.26 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:40<00:03, 21.75it/s, est. speed input: 23807.27 toks/s, output: 23.25 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:41<00:03, 21.81it/s, est. speed input: 23795.28 toks/s, output: 23.24 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:41<00:02, 21.81it/s, est. speed input: 23782.41 toks/s, output: 23.22 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:41<00:02, 21.78it/s, est. speed input: 23768.77 toks/s, output: 23.21 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:42<00:02, 21.81it/s, est. speed input: 23756.96 toks/s, output: 23.20 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:42<00:01, 21.76it/s, est. speed input: 23743.06 toks/s, output: 23.19 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:42<00:01, 21.76it/s, est. speed input: 23730.56 toks/s, output: 23.17 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:43<00:01, 21.79it/s, est. speed input: 23719.30 toks/s, output: 23.16 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:43<00:00, 21.74it/s, est. speed input: 23705.94 toks/s, output: 23.15 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:43<00:00, 22.57it/s, est. speed input: 23718.17 toks/s, output: 23.16 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:43<00:00, 22.57it/s, est. speed input: 23857.75 toks/s, output: 23.30 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:43<00:00, 23.30it/s, est. speed input: 23857.75 toks/s, output: 23.30 toks/s]
[rank0]:[W126 15:00:48.800921208 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 15:00:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:01:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1512836) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1512836) WARNING 01-26 15:01:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.84 requests/s, 22388.22 total tokens/s, 21.84 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 15:01:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:01:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:01:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:01:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:01:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:01:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:01:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:01:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:01:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:01:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:01:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:01:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:01:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:01:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:01:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:01:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:01:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.43it/s]
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1512836) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1512836) 
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1512836) [2026-01-26 15:01:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1512836) [rank0]:W0126 15:01:39.541000 1512836 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1512836) [rank0]:W0126 15:01:39.596000 1512836 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1512836) [rank0]:W0126 15:01:40.326000 1512836 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1512836) [rank0]:W0126 15:01:40.411000 1512836 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1512836) 2026-01-26 15:01:45,237 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1512836) 2026-01-26 15:01:45,460 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1512836) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  6.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:01,  2.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:01<00:00,  4.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  4.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.37it/s]
(EngineCore_DP0 pid=1512836) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 11.55it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.81it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.04it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/2048 [00:00<00:09, 209.78it/s]
Adding requests:   3%|▎         | 62/2048 [00:00<00:06, 324.01it/s]
Adding requests:   5%|▍         | 98/2048 [00:00<00:05, 338.42it/s]
Adding requests:   7%|▋         | 136/2048 [00:00<00:05, 353.66it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:05, 366.35it/s]
Adding requests:  10%|█         | 215/2048 [00:00<00:04, 373.65it/s]
Adding requests:  12%|█▏        | 254/2048 [00:00<00:04, 376.62it/s]
Adding requests:  14%|█▍        | 293/2048 [00:00<00:04, 380.66it/s]
Adding requests:  16%|█▋        | 335/2048 [00:00<00:04, 390.59it/s]
Adding requests:  18%|█▊        | 375/2048 [00:01<00:04, 392.29it/s]
Adding requests:  20%|██        | 417/2048 [00:01<00:04, 399.34it/s]
Adding requests:  22%|██▏       | 457/2048 [00:01<00:04, 395.20it/s]
Adding requests:  24%|██▍       | 499/2048 [00:01<00:03, 401.83it/s]
Adding requests:  26%|██▋       | 542/2048 [00:01<00:03, 408.03it/s]
Adding requests:  28%|██▊       | 583/2048 [00:01<00:03, 402.37it/s]
Adding requests:  30%|███       | 624/2048 [00:01<00:03, 394.43it/s]
Adding requests:  32%|███▏      | 664/2048 [00:01<00:03, 387.78it/s]
Adding requests:  34%|███▍      | 704/2048 [00:01<00:03, 390.41it/s]
Adding requests:  36%|███▋      | 744/2048 [00:01<00:03, 384.82it/s]
Adding requests:  38%|███▊      | 783/2048 [00:02<00:03, 380.09it/s]
Adding requests:  40%|████      | 822/2048 [00:02<00:03, 382.86it/s]
Adding requests:  42%|████▏     | 861/2048 [00:02<00:03, 380.99it/s]
Adding requests:  44%|████▍     | 901/2048 [00:02<00:02, 384.80it/s]
Adding requests:  46%|████▌     | 940/2048 [00:02<00:02, 383.06it/s]
Adding requests:  48%|████▊     | 979/2048 [00:02<00:02, 383.37it/s]
Adding requests:  50%|████▉     | 1018/2048 [00:02<00:02, 379.87it/s]
Adding requests:  52%|█████▏    | 1056/2048 [00:02<00:02, 378.20it/s]
Adding requests:  53%|█████▎    | 1094/2048 [00:02<00:02, 377.95it/s]
Adding requests:  55%|█████▌    | 1135/2048 [00:02<00:02, 386.27it/s]
Adding requests:  57%|█████▋    | 1174/2048 [00:03<00:02, 383.15it/s]
Adding requests:  59%|█████▉    | 1214/2048 [00:03<00:02, 385.26it/s]
Adding requests:  61%|██████    | 1254/2048 [00:03<00:02, 388.40it/s]
Adding requests:  63%|██████▎   | 1293/2048 [00:03<00:01, 380.33it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:03<00:01, 383.74it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:03<00:01, 389.52it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:03<00:01, 386.33it/s]
Adding requests:  71%|███████   | 1452/2048 [00:03<00:01, 386.61it/s]
Adding requests:  73%|███████▎  | 1493/2048 [00:03<00:01, 392.90it/s]
Adding requests:  75%|███████▍  | 1533/2048 [00:04<00:01, 389.39it/s]
Adding requests:  77%|███████▋  | 1572/2048 [00:04<00:01, 382.74it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:04<00:01, 384.33it/s]
Adding requests:  81%|████████  | 1650/2048 [00:04<00:01, 374.82it/s]
Adding requests:  82%|████████▏ | 1688/2048 [00:04<00:00, 372.73it/s]
Adding requests:  84%|████████▍ | 1728/2048 [00:04<00:00, 379.90it/s]
Adding requests:  86%|████████▋ | 1769/2048 [00:04<00:00, 388.20it/s]
Adding requests:  88%|████████▊ | 1808/2048 [00:04<00:00, 382.85it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:04<00:00, 385.52it/s]
Adding requests:  92%|█████████▏| 1888/2048 [00:04<00:00, 389.31it/s]
Adding requests:  94%|█████████▍| 1929/2048 [00:05<00:00, 392.80it/s]
Adding requests:  96%|█████████▌| 1969/2048 [00:05<00:00, 392.81it/s]
Adding requests:  98%|█████████▊| 2009/2048 [00:05<00:00, 387.64it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 373.19it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 382.55it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:00<00:11, 170.42it/s, est. speed input: 174521.35 toks/s, output: 170.42 toks/s]
Processed prompts:   6%|▋         | 132/2048 [00:01<00:23, 81.86it/s, est. speed input: 96868.48 toks/s, output: 94.60 toks/s]   
Processed prompts:   7%|▋         | 146/2048 [00:02<00:35, 52.86it/s, est. speed input: 70554.59 toks/s, output: 68.90 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:02<00:46, 40.68it/s, est. speed input: 58425.96 toks/s, output: 57.06 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:03<00:55, 33.99it/s, est. speed input: 51200.62 toks/s, output: 50.00 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:04<01:00, 30.48it/s, est. speed input: 46799.34 toks/s, output: 45.70 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:04<01:06, 27.69it/s, est. speed input: 43272.53 toks/s, output: 42.26 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:05<01:10, 25.90it/s, est. speed input: 40651.25 toks/s, output: 39.70 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:06<01:13, 24.68it/s, est. speed input: 38606.61 toks/s, output: 37.70 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:07<01:14, 23.90it/s, est. speed input: 36996.17 toks/s, output: 36.13 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:07<01:15, 23.35it/s, est. speed input: 35678.35 toks/s, output: 34.84 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:08<01:16, 22.96it/s, est. speed input: 34573.82 toks/s, output: 33.76 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:09<01:16, 22.69it/s, est. speed input: 33642.01 toks/s, output: 32.85 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:10<01:16, 22.50it/s, est. speed input: 32844.53 toks/s, output: 32.07 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:10<01:16, 22.37it/s, est. speed input: 32152.46 toks/s, output: 31.40 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:11<01:16, 22.23it/s, est. speed input: 31536.31 toks/s, output: 30.80 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:12<01:15, 22.18it/s, est. speed input: 31006.43 toks/s, output: 30.28 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:12<01:15, 22.16it/s, est. speed input: 30537.41 toks/s, output: 29.82 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:13<01:14, 22.13it/s, est. speed input: 30115.22 toks/s, output: 29.41 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:14<01:13, 22.11it/s, est. speed input: 29735.86 toks/s, output: 29.04 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:15<01:13, 22.10it/s, est. speed input: 29393.95 toks/s, output: 28.70 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:15<01:12, 22.09it/s, est. speed input: 29083.89 toks/s, output: 28.40 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:16<01:11, 22.08it/s, est. speed input: 28799.08 toks/s, output: 28.12 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:17<01:10, 22.08it/s, est. speed input: 28539.21 toks/s, output: 27.87 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:18<01:10, 22.06it/s, est. speed input: 28297.38 toks/s, output: 27.63 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:18<01:09, 22.07it/s, est. speed input: 28078.39 toks/s, output: 27.42 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:19<01:08, 22.07it/s, est. speed input: 27874.55 toks/s, output: 27.22 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:20<01:08, 22.04it/s, est. speed input: 27680.52 toks/s, output: 27.03 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:20<01:07, 22.03it/s, est. speed input: 27501.75 toks/s, output: 26.86 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:21<01:06, 22.04it/s, est. speed input: 27337.88 toks/s, output: 26.70 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:22<01:06, 22.02it/s, est. speed input: 27179.70 toks/s, output: 26.54 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:23<01:05, 22.03it/s, est. speed input: 27035.32 toks/s, output: 26.40 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:23<01:04, 21.99it/s, est. speed input: 26894.46 toks/s, output: 26.26 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:24<01:03, 21.99it/s, est. speed input: 26764.47 toks/s, output: 26.14 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:25<01:03, 21.99it/s, est. speed input: 26641.79 toks/s, output: 26.02 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:26<01:02, 21.98it/s, est. speed input: 26525.56 toks/s, output: 25.90 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:26<01:01, 21.96it/s, est. speed input: 26413.98 toks/s, output: 25.79 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:27<01:01, 21.95it/s, est. speed input: 26308.79 toks/s, output: 25.69 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:28<01:00, 21.96it/s, est. speed input: 26210.61 toks/s, output: 25.60 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:28<00:59, 21.92it/s, est. speed input: 26113.33 toks/s, output: 25.50 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:29<00:58, 21.94it/s, est. speed input: 26024.43 toks/s, output: 25.41 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:30<00:58, 21.92it/s, est. speed input: 25937.10 toks/s, output: 25.33 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:31<00:56, 22.27it/s, est. speed input: 25887.41 toks/s, output: 25.28 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:31<00:56, 22.16it/s, est. speed input: 25808.02 toks/s, output: 25.20 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:32<00:55, 22.08it/s, est. speed input: 25732.29 toks/s, output: 25.13 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:33<00:55, 22.00it/s, est. speed input: 25657.30 toks/s, output: 25.06 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:34<00:54, 21.98it/s, est. speed input: 25588.85 toks/s, output: 24.99 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:34<00:53, 21.95it/s, est. speed input: 25521.84 toks/s, output: 24.92 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:35<00:53, 21.95it/s, est. speed input: 25459.03 toks/s, output: 24.86 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:36<00:52, 21.93it/s, est. speed input: 25397.59 toks/s, output: 24.80 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:36<00:51, 21.92it/s, est. speed input: 25338.91 toks/s, output: 24.75 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:37<00:51, 21.89it/s, est. speed input: 25280.70 toks/s, output: 24.69 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:38<00:50, 21.87it/s, est. speed input: 25224.72 toks/s, output: 24.63 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:39<00:49, 21.88it/s, est. speed input: 25172.17 toks/s, output: 24.58 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:39<00:48, 21.88it/s, est. speed input: 25121.41 toks/s, output: 24.53 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:40<00:48, 21.85it/s, est. speed input: 25070.71 toks/s, output: 24.48 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:41<00:47, 21.86it/s, est. speed input: 25023.51 toks/s, output: 24.44 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:42<00:46, 21.85it/s, est. speed input: 24977.13 toks/s, output: 24.39 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:42<00:46, 21.85it/s, est. speed input: 24932.65 toks/s, output: 24.35 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:43<00:45, 21.83it/s, est. speed input: 24888.31 toks/s, output: 24.30 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:44<00:44, 21.83it/s, est. speed input: 24846.33 toks/s, output: 24.26 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:44<00:43, 21.84it/s, est. speed input: 24806.09 toks/s, output: 24.22 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:45<00:43, 21.82it/s, est. speed input: 24765.86 toks/s, output: 24.19 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:46<00:42, 21.82it/s, est. speed input: 24727.55 toks/s, output: 24.15 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:47<00:41, 21.81it/s, est. speed input: 24690.23 toks/s, output: 24.11 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:47<00:41, 21.80it/s, est. speed input: 24653.64 toks/s, output: 24.08 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:48<00:40, 21.78it/s, est. speed input: 24617.12 toks/s, output: 24.04 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:49<00:39, 21.78it/s, est. speed input: 24582.95 toks/s, output: 24.01 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:50<00:38, 21.80it/s, est. speed input: 24550.30 toks/s, output: 23.97 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:50<00:38, 21.78it/s, est. speed input: 24517.44 toks/s, output: 23.94 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:51<00:37, 21.77it/s, est. speed input: 24485.21 toks/s, output: 23.91 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:52<00:36, 21.74it/s, est. speed input: 24452.74 toks/s, output: 23.88 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:53<00:35, 21.74it/s, est. speed input: 24422.38 toks/s, output: 23.85 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:53<00:35, 21.76it/s, est. speed input: 24393.79 toks/s, output: 23.82 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:54<00:34, 21.77it/s, est. speed input: 24366.01 toks/s, output: 23.79 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:55<00:33, 21.76it/s, est. speed input: 24337.94 toks/s, output: 23.77 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:56<00:33, 21.73it/s, est. speed input: 24309.50 toks/s, output: 23.74 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:56<00:32, 21.76it/s, est. speed input: 24284.14 toks/s, output: 23.71 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:57<00:31, 21.75it/s, est. speed input: 24257.98 toks/s, output: 23.69 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:58<00:30, 21.72it/s, est. speed input: 24231.66 toks/s, output: 23.66 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:58<00:30, 21.70it/s, est. speed input: 24206.00 toks/s, output: 23.64 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:59<00:29, 21.71it/s, est. speed input: 24181.84 toks/s, output: 23.62 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:00<00:28, 21.71it/s, est. speed input: 24157.90 toks/s, output: 23.59 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:01<00:27, 21.71it/s, est. speed input: 24134.64 toks/s, output: 23.57 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:01<00:27, 21.70it/s, est. speed input: 24111.75 toks/s, output: 23.55 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:02<00:26, 21.71it/s, est. speed input: 24090.06 toks/s, output: 23.53 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:03<00:25, 21.72it/s, est. speed input: 24068.87 toks/s, output: 23.50 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:04<00:24, 21.70it/s, est. speed input: 24046.91 toks/s, output: 23.48 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:04<00:24, 21.68it/s, est. speed input: 24025.12 toks/s, output: 23.46 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:05<00:23, 21.69it/s, est. speed input: 24005.22 toks/s, output: 23.44 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:06<00:22, 22.05it/s, est. speed input: 23999.85 toks/s, output: 23.44 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:07<00:21, 21.95it/s, est. speed input: 23980.31 toks/s, output: 23.42 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:07<00:21, 21.86it/s, est. speed input: 23960.66 toks/s, output: 23.40 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:08<00:20, 21.81it/s, est. speed input: 23942.05 toks/s, output: 23.38 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:09<00:19, 22.14it/s, est. speed input: 23937.69 toks/s, output: 23.38 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:09<00:18, 22.00it/s, est. speed input: 23919.12 toks/s, output: 23.36 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:10<00:18, 21.88it/s, est. speed input: 23900.42 toks/s, output: 23.34 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:11<00:17, 21.81it/s, est. speed input: 23882.56 toks/s, output: 23.32 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:12<00:16, 21.76it/s, est. speed input: 23864.84 toks/s, output: 23.31 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:12<00:16, 21.73it/s, est. speed input: 23847.80 toks/s, output: 23.29 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:13<00:15, 21.69it/s, est. speed input: 23830.40 toks/s, output: 23.27 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:14<00:14, 21.66it/s, est. speed input: 23813.35 toks/s, output: 23.26 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:15<00:13, 21.64it/s, est. speed input: 23796.63 toks/s, output: 23.24 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:15<00:13, 21.65it/s, est. speed input: 23781.02 toks/s, output: 23.22 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:16<00:12, 21.65it/s, est. speed input: 23765.29 toks/s, output: 23.21 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:17<00:11, 21.63it/s, est. speed input: 23749.51 toks/s, output: 23.19 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:18<00:10, 21.64it/s, est. speed input: 23734.69 toks/s, output: 23.18 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:18<00:10, 21.64it/s, est. speed input: 23719.82 toks/s, output: 23.16 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:19<00:09, 21.62it/s, est. speed input: 23704.78 toks/s, output: 23.15 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:20<00:08, 21.63it/s, est. speed input: 23690.67 toks/s, output: 23.14 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:21<00:08, 21.63it/s, est. speed input: 23676.49 toks/s, output: 23.12 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:21<00:07, 21.64it/s, est. speed input: 23663.10 toks/s, output: 23.11 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:22<00:06, 21.63it/s, est. speed input: 23649.29 toks/s, output: 23.10 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:23<00:05, 21.60it/s, est. speed input: 23635.04 toks/s, output: 23.08 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:24<00:05, 21.61it/s, est. speed input: 23622.02 toks/s, output: 23.07 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:24<00:04, 21.62it/s, est. speed input: 23609.28 toks/s, output: 23.06 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:25<00:03, 21.62it/s, est. speed input: 23596.64 toks/s, output: 23.04 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:26<00:02, 21.61it/s, est. speed input: 23583.72 toks/s, output: 23.03 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:26<00:02, 21.61it/s, est. speed input: 23571.25 toks/s, output: 23.02 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:27<00:01, 21.61it/s, est. speed input: 23559.04 toks/s, output: 23.01 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:28<00:00, 22.02it/s, est. speed input: 23559.44 toks/s, output: 23.01 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:28<00:00, 22.02it/s, est. speed input: 23721.42 toks/s, output: 23.17 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:28<00:00, 23.17it/s, est. speed input: 23721.42 toks/s, output: 23.17 toks/s]
[rank0]:[W126 15:03:23.570242597 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 15:03:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:03:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1515473) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1515473) WARNING 01-26 15:04:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.13 requests/s, 22681.11 total tokens/s, 22.13 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 15:03:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:03:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:03:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:03:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:03:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:03:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:03:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:03:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:03:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:04:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:04:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:04:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:04:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:04:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:04:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:04:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:04:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:04:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:03] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.44it/s]
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1515473) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
(EngineCore_DP0 pid=1515473) 
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1515473) [2026-01-26 15:04:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1515473) [rank0]:W0126 15:04:25.860000 1515473 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1515473) [rank0]:W0126 15:04:25.914000 1515473 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1515473) [rank0]:W0126 15:04:26.533000 1515473 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1515473) [rank0]:W0126 15:04:26.618000 1515473 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1515473) 2026-01-26 15:04:31,253 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1515473) 2026-01-26 15:04:31,722 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1515473) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:09,  1.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:01<00:03,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:02,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  5.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  6.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:02<00:00,  4.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:02<00:00,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  3.75it/s]
(EngineCore_DP0 pid=1515473) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 11.47it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 11.69it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.30it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/4096 [00:00<00:17, 238.95it/s]
Adding requests:   2%|▏         | 64/4096 [00:00<00:12, 332.22it/s]
Adding requests:   2%|▏         | 100/4096 [00:00<00:11, 343.73it/s]
Adding requests:   3%|▎         | 138/4096 [00:00<00:11, 355.71it/s]
Adding requests:   4%|▍         | 178/4096 [00:00<00:10, 368.62it/s]
Adding requests:   5%|▌         | 220/4096 [00:00<00:10, 384.33it/s]
Adding requests:   6%|▋         | 259/4096 [00:00<00:10, 379.93it/s]
Adding requests:   7%|▋         | 299/4096 [00:00<00:09, 384.88it/s]
Adding requests:   8%|▊         | 340/4096 [00:00<00:09, 390.42it/s]
Adding requests:   9%|▉         | 380/4096 [00:01<00:09, 392.95it/s]
Adding requests:  10%|█         | 422/4096 [00:01<00:09, 399.88it/s]
Adding requests:  11%|█▏        | 462/4096 [00:01<00:09, 396.06it/s]
Adding requests:  12%|█▏        | 504/4096 [00:01<00:08, 402.55it/s]
Adding requests:  13%|█▎        | 546/4096 [00:01<00:08, 404.67it/s]
Adding requests:  14%|█▍        | 587/4096 [00:01<00:08, 398.40it/s]
Adding requests:  15%|█▌        | 627/4096 [00:01<00:08, 393.92it/s]
Adding requests:  16%|█▋        | 667/4096 [00:01<00:08, 382.38it/s]
Adding requests:  17%|█▋        | 707/4096 [00:01<00:08, 385.69it/s]
Adding requests:  18%|█▊        | 746/4096 [00:01<00:08, 378.88it/s]
Adding requests:  19%|█▉        | 785/4096 [00:02<00:08, 381.72it/s]
Adding requests:  20%|██        | 824/4096 [00:02<00:08, 382.93it/s]
Adding requests:  21%|██        | 864/4096 [00:02<00:08, 387.94it/s]
Adding requests:  22%|██▏       | 906/4096 [00:02<00:08, 395.62it/s]
Adding requests:  23%|██▎       | 946/4096 [00:02<00:08, 384.39it/s]
Adding requests:  24%|██▍       | 986/4096 [00:02<00:08, 386.22it/s]
Adding requests:  25%|██▌       | 1025/4096 [00:02<00:08, 382.30it/s]
Adding requests:  26%|██▌       | 1064/4096 [00:02<00:07, 382.46it/s]
Adding requests:  27%|██▋       | 1103/4096 [00:02<00:07, 374.48it/s]
Adding requests:  28%|██▊       | 1142/4096 [00:02<00:07, 377.43it/s]
Adding requests:  29%|██▉       | 1180/4096 [00:03<00:07, 377.75it/s]
Adding requests:  30%|██▉       | 1221/4096 [00:03<00:07, 384.92it/s]
Adding requests:  31%|███       | 1260/4096 [00:03<00:07, 383.41it/s]
Adding requests:  32%|███▏      | 1299/4096 [00:03<00:07, 381.36it/s]
Adding requests:  33%|███▎      | 1338/4096 [00:03<00:07, 379.86it/s]
Adding requests:  34%|███▎      | 1378/4096 [00:03<00:07, 384.15it/s]
Adding requests:  35%|███▍      | 1417/4096 [00:03<00:07, 378.62it/s]
Adding requests:  36%|███▌      | 1457/4096 [00:03<00:06, 382.32it/s]
Adding requests:  37%|███▋      | 1497/4096 [00:03<00:06, 385.28it/s]
Adding requests:  38%|███▊      | 1536/4096 [00:04<00:06, 382.29it/s]
Adding requests:  38%|███▊      | 1575/4096 [00:04<00:06, 379.35it/s]
Adding requests:  39%|███▉      | 1613/4096 [00:04<00:06, 377.22it/s]
Adding requests:  40%|████      | 1651/4096 [00:04<00:06, 371.32it/s]
Adding requests:  41%|████      | 1689/4096 [00:04<00:06, 370.79it/s]
Adding requests:  42%|████▏     | 1729/4096 [00:04<00:06, 376.22it/s]
Adding requests:  43%|████▎     | 1770/4096 [00:04<00:06, 385.55it/s]
Adding requests:  44%|████▍     | 1809/4096 [00:04<00:06, 380.65it/s]
Adding requests:  45%|████▌     | 1849/4096 [00:04<00:05, 382.63it/s]
Adding requests:  46%|████▌     | 1889/4096 [00:04<00:05, 386.99it/s]
Adding requests:  47%|████▋     | 1930/4096 [00:05<00:05, 391.79it/s]
Adding requests:  48%|████▊     | 1970/4096 [00:05<00:05, 392.36it/s]
Adding requests:  49%|████▉     | 2010/4096 [00:05<00:05, 386.89it/s]
Adding requests:  50%|█████     | 2049/4096 [00:05<00:05, 382.47it/s]
Adding requests:  51%|█████     | 2088/4096 [00:05<00:05, 371.87it/s]
Adding requests:  52%|█████▏    | 2128/4096 [00:05<00:05, 378.89it/s]
Adding requests:  53%|█████▎    | 2166/4096 [00:05<00:05, 375.81it/s]
Adding requests:  54%|█████▍    | 2204/4096 [00:05<00:05, 371.75it/s]
Adding requests:  55%|█████▍    | 2243/4096 [00:05<00:04, 375.76it/s]
Adding requests:  56%|█████▌    | 2284/4096 [00:05<00:04, 382.99it/s]
Adding requests:  57%|█████▋    | 2324/4096 [00:06<00:04, 381.36it/s]
Adding requests:  58%|█████▊    | 2363/4096 [00:06<00:04, 380.51it/s]
Adding requests:  59%|█████▊    | 2404/4096 [00:06<00:04, 387.70it/s]
Adding requests:  60%|█████▉    | 2444/4096 [00:06<00:04, 390.98it/s]
Adding requests:  61%|██████    | 2484/4096 [00:06<00:04, 389.93it/s]
Adding requests:  62%|██████▏   | 2525/4096 [00:06<00:03, 393.93it/s]
Adding requests:  63%|██████▎   | 2569/4096 [00:06<00:03, 406.90it/s]
Adding requests:  64%|██████▎   | 2610/4096 [00:06<00:03, 403.49it/s]
Adding requests:  65%|██████▍   | 2651/4096 [00:06<00:03, 393.41it/s]
Adding requests:  66%|██████▌   | 2691/4096 [00:07<00:03, 389.92it/s]
Adding requests:  67%|██████▋   | 2731/4096 [00:07<00:03, 386.94it/s]
Adding requests:  68%|██████▊   | 2773/4096 [00:07<00:03, 393.56it/s]
Adding requests:  69%|██████▊   | 2814/4096 [00:07<00:03, 398.15it/s]
Adding requests:  70%|██████▉   | 2854/4096 [00:07<00:03, 397.28it/s]
Adding requests:  71%|███████   | 2894/4096 [00:07<00:03, 395.18it/s]
Adding requests:  72%|███████▏  | 2934/4096 [00:07<00:02, 396.19it/s]
Adding requests:  73%|███████▎  | 2974/4096 [00:07<00:02, 392.42it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:07<00:02, 394.91it/s]
Adding requests:  75%|███████▍  | 3055/4096 [00:07<00:02, 395.24it/s]
Adding requests:  76%|███████▌  | 3095/4096 [00:08<00:02, 393.82it/s]
Adding requests:  77%|███████▋  | 3135/4096 [00:08<00:02, 395.48it/s]
Adding requests:  78%|███████▊  | 3175/4096 [00:08<00:02, 386.58it/s]
Adding requests:  78%|███████▊  | 3214/4096 [00:08<00:02, 384.61it/s]
Adding requests:  79%|███████▉  | 3255/4096 [00:08<00:02, 389.54it/s]
Adding requests:  80%|████████  | 3294/4096 [00:08<00:02, 375.66it/s]
Adding requests:  81%|████████▏ | 3332/4096 [00:08<00:02, 375.61it/s]
Adding requests:  82%|████████▏ | 3373/4096 [00:08<00:01, 385.54it/s]
Adding requests:  83%|████████▎ | 3413/4096 [00:08<00:01, 388.32it/s]
Adding requests:  84%|████████▍ | 3453/4096 [00:08<00:01, 389.98it/s]
Adding requests:  85%|████████▌ | 3493/4096 [00:09<00:01, 387.49it/s]
Adding requests:  86%|████████▋ | 3536/4096 [00:09<00:01, 398.37it/s]
Adding requests:  87%|████████▋ | 3576/4096 [00:09<00:01, 398.54it/s]
Adding requests:  88%|████████▊ | 3616/4096 [00:09<00:01, 398.40it/s]
Adding requests:  89%|████████▉ | 3656/4096 [00:09<00:01, 395.60it/s]
Adding requests:  90%|█████████ | 3696/4096 [00:09<00:01, 377.93it/s]
Adding requests:  91%|█████████ | 3735/4096 [00:09<00:00, 379.73it/s]
Adding requests:  92%|█████████▏| 3774/4096 [00:09<00:00, 371.93it/s]
Adding requests:  93%|█████████▎| 3812/4096 [00:09<00:00, 360.84it/s]
Adding requests:  94%|█████████▍| 3851/4096 [00:10<00:00, 366.76it/s]
Adding requests:  95%|█████████▍| 3890/4096 [00:10<00:00, 371.62it/s]
Adding requests:  96%|█████████▌| 3928/4096 [00:10<00:00, 368.76it/s]
Adding requests:  97%|█████████▋| 3967/4096 [00:10<00:00, 372.86it/s]
Adding requests:  98%|█████████▊| 4005/4096 [00:10<00:00, 374.45it/s]
Adding requests:  99%|█████████▊| 4043/4096 [00:10<00:00, 373.42it/s]
Adding requests: 100%|█████████▉| 4081/4096 [00:10<00:00, 374.60it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 383.62it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 218/4096 [00:00<00:07, 488.24it/s, est. speed input: 499987.65 toks/s, output: 488.25 toks/s]
Processed prompts:   7%|▋         | 267/4096 [00:01<00:33, 115.76it/s, est. speed input: 145780.99 toks/s, output: 142.36 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:03<01:01, 61.90it/s, est. speed input: 89779.76 toks/s, output: 87.68 toks/s]   
Processed prompts:   8%|▊         | 314/4096 [00:04<01:29, 42.30it/s, est. speed input: 67905.97 toks/s, output: 66.31 toks/s]
Processed prompts:   8%|▊         | 346/4096 [00:06<01:48, 34.64it/s, est. speed input: 57455.60 toks/s, output: 56.11 toks/s]
Processed prompts:   9%|▉         | 378/4096 [00:07<02:02, 30.31it/s, est. speed input: 50956.42 toks/s, output: 49.76 toks/s]
Processed prompts:  10%|█         | 410/4096 [00:09<02:13, 27.63it/s, est. speed input: 46499.01 toks/s, output: 45.41 toks/s]
Processed prompts:  11%|█         | 442/4096 [00:10<02:21, 25.89it/s, est. speed input: 43250.13 toks/s, output: 42.24 toks/s]
Processed prompts:  12%|█▏        | 474/4096 [00:11<02:26, 24.75it/s, est. speed input: 40785.00 toks/s, output: 39.83 toks/s]
Processed prompts:  12%|█▏        | 506/4096 [00:13<02:29, 23.98it/s, est. speed input: 38849.10 toks/s, output: 37.94 toks/s]
Processed prompts:  13%|█▎        | 538/4096 [00:14<02:31, 23.45it/s, est. speed input: 37286.33 toks/s, output: 36.41 toks/s]
Processed prompts:  14%|█▍        | 570/4096 [00:16<02:32, 23.08it/s, est. speed input: 36000.63 toks/s, output: 35.16 toks/s]
Processed prompts:  15%|█▍        | 602/4096 [00:17<02:33, 22.81it/s, est. speed input: 34914.70 toks/s, output: 34.10 toks/s]
Processed prompts:  15%|█▌        | 634/4096 [00:19<02:32, 22.63it/s, est. speed input: 33997.62 toks/s, output: 33.20 toks/s]
Processed prompts:  16%|█▋        | 666/4096 [00:20<02:32, 22.50it/s, est. speed input: 33208.38 toks/s, output: 32.43 toks/s]
Processed prompts:  17%|█▋        | 698/4096 [00:21<02:31, 22.43it/s, est. speed input: 32525.73 toks/s, output: 31.76 toks/s]
Processed prompts:  18%|█▊        | 730/4096 [00:23<02:30, 22.36it/s, est. speed input: 31922.47 toks/s, output: 31.17 toks/s]
Processed prompts:  19%|█▊        | 762/4096 [00:24<02:28, 22.50it/s, est. speed input: 31441.69 toks/s, output: 30.70 toks/s]
Processed prompts:  19%|█▉        | 794/4096 [00:26<02:27, 22.42it/s, est. speed input: 30965.89 toks/s, output: 30.24 toks/s]
Processed prompts:  20%|██        | 826/4096 [00:27<02:26, 22.36it/s, est. speed input: 30539.62 toks/s, output: 29.82 toks/s]
Processed prompts:  21%|██        | 858/4096 [00:29<02:25, 22.32it/s, est. speed input: 30155.41 toks/s, output: 29.45 toks/s]
Processed prompts:  22%|██▏       | 890/4096 [00:30<02:23, 22.29it/s, est. speed input: 29805.93 toks/s, output: 29.11 toks/s]
Processed prompts:  23%|██▎       | 922/4096 [00:32<02:22, 22.27it/s, est. speed input: 29488.71 toks/s, output: 28.80 toks/s]
Processed prompts:  23%|██▎       | 954/4096 [00:33<02:21, 22.25it/s, est. speed input: 29198.89 toks/s, output: 28.51 toks/s]
Processed prompts:  24%|██▍       | 986/4096 [00:34<02:19, 22.25it/s, est. speed input: 28933.20 toks/s, output: 28.26 toks/s]
Processed prompts:  25%|██▍       | 1018/4096 [00:36<02:18, 22.23it/s, est. speed input: 28687.61 toks/s, output: 28.02 toks/s]
Processed prompts:  26%|██▌       | 1050/4096 [00:37<02:17, 22.23it/s, est. speed input: 28460.73 toks/s, output: 27.79 toks/s]
Processed prompts:  26%|██▋       | 1082/4096 [00:39<02:15, 22.22it/s, est. speed input: 28250.59 toks/s, output: 27.59 toks/s]
Processed prompts:  27%|██▋       | 1114/4096 [00:40<02:14, 22.19it/s, est. speed input: 28050.83 toks/s, output: 27.39 toks/s]
Processed prompts:  28%|██▊       | 1146/4096 [00:42<02:12, 22.20it/s, est. speed input: 27869.46 toks/s, output: 27.22 toks/s]
Processed prompts:  29%|██▉       | 1178/4096 [00:43<02:11, 22.20it/s, est. speed input: 27700.00 toks/s, output: 27.05 toks/s]
Processed prompts:  30%|██▉       | 1210/4096 [00:44<02:10, 22.19it/s, est. speed input: 27539.84 toks/s, output: 26.89 toks/s]
Processed prompts:  30%|███       | 1242/4096 [00:46<02:08, 22.17it/s, est. speed input: 27387.79 toks/s, output: 26.75 toks/s]
Processed prompts:  31%|███       | 1274/4096 [00:47<02:07, 22.15it/s, est. speed input: 27243.68 toks/s, output: 26.61 toks/s]
Processed prompts:  32%|███▏      | 1306/4096 [00:49<02:05, 22.16it/s, est. speed input: 27111.57 toks/s, output: 26.48 toks/s]
Processed prompts:  33%|███▎      | 1338/4096 [00:50<02:04, 22.16it/s, est. speed input: 26985.80 toks/s, output: 26.35 toks/s]
Processed prompts:  33%|███▎      | 1370/4096 [00:52<02:03, 22.15it/s, est. speed input: 26865.93 toks/s, output: 26.24 toks/s]
Processed prompts:  34%|███▍      | 1402/4096 [00:53<02:01, 22.13it/s, est. speed input: 26751.03 toks/s, output: 26.12 toks/s]
Processed prompts:  35%|███▌      | 1434/4096 [00:55<02:00, 22.11it/s, est. speed input: 26641.45 toks/s, output: 26.02 toks/s]
Processed prompts:  36%|███▌      | 1466/4096 [00:56<01:59, 22.10it/s, est. speed input: 26537.82 toks/s, output: 25.92 toks/s]
Processed prompts:  37%|███▋      | 1498/4096 [00:58<01:57, 22.09it/s, est. speed input: 26439.24 toks/s, output: 25.82 toks/s]
Processed prompts:  37%|███▋      | 1530/4096 [00:59<01:56, 22.08it/s, est. speed input: 26345.15 toks/s, output: 25.73 toks/s]
Processed prompts:  38%|███▊      | 1562/4096 [01:00<01:53, 22.23it/s, est. speed input: 26270.73 toks/s, output: 25.65 toks/s]
Processed prompts:  39%|███▉      | 1594/4096 [01:02<01:52, 22.21it/s, est. speed input: 26187.83 toks/s, output: 25.57 toks/s]
Processed prompts:  40%|███▉      | 1626/4096 [01:03<01:50, 22.32it/s, est. speed input: 26119.62 toks/s, output: 25.51 toks/s]
Processed prompts:  40%|████      | 1658/4096 [01:05<01:49, 22.27it/s, est. speed input: 26043.54 toks/s, output: 25.43 toks/s]
Processed prompts:  41%|████▏     | 1690/4096 [01:06<01:48, 22.22it/s, est. speed input: 25969.33 toks/s, output: 25.36 toks/s]
Processed prompts:  42%|████▏     | 1722/4096 [01:08<01:47, 22.18it/s, est. speed input: 25897.76 toks/s, output: 25.29 toks/s]
Processed prompts:  43%|████▎     | 1754/4096 [01:09<01:45, 22.14it/s, est. speed input: 25828.66 toks/s, output: 25.22 toks/s]
Processed prompts:  44%|████▎     | 1786/4096 [01:10<01:44, 22.12it/s, est. speed input: 25762.81 toks/s, output: 25.16 toks/s]
Processed prompts:  44%|████▍     | 1818/4096 [01:12<01:43, 22.11it/s, est. speed input: 25699.55 toks/s, output: 25.10 toks/s]
Processed prompts:  45%|████▌     | 1850/4096 [01:13<01:41, 22.09it/s, est. speed input: 25638.66 toks/s, output: 25.04 toks/s]
Processed prompts:  46%|████▌     | 1882/4096 [01:15<01:40, 22.09it/s, est. speed input: 25580.13 toks/s, output: 24.98 toks/s]
Processed prompts:  47%|████▋     | 1914/4096 [01:16<01:38, 22.08it/s, est. speed input: 25523.74 toks/s, output: 24.93 toks/s]
Processed prompts:  48%|████▊     | 1946/4096 [01:18<01:37, 22.08it/s, est. speed input: 25469.48 toks/s, output: 24.87 toks/s]
Processed prompts:  48%|████▊     | 1978/4096 [01:19<01:35, 22.07it/s, est. speed input: 25417.17 toks/s, output: 24.82 toks/s]
Processed prompts:  49%|████▉     | 2010/4096 [01:21<01:34, 22.07it/s, est. speed input: 25366.87 toks/s, output: 24.77 toks/s]
Processed prompts:  50%|████▉     | 2042/4096 [01:22<01:33, 22.07it/s, est. speed input: 25317.84 toks/s, output: 24.72 toks/s]
Processed prompts:  51%|█████     | 2074/4096 [01:24<01:31, 22.07it/s, est. speed input: 25271.37 toks/s, output: 24.68 toks/s]
Processed prompts:  51%|█████▏    | 2106/4096 [01:25<01:30, 22.07it/s, est. speed input: 25225.83 toks/s, output: 24.63 toks/s]
Processed prompts:  52%|█████▏    | 2138/4096 [01:26<01:28, 22.07it/s, est. speed input: 25182.01 toks/s, output: 24.59 toks/s]
Processed prompts:  53%|█████▎    | 2170/4096 [01:28<01:26, 22.22it/s, est. speed input: 25148.69 toks/s, output: 24.56 toks/s]
Processed prompts:  54%|█████▍    | 2202/4096 [01:29<01:25, 22.16it/s, est. speed input: 25106.89 toks/s, output: 24.52 toks/s]
Processed prompts:  55%|█████▍    | 2234/4096 [01:31<01:24, 22.14it/s, est. speed input: 25067.46 toks/s, output: 24.48 toks/s]
Processed prompts:  55%|█████▌    | 2266/4096 [01:32<01:22, 22.10it/s, est. speed input: 25027.82 toks/s, output: 24.44 toks/s]
Processed prompts:  56%|█████▌    | 2298/4096 [01:34<01:21, 22.09it/s, est. speed input: 24990.35 toks/s, output: 24.40 toks/s]
Processed prompts:  57%|█████▋    | 2330/4096 [01:35<01:20, 22.05it/s, est. speed input: 24952.20 toks/s, output: 24.37 toks/s]
Processed prompts:  58%|█████▊    | 2362/4096 [01:37<01:18, 22.06it/s, est. speed input: 24917.27 toks/s, output: 24.33 toks/s]
Processed prompts:  58%|█████▊    | 2394/4096 [01:38<01:17, 22.06it/s, est. speed input: 24882.80 toks/s, output: 24.30 toks/s]
Processed prompts:  59%|█████▉    | 2426/4096 [01:39<01:15, 22.05it/s, est. speed input: 24848.89 toks/s, output: 24.27 toks/s]
Processed prompts:  60%|██████    | 2458/4096 [01:41<01:14, 22.03it/s, est. speed input: 24815.43 toks/s, output: 24.23 toks/s]
Processed prompts:  61%|██████    | 2490/4096 [01:42<01:12, 22.03it/s, est. speed input: 24783.68 toks/s, output: 24.20 toks/s]
Processed prompts:  62%|██████▏   | 2522/4096 [01:44<01:11, 22.03it/s, est. speed input: 24752.74 toks/s, output: 24.17 toks/s]
Processed prompts:  62%|██████▏   | 2554/4096 [01:45<01:10, 22.01it/s, est. speed input: 24721.63 toks/s, output: 24.14 toks/s]
Processed prompts:  63%|██████▎   | 2586/4096 [01:47<01:08, 22.03it/s, est. speed input: 24692.73 toks/s, output: 24.11 toks/s]
Processed prompts:  64%|██████▍   | 2618/4096 [01:48<01:07, 22.03it/s, est. speed input: 24664.13 toks/s, output: 24.09 toks/s]
Processed prompts:  65%|██████▍   | 2650/4096 [01:50<01:05, 22.01it/s, est. speed input: 24635.42 toks/s, output: 24.06 toks/s]
Processed prompts:  65%|██████▌   | 2682/4096 [01:51<01:04, 22.01it/s, est. speed input: 24608.06 toks/s, output: 24.03 toks/s]
Processed prompts:  66%|██████▋   | 2714/4096 [01:53<01:02, 22.01it/s, est. speed input: 24581.31 toks/s, output: 24.01 toks/s]
Processed prompts:  67%|██████▋   | 2746/4096 [01:54<01:01, 21.97it/s, est. speed input: 24553.66 toks/s, output: 23.98 toks/s]
Processed prompts:  68%|██████▊   | 2778/4096 [01:55<00:59, 21.98it/s, est. speed input: 24528.41 toks/s, output: 23.95 toks/s]
Processed prompts:  69%|██████▊   | 2810/4096 [01:57<00:58, 21.98it/s, est. speed input: 24503.49 toks/s, output: 23.93 toks/s]
Processed prompts:  69%|██████▉   | 2842/4096 [01:58<00:57, 21.98it/s, est. speed input: 24479.04 toks/s, output: 23.91 toks/s]
Processed prompts:  70%|███████   | 2874/4096 [02:00<00:55, 21.99it/s, est. speed input: 24455.71 toks/s, output: 23.88 toks/s]
Processed prompts:  71%|███████   | 2906/4096 [02:01<00:53, 22.13it/s, est. speed input: 24438.66 toks/s, output: 23.87 toks/s]
Processed prompts:  72%|███████▏  | 2938/4096 [02:03<00:52, 22.09it/s, est. speed input: 24416.04 toks/s, output: 23.84 toks/s]
Processed prompts:  73%|███████▎  | 2970/4096 [02:04<00:51, 22.07it/s, est. speed input: 24394.25 toks/s, output: 23.82 toks/s]
Processed prompts:  73%|███████▎  | 3002/4096 [02:06<00:49, 22.05it/s, est. speed input: 24372.97 toks/s, output: 23.80 toks/s]
Processed prompts:  74%|███████▍  | 3034/4096 [02:07<00:48, 22.04it/s, est. speed input: 24351.83 toks/s, output: 23.78 toks/s]
Processed prompts:  75%|███████▍  | 3066/4096 [02:09<00:46, 22.04it/s, est. speed input: 24331.73 toks/s, output: 23.76 toks/s]
Processed prompts:  76%|███████▌  | 3098/4096 [02:10<00:45, 22.02it/s, est. speed input: 24311.32 toks/s, output: 23.74 toks/s]
Processed prompts:  76%|███████▋  | 3130/4096 [02:11<00:43, 22.02it/s, est. speed input: 24291.83 toks/s, output: 23.72 toks/s]
Processed prompts:  77%|███████▋  | 3162/4096 [02:13<00:42, 22.02it/s, est. speed input: 24272.95 toks/s, output: 23.70 toks/s]
Processed prompts:  78%|███████▊  | 3194/4096 [02:14<00:40, 22.01it/s, est. speed input: 24253.81 toks/s, output: 23.69 toks/s]
Processed prompts:  79%|███████▉  | 3226/4096 [02:16<00:39, 22.01it/s, est. speed input: 24235.61 toks/s, output: 23.67 toks/s]
Processed prompts:  80%|███████▉  | 3258/4096 [02:17<00:38, 22.01it/s, est. speed input: 24217.55 toks/s, output: 23.65 toks/s]
Processed prompts:  80%|████████  | 3290/4096 [02:19<00:36, 21.98it/s, est. speed input: 24198.80 toks/s, output: 23.63 toks/s]
Processed prompts:  81%|████████  | 3322/4096 [02:20<00:35, 21.98it/s, est. speed input: 24181.22 toks/s, output: 23.61 toks/s]
Processed prompts:  82%|████████▏ | 3354/4096 [02:22<00:33, 21.99it/s, est. speed input: 24164.42 toks/s, output: 23.60 toks/s]
Processed prompts:  83%|████████▎ | 3386/4096 [02:23<00:32, 21.98it/s, est. speed input: 24147.36 toks/s, output: 23.58 toks/s]
Processed prompts:  83%|████████▎ | 3418/4096 [02:25<00:30, 21.99it/s, est. speed input: 24131.42 toks/s, output: 23.57 toks/s]
Processed prompts:  84%|████████▍ | 3450/4096 [02:26<00:29, 22.00it/s, est. speed input: 24115.65 toks/s, output: 23.55 toks/s]
Processed prompts:  85%|████████▌ | 3482/4096 [02:27<00:27, 21.99it/s, est. speed input: 24099.72 toks/s, output: 23.53 toks/s]
Processed prompts:  86%|████████▌ | 3514/4096 [02:29<00:26, 22.00it/s, est. speed input: 24084.63 toks/s, output: 23.52 toks/s]
Processed prompts:  87%|████████▋ | 3546/4096 [02:30<00:25, 21.99it/s, est. speed input: 24069.42 toks/s, output: 23.51 toks/s]
Processed prompts:  87%|████████▋ | 3578/4096 [02:32<00:23, 21.98it/s, est. speed input: 24053.99 toks/s, output: 23.49 toks/s]
Processed prompts:  88%|████████▊ | 3610/4096 [02:33<00:22, 21.98it/s, est. speed input: 24039.44 toks/s, output: 23.48 toks/s]
Processed prompts:  89%|████████▉ | 3642/4096 [02:35<00:20, 21.98it/s, est. speed input: 24025.03 toks/s, output: 23.46 toks/s]
Processed prompts:  90%|████████▉ | 3674/4096 [02:36<00:19, 22.13it/s, est. speed input: 24015.94 toks/s, output: 23.45 toks/s]
Processed prompts:  90%|█████████ | 3706/4096 [02:38<00:17, 22.08it/s, est. speed input: 24001.90 toks/s, output: 23.44 toks/s]
Processed prompts:  91%|█████████▏| 3738/4096 [02:39<00:16, 22.04it/s, est. speed input: 23987.84 toks/s, output: 23.43 toks/s]
Processed prompts:  92%|█████████▏| 3770/4096 [02:41<00:14, 22.02it/s, est. speed input: 23974.50 toks/s, output: 23.41 toks/s]
Processed prompts:  93%|█████████▎| 3802/4096 [02:42<00:13, 22.00it/s, est. speed input: 23961.24 toks/s, output: 23.40 toks/s]
Processed prompts:  94%|█████████▎| 3834/4096 [02:43<00:11, 21.99it/s, est. speed input: 23948.11 toks/s, output: 23.39 toks/s]
Processed prompts:  94%|█████████▍| 3866/4096 [02:45<00:10, 22.00it/s, est. speed input: 23935.76 toks/s, output: 23.37 toks/s]
Processed prompts:  95%|█████████▌| 3898/4096 [02:46<00:09, 21.98it/s, est. speed input: 23922.96 toks/s, output: 23.36 toks/s]
Processed prompts:  96%|█████████▌| 3930/4096 [02:48<00:07, 22.14it/s, est. speed input: 23915.51 toks/s, output: 23.35 toks/s]
Processed prompts:  97%|█████████▋| 3962/4096 [02:49<00:06, 22.08it/s, est. speed input: 23903.05 toks/s, output: 23.34 toks/s]
Processed prompts:  98%|█████████▊| 3994/4096 [02:51<00:04, 22.07it/s, est. speed input: 23891.86 toks/s, output: 23.33 toks/s]
Processed prompts:  98%|█████████▊| 4026/4096 [02:52<00:03, 22.03it/s, est. speed input: 23879.89 toks/s, output: 23.32 toks/s]
Processed prompts:  99%|█████████▉| 4058/4096 [02:54<00:01, 22.02it/s, est. speed input: 23868.42 toks/s, output: 23.31 toks/s]
Processed prompts: 100%|█████████▉| 4090/4096 [02:54<00:00, 28.67it/s, est. speed input: 24011.27 toks/s, output: 23.45 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:54<00:00, 28.67it/s, est. speed input: 24046.46 toks/s, output: 23.48 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:54<00:00, 23.48it/s, est. speed input: 24046.46 toks/s, output: 23.48 toks/s]
[rank0]:[W126 15:07:42.558819464 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 15:07:44
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:08:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1519587) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1519587) WARNING 01-26 15:08:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.13 requests/s, 22686.49 total tokens/s, 22.13 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 15:08:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:08:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:08:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:08:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:08:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:08:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:08:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:08:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:08:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 15:08:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:08:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 15:08:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 15:08:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:08:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:08:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:08:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:08:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.46it/s]
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.77it/s]
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.58it/s]
(EngineCore_DP0 pid=1519587) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]
(EngineCore_DP0 pid=1519587) 
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30679040 bytes
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21913600 bytes
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118333440 bytes
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1519587) [2026-01-26 15:08:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=1519587) [rank0]:W0126 15:09:05.808000 1519587 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1519587) [rank0]:W0126 15:09:05.863000 1519587 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1519587) [rank0]:W0126 15:09:06.503000 1519587 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1519587) [rank0]:W0126 15:09:06.588000 1519587 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1519587) 2026-01-26 15:09:11,952 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1519587) 2026-01-26 15:09:12,807 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1519587) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:01<00:21,  1.19s/it]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:14,  1.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:10,  1.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:04,  2.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:02<00:02,  4.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:02,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:03<00:01,  4.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:04<00:02,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:04<00:01,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:04<00:01,  4.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:04<00:00,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:04<00:00,  5.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:04<00:00,  6.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  7.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  3.85it/s]
(EngineCore_DP0 pid=1519587) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  4.66it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:03,  2.27it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:01,  5.58it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  7.30it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  8.62it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  7.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.12it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 29/8192 [00:00<00:28, 287.07it/s]
Adding requests:   1%|          | 69/8192 [00:00<00:23, 352.02it/s]
Adding requests:   1%|▏         | 106/8192 [00:00<00:22, 355.58it/s]
Adding requests:   2%|▏         | 143/8192 [00:00<00:22, 359.87it/s]
Adding requests:   2%|▏         | 182/8192 [00:00<00:21, 368.66it/s]
Adding requests:   3%|▎         | 222/8192 [00:00<00:21, 378.88it/s]
Adding requests:   3%|▎         | 260/8192 [00:00<00:21, 375.25it/s]
Adding requests:   4%|▎         | 300/8192 [00:00<00:20, 380.71it/s]
Adding requests:   4%|▍         | 340/8192 [00:00<00:20, 384.67it/s]
Adding requests:   5%|▍         | 380/8192 [00:01<00:20, 387.00it/s]
Adding requests:   5%|▌         | 421/8192 [00:01<00:19, 392.27it/s]
Adding requests:   6%|▌         | 461/8192 [00:01<00:19, 387.18it/s]
Adding requests:   6%|▌         | 503/8192 [00:01<00:19, 395.17it/s]
Adding requests:   7%|▋         | 544/8192 [00:01<00:19, 399.47it/s]
Adding requests:   7%|▋         | 584/8192 [00:01<00:19, 395.45it/s]
Adding requests:   8%|▊         | 624/8192 [00:01<00:19, 381.22it/s]
Adding requests:   8%|▊         | 663/8192 [00:01<00:20, 376.38it/s]
Adding requests:   9%|▊         | 702/8192 [00:01<00:19, 379.56it/s]
Adding requests:   9%|▉         | 741/8192 [00:01<00:19, 376.36it/s]
Adding requests:  10%|▉         | 779/8192 [00:02<00:19, 376.62it/s]
Adding requests:  10%|▉         | 817/8192 [00:02<00:19, 376.04it/s]
Adding requests:  10%|█         | 858/8192 [00:02<00:19, 384.76it/s]
Adding requests:  11%|█         | 898/8192 [00:02<00:18, 386.96it/s]
Adding requests:  11%|█▏        | 937/8192 [00:02<00:19, 380.69it/s]
Adding requests:  12%|█▏        | 976/8192 [00:02<00:18, 382.06it/s]
Adding requests:  12%|█▏        | 1015/8192 [00:02<00:19, 373.95it/s]
Adding requests:  13%|█▎        | 1054/8192 [00:02<00:19, 375.29it/s]
Adding requests:  13%|█▎        | 1092/8192 [00:02<00:18, 374.82it/s]
Adding requests:  14%|█▍        | 1132/8192 [00:02<00:18, 381.73it/s]
Adding requests:  14%|█▍        | 1171/8192 [00:03<00:18, 376.18it/s]
Adding requests:  15%|█▍        | 1211/8192 [00:03<00:18, 382.37it/s]
Adding requests:  15%|█▌        | 1250/8192 [00:03<00:18, 382.43it/s]
Adding requests:  16%|█▌        | 1289/8192 [00:03<00:18, 378.13it/s]
Adding requests:  16%|█▌        | 1328/8192 [00:03<00:17, 381.35it/s]
Adding requests:  17%|█▋        | 1368/8192 [00:03<00:17, 384.51it/s]
Adding requests:  17%|█▋        | 1407/8192 [00:03<00:17, 382.26it/s]
Adding requests:  18%|█▊        | 1446/8192 [00:03<00:17, 380.65it/s]
Adding requests:  18%|█▊        | 1487/8192 [00:03<00:17, 386.31it/s]
Adding requests:  19%|█▊        | 1527/8192 [00:04<00:17, 387.21it/s]
Adding requests:  19%|█▉        | 1566/8192 [00:04<00:17, 381.49it/s]
Adding requests:  20%|█▉        | 1605/8192 [00:04<00:17, 376.27it/s]
Adding requests:  20%|██        | 1643/8192 [00:04<00:17, 369.86it/s]
Adding requests:  21%|██        | 1681/8192 [00:04<00:17, 368.97it/s]
Adding requests:  21%|██        | 1720/8192 [00:04<00:17, 372.52it/s]
Adding requests:  21%|██▏       | 1759/8192 [00:04<00:17, 376.08it/s]
Adding requests:  22%|██▏       | 1797/8192 [00:04<00:17, 370.51it/s]
Adding requests:  22%|██▏       | 1836/8192 [00:04<00:17, 372.88it/s]
Adding requests:  23%|██▎       | 1875/8192 [00:04<00:16, 377.25it/s]
Adding requests:  23%|██▎       | 1915/8192 [00:05<00:16, 383.55it/s]
Adding requests:  24%|██▍       | 1955/8192 [00:05<00:16, 388.08it/s]
Adding requests:  24%|██▍       | 1994/8192 [00:05<00:16, 382.56it/s]
Adding requests:  25%|██▍       | 2033/8192 [00:05<00:16, 375.61it/s]
Adding requests:  25%|██▌       | 2071/8192 [00:05<00:16, 369.88it/s]
Adding requests:  26%|██▌       | 2110/8192 [00:05<00:16, 375.24it/s]
Adding requests:  26%|██▌       | 2148/8192 [00:05<00:16, 376.40it/s]
Adding requests:  27%|██▋       | 2186/8192 [00:05<00:16, 367.98it/s]
Adding requests:  27%|██▋       | 2224/8192 [00:05<00:16, 369.45it/s]
Adding requests:  28%|██▊       | 2263/8192 [00:05<00:15, 373.19it/s]
Adding requests:  28%|██▊       | 2304/8192 [00:06<00:15, 382.50it/s]
Adding requests:  29%|██▊       | 2344/8192 [00:06<00:15, 386.41it/s]
Adding requests:  29%|██▉       | 2384/8192 [00:06<00:14, 389.37it/s]
Adding requests:  30%|██▉       | 2424/8192 [00:06<00:14, 389.22it/s]
Adding requests:  30%|███       | 2463/8192 [00:06<00:14, 385.08it/s]
Adding requests:  31%|███       | 2504/8192 [00:06<00:14, 389.42it/s]
Adding requests:  31%|███       | 2545/8192 [00:06<00:14, 394.01it/s]
Adding requests:  32%|███▏      | 2587/8192 [00:06<00:13, 400.84it/s]
Adding requests:  32%|███▏      | 2628/8192 [00:06<00:14, 394.57it/s]
Adding requests:  33%|███▎      | 2668/8192 [00:07<00:14, 385.28it/s]
Adding requests:  33%|███▎      | 2707/8192 [00:07<00:14, 382.62it/s]
Adding requests:  34%|███▎      | 2747/8192 [00:07<00:14, 384.97it/s]
Adding requests:  34%|███▍      | 2788/8192 [00:07<00:13, 389.90it/s]
Adding requests:  35%|███▍      | 2829/8192 [00:07<00:13, 394.12it/s]
Adding requests:  35%|███▌      | 2869/8192 [00:07<00:13, 391.08it/s]
Adding requests:  36%|███▌      | 2909/8192 [00:07<00:13, 389.61it/s]
Adding requests:  36%|███▌      | 2950/8192 [00:07<00:13, 394.90it/s]
Adding requests:  36%|███▋      | 2990/8192 [00:07<00:13, 392.90it/s]
Adding requests:  37%|███▋      | 3031/8192 [00:07<00:13, 396.72it/s]
Adding requests:  37%|███▋      | 3071/8192 [00:08<00:12, 396.35it/s]
Adding requests:  38%|███▊      | 3111/8192 [00:08<00:13, 388.03it/s]
Adding requests:  38%|███▊      | 3151/8192 [00:08<00:12, 389.69it/s]
Adding requests:  39%|███▉      | 3191/8192 [00:08<00:12, 387.08it/s]
Adding requests:  39%|███▉      | 3231/8192 [00:08<00:12, 390.01it/s]
Adding requests:  40%|███▉      | 3271/8192 [00:08<00:12, 384.87it/s]
Adding requests:  40%|████      | 3310/8192 [00:08<00:13, 372.68it/s]
Adding requests:  41%|████      | 3350/8192 [00:08<00:12, 378.92it/s]
Adding requests:  41%|████▏     | 3390/8192 [00:08<00:12, 382.94it/s]
Adding requests:  42%|████▏     | 3429/8192 [00:08<00:12, 383.73it/s]
Adding requests:  42%|████▏     | 3470/8192 [00:09<00:12, 388.72it/s]
Adding requests:  43%|████▎     | 3510/8192 [00:09<00:11, 391.41it/s]
Adding requests:  43%|████▎     | 3551/8192 [00:09<00:11, 395.92it/s]
Adding requests:  44%|████▍     | 3591/8192 [00:09<00:11, 393.09it/s]
Adding requests:  44%|████▍     | 3631/8192 [00:09<00:11, 394.89it/s]
Adding requests:  45%|████▍     | 3671/8192 [00:09<00:11, 387.21it/s]
Adding requests:  45%|████▌     | 3710/8192 [00:09<00:11, 384.62it/s]
Adding requests:  46%|████▌     | 3749/8192 [00:09<00:11, 380.97it/s]
Adding requests:  46%|████▌     | 3788/8192 [00:09<00:11, 370.57it/s]
Adding requests:  47%|████▋     | 3826/8192 [00:10<00:11, 365.99it/s]
Adding requests:  47%|████▋     | 3864/8192 [00:10<00:11, 369.98it/s]
Adding requests:  48%|████▊     | 3902/8192 [00:10<00:11, 368.82it/s]
Adding requests:  48%|████▊     | 3939/8192 [00:10<00:11, 367.16it/s]
Adding requests:  49%|████▊     | 3977/8192 [00:10<00:11, 368.59it/s]
Adding requests:  49%|████▉     | 4016/8192 [00:10<00:11, 371.65it/s]
Adding requests:  49%|████▉     | 4054/8192 [00:10<00:11, 368.57it/s]
Adding requests:  50%|████▉     | 4091/8192 [00:10<00:11, 368.60it/s]
Adding requests:  50%|█████     | 4130/8192 [00:10<00:10, 374.22it/s]
Adding requests:  51%|█████     | 4170/8192 [00:10<00:10, 380.78it/s]
Adding requests:  51%|█████▏    | 4209/8192 [00:11<00:10, 373.41it/s]
Adding requests:  52%|█████▏    | 4249/8192 [00:11<00:10, 378.51it/s]
Adding requests:  52%|█████▏    | 4287/8192 [00:11<00:10, 374.22it/s]
Adding requests:  53%|█████▎    | 4326/8192 [00:11<00:10, 377.14it/s]
Adding requests:  53%|█████▎    | 4366/8192 [00:11<00:10, 380.95it/s]
Adding requests:  54%|█████▍    | 4405/8192 [00:11<00:10, 377.30it/s]
Adding requests:  54%|█████▍    | 4445/8192 [00:11<00:09, 380.82it/s]
Adding requests:  55%|█████▍    | 4484/8192 [00:11<00:09, 373.30it/s]
Adding requests:  55%|█████▌    | 4523/8192 [00:11<00:09, 376.12it/s]
Adding requests:  56%|█████▌    | 4561/8192 [00:11<00:09, 376.57it/s]
Adding requests:  56%|█████▌    | 4600/8192 [00:12<00:09, 378.31it/s]
Adding requests:  57%|█████▋    | 4638/8192 [00:12<00:09, 378.13it/s]
Adding requests:  57%|█████▋    | 4676/8192 [00:12<00:09, 372.33it/s]
Adding requests:  58%|█████▊    | 4714/8192 [00:12<00:09, 370.67it/s]
Adding requests:  58%|█████▊    | 4755/8192 [00:12<00:09, 380.88it/s]
Adding requests:  59%|█████▊    | 4794/8192 [00:12<00:09, 374.68it/s]
Adding requests:  59%|█████▉    | 4832/8192 [00:12<00:08, 374.05it/s]
Adding requests:  59%|█████▉    | 4871/8192 [00:12<00:08, 375.72it/s]
Adding requests:  60%|█████▉    | 4909/8192 [00:12<00:08, 375.33it/s]
Adding requests:  60%|██████    | 4949/8192 [00:13<00:08, 382.03it/s]
Adding requests:  61%|██████    | 4988/8192 [00:13<00:08, 382.43it/s]
Adding requests:  61%|██████▏   | 5028/8192 [00:13<00:08, 385.99it/s]
Adding requests:  62%|██████▏   | 5067/8192 [00:13<00:08, 382.47it/s]
Adding requests:  62%|██████▏   | 5106/8192 [00:13<00:08, 382.64it/s]
Adding requests:  63%|██████▎   | 5145/8192 [00:13<00:07, 384.56it/s]
Adding requests:  63%|██████▎   | 5184/8192 [00:13<00:07, 379.72it/s]
Adding requests:  64%|██████▎   | 5222/8192 [00:13<00:07, 377.42it/s]
Adding requests:  64%|██████▍   | 5260/8192 [00:13<00:07, 373.91it/s]
Adding requests:  65%|██████▍   | 5299/8192 [00:13<00:07, 375.99it/s]
Adding requests:  65%|██████▌   | 5337/8192 [00:14<00:07, 375.45it/s]
Adding requests:  66%|██████▌   | 5376/8192 [00:14<00:07, 377.88it/s]
Adding requests:  66%|██████▌   | 5414/8192 [00:14<00:07, 368.70it/s]
Adding requests:  67%|██████▋   | 5454/8192 [00:14<00:07, 376.35it/s]
Adding requests:  67%|██████▋   | 5493/8192 [00:14<00:07, 379.44it/s]
Adding requests:  68%|██████▊   | 5531/8192 [00:14<00:07, 378.85it/s]
Adding requests:  68%|██████▊   | 5569/8192 [00:14<00:06, 377.25it/s]
Adding requests:  68%|██████▊   | 5607/8192 [00:14<00:06, 376.88it/s]
Adding requests:  69%|██████▉   | 5646/8192 [00:14<00:06, 379.68it/s]
Adding requests:  69%|██████▉   | 5684/8192 [00:14<00:06, 378.98it/s]
Adding requests:  70%|██████▉   | 5723/8192 [00:15<00:06, 379.35it/s]
Adding requests:  70%|███████   | 5762/8192 [00:15<00:06, 379.74it/s]
Adding requests:  71%|███████   | 5802/8192 [00:15<00:06, 383.94it/s]
Adding requests:  71%|███████▏  | 5841/8192 [00:15<00:06, 381.15it/s]
Adding requests:  72%|███████▏  | 5880/8192 [00:15<00:06, 372.77it/s]
Adding requests:  72%|███████▏  | 5920/8192 [00:15<00:06, 378.57it/s]
Adding requests:  73%|███████▎  | 5960/8192 [00:15<00:05, 383.21it/s]
Adding requests:  73%|███████▎  | 6000/8192 [00:15<00:05, 384.83it/s]
Adding requests:  74%|███████▎  | 6039/8192 [00:15<00:05, 383.44it/s]
Adding requests:  74%|███████▍  | 6078/8192 [00:15<00:05, 382.05it/s]
Adding requests:  75%|███████▍  | 6117/8192 [00:16<00:05, 380.14it/s]
Adding requests:  75%|███████▌  | 6158/8192 [00:16<00:05, 386.41it/s]
Adding requests:  76%|███████▌  | 6197/8192 [00:16<00:05, 379.28it/s]
Adding requests:  76%|███████▌  | 6236/8192 [00:16<00:05, 379.95it/s]
Adding requests:  77%|███████▋  | 6275/8192 [00:16<00:05, 382.10it/s]
Adding requests:  77%|███████▋  | 6315/8192 [00:16<00:04, 384.74it/s]
Adding requests:  78%|███████▊  | 6356/8192 [00:16<00:04, 390.28it/s]
Adding requests:  78%|███████▊  | 6396/8192 [00:16<00:04, 385.33it/s]
Adding requests:  79%|███████▊  | 6435/8192 [00:16<00:04, 374.52it/s]
Adding requests:  79%|███████▉  | 6473/8192 [00:17<00:04, 374.12it/s]
Adding requests:  79%|███████▉  | 6512/8192 [00:17<00:04, 377.46it/s]
Adding requests:  80%|███████▉  | 6550/8192 [00:17<00:04, 377.31it/s]
Adding requests:  80%|████████  | 6588/8192 [00:17<00:04, 375.60it/s]
Adding requests:  81%|████████  | 6627/8192 [00:17<00:04, 379.57it/s]
Adding requests:  81%|████████▏ | 6666/8192 [00:17<00:04, 381.42it/s]
Adding requests:  82%|████████▏ | 6705/8192 [00:17<00:03, 378.69it/s]
Adding requests:  82%|████████▏ | 6745/8192 [00:17<00:03, 384.46it/s]
Adding requests:  83%|████████▎ | 6784/8192 [00:17<00:03, 385.35it/s]
Adding requests:  83%|████████▎ | 6823/8192 [00:17<00:03, 375.28it/s]
Adding requests:  84%|████████▍ | 6862/8192 [00:18<00:03, 378.91it/s]
Adding requests:  84%|████████▍ | 6901/8192 [00:18<00:03, 378.82it/s]
Adding requests:  85%|████████▍ | 6941/8192 [00:18<00:03, 384.27it/s]
Adding requests:  85%|████████▌ | 6980/8192 [00:18<00:03, 380.03it/s]
Adding requests:  86%|████████▌ | 7020/8192 [00:18<00:03, 385.27it/s]
Adding requests:  86%|████████▌ | 7059/8192 [00:18<00:02, 380.96it/s]
Adding requests:  87%|████████▋ | 7098/8192 [00:18<00:02, 376.24it/s]
Adding requests:  87%|████████▋ | 7137/8192 [00:18<00:02, 379.05it/s]
Adding requests:  88%|████████▊ | 7177/8192 [00:18<00:02, 383.89it/s]
Adding requests:  88%|████████▊ | 7216/8192 [00:18<00:02, 376.95it/s]
Adding requests:  89%|████████▊ | 7255/8192 [00:19<00:02, 379.83it/s]
Adding requests:  89%|████████▉ | 7295/8192 [00:19<00:02, 385.40it/s]
Adding requests:  90%|████████▉ | 7334/8192 [00:19<00:02, 380.55it/s]
Adding requests:  90%|█████████ | 7374/8192 [00:19<00:02, 384.18it/s]
Adding requests:  90%|█████████ | 7413/8192 [00:19<00:02, 383.21it/s]
Adding requests:  91%|█████████ | 7452/8192 [00:19<00:01, 380.48it/s]
Adding requests:  91%|█████████▏| 7491/8192 [00:19<00:01, 377.81it/s]
Adding requests:  92%|█████████▏| 7530/8192 [00:19<00:01, 380.72it/s]
Adding requests:  92%|█████████▏| 7569/8192 [00:19<00:01, 381.22it/s]
Adding requests:  93%|█████████▎| 7608/8192 [00:20<00:01, 378.51it/s]
Adding requests:  93%|█████████▎| 7648/8192 [00:20<00:01, 382.65it/s]
Adding requests:  94%|█████████▍| 7690/8192 [00:20<00:01, 392.65it/s]
Adding requests:  94%|█████████▍| 7730/8192 [00:20<00:01, 389.54it/s]
Adding requests:  95%|█████████▍| 7769/8192 [00:20<00:01, 384.53it/s]
Adding requests:  95%|█████████▌| 7808/8192 [00:20<00:00, 384.05it/s]
Adding requests:  96%|█████████▌| 7847/8192 [00:20<00:00, 377.33it/s]
Adding requests:  96%|█████████▋| 7885/8192 [00:20<00:00, 378.07it/s]
Adding requests:  97%|█████████▋| 7926/8192 [00:20<00:00, 387.43it/s]
Adding requests:  97%|█████████▋| 7966/8192 [00:20<00:00, 390.05it/s]
Adding requests:  98%|█████████▊| 8006/8192 [00:21<00:00, 391.60it/s]
Adding requests:  98%|█████████▊| 8046/8192 [00:21<00:00, 386.58it/s]
Adding requests:  99%|█████████▊| 8088/8192 [00:21<00:00, 393.36it/s]
Adding requests:  99%|█████████▉| 8128/8192 [00:21<00:00, 382.57it/s]
Adding requests: 100%|█████████▉| 8167/8192 [00:21<00:00, 382.18it/s]
Adding requests: 100%|██████████| 8192/8192 [00:21<00:00, 380.64it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 479/8192 [00:02<00:45, 169.83it/s, est. speed input: 173902.82 toks/s, output: 169.83 toks/s]
Processed prompts:   7%|▋         | 543/8192 [00:05<01:32, 82.26it/s, est. speed input: 97543.92 toks/s, output: 95.26 toks/s]   
Processed prompts:   7%|▋         | 607/8192 [00:08<02:18, 54.73it/s, est. speed input: 72451.02 toks/s, output: 70.75 toks/s]
Processed prompts:   8%|▊         | 671/8192 [00:11<02:59, 41.84it/s, est. speed input: 59948.13 toks/s, output: 58.54 toks/s]
Processed prompts:   9%|▉         | 735/8192 [00:14<03:33, 34.93it/s, est. speed input: 52622.46 toks/s, output: 51.39 toks/s]
Processed prompts:  10%|▉         | 799/8192 [00:17<04:01, 30.59it/s, est. speed input: 47617.04 toks/s, output: 46.50 toks/s]
Processed prompts:  11%|█         | 863/8192 [00:20<04:23, 27.85it/s, est. speed input: 44048.42 toks/s, output: 43.02 toks/s]
Processed prompts:  11%|█▏        | 927/8192 [00:22<04:38, 26.05it/s, est. speed input: 41375.71 toks/s, output: 40.41 toks/s]
Processed prompts:  12%|█▏        | 991/8192 [00:25<04:49, 24.85it/s, est. speed input: 39296.56 toks/s, output: 38.38 toks/s]
Processed prompts:  13%|█▎        | 1055/8192 [00:28<04:56, 24.03it/s, est. speed input: 37635.62 toks/s, output: 36.75 toks/s]
Processed prompts:  14%|█▎        | 1119/8192 [00:31<05:01, 23.49it/s, est. speed input: 36282.63 toks/s, output: 35.43 toks/s]
Processed prompts:  14%|█▍        | 1183/8192 [00:34<05:03, 23.10it/s, est. speed input: 35151.72 toks/s, output: 34.33 toks/s]
Processed prompts:  15%|█▌        | 1247/8192 [00:37<05:04, 22.83it/s, est. speed input: 34195.46 toks/s, output: 33.39 toks/s]
Processed prompts:  16%|█▌        | 1311/8192 [00:40<05:03, 22.65it/s, est. speed input: 33375.56 toks/s, output: 32.59 toks/s]
Processed prompts:  17%|█▋        | 1375/8192 [00:43<05:02, 22.52it/s, est. speed input: 32664.99 toks/s, output: 31.90 toks/s]
Processed prompts:  18%|█▊        | 1439/8192 [00:45<05:01, 22.43it/s, est. speed input: 32044.53 toks/s, output: 31.29 toks/s]
Processed prompts:  18%|█▊        | 1503/8192 [00:48<04:59, 22.37it/s, est. speed input: 31496.84 toks/s, output: 30.76 toks/s]
Processed prompts:  19%|█▉        | 1567/8192 [00:51<04:56, 22.37it/s, est. speed input: 31021.87 toks/s, output: 30.29 toks/s]
Processed prompts:  20%|█▉        | 1631/8192 [00:54<04:53, 22.33it/s, est. speed input: 30586.78 toks/s, output: 29.87 toks/s]
Processed prompts:  21%|██        | 1695/8192 [00:57<04:51, 22.30it/s, est. speed input: 30194.26 toks/s, output: 29.49 toks/s]
Processed prompts:  21%|██▏       | 1759/8192 [01:00<04:48, 22.27it/s, est. speed input: 29839.04 toks/s, output: 29.14 toks/s]
Processed prompts:  22%|██▏       | 1823/8192 [01:03<04:46, 22.26it/s, est. speed input: 29517.24 toks/s, output: 28.83 toks/s]
Processed prompts:  23%|██▎       | 1887/8192 [01:06<04:43, 22.25it/s, est. speed input: 29222.44 toks/s, output: 28.54 toks/s]
Processed prompts:  24%|██▍       | 1951/8192 [01:09<04:40, 22.23it/s, est. speed input: 28951.59 toks/s, output: 28.27 toks/s]
Processed prompts:  25%|██▍       | 2015/8192 [01:11<04:37, 22.23it/s, est. speed input: 28703.97 toks/s, output: 28.03 toks/s]
Processed prompts:  25%|██▌       | 2079/8192 [01:14<04:35, 22.23it/s, est. speed input: 28474.38 toks/s, output: 27.81 toks/s]
Processed prompts:  26%|██▌       | 2143/8192 [01:17<04:32, 22.24it/s, est. speed input: 28264.02 toks/s, output: 27.60 toks/s]
Processed prompts:  27%|██▋       | 2207/8192 [01:20<04:29, 22.22it/s, est. speed input: 28065.44 toks/s, output: 27.41 toks/s]
Processed prompts:  28%|██▊       | 2271/8192 [01:23<04:26, 22.20it/s, est. speed input: 27878.69 toks/s, output: 27.23 toks/s]
Processed prompts:  29%|██▊       | 2335/8192 [01:26<04:24, 22.18it/s, est. speed input: 27704.61 toks/s, output: 27.06 toks/s]
Processed prompts:  29%|██▉       | 2399/8192 [01:29<04:21, 22.15it/s, est. speed input: 27538.35 toks/s, output: 26.89 toks/s]
Processed prompts:  30%|███       | 2463/8192 [01:32<04:18, 22.12it/s, est. speed input: 27382.76 toks/s, output: 26.74 toks/s]
Processed prompts:  31%|███       | 2527/8192 [01:35<04:16, 22.11it/s, est. speed input: 27236.92 toks/s, output: 26.60 toks/s]
Processed prompts:  32%|███▏      | 2591/8192 [01:37<04:13, 22.10it/s, est. speed input: 27099.84 toks/s, output: 26.46 toks/s]
Processed prompts:  32%|███▏      | 2655/8192 [01:40<04:10, 22.09it/s, est. speed input: 26970.03 toks/s, output: 26.34 toks/s]
Processed prompts:  33%|███▎      | 2719/8192 [01:43<04:07, 22.08it/s, est. speed input: 26847.80 toks/s, output: 26.22 toks/s]
Processed prompts:  34%|███▍      | 2783/8192 [01:46<04:04, 22.08it/s, est. speed input: 26732.34 toks/s, output: 26.11 toks/s]
Processed prompts:  35%|███▍      | 2847/8192 [01:49<04:02, 22.07it/s, est. speed input: 26621.93 toks/s, output: 26.00 toks/s]
Processed prompts:  36%|███▌      | 2911/8192 [01:52<03:58, 22.13it/s, est. speed input: 26524.05 toks/s, output: 25.90 toks/s]
Processed prompts:  36%|███▋      | 2975/8192 [01:55<03:55, 22.15it/s, est. speed input: 26429.24 toks/s, output: 25.81 toks/s]
Processed prompts:  37%|███▋      | 3039/8192 [01:58<03:52, 22.17it/s, est. speed input: 26339.62 toks/s, output: 25.72 toks/s]
Processed prompts:  38%|███▊      | 3103/8192 [02:01<03:49, 22.14it/s, est. speed input: 26250.01 toks/s, output: 25.63 toks/s]
Processed prompts:  39%|███▊      | 3167/8192 [02:03<03:47, 22.12it/s, est. speed input: 26164.98 toks/s, output: 25.55 toks/s]
Processed prompts:  39%|███▉      | 3231/8192 [02:06<03:44, 22.11it/s, est. speed input: 26083.52 toks/s, output: 25.47 toks/s]
Processed prompts:  40%|████      | 3295/8192 [02:09<03:41, 22.11it/s, est. speed input: 26007.24 toks/s, output: 25.40 toks/s]
Processed prompts:  41%|████      | 3359/8192 [02:12<03:38, 22.12it/s, est. speed input: 25934.61 toks/s, output: 25.33 toks/s]
Processed prompts:  42%|████▏     | 3423/8192 [02:15<03:35, 22.11it/s, est. speed input: 25863.23 toks/s, output: 25.26 toks/s]
Processed prompts:  43%|████▎     | 3487/8192 [02:18<03:32, 22.10it/s, est. speed input: 25794.91 toks/s, output: 25.19 toks/s]
Processed prompts:  43%|████▎     | 3551/8192 [02:21<03:30, 22.09it/s, est. speed input: 25729.62 toks/s, output: 25.13 toks/s]
Processed prompts:  44%|████▍     | 3615/8192 [02:24<03:27, 22.09it/s, est. speed input: 25666.70 toks/s, output: 25.07 toks/s]
Processed prompts:  45%|████▍     | 3679/8192 [02:27<03:23, 22.13it/s, est. speed input: 25609.89 toks/s, output: 25.01 toks/s]
Processed prompts:  46%|████▌     | 3743/8192 [02:29<03:20, 22.15it/s, est. speed input: 25554.40 toks/s, output: 24.96 toks/s]
Processed prompts:  46%|████▋     | 3807/8192 [02:32<03:18, 22.13it/s, est. speed input: 25498.64 toks/s, output: 24.90 toks/s]
Processed prompts:  47%|████▋     | 3871/8192 [02:35<03:15, 22.16it/s, est. speed input: 25448.01 toks/s, output: 24.85 toks/s]
Processed prompts:  48%|████▊     | 3935/8192 [02:38<03:12, 22.13it/s, est. speed input: 25395.89 toks/s, output: 24.80 toks/s]
Processed prompts:  49%|████▉     | 3999/8192 [02:41<03:09, 22.11it/s, est. speed input: 25345.41 toks/s, output: 24.75 toks/s]
Processed prompts:  50%|████▉     | 4063/8192 [02:44<03:06, 22.15it/s, est. speed input: 25300.66 toks/s, output: 24.71 toks/s]
Processed prompts:  50%|█████     | 4127/8192 [02:47<03:03, 22.13it/s, est. speed input: 25253.86 toks/s, output: 24.66 toks/s]
Processed prompts:  51%|█████     | 4191/8192 [02:50<03:01, 22.10it/s, est. speed input: 25208.28 toks/s, output: 24.62 toks/s]
Processed prompts:  52%|█████▏    | 4255/8192 [02:53<02:58, 22.12it/s, est. speed input: 25166.01 toks/s, output: 24.58 toks/s]
Processed prompts:  53%|█████▎    | 4319/8192 [02:56<02:55, 22.12it/s, est. speed input: 25125.04 toks/s, output: 24.54 toks/s]
Processed prompts:  54%|█████▎    | 4383/8192 [02:58<02:52, 22.10it/s, est. speed input: 25083.92 toks/s, output: 24.50 toks/s]
Processed prompts:  54%|█████▍    | 4447/8192 [03:01<02:49, 22.09it/s, est. speed input: 25044.17 toks/s, output: 24.46 toks/s]
Processed prompts:  55%|█████▌    | 4511/8192 [03:04<02:46, 22.09it/s, est. speed input: 25005.86 toks/s, output: 24.42 toks/s]
Processed prompts:  56%|█████▌    | 4575/8192 [03:07<02:43, 22.08it/s, est. speed input: 24968.73 toks/s, output: 24.38 toks/s]
Processed prompts:  57%|█████▋    | 4639/8192 [03:10<02:40, 22.08it/s, est. speed input: 24932.62 toks/s, output: 24.35 toks/s]
Processed prompts:  57%|█████▋    | 4703/8192 [03:13<02:38, 22.07it/s, est. speed input: 24897.55 toks/s, output: 24.31 toks/s]
Processed prompts:  58%|█████▊    | 4767/8192 [03:16<02:35, 22.07it/s, est. speed input: 24863.42 toks/s, output: 24.28 toks/s]
Processed prompts:  59%|█████▉    | 4831/8192 [03:19<02:32, 22.07it/s, est. speed input: 24830.61 toks/s, output: 24.25 toks/s]
Processed prompts:  60%|█████▉    | 4895/8192 [03:22<02:29, 22.07it/s, est. speed input: 24798.75 toks/s, output: 24.22 toks/s]
Processed prompts:  61%|██████    | 4959/8192 [03:25<02:26, 22.13it/s, est. speed input: 24770.41 toks/s, output: 24.19 toks/s]
Processed prompts:  61%|██████▏   | 5023/8192 [03:27<02:23, 22.15it/s, est. speed input: 24742.07 toks/s, output: 24.16 toks/s]
Processed prompts:  62%|██████▏   | 5087/8192 [03:30<02:20, 22.12it/s, est. speed input: 24712.58 toks/s, output: 24.13 toks/s]
Processed prompts:  63%|██████▎   | 5151/8192 [03:33<02:17, 22.11it/s, est. speed input: 24684.04 toks/s, output: 24.11 toks/s]
Processed prompts:  64%|██████▎   | 5215/8192 [03:36<02:14, 22.10it/s, est. speed input: 24656.02 toks/s, output: 24.08 toks/s]
Processed prompts:  64%|██████▍   | 5279/8192 [03:39<02:11, 22.09it/s, est. speed input: 24628.87 toks/s, output: 24.05 toks/s]
Processed prompts:  65%|██████▌   | 5343/8192 [03:42<02:09, 22.08it/s, est. speed input: 24602.34 toks/s, output: 24.03 toks/s]
Processed prompts:  66%|██████▌   | 5407/8192 [03:45<02:06, 22.08it/s, est. speed input: 24576.55 toks/s, output: 24.00 toks/s]
Processed prompts:  67%|██████▋   | 5471/8192 [03:48<02:03, 22.07it/s, est. speed input: 24551.25 toks/s, output: 23.98 toks/s]
Processed prompts:  68%|██████▊   | 5535/8192 [03:51<02:00, 22.07it/s, est. speed input: 24526.87 toks/s, output: 23.95 toks/s]
Processed prompts:  68%|██████▊   | 5599/8192 [03:53<01:57, 22.07it/s, est. speed input: 24502.95 toks/s, output: 23.93 toks/s]
Processed prompts:  69%|██████▉   | 5663/8192 [03:56<01:54, 22.07it/s, est. speed input: 24479.72 toks/s, output: 23.91 toks/s]
Processed prompts:  70%|██████▉   | 5727/8192 [03:59<01:51, 22.07it/s, est. speed input: 24456.84 toks/s, output: 23.88 toks/s]
Processed prompts:  71%|███████   | 5791/8192 [04:02<01:48, 22.07it/s, est. speed input: 24434.73 toks/s, output: 23.86 toks/s]
Processed prompts:  71%|███████▏  | 5855/8192 [04:05<01:45, 22.07it/s, est. speed input: 24413.07 toks/s, output: 23.84 toks/s]
Processed prompts:  72%|███████▏  | 5919/8192 [04:08<01:42, 22.12it/s, est. speed input: 24394.06 toks/s, output: 23.82 toks/s]
Processed prompts:  73%|███████▎  | 5983/8192 [04:11<01:39, 22.15it/s, est. speed input: 24375.17 toks/s, output: 23.80 toks/s]
Processed prompts:  74%|███████▍  | 6047/8192 [04:14<01:36, 22.12it/s, est. speed input: 24354.83 toks/s, output: 23.78 toks/s]
Processed prompts:  75%|███████▍  | 6111/8192 [04:17<01:34, 22.10it/s, est. speed input: 24334.95 toks/s, output: 23.76 toks/s]
Processed prompts:  75%|███████▌  | 6175/8192 [04:20<01:31, 22.09it/s, est. speed input: 24315.51 toks/s, output: 23.75 toks/s]
Processed prompts:  76%|███████▌  | 6239/8192 [04:22<01:28, 22.08it/s, est. speed input: 24296.51 toks/s, output: 23.73 toks/s]
Processed prompts:  77%|███████▋  | 6303/8192 [04:25<01:25, 22.08it/s, est. speed input: 24278.06 toks/s, output: 23.71 toks/s]
Processed prompts:  78%|███████▊  | 6367/8192 [04:28<01:22, 22.08it/s, est. speed input: 24259.96 toks/s, output: 23.69 toks/s]
Processed prompts:  79%|███████▊  | 6431/8192 [04:31<01:19, 22.08it/s, est. speed input: 24242.34 toks/s, output: 23.67 toks/s]
Processed prompts:  79%|███████▉  | 6495/8192 [04:34<01:16, 22.07it/s, est. speed input: 24224.94 toks/s, output: 23.66 toks/s]
Processed prompts:  80%|████████  | 6559/8192 [04:37<01:13, 22.07it/s, est. speed input: 24207.93 toks/s, output: 23.64 toks/s]
Processed prompts:  81%|████████  | 6623/8192 [04:40<01:11, 22.07it/s, est. speed input: 24191.29 toks/s, output: 23.62 toks/s]
Processed prompts:  82%|████████▏ | 6687/8192 [04:43<01:08, 22.07it/s, est. speed input: 24175.06 toks/s, output: 23.61 toks/s]
Processed prompts:  82%|████████▏ | 6751/8192 [04:46<01:05, 22.07it/s, est. speed input: 24158.91 toks/s, output: 23.59 toks/s]
Processed prompts:  83%|████████▎ | 6815/8192 [04:49<01:02, 22.07it/s, est. speed input: 24143.27 toks/s, output: 23.58 toks/s]
Processed prompts:  84%|████████▍ | 6879/8192 [04:51<00:59, 22.07it/s, est. speed input: 24128.03 toks/s, output: 23.56 toks/s]
Processed prompts:  85%|████████▍ | 6943/8192 [04:54<00:56, 22.07it/s, est. speed input: 24112.96 toks/s, output: 23.55 toks/s]
Processed prompts:  86%|████████▌ | 7007/8192 [04:57<00:53, 22.07it/s, est. speed input: 24098.30 toks/s, output: 23.53 toks/s]
Processed prompts:  86%|████████▋ | 7071/8192 [05:00<00:50, 22.06it/s, est. speed input: 24083.58 toks/s, output: 23.52 toks/s]
Processed prompts:  87%|████████▋ | 7135/8192 [05:03<00:47, 22.07it/s, est. speed input: 24069.51 toks/s, output: 23.51 toks/s]
Processed prompts:  88%|████████▊ | 7199/8192 [05:06<00:44, 22.07it/s, est. speed input: 24055.68 toks/s, output: 23.49 toks/s]
Processed prompts:  89%|████████▊ | 7263/8192 [05:09<00:42, 22.07it/s, est. speed input: 24041.96 toks/s, output: 23.48 toks/s]
Processed prompts:  89%|████████▉ | 7327/8192 [05:12<00:39, 22.07it/s, est. speed input: 24028.60 toks/s, output: 23.47 toks/s]
Processed prompts:  90%|█████████ | 7391/8192 [05:15<00:36, 22.07it/s, est. speed input: 24015.33 toks/s, output: 23.45 toks/s]
Processed prompts:  91%|█████████ | 7455/8192 [05:18<00:33, 22.07it/s, est. speed input: 24002.42 toks/s, output: 23.44 toks/s]
Processed prompts:  92%|█████████▏| 7519/8192 [05:20<00:30, 22.07it/s, est. speed input: 23989.86 toks/s, output: 23.43 toks/s]
Processed prompts:  93%|█████████▎| 7583/8192 [05:23<00:27, 22.07it/s, est. speed input: 23977.41 toks/s, output: 23.42 toks/s]
Processed prompts:  93%|█████████▎| 7647/8192 [05:26<00:24, 22.07it/s, est. speed input: 23965.07 toks/s, output: 23.40 toks/s]
Processed prompts:  94%|█████████▍| 7711/8192 [05:29<00:21, 22.07it/s, est. speed input: 23953.03 toks/s, output: 23.39 toks/s]
Processed prompts:  95%|█████████▍| 7775/8192 [05:32<00:18, 22.07it/s, est. speed input: 23941.32 toks/s, output: 23.38 toks/s]
Processed prompts:  96%|█████████▌| 7839/8192 [05:35<00:15, 22.07it/s, est. speed input: 23929.74 toks/s, output: 23.37 toks/s]
Processed prompts:  96%|█████████▋| 7903/8192 [05:38<00:13, 22.07it/s, est. speed input: 23918.33 toks/s, output: 23.36 toks/s]
Processed prompts:  97%|█████████▋| 7967/8192 [05:41<00:10, 22.07it/s, est. speed input: 23907.09 toks/s, output: 23.35 toks/s]
Processed prompts:  98%|█████████▊| 8031/8192 [05:44<00:07, 22.07it/s, est. speed input: 23895.98 toks/s, output: 23.34 toks/s]
Processed prompts:  99%|█████████▉| 8095/8192 [05:47<00:04, 22.07it/s, est. speed input: 23885.28 toks/s, output: 23.33 toks/s]
Processed prompts: 100%|█████████▉| 8159/8192 [05:48<00:01, 25.65it/s, est. speed input: 23966.95 toks/s, output: 23.41 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [05:48<00:00, 25.65it/s, est. speed input: 24063.85 toks/s, output: 23.50 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [05:48<00:00, 23.50it/s, est. speed input: 24063.85 toks/s, output: 23.50 toks/s]
[rank0]:[W126 15:15:32.134517480 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 09:09:58
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:10:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3361619) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3361619) WARNING 01-28 09:10:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.15 requests/s, 16491.61 total tokens/s, 32.15 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 09:10:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:10:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:10:05] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:10:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:10:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:10:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:10:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:10:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:10:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:10:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:10:11] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:10:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:10:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:10:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:10:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:10:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3361619) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3361619) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=3361619) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=3361619) 
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3361619) [2026-01-28 09:10:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3361619) 2026-01-28 09:10:30,878 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3361619) 2026-01-28 09:10:30,906 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3361619) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  4.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.88it/s]
(EngineCore_DP0 pid=3361619) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 15.14it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 475.61it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 676.74it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:24,  5.26it/s, est. speed input: 2695.32 toks/s, output: 5.26 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:06, 19.16it/s, est. speed input: 8468.13 toks/s, output: 16.54 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 25.77it/s, est. speed input: 11145.82 toks/s, output: 21.77 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 29.46it/s, est. speed input: 12692.42 toks/s, output: 24.79 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 31.64it/s, est. speed input: 13686.10 toks/s, output: 26.73 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.03it/s, est. speed input: 14386.63 toks/s, output: 28.10 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 33.99it/s, est. speed input: 14912.05 toks/s, output: 29.12 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 34.61it/s, est. speed input: 15315.26 toks/s, output: 29.91 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 34.79it/s, est. speed input: 15597.70 toks/s, output: 30.46 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 34.86it/s, est. speed input: 15819.65 toks/s, output: 30.90 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 34.90it/s, est. speed input: 16003.28 toks/s, output: 31.26 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 34.97it/s, est. speed input: 16161.56 toks/s, output: 31.56 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 34.95it/s, est. speed input: 16288.43 toks/s, output: 31.81 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 34.94it/s, est. speed input: 16398.94 toks/s, output: 32.03 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 35.01it/s, est. speed input: 16502.53 toks/s, output: 32.23 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 34.98it/s, est. speed input: 16585.78 toks/s, output: 32.39 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 34.92it/s, est. speed input: 16656.26 toks/s, output: 32.53 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 34.96it/s, est. speed input: 16725.81 toks/s, output: 32.67 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 34.97it/s, est. speed input: 16786.96 toks/s, output: 32.79 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 35.01it/s, est. speed input: 16844.79 toks/s, output: 32.90 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 34.76it/s, est. speed input: 16875.90 toks/s, output: 32.96 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 34.80it/s, est. speed input: 16920.26 toks/s, output: 33.05 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 34.84it/s, est. speed input: 16961.60 toks/s, output: 33.13 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 34.85it/s, est. speed input: 16998.42 toks/s, output: 33.20 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 34.84it/s, est. speed input: 17030.56 toks/s, output: 33.26 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 34.84it/s, est. speed input: 17061.30 toks/s, output: 33.32 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 34.63it/s, est. speed input: 17076.89 toks/s, output: 33.35 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 34.96it/s, est. speed input: 17118.95 toks/s, output: 33.44 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 35.18it/s, est. speed input: 17157.51 toks/s, output: 33.51 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 35.36it/s, est. speed input: 17195.23 toks/s, output: 33.58 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 35.51it/s, est. speed input: 17231.39 toks/s, output: 33.65 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 35.62it/s, est. speed input: 17265.48 toks/s, output: 33.72 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.62it/s, est. speed input: 17288.83 toks/s, output: 33.77 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.76it/s, est. speed input: 17288.83 toks/s, output: 33.77 toks/s]
[rank0]:[W128 09:10:37.444354669 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 09:10:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:10:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3362799) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3362799) WARNING 01-28 09:11:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.17 requests/s, 32973.46 total tokens/s, 32.17 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 09:10:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:10:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:10:46] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:10:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:10:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:10:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:10:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:10:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:10:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:10:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:10:53] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:10:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:10:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:10:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:10:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:10:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:10:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3362799) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3362799) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.37it/s]
(EngineCore_DP0 pid=3362799) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.36it/s]
(EngineCore_DP0 pid=3362799) 
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3362799) [2026-01-28 09:10:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3362799) 2026-01-28 09:11:13,639 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3362799) 2026-01-28 09:11:13,667 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3362799) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.49it/s]
(EngineCore_DP0 pid=3362799) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.63it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  21%|██        | 27/128 [00:00<00:00, 265.72it/s]
Adding requests:  62%|██████▏   | 79/128 [00:00<00:00, 411.17it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 423.35it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 49.31it/s, est. speed input: 50506.09 toks/s, output: 49.32 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:02, 39.52it/s, est. speed input: 41721.56 toks/s, output: 40.74 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 37.20it/s, est. speed input: 39463.28 toks/s, output: 38.54 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:02, 36.39it/s, est. speed input: 38619.05 toks/s, output: 37.71 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:02, 35.82it/s, est. speed input: 38051.00 toks/s, output: 37.16 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 35.38it/s, est. speed input: 37613.48 toks/s, output: 36.73 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 35.01it/s, est. speed input: 37263.10 toks/s, output: 36.39 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:00<00:02, 34.81it/s, est. speed input: 37015.72 toks/s, output: 36.15 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 34.74it/s, est. speed input: 36842.61 toks/s, output: 35.98 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 34.63it/s, est. speed input: 36685.44 toks/s, output: 35.82 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 34.55it/s, est. speed input: 36554.05 toks/s, output: 35.70 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:02, 34.46it/s, est. speed input: 36433.79 toks/s, output: 35.58 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:02, 34.42it/s, est. speed input: 36337.51 toks/s, output: 35.49 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:02, 34.43it/s, est. speed input: 36264.11 toks/s, output: 35.41 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 34.39it/s, est. speed input: 36187.79 toks/s, output: 35.34 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 34.41it/s, est. speed input: 36132.88 toks/s, output: 35.29 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:01, 34.41it/s, est. speed input: 36080.28 toks/s, output: 35.23 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 34.39it/s, est. speed input: 36031.57 toks/s, output: 35.19 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 34.37it/s, est. speed input: 35984.38 toks/s, output: 35.14 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 34.33it/s, est. speed input: 35939.68 toks/s, output: 35.10 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 34.35it/s, est. speed input: 35905.55 toks/s, output: 35.06 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:01, 34.35it/s, est. speed input: 35872.26 toks/s, output: 35.03 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:00, 34.35it/s, est. speed input: 35842.28 toks/s, output: 35.00 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 34.31it/s, est. speed input: 35810.23 toks/s, output: 34.97 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:02<00:00, 34.32it/s, est. speed input: 35784.86 toks/s, output: 34.95 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:03<00:00, 34.27it/s, est. speed input: 35753.19 toks/s, output: 34.91 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:03<00:00, 34.35it/s, est. speed input: 35739.48 toks/s, output: 34.90 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 34.35it/s, est. speed input: 35719.18 toks/s, output: 34.88 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 34.37it/s, est. speed input: 35702.66 toks/s, output: 34.87 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 34.41it/s, est. speed input: 35690.79 toks/s, output: 34.85 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 34.36it/s, est. speed input: 35670.92 toks/s, output: 34.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.36it/s, est. speed input: 35666.44 toks/s, output: 34.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.83it/s, est. speed input: 35666.44 toks/s, output: 34.83 toks/s]
[rank0]:[W128 09:11:19.872174786 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 09:11:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:11:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3363883) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3363883) WARNING 01-28 09:11:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 63.48 requests/s, 65063.41 total tokens/s, 63.48 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 09:11:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:11:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:11:29] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:11:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:11:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:11:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:11:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:11:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:11:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:11:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:11:36] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:11:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:11:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:11:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:11:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:11:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3363883) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3363883) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.34it/s]
(EngineCore_DP0 pid=3363883) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.34it/s]
(EngineCore_DP0 pid=3363883) 
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3363883) [2026-01-28 09:11:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3363883) 2026-01-28 09:11:55,864 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3363883) 2026-01-28 09:11:55,891 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3363883) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 13.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 13.07it/s]
(EngineCore_DP0 pid=3363883) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 16.60it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 16.58it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 50/256 [00:00<00:00, 496.76it/s]
Adding requests:  39%|███▉      | 101/256 [00:00<00:00, 500.49it/s]
Adding requests:  59%|█████▉    | 152/256 [00:00<00:00, 500.47it/s]
Adding requests:  79%|███████▉  | 203/256 [00:00<00:00, 494.64it/s]
Adding requests: 100%|█████████▉| 255/256 [00:00<00:00, 501.90it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 500.01it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 225.54it/s, est. speed input: 230996.05 toks/s, output: 225.55 toks/s]
Processed prompts:  18%|█▊        | 47/256 [00:00<00:02, 102.08it/s, est. speed input: 114098.85 toks/s, output: 111.42 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:00<00:02, 88.38it/s, est. speed input: 100338.52 toks/s, output: 97.98 toks/s]  
Processed prompts:  28%|██▊       | 72/256 [00:00<00:02, 79.55it/s, est. speed input: 92443.66 toks/s, output: 90.27 toks/s] 
Processed prompts:  32%|███▏      | 81/256 [00:00<00:02, 78.65it/s, est. speed input: 90543.23 toks/s, output: 88.42 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:01<00:02, 73.09it/s, est. speed input: 86583.04 toks/s, output: 84.55 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:01<00:02, 71.70it/s, est. speed input: 84863.10 toks/s, output: 82.87 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:01<00:02, 70.64it/s, est. speed input: 83460.43 toks/s, output: 81.50 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:01<00:02, 69.87it/s, est. speed input: 82301.00 toks/s, output: 80.37 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:01<00:01, 69.37it/s, est. speed input: 81340.42 toks/s, output: 79.43 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:01<00:01, 68.87it/s, est. speed input: 80477.51 toks/s, output: 78.59 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:01<00:01, 68.38it/s, est. speed input: 79697.00 toks/s, output: 77.83 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:01<00:01, 68.23it/s, est. speed input: 79060.04 toks/s, output: 77.21 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:02<00:01, 67.97it/s, est. speed input: 78463.79 toks/s, output: 76.62 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:02<00:01, 67.80it/s, est. speed input: 77937.10 toks/s, output: 76.11 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:02<00:01, 67.63it/s, est. speed input: 77456.03 toks/s, output: 75.64 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:02<00:01, 67.49it/s, est. speed input: 77019.31 toks/s, output: 75.21 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:02<00:01, 67.48it/s, est. speed input: 76639.86 toks/s, output: 74.84 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:02<00:00, 67.44it/s, est. speed input: 76290.59 toks/s, output: 74.50 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:02<00:00, 67.49it/s, est. speed input: 75983.37 toks/s, output: 74.20 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:02<00:00, 67.52it/s, est. speed input: 75700.35 toks/s, output: 73.93 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:02<00:00, 67.49it/s, est. speed input: 75433.85 toks/s, output: 73.67 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:03<00:00, 67.60it/s, est. speed input: 75205.98 toks/s, output: 73.44 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:03<00:00, 67.62it/s, est. speed input: 74987.25 toks/s, output: 73.23 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:03<00:00, 67.68it/s, est. speed input: 74790.49 toks/s, output: 73.04 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:03<00:00, 67.71it/s, est. speed input: 74604.50 toks/s, output: 72.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 67.71it/s, est. speed input: 74482.11 toks/s, output: 72.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 72.73it/s, est. speed input: 74482.11 toks/s, output: 72.74 toks/s]
[rank0]:[W128 09:12:02.070218983 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 09:12:04
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:12:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3364997) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3364997) WARNING 01-28 09:12:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 81.88 requests/s, 83924.19 total tokens/s, 81.88 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 09:12:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:12:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:12:12] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:12:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:12:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:12:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:12:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:12:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:12:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:12:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:12:19] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:12:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:12:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:12:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:12:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:12:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:12:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3364997) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3364997) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.41it/s]
(EngineCore_DP0 pid=3364997) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.41it/s]
(EngineCore_DP0 pid=3364997) 
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3364997) [2026-01-28 09:12:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3364997) 2026-01-28 09:12:38,696 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3364997) 2026-01-28 09:12:38,724 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3364997) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 12.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 12.06it/s]
(EngineCore_DP0 pid=3364997) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  7.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.34it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 28/512 [00:00<00:01, 274.82it/s]
Adding requests:  16%|█▌        | 81/512 [00:00<00:01, 420.25it/s]
Adding requests:  26%|██▌       | 132/512 [00:00<00:00, 460.07it/s]
Adding requests:  35%|███▌      | 181/512 [00:00<00:00, 471.32it/s]
Adding requests:  46%|████▌     | 233/512 [00:00<00:00, 486.69it/s]
Adding requests:  55%|█████▌    | 284/512 [00:00<00:00, 491.20it/s]
Adding requests:  65%|██████▌   | 334/512 [00:00<00:00, 492.27it/s]
Adding requests:  75%|███████▌  | 385/512 [00:00<00:00, 495.08it/s]
Adding requests:  85%|████████▌ | 436/512 [00:00<00:00, 498.79it/s]
Adding requests:  95%|█████████▌| 487/512 [00:01<00:00, 501.04it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 481.79it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:00<00:00, 607.42it/s, est. speed input: 622105.22 toks/s, output: 607.45 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:00<00:02, 141.17it/s, est. speed input: 164213.48 toks/s, output: 160.36 toks/s]
Processed prompts:  31%|███       | 158/512 [00:01<00:03, 117.28it/s, est. speed input: 138936.51 toks/s, output: 135.68 toks/s]
Processed prompts:  35%|███▍      | 179/512 [00:01<00:03, 110.49it/s, est. speed input: 131536.55 toks/s, output: 128.45 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:01<00:03, 105.24it/s, est. speed input: 126729.50 toks/s, output: 123.76 toks/s]
Processed prompts:  41%|████      | 209/512 [00:01<00:02, 104.53it/s, est. speed input: 124914.56 toks/s, output: 121.99 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:01<00:03, 95.02it/s, est. speed input: 119756.82 toks/s, output: 116.95 toks/s] 
Processed prompts:  46%|████▌     | 234/512 [00:02<00:02, 92.98it/s, est. speed input: 117599.59 toks/s, output: 114.84 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:02<00:02, 91.33it/s, est. speed input: 115731.48 toks/s, output: 113.02 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:02<00:02, 90.23it/s, est. speed input: 114149.78 toks/s, output: 111.47 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:02<00:02, 89.42it/s, est. speed input: 112756.71 toks/s, output: 110.11 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:02<00:02, 88.83it/s, est. speed input: 111517.22 toks/s, output: 108.90 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:02<00:02, 88.49it/s, est. speed input: 110421.77 toks/s, output: 107.83 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:02<00:02, 88.01it/s, est. speed input: 109385.08 toks/s, output: 106.82 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:03<00:02, 87.51it/s, est. speed input: 108414.15 toks/s, output: 105.87 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:03<00:02, 87.22it/s, est. speed input: 107539.33 toks/s, output: 105.02 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:03<00:01, 88.33it/s, est. speed input: 106965.40 toks/s, output: 104.46 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:03<00:01, 87.87it/s, est. speed input: 106231.91 toks/s, output: 103.74 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:03<00:01, 87.58it/s, est. speed input: 105561.86 toks/s, output: 103.09 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:03<00:01, 87.63it/s, est. speed input: 104978.99 toks/s, output: 102.52 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:03<00:01, 87.46it/s, est. speed input: 104407.95 toks/s, output: 101.96 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:03<00:01, 87.18it/s, est. speed input: 103855.78 toks/s, output: 101.42 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:04<00:01, 87.08it/s, est. speed input: 103352.52 toks/s, output: 100.93 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:04<00:00, 86.92it/s, est. speed input: 102870.92 toks/s, output: 100.46 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:04<00:00, 86.80it/s, est. speed input: 102420.01 toks/s, output: 100.02 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:04<00:00, 88.33it/s, est. speed input: 102185.43 toks/s, output: 99.79 toks/s] 
Processed prompts:  90%|█████████ | 462/512 [00:04<00:00, 88.27it/s, est. speed input: 101834.91 toks/s, output: 99.45 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:04<00:00, 87.98it/s, est. speed input: 101478.08 toks/s, output: 99.10 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:04<00:00, 87.86it/s, est. speed input: 101149.77 toks/s, output: 98.78 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:05<00:00, 87.49it/s, est. speed input: 100809.50 toks/s, output: 98.45 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:05<00:00, 88.87it/s, est. speed input: 100650.03 toks/s, output: 98.29 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 88.87it/s, est. speed input: 101040.97 toks/s, output: 98.67 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 98.67it/s, est. speed input: 101040.97 toks/s, output: 98.67 toks/s]
[rank0]:[W128 09:12:47.600196698 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 09:12:49
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:13:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3366138) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3366138) WARNING 01-28 09:13:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 92.74 requests/s, 95055.82 total tokens/s, 92.74 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 09:13:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:13:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:13:00] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:13:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:13:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:13:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:13:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:13:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:13:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:13:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:13:06] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:13:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:13:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:13:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:13:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:13:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3366138) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3366138) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=3366138) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=3366138) 
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3366138) [2026-01-28 09:13:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3366138) 2026-01-28 09:13:25,841 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3366138) 2026-01-28 09:13:25,869 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3366138) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  5.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  9.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.98it/s]
(EngineCore_DP0 pid=3366138) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 16.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 16.74it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 32/1024 [00:00<00:03, 317.65it/s]
Adding requests:   8%|▊         | 84/1024 [00:00<00:02, 433.29it/s]
Adding requests:  13%|█▎        | 135/1024 [00:00<00:01, 466.70it/s]
Adding requests:  18%|█▊        | 184/1024 [00:00<00:01, 475.39it/s]
Adding requests:  23%|██▎       | 236/1024 [00:00<00:01, 489.08it/s]
Adding requests:  28%|██▊       | 287/1024 [00:00<00:01, 492.51it/s]
Adding requests:  33%|███▎      | 337/1024 [00:00<00:01, 493.92it/s]
Adding requests:  38%|███▊      | 389/1024 [00:00<00:01, 502.08it/s]
Adding requests:  43%|████▎     | 440/1024 [00:00<00:01, 502.87it/s]
Adding requests:  48%|████▊     | 491/1024 [00:01<00:01, 503.93it/s]
Adding requests:  53%|█████▎    | 542/1024 [00:01<00:00, 493.83it/s]
Adding requests:  58%|█████▊    | 595/1024 [00:01<00:00, 504.34it/s]
Adding requests:  63%|██████▎   | 646/1024 [00:01<00:00, 501.84it/s]
Adding requests:  68%|██████▊   | 700/1024 [00:01<00:00, 511.24it/s]
Adding requests:  73%|███████▎  | 752/1024 [00:01<00:00, 510.74it/s]
Adding requests:  79%|███████▊  | 804/1024 [00:01<00:00, 507.89it/s]
Adding requests:  83%|████████▎ | 855/1024 [00:01<00:00, 501.91it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:01<00:00, 508.69it/s]
Adding requests:  94%|█████████▍| 960/1024 [00:01<00:00, 510.65it/s]
Adding requests:  99%|█████████▉| 1012/1024 [00:02<00:00, 513.23it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 497.96it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:00<00:00, 1042.76it/s, est. speed input: 1067920.56 toks/s, output: 1042.80 toks/s]
Processed prompts:  29%|██▉       | 299/1024 [00:01<00:03, 193.56it/s, est. speed input: 235542.73 toks/s, output: 230.02 toks/s]   
Processed prompts:  34%|███▍      | 348/1024 [00:01<00:04, 158.05it/s, est. speed input: 197368.90 toks/s, output: 192.74 toks/s]
Processed prompts:  37%|███▋      | 379/1024 [00:02<00:04, 140.34it/s, est. speed input: 180673.97 toks/s, output: 176.44 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:02<00:04, 129.05it/s, est. speed input: 171078.44 toks/s, output: 167.07 toks/s]
Processed prompts:  41%|████      | 420/1024 [00:02<00:04, 124.93it/s, est. speed input: 166868.81 toks/s, output: 162.96 toks/s]
Processed prompts:  43%|████▎     | 436/1024 [00:02<00:04, 118.73it/s, est. speed input: 162444.58 toks/s, output: 158.64 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:02<00:05, 111.89it/s, est. speed input: 158322.34 toks/s, output: 154.61 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:03<00:05, 107.44it/s, est. speed input: 154845.25 toks/s, output: 151.21 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:03<00:05, 103.81it/s, est. speed input: 151718.30 toks/s, output: 148.16 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:03<00:05, 100.97it/s, est. speed input: 148900.36 toks/s, output: 145.41 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:03<00:05, 98.82it/s, est. speed input: 146350.81 toks/s, output: 142.92 toks/s] 
Processed prompts:  52%|█████▏    | 530/1024 [00:03<00:05, 97.27it/s, est. speed input: 144040.69 toks/s, output: 140.66 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:03<00:04, 96.12it/s, est. speed input: 141928.56 toks/s, output: 138.60 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:04<00:04, 95.21it/s, est. speed input: 139975.82 toks/s, output: 136.69 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:04<00:04, 94.63it/s, est. speed input: 138192.30 toks/s, output: 134.95 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:04<00:04, 94.36it/s, est. speed input: 136572.95 toks/s, output: 133.37 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:04<00:04, 93.97it/s, est. speed input: 135037.63 toks/s, output: 131.87 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:04<00:04, 93.75it/s, est. speed input: 133622.87 toks/s, output: 130.49 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:04<00:04, 93.62it/s, est. speed input: 132310.11 toks/s, output: 129.21 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:05<00:03, 93.52it/s, est. speed input: 131081.22 toks/s, output: 128.01 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:05<00:03, 93.36it/s, est. speed input: 129919.63 toks/s, output: 126.87 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:05<00:03, 93.25it/s, est. speed input: 128830.80 toks/s, output: 125.81 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:05<00:03, 93.25it/s, est. speed input: 127820.17 toks/s, output: 124.82 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:05<00:03, 93.21it/s, est. speed input: 126862.91 toks/s, output: 123.89 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:05<00:03, 93.18it/s, est. speed input: 125960.53 toks/s, output: 123.01 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:06<00:02, 93.27it/s, est. speed input: 125121.18 toks/s, output: 122.19 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:06<00:02, 93.14it/s, est. speed input: 124305.05 toks/s, output: 121.39 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:06<00:02, 93.21it/s, est. speed input: 123549.98 toks/s, output: 120.65 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:06<00:02, 93.16it/s, est. speed input: 122823.35 toks/s, output: 119.94 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:06<00:02, 93.20it/s, est. speed input: 122140.66 toks/s, output: 119.28 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:07<00:02, 93.15it/s, est. speed input: 121482.52 toks/s, output: 118.63 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:07<00:01, 93.10it/s, est. speed input: 120855.68 toks/s, output: 118.02 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:07<00:01, 93.10it/s, est. speed input: 120260.93 toks/s, output: 117.44 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:07<00:01, 90.62it/s, est. speed input: 119444.21 toks/s, output: 116.64 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:07<00:01, 93.49it/s, est. speed input: 119114.43 toks/s, output: 116.32 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:07<00:01, 93.40it/s, est. speed input: 118599.58 toks/s, output: 115.82 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:08<00:01, 93.22it/s, est. speed input: 118095.25 toks/s, output: 115.33 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:08<00:00, 94.65it/s, est. speed input: 117747.27 toks/s, output: 114.99 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:08<00:00, 94.15it/s, est. speed input: 117285.62 toks/s, output: 114.54 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:08<00:00, 93.75it/s, est. speed input: 116838.70 toks/s, output: 114.10 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:08<00:00, 95.01it/s, est. speed input: 116532.84 toks/s, output: 113.80 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:08<00:00, 94.30it/s, est. speed input: 116113.23 toks/s, output: 113.39 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:08<00:00, 94.30it/s, est. speed input: 116723.35 toks/s, output: 113.99 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:08<00:00, 113.98it/s, est. speed input: 116723.35 toks/s, output: 113.99 toks/s]
[rank0]:[W128 09:13:39.593974661 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 09:13:41
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:13:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3367492) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3367492) WARNING 01-28 09:14:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 95.29 requests/s, 97676.82 total tokens/s, 95.29 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 09:13:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:13:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:13:56] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:13:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:13:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:13:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:13:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:13:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:13:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:14:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:14:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:14:03] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:14:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:14:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:14:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:14:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:14:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:14:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3367492) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3367492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=3367492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=3367492) 
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3367492) [2026-01-28 09:14:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3367492) 2026-01-28 09:14:22,568 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3367492) 2026-01-28 09:14:22,597 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3367492) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 11.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  9.09it/s]
(EngineCore_DP0 pid=3367492) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 15.57it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 16.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 16.24it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 33/2048 [00:00<00:06, 326.26it/s]
Adding requests:   4%|▍         | 84/2048 [00:00<00:04, 430.34it/s]
Adding requests:   7%|▋         | 134/2048 [00:00<00:04, 460.11it/s]
Adding requests:   9%|▉         | 183/2048 [00:00<00:03, 470.14it/s]
Adding requests:  11%|█▏        | 233/2048 [00:00<00:03, 480.54it/s]
Adding requests:  14%|█▍        | 283/2048 [00:00<00:03, 483.84it/s]
Adding requests:  16%|█▌        | 332/2048 [00:00<00:03, 485.60it/s]
Adding requests:  19%|█▊        | 382/2048 [00:00<00:03, 488.18it/s]
Adding requests:  21%|██        | 432/2048 [00:00<00:03, 490.83it/s]
Adding requests:  24%|██▎       | 482/2048 [00:01<00:03, 491.11it/s]
Adding requests:  26%|██▌       | 532/2048 [00:01<00:03, 480.02it/s]
Adding requests:  29%|██▊       | 584/2048 [00:01<00:02, 490.07it/s]
Adding requests:  31%|███       | 635/2048 [00:01<00:02, 494.14it/s]
Adding requests:  34%|███▎      | 687/2048 [00:01<00:02, 500.76it/s]
Adding requests:  36%|███▌      | 738/2048 [00:01<00:02, 499.90it/s]
Adding requests:  39%|███▊      | 789/2048 [00:01<00:02, 493.77it/s]
Adding requests:  41%|████      | 839/2048 [00:01<00:02, 484.04it/s]
Adding requests:  44%|████▎     | 891/2048 [00:01<00:02, 494.12it/s]
Adding requests:  46%|████▌     | 942/2048 [00:01<00:02, 496.02it/s]
Adding requests:  49%|████▊     | 994/2048 [00:02<00:02, 501.65it/s]
Adding requests:  51%|█████     | 1046/2048 [00:02<00:01, 505.54it/s]
Adding requests:  54%|█████▎    | 1097/2048 [00:02<00:01, 501.67it/s]
Adding requests:  56%|█████▌    | 1148/2048 [00:02<00:01, 500.08it/s]
Adding requests:  59%|█████▊    | 1202/2048 [00:02<00:01, 510.81it/s]
Adding requests:  61%|██████    | 1254/2048 [00:02<00:01, 502.73it/s]
Adding requests:  64%|██████▎   | 1305/2048 [00:02<00:01, 500.69it/s]
Adding requests:  66%|██████▌   | 1356/2048 [00:02<00:01, 500.61it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:02<00:01, 503.40it/s]
Adding requests:  71%|███████   | 1459/2048 [00:02<00:01, 501.38it/s]
Adding requests:  74%|███████▎  | 1510/2048 [00:03<00:01, 502.59it/s]
Adding requests:  76%|███████▌  | 1561/2048 [00:03<00:00, 503.21it/s]
Adding requests:  79%|███████▉  | 1613/2048 [00:03<00:00, 506.47it/s]
Adding requests:  81%|████████▏ | 1664/2048 [00:03<00:00, 504.33it/s]
Adding requests:  84%|████████▎ | 1715/2048 [00:03<00:00, 501.82it/s]
Adding requests:  86%|████████▌ | 1766/2048 [00:03<00:00, 499.04it/s]
Adding requests:  89%|████████▊ | 1817/2048 [00:03<00:00, 500.62it/s]
Adding requests:  91%|█████████ | 1868/2048 [00:03<00:00, 499.72it/s]
Adding requests:  94%|█████████▎| 1918/2048 [00:03<00:00, 493.03it/s]
Adding requests:  96%|█████████▌| 1968/2048 [00:03<00:00, 492.90it/s]
Adding requests:  99%|█████████▊| 2019/2048 [00:04<00:00, 497.63it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 493.92it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:00<00:00, 2623.50it/s, est. speed input: 2686890.92 toks/s, output: 2623.63 toks/s]
Processed prompts:  32%|███▏      | 649/2048 [00:02<00:07, 192.62it/s, est. speed input: 236313.24 toks/s, output: 230.77 toks/s]   
Processed prompts:  37%|███▋      | 763/2048 [00:03<00:08, 156.78it/s, est. speed input: 196195.47 toks/s, output: 191.60 toks/s]
Processed prompts:  41%|████      | 830/2048 [00:04<00:08, 143.47it/s, est. speed input: 182730.10 toks/s, output: 178.45 toks/s]
Processed prompts:  43%|████▎     | 875/2048 [00:05<00:08, 132.62it/s, est. speed input: 173869.19 toks/s, output: 169.79 toks/s]
Processed prompts:  44%|████▍     | 907/2048 [00:05<00:09, 126.62it/s, est. speed input: 169211.06 toks/s, output: 165.24 toks/s]
Processed prompts:  45%|████▌     | 931/2048 [00:05<00:09, 117.00it/s, est. speed input: 163984.36 toks/s, output: 160.14 toks/s]
Processed prompts:  46%|████▋     | 950/2048 [00:05<00:09, 116.43it/s, est. speed input: 162595.95 toks/s, output: 158.78 toks/s]
Processed prompts:  47%|████▋     | 967/2048 [00:06<00:09, 114.31it/s, est. speed input: 161007.09 toks/s, output: 157.23 toks/s]
Processed prompts:  48%|████▊     | 982/2048 [00:06<00:09, 111.14it/s, est. speed input: 159407.80 toks/s, output: 155.67 toks/s]
Processed prompts:  49%|████▊     | 995/2048 [00:06<00:10, 104.53it/s, est. speed input: 157346.24 toks/s, output: 153.66 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:06<00:10, 101.20it/s, est. speed input: 155687.50 toks/s, output: 152.04 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:06<00:10, 99.86it/s, est. speed input: 154266.48 toks/s, output: 150.65 toks/s] 
Processed prompts:  51%|█████     | 1042/2048 [00:06<00:10, 98.72it/s, est. speed input: 152906.70 toks/s, output: 149.32 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:07<00:10, 97.74it/s, est. speed input: 151597.64 toks/s, output: 148.04 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:07<00:10, 97.17it/s, est. speed input: 150371.40 toks/s, output: 146.85 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:07<00:09, 96.56it/s, est. speed input: 149177.86 toks/s, output: 145.68 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:07<00:09, 96.41it/s, est. speed input: 148070.02 toks/s, output: 144.60 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:07<00:09, 96.05it/s, est. speed input: 146982.13 toks/s, output: 143.54 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:07<00:09, 95.90it/s, est. speed input: 145950.62 toks/s, output: 142.53 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:08<00:09, 97.21it/s, est. speed input: 145108.95 toks/s, output: 141.71 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:08<00:09, 96.63it/s, est. speed input: 144148.33 toks/s, output: 140.77 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:08<00:08, 96.26it/s, est. speed input: 143229.98 toks/s, output: 139.87 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:08<00:08, 96.09it/s, est. speed input: 142354.42 toks/s, output: 139.02 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:08<00:08, 95.91it/s, est. speed input: 141507.59 toks/s, output: 138.19 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:08<00:08, 95.64it/s, est. speed input: 140678.72 toks/s, output: 137.38 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:09<00:08, 95.59it/s, est. speed input: 139892.31 toks/s, output: 136.61 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:09<00:08, 97.07it/s, est. speed input: 139265.00 toks/s, output: 136.00 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:09<00:07, 96.58it/s, est. speed input: 138530.32 toks/s, output: 135.28 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:09<00:07, 96.30it/s, est. speed input: 137827.33 toks/s, output: 134.60 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:09<00:07, 96.03it/s, est. speed input: 137140.55 toks/s, output: 133.93 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:09<00:07, 95.88it/s, est. speed input: 136480.44 toks/s, output: 133.28 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:10<00:07, 95.41it/s, est. speed input: 135814.25 toks/s, output: 132.63 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:10<00:07, 95.46it/s, est. speed input: 135198.57 toks/s, output: 132.03 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:10<00:07, 95.30it/s, est. speed input: 134587.46 toks/s, output: 131.43 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:10<00:06, 95.42it/s, est. speed input: 134013.59 toks/s, output: 130.87 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:10<00:06, 95.46it/s, est. speed input: 133453.97 toks/s, output: 130.33 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:10<00:06, 95.36it/s, est. speed input: 132901.90 toks/s, output: 129.79 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:11<00:06, 95.22it/s, est. speed input: 132362.05 toks/s, output: 129.26 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:11<00:06, 95.20it/s, est. speed input: 131843.63 toks/s, output: 128.75 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:11<00:06, 95.20it/s, est. speed input: 131340.41 toks/s, output: 128.26 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:11<00:05, 95.21it/s, est. speed input: 130853.25 toks/s, output: 127.79 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:11<00:05, 95.27it/s, est. speed input: 130383.22 toks/s, output: 127.33 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:11<00:05, 95.33it/s, est. speed input: 129927.25 toks/s, output: 126.88 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:12<00:05, 95.24it/s, est. speed input: 129476.11 toks/s, output: 126.44 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:12<00:05, 95.20it/s, est. speed input: 129038.45 toks/s, output: 126.01 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:12<00:05, 95.19it/s, est. speed input: 128613.28 toks/s, output: 125.60 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:12<00:04, 96.70it/s, est. speed input: 128288.55 toks/s, output: 125.28 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:12<00:04, 96.20it/s, est. speed input: 127882.30 toks/s, output: 124.88 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:12<00:04, 95.96it/s, est. speed input: 127492.91 toks/s, output: 124.50 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:13<00:04, 95.66it/s, est. speed input: 127105.72 toks/s, output: 124.13 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:13<00:04, 95.59it/s, est. speed input: 126736.26 toks/s, output: 123.77 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:13<00:04, 95.38it/s, est. speed input: 126366.77 toks/s, output: 123.40 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:13<00:03, 95.28it/s, est. speed input: 126009.27 toks/s, output: 123.06 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:13<00:03, 95.30it/s, est. speed input: 125665.22 toks/s, output: 122.72 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:14<00:03, 95.16it/s, est. speed input: 125321.12 toks/s, output: 122.38 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:14<00:03, 95.30it/s, est. speed input: 124997.75 toks/s, output: 122.07 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:14<00:03, 95.10it/s, est. speed input: 124666.67 toks/s, output: 121.74 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:14<00:03, 95.14it/s, est. speed input: 124352.12 toks/s, output: 121.44 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:14<00:02, 95.11it/s, est. speed input: 124042.08 toks/s, output: 121.13 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:14<00:02, 95.04it/s, est. speed input: 123736.85 toks/s, output: 120.84 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:15<00:02, 95.06it/s, est. speed input: 123441.60 toks/s, output: 120.55 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:15<00:02, 95.05it/s, est. speed input: 123151.49 toks/s, output: 120.26 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:15<00:02, 95.06it/s, est. speed input: 122868.79 toks/s, output: 119.99 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:15<00:01, 95.01it/s, est. speed input: 122589.73 toks/s, output: 119.72 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:15<00:01, 96.57it/s, est. speed input: 122388.98 toks/s, output: 119.52 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:15<00:01, 96.15it/s, est. speed input: 122124.46 toks/s, output: 119.26 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:16<00:01, 95.77it/s, est. speed input: 121861.80 toks/s, output: 119.01 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:16<00:01, 95.53it/s, est. speed input: 121605.83 toks/s, output: 118.76 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:16<00:01, 95.51it/s, est. speed input: 121361.20 toks/s, output: 118.52 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:16<00:00, 96.93it/s, est. speed input: 121182.36 toks/s, output: 118.34 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:16<00:00, 96.33it/s, est. speed input: 120940.62 toks/s, output: 118.11 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:16<00:00, 95.93it/s, est. speed input: 120704.14 toks/s, output: 117.87 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:17<00:00, 95.71it/s, est. speed input: 120474.79 toks/s, output: 117.65 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:17<00:00, 95.40it/s, est. speed input: 120243.37 toks/s, output: 117.42 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:17<00:00, 97.33it/s, est. speed input: 120102.31 toks/s, output: 117.29 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:17<00:00, 97.33it/s, est. speed input: 120925.15 toks/s, output: 118.09 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:17<00:00, 118.09it/s, est. speed input: 120925.15 toks/s, output: 118.09 toks/s]
[rank0]:[W128 09:14:47.082932629 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 09:14:49
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/BitNet-2B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:15:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3368986) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3368986) WARNING 01-28 09:15:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 98.62 requests/s, 101082.11 total tokens/s, 98.62 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 09:15:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:15:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:15:12] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:15:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:15:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:15:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:15:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:15:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:15:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 09:15:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:15:19] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:15:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:15:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:15:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:15:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:15:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:15:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3368986) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3368986) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=3368986) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=3368986) 
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3368986) [2026-01-28 09:15:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3368986) [rank0]:W0128 09:15:34.431000 3368986 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3368986) [rank0]:W0128 09:15:34.511000 3368986 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3368986) [rank0]:W0128 09:15:35.573000 3368986 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3368986) [rank0]:W0128 09:15:35.701000 3368986 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3368986) 2026-01-28 09:15:39,551 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3368986) 2026-01-28 09:15:39,591 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3368986) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  5.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  6.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 11.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 13.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 13.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 11.22it/s]
(EngineCore_DP0 pid=3368986) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 15.46it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 16.14it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 16.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 16.17it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 36/4096 [00:00<00:11, 354.37it/s]
Adding requests:   2%|▏         | 88/4096 [00:00<00:08, 445.85it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:08, 472.34it/s]
Adding requests:   5%|▍         | 188/4096 [00:00<00:08, 478.92it/s]
Adding requests:   6%|▌         | 240/4096 [00:00<00:07, 492.69it/s]
Adding requests:   7%|▋         | 291/4096 [00:00<00:07, 495.93it/s]
Adding requests:   8%|▊         | 341/4096 [00:00<00:07, 495.67it/s]
Adding requests:  10%|▉         | 393/4096 [00:00<00:07, 502.82it/s]
Adding requests:  11%|█         | 444/4096 [00:00<00:07, 502.76it/s]
Adding requests:  12%|█▏        | 495/4096 [00:01<00:07, 503.49it/s]
Adding requests:  13%|█▎        | 546/4096 [00:01<00:07, 493.94it/s]
Adding requests:  15%|█▍        | 598/4096 [00:01<00:06, 500.72it/s]
Adding requests:  16%|█▌        | 650/4096 [00:01<00:06, 505.67it/s]
Adding requests:  17%|█▋        | 703/4096 [00:01<00:06, 512.47it/s]
Adding requests:  18%|█▊        | 755/4096 [00:01<00:06, 510.03it/s]
Adding requests:  20%|█▉        | 807/4096 [00:01<00:06, 501.83it/s]
Adding requests:  21%|██        | 858/4096 [00:01<00:06, 500.45it/s]
Adding requests:  22%|██▏       | 911/4096 [00:01<00:06, 507.62it/s]
Adding requests:  24%|██▎       | 964/4096 [00:01<00:06, 511.13it/s]
Adding requests:  25%|██▍       | 1017/4096 [00:02<00:05, 514.51it/s]
Adding requests:  26%|██▌       | 1069/4096 [00:02<00:05, 514.90it/s]
Adding requests:  27%|██▋       | 1121/4096 [00:02<00:06, 493.46it/s]
Adding requests:  29%|██▊       | 1175/4096 [00:02<00:05, 504.50it/s]
Adding requests:  30%|███       | 1229/4096 [00:02<00:05, 514.04it/s]
Adding requests:  31%|███▏      | 1281/4096 [00:02<00:05, 510.71it/s]
Adding requests:  33%|███▎      | 1335/4096 [00:02<00:05, 518.39it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:02<00:05, 519.50it/s]
Adding requests:  35%|███▌      | 1441/4096 [00:02<00:05, 519.56it/s]
Adding requests:  36%|███▋      | 1495/4096 [00:02<00:04, 523.91it/s]
Adding requests:  38%|███▊      | 1548/4096 [00:03<00:04, 525.06it/s]
Adding requests:  39%|███▉      | 1603/4096 [00:03<00:04, 531.26it/s]
Adding requests:  40%|████      | 1657/4096 [00:03<00:04, 528.04it/s]
Adding requests:  42%|████▏     | 1710/4096 [00:03<00:04, 524.85it/s]
Adding requests:  43%|████▎     | 1763/4096 [00:03<00:04, 525.00it/s]
Adding requests:  44%|████▍     | 1816/4096 [00:03<00:04, 525.05it/s]
Adding requests:  46%|████▌     | 1869/4096 [00:03<00:04, 519.87it/s]
Adding requests:  47%|████▋     | 1922/4096 [00:03<00:04, 522.16it/s]
Adding requests:  48%|████▊     | 1975/4096 [00:03<00:04, 519.65it/s]
Adding requests:  50%|████▉     | 2029/4096 [00:03<00:03, 523.93it/s]
Adding requests:  51%|█████     | 2082/4096 [00:04<00:03, 525.11it/s]
Adding requests:  52%|█████▏    | 2135/4096 [00:04<00:03, 519.39it/s]
Adding requests:  53%|█████▎    | 2187/4096 [00:04<00:03, 514.18it/s]
Adding requests:  55%|█████▍    | 2241/4096 [00:04<00:03, 520.80it/s]
Adding requests:  56%|█████▌    | 2294/4096 [00:04<00:03, 505.83it/s]
Adding requests:  57%|█████▋    | 2347/4096 [00:04<00:03, 511.05it/s]
Adding requests:  59%|█████▊    | 2399/4096 [00:04<00:03, 513.20it/s]
Adding requests:  60%|█████▉    | 2451/4096 [00:04<00:03, 514.41it/s]
Adding requests:  61%|██████    | 2503/4096 [00:04<00:03, 515.13it/s]
Adding requests:  62%|██████▏   | 2557/4096 [00:05<00:02, 521.92it/s]
Adding requests:  64%|██████▎   | 2610/4096 [00:05<00:02, 522.25it/s]
Adding requests:  65%|██████▌   | 2664/4096 [00:05<00:02, 526.82it/s]
Adding requests:  66%|██████▋   | 2717/4096 [00:05<00:02, 520.38it/s]
Adding requests:  68%|██████▊   | 2770/4096 [00:05<00:02, 522.65it/s]
Adding requests:  69%|██████▉   | 2823/4096 [00:05<00:02, 516.52it/s]
Adding requests:  70%|███████   | 2877/4096 [00:05<00:02, 520.77it/s]
Adding requests:  72%|███████▏  | 2930/4096 [00:05<00:02, 518.48it/s]
Adding requests:  73%|███████▎  | 2982/4096 [00:05<00:02, 517.42it/s]
Adding requests:  74%|███████▍  | 3035/4096 [00:05<00:02, 518.90it/s]
Adding requests:  75%|███████▌  | 3087/4096 [00:06<00:01, 517.98it/s]
Adding requests:  77%|███████▋  | 3139/4096 [00:06<00:01, 517.17it/s]
Adding requests:  78%|███████▊  | 3191/4096 [00:06<00:01, 517.39it/s]
Adding requests:  79%|███████▉  | 3243/4096 [00:06<00:01, 514.90it/s]
Adding requests:  80%|████████  | 3296/4096 [00:06<00:01, 517.41it/s]
Adding requests:  82%|████████▏ | 3349/4096 [00:06<00:01, 519.81it/s]
Adding requests:  83%|████████▎ | 3401/4096 [00:06<00:01, 518.09it/s]
Adding requests:  84%|████████▍ | 3453/4096 [00:06<00:01, 518.26it/s]
Adding requests:  86%|████████▌ | 3505/4096 [00:06<00:01, 513.47it/s]
Adding requests:  87%|████████▋ | 3558/4096 [00:06<00:01, 516.42it/s]
Adding requests:  88%|████████▊ | 3610/4096 [00:07<00:00, 500.46it/s]
Adding requests:  89%|████████▉ | 3661/4096 [00:07<00:00, 501.52it/s]
Adding requests:  91%|█████████ | 3714/4096 [00:07<00:00, 509.65it/s]
Adding requests:  92%|█████████▏| 3768/4096 [00:07<00:00, 515.80it/s]
Adding requests:  93%|█████████▎| 3822/4096 [00:07<00:00, 520.50it/s]
Adding requests:  95%|█████████▍| 3877/4096 [00:07<00:00, 527.52it/s]
Adding requests:  96%|█████████▌| 3930/4096 [00:07<00:00, 524.88it/s]
Adding requests:  97%|█████████▋| 3983/4096 [00:07<00:00, 523.77it/s]
Adding requests:  99%|█████████▊| 4036/4096 [00:07<00:00, 521.11it/s]
Adding requests: 100%|█████████▉| 4089/4096 [00:08<00:00, 439.10it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 509.26it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▊        | 763/4096 [00:00<00:00, 6602.12it/s, est. speed input: 6763044.05 toks/s, output: 6602.78 toks/s]
Processed prompts:  35%|███▍      | 1424/4096 [00:06<00:14, 182.93it/s, est. speed input: 222020.25 toks/s, output: 216.82 toks/s]  
Processed prompts:  42%|████▏     | 1702/4096 [00:09<00:16, 148.76it/s, est. speed input: 183705.63 toks/s, output: 179.40 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [00:11<00:16, 136.44it/s, est. speed input: 171343.73 toks/s, output: 167.33 toks/s]
Processed prompts:  48%|████▊     | 1956/4096 [00:12<00:16, 130.54it/s, est. speed input: 165919.53 toks/s, output: 162.03 toks/s]
Processed prompts:  49%|████▉     | 2023/4096 [00:12<00:16, 126.72it/s, est. speed input: 162827.88 toks/s, output: 159.01 toks/s]
Processed prompts:  51%|█████     | 2071/4096 [00:13<00:15, 128.56it/s, est. speed input: 162521.83 toks/s, output: 158.71 toks/s]
Processed prompts:  51%|█████▏    | 2108/4096 [00:13<00:17, 113.85it/s, est. speed input: 157559.80 toks/s, output: 153.87 toks/s]
Processed prompts:  52%|█████▏    | 2139/4096 [00:14<00:17, 111.45it/s, est. speed input: 156161.30 toks/s, output: 152.50 toks/s]
Processed prompts:  53%|█████▎    | 2171/4096 [00:14<00:17, 109.41it/s, est. speed input: 154898.86 toks/s, output: 151.27 toks/s]
Processed prompts:  54%|█████▍    | 2203/4096 [00:14<00:17, 107.35it/s, est. speed input: 153686.58 toks/s, output: 150.08 toks/s]
Processed prompts:  55%|█████▍    | 2235/4096 [00:14<00:17, 106.66it/s, est. speed input: 152713.01 toks/s, output: 149.13 toks/s]
Processed prompts:  55%|█████▌    | 2267/4096 [00:15<00:17, 104.68it/s, est. speed input: 151597.19 toks/s, output: 148.04 toks/s]
Processed prompts:  56%|█████▌    | 2299/4096 [00:15<00:17, 103.68it/s, est. speed input: 150606.66 toks/s, output: 147.08 toks/s]
Processed prompts:  57%|█████▋    | 2331/4096 [00:15<00:17, 102.92it/s, est. speed input: 149660.38 toks/s, output: 146.15 toks/s]
Processed prompts:  58%|█████▊    | 2363/4096 [00:16<00:16, 103.24it/s, est. speed input: 148847.86 toks/s, output: 145.36 toks/s]
Processed prompts:  58%|█████▊    | 2395/4096 [00:16<00:16, 101.74it/s, est. speed input: 147892.06 toks/s, output: 144.43 toks/s]
Processed prompts:  59%|█████▉    | 2427/4096 [00:16<00:16, 100.77it/s, est. speed input: 146984.29 toks/s, output: 143.54 toks/s]
Processed prompts:  60%|██████    | 2459/4096 [00:17<00:16, 100.04it/s, est. speed input: 146108.46 toks/s, output: 142.68 toks/s]
Processed prompts:  61%|██████    | 2491/4096 [00:17<00:16, 100.23it/s, est. speed input: 145330.13 toks/s, output: 141.92 toks/s]
Processed prompts:  62%|██████▏   | 2523/4096 [00:17<00:15, 99.77it/s, est. speed input: 144526.64 toks/s, output: 141.14 toks/s] 
Processed prompts:  62%|██████▏   | 2555/4096 [00:18<00:15, 99.28it/s, est. speed input: 143737.31 toks/s, output: 140.37 toks/s]
Processed prompts:  63%|██████▎   | 2587/4096 [00:18<00:15, 99.92it/s, est. speed input: 143059.02 toks/s, output: 139.71 toks/s]
Processed prompts:  64%|██████▍   | 2619/4096 [00:18<00:14, 99.58it/s, est. speed input: 142338.45 toks/s, output: 139.00 toks/s]
Processed prompts:  65%|██████▍   | 2651/4096 [00:19<00:14, 99.26it/s, est. speed input: 141635.87 toks/s, output: 138.32 toks/s]
Processed prompts:  66%|██████▌   | 2683/4096 [00:19<00:14, 99.24it/s, est. speed input: 140972.41 toks/s, output: 137.67 toks/s]
Processed prompts:  66%|██████▋   | 2715/4096 [00:19<00:13, 99.11it/s, est. speed input: 140322.23 toks/s, output: 137.03 toks/s]
Processed prompts:  67%|██████▋   | 2747/4096 [00:20<00:13, 99.02it/s, est. speed input: 139692.91 toks/s, output: 136.42 toks/s]
Processed prompts:  68%|██████▊   | 2779/4096 [00:20<00:13, 98.88it/s, est. speed input: 139077.36 toks/s, output: 135.82 toks/s]
Processed prompts:  69%|██████▊   | 2811/4096 [00:20<00:12, 98.92it/s, est. speed input: 138491.75 toks/s, output: 135.25 toks/s]
Processed prompts:  69%|██████▉   | 2843/4096 [00:21<00:12, 98.72it/s, est. speed input: 137906.94 toks/s, output: 134.67 toks/s]
Processed prompts:  70%|███████   | 2875/4096 [00:21<00:12, 98.57it/s, est. speed input: 137339.70 toks/s, output: 134.12 toks/s]
Processed prompts:  71%|███████   | 2907/4096 [00:21<00:12, 98.56it/s, est. speed input: 136796.27 toks/s, output: 133.59 toks/s]
Processed prompts:  72%|███████▏  | 2939/4096 [00:22<00:11, 98.56it/s, est. speed input: 136268.63 toks/s, output: 133.07 toks/s]
Processed prompts:  73%|███████▎  | 2971/4096 [00:22<00:11, 98.65it/s, est. speed input: 135762.36 toks/s, output: 132.58 toks/s]
Processed prompts:  73%|███████▎  | 3003/4096 [00:22<00:11, 98.52it/s, est. speed input: 135257.98 toks/s, output: 132.09 toks/s]
Processed prompts:  74%|███████▍  | 3035/4096 [00:23<00:10, 98.46it/s, est. speed input: 134769.93 toks/s, output: 131.61 toks/s]
Processed prompts:  75%|███████▍  | 3067/4096 [00:23<00:10, 98.50it/s, est. speed input: 134300.57 toks/s, output: 131.15 toks/s]
Processed prompts:  76%|███████▌  | 3099/4096 [00:23<00:10, 98.48it/s, est. speed input: 133841.55 toks/s, output: 130.70 toks/s]
Processed prompts:  76%|███████▋  | 3131/4096 [00:24<00:09, 99.23it/s, est. speed input: 133441.13 toks/s, output: 130.31 toks/s]
Processed prompts:  77%|███████▋  | 3163/4096 [00:24<00:09, 98.98it/s, est. speed input: 133004.32 toks/s, output: 129.89 toks/s]
Processed prompts:  78%|███████▊  | 3195/4096 [00:24<00:09, 98.70it/s, est. speed input: 132573.47 toks/s, output: 129.47 toks/s]
Processed prompts:  79%|███████▉  | 3227/4096 [00:25<00:08, 98.63it/s, est. speed input: 132160.97 toks/s, output: 129.06 toks/s]
Processed prompts:  80%|███████▉  | 3259/4096 [00:25<00:08, 98.56it/s, est. speed input: 131757.78 toks/s, output: 128.67 toks/s]
Processed prompts:  80%|████████  | 3291/4096 [00:25<00:08, 98.63it/s, est. speed input: 131371.52 toks/s, output: 128.29 toks/s]
Processed prompts:  81%|████████  | 3323/4096 [00:25<00:07, 98.15it/s, est. speed input: 130965.08 toks/s, output: 127.90 toks/s]
Processed prompts:  82%|████████▏ | 3355/4096 [00:26<00:07, 98.25it/s, est. speed input: 130593.27 toks/s, output: 127.53 toks/s]
Processed prompts:  83%|████████▎ | 3387/4096 [00:26<00:07, 98.47it/s, est. speed input: 130238.26 toks/s, output: 127.19 toks/s]
Processed prompts:  83%|████████▎ | 3419/4096 [00:26<00:06, 98.26it/s, est. speed input: 129872.77 toks/s, output: 126.83 toks/s]
Processed prompts:  84%|████████▍ | 3451/4096 [00:27<00:06, 98.35it/s, est. speed input: 129528.47 toks/s, output: 126.49 toks/s]
Processed prompts:  85%|████████▌ | 3483/4096 [00:27<00:06, 100.28it/s, est. speed input: 129286.77 toks/s, output: 126.26 toks/s]
Processed prompts:  86%|████████▌ | 3515/4096 [00:27<00:05, 99.72it/s, est. speed input: 128954.60 toks/s, output: 125.93 toks/s] 
Processed prompts:  87%|████████▋ | 3547/4096 [00:28<00:05, 99.16it/s, est. speed input: 128621.99 toks/s, output: 125.61 toks/s]
Processed prompts:  87%|████████▋ | 3579/4096 [00:28<00:05, 99.21it/s, est. speed input: 128318.25 toks/s, output: 125.31 toks/s]
Processed prompts:  88%|████████▊ | 3611/4096 [00:28<00:04, 98.90it/s, est. speed input: 128004.96 toks/s, output: 125.00 toks/s]
Processed prompts:  89%|████████▉ | 3643/4096 [00:29<00:04, 98.68it/s, est. speed input: 127698.13 toks/s, output: 124.71 toks/s]
Processed prompts:  90%|████████▉ | 3675/4096 [00:29<00:04, 98.50it/s, est. speed input: 127397.24 toks/s, output: 124.41 toks/s]
Processed prompts:  91%|█████████ | 3707/4096 [00:29<00:03, 98.48it/s, est. speed input: 127107.48 toks/s, output: 124.13 toks/s]
Processed prompts:  91%|█████████▏| 3739/4096 [00:30<00:03, 99.10it/s, est. speed input: 126853.18 toks/s, output: 123.88 toks/s]
Processed prompts:  92%|█████████▏| 3771/4096 [00:30<00:03, 98.95it/s, est. speed input: 126577.91 toks/s, output: 123.61 toks/s]
Processed prompts:  93%|█████████▎| 3803/4096 [00:30<00:02, 98.70it/s, est. speed input: 126302.01 toks/s, output: 123.34 toks/s]
Processed prompts:  94%|█████████▎| 3835/4096 [00:31<00:02, 99.18it/s, est. speed input: 126060.43 toks/s, output: 123.11 toks/s]
Processed prompts:  94%|█████████▍| 3867/4096 [00:31<00:02, 98.82it/s, est. speed input: 125793.85 toks/s, output: 122.85 toks/s]
Processed prompts:  95%|█████████▌| 3899/4096 [00:31<00:01, 98.72it/s, est. speed input: 125538.74 toks/s, output: 122.60 toks/s]
Processed prompts:  96%|█████████▌| 3931/4096 [00:32<00:01, 98.64it/s, est. speed input: 125288.65 toks/s, output: 122.35 toks/s]
Processed prompts:  97%|█████████▋| 3963/4096 [00:32<00:01, 98.55it/s, est. speed input: 125042.28 toks/s, output: 122.11 toks/s]
Processed prompts:  98%|█████████▊| 3995/4096 [00:32<00:01, 98.34it/s, est. speed input: 124794.24 toks/s, output: 121.87 toks/s]
Processed prompts:  98%|█████████▊| 4027/4096 [00:33<00:00, 99.11it/s, est. speed input: 124589.05 toks/s, output: 121.67 toks/s]
Processed prompts:  99%|█████████▉| 4059/4096 [00:33<00:00, 99.19it/s, est. speed input: 124369.07 toks/s, output: 121.45 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:33<00:00, 99.19it/s, est. speed input: 125247.23 toks/s, output: 122.31 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:33<00:00, 122.31it/s, est. speed input: 125247.23 toks/s, output: 122.31 toks/s]
[rank0]:[W128 09:16:24.507104356 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

