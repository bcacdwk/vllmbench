
========== M=16 ==========
Time: 2026-01-25 22:10:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:10:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=500346) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=500346) WARNING 01-25 22:11:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.61 requests/s, 520.30 total tokens/s, 30.61 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-25 22:10:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:10:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 22:10:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:10:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 22:10:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:10:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:10:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:11:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:11:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 22:11:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 22:11:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 22:11:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:11:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:11:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:11:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:11:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=500346) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=500346) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.76it/s]
(EngineCore_DP0 pid=500346) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.75it/s]
(EngineCore_DP0 pid=500346) 
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=500346) [2026-01-25 22:11:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=500346) 2026-01-25 22:11:17,411 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=500346) 2026-01-25 22:11:17,451 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=500346) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]
(EngineCore_DP0 pid=500346) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 14.96it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2544.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:36,  3.48it/s, est. speed input: 55.77 toks/s, output: 3.49 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:08, 14.67it/s, est. speed input: 196.89 toks/s, output: 12.30 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 21.16it/s, est. speed input: 273.42 toks/s, output: 17.09 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 25.12it/s, est. speed input: 321.08 toks/s, output: 20.07 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 27.70it/s, est. speed input: 353.85 toks/s, output: 22.11 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 29.37it/s, est. speed input: 377.54 toks/s, output: 23.60 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 30.50it/s, est. speed input: 395.61 toks/s, output: 24.72 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 31.29it/s, est. speed input: 409.84 toks/s, output: 25.61 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 31.80it/s, est. speed input: 421.23 toks/s, output: 26.33 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.01it/s, est. speed input: 430.03 toks/s, output: 26.88 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.29it/s, est. speed input: 437.89 toks/s, output: 27.37 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.50it/s, est. speed input: 444.63 toks/s, output: 27.79 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.61it/s, est. speed input: 450.32 toks/s, output: 28.14 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.69it/s, est. speed input: 455.25 toks/s, output: 28.45 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.73it/s, est. speed input: 459.54 toks/s, output: 28.72 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.79it/s, est. speed input: 463.42 toks/s, output: 28.96 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.84it/s, est. speed input: 466.89 toks/s, output: 29.18 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.85it/s, est. speed input: 469.96 toks/s, output: 29.37 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.98it/s, est. speed input: 473.00 toks/s, output: 29.56 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.92it/s, est. speed input: 475.44 toks/s, output: 29.71 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.02it/s, est. speed input: 477.94 toks/s, output: 29.87 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.07it/s, est. speed input: 480.20 toks/s, output: 30.01 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.00it/s, est. speed input: 482.07 toks/s, output: 30.13 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.97it/s, est. speed input: 483.82 toks/s, output: 30.24 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.97it/s, est. speed input: 485.47 toks/s, output: 30.34 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.00it/s, est. speed input: 487.07 toks/s, output: 30.44 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.18it/s, est. speed input: 488.82 toks/s, output: 30.55 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.38it/s, est. speed input: 490.58 toks/s, output: 30.66 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.46it/s, est. speed input: 492.12 toks/s, output: 30.76 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.53it/s, est. speed input: 493.60 toks/s, output: 30.85 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.12it/s, est. speed input: 494.28 toks/s, output: 30.89 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 33.04it/s, est. speed input: 495.23 toks/s, output: 30.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 33.04it/s, est. speed input: 495.91 toks/s, output: 30.99 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.99it/s, est. speed input: 495.91 toks/s, output: 30.99 toks/s]
[rank0]:[W125 22:11:24.105285056 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 22:11:26
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M128.json


========== M=16 ==========
Time: 2026-01-26 07:52:18
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:52:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1003385) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1003385) WARNING 01-26 07:52:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.02 requests/s, 544.37 total tokens/s, 32.02 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 07:52:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:52:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:52:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:52:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:52:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:52:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:52:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:52:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:52:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:52:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:52:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:52:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1003385) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1003385) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.80it/s]
(EngineCore_DP0 pid=1003385) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.79it/s]
(EngineCore_DP0 pid=1003385) 
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1003385) [2026-01-26 07:52:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1003385) 2026-01-26 07:52:43,110 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1003385) 2026-01-26 07:52:43,147 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1003385) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
(EngineCore_DP0 pid=1003385) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 16.76it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 3987.90it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:29,  4.37it/s, est. speed input: 69.91 toks/s, output: 4.37 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 17.04it/s, est. speed input: 232.22 toks/s, output: 14.51 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 23.35it/s, est. speed input: 310.64 toks/s, output: 19.41 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 27.31it/s, est. speed input: 359.63 toks/s, output: 22.47 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 29.78it/s, est. speed input: 392.32 toks/s, output: 24.52 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 31.13it/s, est. speed input: 414.14 toks/s, output: 25.88 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.95it/s, est. speed input: 430.14 toks/s, output: 26.88 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 32.46it/s, est. speed input: 442.30 toks/s, output: 27.64 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.90it/s, est. speed input: 452.41 toks/s, output: 28.27 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 33.16it/s, est. speed input: 460.47 toks/s, output: 28.78 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 33.34it/s, est. speed input: 467.18 toks/s, output: 29.20 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 33.50it/s, est. speed input: 472.98 toks/s, output: 29.56 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 33.61it/s, est. speed input: 477.93 toks/s, output: 29.87 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 33.66it/s, est. speed input: 482.14 toks/s, output: 30.13 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 33.73it/s, est. speed input: 485.92 toks/s, output: 30.37 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 33.83it/s, est. speed input: 489.41 toks/s, output: 30.59 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 33.93it/s, est. speed input: 492.58 toks/s, output: 30.79 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.96it/s, est. speed input: 495.31 toks/s, output: 30.96 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 34.01it/s, est. speed input: 497.85 toks/s, output: 31.12 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 34.03it/s, est. speed input: 500.09 toks/s, output: 31.26 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 34.02it/s, est. speed input: 502.11 toks/s, output: 31.38 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 34.04it/s, est. speed input: 503.98 toks/s, output: 31.50 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 34.06it/s, est. speed input: 505.72 toks/s, output: 31.61 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 34.04it/s, est. speed input: 507.24 toks/s, output: 31.70 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 34.05it/s, est. speed input: 508.72 toks/s, output: 31.79 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 34.06it/s, est. speed input: 510.07 toks/s, output: 31.88 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 34.04it/s, est. speed input: 511.28 toks/s, output: 31.95 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 34.01it/s, est. speed input: 512.38 toks/s, output: 32.02 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 34.01it/s, est. speed input: 513.44 toks/s, output: 32.09 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 34.01it/s, est. speed input: 514.43 toks/s, output: 32.15 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.80it/s, est. speed input: 515.04 toks/s, output: 32.19 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.91it/s, est. speed input: 515.98 toks/s, output: 32.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.91it/s, est. speed input: 516.71 toks/s, output: 32.29 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.29it/s, est. speed input: 516.71 toks/s, output: 32.29 toks/s]
[rank0]:[W126 07:52:49.474933031 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 07:52:51
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:52:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1004389) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1004389) WARNING 01-26 07:53:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.40 requests/s, 4051.06 total tokens/s, 31.40 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 07:52:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:52:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:52:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:52:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:52:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:52:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:52:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:52:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:53:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:53:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:53:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:53:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:53:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:53:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1004389) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1004389) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.78it/s]
(EngineCore_DP0 pid=1004389) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.77it/s]
(EngineCore_DP0 pid=1004389) 
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1004389) [2026-01-26 07:53:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1004389) 2026-01-26 07:53:19,131 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1004389) 2026-01-26 07:53:19,201 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1004389) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.84it/s]
(EngineCore_DP0 pid=1004389) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.60it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1361.88it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:17,  7.07it/s, est. speed input: 905.85 toks/s, output: 7.08 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 21.32it/s, est. speed input: 2435.34 toks/s, output: 19.02 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 26.39it/s, est. speed input: 2994.42 toks/s, output: 23.39 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 28.87it/s, est. speed input: 3284.06 toks/s, output: 25.65 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 30.25it/s, est. speed input: 3460.57 toks/s, output: 27.03 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 31.10it/s, est. speed input: 3579.78 toks/s, output: 27.97 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:03, 31.64it/s, est. speed input: 3665.79 toks/s, output: 28.64 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:03, 31.98it/s, est. speed input: 3729.74 toks/s, output: 29.14 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 32.21it/s, est. speed input: 3779.63 toks/s, output: 29.53 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 32.40it/s, est. speed input: 3821.11 toks/s, output: 29.85 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 32.57it/s, est. speed input: 3856.82 toks/s, output: 30.13 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 32.71it/s, est. speed input: 3886.91 toks/s, output: 30.37 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.70it/s, est. speed input: 3909.51 toks/s, output: 30.54 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.72it/s, est. speed input: 3929.72 toks/s, output: 30.70 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:02, 32.71it/s, est. speed input: 3946.61 toks/s, output: 30.83 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 32.71it/s, est. speed input: 3961.32 toks/s, output: 30.95 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.72it/s, est. speed input: 3974.72 toks/s, output: 31.05 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 33.01it/s, est. speed input: 3992.97 toks/s, output: 31.19 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 33.24it/s, est. speed input: 4009.92 toks/s, output: 31.33 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 33.43it/s, est. speed input: 4025.59 toks/s, output: 31.45 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 33.51it/s, est. speed input: 4038.92 toks/s, output: 31.55 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 33.59it/s, est. speed input: 4051.52 toks/s, output: 31.65 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 33.56it/s, est. speed input: 4061.51 toks/s, output: 31.73 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:01, 33.52it/s, est. speed input: 4070.45 toks/s, output: 31.80 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 33.29it/s, est. speed input: 4075.33 toks/s, output: 31.84 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 33.17it/s, est. speed input: 4080.52 toks/s, output: 31.88 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 33.06it/s, est. speed input: 4084.86 toks/s, output: 31.91 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 33.11it/s, est. speed input: 4090.86 toks/s, output: 31.96 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 33.31it/s, est. speed input: 4098.68 toks/s, output: 32.02 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 33.49it/s, est. speed input: 4106.49 toks/s, output: 32.08 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 33.41it/s, est. speed input: 4111.18 toks/s, output: 32.12 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 33.25it/s, est. speed input: 4114.20 toks/s, output: 32.14 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.25it/s, est. speed input: 4116.53 toks/s, output: 32.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.16it/s, est. speed input: 4116.53 toks/s, output: 32.16 toks/s]
[rank0]:[W126 07:53:25.257301391 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 07:53:27
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:53:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1005415) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1005415) WARNING 01-26 07:53:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.03 requests/s, 7460.23 total tokens/s, 29.03 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 07:53:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:53:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:53:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:53:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:53:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:53:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:53:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:53:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 07:53:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 07:53:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:53:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:53:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:53:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:53:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1005415) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1005415) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.76it/s]
(EngineCore_DP0 pid=1005415) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.75it/s]
(EngineCore_DP0 pid=1005415) 
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1005415) [2026-01-26 07:53:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1005415) 2026-01-26 07:53:55,003 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1005415) 2026-01-26 07:53:55,033 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1005415) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.88it/s]
(EngineCore_DP0 pid=1005415) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.45it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  62%|██████▎   | 80/128 [00:00<00:00, 798.42it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 980.95it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:44,  2.86it/s, est. speed input: 732.60 toks/s, output: 2.86 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.83it/s, est. speed input: 2716.17 toks/s, output: 10.61 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 19.26it/s, est. speed input: 3883.29 toks/s, output: 15.17 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 23.56it/s, est. speed input: 4656.64 toks/s, output: 18.19 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 26.46it/s, est. speed input: 5204.04 toks/s, output: 20.33 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 28.21it/s, est. speed input: 5593.78 toks/s, output: 21.85 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 29.47it/s, est. speed input: 5899.81 toks/s, output: 23.05 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:03, 30.35it/s, est. speed input: 6143.30 toks/s, output: 24.00 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 30.98it/s, est. speed input: 6343.43 toks/s, output: 24.78 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 31.41it/s, est. speed input: 6509.20 toks/s, output: 25.43 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 31.75it/s, est. speed input: 6650.94 toks/s, output: 25.98 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 31.97it/s, est. speed input: 6771.35 toks/s, output: 26.45 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 32.15it/s, est. speed input: 6876.78 toks/s, output: 26.86 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:02, 32.16it/s, est. speed input: 6963.70 toks/s, output: 27.20 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 32.25it/s, est. speed input: 7043.57 toks/s, output: 27.51 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 32.45it/s, est. speed input: 7120.57 toks/s, output: 27.81 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 32.37it/s, est. speed input: 7180.50 toks/s, output: 28.05 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 32.29it/s, est. speed input: 7233.62 toks/s, output: 28.26 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 32.26it/s, est. speed input: 7282.34 toks/s, output: 28.45 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 32.23it/s, est. speed input: 7326.10 toks/s, output: 28.62 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 32.23it/s, est. speed input: 7367.07 toks/s, output: 28.78 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 32.24it/s, est. speed input: 7404.65 toks/s, output: 28.92 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 32.18it/s, est. speed input: 7437.04 toks/s, output: 29.05 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 32.18it/s, est. speed input: 7468.32 toks/s, output: 29.17 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:03<00:00, 32.19it/s, est. speed input: 7497.73 toks/s, output: 29.29 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 32.19it/s, est. speed input: 7524.41 toks/s, output: 29.39 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 32.15it/s, est. speed input: 7548.32 toks/s, output: 29.49 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 32.18it/s, est. speed input: 7572.20 toks/s, output: 29.58 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 32.16it/s, est. speed input: 7593.25 toks/s, output: 29.66 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 32.11it/s, est. speed input: 7612.34 toks/s, output: 29.74 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:04<00:00, 32.10it/s, est. speed input: 7630.68 toks/s, output: 29.81 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:04<00:00, 32.11it/s, est. speed input: 7648.38 toks/s, output: 29.88 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 32.11it/s, est. speed input: 7661.18 toks/s, output: 29.93 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 29.92it/s, est. speed input: 7661.18 toks/s, output: 29.93 toks/s]
[rank0]:[W126 07:54:01.865127149 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:46:32
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:46:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1082852) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1082852) WARNING 01-26 08:46:53 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.82 requests/s, 16325.51 total tokens/s, 31.82 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:46:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:46:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:46:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:46:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:46:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:46:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:46:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:46:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:46:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:46:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:46:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:46:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:46:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:46:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:46:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:46:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:46:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1082852) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1082852) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.77it/s]
(EngineCore_DP0 pid=1082852) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.77it/s]
(EngineCore_DP0 pid=1082852) 
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1082852) [2026-01-26 08:46:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1082852) 2026-01-26 08:47:00,392 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1082852) 2026-01-26 08:47:00,422 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1082852) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 14.81it/s]
(EngineCore_DP0 pid=1082852) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.65it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  52%|█████▏    | 67/128 [00:00<00:00, 663.66it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 765.69it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 47.58it/s, est. speed input: 24362.39 toks/s, output: 47.58 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 38.27it/s, est. speed input: 20244.94 toks/s, output: 39.54 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 36.04it/s, est. speed input: 19221.60 toks/s, output: 37.54 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:03, 34.83it/s, est. speed input: 18653.68 toks/s, output: 36.43 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:03, 34.14it/s, est. speed input: 18308.22 toks/s, output: 35.76 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:03, 33.62it/s, est. speed input: 18046.25 toks/s, output: 35.25 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 33.36it/s, est. speed input: 17875.68 toks/s, output: 34.91 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:02, 33.18it/s, est. speed input: 17744.27 toks/s, output: 34.66 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:02, 33.00it/s, est. speed input: 17630.24 toks/s, output: 34.43 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:02, 32.96it/s, est. speed input: 17553.31 toks/s, output: 34.28 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:02, 32.94it/s, est. speed input: 17489.76 toks/s, output: 34.16 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:02, 32.83it/s, est. speed input: 17424.04 toks/s, output: 34.03 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:01<00:02, 32.76it/s, est. speed input: 17367.82 toks/s, output: 33.92 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:01<00:02, 32.73it/s, est. speed input: 17322.62 toks/s, output: 33.83 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:01<00:01, 32.66it/s, est. speed input: 17278.15 toks/s, output: 33.75 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 32.63it/s, est. speed input: 17239.75 toks/s, output: 33.67 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:01, 32.62it/s, est. speed input: 17208.03 toks/s, output: 33.61 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:02<00:01, 32.62it/s, est. speed input: 17180.12 toks/s, output: 33.55 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:01, 32.65it/s, est. speed input: 17157.79 toks/s, output: 33.51 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:02<00:01, 32.62it/s, est. speed input: 17133.32 toks/s, output: 33.46 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:01, 32.57it/s, est. speed input: 17108.99 toks/s, output: 33.42 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:01, 32.56it/s, est. speed input: 17088.95 toks/s, output: 33.38 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:02<00:01, 32.57it/s, est. speed input: 17071.56 toks/s, output: 33.34 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:02<00:00, 32.59it/s, est. speed input: 17056.62 toks/s, output: 33.31 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:03<00:00, 32.57it/s, est. speed input: 17040.71 toks/s, output: 33.28 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:03<00:00, 32.57it/s, est. speed input: 17026.96 toks/s, output: 33.26 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:03<00:00, 32.59it/s, est. speed input: 17015.06 toks/s, output: 33.23 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:03<00:00, 32.64it/s, est. speed input: 17006.81 toks/s, output: 33.22 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:03<00:00, 32.78it/s, est. speed input: 17004.97 toks/s, output: 33.21 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:03<00:00, 32.92it/s, est. speed input: 17005.23 toks/s, output: 33.21 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 33.03it/s, est. speed input: 17006.66 toks/s, output: 33.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.03it/s, est. speed input: 17007.59 toks/s, output: 33.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 33.22it/s, est. speed input: 17007.59 toks/s, output: 33.22 toks/s]
[rank0]:[W126 08:47:06.681201166 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:47:08
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:47:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1083905) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1083905) WARNING 01-26 08:47:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.63 requests/s, 32418.93 total tokens/s, 31.63 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:47:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:47:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:47:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:47:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:47:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:47:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:47:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:47:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:47:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:47:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:47:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:47:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1083905) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1083905) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.69it/s]
(EngineCore_DP0 pid=1083905) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.68it/s]
(EngineCore_DP0 pid=1083905) 
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1083905) [2026-01-26 08:47:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1083905) 2026-01-26 08:47:37,828 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1083905) 2026-01-26 08:47:37,866 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1083905) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  5.30it/s]
(EngineCore_DP0 pid=1083905) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 18.25it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 245.84it/s]
Adding requests:  59%|█████▉    | 76/128 [00:00<00:00, 398.56it/s]
Adding requests:  99%|█████████▉| 127/128 [00:00<00:00, 445.89it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 417.94it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 70.19it/s, est. speed input: 71883.20 toks/s, output: 70.19 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:02, 42.74it/s, est. speed input: 46501.74 toks/s, output: 45.41 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 38.97it/s, est. speed input: 42816.15 toks/s, output: 41.81 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 36.71it/s, est. speed input: 40679.82 toks/s, output: 39.72 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 35.58it/s, est. speed input: 39582.33 toks/s, output: 38.65 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 34.65it/s, est. speed input: 38717.60 toks/s, output: 37.81 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:02, 34.21it/s, est. speed input: 38153.55 toks/s, output: 37.26 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 33.79it/s, est. speed input: 37665.36 toks/s, output: 36.78 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 33.70it/s, est. speed input: 37348.09 toks/s, output: 36.47 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 33.61it/s, est. speed input: 37073.78 toks/s, output: 36.20 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:02, 33.61it/s, est. speed input: 36863.31 toks/s, output: 36.00 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:02, 33.59it/s, est. speed input: 36677.76 toks/s, output: 35.82 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 33.54it/s, est. speed input: 36508.92 toks/s, output: 35.65 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 33.42it/s, est. speed input: 36342.18 toks/s, output: 35.49 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 33.31it/s, est. speed input: 36190.63 toks/s, output: 35.34 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:02<00:01, 33.24it/s, est. speed input: 36056.83 toks/s, output: 35.21 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 33.17it/s, est. speed input: 35934.42 toks/s, output: 35.09 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 33.12it/s, est. speed input: 35823.13 toks/s, output: 34.98 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 33.11it/s, est. speed input: 35727.73 toks/s, output: 34.89 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 33.14it/s, est. speed input: 35647.59 toks/s, output: 34.81 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:01, 33.11it/s, est. speed input: 35565.97 toks/s, output: 34.73 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 33.09it/s, est. speed input: 35492.70 toks/s, output: 34.66 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 33.17it/s, est. speed input: 35438.51 toks/s, output: 34.61 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:03<00:00, 33.16it/s, est. speed input: 35378.53 toks/s, output: 34.55 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:03<00:00, 33.12it/s, est. speed input: 35319.35 toks/s, output: 34.49 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 32.97it/s, est. speed input: 35248.85 toks/s, output: 34.42 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 32.92it/s, est. speed input: 35190.33 toks/s, output: 34.37 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 32.89it/s, est. speed input: 35135.98 toks/s, output: 34.31 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 32.81it/s, est. speed input: 35078.93 toks/s, output: 34.26 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 32.81it/s, est. speed input: 35057.02 toks/s, output: 34.24 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.23it/s, est. speed input: 35057.02 toks/s, output: 34.24 toks/s]
[rank0]:[W126 08:47:44.302231232 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:47:46
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:47:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1084989) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1084989) WARNING 01-26 08:48:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 60.09 requests/s, 61593.09 total tokens/s, 60.09 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:47:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:47:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:47:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:47:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:47:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:47:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:48:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:48:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:48:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:48:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:48:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:48:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1084989) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1084989) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.74it/s]
(EngineCore_DP0 pid=1084989) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.74it/s]
(EngineCore_DP0 pid=1084989) 
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1084989) [2026-01-26 08:48:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1084989) 2026-01-26 08:48:14,821 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1084989) 2026-01-26 08:48:14,890 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1084989) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 15.28it/s]
(EngineCore_DP0 pid=1084989) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 19.57it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 28/256 [00:00<00:00, 279.81it/s]
Adding requests:  31%|███▏      | 80/256 [00:00<00:00, 417.02it/s]
Adding requests:  51%|█████     | 131/256 [00:00<00:00, 455.28it/s]
Adding requests:  70%|███████   | 180/256 [00:00<00:00, 467.75it/s]
Adding requests:  90%|████████▉ | 230/256 [00:00<00:00, 478.59it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 460.16it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 180.08it/s, est. speed input: 184464.71 toks/s, output: 180.10 toks/s]
Processed prompts:  16%|█▌        | 41/256 [00:00<00:02, 95.51it/s, est. speed input: 105807.01 toks/s, output: 103.32 toks/s] 
Processed prompts:  21%|██        | 53/256 [00:00<00:02, 82.77it/s, est. speed input: 93477.55 toks/s, output: 91.28 toks/s]  
Processed prompts:  25%|██▍       | 63/256 [00:00<00:02, 76.91it/s, est. speed input: 87905.75 toks/s, output: 85.84 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:00<00:02, 71.05it/s, est. speed input: 83123.60 toks/s, output: 81.17 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:01<00:02, 69.61it/s, est. speed input: 81209.00 toks/s, output: 79.30 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:01<00:02, 68.37it/s, est. speed input: 79639.28 toks/s, output: 77.77 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:01<00:02, 67.51it/s, est. speed input: 78395.15 toks/s, output: 76.56 toks/s]
Processed prompts:  41%|████      | 104/256 [00:01<00:02, 67.27it/s, est. speed input: 77511.40 toks/s, output: 75.69 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:01<00:02, 66.95it/s, est. speed input: 76720.55 toks/s, output: 74.92 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:01<00:02, 66.36it/s, est. speed input: 75943.25 toks/s, output: 74.16 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:01<00:01, 65.93it/s, est. speed input: 75275.24 toks/s, output: 73.51 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:01<00:01, 65.76it/s, est. speed input: 74725.42 toks/s, output: 72.97 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:01<00:01, 65.56it/s, est. speed input: 74227.68 toks/s, output: 72.49 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:02<00:01, 65.41it/s, est. speed input: 73783.22 toks/s, output: 72.05 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:02<00:01, 65.32it/s, est. speed input: 73391.22 toks/s, output: 71.67 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:02<00:01, 65.32it/s, est. speed input: 73054.24 toks/s, output: 71.34 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:02<00:01, 65.36it/s, est. speed input: 72756.59 toks/s, output: 71.05 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:02<00:01, 65.31it/s, est. speed input: 72472.10 toks/s, output: 70.77 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:02<00:00, 65.33it/s, est. speed input: 72225.27 toks/s, output: 70.53 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:02<00:00, 65.30it/s, est. speed input: 71990.90 toks/s, output: 70.30 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:02<00:00, 65.31it/s, est. speed input: 71780.74 toks/s, output: 70.10 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:03<00:00, 65.24it/s, est. speed input: 71575.83 toks/s, output: 69.90 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:03<00:00, 65.28it/s, est. speed input: 71399.57 toks/s, output: 69.73 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:03<00:00, 65.32it/s, est. speed input: 71237.51 toks/s, output: 69.57 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:03<00:00, 65.34it/s, est. speed input: 71085.74 toks/s, output: 69.42 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:03<00:00, 65.32it/s, est. speed input: 70939.92 toks/s, output: 69.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.37it/s, est. speed input: 70812.78 toks/s, output: 69.15 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 65.37it/s, est. speed input: 70812.78 toks/s, output: 69.15 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 69.15it/s, est. speed input: 70812.78 toks/s, output: 69.15 toks/s]
[rank0]:[W126 08:48:21.340181496 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:48:23
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:48:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1086058) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1086058) WARNING 01-26 08:48:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 111.00 requests/s, 113774.06 total tokens/s, 111.00 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:48:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:48:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:48:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:48:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:48:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:48:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:48:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:48:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:48:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:48:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:48:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:48:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:48:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:48:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1086058) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1086058) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.98it/s]
(EngineCore_DP0 pid=1086058) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.98it/s]
(EngineCore_DP0 pid=1086058) 
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1086058) [2026-01-26 08:48:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1086058) 2026-01-26 08:48:53,706 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1086058) 2026-01-26 08:48:53,737 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1086058) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00, 15.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 16.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 16.19it/s]
(EngineCore_DP0 pid=1086058) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.90it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  5.56it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  6.79it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 235.76it/s]
Adding requests:  13%|█▎        | 69/512 [00:00<00:01, 358.12it/s]
Adding requests:  23%|██▎       | 119/512 [00:00<00:00, 422.32it/s]
Adding requests:  33%|███▎      | 168/512 [00:00<00:00, 446.71it/s]
Adding requests:  43%|████▎     | 218/512 [00:00<00:00, 463.35it/s]
Adding requests:  53%|█████▎    | 270/512 [00:00<00:00, 480.79it/s]
Adding requests:  62%|██████▏   | 319/512 [00:00<00:00, 480.85it/s]
Adding requests:  72%|███████▏  | 370/512 [00:00<00:00, 489.77it/s]
Adding requests:  82%|████████▏ | 421/512 [00:00<00:00, 494.56it/s]
Adding requests:  92%|█████████▏| 471/512 [00:01<00:00, 494.50it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 467.15it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:00<00:00, 609.77it/s, est. speed input: 624504.02 toks/s, output: 609.80 toks/s]
Processed prompts:  26%|██▋       | 135/512 [00:00<00:01, 205.12it/s, est. speed input: 235774.18 toks/s, output: 230.24 toks/s]
Processed prompts:  33%|███▎      | 168/512 [00:00<00:01, 177.71it/s, est. speed input: 206919.78 toks/s, output: 202.07 toks/s]
Processed prompts:  38%|███▊      | 192/512 [00:01<00:01, 163.99it/s, est. speed input: 193773.90 toks/s, output: 189.23 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:01<00:01, 155.04it/s, est. speed input: 185728.54 toks/s, output: 181.37 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:01<00:01, 144.42it/s, est. speed input: 177898.22 toks/s, output: 173.72 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:01<00:01, 140.70it/s, est. speed input: 173949.87 toks/s, output: 169.87 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:01<00:01, 137.53it/s, est. speed input: 170566.50 toks/s, output: 166.57 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:01<00:01, 135.12it/s, est. speed input: 167705.66 toks/s, output: 163.77 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:01<00:01, 133.23it/s, est. speed input: 165215.86 toks/s, output: 161.34 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:01<00:01, 131.86it/s, est. speed input: 163055.15 toks/s, output: 159.23 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:02<00:01, 130.76it/s, est. speed input: 161127.69 toks/s, output: 157.35 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:02<00:01, 128.79it/s, est. speed input: 159137.75 toks/s, output: 155.41 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:02<00:01, 128.78it/s, est. speed input: 157678.39 toks/s, output: 153.98 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:02<00:01, 128.54it/s, est. speed input: 156319.70 toks/s, output: 152.65 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:02<00:00, 128.46it/s, est. speed input: 155109.80 toks/s, output: 151.47 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:02<00:00, 128.41it/s, est. speed input: 154013.90 toks/s, output: 150.40 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:02<00:00, 128.42it/s, est. speed input: 153021.22 toks/s, output: 149.43 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:02<00:00, 128.42it/s, est. speed input: 152111.17 toks/s, output: 148.54 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:03<00:00, 127.61it/s, est. speed input: 151146.07 toks/s, output: 147.60 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:03<00:00, 127.83it/s, est. speed input: 150377.43 toks/s, output: 146.85 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:03<00:00, 127.92it/s, est. speed input: 149657.28 toks/s, output: 146.15 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:03<00:00, 128.01it/s, est. speed input: 148992.96 toks/s, output: 145.50 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 128.01it/s, est. speed input: 149174.13 toks/s, output: 145.68 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 145.67it/s, est. speed input: 149174.13 toks/s, output: 145.68 toks/s]
[rank0]:[W126 08:49:00.955924520 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:49:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:49:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1087150) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1087150) WARNING 01-26 08:49:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 166.81 requests/s, 170979.29 total tokens/s, 166.81 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:49:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:49:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:49:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:49:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:49:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:49:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:49:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:49:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:49:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:49:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:49:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:49:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:49:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:49:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:49:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:49:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:49:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1087150) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1087150) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.48it/s]
(EngineCore_DP0 pid=1087150) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.47it/s]
(EngineCore_DP0 pid=1087150) 
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1087150) [2026-01-26 08:49:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1087150) 2026-01-26 08:49:35,231 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1087150) 2026-01-26 08:49:35,294 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1087150) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 14.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 13.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 13.22it/s]
(EngineCore_DP0 pid=1087150) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 13.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.32it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 30/1024 [00:00<00:03, 299.91it/s]
Adding requests:   8%|▊         | 81/1024 [00:00<00:02, 420.36it/s]
Adding requests:  13%|█▎        | 131/1024 [00:00<00:01, 453.11it/s]
Adding requests:  17%|█▋        | 179/1024 [00:00<00:01, 461.16it/s]
Adding requests:  22%|██▏       | 230/1024 [00:00<00:01, 476.16it/s]
Adding requests:  27%|██▋       | 279/1024 [00:00<00:01, 480.63it/s]
Adding requests:  32%|███▏      | 328/1024 [00:00<00:01, 480.41it/s]
Adding requests:  37%|███▋      | 379/1024 [00:00<00:01, 487.83it/s]
Adding requests:  42%|████▏     | 429/1024 [00:00<00:01, 490.31it/s]
Adding requests:  47%|████▋     | 479/1024 [00:01<00:01, 491.08it/s]
Adding requests:  52%|█████▏    | 529/1024 [00:01<00:01, 473.46it/s]
Adding requests:  57%|█████▋    | 580/1024 [00:01<00:00, 482.33it/s]
Adding requests:  62%|██████▏   | 631/1024 [00:01<00:00, 487.83it/s]
Adding requests:  67%|██████▋   | 683/1024 [00:01<00:00, 495.16it/s]
Adding requests:  72%|███████▏  | 734/1024 [00:01<00:00, 498.52it/s]
Adding requests:  77%|███████▋  | 784/1024 [00:01<00:00, 493.66it/s]
Adding requests:  81%|████████▏ | 834/1024 [00:01<00:00, 484.07it/s]
Adding requests:  86%|████████▋ | 885/1024 [00:01<00:00, 490.50it/s]
Adding requests:  91%|█████████▏| 936/1024 [00:01<00:00, 493.99it/s]
Adding requests:  96%|█████████▋| 986/1024 [00:02<00:00, 495.55it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 483.03it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:00<00:00, 1942.85it/s, est. speed input: 1989754.47 toks/s, output: 1942.93 toks/s]
Processed prompts:  45%|████▌     | 461/1024 [00:01<00:01, 305.00it/s, est. speed input: 365682.65 toks/s, output: 357.11 toks/s]   
Processed prompts:  54%|█████▍    | 551/1024 [00:01<00:01, 273.61it/s, est. speed input: 327998.15 toks/s, output: 320.31 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:02<00:01, 251.72it/s, est. speed input: 307109.26 toks/s, output: 299.91 toks/s]
Processed prompts:  64%|██████▍   | 653/1024 [00:02<00:01, 245.88it/s, est. speed input: 299954.06 toks/s, output: 292.92 toks/s]
Processed prompts:  67%|██████▋   | 689/1024 [00:02<00:01, 243.20it/s, est. speed input: 295769.24 toks/s, output: 288.84 toks/s]
Processed prompts:  70%|███████   | 721/1024 [00:02<00:01, 235.62it/s, est. speed input: 290515.95 toks/s, output: 283.71 toks/s]
Processed prompts:  73%|███████▎  | 749/1024 [00:02<00:01, 222.95it/s, est. speed input: 284272.12 toks/s, output: 277.61 toks/s]
Processed prompts:  76%|███████▌  | 774/1024 [00:02<00:01, 220.76it/s, est. speed input: 281437.96 toks/s, output: 274.84 toks/s]
Processed prompts:  78%|███████▊  | 798/1024 [00:02<00:01, 217.03it/s, est. speed input: 278502.01 toks/s, output: 271.97 toks/s]
Processed prompts:  80%|████████  | 821/1024 [00:03<00:00, 211.68it/s, est. speed input: 275423.98 toks/s, output: 268.97 toks/s]
Processed prompts:  82%|████████▏ | 843/1024 [00:03<00:00, 205.51it/s, est. speed input: 272314.95 toks/s, output: 265.93 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:03<00:00, 203.39it/s, est. speed input: 269830.68 toks/s, output: 263.50 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:03<00:00, 203.87it/s, est. speed input: 267776.09 toks/s, output: 261.50 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:03<00:00, 204.36it/s, est. speed input: 265878.74 toks/s, output: 259.64 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:03<00:00, 206.25it/s, est. speed input: 264323.71 toks/s, output: 258.13 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:03<00:00, 205.87it/s, est. speed input: 262623.60 toks/s, output: 256.47 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:03<00:00, 207.94it/s, est. speed input: 261327.90 toks/s, output: 255.20 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:03<00:00, 207.23it/s, est. speed input: 259837.33 toks/s, output: 253.75 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 207.23it/s, est. speed input: 261068.43 toks/s, output: 254.95 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:04<00:00, 254.93it/s, est. speed input: 261068.43 toks/s, output: 254.95 toks/s]
[rank0]:[W126 08:49:44.009421489 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:49:46
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:50:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1088358) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1088358) WARNING 01-26 08:50:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 209.17 requests/s, 214401.29 total tokens/s, 209.17 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:50:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:50:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:50:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:50:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:50:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:50:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:50:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:50:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:50:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:50:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:50:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:50:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:50:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:50:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:50:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:50:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:50:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1088358) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1088358) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.74it/s]
(EngineCore_DP0 pid=1088358) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.73it/s]
(EngineCore_DP0 pid=1088358) 
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1088358) [2026-01-26 08:50:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1088358) 2026-01-26 08:50:22,375 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1088358) 2026-01-26 08:50:22,475 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1088358) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 14.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 18.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 18.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 17.89it/s]
(EngineCore_DP0 pid=1088358) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 20.50it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.26it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 32/2048 [00:00<00:06, 315.57it/s]
Adding requests:   4%|▍         | 83/2048 [00:00<00:04, 427.23it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:04, 457.83it/s]
Adding requests:   9%|▉         | 182/2048 [00:00<00:03, 467.76it/s]
Adding requests:  11%|█▏        | 233/2048 [00:00<00:03, 482.60it/s]
Adding requests:  14%|█▍        | 283/2048 [00:00<00:03, 488.12it/s]
Adding requests:  16%|█▋        | 333/2048 [00:00<00:03, 488.93it/s]
Adding requests:  19%|█▊        | 383/2048 [00:00<00:03, 490.53it/s]
Adding requests:  21%|██        | 433/2048 [00:00<00:03, 492.98it/s]
Adding requests:  24%|██▎       | 483/2048 [00:01<00:03, 492.56it/s]
Adding requests:  26%|██▌       | 533/2048 [00:01<00:03, 480.72it/s]
Adding requests:  29%|██▊       | 584/2048 [00:01<00:02, 488.24it/s]
Adding requests:  31%|███       | 634/2048 [00:01<00:02, 490.92it/s]
Adding requests:  33%|███▎      | 685/2048 [00:01<00:02, 496.34it/s]
Adding requests:  36%|███▌      | 736/2048 [00:01<00:02, 499.87it/s]
Adding requests:  38%|███▊      | 787/2048 [00:01<00:02, 495.28it/s]
Adding requests:  41%|████      | 837/2048 [00:01<00:02, 472.59it/s]
Adding requests:  43%|████▎     | 889/2048 [00:01<00:02, 484.95it/s]
Adding requests:  46%|████▌     | 940/2048 [00:01<00:02, 490.68it/s]
Adding requests:  48%|████▊     | 991/2048 [00:02<00:02, 495.28it/s]
Adding requests:  51%|█████     | 1042/2048 [00:02<00:02, 498.09it/s]
Adding requests:  53%|█████▎    | 1092/2048 [00:02<00:01, 496.30it/s]
Adding requests:  56%|█████▌    | 1142/2048 [00:02<00:01, 494.77it/s]
Adding requests:  58%|█████▊    | 1196/2048 [00:02<00:01, 506.18it/s]
Adding requests:  61%|██████    | 1247/2048 [00:02<00:01, 503.29it/s]
Adding requests:  63%|██████▎   | 1298/2048 [00:02<00:01, 491.45it/s]
Adding requests:  66%|██████▌   | 1350/2048 [00:02<00:01, 499.37it/s]
Adding requests:  68%|██████▊   | 1402/2048 [00:02<00:01, 504.07it/s]
Adding requests:  71%|███████   | 1453/2048 [00:02<00:01, 504.59it/s]
Adding requests:  74%|███████▎  | 1506/2048 [00:03<00:01, 507.84it/s]
Adding requests:  76%|███████▌  | 1557/2048 [00:03<00:00, 503.86it/s]
Adding requests:  79%|███████▊  | 1609/2048 [00:03<00:00, 508.31it/s]
Adding requests:  81%|████████  | 1660/2048 [00:03<00:00, 505.71it/s]
Adding requests:  84%|████████▎ | 1711/2048 [00:03<00:00, 505.63it/s]
Adding requests:  86%|████████▌ | 1762/2048 [00:03<00:00, 506.76it/s]
Adding requests:  89%|████████▊ | 1813/2048 [00:03<00:00, 506.78it/s]
Adding requests:  91%|█████████ | 1864/2048 [00:03<00:00, 501.43it/s]
Adding requests:  94%|█████████▎| 1916/2048 [00:03<00:00, 504.00it/s]
Adding requests:  96%|█████████▌| 1967/2048 [00:03<00:00, 483.53it/s]
Adding requests:  99%|█████████▊| 2018/2048 [00:04<00:00, 489.29it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 492.41it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:00<00:00, 5537.25it/s, est. speed input: 5670935.26 toks/s, output: 5537.49 toks/s]
Processed prompts:  69%|██████▉   | 1420/2048 [00:02<00:01, 437.90it/s, est. speed input: 539272.67 toks/s, output: 526.63 toks/s]  
Processed prompts:  81%|████████  | 1661/2048 [00:03<00:01, 353.78it/s, est. speed input: 445414.74 toks/s, output: 434.97 toks/s]
Processed prompts:  88%|████████▊ | 1802/2048 [00:04<00:00, 318.00it/s, est. speed input: 410379.99 toks/s, output: 400.76 toks/s]
Processed prompts:  93%|█████████▎| 1896/2048 [00:04<00:00, 297.64it/s, est. speed input: 392661.63 toks/s, output: 383.46 toks/s]
Processed prompts:  96%|█████████▌| 1964/2048 [00:05<00:00, 287.11it/s, est. speed input: 383623.19 toks/s, output: 374.63 toks/s]
Processed prompts:  98%|█████████▊| 2017/2048 [00:05<00:00, 276.82it/s, est. speed input: 376553.61 toks/s, output: 367.73 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:05<00:00, 276.82it/s, est. speed input: 372549.88 toks/s, output: 363.82 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:05<00:00, 363.80it/s, est. speed input: 372549.88 toks/s, output: 363.82 toks/s]
[rank0]:[W126 08:50:35.215172984 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:50:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:51:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1089744) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1089744) WARNING 01-26 08:51:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 217.85 requests/s, 223293.41 total tokens/s, 217.85 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:51:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:51:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:51:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:51:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1089744) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1089744) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.77it/s]
(EngineCore_DP0 pid=1089744) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.77it/s]
(EngineCore_DP0 pid=1089744) 
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1089744) [2026-01-26 08:51:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1089744) [rank0]:W0126 08:51:19.223000 1089744 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1089744) [rank0]:W0126 08:51:19.277000 1089744 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1089744) [rank0]:W0126 08:51:19.912000 1089744 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1089744) [rank0]:W0126 08:51:19.987000 1089744 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1089744) 2026-01-26 08:51:23,037 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1089744) 2026-01-26 08:51:23,070 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1089744) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 13.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:01,  6.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:01<00:01,  4.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  6.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  7.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  9.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.50it/s]
(EngineCore_DP0 pid=1089744) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 18.94it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 20.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 20.17it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 31/4096 [00:00<00:13, 307.26it/s]
Adding requests:   2%|▏         | 82/4096 [00:00<00:09, 422.41it/s]
Adding requests:   3%|▎         | 132/4096 [00:00<00:08, 456.59it/s]
Adding requests:   4%|▍         | 181/4096 [00:00<00:08, 466.69it/s]
Adding requests:   6%|▌         | 232/4096 [00:00<00:08, 479.91it/s]
Adding requests:   7%|▋         | 282/4096 [00:00<00:07, 486.46it/s]
Adding requests:   8%|▊         | 331/4096 [00:00<00:07, 486.71it/s]
Adding requests:   9%|▉         | 382/4096 [00:00<00:07, 492.95it/s]
Adding requests:  11%|█         | 433/4096 [00:00<00:07, 496.62it/s]
Adding requests:  12%|█▏        | 483/4096 [00:01<00:07, 497.48it/s]
Adding requests:  13%|█▎        | 533/4096 [00:01<00:07, 486.27it/s]
Adding requests:  14%|█▍        | 585/4096 [00:01<00:07, 494.61it/s]
Adding requests:  16%|█▌        | 636/4096 [00:01<00:06, 497.93it/s]
Adding requests:  17%|█▋        | 688/4096 [00:01<00:06, 503.18it/s]
Adding requests:  18%|█▊        | 740/4096 [00:01<00:06, 505.11it/s]
Adding requests:  19%|█▉        | 791/4096 [00:01<00:06, 500.46it/s]
Adding requests:  21%|██        | 842/4096 [00:01<00:06, 492.30it/s]
Adding requests:  22%|██▏       | 894/4096 [00:01<00:06, 499.42it/s]
Adding requests:  23%|██▎       | 945/4096 [00:01<00:06, 501.27it/s]
Adding requests:  24%|██▍       | 996/4096 [00:02<00:06, 502.43it/s]
Adding requests:  26%|██▌       | 1047/4096 [00:02<00:06, 493.38it/s]
Adding requests:  27%|██▋       | 1097/4096 [00:02<00:06, 490.68it/s]
Adding requests:  28%|██▊       | 1147/4096 [00:02<00:06, 491.08it/s]
Adding requests:  29%|██▉       | 1201/4096 [00:02<00:05, 503.02it/s]
Adding requests:  31%|███       | 1252/4096 [00:02<00:05, 501.86it/s]
Adding requests:  32%|███▏      | 1303/4096 [00:02<00:05, 502.45it/s]
Adding requests:  33%|███▎      | 1354/4096 [00:02<00:05, 504.57it/s]
Adding requests:  34%|███▍      | 1407/4096 [00:02<00:05, 510.71it/s]
Adding requests:  36%|███▌      | 1459/4096 [00:02<00:05, 508.89it/s]
Adding requests:  37%|███▋      | 1512/4096 [00:03<00:05, 512.14it/s]
Adding requests:  38%|███▊      | 1564/4096 [00:03<00:04, 512.49it/s]
Adding requests:  39%|███▉      | 1616/4096 [00:03<00:04, 513.69it/s]
Adding requests:  41%|████      | 1668/4096 [00:03<00:04, 510.08it/s]
Adding requests:  42%|████▏     | 1720/4096 [00:03<00:04, 511.91it/s]
Adding requests:  43%|████▎     | 1772/4096 [00:03<00:04, 509.99it/s]
Adding requests:  45%|████▍     | 1824/4096 [00:03<00:04, 509.79it/s]
Adding requests:  46%|████▌     | 1875/4096 [00:03<00:04, 507.77it/s]
Adding requests:  47%|████▋     | 1926/4096 [00:03<00:04, 507.24it/s]
Adding requests:  48%|████▊     | 1977/4096 [00:03<00:04, 506.38it/s]
Adding requests:  50%|████▉     | 2029/4096 [00:04<00:04, 509.55it/s]
Adding requests:  51%|█████     | 2081/4096 [00:04<00:03, 511.60it/s]
Adding requests:  52%|█████▏    | 2133/4096 [00:04<00:03, 507.40it/s]
Adding requests:  53%|█████▎    | 2184/4096 [00:04<00:03, 488.26it/s]
Adding requests:  55%|█████▍    | 2234/4096 [00:04<00:03, 491.61it/s]
Adding requests:  56%|█████▌    | 2285/4096 [00:04<00:03, 495.94it/s]
Adding requests:  57%|█████▋    | 2336/4096 [00:04<00:03, 498.12it/s]
Adding requests:  58%|█████▊    | 2388/4096 [00:04<00:03, 502.93it/s]
Adding requests:  60%|█████▉    | 2439/4096 [00:04<00:03, 503.86it/s]
Adding requests:  61%|██████    | 2491/4096 [00:04<00:03, 506.83it/s]
Adding requests:  62%|██████▏   | 2542/4096 [00:05<00:03, 504.89it/s]
Adding requests:  63%|██████▎   | 2594/4096 [00:05<00:02, 506.95it/s]
Adding requests:  65%|██████▍   | 2645/4096 [00:05<00:02, 507.85it/s]
Adding requests:  66%|██████▌   | 2696/4096 [00:05<00:02, 506.01it/s]
Adding requests:  67%|██████▋   | 2747/4096 [00:05<00:02, 504.21it/s]
Adding requests:  68%|██████▊   | 2798/4096 [00:05<00:02, 502.32it/s]
Adding requests:  70%|██████▉   | 2849/4096 [00:05<00:02, 504.43it/s]
Adding requests:  71%|███████   | 2901/4096 [00:05<00:02, 506.42it/s]
Adding requests:  72%|███████▏  | 2952/4096 [00:05<00:02, 502.59it/s]
Adding requests:  73%|███████▎  | 3003/4096 [00:06<00:02, 504.03it/s]
Adding requests:  75%|███████▍  | 3054/4096 [00:06<00:02, 504.68it/s]
Adding requests:  76%|███████▌  | 3105/4096 [00:06<00:01, 502.18it/s]
Adding requests:  77%|███████▋  | 3156/4096 [00:06<00:01, 503.03it/s]
Adding requests:  78%|███████▊  | 3207/4096 [00:06<00:01, 503.60it/s]
Adding requests:  80%|███████▉  | 3259/4096 [00:06<00:01, 506.36it/s]
Adding requests:  81%|████████  | 3311/4096 [00:06<00:01, 508.22it/s]
Adding requests:  82%|████████▏ | 3363/4096 [00:06<00:01, 509.46it/s]
Adding requests:  83%|████████▎ | 3415/4096 [00:06<00:01, 510.36it/s]
Adding requests:  85%|████████▍ | 3467/4096 [00:06<00:01, 491.98it/s]
Adding requests:  86%|████████▌ | 3517/4096 [00:07<00:01, 489.20it/s]
Adding requests:  87%|████████▋ | 3567/4096 [00:07<00:01, 490.21it/s]
Adding requests:  88%|████████▊ | 3618/4096 [00:07<00:00, 494.58it/s]
Adding requests:  90%|████████▉ | 3668/4096 [00:07<00:00, 495.94it/s]
Adding requests:  91%|█████████ | 3719/4096 [00:07<00:00, 498.30it/s]
Adding requests:  92%|█████████▏| 3771/4096 [00:07<00:00, 504.67it/s]
Adding requests:  93%|█████████▎| 3823/4096 [00:07<00:00, 507.14it/s]
Adding requests:  95%|█████████▍| 3876/4096 [00:07<00:00, 512.80it/s]
Adding requests:  96%|█████████▌| 3928/4096 [00:07<00:00, 509.44it/s]
Adding requests:  97%|█████████▋| 3979/4096 [00:07<00:00, 509.29it/s]
Adding requests:  98%|█████████▊| 4030/4096 [00:08<00:00, 505.66it/s]
Adding requests: 100%|█████████▉| 4081/4096 [00:08<00:00, 504.11it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 500.38it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  43%|████▎     | 1752/4096 [00:00<00:00, 12747.76it/s, est. speed input: 13055925.57 toks/s, output: 12748.45 toks/s]
Processed prompts:  74%|███████▍  | 3027/4096 [00:05<00:02, 436.91it/s, est. speed input: 537537.37 toks/s, output: 524.94 toks/s]      
Processed prompts:  87%|████████▋ | 3566/4096 [00:08<00:01, 353.80it/s, est. speed input: 443622.90 toks/s, output: 433.22 toks/s]
Processed prompts:  94%|█████████▍| 3869/4096 [00:09<00:00, 318.01it/s, est. speed input: 408687.93 toks/s, output: 399.11 toks/s]
Processed prompts:  99%|█████████▉| 4061/4096 [00:10<00:00, 301.23it/s, est. speed input: 393601.55 toks/s, output: 384.38 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:10<00:00, 301.23it/s, est. speed input: 395220.05 toks/s, output: 385.96 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:10<00:00, 385.95it/s, est. speed input: 395220.05 toks/s, output: 385.96 toks/s]
[rank0]:[W126 08:51:45.705532518 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:51:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:52:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1091441) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1091441) WARNING 01-26 08:52:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 218.04 requests/s, 223495.98 total tokens/s, 218.04 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:52:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:52:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:52:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:52:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:52:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:52:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:52:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:52:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:52:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:52:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:52:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:52:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:52:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:52:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:52:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:52:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:52:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1091441) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1091441) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.37it/s]
(EngineCore_DP0 pid=1091441) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.36it/s]
(EngineCore_DP0 pid=1091441) 
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1091441) [2026-01-26 08:52:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1091441) [rank0]:W0126 08:52:47.602000 1091441 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1091441) [rank0]:W0126 08:52:47.657000 1091441 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1091441) [rank0]:W0126 08:52:48.574000 1091441 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1091441) [rank0]:W0126 08:52:48.650000 1091441 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1091441) 2026-01-26 08:52:51,947 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1091441) 2026-01-26 08:52:52,009 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1091441) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:01, 13.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:01, 14.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:01, 12.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 14.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:01,  5.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:01<00:01,  6.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:01<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:01<00:00, 11.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 12.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 10.22it/s]
(EngineCore_DP0 pid=1091441) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 19.38it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 20.12it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 20.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 10.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 12.92it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 39/8192 [00:00<00:21, 383.81it/s]
Adding requests:   1%|          | 90/8192 [00:00<00:17, 453.45it/s]
Adding requests:   2%|▏         | 138/8192 [00:00<00:17, 465.31it/s]
Adding requests:   2%|▏         | 187/8192 [00:00<00:16, 472.02it/s]
Adding requests:   3%|▎         | 237/8192 [00:00<00:16, 480.65it/s]
Adding requests:   4%|▎         | 287/8192 [00:00<00:16, 483.47it/s]
Adding requests:   4%|▍         | 336/8192 [00:00<00:16, 482.82it/s]
Adding requests:   5%|▍         | 386/8192 [00:00<00:16, 486.40it/s]
Adding requests:   5%|▌         | 436/8192 [00:00<00:15, 489.03it/s]
Adding requests:   6%|▌         | 487/8192 [00:01<00:15, 492.48it/s]
Adding requests:   7%|▋         | 537/8192 [00:01<00:15, 480.98it/s]
Adding requests:   7%|▋         | 587/8192 [00:01<00:15, 485.02it/s]
Adding requests:   8%|▊         | 636/8192 [00:01<00:15, 485.37it/s]
Adding requests:   8%|▊         | 688/8192 [00:01<00:15, 493.42it/s]
Adding requests:   9%|▉         | 740/8192 [00:01<00:14, 497.14it/s]
Adding requests:  10%|▉         | 790/8192 [00:01<00:14, 494.24it/s]
Adding requests:  10%|█         | 840/8192 [00:01<00:15, 485.29it/s]
Adding requests:  11%|█         | 891/8192 [00:01<00:14, 490.88it/s]
Adding requests:  11%|█▏        | 941/8192 [00:01<00:14, 492.71it/s]
Adding requests:  12%|█▏        | 992/8192 [00:02<00:14, 495.16it/s]
Adding requests:  13%|█▎        | 1042/8192 [00:02<00:14, 487.36it/s]
Adding requests:  13%|█▎        | 1092/8192 [00:02<00:14, 489.61it/s]
Adding requests:  14%|█▍        | 1141/8192 [00:02<00:14, 489.37it/s]
Adding requests:  15%|█▍        | 1194/8192 [00:02<00:13, 500.37it/s]
Adding requests:  15%|█▌        | 1245/8192 [00:02<00:13, 500.52it/s]
Adding requests:  16%|█▌        | 1296/8192 [00:02<00:13, 497.57it/s]
Adding requests:  16%|█▋        | 1347/8192 [00:02<00:13, 499.22it/s]
Adding requests:  17%|█▋        | 1399/8192 [00:02<00:13, 504.50it/s]
Adding requests:  18%|█▊        | 1450/8192 [00:02<00:13, 501.52it/s]
Adding requests:  18%|█▊        | 1502/8192 [00:03<00:13, 504.45it/s]
Adding requests:  19%|█▉        | 1553/8192 [00:03<00:13, 503.34it/s]
Adding requests:  20%|█▉        | 1607/8192 [00:03<00:12, 512.30it/s]
Adding requests:  20%|██        | 1659/8192 [00:03<00:12, 508.80it/s]
Adding requests:  21%|██        | 1710/8192 [00:03<00:13, 495.43it/s]
Adding requests:  21%|██▏       | 1760/8192 [00:03<00:13, 494.18it/s]
Adding requests:  22%|██▏       | 1812/8192 [00:03<00:12, 499.34it/s]
Adding requests:  23%|██▎       | 1862/8192 [00:03<00:12, 498.81it/s]
Adding requests:  23%|██▎       | 1913/8192 [00:03<00:12, 500.15it/s]
Adding requests:  24%|██▍       | 1964/8192 [00:03<00:12, 499.69it/s]
Adding requests:  25%|██▍       | 2015/8192 [00:04<00:12, 501.87it/s]
Adding requests:  25%|██▌       | 2067/8192 [00:04<00:12, 505.92it/s]
Adding requests:  26%|██▌       | 2119/8192 [00:04<00:11, 507.05it/s]
Adding requests:  26%|██▋       | 2170/8192 [00:04<00:12, 501.78it/s]
Adding requests:  27%|██▋       | 2221/8192 [00:04<00:11, 500.63it/s]
Adding requests:  28%|██▊       | 2272/8192 [00:04<00:11, 501.59it/s]
Adding requests:  28%|██▊       | 2323/8192 [00:04<00:11, 494.94it/s]
Adding requests:  29%|██▉       | 2374/8192 [00:04<00:11, 498.40it/s]
Adding requests:  30%|██▉       | 2426/8192 [00:04<00:11, 502.64it/s]
Adding requests:  30%|███       | 2477/8192 [00:05<00:11, 503.36it/s]
Adding requests:  31%|███       | 2528/8192 [00:05<00:11, 503.16it/s]
Adding requests:  32%|███▏      | 2581/8192 [00:05<00:11, 510.08it/s]
Adding requests:  32%|███▏      | 2633/8192 [00:05<00:10, 508.16it/s]
Adding requests:  33%|███▎      | 2685/8192 [00:05<00:10, 510.43it/s]
Adding requests:  33%|███▎      | 2737/8192 [00:05<00:10, 505.90it/s]
Adding requests:  34%|███▍      | 2788/8192 [00:05<00:10, 505.30it/s]
Adding requests:  35%|███▍      | 2839/8192 [00:05<00:10, 503.88it/s]
Adding requests:  35%|███▌      | 2892/8192 [00:05<00:10, 507.09it/s]
Adding requests:  36%|███▌      | 2943/8192 [00:05<00:10, 491.97it/s]
Adding requests:  37%|███▋      | 2993/8192 [00:06<00:10, 492.55it/s]
Adding requests:  37%|███▋      | 3044/8192 [00:06<00:10, 494.97it/s]
Adding requests:  38%|███▊      | 3094/8192 [00:06<00:10, 496.02it/s]
Adding requests:  38%|███▊      | 3145/8192 [00:06<00:10, 497.66it/s]
Adding requests:  39%|███▉      | 3196/8192 [00:06<00:09, 500.19it/s]
Adding requests:  40%|███▉      | 3249/8192 [00:06<00:09, 506.88it/s]
Adding requests:  40%|████      | 3300/8192 [00:06<00:09, 506.51it/s]
Adding requests:  41%|████      | 3352/8192 [00:06<00:09, 509.95it/s]
Adding requests:  42%|████▏     | 3404/8192 [00:06<00:09, 508.22it/s]
Adding requests:  42%|████▏     | 3455/8192 [00:06<00:09, 506.91it/s]
Adding requests:  43%|████▎     | 3506/8192 [00:07<00:09, 501.94it/s]
Adding requests:  43%|████▎     | 3558/8192 [00:07<00:09, 504.70it/s]
Adding requests:  44%|████▍     | 3609/8192 [00:07<00:09, 502.95it/s]
Adding requests:  45%|████▍     | 3660/8192 [00:07<00:09, 501.50it/s]
Adding requests:  45%|████▌     | 3712/8192 [00:07<00:08, 506.62it/s]
Adding requests:  46%|████▌     | 3763/8192 [00:07<00:08, 504.35it/s]
Adding requests:  47%|████▋     | 3815/8192 [00:07<00:08, 508.93it/s]
Adding requests:  47%|████▋     | 3868/8192 [00:07<00:08, 512.79it/s]
Adding requests:  48%|████▊     | 3920/8192 [00:07<00:08, 510.62it/s]
Adding requests:  48%|████▊     | 3972/8192 [00:07<00:08, 510.53it/s]
Adding requests:  49%|████▉     | 4024/8192 [00:08<00:08, 508.83it/s]
Adding requests:  50%|████▉     | 4075/8192 [00:08<00:08, 503.76it/s]
Adding requests:  50%|█████     | 4127/8192 [00:08<00:08, 507.29it/s]
Adding requests:  51%|█████     | 4178/8192 [00:08<00:07, 507.88it/s]
Adding requests:  52%|█████▏    | 4230/8192 [00:08<00:07, 509.07it/s]
Adding requests:  52%|█████▏    | 4281/8192 [00:08<00:07, 491.18it/s]
Adding requests:  53%|█████▎    | 4335/8192 [00:08<00:07, 502.96it/s]
Adding requests:  54%|█████▎    | 4387/8192 [00:08<00:07, 507.23it/s]
Adding requests:  54%|█████▍    | 4439/8192 [00:08<00:07, 508.13it/s]
Adding requests:  55%|█████▍    | 4490/8192 [00:08<00:07, 504.71it/s]
Adding requests:  55%|█████▌    | 4541/8192 [00:09<00:07, 504.63it/s]
Adding requests:  56%|█████▌    | 4593/8192 [00:09<00:07, 506.78it/s]
Adding requests:  57%|█████▋    | 4646/8192 [00:09<00:06, 512.84it/s]
Adding requests:  57%|█████▋    | 4698/8192 [00:09<00:06, 505.34it/s]
Adding requests:  58%|█████▊    | 4750/8192 [00:09<00:06, 508.61it/s]
Adding requests:  59%|█████▊    | 4801/8192 [00:09<00:06, 507.68it/s]
Adding requests:  59%|█████▉    | 4852/8192 [00:09<00:06, 507.75it/s]
Adding requests:  60%|█████▉    | 4903/8192 [00:09<00:06, 503.09it/s]
Adding requests:  60%|██████    | 4955/8192 [00:09<00:06, 506.74it/s]
Adding requests:  61%|██████    | 5006/8192 [00:10<00:06, 506.41it/s]
Adding requests:  62%|██████▏   | 5058/8192 [00:10<00:06, 510.40it/s]
Adding requests:  62%|██████▏   | 5111/8192 [00:10<00:05, 515.32it/s]
Adding requests:  63%|██████▎   | 5163/8192 [00:10<00:05, 514.71it/s]
Adding requests:  64%|██████▎   | 5215/8192 [00:10<00:05, 512.11it/s]
Adding requests:  64%|██████▍   | 5267/8192 [00:10<00:05, 508.53it/s]
Adding requests:  65%|██████▍   | 5319/8192 [00:10<00:05, 510.70it/s]
Adding requests:  66%|██████▌   | 5371/8192 [00:10<00:05, 512.32it/s]
Adding requests:  66%|██████▌   | 5423/8192 [00:10<00:05, 510.58it/s]
Adding requests:  67%|██████▋   | 5475/8192 [00:10<00:05, 507.94it/s]
Adding requests:  67%|██████▋   | 5526/8192 [00:11<00:05, 504.53it/s]
Adding requests:  68%|██████▊   | 5577/8192 [00:11<00:05, 486.40it/s]
Adding requests:  69%|██████▊   | 5627/8192 [00:11<00:05, 490.19it/s]
Adding requests:  69%|██████▉   | 5677/8192 [00:11<00:05, 491.88it/s]
Adding requests:  70%|██████▉   | 5729/8192 [00:11<00:04, 497.07it/s]
Adding requests:  71%|███████   | 5781/8192 [00:11<00:04, 500.96it/s]
Adding requests:  71%|███████   | 5832/8192 [00:11<00:04, 498.77it/s]
Adding requests:  72%|███████▏  | 5884/8192 [00:11<00:04, 504.06it/s]
Adding requests:  72%|███████▏  | 5936/8192 [00:11<00:04, 506.06it/s]
Adding requests:  73%|███████▎  | 5988/8192 [00:11<00:04, 508.29it/s]
Adding requests:  74%|███████▎  | 6040/8192 [00:12<00:04, 511.68it/s]
Adding requests:  74%|███████▍  | 6092/8192 [00:12<00:04, 508.61it/s]
Adding requests:  75%|███████▌  | 6144/8192 [00:12<00:04, 509.44it/s]
Adding requests:  76%|███████▌  | 6196/8192 [00:12<00:03, 510.59it/s]
Adding requests:  76%|███████▋  | 6250/8192 [00:12<00:03, 516.45it/s]
Adding requests:  77%|███████▋  | 6303/8192 [00:12<00:03, 517.72it/s]
Adding requests:  78%|███████▊  | 6356/8192 [00:12<00:03, 520.48it/s]
Adding requests:  78%|███████▊  | 6409/8192 [00:12<00:03, 519.02it/s]
Adding requests:  79%|███████▉  | 6462/8192 [00:12<00:03, 520.88it/s]
Adding requests:  80%|███████▉  | 6516/8192 [00:12<00:03, 523.74it/s]
Adding requests:  80%|████████  | 6569/8192 [00:13<00:03, 521.15it/s]
Adding requests:  81%|████████  | 6622/8192 [00:13<00:03, 514.41it/s]
Adding requests:  81%|████████▏ | 6674/8192 [00:13<00:02, 514.25it/s]
Adding requests:  82%|████████▏ | 6726/8192 [00:13<00:02, 514.50it/s]
Adding requests:  83%|████████▎ | 6778/8192 [00:13<00:02, 515.33it/s]
Adding requests:  83%|████████▎ | 6830/8192 [00:13<00:02, 498.47it/s]
Adding requests:  84%|████████▍ | 6883/8192 [00:13<00:02, 505.92it/s]
Adding requests:  85%|████████▍ | 6936/8192 [00:13<00:02, 511.83it/s]
Adding requests:  85%|████████▌ | 6988/8192 [00:13<00:02, 510.30it/s]
Adding requests:  86%|████████▌ | 7040/8192 [00:14<00:02, 508.83it/s]
Adding requests:  87%|████████▋ | 7092/8192 [00:14<00:02, 510.00it/s]
Adding requests:  87%|████████▋ | 7144/8192 [00:14<00:02, 510.86it/s]
Adding requests:  88%|████████▊ | 7196/8192 [00:14<00:01, 509.49it/s]
Adding requests:  88%|████████▊ | 7248/8192 [00:14<00:01, 511.96it/s]
Adding requests:  89%|████████▉ | 7301/8192 [00:14<00:01, 514.63it/s]
Adding requests:  90%|████████▉ | 7353/8192 [00:14<00:01, 512.34it/s]
Adding requests:  90%|█████████ | 7406/8192 [00:14<00:01, 516.42it/s]
Adding requests:  91%|█████████ | 7460/8192 [00:14<00:01, 521.68it/s]
Adding requests:  92%|█████████▏| 7513/8192 [00:14<00:01, 520.37it/s]
Adding requests:  92%|█████████▏| 7566/8192 [00:15<00:01, 518.66it/s]
Adding requests:  93%|█████████▎| 7618/8192 [00:15<00:01, 513.50it/s]
Adding requests:  94%|█████████▎| 7672/8192 [00:15<00:01, 518.46it/s]
Adding requests:  94%|█████████▍| 7725/8192 [00:15<00:00, 519.33it/s]
Adding requests:  95%|█████████▍| 7777/8192 [00:15<00:00, 516.21it/s]
Adding requests:  96%|█████████▌| 7829/8192 [00:15<00:00, 513.76it/s]
Adding requests:  96%|█████████▌| 7881/8192 [00:15<00:00, 512.63it/s]
Adding requests:  97%|█████████▋| 7933/8192 [00:15<00:00, 509.60it/s]
Adding requests:  97%|█████████▋| 7984/8192 [00:15<00:00, 508.38it/s]
Adding requests:  98%|█████████▊| 8035/8192 [00:15<00:00, 504.44it/s]
Adding requests:  99%|█████████▊| 8088/8192 [00:16<00:00, 511.05it/s]
Adding requests:  99%|█████████▉| 8140/8192 [00:16<00:00, 493.46it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 503.86it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  43%|████▎     | 3494/8192 [00:00<00:00, 9737.86it/s, est. speed input: 9972339.44 toks/s, output: 9738.06 toks/s]
Processed prompts:  55%|█████▍    | 4468/8192 [00:04<00:05, 743.95it/s, est. speed input: 972539.49 toks/s, output: 949.74 toks/s]   
Processed prompts:  60%|█████▉    | 4883/8192 [00:06<00:05, 566.16it/s, est. speed input: 775478.28 toks/s, output: 757.30 toks/s]
Processed prompts:  62%|██████▏   | 5119/8192 [00:07<00:06, 475.62it/s, est. speed input: 689246.06 toks/s, output: 673.09 toks/s]
Processed prompts:  64%|██████▍   | 5270/8192 [00:08<00:06, 444.06it/s, est. speed input: 660072.78 toks/s, output: 644.60 toks/s]
Processed prompts:  66%|██████▌   | 5376/8192 [00:08<00:07, 397.67it/s, est. speed input: 628904.84 toks/s, output: 614.16 toks/s]
Processed prompts:  67%|██████▋   | 5453/8192 [00:09<00:07, 383.34it/s, est. speed input: 617739.37 toks/s, output: 603.26 toks/s]
Processed prompts:  67%|██████▋   | 5514/8192 [00:09<00:07, 359.22it/s, est. speed input: 605230.22 toks/s, output: 591.04 toks/s]
Processed prompts:  68%|██████▊   | 5562/8192 [00:09<00:08, 327.05it/s, est. speed input: 592092.18 toks/s, output: 578.21 toks/s]
Processed prompts:  68%|██████▊   | 5606/8192 [00:09<00:08, 293.72it/s, est. speed input: 579399.87 toks/s, output: 565.82 toks/s]
Processed prompts:  69%|██████▉   | 5670/8192 [00:10<00:09, 278.65it/s, est. speed input: 569522.93 toks/s, output: 556.17 toks/s]
Processed prompts:  70%|██████▉   | 5734/8192 [00:10<00:09, 264.13it/s, est. speed input: 559805.36 toks/s, output: 546.68 toks/s]
Processed prompts:  71%|███████   | 5798/8192 [00:10<00:09, 252.49it/s, est. speed input: 550653.49 toks/s, output: 537.75 toks/s]
Processed prompts:  72%|███████▏  | 5862/8192 [00:11<00:09, 243.94it/s, est. speed input: 542111.85 toks/s, output: 529.40 toks/s]
Processed prompts:  72%|███████▏  | 5926/8192 [00:11<00:09, 238.75it/s, est. speed input: 534287.30 toks/s, output: 521.76 toks/s]
Processed prompts:  73%|███████▎  | 5990/8192 [00:11<00:09, 233.95it/s, est. speed input: 526669.03 toks/s, output: 514.32 toks/s]
Processed prompts:  74%|███████▍  | 6054/8192 [00:11<00:09, 229.75it/s, est. speed input: 519288.76 toks/s, output: 507.12 toks/s]
Processed prompts:  75%|███████▍  | 6118/8192 [00:12<00:09, 227.51it/s, est. speed input: 512405.08 toks/s, output: 500.39 toks/s]
Processed prompts:  75%|███████▌  | 6182/8192 [00:12<00:08, 225.59it/s, est. speed input: 505782.71 toks/s, output: 493.93 toks/s]
Processed prompts:  76%|███████▌  | 6246/8192 [00:12<00:08, 224.43it/s, est. speed input: 499496.00 toks/s, output: 487.79 toks/s]
Processed prompts:  77%|███████▋  | 6310/8192 [00:13<00:08, 222.67it/s, est. speed input: 493332.95 toks/s, output: 481.77 toks/s]
Processed prompts:  78%|███████▊  | 6374/8192 [00:13<00:08, 223.56it/s, est. speed input: 487776.71 toks/s, output: 476.34 toks/s]
Processed prompts:  79%|███████▊  | 6438/8192 [00:13<00:07, 222.13it/s, est. speed input: 482136.38 toks/s, output: 470.83 toks/s]
Processed prompts:  79%|███████▉  | 6502/8192 [00:13<00:07, 221.15it/s, est. speed input: 476733.41 toks/s, output: 465.56 toks/s]
Processed prompts:  80%|████████  | 6566/8192 [00:14<00:07, 222.30it/s, est. speed input: 471818.59 toks/s, output: 460.76 toks/s]
Processed prompts:  81%|████████  | 6630/8192 [00:14<00:07, 221.97it/s, est. speed input: 466936.85 toks/s, output: 455.99 toks/s]
Processed prompts:  82%|████████▏ | 6694/8192 [00:14<00:06, 221.31it/s, est. speed input: 462188.08 toks/s, output: 451.35 toks/s]
Processed prompts:  82%|████████▏ | 6758/8192 [00:15<00:06, 221.13it/s, est. speed input: 457658.71 toks/s, output: 446.93 toks/s]
Processed prompts:  83%|████████▎ | 6822/8192 [00:15<00:06, 220.61it/s, est. speed input: 453248.91 toks/s, output: 442.62 toks/s]
Processed prompts:  84%|████████▍ | 6886/8192 [00:15<00:05, 220.62it/s, est. speed input: 449049.50 toks/s, output: 438.52 toks/s]
Processed prompts:  85%|████████▍ | 6950/8192 [00:15<00:05, 220.37it/s, est. speed input: 444971.57 toks/s, output: 434.54 toks/s]
Processed prompts:  86%|████████▌ | 7014/8192 [00:16<00:05, 220.78it/s, est. speed input: 441109.36 toks/s, output: 430.77 toks/s]
Processed prompts:  86%|████████▋ | 7078/8192 [00:16<00:05, 222.02it/s, est. speed input: 437490.59 toks/s, output: 427.24 toks/s]
Processed prompts:  87%|████████▋ | 7142/8192 [00:16<00:04, 222.76it/s, est. speed input: 433978.99 toks/s, output: 423.81 toks/s]
Processed prompts:  88%|████████▊ | 7206/8192 [00:17<00:04, 221.45it/s, est. speed input: 430386.00 toks/s, output: 420.30 toks/s]
Processed prompts:  89%|████████▊ | 7270/8192 [00:17<00:04, 223.64it/s, est. speed input: 427241.84 toks/s, output: 417.23 toks/s]
Processed prompts:  90%|████████▉ | 7334/8192 [00:17<00:03, 222.23it/s, est. speed input: 423893.52 toks/s, output: 413.96 toks/s]
Processed prompts:  90%|█████████ | 7398/8192 [00:18<00:03, 223.18it/s, est. speed input: 420848.22 toks/s, output: 410.98 toks/s]
Processed prompts:  91%|█████████ | 7462/8192 [00:18<00:03, 221.73it/s, est. speed input: 417690.26 toks/s, output: 407.90 toks/s]
Processed prompts:  92%|█████████▏| 7526/8192 [00:18<00:02, 222.54it/s, est. speed input: 414807.55 toks/s, output: 405.08 toks/s]
Processed prompts:  93%|█████████▎| 7590/8192 [00:18<00:02, 223.17it/s, est. speed input: 412016.91 toks/s, output: 402.36 toks/s]
Processed prompts:  93%|█████████▎| 7654/8192 [00:19<00:02, 221.79it/s, est. speed input: 409142.17 toks/s, output: 399.55 toks/s]
Processed prompts:  94%|█████████▍| 7718/8192 [00:19<00:02, 221.67it/s, est. speed input: 406429.81 toks/s, output: 396.90 toks/s]
Processed prompts:  95%|█████████▍| 7782/8192 [00:19<00:01, 220.82it/s, est. speed input: 403729.02 toks/s, output: 394.27 toks/s]
Processed prompts:  96%|█████████▌| 7846/8192 [00:20<00:01, 220.28it/s, est. speed input: 401110.97 toks/s, output: 391.71 toks/s]
Processed prompts:  97%|█████████▋| 7910/8192 [00:20<00:01, 220.35it/s, est. speed input: 398607.51 toks/s, output: 389.26 toks/s]
Processed prompts:  97%|█████████▋| 7974/8192 [00:20<00:00, 220.02it/s, est. speed input: 396142.18 toks/s, output: 386.86 toks/s]
Processed prompts:  98%|█████████▊| 8038/8192 [00:20<00:00, 220.18it/s, est. speed input: 393777.87 toks/s, output: 384.55 toks/s]
Processed prompts:  99%|█████████▉| 8102/8192 [00:21<00:00, 221.91it/s, est. speed input: 391609.55 toks/s, output: 382.43 toks/s]
Processed prompts: 100%|█████████▉| 8166/8192 [00:21<00:00, 269.16it/s, est. speed input: 392486.07 toks/s, output: 383.29 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:21<00:00, 269.16it/s, est. speed input: 393717.90 toks/s, output: 384.49 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [00:21<00:00, 384.49it/s, est. speed input: 393717.90 toks/s, output: 384.49 toks/s]
[rank0]:[W126 08:53:34.482148174 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:13:24
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:13:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1194781) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1194781) WARNING 01-26 10:13:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.64 requests/s, 17259.86 total tokens/s, 33.64 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 10:13:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:13:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:13:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:13:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:13:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:13:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:13:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:13:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:13:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:13:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:13:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:13:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:13:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:13:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:13:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:13:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:13:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1194781) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1194781) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.55it/s]
(EngineCore_DP0 pid=1194781) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.55it/s]
(EngineCore_DP0 pid=1194781) 
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1194781) [2026-01-26 10:13:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1194781) 2026-01-26 10:13:57,893 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1194781) 2026-01-26 10:13:57,916 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1194781) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
(EngineCore_DP0 pid=1194781) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.58it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 519.57it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 698.05it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:27,  4.69it/s, est. speed input: 2402.41 toks/s, output: 4.69 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 17.35it/s, est. speed input: 7646.54 toks/s, output: 14.93 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 24.75it/s, est. speed input: 10480.58 toks/s, output: 20.47 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 29.20it/s, est. speed input: 12206.82 toks/s, output: 23.84 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 32.08it/s, est. speed input: 13383.26 toks/s, output: 26.14 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 33.77it/s, est. speed input: 14194.72 toks/s, output: 27.72 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 35.19it/s, est. speed input: 14854.35 toks/s, output: 29.01 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 36.13it/s, est. speed input: 15366.78 toks/s, output: 30.01 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 36.77it/s, est. speed input: 15777.31 toks/s, output: 30.81 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 37.11it/s, est. speed input: 16103.25 toks/s, output: 31.45 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 37.49it/s, est. speed input: 16390.38 toks/s, output: 32.01 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 37.70it/s, est. speed input: 16630.47 toks/s, output: 32.48 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 37.87it/s, est. speed input: 16837.12 toks/s, output: 32.88 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 38.00it/s, est. speed input: 17019.51 toks/s, output: 33.24 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 38.04it/s, est. speed input: 17173.62 toks/s, output: 33.54 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 38.07it/s, est. speed input: 17310.75 toks/s, output: 33.81 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 38.13it/s, est. speed input: 17435.60 toks/s, output: 34.05 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 37.94it/s, est. speed input: 17529.43 toks/s, output: 34.24 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 37.66it/s, est. speed input: 17602.18 toks/s, output: 34.38 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 37.43it/s, est. speed input: 17664.63 toks/s, output: 34.50 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 37.28it/s, est. speed input: 17722.39 toks/s, output: 34.61 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 37.10it/s, est. speed input: 17769.36 toks/s, output: 34.71 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 37.02it/s, est. speed input: 17815.83 toks/s, output: 34.80 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 36.92it/s, est. speed input: 17855.20 toks/s, output: 34.87 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 36.80it/s, est. speed input: 17889.00 toks/s, output: 34.94 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 36.82it/s, est. speed input: 17926.00 toks/s, output: 35.01 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 36.81it/s, est. speed input: 17958.88 toks/s, output: 35.08 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 36.83it/s, est. speed input: 17991.43 toks/s, output: 35.14 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 36.77it/s, est. speed input: 18017.14 toks/s, output: 35.19 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 36.73it/s, est. speed input: 18041.50 toks/s, output: 35.24 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 36.74it/s, est. speed input: 18066.53 toks/s, output: 35.29 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 36.75it/s, est. speed input: 18089.45 toks/s, output: 35.33 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.75it/s, est. speed input: 18107.34 toks/s, output: 35.37 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 35.36it/s, est. speed input: 18107.34 toks/s, output: 35.37 toks/s]
[rank0]:[W126 10:14:04.758826046 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 10:14:06
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:14:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1195956) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1195956) WARNING 01-26 10:14:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.57 requests/s, 35435.16 total tokens/s, 34.57 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 10:14:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:14:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:14:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:14:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:14:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:14:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:14:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:14:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:14:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:14:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:14:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:14:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1195956) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1195956) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1195956) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1195956) 
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1195956) [2026-01-26 10:14:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1195956) 2026-01-26 10:14:40,917 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1195956) 2026-01-26 10:14:40,963 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1195956) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.49it/s]
(EngineCore_DP0 pid=1195956) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  22%|██▏       | 28/128 [00:00<00:00, 278.61it/s]
Adding requests:  62%|██████▏   | 79/128 [00:00<00:00, 413.81it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 425.65it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 42.82it/s, est. speed input: 43858.69 toks/s, output: 42.83 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:02, 39.56it/s, est. speed input: 40986.54 toks/s, output: 40.02 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:02, 38.71it/s, est. speed input: 40216.37 toks/s, output: 39.27 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:02, 38.28it/s, est. speed input: 39809.07 toks/s, output: 38.87 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:02, 37.99it/s, est. speed input: 39536.14 toks/s, output: 38.61 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 37.90it/s, est. speed input: 39390.67 toks/s, output: 38.47 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:00<00:02, 37.82it/s, est. speed input: 39276.41 toks/s, output: 38.35 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:00<00:02, 37.75it/s, est. speed input: 39184.63 toks/s, output: 38.27 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:00<00:02, 37.72it/s, est. speed input: 39117.16 toks/s, output: 38.20 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:02, 37.67it/s, est. speed input: 39054.78 toks/s, output: 38.14 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 37.59it/s, est. speed input: 38986.56 toks/s, output: 38.07 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:01<00:02, 37.51it/s, est. speed input: 38925.57 toks/s, output: 38.01 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:01<00:01, 37.54it/s, est. speed input: 38893.72 toks/s, output: 37.98 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:01<00:01, 37.55it/s, est. speed input: 38863.83 toks/s, output: 37.95 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 37.53it/s, est. speed input: 38833.27 toks/s, output: 37.92 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 37.24it/s, est. speed input: 38746.10 toks/s, output: 37.84 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:01<00:01, 37.33it/s, est. speed input: 38728.82 toks/s, output: 37.82 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:01<00:01, 37.43it/s, est. speed input: 38720.01 toks/s, output: 37.81 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:02<00:01, 37.43it/s, est. speed input: 38699.96 toks/s, output: 37.79 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:02<00:01, 37.43it/s, est. speed input: 38681.37 toks/s, output: 37.77 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 37.38it/s, est. speed input: 38657.95 toks/s, output: 37.75 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:02<00:01, 37.36it/s, est. speed input: 38637.27 toks/s, output: 37.73 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:02<00:00, 37.34it/s, est. speed input: 38617.38 toks/s, output: 37.71 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:02<00:00, 37.39it/s, est. speed input: 38608.42 toks/s, output: 37.70 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 37.44it/s, est. speed input: 38602.64 toks/s, output: 37.70 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 37.47it/s, est. speed input: 38596.74 toks/s, output: 37.69 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:02<00:00, 37.48it/s, est. speed input: 38589.26 toks/s, output: 37.68 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:03<00:00, 37.46it/s, est. speed input: 38579.13 toks/s, output: 37.67 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:03<00:00, 37.43it/s, est. speed input: 38568.77 toks/s, output: 37.66 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:03<00:00, 37.43it/s, est. speed input: 38560.60 toks/s, output: 37.66 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 37.44it/s, est. speed input: 38554.05 toks/s, output: 37.65 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.44it/s, est. speed input: 38550.61 toks/s, output: 37.65 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 37.64it/s, est. speed input: 38550.61 toks/s, output: 37.65 toks/s]
[rank0]:[W126 10:14:47.247950834 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 10:14:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:14:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1197067) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1197067) WARNING 01-26 10:15:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 65.61 requests/s, 67245.41 total tokens/s, 65.61 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 10:14:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:14:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:14:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:14:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:14:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:14:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:14:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:14:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:15:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:15:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:15:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:15:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:15:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:15:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1197067) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1197067) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.58it/s]
(EngineCore_DP0 pid=1197067) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.58it/s]
(EngineCore_DP0 pid=1197067) 
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1197067) [2026-01-26 10:15:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1197067) 2026-01-26 10:15:24,909 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1197067) 2026-01-26 10:15:24,932 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1197067) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 15.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.35it/s]
(EngineCore_DP0 pid=1197067) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|█         | 26/256 [00:00<00:00, 258.36it/s]
Adding requests:  30%|███       | 78/256 [00:00<00:00, 408.42it/s]
Adding requests:  50%|█████     | 128/256 [00:00<00:00, 447.76it/s]
Adding requests:  69%|██████▉   | 177/256 [00:00<00:00, 462.71it/s]
Adding requests:  89%|████████▉ | 228/256 [00:00<00:00, 478.05it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 456.69it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 14/256 [00:00<00:02, 112.33it/s, est. speed input: 115064.39 toks/s, output: 112.34 toks/s]
Processed prompts:  10%|█         | 26/256 [00:00<00:02, 88.17it/s, est. speed input: 93553.85 toks/s, output: 91.35 toks/s]   
Processed prompts:  14%|█▍        | 36/256 [00:00<00:02, 82.45it/s, est. speed input: 88213.68 toks/s, output: 86.14 toks/s]
Processed prompts:  18%|█▊        | 45/256 [00:00<00:02, 83.14it/s, est. speed input: 87872.45 toks/s, output: 85.81 toks/s]
Processed prompts:  21%|██        | 54/256 [00:00<00:02, 77.35it/s, est. speed input: 84096.41 toks/s, output: 82.12 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:00<00:02, 76.62it/s, est. speed input: 83063.12 toks/s, output: 81.11 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:00<00:02, 76.22it/s, est. speed input: 82333.82 toks/s, output: 80.40 toks/s]
Processed prompts:  30%|███       | 78/256 [00:00<00:02, 75.91it/s, est. speed input: 81752.00 toks/s, output: 79.83 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:02, 75.68it/s, est. speed input: 81280.62 toks/s, output: 79.37 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:01<00:02, 75.55it/s, est. speed input: 80901.98 toks/s, output: 79.00 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:01<00:02, 75.53it/s, est. speed input: 80605.61 toks/s, output: 78.71 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:01<00:01, 75.46it/s, est. speed input: 80341.06 toks/s, output: 78.46 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:01<00:01, 75.47it/s, est. speed input: 80126.76 toks/s, output: 78.25 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:01<00:01, 75.47it/s, est. speed input: 79940.29 toks/s, output: 78.06 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:01<00:01, 75.38it/s, est. speed input: 79757.68 toks/s, output: 77.89 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:01<00:01, 75.36it/s, est. speed input: 79604.25 toks/s, output: 77.74 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:01<00:01, 75.39it/s, est. speed input: 79475.02 toks/s, output: 77.61 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:02<00:01, 75.40it/s, est. speed input: 79358.65 toks/s, output: 77.50 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:02<00:01, 75.48it/s, est. speed input: 79266.52 toks/s, output: 77.41 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:02<00:01, 75.41it/s, est. speed input: 79162.23 toks/s, output: 77.31 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:02<00:00, 75.40it/s, est. speed input: 79072.39 toks/s, output: 77.22 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:02<00:00, 75.37it/s, est. speed input: 78987.22 toks/s, output: 77.13 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:02<00:00, 75.23it/s, est. speed input: 78893.54 toks/s, output: 77.04 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:02<00:00, 75.31it/s, est. speed input: 78829.84 toks/s, output: 76.98 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:02<00:00, 75.31it/s, est. speed input: 78765.00 toks/s, output: 76.92 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:02<00:00, 75.36it/s, est. speed input: 78709.95 toks/s, output: 76.86 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:02<00:00, 75.32it/s, est. speed input: 78651.12 toks/s, output: 76.81 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:03<00:00, 75.30it/s, est. speed input: 78597.00 toks/s, output: 76.75 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:03<00:00, 75.28it/s, est. speed input: 78544.41 toks/s, output: 76.70 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:03<00:00, 75.28it/s, est. speed input: 78497.60 toks/s, output: 76.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 75.28it/s, est. speed input: 78492.14 toks/s, output: 76.65 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 76.65it/s, est. speed input: 78492.14 toks/s, output: 76.65 toks/s]
[rank0]:[W126 10:15:31.540532763 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 10:15:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:15:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1198182) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1198182) WARNING 01-26 10:15:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 82.52 requests/s, 84578.93 total tokens/s, 82.52 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 10:15:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:15:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:15:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:15:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:15:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:15:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:15:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:15:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:15:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:15:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:15:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:15:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:15:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:15:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1198182) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1198182) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1198182) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1198182) 
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1198182) [2026-01-26 10:15:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1198182) 2026-01-26 10:16:08,652 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1198182) 2026-01-26 10:16:08,676 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1198182) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  9.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.60it/s]
(EngineCore_DP0 pid=1198182) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  5.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.80it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 27/512 [00:00<00:01, 268.19it/s]
Adding requests:  15%|█▌        | 78/512 [00:00<00:01, 407.04it/s]
Adding requests:  25%|██▌       | 128/512 [00:00<00:00, 447.96it/s]
Adding requests:  35%|███▍      | 177/512 [00:00<00:00, 460.69it/s]
Adding requests:  45%|████▍     | 228/512 [00:00<00:00, 476.30it/s]
Adding requests:  54%|█████▍    | 278/512 [00:00<00:00, 483.05it/s]
Adding requests:  64%|██████▍   | 328/512 [00:00<00:00, 485.43it/s]
Adding requests:  74%|███████▍  | 379/512 [00:00<00:00, 492.56it/s]
Adding requests:  84%|████████▍ | 430/512 [00:00<00:00, 496.94it/s]
Adding requests:  94%|█████████▍| 480/512 [00:01<00:00, 496.35it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 475.34it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:00<00:00, 666.13it/s, est. speed input: 682242.79 toks/s, output: 666.17 toks/s]
Processed prompts:  28%|██▊       | 141/512 [00:00<00:02, 146.07it/s, est. speed input: 170536.29 toks/s, output: 166.54 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:01<00:02, 117.73it/s, est. speed input: 140971.58 toks/s, output: 137.66 toks/s]
Processed prompts:  38%|███▊      | 196/512 [00:01<00:02, 112.29it/s, est. speed input: 134396.01 toks/s, output: 131.25 toks/s]
Processed prompts:  42%|████▏     | 213/512 [00:01<00:02, 107.92it/s, est. speed input: 130061.69 toks/s, output: 127.01 toks/s]
Processed prompts:  45%|████▍     | 228/512 [00:01<00:02, 101.17it/s, est. speed input: 125262.52 toks/s, output: 122.33 toks/s]
Processed prompts:  47%|████▋     | 241/512 [00:02<00:02, 99.55it/s, est. speed input: 123194.46 toks/s, output: 120.31 toks/s] 
Processed prompts:  49%|████▉     | 253/512 [00:02<00:02, 96.55it/s, est. speed input: 120939.41 toks/s, output: 118.10 toks/s]
Processed prompts:  52%|█████▏    | 264/512 [00:02<00:02, 92.36it/s, est. speed input: 118530.30 toks/s, output: 115.75 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:02<00:02, 87.23it/s, est. speed input: 116004.02 toks/s, output: 113.28 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:02<00:02, 87.15it/s, est. speed input: 114547.04 toks/s, output: 111.86 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:02<00:02, 87.04it/s, est. speed input: 113228.83 toks/s, output: 110.57 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:02<00:02, 86.66it/s, est. speed input: 111970.59 toks/s, output: 109.34 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:02<00:02, 86.47it/s, est. speed input: 110848.85 toks/s, output: 108.25 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:03<00:02, 86.50it/s, est. speed input: 109861.09 toks/s, output: 107.28 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:03<00:01, 87.59it/s, est. speed input: 109150.53 toks/s, output: 106.59 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:03<00:01, 87.46it/s, est. speed input: 108339.80 toks/s, output: 105.80 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:03<00:01, 87.26it/s, est. speed input: 107575.81 toks/s, output: 105.05 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:03<00:01, 87.04it/s, est. speed input: 106856.96 toks/s, output: 104.35 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:03<00:01, 86.79it/s, est. speed input: 106176.22 toks/s, output: 103.69 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:03<00:01, 86.75it/s, est. speed input: 105562.81 toks/s, output: 103.09 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:04<00:01, 86.62it/s, est. speed input: 104977.33 toks/s, output: 102.52 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:04<00:00, 86.56it/s, est. speed input: 104434.90 toks/s, output: 101.99 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:04<00:00, 86.58it/s, est. speed input: 103934.62 toks/s, output: 101.50 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:04<00:00, 88.12it/s, est. speed input: 103649.84 toks/s, output: 101.22 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:04<00:00, 87.77it/s, est. speed input: 103214.12 toks/s, output: 100.79 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:04<00:00, 87.27it/s, est. speed input: 102774.77 toks/s, output: 100.37 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:04<00:00, 86.90it/s, est. speed input: 102357.92 toks/s, output: 99.96 toks/s] 
Processed prompts:  98%|█████████▊| 502/512 [00:05<00:00, 86.68it/s, est. speed input: 101967.17 toks/s, output: 99.58 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 86.68it/s, est. speed input: 102283.19 toks/s, output: 99.89 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:05<00:00, 99.88it/s, est. speed input: 102283.19 toks/s, output: 99.89 toks/s]
[rank0]:[W126 10:16:17.802832281 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 10:16:19
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:16:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1199333) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1199333) WARNING 01-26 10:16:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 89.66 requests/s, 91901.21 total tokens/s, 89.66 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 10:16:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:16:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:16:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:16:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:16:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:16:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:16:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:16:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:16:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:16:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:16:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:16:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:16:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:16:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:16:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:16:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:16:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1199333) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1199333) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1199333) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1199333) 
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1199333) [2026-01-26 10:16:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1199333) 2026-01-26 10:16:57,559 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1199333) 2026-01-26 10:16:57,594 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1199333) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:01,  2.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:01<00:00,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  5.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.18it/s]
(EngineCore_DP0 pid=1199333) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  9.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.77it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 12.14it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 30/1024 [00:00<00:03, 297.77it/s]
Adding requests:   8%|▊         | 81/1024 [00:00<00:02, 420.53it/s]
Adding requests:  13%|█▎        | 131/1024 [00:00<00:01, 455.40it/s]
Adding requests:  17%|█▋        | 179/1024 [00:00<00:01, 463.87it/s]
Adding requests:  22%|██▏       | 230/1024 [00:00<00:01, 478.73it/s]
Adding requests:  27%|██▋       | 280/1024 [00:00<00:01, 482.92it/s]
Adding requests:  32%|███▏      | 329/1024 [00:00<00:01, 483.86it/s]
Adding requests:  37%|███▋      | 380/1024 [00:00<00:01, 490.47it/s]
Adding requests:  42%|████▏     | 430/1024 [00:00<00:01, 493.09it/s]
Adding requests:  47%|████▋     | 480/1024 [00:01<00:01, 492.79it/s]
Adding requests:  52%|█████▏    | 530/1024 [00:01<00:01, 476.97it/s]
Adding requests:  57%|█████▋    | 581/1024 [00:01<00:00, 486.04it/s]
Adding requests:  62%|██████▏   | 632/1024 [00:01<00:00, 490.38it/s]
Adding requests:  67%|██████▋   | 684/1024 [00:01<00:00, 497.51it/s]
Adding requests:  72%|███████▏  | 735/1024 [00:01<00:00, 500.58it/s]
Adding requests:  77%|███████▋  | 786/1024 [00:01<00:00, 496.21it/s]
Adding requests:  82%|████████▏ | 836/1024 [00:01<00:00, 484.37it/s]
Adding requests:  87%|████████▋ | 888/1024 [00:01<00:00, 492.42it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:01<00:00, 494.76it/s]
Adding requests:  97%|█████████▋| 990/1024 [00:02<00:00, 497.95it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 485.12it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:00<00:00, 1755.20it/s, est. speed input: 1797754.71 toks/s, output: 1755.33 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:02<00:04, 150.45it/s, est. speed input: 178715.82 toks/s, output: 174.52 toks/s]   
Processed prompts:  42%|████▏     | 432/1024 [00:02<00:04, 131.73it/s, est. speed input: 156911.20 toks/s, output: 153.23 toks/s]
Processed prompts:  47%|████▋     | 479/1024 [00:03<00:04, 121.34it/s, est. speed input: 146947.94 toks/s, output: 143.50 toks/s]
Processed prompts:  50%|████▉     | 511/1024 [00:03<00:04, 115.30it/s, est. speed input: 141784.57 toks/s, output: 138.46 toks/s]
Processed prompts:  52%|█████▏    | 535/1024 [00:03<00:04, 111.02it/s, est. speed input: 138517.83 toks/s, output: 135.27 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:04<00:04, 103.27it/s, est. speed input: 134475.57 toks/s, output: 131.32 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:04<00:04, 101.29it/s, est. speed input: 132813.98 toks/s, output: 129.70 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:04<00:04, 99.32it/s, est. speed input: 131272.78 toks/s, output: 128.20 toks/s] 
Processed prompts:  59%|█████▉    | 602/1024 [00:04<00:04, 97.48it/s, est. speed input: 129838.82 toks/s, output: 126.79 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:04<00:04, 95.95it/s, est. speed input: 128522.01 toks/s, output: 125.51 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:05<00:04, 94.69it/s, est. speed input: 127296.31 toks/s, output: 124.31 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:05<00:03, 93.60it/s, est. speed input: 126138.76 toks/s, output: 123.18 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:05<00:03, 92.89it/s, est. speed input: 125074.00 toks/s, output: 122.14 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:05<00:03, 92.34it/s, est. speed input: 124074.43 toks/s, output: 121.17 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:05<00:03, 91.84it/s, est. speed input: 123122.36 toks/s, output: 120.24 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:05<00:03, 91.53it/s, est. speed input: 122232.74 toks/s, output: 119.37 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:06<00:03, 91.30it/s, est. speed input: 121393.02 toks/s, output: 118.55 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:06<00:03, 91.19it/s, est. speed input: 120607.36 toks/s, output: 117.78 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:06<00:02, 91.11it/s, est. speed input: 119864.82 toks/s, output: 117.05 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:06<00:02, 91.07it/s, est. speed input: 119161.78 toks/s, output: 116.37 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:06<00:02, 90.97it/s, est. speed input: 118487.27 toks/s, output: 115.71 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:07<00:02, 90.87it/s, est. speed input: 117843.63 toks/s, output: 115.08 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:07<00:02, 90.79it/s, est. speed input: 117229.50 toks/s, output: 114.48 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:07<00:02, 90.84it/s, est. speed input: 116655.98 toks/s, output: 113.92 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:07<00:01, 90.78it/s, est. speed input: 116100.56 toks/s, output: 113.38 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:07<00:01, 90.87it/s, est. speed input: 115581.96 toks/s, output: 112.87 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:07<00:01, 90.82it/s, est. speed input: 115076.74 toks/s, output: 112.38 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:08<00:01, 90.77it/s, est. speed input: 114591.22 toks/s, output: 111.91 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:08<00:01, 90.76it/s, est. speed input: 114129.21 toks/s, output: 111.45 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:08<00:00, 91.79it/s, est. speed input: 113776.32 toks/s, output: 111.11 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:08<00:00, 91.41it/s, est. speed input: 113344.14 toks/s, output: 110.69 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:08<00:00, 91.17it/s, est. speed input: 112931.06 toks/s, output: 110.28 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:08<00:00, 92.23it/s, est. speed input: 112632.79 toks/s, output: 109.99 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:09<00:00, 91.85it/s, est. speed input: 112258.20 toks/s, output: 109.63 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:09<00:00, 92.93it/s, est. speed input: 111998.75 toks/s, output: 109.37 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 92.93it/s, est. speed input: 112653.91 toks/s, output: 110.01 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:09<00:00, 110.01it/s, est. speed input: 112653.91 toks/s, output: 110.01 toks/s]
[rank0]:[W126 10:17:12.453884610 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 10:17:14
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:17:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1200636) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1200636) WARNING 01-26 10:17:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 93.33 requests/s, 95666.53 total tokens/s, 93.33 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 10:17:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:17:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:17:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:17:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:17:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:17:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:17:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:17:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:17:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:17:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:17:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:17:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:17:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:17:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:17:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:17:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:17:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1200636) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1200636) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1200636) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1200636) 
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1200636) [2026-01-26 10:17:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1200636) 2026-01-26 10:17:57,712 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1200636) 2026-01-26 10:17:57,789 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1200636) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 14.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 10.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  4.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.78it/s]
(EngineCore_DP0 pid=1200636) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 10.19it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 12.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 13.03it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 26/2048 [00:00<00:07, 254.65it/s]
Adding requests:   4%|▍         | 77/2048 [00:00<00:04, 402.17it/s]
Adding requests:   6%|▌         | 127/2048 [00:00<00:04, 444.64it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:04, 459.43it/s]
Adding requests:  11%|█         | 227/2048 [00:00<00:03, 475.57it/s]
Adding requests:  14%|█▎        | 278/2048 [00:00<00:03, 483.99it/s]
Adding requests:  16%|█▌        | 328/2048 [00:00<00:03, 486.56it/s]
Adding requests:  19%|█▊        | 379/2048 [00:00<00:03, 493.83it/s]
Adding requests:  21%|██        | 430/2048 [00:00<00:03, 497.97it/s]
Adding requests:  23%|██▎       | 480/2048 [00:01<00:03, 497.41it/s]
Adding requests:  26%|██▌       | 530/2048 [00:01<00:03, 487.00it/s]
Adding requests:  28%|██▊       | 582/2048 [00:01<00:02, 494.50it/s]
Adding requests:  31%|███       | 633/2048 [00:01<00:02, 497.60it/s]
Adding requests:  33%|███▎      | 685/2048 [00:01<00:02, 502.82it/s]
Adding requests:  36%|███▌      | 737/2048 [00:01<00:02, 505.99it/s]
Adding requests:  38%|███▊      | 788/2048 [00:01<00:02, 500.98it/s]
Adding requests:  41%|████      | 839/2048 [00:01<00:02, 483.95it/s]
Adding requests:  44%|████▎     | 891/2048 [00:01<00:02, 492.39it/s]
Adding requests:  46%|████▌     | 942/2048 [00:01<00:02, 495.30it/s]
Adding requests:  49%|████▊     | 994/2048 [00:02<00:02, 499.49it/s]
Adding requests:  51%|█████     | 1045/2048 [00:02<00:01, 501.94it/s]
Adding requests:  54%|█████▎    | 1096/2048 [00:02<00:01, 501.16it/s]
Adding requests:  56%|█████▌    | 1147/2048 [00:02<00:01, 498.62it/s]
Adding requests:  59%|█████▊    | 1201/2048 [00:02<00:01, 508.38it/s]
Adding requests:  61%|██████    | 1252/2048 [00:02<00:01, 505.19it/s]
Adding requests:  64%|██████▎   | 1303/2048 [00:02<00:01, 505.26it/s]
Adding requests:  66%|██████▌   | 1355/2048 [00:02<00:01, 508.11it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:02<00:01, 512.73it/s]
Adding requests:  71%|███████▏  | 1460/2048 [00:02<00:01, 511.90it/s]
Adding requests:  74%|███████▍  | 1513/2048 [00:03<00:01, 514.62it/s]
Adding requests:  76%|███████▋  | 1565/2048 [00:03<00:00, 515.12it/s]
Adding requests:  79%|███████▉  | 1617/2048 [00:03<00:00, 516.14it/s]
Adding requests:  81%|████████▏ | 1669/2048 [00:03<00:00, 512.97it/s]
Adding requests:  84%|████████▍ | 1721/2048 [00:03<00:00, 514.22it/s]
Adding requests:  87%|████████▋ | 1773/2048 [00:03<00:00, 509.40it/s]
Adding requests:  89%|████████▉ | 1825/2048 [00:03<00:00, 510.27it/s]
Adding requests:  92%|█████████▏| 1877/2048 [00:03<00:00, 509.27it/s]
Adding requests:  94%|█████████▍| 1928/2048 [00:03<00:00, 507.47it/s]
Adding requests:  97%|█████████▋| 1980/2048 [00:03<00:00, 509.19it/s]
Adding requests:  99%|█████████▉| 2031/2048 [00:04<00:00, 500.34it/s]
Adding requests: 100%|██████████| 2048/2048 [00:04<00:00, 497.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:00<00:01, 1610.99it/s, est. speed input: 1649812.89 toks/s, output: 1611.04 toks/s]
Processed prompts:  27%|██▋       | 548/2048 [00:01<00:06, 231.60it/s, est. speed input: 289552.09 toks/s, output: 282.76 toks/s]   
Processed prompts:  30%|███       | 620/2048 [00:02<00:07, 188.09it/s, est. speed input: 242049.10 toks/s, output: 236.38 toks/s]
Processed prompts:  32%|███▏      | 664/2048 [00:03<00:08, 160.63it/s, est. speed input: 216872.56 toks/s, output: 211.79 toks/s]
Processed prompts:  34%|███▍      | 694/2048 [00:03<00:09, 145.43it/s, est. speed input: 204154.22 toks/s, output: 199.37 toks/s]
Processed prompts:  35%|███▌      | 717/2048 [00:03<00:09, 144.04it/s, est. speed input: 201044.86 toks/s, output: 196.33 toks/s]
Processed prompts:  36%|███▌      | 737/2048 [00:03<00:09, 139.88it/s, est. speed input: 197407.89 toks/s, output: 192.78 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:04<00:11, 112.41it/s, est. speed input: 185388.80 toks/s, output: 181.04 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:04<00:11, 108.92it/s, est. speed input: 181811.67 toks/s, output: 177.55 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:04<00:11, 105.85it/s, est. speed input: 178566.42 toks/s, output: 174.38 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:04<00:12, 103.13it/s, est. speed input: 175552.81 toks/s, output: 171.44 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:04<00:12, 100.90it/s, est. speed input: 172765.14 toks/s, output: 168.71 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:05<00:12, 98.89it/s, est. speed input: 170117.41 toks/s, output: 166.13 toks/s] 
Processed prompts:  42%|████▏     | 850/2048 [00:05<00:12, 97.19it/s, est. speed input: 167612.64 toks/s, output: 163.68 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:05<00:12, 96.12it/s, est. speed input: 165311.28 toks/s, output: 161.44 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:05<00:12, 95.41it/s, est. speed input: 163165.88 toks/s, output: 159.34 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:05<00:12, 95.04it/s, est. speed input: 161177.38 toks/s, output: 157.40 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:05<00:11, 94.53it/s, est. speed input: 159261.17 toks/s, output: 155.53 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:06<00:11, 95.81it/s, est. speed input: 157714.60 toks/s, output: 154.02 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:06<00:11, 94.90it/s, est. speed input: 155974.12 toks/s, output: 152.32 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:06<00:11, 94.59it/s, est. speed input: 154375.19 toks/s, output: 150.76 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:06<00:11, 95.72it/s, est. speed input: 153047.27 toks/s, output: 149.46 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:06<00:11, 95.10it/s, est. speed input: 151593.45 toks/s, output: 148.04 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:06<00:10, 94.74it/s, est. speed input: 150221.90 toks/s, output: 146.70 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:07<00:10, 94.18it/s, est. speed input: 148877.50 toks/s, output: 145.39 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:07<00:10, 93.95it/s, est. speed input: 147615.54 toks/s, output: 144.16 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:07<00:10, 93.85it/s, est. speed input: 146420.29 toks/s, output: 142.99 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:07<00:10, 93.61it/s, est. speed input: 145258.73 toks/s, output: 141.85 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:07<00:10, 93.60it/s, est. speed input: 144166.64 toks/s, output: 140.79 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:07<00:10, 93.54it/s, est. speed input: 143116.79 toks/s, output: 139.76 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:08<00:09, 93.55it/s, est. speed input: 142116.76 toks/s, output: 138.79 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:08<00:09, 93.44it/s, est. speed input: 141144.78 toks/s, output: 137.84 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:08<00:09, 95.13it/s, est. speed input: 140390.70 toks/s, output: 137.10 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:08<00:09, 94.74it/s, est. speed input: 139510.84 toks/s, output: 136.24 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:08<00:09, 94.40it/s, est. speed input: 138658.95 toks/s, output: 135.41 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:08<00:09, 93.80it/s, est. speed input: 137806.48 toks/s, output: 134.58 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:09<00:08, 93.74it/s, est. speed input: 137018.06 toks/s, output: 133.81 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:09<00:08, 93.43it/s, est. speed input: 136235.00 toks/s, output: 133.04 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:09<00:08, 93.54it/s, est. speed input: 135509.27 toks/s, output: 132.33 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:09<00:08, 93.54it/s, est. speed input: 134802.63 toks/s, output: 131.64 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:09<00:08, 93.42it/s, est. speed input: 134111.05 toks/s, output: 130.97 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:09<00:08, 93.37it/s, est. speed input: 133445.37 toks/s, output: 130.32 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:10<00:07, 93.20it/s, est. speed input: 132792.33 toks/s, output: 129.68 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:10<00:07, 93.15it/s, est. speed input: 132166.03 toks/s, output: 129.07 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:10<00:07, 93.26it/s, est. speed input: 131570.90 toks/s, output: 128.49 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:10<00:07, 93.38it/s, est. speed input: 130999.06 toks/s, output: 127.93 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:10<00:07, 93.34it/s, est. speed input: 130435.77 toks/s, output: 127.38 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:10<00:07, 93.41it/s, est. speed input: 129896.98 toks/s, output: 126.85 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:11<00:06, 93.28it/s, est. speed input: 129362.46 toks/s, output: 126.33 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:11<00:06, 93.10it/s, est. speed input: 128837.52 toks/s, output: 125.82 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:11<00:06, 93.32it/s, est. speed input: 128352.15 toks/s, output: 125.34 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:11<00:06, 93.26it/s, est. speed input: 127866.28 toks/s, output: 124.87 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:11<00:06, 93.39it/s, est. speed input: 127406.48 toks/s, output: 124.42 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:12<00:05, 93.32it/s, est. speed input: 126948.73 toks/s, output: 123.97 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:12<00:05, 93.25it/s, est. speed input: 126503.16 toks/s, output: 123.54 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:12<00:05, 93.19it/s, est. speed input: 126068.52 toks/s, output: 123.11 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:12<00:05, 93.21it/s, est. speed input: 125650.19 toks/s, output: 122.70 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:12<00:05, 93.27it/s, est. speed input: 125245.67 toks/s, output: 122.31 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:12<00:05, 93.19it/s, est. speed input: 124844.95 toks/s, output: 121.92 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:13<00:04, 94.99it/s, est. speed input: 124561.00 toks/s, output: 121.64 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:13<00:04, 94.27it/s, est. speed input: 124172.68 toks/s, output: 121.26 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:13<00:04, 93.89it/s, est. speed input: 123801.08 toks/s, output: 120.90 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:13<00:04, 93.71it/s, est. speed input: 123443.69 toks/s, output: 120.55 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:13<00:04, 93.61it/s, est. speed input: 123096.06 toks/s, output: 120.21 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:13<00:04, 93.56it/s, est. speed input: 122758.36 toks/s, output: 119.88 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:14<00:03, 93.32it/s, est. speed input: 122417.75 toks/s, output: 119.55 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:14<00:03, 93.13it/s, est. speed input: 122084.58 toks/s, output: 119.22 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:14<00:03, 93.00it/s, est. speed input: 121759.27 toks/s, output: 118.91 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:14<00:03, 93.05it/s, est. speed input: 121448.93 toks/s, output: 118.60 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:14<00:03, 93.17it/s, est. speed input: 121150.36 toks/s, output: 118.31 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:14<00:03, 93.29it/s, est. speed input: 120860.00 toks/s, output: 118.03 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:15<00:02, 93.13it/s, est. speed input: 120564.69 toks/s, output: 117.74 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:15<00:02, 92.83it/s, est. speed input: 120266.72 toks/s, output: 117.45 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:15<00:02, 92.96it/s, est. speed input: 119991.56 toks/s, output: 117.18 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:15<00:02, 93.02it/s, est. speed input: 119721.12 toks/s, output: 116.91 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:15<00:02, 93.00it/s, est. speed input: 119453.44 toks/s, output: 116.65 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:15<00:02, 92.96it/s, est. speed input: 119190.81 toks/s, output: 116.40 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:16<00:01, 94.46it/s, est. speed input: 119001.69 toks/s, output: 116.21 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:16<00:01, 93.77it/s, est. speed input: 118740.01 toks/s, output: 115.96 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:16<00:01, 93.37it/s, est. speed input: 118487.13 toks/s, output: 115.71 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:16<00:01, 93.43it/s, est. speed input: 118254.12 toks/s, output: 115.48 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:16<00:01, 93.30it/s, est. speed input: 118018.70 toks/s, output: 115.25 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:16<00:00, 95.12it/s, est. speed input: 117867.70 toks/s, output: 115.10 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:17<00:00, 94.67it/s, est. speed input: 117648.35 toks/s, output: 114.89 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:17<00:00, 94.24it/s, est. speed input: 117428.93 toks/s, output: 114.68 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:17<00:00, 93.89it/s, est. speed input: 117211.65 toks/s, output: 114.46 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:17<00:00, 93.89it/s, est. speed input: 117008.24 toks/s, output: 114.27 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:17<00:00, 95.65it/s, est. speed input: 116877.68 toks/s, output: 114.14 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:17<00:00, 95.65it/s, est. speed input: 117678.29 toks/s, output: 114.92 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:17<00:00, 114.92it/s, est. speed input: 117678.29 toks/s, output: 114.92 toks/s]
[rank0]:[W126 10:18:23.254692921 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 10:18:25
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:18:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1202204) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1202204) WARNING 01-26 10:19:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 94.27 requests/s, 96627.79 total tokens/s, 94.27 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 10:18:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:18:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:18:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:18:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:18:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:18:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:18:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:18:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:18:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:18:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:18:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:18:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:18:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:18:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:18:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:18:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:18:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1202204) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1202204) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1202204) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=1202204) 
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1202204) [2026-01-26 10:18:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1202204) [rank0]:W0126 10:19:11.016000 1202204 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1202204) [rank0]:W0126 10:19:11.104000 1202204 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1202204) [rank0]:W0126 10:19:12.049000 1202204 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1202204) [rank0]:W0126 10:19:12.176000 1202204 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1202204) 2026-01-26 10:19:15,930 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1202204) 2026-01-26 10:19:15,955 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1202204) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  5.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  9.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  9.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  6.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  6.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  6.89it/s]
(EngineCore_DP0 pid=1202204) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 15.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 13.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 13.39it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 31/4096 [00:00<00:13, 305.93it/s]
Adding requests:   2%|▏         | 82/4096 [00:00<00:09, 421.48it/s]
Adding requests:   3%|▎         | 132/4096 [00:00<00:08, 455.90it/s]
Adding requests:   4%|▍         | 180/4096 [00:00<00:08, 465.30it/s]
Adding requests:   6%|▌         | 230/4096 [00:00<00:08, 477.09it/s]
Adding requests:   7%|▋         | 280/4096 [00:00<00:07, 481.63it/s]
Adding requests:   8%|▊         | 329/4096 [00:00<00:07, 483.05it/s]
Adding requests:   9%|▉         | 380/4096 [00:00<00:07, 491.08it/s]
Adding requests:  11%|█         | 431/4096 [00:00<00:07, 493.85it/s]
Adding requests:  12%|█▏        | 481/4096 [00:01<00:07, 494.82it/s]
Adding requests:  13%|█▎        | 531/4096 [00:01<00:07, 482.12it/s]
Adding requests:  14%|█▍        | 583/4096 [00:01<00:07, 490.48it/s]
Adding requests:  15%|█▌        | 633/4096 [00:01<00:07, 492.33it/s]
Adding requests:  17%|█▋        | 685/4096 [00:01<00:06, 497.48it/s]
Adding requests:  18%|█▊        | 736/4096 [00:01<00:06, 499.57it/s]
Adding requests:  19%|█▉        | 786/4096 [00:01<00:06, 493.71it/s]
Adding requests:  20%|██        | 836/4096 [00:01<00:06, 484.61it/s]
Adding requests:  22%|██▏       | 888/4096 [00:01<00:06, 492.02it/s]
Adding requests:  23%|██▎       | 939/4096 [00:01<00:06, 495.70it/s]
Adding requests:  24%|██▍       | 990/4096 [00:02<00:06, 497.60it/s]
Adding requests:  25%|██▌       | 1041/4096 [00:02<00:06, 498.05it/s]
Adding requests:  27%|██▋       | 1091/4096 [00:02<00:06, 486.92it/s]
Adding requests:  28%|██▊       | 1140/4096 [00:02<00:06, 484.37it/s]
Adding requests:  29%|██▉       | 1194/4096 [00:02<00:05, 497.71it/s]
Adding requests:  30%|███       | 1245/4096 [00:02<00:05, 500.18it/s]
Adding requests:  32%|███▏      | 1296/4096 [00:02<00:05, 497.91it/s]
Adding requests:  33%|███▎      | 1347/4096 [00:02<00:05, 500.52it/s]
Adding requests:  34%|███▍      | 1399/4096 [00:02<00:05, 505.03it/s]
Adding requests:  35%|███▌      | 1450/4096 [00:02<00:05, 504.48it/s]
Adding requests:  37%|███▋      | 1503/4096 [00:03<00:05, 509.41it/s]
Adding requests:  38%|███▊      | 1554/4096 [00:03<00:05, 506.68it/s]
Adding requests:  39%|███▉      | 1607/4096 [00:03<00:04, 512.01it/s]
Adding requests:  41%|████      | 1659/4096 [00:03<00:04, 508.30it/s]
Adding requests:  42%|████▏     | 1710/4096 [00:03<00:04, 506.21it/s]
Adding requests:  43%|████▎     | 1761/4096 [00:03<00:04, 504.99it/s]
Adding requests:  44%|████▍     | 1812/4096 [00:03<00:04, 506.42it/s]
Adding requests:  45%|████▌     | 1863/4096 [00:03<00:04, 501.79it/s]
Adding requests:  47%|████▋     | 1914/4096 [00:03<00:04, 503.12it/s]
Adding requests:  48%|████▊     | 1965/4096 [00:03<00:04, 501.53it/s]
Adding requests:  49%|████▉     | 2016/4096 [00:04<00:04, 503.33it/s]
Adding requests:  50%|█████     | 2067/4096 [00:04<00:04, 504.90it/s]
Adding requests:  52%|█████▏    | 2118/4096 [00:04<00:03, 505.11it/s]
Adding requests:  53%|█████▎    | 2169/4096 [00:04<00:03, 496.74it/s]
Adding requests:  54%|█████▍    | 2219/4096 [00:04<00:03, 495.86it/s]
Adding requests:  55%|█████▌    | 2270/4096 [00:04<00:03, 497.72it/s]
Adding requests:  57%|█████▋    | 2320/4096 [00:04<00:03, 489.31it/s]
Adding requests:  58%|█████▊    | 2370/4096 [00:04<00:03, 492.02it/s]
Adding requests:  59%|█████▉    | 2421/4096 [00:04<00:03, 496.15it/s]
Adding requests:  60%|██████    | 2472/4096 [00:05<00:03, 498.46it/s]
Adding requests:  62%|██████▏   | 2522/4096 [00:05<00:03, 498.51it/s]
Adding requests:  63%|██████▎   | 2574/4096 [00:05<00:03, 504.26it/s]
Adding requests:  64%|██████▍   | 2625/4096 [00:05<00:02, 503.52it/s]
Adding requests:  65%|██████▌   | 2676/4096 [00:05<00:02, 504.86it/s]
Adding requests:  67%|██████▋   | 2727/4096 [00:05<00:02, 503.00it/s]
Adding requests:  68%|██████▊   | 2778/4096 [00:05<00:02, 502.21it/s]
Adding requests:  69%|██████▉   | 2829/4096 [00:05<00:02, 497.83it/s]
Adding requests:  70%|███████   | 2881/4096 [00:05<00:02, 501.35it/s]
Adding requests:  72%|███████▏  | 2932/4096 [00:05<00:02, 498.55it/s]
Adding requests:  73%|███████▎  | 2982/4096 [00:06<00:02, 497.96it/s]
Adding requests:  74%|███████▍  | 3033/4096 [00:06<00:02, 498.60it/s]
Adding requests:  75%|███████▌  | 3083/4096 [00:06<00:02, 495.82it/s]
Adding requests:  77%|███████▋  | 3134/4096 [00:06<00:01, 499.47it/s]
Adding requests:  78%|███████▊  | 3184/4096 [00:06<00:01, 497.65it/s]
Adding requests:  79%|███████▉  | 3235/4096 [00:06<00:01, 499.92it/s]
Adding requests:  80%|████████  | 3286/4096 [00:06<00:01, 501.40it/s]
Adding requests:  81%|████████▏ | 3337/4096 [00:06<00:01, 501.91it/s]
Adding requests:  83%|████████▎ | 3388/4096 [00:06<00:01, 503.47it/s]
Adding requests:  84%|████████▍ | 3440/4096 [00:06<00:01, 506.43it/s]
Adding requests:  85%|████████▌ | 3491/4096 [00:07<00:01, 497.67it/s]
Adding requests:  86%|████████▋ | 3542/4096 [00:07<00:01, 498.73it/s]
Adding requests:  88%|████████▊ | 3593/4096 [00:07<00:01, 499.51it/s]
Adding requests:  89%|████████▉ | 3643/4096 [00:07<00:00, 482.86it/s]
Adding requests:  90%|█████████ | 3695/4096 [00:07<00:00, 490.92it/s]
Adding requests:  91%|█████████▏| 3745/4096 [00:07<00:00, 491.61it/s]
Adding requests:  93%|█████████▎| 3799/4096 [00:07<00:00, 503.18it/s]
Adding requests:  94%|█████████▍| 3850/4096 [00:07<00:00, 504.52it/s]
Adding requests:  95%|█████████▌| 3901/4096 [00:07<00:00, 505.77it/s]
Adding requests:  96%|█████████▋| 3952/4096 [00:07<00:00, 504.95it/s]
Adding requests:  98%|█████████▊| 4003/4096 [00:08<00:00, 503.36it/s]
Adding requests:  99%|█████████▉| 4054/4096 [00:08<00:00, 499.53it/s]
Adding requests: 100%|██████████| 4096/4096 [00:08<00:00, 496.51it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 725/4096 [00:00<00:00, 3391.89it/s, est. speed input: 3473671.56 toks/s, output: 3392.00 toks/s]
Processed prompts:  26%|██▌       | 1065/4096 [00:03<00:12, 242.90it/s, est. speed input: 306920.47 toks/s, output: 299.73 toks/s]  
Processed prompts:  30%|██▉       | 1211/4096 [00:05<00:16, 179.64it/s, est. speed input: 237283.90 toks/s, output: 231.72 toks/s]
Processed prompts:  32%|███▏      | 1295/4096 [00:05<00:16, 169.28it/s, est. speed input: 224815.33 toks/s, output: 219.55 toks/s]
Processed prompts:  33%|███▎      | 1351/4096 [00:06<00:18, 151.04it/s, est. speed input: 210574.36 toks/s, output: 205.64 toks/s]
Processed prompts:  34%|███▍      | 1390/4096 [00:06<00:18, 146.33it/s, est. speed input: 206065.49 toks/s, output: 201.24 toks/s]
Processed prompts:  35%|███▍      | 1420/4096 [00:07<00:19, 137.30it/s, est. speed input: 200750.64 toks/s, output: 196.05 toks/s]
Processed prompts:  35%|███▌      | 1443/4096 [00:07<00:21, 124.64it/s, est. speed input: 194978.61 toks/s, output: 190.41 toks/s]
Processed prompts:  36%|███▌      | 1461/4096 [00:07<00:23, 109.82it/s, est. speed input: 189037.92 toks/s, output: 184.61 toks/s]
Processed prompts:  36%|███▋      | 1493/4096 [00:08<00:24, 106.38it/s, est. speed input: 185282.15 toks/s, output: 180.94 toks/s]
Processed prompts:  37%|███▋      | 1525/4096 [00:08<00:24, 103.53it/s, est. speed input: 181820.73 toks/s, output: 177.56 toks/s]
Processed prompts:  38%|███▊      | 1557/4096 [00:08<00:25, 101.34it/s, est. speed input: 178639.83 toks/s, output: 174.45 toks/s]
Processed prompts:  39%|███▉      | 1589/4096 [00:09<00:25, 99.61it/s, est. speed input: 175678.41 toks/s, output: 171.56 toks/s] 
Processed prompts:  40%|███▉      | 1621/4096 [00:09<00:25, 98.35it/s, est. speed input: 172935.10 toks/s, output: 168.88 toks/s]
Processed prompts:  40%|████      | 1653/4096 [00:09<00:25, 97.46it/s, est. speed input: 170384.23 toks/s, output: 166.39 toks/s]
Processed prompts:  41%|████      | 1685/4096 [00:10<00:24, 96.72it/s, est. speed input: 167981.62 toks/s, output: 164.04 toks/s]
Processed prompts:  42%|████▏     | 1717/4096 [00:10<00:24, 96.16it/s, est. speed input: 165725.35 toks/s, output: 161.84 toks/s]
Processed prompts:  43%|████▎     | 1749/4096 [00:10<00:24, 95.84it/s, est. speed input: 163623.59 toks/s, output: 159.79 toks/s]
Processed prompts:  43%|████▎     | 1781/4096 [00:11<00:24, 95.54it/s, est. speed input: 161633.35 toks/s, output: 157.84 toks/s]
Processed prompts:  44%|████▍     | 1813/4096 [00:11<00:23, 95.54it/s, est. speed input: 159793.97 toks/s, output: 156.05 toks/s]
Processed prompts:  45%|████▌     | 1845/4096 [00:11<00:23, 95.52it/s, est. speed input: 158054.80 toks/s, output: 154.35 toks/s]
Processed prompts:  46%|████▌     | 1877/4096 [00:12<00:23, 96.25it/s, est. speed input: 156521.21 toks/s, output: 152.85 toks/s]
Processed prompts:  47%|████▋     | 1909/4096 [00:12<00:22, 96.03it/s, est. speed input: 154962.02 toks/s, output: 151.33 toks/s]
Processed prompts:  47%|████▋     | 1941/4096 [00:12<00:22, 96.58it/s, est. speed input: 153579.31 toks/s, output: 149.98 toks/s]
Processed prompts:  48%|████▊     | 1973/4096 [00:13<00:22, 96.35it/s, est. speed input: 152185.01 toks/s, output: 148.62 toks/s]
Processed prompts:  49%|████▉     | 2005/4096 [00:13<00:21, 96.05it/s, est. speed input: 150839.25 toks/s, output: 147.30 toks/s]
Processed prompts:  50%|████▉     | 2037/4096 [00:13<00:21, 95.84it/s, est. speed input: 149559.34 toks/s, output: 146.05 toks/s]
Processed prompts:  51%|█████     | 2069/4096 [00:14<00:21, 95.78it/s, est. speed input: 148349.65 toks/s, output: 144.87 toks/s]
Processed prompts:  51%|█████▏    | 2101/4096 [00:14<00:20, 95.70it/s, est. speed input: 147191.40 toks/s, output: 143.74 toks/s]
Processed prompts:  52%|█████▏    | 2133/4096 [00:14<00:20, 95.52it/s, est. speed input: 146071.29 toks/s, output: 142.65 toks/s]
Processed prompts:  53%|█████▎    | 2165/4096 [00:15<00:20, 95.54it/s, est. speed input: 145015.65 toks/s, output: 141.62 toks/s]
Processed prompts:  54%|█████▎    | 2197/4096 [00:15<00:19, 95.46it/s, est. speed input: 143995.63 toks/s, output: 140.62 toks/s]
Processed prompts:  54%|█████▍    | 2229/4096 [00:15<00:19, 97.07it/s, est. speed input: 143190.82 toks/s, output: 139.83 toks/s]
Processed prompts:  55%|█████▌    | 2261/4096 [00:16<00:19, 96.56it/s, est. speed input: 142252.75 toks/s, output: 138.92 toks/s]
Processed prompts:  56%|█████▌    | 2293/4096 [00:16<00:18, 97.02it/s, est. speed input: 141431.88 toks/s, output: 138.12 toks/s]
Processed prompts:  57%|█████▋    | 2325/4096 [00:16<00:18, 97.36it/s, est. speed input: 140643.66 toks/s, output: 137.35 toks/s]
Processed prompts:  58%|█████▊    | 2357/4096 [00:17<00:17, 96.75it/s, est. speed input: 139807.94 toks/s, output: 136.53 toks/s]
Processed prompts:  58%|█████▊    | 2389/4096 [00:17<00:17, 96.35it/s, est. speed input: 139005.47 toks/s, output: 135.75 toks/s]
Processed prompts:  59%|█████▉    | 2421/4096 [00:17<00:17, 96.12it/s, est. speed input: 138238.15 toks/s, output: 135.00 toks/s]
Processed prompts:  60%|█████▉    | 2453/4096 [00:18<00:17, 95.81it/s, est. speed input: 137485.72 toks/s, output: 134.26 toks/s]
Processed prompts:  61%|██████    | 2485/4096 [00:18<00:16, 96.33it/s, est. speed input: 136822.51 toks/s, output: 133.62 toks/s]
Processed prompts:  61%|██████▏   | 2517/4096 [00:18<00:16, 96.05it/s, est. speed input: 136129.82 toks/s, output: 132.94 toks/s]
Processed prompts:  62%|██████▏   | 2549/4096 [00:19<00:16, 95.73it/s, est. speed input: 135450.48 toks/s, output: 132.28 toks/s]
Processed prompts:  63%|██████▎   | 2581/4096 [00:19<00:15, 96.28it/s, est. speed input: 134856.08 toks/s, output: 131.70 toks/s]
Processed prompts:  64%|██████▍   | 2613/4096 [00:19<00:15, 95.96it/s, est. speed input: 134226.59 toks/s, output: 131.08 toks/s]
Processed prompts:  65%|██████▍   | 2645/4096 [00:20<00:15, 95.72it/s, est. speed input: 133616.61 toks/s, output: 130.48 toks/s]
Processed prompts:  65%|██████▌   | 2677/4096 [00:20<00:14, 95.44it/s, est. speed input: 133017.90 toks/s, output: 129.90 toks/s]
Processed prompts:  66%|██████▌   | 2709/4096 [00:20<00:14, 95.35it/s, est. speed input: 132445.90 toks/s, output: 129.34 toks/s]
Processed prompts:  67%|██████▋   | 2741/4096 [00:21<00:14, 95.40it/s, est. speed input: 131900.71 toks/s, output: 128.81 toks/s]
Processed prompts:  68%|██████▊   | 2773/4096 [00:21<00:13, 95.21it/s, est. speed input: 131356.25 toks/s, output: 128.28 toks/s]
Processed prompts:  68%|██████▊   | 2805/4096 [00:21<00:13, 95.28it/s, est. speed input: 130842.74 toks/s, output: 127.78 toks/s]
Processed prompts:  69%|██████▉   | 2837/4096 [00:22<00:13, 95.22it/s, est. speed input: 130337.24 toks/s, output: 127.28 toks/s]
Processed prompts:  70%|███████   | 2869/4096 [00:22<00:12, 95.08it/s, est. speed input: 129840.21 toks/s, output: 126.80 toks/s]
Processed prompts:  71%|███████   | 2901/4096 [00:22<00:12, 95.14it/s, est. speed input: 129368.39 toks/s, output: 126.34 toks/s]
Processed prompts:  72%|███████▏  | 2933/4096 [00:23<00:12, 95.24it/s, est. speed input: 128913.21 toks/s, output: 125.89 toks/s]
Processed prompts:  72%|███████▏  | 2965/4096 [00:23<00:11, 95.14it/s, est. speed input: 128460.87 toks/s, output: 125.45 toks/s]
Processed prompts:  73%|███████▎  | 2997/4096 [00:23<00:11, 95.09it/s, est. speed input: 128022.43 toks/s, output: 125.02 toks/s]
Processed prompts:  74%|███████▍  | 3029/4096 [00:24<00:11, 95.13it/s, est. speed input: 127600.65 toks/s, output: 124.61 toks/s]
Processed prompts:  75%|███████▍  | 3061/4096 [00:24<00:10, 94.96it/s, est. speed input: 127178.35 toks/s, output: 124.20 toks/s]
Processed prompts:  76%|███████▌  | 3093/4096 [00:24<00:10, 95.04it/s, est. speed input: 126779.17 toks/s, output: 123.81 toks/s]
Processed prompts:  76%|███████▋  | 3125/4096 [00:25<00:10, 95.98it/s, est. speed input: 126442.01 toks/s, output: 123.48 toks/s]
Processed prompts:  77%|███████▋  | 3157/4096 [00:25<00:09, 95.60it/s, est. speed input: 126054.57 toks/s, output: 123.10 toks/s]
Processed prompts:  78%|███████▊  | 3189/4096 [00:25<00:09, 95.48it/s, est. speed input: 125685.01 toks/s, output: 122.74 toks/s]
Processed prompts:  79%|███████▊  | 3221/4096 [00:26<00:09, 95.39it/s, est. speed input: 125324.19 toks/s, output: 122.39 toks/s]
Processed prompts:  79%|███████▉  | 3253/4096 [00:26<00:08, 95.23it/s, est. speed input: 124967.65 toks/s, output: 122.04 toks/s]
Processed prompts:  80%|████████  | 3285/4096 [00:26<00:08, 95.16it/s, est. speed input: 124621.73 toks/s, output: 121.70 toks/s]
Processed prompts:  81%|████████  | 3317/4096 [00:27<00:08, 95.05it/s, est. speed input: 124281.76 toks/s, output: 121.37 toks/s]
Processed prompts:  82%|████████▏ | 3349/4096 [00:27<00:07, 94.88it/s, est. speed input: 123944.39 toks/s, output: 121.04 toks/s]
Processed prompts:  83%|████████▎ | 3381/4096 [00:28<00:07, 94.95it/s, est. speed input: 123625.47 toks/s, output: 120.73 toks/s]
Processed prompts:  83%|████████▎ | 3413/4096 [00:28<00:07, 95.00it/s, est. speed input: 123314.42 toks/s, output: 120.42 toks/s]
Processed prompts:  84%|████████▍ | 3445/4096 [00:28<00:06, 94.97it/s, est. speed input: 123006.91 toks/s, output: 120.12 toks/s]
Processed prompts:  85%|████████▍ | 3477/4096 [00:29<00:06, 95.04it/s, est. speed input: 122711.45 toks/s, output: 119.84 toks/s]
Processed prompts:  86%|████████▌ | 3509/4096 [00:29<00:06, 95.08it/s, est. speed input: 122421.88 toks/s, output: 119.55 toks/s]
Processed prompts:  86%|████████▋ | 3541/4096 [00:29<00:05, 94.86it/s, est. speed input: 122127.01 toks/s, output: 119.26 toks/s]
Processed prompts:  87%|████████▋ | 3573/4096 [00:30<00:05, 94.80it/s, est. speed input: 121843.33 toks/s, output: 118.99 toks/s]
Processed prompts:  88%|████████▊ | 3605/4096 [00:30<00:05, 94.90it/s, est. speed input: 121572.68 toks/s, output: 118.72 toks/s]
Processed prompts:  89%|████████▉ | 3637/4096 [00:30<00:04, 94.84it/s, est. speed input: 121301.93 toks/s, output: 118.46 toks/s]
Processed prompts:  90%|████████▉ | 3669/4096 [00:31<00:04, 94.94it/s, est. speed input: 121043.88 toks/s, output: 118.21 toks/s]
Processed prompts:  90%|█████████ | 3701/4096 [00:31<00:04, 94.99it/s, est. speed input: 120790.24 toks/s, output: 117.96 toks/s]
Processed prompts:  91%|█████████ | 3733/4096 [00:31<00:03, 95.69it/s, est. speed input: 120571.64 toks/s, output: 117.75 toks/s]
Processed prompts:  92%|█████████▏| 3765/4096 [00:32<00:03, 95.49it/s, est. speed input: 120327.19 toks/s, output: 117.51 toks/s]
Processed prompts:  93%|█████████▎| 3797/4096 [00:32<00:03, 95.39it/s, est. speed input: 120089.60 toks/s, output: 117.27 toks/s]
Processed prompts:  93%|█████████▎| 3829/4096 [00:32<00:02, 95.16it/s, est. speed input: 119849.69 toks/s, output: 117.04 toks/s]
Processed prompts:  94%|█████████▍| 3861/4096 [00:33<00:02, 94.99it/s, est. speed input: 119614.34 toks/s, output: 116.81 toks/s]
Processed prompts:  95%|█████████▌| 3893/4096 [00:33<00:02, 95.00it/s, est. speed input: 119389.41 toks/s, output: 116.59 toks/s]
Processed prompts:  96%|█████████▌| 3925/4096 [00:33<00:01, 94.82it/s, est. speed input: 119160.93 toks/s, output: 116.37 toks/s]
Processed prompts:  97%|█████████▋| 3957/4096 [00:34<00:01, 94.81it/s, est. speed input: 118942.09 toks/s, output: 116.15 toks/s]
Processed prompts:  97%|█████████▋| 3989/4096 [00:34<00:01, 94.92it/s, est. speed input: 118731.92 toks/s, output: 115.95 toks/s]
Processed prompts:  98%|█████████▊| 4021/4096 [00:34<00:00, 95.64it/s, est. speed input: 118551.98 toks/s, output: 115.77 toks/s]
Processed prompts:  99%|█████████▉| 4053/4096 [00:35<00:00, 95.68it/s, est. speed input: 118356.71 toks/s, output: 115.58 toks/s]
Processed prompts: 100%|█████████▉| 4085/4096 [00:35<00:00, 117.20it/s, est. speed input: 118851.42 toks/s, output: 116.07 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 117.20it/s, est. speed input: 119169.79 toks/s, output: 116.38 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:35<00:00, 116.38it/s, est. speed input: 119169.79 toks/s, output: 116.38 toks/s]
[rank0]:[W126 10:20:03.800652461 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:20:05
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:20:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1204233) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1204233) WARNING 01-26 10:21:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 95.40 requests/s, 97785.05 total tokens/s, 95.40 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:20:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:20:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:20:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:20:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:20:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:20:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:20:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:20:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:20:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:20:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 10:20:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 10:20:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 10:20:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:20:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:20:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:20:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:20:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1204233) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1204233) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1204233) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=1204233) 
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1204233) [2026-01-26 10:20:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1204233) [rank0]:W0126 10:21:07.739000 1204233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1204233) [rank0]:W0126 10:21:07.826000 1204233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1204233) [rank0]:W0126 10:21:08.694000 1204233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1204233) [rank0]:W0126 10:21:08.821000 1204233 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1204233) 2026-01-26 10:21:12,497 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1204233) 2026-01-26 10:21:12,533 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1204233) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:08,  2.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:10,  1.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:07,  2.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:04,  3.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  5.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:00,  9.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:00, 11.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:02<00:00, 13.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:02<00:00, 15.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:02<00:00,  8.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  6.12it/s]
(EngineCore_DP0 pid=1204233) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  9.76it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00, 15.51it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 11.56it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 14.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 16.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 15.41it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 40/8192 [00:00<00:20, 399.70it/s]
Adding requests:   1%|          | 91/8192 [00:00<00:17, 460.12it/s]
Adding requests:   2%|▏         | 140/8192 [00:00<00:17, 469.59it/s]
Adding requests:   2%|▏         | 188/8192 [00:00<00:16, 472.34it/s]
Adding requests:   3%|▎         | 238/8192 [00:00<00:16, 482.11it/s]
Adding requests:   4%|▎         | 287/8192 [00:00<00:16, 484.15it/s]
Adding requests:   4%|▍         | 336/8192 [00:00<00:16, 483.23it/s]
Adding requests:   5%|▍         | 387/8192 [00:00<00:15, 489.34it/s]
Adding requests:   5%|▌         | 437/8192 [00:00<00:15, 490.87it/s]
Adding requests:   6%|▌         | 487/8192 [00:01<00:15, 493.15it/s]
Adding requests:   7%|▋         | 537/8192 [00:01<00:15, 480.96it/s]
Adding requests:   7%|▋         | 589/8192 [00:01<00:15, 491.59it/s]
Adding requests:   8%|▊         | 639/8192 [00:01<00:15, 493.66it/s]
Adding requests:   8%|▊         | 690/8192 [00:01<00:15, 492.88it/s]
Adding requests:   9%|▉         | 740/8192 [00:01<00:15, 494.10it/s]
Adding requests:  10%|▉         | 790/8192 [00:01<00:15, 491.35it/s]
Adding requests:  10%|█         | 840/8192 [00:01<00:15, 482.94it/s]
Adding requests:  11%|█         | 892/8192 [00:01<00:14, 492.48it/s]
Adding requests:  12%|█▏        | 943/8192 [00:01<00:14, 494.70it/s]
Adding requests:  12%|█▏        | 994/8192 [00:02<00:14, 496.92it/s]
Adding requests:  13%|█▎        | 1045/8192 [00:02<00:14, 499.91it/s]
Adding requests:  13%|█▎        | 1096/8192 [00:02<00:14, 497.86it/s]
Adding requests:  14%|█▍        | 1146/8192 [00:02<00:14, 495.76it/s]
Adding requests:  15%|█▍        | 1199/8192 [00:02<00:13, 503.81it/s]
Adding requests:  15%|█▌        | 1250/8192 [00:02<00:13, 504.97it/s]
Adding requests:  16%|█▌        | 1301/8192 [00:02<00:13, 499.37it/s]
Adding requests:  17%|█▋        | 1353/8192 [00:02<00:13, 502.44it/s]
Adding requests:  17%|█▋        | 1405/8192 [00:02<00:13, 506.16it/s]
Adding requests:  18%|█▊        | 1456/8192 [00:02<00:13, 505.52it/s]
Adding requests:  18%|█▊        | 1508/8192 [00:03<00:13, 507.46it/s]
Adding requests:  19%|█▉        | 1559/8192 [00:03<00:13, 506.66it/s]
Adding requests:  20%|█▉        | 1611/8192 [00:03<00:12, 510.56it/s]
Adding requests:  20%|██        | 1663/8192 [00:03<00:12, 508.32it/s]
Adding requests:  21%|██        | 1714/8192 [00:03<00:12, 508.78it/s]
Adding requests:  22%|██▏       | 1765/8192 [00:03<00:12, 506.29it/s]
Adding requests:  22%|██▏       | 1817/8192 [00:03<00:12, 508.66it/s]
Adding requests:  23%|██▎       | 1868/8192 [00:03<00:12, 487.81it/s]
Adding requests:  23%|██▎       | 1919/8192 [00:03<00:12, 493.99it/s]
Adding requests:  24%|██▍       | 1969/8192 [00:03<00:12, 495.47it/s]
Adding requests:  25%|██▍       | 2021/8192 [00:04<00:12, 500.98it/s]
Adding requests:  25%|██▌       | 2073/8192 [00:04<00:12, 505.09it/s]
Adding requests:  26%|██▌       | 2124/8192 [00:04<00:12, 502.99it/s]
Adding requests:  27%|██▋       | 2175/8192 [00:04<00:12, 498.49it/s]
Adding requests:  27%|██▋       | 2226/8192 [00:04<00:11, 499.88it/s]
Adding requests:  28%|██▊       | 2277/8192 [00:04<00:11, 501.81it/s]
Adding requests:  28%|██▊       | 2328/8192 [00:04<00:11, 502.23it/s]
Adding requests:  29%|██▉       | 2379/8192 [00:04<00:11, 503.88it/s]
Adding requests:  30%|██▉       | 2431/8192 [00:04<00:11, 506.42it/s]
Adding requests:  30%|███       | 2482/8192 [00:04<00:11, 505.95it/s]
Adding requests:  31%|███       | 2533/8192 [00:05<00:11, 504.84it/s]
Adding requests:  32%|███▏      | 2585/8192 [00:05<00:11, 507.86it/s]
Adding requests:  32%|███▏      | 2636/8192 [00:05<00:10, 507.47it/s]
Adding requests:  33%|███▎      | 2688/8192 [00:05<00:10, 508.15it/s]
Adding requests:  33%|███▎      | 2739/8192 [00:05<00:10, 504.11it/s]
Adding requests:  34%|███▍      | 2790/8192 [00:05<00:10, 502.39it/s]
Adding requests:  35%|███▍      | 2841/8192 [00:05<00:10, 502.15it/s]
Adding requests:  35%|███▌      | 2893/8192 [00:05<00:10, 505.55it/s]
Adding requests:  36%|███▌      | 2944/8192 [00:05<00:10, 500.60it/s]
Adding requests:  37%|███▋      | 2996/8192 [00:06<00:10, 502.68it/s]
Adding requests:  37%|███▋      | 3047/8192 [00:06<00:10, 503.19it/s]
Adding requests:  38%|███▊      | 3098/8192 [00:06<00:10, 501.66it/s]
Adding requests:  38%|███▊      | 3149/8192 [00:06<00:10, 500.88it/s]
Adding requests:  39%|███▉      | 3200/8192 [00:06<00:10, 483.51it/s]
Adding requests:  40%|███▉      | 3252/8192 [00:06<00:10, 493.44it/s]
Adding requests:  40%|████      | 3303/8192 [00:06<00:09, 495.81it/s]
Adding requests:  41%|████      | 3355/8192 [00:06<00:09, 502.82it/s]
Adding requests:  42%|████▏     | 3406/8192 [00:06<00:09, 501.84it/s]
Adding requests:  42%|████▏     | 3457/8192 [00:06<00:09, 501.27it/s]
Adding requests:  43%|████▎     | 3508/8192 [00:07<00:09, 498.27it/s]
Adding requests:  43%|████▎     | 3559/8192 [00:07<00:09, 499.81it/s]
Adding requests:  44%|████▍     | 3610/8192 [00:07<00:09, 498.42it/s]
Adding requests:  45%|████▍     | 3660/8192 [00:07<00:09, 496.93it/s]
Adding requests:  45%|████▌     | 3712/8192 [00:07<00:08, 502.30it/s]
Adding requests:  46%|████▌     | 3763/8192 [00:07<00:08, 500.48it/s]
Adding requests:  47%|████▋     | 3815/8192 [00:07<00:08, 505.52it/s]
Adding requests:  47%|████▋     | 3867/8192 [00:07<00:08, 508.53it/s]
Adding requests:  48%|████▊     | 3918/8192 [00:07<00:08, 507.36it/s]
Adding requests:  48%|████▊     | 3969/8192 [00:07<00:08, 507.33it/s]
Adding requests:  49%|████▉     | 4020/8192 [00:08<00:08, 507.09it/s]
Adding requests:  50%|████▉     | 4071/8192 [00:08<00:08, 500.20it/s]
Adding requests:  50%|█████     | 4122/8192 [00:08<00:08, 501.69it/s]
Adding requests:  51%|█████     | 4173/8192 [00:08<00:07, 504.05it/s]
Adding requests:  52%|█████▏    | 4224/8192 [00:08<00:07, 505.50it/s]
Adding requests:  52%|█████▏    | 4275/8192 [00:08<00:07, 504.50it/s]
Adding requests:  53%|█████▎    | 4327/8192 [00:08<00:07, 507.27it/s]
Adding requests:  53%|█████▎    | 4380/8192 [00:08<00:07, 512.82it/s]
Adding requests:  54%|█████▍    | 4432/8192 [00:08<00:07, 510.11it/s]
Adding requests:  55%|█████▍    | 4484/8192 [00:08<00:07, 507.16it/s]
Adding requests:  55%|█████▌    | 4535/8192 [00:09<00:07, 485.27it/s]
Adding requests:  56%|█████▌    | 4587/8192 [00:09<00:07, 492.35it/s]
Adding requests:  57%|█████▋    | 4639/8192 [00:09<00:07, 498.69it/s]
Adding requests:  57%|█████▋    | 4689/8192 [00:09<00:07, 496.43it/s]
Adding requests:  58%|█████▊    | 4741/8192 [00:09<00:06, 502.19it/s]
Adding requests:  58%|█████▊    | 4792/8192 [00:09<00:06, 503.58it/s]
Adding requests:  59%|█████▉    | 4843/8192 [00:09<00:06, 503.26it/s]
Adding requests:  60%|█████▉    | 4894/8192 [00:09<00:06, 498.49it/s]
Adding requests:  60%|██████    | 4945/8192 [00:09<00:06, 501.72it/s]
Adding requests:  61%|██████    | 4996/8192 [00:10<00:06, 501.68it/s]
Adding requests:  62%|██████▏   | 5048/8192 [00:10<00:06, 505.58it/s]
Adding requests:  62%|██████▏   | 5101/8192 [00:10<00:06, 510.59it/s]
Adding requests:  63%|██████▎   | 5153/8192 [00:10<00:05, 511.28it/s]
Adding requests:  64%|██████▎   | 5205/8192 [00:10<00:05, 509.05it/s]
Adding requests:  64%|██████▍   | 5256/8192 [00:10<00:05, 503.55it/s]
Adding requests:  65%|██████▍   | 5308/8192 [00:10<00:05, 506.38it/s]
Adding requests:  65%|██████▌   | 5360/8192 [00:10<00:05, 507.23it/s]
Adding requests:  66%|██████▌   | 5411/8192 [00:10<00:05, 506.90it/s]
Adding requests:  67%|██████▋   | 5462/8192 [00:10<00:05, 503.70it/s]
Adding requests:  67%|██████▋   | 5513/8192 [00:11<00:05, 499.76it/s]
Adding requests:  68%|██████▊   | 5564/8192 [00:11<00:05, 500.35it/s]
Adding requests:  69%|██████▊   | 5615/8192 [00:11<00:05, 501.93it/s]
Adding requests:  69%|██████▉   | 5666/8192 [00:11<00:05, 494.60it/s]
Adding requests:  70%|██████▉   | 5717/8192 [00:11<00:04, 498.89it/s]
Adding requests:  70%|███████   | 5769/8192 [00:11<00:04, 504.38it/s]
Adding requests:  71%|███████   | 5820/8192 [00:11<00:04, 499.40it/s]
Adding requests:  72%|███████▏  | 5870/8192 [00:11<00:04, 484.08it/s]
Adding requests:  72%|███████▏  | 5922/8192 [00:11<00:04, 491.66it/s]
Adding requests:  73%|███████▎  | 5973/8192 [00:11<00:04, 494.84it/s]
Adding requests:  74%|███████▎  | 6025/8192 [00:12<00:04, 501.02it/s]
Adding requests:  74%|███████▍  | 6076/8192 [00:12<00:04, 502.32it/s]
Adding requests:  75%|███████▍  | 6127/8192 [00:12<00:04, 504.11it/s]
Adding requests:  75%|███████▌  | 6178/8192 [00:12<00:04, 503.09it/s]
Adding requests:  76%|███████▌  | 6231/8192 [00:12<00:03, 510.30it/s]
Adding requests:  77%|███████▋  | 6283/8192 [00:12<00:03, 511.92it/s]
Adding requests:  77%|███████▋  | 6335/8192 [00:12<00:03, 513.35it/s]
Adding requests:  78%|███████▊  | 6387/8192 [00:12<00:03, 513.89it/s]
Adding requests:  79%|███████▊  | 6440/8192 [00:12<00:03, 517.51it/s]
Adding requests:  79%|███████▉  | 6493/8192 [00:12<00:03, 518.82it/s]
Adding requests:  80%|███████▉  | 6545/8192 [00:13<00:03, 518.55it/s]
Adding requests:  81%|████████  | 6597/8192 [00:13<00:03, 514.42it/s]
Adding requests:  81%|████████  | 6649/8192 [00:13<00:03, 513.66it/s]
Adding requests:  82%|████████▏ | 6701/8192 [00:13<00:02, 512.27it/s]
Adding requests:  82%|████████▏ | 6753/8192 [00:13<00:02, 507.84it/s]
Adding requests:  83%|████████▎ | 6806/8192 [00:13<00:02, 513.70it/s]
Adding requests:  84%|████████▎ | 6858/8192 [00:13<00:02, 513.42it/s]
Adding requests:  84%|████████▍ | 6911/8192 [00:13<00:02, 515.60it/s]
Adding requests:  85%|████████▌ | 6964/8192 [00:13<00:02, 518.46it/s]
Adding requests:  86%|████████▌ | 7016/8192 [00:13<00:02, 512.05it/s]
Adding requests:  86%|████████▋ | 7068/8192 [00:14<00:02, 508.98it/s]
Adding requests:  87%|████████▋ | 7121/8192 [00:14<00:02, 513.32it/s]
Adding requests:  88%|████████▊ | 7173/8192 [00:14<00:02, 495.33it/s]
Adding requests:  88%|████████▊ | 7225/8192 [00:14<00:01, 501.25it/s]
Adding requests:  89%|████████▉ | 7277/8192 [00:14<00:01, 504.35it/s]
Adding requests:  89%|████████▉ | 7329/8192 [00:14<00:01, 508.25it/s]
Adding requests:  90%|█████████ | 7380/8192 [00:14<00:01, 506.25it/s]
Adding requests:  91%|█████████ | 7434/8192 [00:14<00:01, 515.61it/s]
Adding requests:  91%|█████████▏| 7486/8192 [00:14<00:01, 515.85it/s]
Adding requests:  92%|█████████▏| 7538/8192 [00:15<00:01, 513.13it/s]
Adding requests:  93%|█████████▎| 7590/8192 [00:15<00:01, 512.02it/s]
Adding requests:  93%|█████████▎| 7642/8192 [00:15<00:01, 510.07it/s]
Adding requests:  94%|█████████▍| 7695/8192 [00:15<00:00, 514.96it/s]
Adding requests:  95%|█████████▍| 7747/8192 [00:15<00:00, 512.32it/s]
Adding requests:  95%|█████████▌| 7799/8192 [00:15<00:00, 506.48it/s]
Adding requests:  96%|█████████▌| 7851/8192 [00:15<00:00, 509.70it/s]
Adding requests:  96%|█████████▋| 7902/8192 [00:15<00:00, 507.06it/s]
Adding requests:  97%|█████████▋| 7953/8192 [00:15<00:00, 504.03it/s]
Adding requests:  98%|█████████▊| 8004/8192 [00:15<00:00, 504.84it/s]
Adding requests:  98%|█████████▊| 8055/8192 [00:16<00:00, 502.41it/s]
Adding requests:  99%|█████████▉| 8107/8192 [00:16<00:00, 507.49it/s]
Adding requests: 100%|█████████▉| 8159/8192 [00:16<00:00, 508.86it/s]
Adding requests: 100%|██████████| 8192/8192 [00:16<00:00, 502.54it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|█▊        | 1505/8192 [00:00<00:00, 11715.11it/s, est. speed input: 11998496.05 toks/s, output: 11715.76 toks/s]
Processed prompts:  33%|███▎      | 2677/8192 [00:12<00:29, 184.88it/s, est. speed input: 227000.94 toks/s, output: 221.68 toks/s]      
Processed prompts:  33%|███▎      | 2721/8192 [00:12<00:31, 176.12it/s, est. speed input: 218621.63 toks/s, output: 213.50 toks/s]
Processed prompts:  39%|███▉      | 3208/8192 [00:17<00:34, 145.55it/s, est. speed input: 188491.77 toks/s, output: 184.07 toks/s]
Processed prompts:  42%|████▏     | 3477/8192 [00:20<00:35, 133.92it/s, est. speed input: 177064.61 toks/s, output: 172.91 toks/s]
Processed prompts:  44%|████▍     | 3644/8192 [00:22<00:36, 122.92it/s, est. speed input: 168696.29 toks/s, output: 164.74 toks/s]
Processed prompts:  46%|████▌     | 3754/8192 [00:23<00:38, 116.05it/s, est. speed input: 163909.01 toks/s, output: 160.07 toks/s]
Processed prompts:  47%|████▋     | 3830/8192 [00:24<00:37, 115.73it/s, est. speed input: 162569.52 toks/s, output: 158.76 toks/s]
Processed prompts:  47%|████▋     | 3885/8192 [00:24<00:38, 111.20it/s, est. speed input: 160446.84 toks/s, output: 156.69 toks/s]
Processed prompts:  48%|████▊     | 3937/8192 [00:25<00:40, 105.75it/s, est. speed input: 158306.71 toks/s, output: 154.60 toks/s]
Processed prompts:  49%|████▉     | 4001/8192 [00:26<00:40, 104.02it/s, est. speed input: 156793.50 toks/s, output: 153.12 toks/s]
Processed prompts:  50%|████▉     | 4065/8192 [00:26<00:40, 102.20it/s, est. speed input: 155314.13 toks/s, output: 151.67 toks/s]
Processed prompts:  50%|█████     | 4129/8192 [00:27<00:40, 100.54it/s, est. speed input: 153893.32 toks/s, output: 150.29 toks/s]
Processed prompts:  51%|█████     | 4193/8192 [00:28<00:40, 99.51it/s, est. speed input: 152590.19 toks/s, output: 149.01 toks/s] 
Processed prompts:  52%|█████▏    | 4257/8192 [00:28<00:39, 98.77it/s, est. speed input: 151357.44 toks/s, output: 147.81 toks/s]
Processed prompts:  53%|█████▎    | 4321/8192 [00:29<00:39, 98.13it/s, est. speed input: 150171.75 toks/s, output: 146.65 toks/s]
Processed prompts:  54%|█████▎    | 4385/8192 [00:30<00:39, 97.28it/s, est. speed input: 148993.58 toks/s, output: 145.50 toks/s]
Processed prompts:  54%|█████▍    | 4449/8192 [00:30<00:38, 96.64it/s, est. speed input: 147864.36 toks/s, output: 144.40 toks/s]
Processed prompts:  55%|█████▌    | 4513/8192 [00:31<00:38, 96.25it/s, est. speed input: 146791.77 toks/s, output: 143.35 toks/s]
Processed prompts:  56%|█████▌    | 4577/8192 [00:32<00:37, 95.93it/s, est. speed input: 145759.38 toks/s, output: 142.34 toks/s]
Processed prompts:  57%|█████▋    | 4641/8192 [00:32<00:37, 95.66it/s, est. speed input: 144765.37 toks/s, output: 141.37 toks/s]
Processed prompts:  57%|█████▋    | 4705/8192 [00:33<00:36, 95.54it/s, est. speed input: 143817.88 toks/s, output: 140.45 toks/s]
Processed prompts:  58%|█████▊    | 4769/8192 [00:34<00:35, 95.76it/s, est. speed input: 142938.68 toks/s, output: 139.59 toks/s]
Processed prompts:  59%|█████▉    | 4833/8192 [00:34<00:35, 95.85it/s, est. speed input: 142086.08 toks/s, output: 138.76 toks/s]
Processed prompts:  60%|█████▉    | 4897/8192 [00:35<00:34, 95.66it/s, est. speed input: 141241.91 toks/s, output: 137.93 toks/s]
Processed prompts:  61%|██████    | 4961/8192 [00:36<00:33, 95.73it/s, est. speed input: 140448.07 toks/s, output: 137.16 toks/s]
Processed prompts:  61%|██████▏   | 5025/8192 [00:36<00:33, 95.53it/s, est. speed input: 139659.76 toks/s, output: 136.39 toks/s]
Processed prompts:  62%|██████▏   | 5089/8192 [00:37<00:32, 95.42it/s, est. speed input: 138903.13 toks/s, output: 135.65 toks/s]
Processed prompts:  63%|██████▎   | 5153/8192 [00:38<00:31, 95.09it/s, est. speed input: 138151.95 toks/s, output: 134.91 toks/s]
Processed prompts:  64%|██████▎   | 5217/8192 [00:38<00:31, 94.96it/s, est. speed input: 137434.75 toks/s, output: 134.21 toks/s]
Processed prompts:  64%|██████▍   | 5281/8192 [00:39<00:30, 95.00it/s, est. speed input: 136752.72 toks/s, output: 133.55 toks/s]
Processed prompts:  65%|██████▌   | 5345/8192 [00:40<00:29, 95.02it/s, est. speed input: 136092.97 toks/s, output: 132.90 toks/s]
Processed prompts:  66%|██████▌   | 5409/8192 [00:40<00:29, 94.83it/s, est. speed input: 135439.03 toks/s, output: 132.26 toks/s]
Processed prompts:  67%|██████▋   | 5473/8192 [00:41<00:28, 94.87it/s, est. speed input: 134819.98 toks/s, output: 131.66 toks/s]
Processed prompts:  68%|██████▊   | 5537/8192 [00:42<00:27, 95.30it/s, est. speed input: 134250.70 toks/s, output: 131.10 toks/s]
Processed prompts:  68%|██████▊   | 5601/8192 [00:42<00:27, 95.18it/s, est. speed input: 133668.10 toks/s, output: 130.54 toks/s]
Processed prompts:  69%|██████▉   | 5665/8192 [00:43<00:26, 95.08it/s, est. speed input: 133102.33 toks/s, output: 129.98 toks/s]
Processed prompts:  70%|██████▉   | 5729/8192 [00:44<00:25, 95.11it/s, est. speed input: 132560.76 toks/s, output: 129.45 toks/s]
Processed prompts:  71%|███████   | 5793/8192 [00:44<00:25, 94.95it/s, est. speed input: 132022.77 toks/s, output: 128.93 toks/s]
Processed prompts:  71%|███████▏  | 5857/8192 [00:45<00:24, 94.86it/s, est. speed input: 131502.41 toks/s, output: 128.42 toks/s]
Processed prompts:  72%|███████▏  | 5921/8192 [00:46<00:23, 94.83it/s, est. speed input: 130999.58 toks/s, output: 127.93 toks/s]
Processed prompts:  73%|███████▎  | 5985/8192 [00:46<00:23, 94.80it/s, est. speed input: 130510.69 toks/s, output: 127.45 toks/s]
Processed prompts:  74%|███████▍  | 6049/8192 [00:47<00:22, 94.78it/s, est. speed input: 130035.08 toks/s, output: 126.99 toks/s]
Processed prompts:  75%|███████▍  | 6113/8192 [00:48<00:21, 94.73it/s, est. speed input: 129571.34 toks/s, output: 126.53 toks/s]
Processed prompts:  75%|███████▌  | 6177/8192 [00:48<00:21, 94.82it/s, est. speed input: 129127.50 toks/s, output: 126.10 toks/s]
Processed prompts:  76%|███████▌  | 6241/8192 [00:49<00:20, 94.82it/s, est. speed input: 128692.09 toks/s, output: 125.68 toks/s]
Processed prompts:  77%|███████▋  | 6305/8192 [00:50<00:19, 94.72it/s, est. speed input: 128262.15 toks/s, output: 125.26 toks/s]
Processed prompts:  78%|███████▊  | 6369/8192 [00:51<00:19, 94.83it/s, est. speed input: 127854.53 toks/s, output: 124.86 toks/s]
Processed prompts:  79%|███████▊  | 6433/8192 [00:51<00:18, 94.58it/s, est. speed input: 127438.72 toks/s, output: 124.45 toks/s]
Processed prompts:  79%|███████▉  | 6497/8192 [00:52<00:17, 94.67it/s, est. speed input: 127048.66 toks/s, output: 124.07 toks/s]
Processed prompts:  80%|████████  | 6561/8192 [00:53<00:17, 95.00it/s, est. speed input: 126683.76 toks/s, output: 123.71 toks/s]
Processed prompts:  81%|████████  | 6625/8192 [00:53<00:16, 95.24it/s, est. speed input: 126327.90 toks/s, output: 123.37 toks/s]
Processed prompts:  82%|████████▏ | 6689/8192 [00:54<00:15, 95.03it/s, est. speed input: 125960.36 toks/s, output: 123.01 toks/s]
Processed prompts:  82%|████████▏ | 6753/8192 [00:55<00:15, 94.93it/s, est. speed input: 125604.90 toks/s, output: 122.66 toks/s]
Processed prompts:  83%|████████▎ | 6817/8192 [00:55<00:14, 94.79it/s, est. speed input: 125253.49 toks/s, output: 122.32 toks/s]
Processed prompts:  84%|████████▍ | 6881/8192 [00:56<00:13, 94.73it/s, est. speed input: 124913.17 toks/s, output: 121.99 toks/s]
Processed prompts:  85%|████████▍ | 6945/8192 [00:57<00:13, 94.73it/s, est. speed input: 124582.89 toks/s, output: 121.66 toks/s]
Processed prompts:  86%|████████▌ | 7009/8192 [00:57<00:12, 94.72it/s, est. speed input: 124259.54 toks/s, output: 121.35 toks/s]
Processed prompts:  86%|████████▋ | 7073/8192 [00:58<00:11, 94.57it/s, est. speed input: 123936.56 toks/s, output: 121.03 toks/s]
Processed prompts:  87%|████████▋ | 7137/8192 [00:59<00:11, 95.00it/s, est. speed input: 123648.03 toks/s, output: 120.75 toks/s]
Processed prompts:  88%|████████▊ | 7201/8192 [00:59<00:10, 94.90it/s, est. speed input: 123345.94 toks/s, output: 120.45 toks/s]
Processed prompts:  89%|████████▊ | 7265/8192 [01:00<00:09, 95.07it/s, est. speed input: 123062.35 toks/s, output: 120.18 toks/s]
Processed prompts:  89%|████████▉ | 7329/8192 [01:01<00:09, 94.93it/s, est. speed input: 122772.61 toks/s, output: 119.90 toks/s]
Processed prompts:  90%|█████████ | 7393/8192 [01:01<00:08, 95.14it/s, est. speed input: 122503.48 toks/s, output: 119.63 toks/s]
Processed prompts:  91%|█████████ | 7457/8192 [01:02<00:07, 94.98it/s, est. speed input: 122226.05 toks/s, output: 119.36 toks/s]
Processed prompts:  92%|█████████▏| 7521/8192 [01:03<00:07, 94.89it/s, est. speed input: 121955.47 toks/s, output: 119.10 toks/s]
Processed prompts:  93%|█████████▎| 7585/8192 [01:03<00:06, 94.75it/s, est. speed input: 121687.37 toks/s, output: 118.84 toks/s]
Processed prompts:  93%|█████████▎| 7649/8192 [01:04<00:05, 94.75it/s, est. speed input: 121429.11 toks/s, output: 118.58 toks/s]
Processed prompts:  94%|█████████▍| 7713/8192 [01:05<00:05, 94.67it/s, est. speed input: 121172.74 toks/s, output: 118.33 toks/s]
Processed prompts:  95%|█████████▍| 7777/8192 [01:05<00:04, 94.57it/s, est. speed input: 120919.41 toks/s, output: 118.09 toks/s]
Processed prompts:  96%|█████████▌| 7841/8192 [01:06<00:03, 94.58it/s, est. speed input: 120674.78 toks/s, output: 117.85 toks/s]
Processed prompts:  96%|█████████▋| 7905/8192 [01:07<00:03, 94.60it/s, est. speed input: 120435.78 toks/s, output: 117.61 toks/s]
Processed prompts:  97%|█████████▋| 7969/8192 [01:07<00:02, 94.47it/s, est. speed input: 120195.49 toks/s, output: 117.38 toks/s]
Processed prompts:  98%|█████████▊| 8033/8192 [01:08<00:01, 94.47it/s, est. speed input: 119963.73 toks/s, output: 117.15 toks/s]
Processed prompts:  99%|█████████▉| 8097/8192 [01:09<00:01, 94.97it/s, est. speed input: 119757.00 toks/s, output: 116.95 toks/s]
Processed prompts: 100%|█████████▉| 8161/8192 [01:09<00:00, 112.25it/s, est. speed input: 120134.21 toks/s, output: 117.32 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:09<00:00, 112.25it/s, est. speed input: 120588.88 toks/s, output: 117.76 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [01:09<00:00, 117.76it/s, est. speed input: 120588.88 toks/s, output: 117.76 toks/s]
[rank0]:[W126 10:22:44.482496291 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:53:26
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:53:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1316821) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1316821) WARNING 01-26 11:53:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 36.72 requests/s, 18836.73 total tokens/s, 36.72 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:53:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:53:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:53:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:53:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:53:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:53:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:53:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:53:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:53:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:53:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:53:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:53:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:53:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:53:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:53:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:53:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:53:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1316821) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1316821) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.62it/s]
(EngineCore_DP0 pid=1316821) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1316821) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1316821) 
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1316821) [2026-01-26 11:53:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1316821) 2026-01-26 11:54:01,946 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1316821) 2026-01-26 11:54:01,969 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1316821) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  2.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.91it/s]
(EngineCore_DP0 pid=1316821) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 17.69it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  27%|██▋       | 35/128 [00:00<00:00, 349.82it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 547.60it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 541.12it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:16,  7.80it/s, est. speed input: 3996.06 toks/s, output: 7.80 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:04, 26.72it/s, est. speed input: 12202.15 toks/s, output: 23.83 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:03, 33.01it/s, est. speed input: 15029.83 toks/s, output: 29.35 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:03, 36.10it/s, est. speed input: 16483.69 toks/s, output: 32.19 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:02, 37.78it/s, est. speed input: 17355.03 toks/s, output: 33.89 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:02, 38.80it/s, est. speed input: 17936.78 toks/s, output: 35.03 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:00<00:02, 39.44it/s, est. speed input: 18352.73 toks/s, output: 35.84 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:00<00:02, 39.81it/s, est. speed input: 18657.31 toks/s, output: 36.44 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 40.09it/s, est. speed input: 18897.80 toks/s, output: 36.91 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 40.30it/s, est. speed input: 19094.71 toks/s, output: 37.29 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:01, 40.36it/s, est. speed input: 19244.06 toks/s, output: 37.59 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:01<00:01, 40.56it/s, est. speed input: 19389.36 toks/s, output: 37.87 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 40.62it/s, est. speed input: 19501.97 toks/s, output: 38.09 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:01<00:01, 40.67it/s, est. speed input: 19600.04 toks/s, output: 38.28 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:01<00:01, 40.75it/s, est. speed input: 19689.69 toks/s, output: 38.46 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:01<00:01, 40.73it/s, est. speed input: 19761.25 toks/s, output: 38.60 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 40.77it/s, est. speed input: 19828.90 toks/s, output: 38.73 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:02<00:01, 40.76it/s, est. speed input: 19886.20 toks/s, output: 38.84 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:02<00:00, 40.74it/s, est. speed input: 19936.32 toks/s, output: 38.94 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:02<00:00, 40.75it/s, est. speed input: 19982.74 toks/s, output: 39.03 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 40.75it/s, est. speed input: 20024.95 toks/s, output: 39.11 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:02<00:00, 40.71it/s, est. speed input: 20059.93 toks/s, output: 39.18 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:02<00:00, 40.68it/s, est. speed input: 20091.64 toks/s, output: 39.24 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:02<00:00, 40.62it/s, est. speed input: 20118.00 toks/s, output: 39.29 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 40.60it/s, est. speed input: 20143.78 toks/s, output: 39.34 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:03<00:00, 40.61it/s, est. speed input: 20169.14 toks/s, output: 39.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 40.61it/s, est. speed input: 20179.36 toks/s, output: 39.41 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.41it/s, est. speed input: 20179.36 toks/s, output: 39.41 toks/s]
[rank0]:[W126 11:54:08.387760384 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:54:10
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:54:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1318011) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1318011) WARNING 01-26 11:54:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 37.07 requests/s, 37993.50 total tokens/s, 37.07 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 11:54:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:54:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:54:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:54:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:54:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:54:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:54:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:54:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:54:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:54:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:54:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:54:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:54:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:54:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:54:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:54:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:54:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1318011) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1318011) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.64it/s]
(EngineCore_DP0 pid=1318011) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1318011) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1318011) 
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1318011) [2026-01-26 11:54:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1318011) 2026-01-26 11:54:45,153 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1318011) 2026-01-26 11:54:45,184 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1318011) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
(EngineCore_DP0 pid=1318011) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▌        | 20/128 [00:00<00:00, 198.53it/s]
Adding requests:  48%|████▊     | 61/128 [00:00<00:00, 318.33it/s]
Adding requests:  77%|███████▋  | 98/128 [00:00<00:00, 338.03it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 332.15it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 55.35it/s, est. speed input: 56702.73 toks/s, output: 55.36 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:02, 45.97it/s, est. speed input: 48307.36 toks/s, output: 47.17 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:02, 43.81it/s, est. speed input: 46276.72 toks/s, output: 45.19 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:00<00:02, 42.77it/s, est. speed input: 45255.33 toks/s, output: 44.19 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:02, 42.23it/s, est. speed input: 44666.40 toks/s, output: 43.62 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:02, 41.92it/s, est. speed input: 44281.08 toks/s, output: 43.24 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:00<00:02, 41.70it/s, est. speed input: 43988.00 toks/s, output: 42.96 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:00<00:02, 41.56it/s, est. speed input: 43776.60 toks/s, output: 42.75 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:01, 41.46it/s, est. speed input: 43604.92 toks/s, output: 42.58 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:01, 41.38it/s, est. speed input: 43462.90 toks/s, output: 42.44 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 41.36it/s, est. speed input: 43361.44 toks/s, output: 42.34 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:01<00:01, 41.31it/s, est. speed input: 43262.42 toks/s, output: 42.25 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:01<00:01, 41.27it/s, est. speed input: 43178.55 toks/s, output: 42.17 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:01<00:01, 41.26it/s, est. speed input: 43111.62 toks/s, output: 42.10 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:01<00:01, 41.26it/s, est. speed input: 43054.63 toks/s, output: 42.04 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:01<00:01, 41.25it/s, est. speed input: 43002.16 toks/s, output: 41.99 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:02<00:00, 41.23it/s, est. speed input: 42954.02 toks/s, output: 41.95 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:02<00:00, 41.20it/s, est. speed input: 42907.72 toks/s, output: 41.90 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 41.20it/s, est. speed input: 42870.37 toks/s, output: 41.87 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:02<00:00, 41.30it/s, est. speed input: 42853.65 toks/s, output: 41.85 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:02<00:00, 41.35it/s, est. speed input: 42834.19 toks/s, output: 41.83 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:02<00:00, 41.30it/s, est. speed input: 42804.63 toks/s, output: 41.80 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:02<00:00, 41.34it/s, est. speed input: 42787.98 toks/s, output: 41.78 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:02<00:00, 41.36it/s, est. speed input: 42771.72 toks/s, output: 41.77 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 41.33it/s, est. speed input: 42751.64 toks/s, output: 41.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 41.33it/s, est. speed input: 42749.78 toks/s, output: 41.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 41.74it/s, est. speed input: 42749.78 toks/s, output: 41.75 toks/s]
[rank0]:[W126 11:54:51.161012709 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 11:54:53
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:55:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1319130) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1319130) WARNING 01-26 11:55:17 [backends.py:609] Failed to read file <frozen os>
Throughput: 43.04 requests/s, 44112.61 total tokens/s, 43.04 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 11:55:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:55:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1319130) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1319130) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.62it/s]
(EngineCore_DP0 pid=1319130) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.91it/s]
(EngineCore_DP0 pid=1319130) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.99it/s]
(EngineCore_DP0 pid=1319130) 
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1319130) [2026-01-26 11:55:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1319130) 2026-01-26 11:55:28,001 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1319130) 2026-01-26 11:55:28,024 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1319130) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  6.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  6.78it/s]
(EngineCore_DP0 pid=1319130) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  1.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   7%|▋         | 19/256 [00:00<00:01, 187.31it/s]
Adding requests:  23%|██▎       | 58/256 [00:00<00:00, 302.89it/s]
Adding requests:  37%|███▋      | 95/256 [00:00<00:00, 332.63it/s]
Adding requests:  52%|█████▏    | 133/256 [00:00<00:00, 347.74it/s]
Adding requests:  67%|██████▋   | 172/256 [00:00<00:00, 362.07it/s]
Adding requests:  83%|████████▎ | 212/256 [00:00<00:00, 374.77it/s]
Adding requests:  98%|█████████▊| 251/256 [00:00<00:00, 378.69it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 354.48it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 141.53it/s, est. speed input: 144947.46 toks/s, output: 141.54 toks/s]
Processed prompts:  14%|█▎        | 35/256 [00:00<00:03, 72.43it/s, est. speed input: 80949.45 toks/s, output: 79.05 toks/s]   
Processed prompts:  17%|█▋        | 44/256 [00:00<00:03, 59.16it/s, est. speed input: 68504.62 toks/s, output: 66.90 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:00<00:03, 57.83it/s, est. speed input: 66379.02 toks/s, output: 64.82 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:00<00:03, 51.57it/s, est. speed input: 61680.99 toks/s, output: 60.23 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:01<00:03, 50.02it/s, est. speed input: 59911.11 toks/s, output: 58.51 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:03, 48.96it/s, est. speed input: 58568.83 toks/s, output: 57.19 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:01<00:03, 48.17it/s, est. speed input: 57487.64 toks/s, output: 56.14 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:03, 47.66it/s, est. speed input: 56615.17 toks/s, output: 55.29 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:01<00:03, 47.37it/s, est. speed input: 55908.72 toks/s, output: 54.60 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:01<00:03, 47.07it/s, est. speed input: 55282.01 toks/s, output: 53.99 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:01<00:03, 46.73it/s, est. speed input: 54706.91 toks/s, output: 53.42 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:03, 46.42it/s, est. speed input: 54188.37 toks/s, output: 52.92 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:02<00:03, 46.26it/s, est. speed input: 53746.38 toks/s, output: 52.49 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:02, 46.25it/s, est. speed input: 53379.75 toks/s, output: 52.13 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:02<00:02, 46.24it/s, est. speed input: 53050.39 toks/s, output: 51.81 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:02<00:02, 46.29it/s, est. speed input: 52766.29 toks/s, output: 51.53 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:02<00:02, 46.30it/s, est. speed input: 52507.42 toks/s, output: 51.28 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:02<00:02, 46.24it/s, est. speed input: 52258.27 toks/s, output: 51.03 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:02<00:02, 46.15it/s, est. speed input: 52025.65 toks/s, output: 50.81 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:03<00:02, 46.11it/s, est. speed input: 51815.59 toks/s, output: 50.60 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:03<00:02, 46.06it/s, est. speed input: 51619.42 toks/s, output: 50.41 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:03<00:01, 46.08it/s, est. speed input: 51446.20 toks/s, output: 50.24 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:03<00:01, 46.07it/s, est. speed input: 51283.58 toks/s, output: 50.08 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:03<00:01, 46.12it/s, est. speed input: 51140.86 toks/s, output: 49.94 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:03<00:01, 46.17it/s, est. speed input: 51008.97 toks/s, output: 49.81 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:03<00:01, 46.16it/s, est. speed input: 50881.09 toks/s, output: 49.69 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:03<00:01, 46.07it/s, est. speed input: 50751.76 toks/s, output: 49.56 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:04<00:01, 47.41it/s, est. speed input: 50789.75 toks/s, output: 49.60 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:04<00:01, 47.21it/s, est. speed input: 50700.61 toks/s, output: 49.51 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:04<00:00, 46.94it/s, est. speed input: 50603.09 toks/s, output: 49.42 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:04<00:00, 46.66it/s, est. speed input: 50501.05 toks/s, output: 49.32 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:04<00:00, 46.53it/s, est. speed input: 50411.37 toks/s, output: 49.23 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:04<00:00, 46.39it/s, est. speed input: 50321.92 toks/s, output: 49.14 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:04<00:00, 46.43it/s, est. speed input: 50250.47 toks/s, output: 49.07 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:04<00:00, 46.16it/s, est. speed input: 50154.73 toks/s, output: 48.98 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:05<00:00, 46.06it/s, est. speed input: 50072.61 toks/s, output: 48.90 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 48.13it/s, est. speed input: 50178.62 toks/s, output: 49.00 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 48.13it/s, est. speed input: 50178.62 toks/s, output: 49.00 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 49.00it/s, est. speed input: 50178.62 toks/s, output: 49.00 toks/s]
[rank0]:[W126 11:55:36.870969711 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 11:55:38
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:55:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1320277) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1320277) WARNING 01-26 11:56:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 47.42 requests/s, 48602.84 total tokens/s, 47.42 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 11:55:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:55:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:55:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:55:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:55:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:55:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:55:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:55:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:55:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1320277) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1320277) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.63it/s]
(EngineCore_DP0 pid=1320277) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1320277) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1320277) 
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1320277) [2026-01-26 11:55:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1320277) 2026-01-26 11:56:15,372 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1320277) 2026-01-26 11:56:15,397 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1320277) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  5.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  5.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.82it/s]
(EngineCore_DP0 pid=1320277) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 17.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 18.49it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 20/512 [00:00<00:02, 195.71it/s]
Adding requests:  12%|█▏        | 59/512 [00:00<00:01, 308.36it/s]
Adding requests:  19%|█▉        | 96/512 [00:00<00:01, 332.58it/s]
Adding requests:  26%|██▌       | 133/512 [00:00<00:01, 344.06it/s]
Adding requests:  34%|███▎      | 172/512 [00:00<00:00, 359.18it/s]
Adding requests:  42%|████▏     | 213/512 [00:00<00:00, 374.90it/s]
Adding requests:  49%|████▉     | 252/512 [00:00<00:00, 377.47it/s]
Adding requests:  57%|█████▋    | 291/512 [00:00<00:00, 380.16it/s]
Adding requests:  65%|██████▍   | 332/512 [00:00<00:00, 387.89it/s]
Adding requests:  73%|███████▎  | 373/512 [00:01<00:00, 394.28it/s]
Adding requests:  81%|████████  | 414/512 [00:01<00:00, 398.35it/s]
Adding requests:  89%|████████▊ | 454/512 [00:01<00:00, 396.19it/s]
Adding requests:  97%|█████████▋| 497/512 [00:01<00:00, 404.50it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 377.53it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:00<00:01, 395.77it/s, est. speed input: 405325.60 toks/s, output: 395.78 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:00<00:04, 88.29it/s, est. speed input: 105338.69 toks/s, output: 102.87 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:01<00:05, 72.86it/s, est. speed input: 88852.83 toks/s, output: 86.77 toks/s]  
Processed prompts:  26%|██▋       | 135/512 [00:01<00:05, 67.79it/s, est. speed input: 83569.63 toks/s, output: 81.61 toks/s]
Processed prompts:  28%|██▊       | 145/512 [00:01<00:05, 66.05it/s, est. speed input: 81402.34 toks/s, output: 79.49 toks/s]
Processed prompts:  30%|███       | 154/512 [00:02<00:06, 57.26it/s, est. speed input: 76005.65 toks/s, output: 74.22 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:02<00:06, 55.33it/s, est. speed input: 74044.42 toks/s, output: 72.31 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:02<00:06, 53.63it/s, est. speed input: 72336.23 toks/s, output: 70.64 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:02<00:06, 52.35it/s, est. speed input: 70884.94 toks/s, output: 69.22 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:02<00:06, 51.16it/s, est. speed input: 69551.25 toks/s, output: 67.92 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:02<00:06, 49.99it/s, est. speed input: 68294.65 toks/s, output: 66.69 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:03<00:06, 50.50it/s, est. speed input: 67532.93 toks/s, output: 65.95 toks/s]
Processed prompts:  41%|████      | 210/512 [00:03<00:06, 49.90it/s, est. speed input: 66615.72 toks/s, output: 65.05 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:03<00:05, 49.39it/s, est. speed input: 65768.92 toks/s, output: 64.23 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:03<00:05, 49.05it/s, est. speed input: 65006.39 toks/s, output: 63.48 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:03<00:05, 48.60it/s, est. speed input: 64269.82 toks/s, output: 62.76 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:03<00:05, 48.29it/s, est. speed input: 63598.19 toks/s, output: 62.11 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:04<00:05, 48.21it/s, est. speed input: 63007.09 toks/s, output: 61.53 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:04<00:05, 48.14it/s, est. speed input: 62458.93 toks/s, output: 60.99 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:04<00:05, 48.19it/s, est. speed input: 61970.55 toks/s, output: 60.52 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:04<00:04, 48.14it/s, est. speed input: 61503.46 toks/s, output: 60.06 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:04<00:04, 48.08it/s, est. speed input: 61064.95 toks/s, output: 59.63 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:04<00:04, 47.94it/s, est. speed input: 60642.47 toks/s, output: 59.22 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:05<00:04, 47.88it/s, est. speed input: 60253.73 toks/s, output: 58.84 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:05<00:04, 49.21it/s, est. speed input: 60067.89 toks/s, output: 58.66 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:05<00:04, 49.05it/s, est. speed input: 59756.05 toks/s, output: 58.36 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:05<00:03, 48.71it/s, est. speed input: 59434.48 toks/s, output: 58.04 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:05<00:03, 48.42it/s, est. speed input: 59126.44 toks/s, output: 57.74 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:05<00:03, 48.27it/s, est. speed input: 58840.52 toks/s, output: 57.46 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:06<00:03, 48.07it/s, est. speed input: 58560.59 toks/s, output: 57.19 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:06<00:03, 47.96it/s, est. speed input: 58298.61 toks/s, output: 56.93 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:06<00:03, 48.01it/s, est. speed input: 58064.06 toks/s, output: 56.70 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:06<00:02, 47.96it/s, est. speed input: 57832.41 toks/s, output: 56.48 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:06<00:02, 47.89it/s, est. speed input: 57609.18 toks/s, output: 56.26 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:06<00:02, 47.89it/s, est. speed input: 57401.22 toks/s, output: 56.06 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:07<00:02, 47.85it/s, est. speed input: 57199.50 toks/s, output: 55.86 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:07<00:02, 47.82it/s, est. speed input: 57006.62 toks/s, output: 55.67 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:07<00:02, 47.90it/s, est. speed input: 56832.29 toks/s, output: 55.50 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:07<00:01, 47.88it/s, est. speed input: 56657.71 toks/s, output: 55.33 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:07<00:01, 47.97it/s, est. speed input: 56500.29 toks/s, output: 55.18 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:07<00:01, 49.25it/s, est. speed input: 56448.06 toks/s, output: 55.12 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:08<00:01, 48.90it/s, est. speed input: 56299.24 toks/s, output: 54.98 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:08<00:01, 48.48it/s, est. speed input: 56142.79 toks/s, output: 54.83 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:08<00:01, 48.38it/s, est. speed input: 56006.92 toks/s, output: 54.69 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:08<00:00, 48.23it/s, est. speed input: 55870.80 toks/s, output: 54.56 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:08<00:00, 48.15it/s, est. speed input: 55741.30 toks/s, output: 54.43 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:08<00:00, 48.05it/s, est. speed input: 55613.75 toks/s, output: 54.31 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:09<00:00, 48.07it/s, est. speed input: 55496.77 toks/s, output: 54.20 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:09<00:00, 47.93it/s, est. speed input: 55373.50 toks/s, output: 54.08 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:09<00:00, 48.03it/s, est. speed input: 55268.63 toks/s, output: 53.97 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 48.03it/s, est. speed input: 55540.77 toks/s, output: 54.24 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 54.24it/s, est. speed input: 55540.77 toks/s, output: 54.24 toks/s]
[rank0]:[W126 11:56:29.199636004 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 11:56:31
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:56:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1321542) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1321542) WARNING 01-26 11:56:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 49.08 requests/s, 50307.87 total tokens/s, 49.08 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 11:56:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:56:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:56:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:56:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:56:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:56:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:56:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:56:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:56:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:56:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:56:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:56:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:56:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:56:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:56:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1321542) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1321542) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.63it/s]
(EngineCore_DP0 pid=1321542) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1321542) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.01it/s]
(EngineCore_DP0 pid=1321542) 
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1321542) [2026-01-26 11:56:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1321542) 2026-01-26 11:57:10,161 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1321542) 2026-01-26 11:57:10,185 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1321542) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:01,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:01<00:00,  2.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:01<00:00,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.03it/s]
(EngineCore_DP0 pid=1321542) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 19.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 20.13it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 28/1024 [00:00<00:03, 278.09it/s]
Adding requests:   7%|▋         | 68/1024 [00:00<00:02, 348.78it/s]
Adding requests:  10%|█         | 105/1024 [00:00<00:02, 357.07it/s]
Adding requests:  14%|█▍        | 142/1024 [00:00<00:02, 361.02it/s]
Adding requests:  18%|█▊        | 182/1024 [00:00<00:02, 372.10it/s]
Adding requests:  22%|██▏       | 223/1024 [00:00<00:02, 384.74it/s]
Adding requests:  26%|██▌       | 262/1024 [00:00<00:01, 381.14it/s]
Adding requests:  29%|██▉       | 302/1024 [00:00<00:01, 386.17it/s]
Adding requests:  33%|███▎      | 343/1024 [00:00<00:01, 389.88it/s]
Adding requests:  38%|███▊      | 384/1024 [00:01<00:01, 394.45it/s]
Adding requests:  42%|████▏     | 425/1024 [00:01<00:01, 397.50it/s]
Adding requests:  45%|████▌     | 465/1024 [00:01<00:01, 393.13it/s]
Adding requests:  50%|████▉     | 507/1024 [00:01<00:01, 398.39it/s]
Adding requests:  53%|█████▎    | 547/1024 [00:01<00:01, 396.46it/s]
Adding requests:  57%|█████▋    | 587/1024 [00:01<00:01, 395.07it/s]
Adding requests:  61%|██████    | 627/1024 [00:01<00:01, 394.13it/s]
Adding requests:  65%|██████▌   | 667/1024 [00:01<00:00, 385.34it/s]
Adding requests:  69%|██████▉   | 708/1024 [00:01<00:00, 391.42it/s]
Adding requests:  73%|███████▎  | 748/1024 [00:01<00:00, 385.29it/s]
Adding requests:  77%|███████▋  | 788/1024 [00:02<00:00, 388.51it/s]
Adding requests:  81%|████████  | 828/1024 [00:02<00:00, 390.11it/s]
Adding requests:  85%|████████▍ | 868/1024 [00:02<00:00, 391.86it/s]
Adding requests:  89%|████████▉ | 909/1024 [00:02<00:00, 396.27it/s]
Adding requests:  93%|█████████▎| 949/1024 [00:02<00:00, 387.28it/s]
Adding requests:  97%|█████████▋| 989/1024 [00:02<00:00, 389.63it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 385.74it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:00<00:01, 583.13it/s, est. speed input: 597189.97 toks/s, output: 583.15 toks/s]
Processed prompts:  18%|█▊        | 189/1024 [00:01<00:07, 115.84it/s, est. speed input: 142121.67 toks/s, output: 138.79 toks/s]
Processed prompts:  21%|██        | 217/1024 [00:01<00:08, 96.25it/s, est. speed input: 120950.01 toks/s, output: 118.11 toks/s] 
Processed prompts:  23%|██▎       | 235/1024 [00:02<00:10, 76.68it/s, est. speed input: 103783.29 toks/s, output: 101.35 toks/s]
Processed prompts:  24%|██▍       | 248/1024 [00:02<00:10, 77.11it/s, est. speed input: 102329.20 toks/s, output: 99.93 toks/s] 
Processed prompts:  25%|██▌       | 259/1024 [00:02<00:11, 64.70it/s, est. speed input: 94393.76 toks/s, output: 92.18 toks/s] 
Processed prompts:  26%|██▌       | 268/1024 [00:02<00:11, 63.14it/s, est. speed input: 92334.64 toks/s, output: 90.17 toks/s]
Processed prompts:  27%|██▋       | 276/1024 [00:03<00:12, 60.64it/s, est. speed input: 90237.05 toks/s, output: 88.12 toks/s]
Processed prompts:  28%|██▊       | 283/1024 [00:03<00:13, 56.92it/s, est. speed input: 87991.67 toks/s, output: 85.93 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:03<00:13, 53.58it/s, est. speed input: 85910.10 toks/s, output: 83.90 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:03<00:13, 52.38it/s, est. speed input: 84288.32 toks/s, output: 82.31 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:03<00:13, 52.95it/s, est. speed input: 83190.87 toks/s, output: 81.24 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:03<00:13, 51.99it/s, est. speed input: 81853.52 toks/s, output: 79.93 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:04<00:13, 51.30it/s, est. speed input: 80626.66 toks/s, output: 78.74 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:04<00:13, 50.66it/s, est. speed input: 79463.88 toks/s, output: 77.60 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:04<00:13, 50.22it/s, est. speed input: 78391.00 toks/s, output: 76.55 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:04<00:13, 49.81it/s, est. speed input: 77375.21 toks/s, output: 75.56 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:04<00:13, 49.52it/s, est. speed input: 76429.38 toks/s, output: 74.64 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:04<00:13, 49.51it/s, est. speed input: 75580.49 toks/s, output: 73.81 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:05<00:13, 49.44it/s, est. speed input: 74775.32 toks/s, output: 73.02 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:05<00:13, 49.36it/s, est. speed input: 74016.39 toks/s, output: 72.28 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:05<00:12, 49.22it/s, est. speed input: 73289.64 toks/s, output: 71.57 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:05<00:12, 49.21it/s, est. speed input: 72618.87 toks/s, output: 70.92 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:05<00:12, 49.19it/s, est. speed input: 71984.50 toks/s, output: 70.30 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:05<00:12, 49.22it/s, est. speed input: 71390.43 toks/s, output: 69.72 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:06<00:12, 49.18it/s, est. speed input: 70821.22 toks/s, output: 69.16 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:06<00:12, 49.16it/s, est. speed input: 70282.24 toks/s, output: 68.63 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:06<00:11, 50.74it/s, est. speed input: 69957.37 toks/s, output: 68.32 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:06<00:11, 50.23it/s, est. speed input: 69464.94 toks/s, output: 67.84 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:06<00:11, 49.95it/s, est. speed input: 69004.06 toks/s, output: 67.39 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:06<00:11, 49.71it/s, est. speed input: 68559.82 toks/s, output: 66.95 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:07<00:11, 49.54it/s, est. speed input: 68136.42 toks/s, output: 66.54 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:07<00:11, 49.36it/s, est. speed input: 67725.23 toks/s, output: 66.14 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:07<00:11, 49.20it/s, est. speed input: 67329.62 toks/s, output: 65.75 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:07<00:10, 49.20it/s, est. speed input: 66961.17 toks/s, output: 65.39 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:07<00:10, 49.13it/s, est. speed input: 66602.77 toks/s, output: 65.04 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:07<00:10, 49.22it/s, est. speed input: 66271.91 toks/s, output: 64.72 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:07<00:10, 49.25it/s, est. speed input: 65951.54 toks/s, output: 64.41 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:08<00:10, 49.21it/s, est. speed input: 65638.22 toks/s, output: 64.10 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:08<00:10, 49.14it/s, est. speed input: 65334.00 toks/s, output: 63.80 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:08<00:09, 49.02it/s, est. speed input: 65034.94 toks/s, output: 63.51 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:08<00:09, 48.95it/s, est. speed input: 64748.64 toks/s, output: 63.23 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:08<00:09, 49.05it/s, est. speed input: 64484.81 toks/s, output: 62.97 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:08<00:09, 49.08it/s, est. speed input: 64227.85 toks/s, output: 62.72 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:09<00:09, 49.08it/s, est. speed input: 63978.13 toks/s, output: 62.48 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:09<00:09, 49.01it/s, est. speed input: 63732.27 toks/s, output: 62.24 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:09<00:08, 48.96it/s, est. speed input: 63494.51 toks/s, output: 62.01 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:09<00:08, 48.85it/s, est. speed input: 63259.04 toks/s, output: 61.78 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:09<00:08, 48.96it/s, est. speed input: 63045.89 toks/s, output: 61.57 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:09<00:08, 48.99it/s, est. speed input: 62835.18 toks/s, output: 61.36 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:10<00:08, 49.02it/s, est. speed input: 62633.14 toks/s, output: 61.16 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:10<00:08, 48.95it/s, est. speed input: 62430.72 toks/s, output: 60.97 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:10<00:07, 48.96it/s, est. speed input: 62238.20 toks/s, output: 60.78 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:10<00:07, 48.83it/s, est. speed input: 62043.22 toks/s, output: 60.59 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:10<00:07, 48.96it/s, est. speed input: 61867.99 toks/s, output: 60.42 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:10<00:07, 48.98it/s, est. speed input: 61693.94 toks/s, output: 60.25 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:11<00:07, 48.90it/s, est. speed input: 61518.79 toks/s, output: 60.08 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:11<00:07, 48.92it/s, est. speed input: 61353.66 toks/s, output: 59.92 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:11<00:06, 48.96it/s, est. speed input: 61194.37 toks/s, output: 59.76 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:11<00:06, 48.92it/s, est. speed input: 61035.80 toks/s, output: 59.61 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:11<00:06, 49.02it/s, est. speed input: 60889.59 toks/s, output: 59.46 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:11<00:06, 49.04it/s, est. speed input: 60744.03 toks/s, output: 59.32 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:12<00:06, 48.94it/s, est. speed input: 60596.23 toks/s, output: 59.18 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:12<00:06, 48.87it/s, est. speed input: 60452.07 toks/s, output: 59.04 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:12<00:06, 48.90it/s, est. speed input: 60316.00 toks/s, output: 58.90 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:12<00:05, 48.94it/s, est. speed input: 60184.91 toks/s, output: 58.77 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:12<00:05, 49.07it/s, est. speed input: 60062.07 toks/s, output: 58.65 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:12<00:05, 49.18it/s, est. speed input: 59943.63 toks/s, output: 58.54 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:13<00:05, 49.07it/s, est. speed input: 59818.70 toks/s, output: 58.42 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:13<00:05, 49.13it/s, est. speed input: 59703.30 toks/s, output: 58.30 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:13<00:05, 49.12it/s, est. speed input: 59588.50 toks/s, output: 58.19 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:13<00:04, 50.80it/s, est. speed input: 59555.48 toks/s, output: 58.16 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:13<00:04, 50.37it/s, est. speed input: 59449.25 toks/s, output: 58.06 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:13<00:04, 50.21it/s, est. speed input: 59351.68 toks/s, output: 57.96 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:13<00:04, 50.04it/s, est. speed input: 59253.65 toks/s, output: 57.86 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:14<00:04, 49.81it/s, est. speed input: 59153.00 toks/s, output: 57.77 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:14<00:03, 49.60it/s, est. speed input: 59052.16 toks/s, output: 57.67 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:14<00:03, 49.38it/s, est. speed input: 58950.60 toks/s, output: 57.57 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:14<00:03, 49.33it/s, est. speed input: 58855.67 toks/s, output: 57.48 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:14<00:03, 49.30it/s, est. speed input: 58762.81 toks/s, output: 57.39 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:14<00:03, 49.29it/s, est. speed input: 58672.94 toks/s, output: 57.30 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:15<00:03, 49.25it/s, est. speed input: 58583.22 toks/s, output: 57.21 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:15<00:03, 49.34it/s, est. speed input: 58500.37 toks/s, output: 57.13 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:15<00:02, 49.30it/s, est. speed input: 58414.99 toks/s, output: 57.05 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:15<00:02, 49.22it/s, est. speed input: 58329.57 toks/s, output: 56.96 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:15<00:02, 49.25it/s, est. speed input: 58249.06 toks/s, output: 56.88 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:15<00:02, 49.23it/s, est. speed input: 58168.73 toks/s, output: 56.81 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:16<00:02, 49.20it/s, est. speed input: 58089.07 toks/s, output: 56.73 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:16<00:02, 49.21it/s, est. speed input: 58012.54 toks/s, output: 56.65 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:16<00:01, 49.29it/s, est. speed input: 57940.15 toks/s, output: 56.58 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:16<00:01, 49.36it/s, est. speed input: 57869.94 toks/s, output: 56.51 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:16<00:01, 49.33it/s, est. speed input: 57797.96 toks/s, output: 56.44 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:16<00:01, 49.17it/s, est. speed input: 57722.06 toks/s, output: 56.37 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:17<00:01, 49.15it/s, est. speed input: 57651.02 toks/s, output: 56.30 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:17<00:01, 49.12it/s, est. speed input: 57580.99 toks/s, output: 56.23 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:17<00:00, 49.17it/s, est. speed input: 57514.49 toks/s, output: 56.17 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:17<00:00, 49.21it/s, est. speed input: 57449.80 toks/s, output: 56.10 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:17<00:00, 49.37it/s, est. speed input: 57390.57 toks/s, output: 56.05 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:17<00:00, 49.34it/s, est. speed input: 57327.72 toks/s, output: 55.98 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:18<00:00, 49.30it/s, est. speed input: 57265.08 toks/s, output: 55.92 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:18<00:00, 50.81it/s, est. speed input: 57255.33 toks/s, output: 55.91 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:18<00:00, 50.81it/s, est. speed input: 57591.50 toks/s, output: 56.24 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:18<00:00, 56.24it/s, est. speed input: 57591.50 toks/s, output: 56.24 toks/s]
[rank0]:[W126 11:57:34.301973125 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 11:57:36
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:57:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1322990) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1322990) WARNING 01-26 11:58:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 50.40 requests/s, 51662.66 total tokens/s, 50.40 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 11:57:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:57:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:57:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:57:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:57:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:57:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:57:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:57:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:57:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:58:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:58:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:58:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:58:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:58:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:58:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:58:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:58:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:58:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1322990) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1322990) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=1322990) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.87it/s]
(EngineCore_DP0 pid=1322990) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.93it/s]
(EngineCore_DP0 pid=1322990) 
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1322990) [2026-01-26 11:58:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1322990) [rank0]:W0126 11:58:16.674000 1322990 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1322990) [rank0]:W0126 11:58:16.753000 1322990 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1322990) [rank0]:W0126 11:58:17.719000 1322990 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1322990) [rank0]:W0126 11:58:17.850000 1322990 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1322990) 2026-01-26 11:58:21,952 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1322990) 2026-01-26 11:58:21,978 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1322990) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:04,  1.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:02,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:01<00:00,  4.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  7.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  5.29it/s]
(EngineCore_DP0 pid=1322990) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 19.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 20.12it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 20.00it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 242.74it/s]
Adding requests:   3%|▎         | 65/2048 [00:00<00:05, 331.39it/s]
Adding requests:   5%|▍         | 101/2048 [00:00<00:05, 341.18it/s]
Adding requests:   7%|▋         | 137/2048 [00:00<00:05, 347.81it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:05, 361.87it/s]
Adding requests:  11%|█         | 217/2048 [00:00<00:04, 376.89it/s]
Adding requests:  12%|█▎        | 256/2048 [00:00<00:04, 378.75it/s]
Adding requests:  14%|█▍        | 296/2048 [00:00<00:04, 383.80it/s]
Adding requests:  17%|█▋        | 338/2048 [00:00<00:04, 392.11it/s]
Adding requests:  18%|█▊        | 378/2048 [00:01<00:04, 394.25it/s]
Adding requests:  21%|██        | 421/2048 [00:01<00:04, 402.18it/s]
Adding requests:  23%|██▎       | 462/2048 [00:01<00:03, 397.63it/s]
Adding requests:  25%|██▍       | 504/2048 [00:01<00:03, 404.14it/s]
Adding requests:  27%|██▋       | 547/2048 [00:01<00:03, 408.46it/s]
Adding requests:  29%|██▊       | 588/2048 [00:01<00:03, 402.80it/s]
Adding requests:  31%|███       | 629/2048 [00:01<00:03, 398.40it/s]
Adding requests:  33%|███▎      | 669/2048 [00:01<00:03, 387.32it/s]
Adding requests:  35%|███▍      | 710/2048 [00:01<00:03, 393.41it/s]
Adding requests:  37%|███▋      | 750/2048 [00:01<00:03, 381.39it/s]
Adding requests:  39%|███▊      | 789/2048 [00:02<00:03, 379.91it/s]
Adding requests:  40%|████      | 829/2048 [00:02<00:03, 385.13it/s]
Adding requests:  42%|████▏     | 869/2048 [00:02<00:03, 388.85it/s]
Adding requests:  44%|████▍     | 909/2048 [00:02<00:02, 391.92it/s]
Adding requests:  46%|████▋     | 949/2048 [00:02<00:02, 383.54it/s]
Adding requests:  48%|████▊     | 989/2048 [00:02<00:02, 386.32it/s]
Adding requests:  50%|█████     | 1028/2048 [00:02<00:02, 383.87it/s]
Adding requests:  52%|█████▏    | 1067/2048 [00:02<00:02, 381.20it/s]
Adding requests:  54%|█████▍    | 1106/2048 [00:02<00:02, 379.47it/s]
Adding requests:  56%|█████▌    | 1147/2048 [00:02<00:02, 386.12it/s]
Adding requests:  58%|█████▊    | 1186/2048 [00:03<00:02, 384.78it/s]
Adding requests:  60%|█████▉    | 1227/2048 [00:03<00:02, 390.25it/s]
Adding requests:  62%|██████▏   | 1267/2048 [00:03<00:02, 388.09it/s]
Adding requests:  64%|██████▍   | 1306/2048 [00:03<00:01, 384.71it/s]
Adding requests:  66%|██████▌   | 1345/2048 [00:03<00:01, 385.07it/s]
Adding requests:  68%|██████▊   | 1385/2048 [00:03<00:01, 388.41it/s]
Adding requests:  70%|██████▉   | 1424/2048 [00:03<00:01, 384.12it/s]
Adding requests:  71%|███████▏  | 1464/2048 [00:03<00:01, 388.15it/s]
Adding requests:  73%|███████▎  | 1505/2048 [00:03<00:01, 391.99it/s]
Adding requests:  75%|███████▌  | 1545/2048 [00:04<00:01, 390.34it/s]
Adding requests:  77%|███████▋  | 1585/2048 [00:04<00:01, 382.94it/s]
Adding requests:  79%|███████▉  | 1624/2048 [00:04<00:01, 377.27it/s]
Adding requests:  81%|████████  | 1662/2048 [00:04<00:01, 372.40it/s]
Adding requests:  83%|████████▎ | 1701/2048 [00:04<00:00, 376.26it/s]
Adding requests:  85%|████████▌ | 1741/2048 [00:04<00:00, 380.84it/s]
Adding requests:  87%|████████▋ | 1782/2048 [00:04<00:00, 387.78it/s]
Adding requests:  89%|████████▉ | 1821/2048 [00:04<00:00, 383.05it/s]
Adding requests:  91%|█████████ | 1861/2048 [00:04<00:00, 387.30it/s]
Adding requests:  93%|█████████▎| 1900/2048 [00:04<00:00, 386.50it/s]
Adding requests:  95%|█████████▍| 1939/2048 [00:05<00:00, 385.80it/s]
Adding requests:  97%|█████████▋| 1979/2048 [00:05<00:00, 389.42it/s]
Adding requests:  99%|█████████▊| 2018/2048 [00:05<00:00, 379.82it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 383.88it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 269/2048 [00:00<00:02, 742.03it/s, est. speed input: 759887.22 toks/s, output: 742.04 toks/s]
Processed prompts:  17%|█▋        | 344/2048 [00:01<00:09, 174.41it/s, est. speed input: 217657.09 toks/s, output: 212.55 toks/s]
Processed prompts:  19%|█▊        | 379/2048 [00:02<00:12, 129.18it/s, est. speed input: 171770.08 toks/s, output: 167.74 toks/s]
Processed prompts:  20%|█▉        | 401/2048 [00:02<00:17, 96.10it/s, est. speed input: 141727.87 toks/s, output: 138.41 toks/s] 
Processed prompts:  20%|██        | 416/2048 [00:03<00:18, 86.29it/s, est. speed input: 132437.73 toks/s, output: 129.33 toks/s]
Processed prompts:  21%|██        | 429/2048 [00:03<00:20, 77.22it/s, est. speed input: 124935.90 toks/s, output: 122.01 toks/s]
Processed prompts:  22%|██▏       | 445/2048 [00:03<00:22, 70.62it/s, est. speed input: 118804.01 toks/s, output: 116.02 toks/s]
Processed prompts:  23%|██▎       | 461/2048 [00:04<00:24, 65.25it/s, est. speed input: 113579.74 toks/s, output: 110.92 toks/s]
Processed prompts:  23%|██▎       | 477/2048 [00:04<00:25, 61.25it/s, est. speed input: 109169.91 toks/s, output: 106.61 toks/s]
Processed prompts:  24%|██▍       | 493/2048 [00:04<00:26, 58.19it/s, est. speed input: 105332.34 toks/s, output: 102.86 toks/s]
Processed prompts:  25%|██▍       | 509/2048 [00:05<00:27, 55.93it/s, est. speed input: 101973.37 toks/s, output: 99.58 toks/s] 
Processed prompts:  26%|██▌       | 525/2048 [00:05<00:28, 54.15it/s, est. speed input: 98959.48 toks/s, output: 96.64 toks/s] 
Processed prompts:  26%|██▋       | 541/2048 [00:05<00:28, 52.97it/s, est. speed input: 96312.53 toks/s, output: 94.05 toks/s]
Processed prompts:  27%|██▋       | 557/2048 [00:06<00:28, 52.19it/s, est. speed input: 93967.61 toks/s, output: 91.76 toks/s]
Processed prompts:  28%|██▊       | 573/2048 [00:06<00:28, 51.59it/s, est. speed input: 91839.90 toks/s, output: 89.69 toks/s]
Processed prompts:  29%|██▉       | 589/2048 [00:06<00:28, 51.16it/s, est. speed input: 89912.40 toks/s, output: 87.80 toks/s]
Processed prompts:  30%|██▉       | 605/2048 [00:07<00:28, 50.84it/s, est. speed input: 88156.24 toks/s, output: 86.09 toks/s]
Processed prompts:  30%|███       | 621/2048 [00:07<00:28, 50.57it/s, est. speed input: 86541.69 toks/s, output: 84.51 toks/s]
Processed prompts:  31%|███       | 637/2048 [00:07<00:27, 50.54it/s, est. speed input: 85100.24 toks/s, output: 83.11 toks/s]
Processed prompts:  32%|███▏      | 653/2048 [00:07<00:27, 50.48it/s, est. speed input: 83764.40 toks/s, output: 81.80 toks/s]
Processed prompts:  33%|███▎      | 669/2048 [00:08<00:27, 50.40it/s, est. speed input: 82522.72 toks/s, output: 80.59 toks/s]
Processed prompts:  33%|███▎      | 685/2048 [00:08<00:27, 50.41it/s, est. speed input: 81386.80 toks/s, output: 79.48 toks/s]
Processed prompts:  34%|███▍      | 701/2048 [00:08<00:26, 50.38it/s, est. speed input: 80324.02 toks/s, output: 78.44 toks/s]
Processed prompts:  35%|███▌      | 717/2048 [00:09<00:26, 50.34it/s, est. speed input: 79329.53 toks/s, output: 77.47 toks/s]
Processed prompts:  36%|███▌      | 733/2048 [00:09<00:26, 50.40it/s, est. speed input: 78418.77 toks/s, output: 76.58 toks/s]
Processed prompts:  37%|███▋      | 749/2048 [00:09<00:25, 50.46it/s, est. speed input: 77566.99 toks/s, output: 75.75 toks/s]
Processed prompts:  37%|███▋      | 765/2048 [00:10<00:25, 50.44it/s, est. speed input: 76758.87 toks/s, output: 74.96 toks/s]
Processed prompts:  38%|███▊      | 781/2048 [00:10<00:24, 51.28it/s, est. speed input: 76127.65 toks/s, output: 74.34 toks/s]
Processed prompts:  39%|███▉      | 797/2048 [00:10<00:24, 51.04it/s, est. speed input: 75412.51 toks/s, output: 73.64 toks/s]
Processed prompts:  40%|███▉      | 813/2048 [00:11<00:24, 50.84it/s, est. speed input: 74733.72 toks/s, output: 72.98 toks/s]
Processed prompts:  40%|████      | 829/2048 [00:11<00:24, 50.63it/s, est. speed input: 74081.75 toks/s, output: 72.35 toks/s]
Processed prompts:  41%|████▏     | 845/2048 [00:11<00:23, 50.51it/s, est. speed input: 73469.12 toks/s, output: 71.75 toks/s]
Processed prompts:  42%|████▏     | 861/2048 [00:12<00:23, 50.51it/s, est. speed input: 72899.42 toks/s, output: 71.19 toks/s]
Processed prompts:  43%|████▎     | 877/2048 [00:12<00:23, 50.45it/s, est. speed input: 72352.31 toks/s, output: 70.66 toks/s]
Processed prompts:  44%|████▎     | 893/2048 [00:12<00:22, 50.40it/s, est. speed input: 71830.24 toks/s, output: 70.15 toks/s]
Processed prompts:  44%|████▍     | 909/2048 [00:13<00:22, 50.46it/s, est. speed input: 71345.41 toks/s, output: 69.67 toks/s]
Processed prompts:  45%|████▌     | 925/2048 [00:13<00:22, 50.42it/s, est. speed input: 70874.47 toks/s, output: 69.21 toks/s]
Processed prompts:  46%|████▌     | 941/2048 [00:13<00:22, 50.26it/s, est. speed input: 70410.20 toks/s, output: 68.76 toks/s]
Processed prompts:  47%|████▋     | 957/2048 [00:14<00:21, 50.32it/s, est. speed input: 69986.35 toks/s, output: 68.35 toks/s]
Processed prompts:  48%|████▊     | 973/2048 [00:14<00:21, 50.28it/s, est. speed input: 69572.00 toks/s, output: 67.94 toks/s]
Processed prompts:  48%|████▊     | 989/2048 [00:14<00:21, 50.18it/s, est. speed input: 69168.95 toks/s, output: 67.55 toks/s]
Processed prompts:  49%|████▉     | 1005/2048 [00:14<00:20, 50.21it/s, est. speed input: 68793.19 toks/s, output: 67.18 toks/s]
Processed prompts:  50%|████▉     | 1021/2048 [00:15<00:20, 50.19it/s, est. speed input: 68428.22 toks/s, output: 66.82 toks/s]
Processed prompts:  51%|█████     | 1037/2048 [00:15<00:20, 50.10it/s, est. speed input: 68072.06 toks/s, output: 66.48 toks/s]
Processed prompts:  51%|█████▏    | 1053/2048 [00:15<00:19, 50.14it/s, est. speed input: 67739.14 toks/s, output: 66.15 toks/s]
Processed prompts:  52%|█████▏    | 1069/2048 [00:16<00:19, 50.15it/s, est. speed input: 67418.09 toks/s, output: 65.84 toks/s]
Processed prompts:  53%|█████▎    | 1085/2048 [00:16<00:19, 50.15it/s, est. speed input: 67108.33 toks/s, output: 65.54 toks/s]
Processed prompts:  54%|█████▍    | 1101/2048 [00:16<00:18, 50.18it/s, est. speed input: 66813.08 toks/s, output: 65.25 toks/s]
Processed prompts:  55%|█████▍    | 1117/2048 [00:17<00:18, 50.26it/s, est. speed input: 66533.16 toks/s, output: 64.97 toks/s]
Processed prompts:  55%|█████▌    | 1133/2048 [00:17<00:18, 50.25it/s, est. speed input: 66259.00 toks/s, output: 64.71 toks/s]
Processed prompts:  56%|█████▌    | 1149/2048 [00:17<00:17, 50.19it/s, est. speed input: 65989.35 toks/s, output: 64.44 toks/s]
Processed prompts:  57%|█████▋    | 1165/2048 [00:18<00:17, 50.23it/s, est. speed input: 65736.50 toks/s, output: 64.20 toks/s]
Processed prompts:  58%|█████▊    | 1181/2048 [00:18<00:17, 50.16it/s, est. speed input: 65484.77 toks/s, output: 63.95 toks/s]
Processed prompts:  58%|█████▊    | 1197/2048 [00:18<00:16, 51.06it/s, est. speed input: 65310.19 toks/s, output: 63.78 toks/s]
Processed prompts:  59%|█████▉    | 1213/2048 [00:19<00:16, 50.84it/s, est. speed input: 65080.52 toks/s, output: 63.56 toks/s]
Processed prompts:  60%|██████    | 1229/2048 [00:19<00:15, 51.52it/s, est. speed input: 64915.47 toks/s, output: 63.39 toks/s]
Processed prompts:  61%|██████    | 1245/2048 [00:19<00:15, 51.08it/s, est. speed input: 64694.64 toks/s, output: 63.18 toks/s]
Processed prompts:  62%|██████▏   | 1261/2048 [00:20<00:15, 50.82it/s, est. speed input: 64483.56 toks/s, output: 62.97 toks/s]
Processed prompts:  62%|██████▏   | 1277/2048 [00:20<00:15, 50.57it/s, est. speed input: 64274.88 toks/s, output: 62.77 toks/s]
Processed prompts:  63%|██████▎   | 1293/2048 [00:20<00:14, 50.42it/s, est. speed input: 64073.77 toks/s, output: 62.57 toks/s]
Processed prompts:  64%|██████▍   | 1309/2048 [00:20<00:14, 50.32it/s, est. speed input: 63878.95 toks/s, output: 62.38 toks/s]
Processed prompts:  65%|██████▍   | 1325/2048 [00:21<00:14, 51.19it/s, est. speed input: 63748.69 toks/s, output: 62.25 toks/s]
Processed prompts:  65%|██████▌   | 1341/2048 [00:21<00:13, 50.80it/s, est. speed input: 63561.01 toks/s, output: 62.07 toks/s]
Processed prompts:  66%|██████▋   | 1357/2048 [00:21<00:13, 50.53it/s, est. speed input: 63379.27 toks/s, output: 61.89 toks/s]
Processed prompts:  67%|██████▋   | 1373/2048 [00:22<00:13, 50.41it/s, est. speed input: 63206.24 toks/s, output: 61.72 toks/s]
Processed prompts:  68%|██████▊   | 1389/2048 [00:22<00:13, 50.27it/s, est. speed input: 63034.79 toks/s, output: 61.56 toks/s]
Processed prompts:  69%|██████▊   | 1405/2048 [00:22<00:12, 50.15it/s, est. speed input: 62867.47 toks/s, output: 61.39 toks/s]
Processed prompts:  69%|██████▉   | 1421/2048 [00:23<00:12, 50.18it/s, est. speed input: 62710.49 toks/s, output: 61.24 toks/s]
Processed prompts:  70%|███████   | 1437/2048 [00:23<00:12, 50.17it/s, est. speed input: 62556.40 toks/s, output: 61.09 toks/s]
Processed prompts:  71%|███████   | 1453/2048 [00:23<00:11, 50.94it/s, est. speed input: 62448.86 toks/s, output: 60.99 toks/s]
Processed prompts:  72%|███████▏  | 1469/2048 [00:24<00:11, 50.68it/s, est. speed input: 62301.18 toks/s, output: 60.84 toks/s]
Processed prompts:  73%|███████▎  | 1485/2048 [00:24<00:11, 50.51it/s, est. speed input: 62158.08 toks/s, output: 60.70 toks/s]
Processed prompts:  73%|███████▎  | 1501/2048 [00:24<00:10, 50.31it/s, est. speed input: 62014.29 toks/s, output: 60.56 toks/s]
Processed prompts:  74%|███████▍  | 1517/2048 [00:25<00:10, 51.07it/s, est. speed input: 61920.29 toks/s, output: 60.47 toks/s]
Processed prompts:  75%|███████▍  | 1533/2048 [00:25<00:10, 50.82it/s, est. speed input: 61789.09 toks/s, output: 60.34 toks/s]
Processed prompts:  76%|███████▌  | 1549/2048 [00:25<00:09, 50.53it/s, est. speed input: 61655.24 toks/s, output: 60.21 toks/s]
Processed prompts:  76%|███████▋  | 1565/2048 [00:26<00:09, 51.26it/s, est. speed input: 61570.01 toks/s, output: 60.13 toks/s]
Processed prompts:  77%|███████▋  | 1581/2048 [00:26<00:09, 50.92it/s, est. speed input: 61446.32 toks/s, output: 60.01 toks/s]
Processed prompts:  78%|███████▊  | 1597/2048 [00:26<00:08, 50.66it/s, est. speed input: 61324.10 toks/s, output: 59.89 toks/s]
Processed prompts:  79%|███████▉  | 1613/2048 [00:26<00:08, 51.36it/s, est. speed input: 61246.01 toks/s, output: 59.81 toks/s]
Processed prompts:  80%|███████▉  | 1629/2048 [00:27<00:08, 50.98it/s, est. speed input: 61130.09 toks/s, output: 59.70 toks/s]
Processed prompts:  80%|████████  | 1645/2048 [00:27<00:07, 50.67it/s, est. speed input: 61014.52 toks/s, output: 59.58 toks/s]
Processed prompts:  81%|████████  | 1661/2048 [00:27<00:07, 50.49it/s, est. speed input: 60903.23 toks/s, output: 59.48 toks/s]
Processed prompts:  82%|████████▏ | 1677/2048 [00:28<00:07, 50.30it/s, est. speed input: 60791.06 toks/s, output: 59.37 toks/s]
Processed prompts:  83%|████████▎ | 1693/2048 [00:28<00:07, 50.21it/s, est. speed input: 60683.56 toks/s, output: 59.26 toks/s]
Processed prompts:  83%|████████▎ | 1709/2048 [00:28<00:06, 50.14it/s, est. speed input: 60578.54 toks/s, output: 59.16 toks/s]
Processed prompts:  84%|████████▍ | 1725/2048 [00:29<00:06, 50.10it/s, est. speed input: 60475.57 toks/s, output: 59.06 toks/s]
Processed prompts:  85%|████████▌ | 1741/2048 [00:29<00:06, 50.94it/s, est. speed input: 60412.36 toks/s, output: 59.00 toks/s]
Processed prompts:  86%|████████▌ | 1757/2048 [00:29<00:05, 51.62it/s, est. speed input: 60353.39 toks/s, output: 58.94 toks/s]
Processed prompts:  87%|████████▋ | 1773/2048 [00:30<00:05, 51.17it/s, est. speed input: 60258.10 toks/s, output: 58.85 toks/s]
Processed prompts:  87%|████████▋ | 1789/2048 [00:30<00:05, 50.80it/s, est. speed input: 60162.32 toks/s, output: 58.75 toks/s]
Processed prompts:  88%|████████▊ | 1805/2048 [00:30<00:04, 50.57it/s, est. speed input: 60069.76 toks/s, output: 58.66 toks/s]
Processed prompts:  89%|████████▉ | 1821/2048 [00:31<00:04, 50.46it/s, est. speed input: 59980.86 toks/s, output: 58.57 toks/s]
Processed prompts:  90%|████████▉ | 1837/2048 [00:31<00:04, 50.25it/s, est. speed input: 59888.76 toks/s, output: 58.49 toks/s]
Processed prompts:  90%|█████████ | 1853/2048 [00:31<00:03, 50.15it/s, est. speed input: 59799.97 toks/s, output: 58.40 toks/s]
Processed prompts:  91%|█████████▏| 1869/2048 [00:32<00:03, 50.15it/s, est. speed input: 59715.88 toks/s, output: 58.32 toks/s]
Processed prompts:  92%|█████████▏| 1885/2048 [00:32<00:03, 50.99it/s, est. speed input: 59665.90 toks/s, output: 58.27 toks/s]
Processed prompts:  93%|█████████▎| 1901/2048 [00:32<00:02, 50.64it/s, est. speed input: 59580.96 toks/s, output: 58.18 toks/s]
Processed prompts:  94%|█████████▎| 1917/2048 [00:32<00:02, 50.52it/s, est. speed input: 59502.56 toks/s, output: 58.11 toks/s]
Processed prompts:  94%|█████████▍| 1933/2048 [00:33<00:02, 50.35it/s, est. speed input: 59422.30 toks/s, output: 58.03 toks/s]
Processed prompts:  95%|█████████▌| 1949/2048 [00:33<00:01, 50.20it/s, est. speed input: 59342.58 toks/s, output: 57.95 toks/s]
Processed prompts:  96%|█████████▌| 1965/2048 [00:33<00:01, 50.14it/s, est. speed input: 59265.64 toks/s, output: 57.88 toks/s]
Processed prompts:  97%|█████████▋| 1981/2048 [00:34<00:01, 51.07it/s, est. speed input: 59225.37 toks/s, output: 57.84 toks/s]
Processed prompts:  98%|█████████▊| 1997/2048 [00:34<00:01, 50.70it/s, est. speed input: 59149.63 toks/s, output: 57.76 toks/s]
Processed prompts:  98%|█████████▊| 2013/2048 [00:34<00:00, 50.48it/s, est. speed input: 59076.34 toks/s, output: 57.69 toks/s]
Processed prompts:  99%|█████████▉| 2029/2048 [00:35<00:00, 50.43it/s, est. speed input: 59008.27 toks/s, output: 57.63 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:35<00:00, 50.43it/s, est. speed input: 59417.42 toks/s, output: 58.02 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:35<00:00, 58.02it/s, est. speed input: 59417.42 toks/s, output: 58.02 toks/s]
[rank0]:[W126 11:59:06.158888597 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 11:59:08
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:59:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1324848) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1324848) WARNING 01-26 11:59:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 49.93 requests/s, 51179.11 total tokens/s, 49.93 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 11:59:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:59:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:59:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:59:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:59:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:59:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:59:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:59:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:59:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:59:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:59:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 11:59:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 11:59:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:59:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:59:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:59:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:59:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1324848) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1324848) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.62it/s]
(EngineCore_DP0 pid=1324848) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1324848) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  2.00it/s]
(EngineCore_DP0 pid=1324848) 
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1324848) [2026-01-26 11:59:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1324848) [rank0]:W0126 11:59:59.178000 1324848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1324848) [rank0]:W0126 11:59:59.255000 1324848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1324848) [rank0]:W0126 12:00:00.190000 1324848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1324848) [rank0]:W0126 12:00:00.316000 1324848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1324848) 2026-01-26 12:00:04,473 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1324848) 2026-01-26 12:00:04,499 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1324848) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  4.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:02,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  4.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:01,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:01<00:01,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  6.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  6.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  6.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  5.81it/s]
(EngineCore_DP0 pid=1324848) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00, 18.78it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00, 19.46it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00, 14.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 15.15it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 245.38it/s]
Adding requests:   2%|▏         | 65/4096 [00:00<00:12, 334.11it/s]
Adding requests:   2%|▏         | 101/4096 [00:00<00:11, 343.83it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:11, 356.79it/s]
Adding requests:   4%|▍         | 178/4096 [00:00<00:10, 367.91it/s]
Adding requests:   5%|▌         | 220/4096 [00:00<00:10, 383.13it/s]
Adding requests:   6%|▋         | 259/4096 [00:00<00:10, 379.35it/s]
Adding requests:   7%|▋         | 299/4096 [00:00<00:09, 384.40it/s]
Adding requests:   8%|▊         | 339/4096 [00:00<00:09, 388.55it/s]
Adding requests:   9%|▉         | 379/4096 [00:01<00:09, 391.58it/s]
Adding requests:  10%|█         | 421/4096 [00:01<00:09, 397.13it/s]
Adding requests:  11%|█▏        | 461/4096 [00:01<00:09, 392.32it/s]
Adding requests:  12%|█▏        | 504/4096 [00:01<00:08, 400.10it/s]
Adding requests:  13%|█▎        | 546/4096 [00:01<00:08, 404.45it/s]
Adding requests:  14%|█▍        | 587/4096 [00:01<00:08, 399.98it/s]
Adding requests:  15%|█▌        | 628/4096 [00:01<00:08, 395.85it/s]
Adding requests:  16%|█▋        | 668/4096 [00:01<00:08, 385.45it/s]
Adding requests:  17%|█▋        | 709/4096 [00:01<00:08, 390.16it/s]
Adding requests:  18%|█▊        | 749/4096 [00:01<00:08, 381.90it/s]
Adding requests:  19%|█▉        | 789/4096 [00:02<00:08, 384.55it/s]
Adding requests:  20%|██        | 828/4096 [00:02<00:08, 386.05it/s]
Adding requests:  21%|██        | 868/4096 [00:02<00:08, 388.29it/s]
Adding requests:  22%|██▏       | 908/4096 [00:02<00:08, 391.21it/s]
Adding requests:  23%|██▎       | 948/4096 [00:02<00:08, 382.79it/s]
Adding requests:  24%|██▍       | 988/4096 [00:02<00:08, 384.56it/s]
Adding requests:  25%|██▌       | 1027/4096 [00:02<00:08, 379.18it/s]
Adding requests:  26%|██▌       | 1065/4096 [00:02<00:07, 378.95it/s]
Adding requests:  27%|██▋       | 1103/4096 [00:02<00:08, 368.41it/s]
Adding requests:  28%|██▊       | 1143/4096 [00:02<00:07, 375.17it/s]
Adding requests:  29%|██▉       | 1181/4096 [00:03<00:07, 376.47it/s]
Adding requests:  30%|██▉       | 1221/4096 [00:03<00:07, 382.22it/s]
Adding requests:  31%|███       | 1260/4096 [00:03<00:07, 380.38it/s]
Adding requests:  32%|███▏      | 1299/4096 [00:03<00:07, 377.83it/s]
Adding requests:  33%|███▎      | 1338/4096 [00:03<00:07, 378.90it/s]
Adding requests:  34%|███▎      | 1379/4096 [00:03<00:07, 385.01it/s]
Adding requests:  35%|███▍      | 1418/4096 [00:03<00:07, 381.14it/s]
Adding requests:  36%|███▌      | 1458/4096 [00:03<00:06, 386.24it/s]
Adding requests:  37%|███▋      | 1498/4096 [00:03<00:06, 390.22it/s]
Adding requests:  38%|███▊      | 1538/4096 [00:04<00:06, 389.22it/s]
Adding requests:  39%|███▊      | 1577/4096 [00:04<00:06, 381.75it/s]
Adding requests:  39%|███▉      | 1616/4096 [00:04<00:06, 378.76it/s]
Adding requests:  40%|████      | 1654/4096 [00:04<00:06, 371.69it/s]
Adding requests:  41%|████▏     | 1692/4096 [00:04<00:06, 373.47it/s]
Adding requests:  42%|████▏     | 1732/4096 [00:04<00:06, 378.45it/s]
Adding requests:  43%|████▎     | 1773/4096 [00:04<00:06, 385.18it/s]
Adding requests:  44%|████▍     | 1812/4096 [00:04<00:05, 383.49it/s]
Adding requests:  45%|████▌     | 1851/4096 [00:04<00:05, 383.33it/s]
Adding requests:  46%|████▌     | 1891/4096 [00:04<00:05, 387.32it/s]
Adding requests:  47%|████▋     | 1931/4096 [00:05<00:05, 389.84it/s]
Adding requests:  48%|████▊     | 1970/4096 [00:05<00:05, 389.86it/s]
Adding requests:  49%|████▉     | 2009/4096 [00:05<00:05, 385.79it/s]
Adding requests:  50%|█████     | 2048/4096 [00:05<00:05, 382.04it/s]
Adding requests:  51%|█████     | 2087/4096 [00:05<00:05, 371.85it/s]
Adding requests:  52%|█████▏    | 2128/4096 [00:05<00:05, 379.71it/s]
Adding requests:  53%|█████▎    | 2167/4096 [00:05<00:05, 376.28it/s]
Adding requests:  54%|█████▍    | 2205/4096 [00:05<00:05, 371.40it/s]
Adding requests:  55%|█████▍    | 2244/4096 [00:05<00:04, 376.00it/s]
Adding requests:  56%|█████▌    | 2285/4096 [00:05<00:04, 382.68it/s]
Adding requests:  57%|█████▋    | 2324/4096 [00:06<00:04, 377.06it/s]
Adding requests:  58%|█████▊    | 2364/4096 [00:06<00:04, 382.01it/s]
Adding requests:  59%|█████▊    | 2405/4096 [00:06<00:04, 387.64it/s]
Adding requests:  60%|█████▉    | 2445/4096 [00:06<00:04, 389.60it/s]
Adding requests:  61%|██████    | 2484/4096 [00:06<00:04, 388.65it/s]
Adding requests:  62%|██████▏   | 2525/4096 [00:06<00:04, 391.86it/s]
Adding requests:  63%|██████▎   | 2569/4096 [00:06<00:03, 404.95it/s]
Adding requests:  64%|██████▎   | 2610/4096 [00:06<00:03, 401.27it/s]
Adding requests:  65%|██████▍   | 2651/4096 [00:06<00:03, 390.29it/s]
Adding requests:  66%|██████▌   | 2691/4096 [00:07<00:03, 387.67it/s]
Adding requests:  67%|██████▋   | 2730/4096 [00:07<00:03, 384.00it/s]
Adding requests:  68%|██████▊   | 2771/4096 [00:07<00:03, 389.67it/s]
Adding requests:  69%|██████▊   | 2812/4096 [00:07<00:03, 395.33it/s]
Adding requests:  70%|██████▉   | 2853/4096 [00:07<00:03, 396.61it/s]
Adding requests:  71%|███████   | 2893/4096 [00:07<00:03, 394.79it/s]
Adding requests:  72%|███████▏  | 2933/4096 [00:07<00:02, 395.31it/s]
Adding requests:  73%|███████▎  | 2973/4096 [00:07<00:02, 395.62it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:07<00:02, 400.21it/s]
Adding requests:  75%|███████▍  | 3056/4096 [00:07<00:02, 400.88it/s]
Adding requests:  76%|███████▌  | 3097/4096 [00:08<00:02, 401.30it/s]
Adding requests:  77%|███████▋  | 3138/4096 [00:08<00:02, 403.43it/s]
Adding requests:  78%|███████▊  | 3179/4096 [00:08<00:02, 394.33it/s]
Adding requests:  79%|███████▊  | 3219/4096 [00:08<00:02, 393.91it/s]
Adding requests:  80%|███████▉  | 3259/4096 [00:08<00:02, 395.63it/s]
Adding requests:  81%|████████  | 3299/4096 [00:08<00:02, 382.02it/s]
Adding requests:  81%|████████▏ | 3338/4096 [00:08<00:01, 383.81it/s]
Adding requests:  82%|████████▏ | 3379/4096 [00:08<00:01, 388.38it/s]
Adding requests:  83%|████████▎ | 3418/4096 [00:08<00:01, 387.42it/s]
Adding requests:  84%|████████▍ | 3459/4096 [00:08<00:01, 390.87it/s]
Adding requests:  85%|████████▌ | 3499/4096 [00:09<00:01, 387.99it/s]
Adding requests:  86%|████████▋ | 3542/4096 [00:09<00:01, 398.30it/s]
Adding requests:  87%|████████▋ | 3582/4096 [00:09<00:01, 396.52it/s]
Adding requests:  88%|████████▊ | 3622/4096 [00:09<00:01, 397.28it/s]
Adding requests:  89%|████████▉ | 3662/4096 [00:09<00:01, 380.84it/s]
Adding requests:  90%|█████████ | 3701/4096 [00:09<00:01, 380.60it/s]
Adding requests:  91%|█████████▏| 3740/4096 [00:09<00:00, 382.83it/s]
Adding requests:  92%|█████████▏| 3779/4096 [00:09<00:00, 372.87it/s]
Adding requests:  93%|█████████▎| 3817/4096 [00:09<00:00, 363.94it/s]
Adding requests:  94%|█████████▍| 3855/4096 [00:10<00:00, 368.46it/s]
Adding requests:  95%|█████████▌| 3893/4096 [00:10<00:00, 369.47it/s]
Adding requests:  96%|█████████▌| 3931/4096 [00:10<00:00, 366.55it/s]
Adding requests:  97%|█████████▋| 3969/4096 [00:10<00:00, 370.07it/s]
Adding requests:  98%|█████████▊| 4007/4096 [00:10<00:00, 370.40it/s]
Adding requests:  99%|█████████▉| 4045/4096 [00:10<00:00, 370.23it/s]
Adding requests: 100%|█████████▉| 4083/4096 [00:10<00:00, 371.21it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 383.72it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 509/4096 [00:00<00:04, 774.49it/s, est. speed input: 793103.83 toks/s, output: 774.50 toks/s]
Processed prompts:  14%|█▍        | 587/4096 [00:01<00:13, 251.87it/s, est. speed input: 312831.13 toks/s, output: 305.50 toks/s]
Processed prompts:  15%|█▌        | 623/4096 [00:02<00:18, 184.51it/s, est. speed input: 249467.59 toks/s, output: 243.62 toks/s]
Processed prompts:  16%|█▌        | 645/4096 [00:03<00:25, 135.18it/s, est. speed input: 207001.81 toks/s, output: 202.15 toks/s]
Processed prompts:  16%|█▋        | 669/4096 [00:03<00:32, 104.11it/s, est. speed input: 179195.26 toks/s, output: 174.99 toks/s]
Processed prompts:  17%|█▋        | 701/4096 [00:04<00:38, 87.22it/s, est. speed input: 161018.97 toks/s, output: 157.24 toks/s] 
Processed prompts:  18%|█▊        | 733/4096 [00:05<00:44, 75.87it/s, est. speed input: 147421.30 toks/s, output: 143.96 toks/s]
Processed prompts:  19%|█▊        | 765/4096 [00:05<00:48, 68.58it/s, est. speed input: 137179.55 toks/s, output: 133.96 toks/s]
Processed prompts:  19%|█▉        | 797/4096 [00:06<00:52, 63.01it/s, est. speed input: 128617.89 toks/s, output: 125.60 toks/s]
Processed prompts:  20%|██        | 829/4096 [00:06<00:55, 59.19it/s, est. speed input: 121625.13 toks/s, output: 118.77 toks/s]
Processed prompts:  21%|██        | 861/4096 [00:07<00:57, 56.49it/s, est. speed input: 115766.05 toks/s, output: 113.05 toks/s]
Processed prompts:  22%|██▏       | 893/4096 [00:08<00:58, 54.68it/s, est. speed input: 110845.47 toks/s, output: 108.25 toks/s]
Processed prompts:  23%|██▎       | 925/4096 [00:08<00:59, 53.38it/s, est. speed input: 106610.40 toks/s, output: 104.11 toks/s]
Processed prompts:  23%|██▎       | 957/4096 [00:09<00:59, 52.44it/s, est. speed input: 102922.46 toks/s, output: 100.51 toks/s]
Processed prompts:  24%|██▍       | 989/4096 [00:10<01:00, 51.76it/s, est. speed input: 99689.63 toks/s, output: 97.35 toks/s]  
Processed prompts:  25%|██▍       | 1021/4096 [00:10<00:59, 51.33it/s, est. speed input: 96850.77 toks/s, output: 94.58 toks/s]
Processed prompts:  26%|██▌       | 1053/4096 [00:11<00:59, 51.03it/s, est. speed input: 94330.72 toks/s, output: 92.12 toks/s]
Processed prompts:  26%|██▋       | 1085/4096 [00:12<00:59, 50.85it/s, est. speed input: 92086.48 toks/s, output: 89.93 toks/s]
Processed prompts:  27%|██▋       | 1117/4096 [00:12<00:58, 50.65it/s, est. speed input: 90044.10 toks/s, output: 87.93 toks/s]
Processed prompts:  28%|██▊       | 1149/4096 [00:13<00:58, 50.54it/s, est. speed input: 88205.34 toks/s, output: 86.14 toks/s]
Processed prompts:  29%|██▉       | 1181/4096 [00:13<00:57, 50.80it/s, est. speed input: 86621.12 toks/s, output: 84.59 toks/s]
Processed prompts:  30%|██▉       | 1213/4096 [00:14<00:56, 50.92it/s, est. speed input: 85155.53 toks/s, output: 83.16 toks/s]
Processed prompts:  30%|███       | 1245/4096 [00:15<00:56, 50.76it/s, est. speed input: 83756.45 toks/s, output: 81.79 toks/s]
Processed prompts:  31%|███       | 1277/4096 [00:15<00:55, 50.60it/s, est. speed input: 82457.73 toks/s, output: 80.52 toks/s]
Processed prompts:  32%|███▏      | 1309/4096 [00:16<00:54, 50.75it/s, est. speed input: 81314.01 toks/s, output: 79.41 toks/s]
Processed prompts:  33%|███▎      | 1341/4096 [00:17<00:54, 50.63it/s, est. speed input: 80208.34 toks/s, output: 78.33 toks/s]
Processed prompts:  34%|███▎      | 1373/4096 [00:17<00:53, 50.47it/s, est. speed input: 79168.90 toks/s, output: 77.31 toks/s]
Processed prompts:  34%|███▍      | 1405/4096 [00:18<00:53, 50.41it/s, est. speed input: 78210.87 toks/s, output: 76.38 toks/s]
Processed prompts:  35%|███▌      | 1437/4096 [00:19<00:52, 50.72it/s, est. speed input: 77375.66 toks/s, output: 75.56 toks/s]
Processed prompts:  36%|███▌      | 1469/4096 [00:19<00:51, 50.56it/s, est. speed input: 76532.70 toks/s, output: 74.74 toks/s]
Processed prompts:  37%|███▋      | 1501/4096 [00:20<00:51, 50.83it/s, est. speed input: 75801.96 toks/s, output: 74.03 toks/s]
Processed prompts:  37%|███▋      | 1533/4096 [00:20<00:50, 50.57it/s, est. speed input: 75048.95 toks/s, output: 73.29 toks/s]
Processed prompts:  38%|███▊      | 1565/4096 [00:21<00:49, 50.80it/s, est. speed input: 74397.76 toks/s, output: 72.65 toks/s]
Processed prompts:  39%|███▉      | 1597/4096 [00:22<00:49, 50.89it/s, est. speed input: 73774.27 toks/s, output: 72.05 toks/s]
Processed prompts:  40%|███▉      | 1629/4096 [00:22<00:48, 50.66it/s, est. speed input: 73145.86 toks/s, output: 71.43 toks/s]
Processed prompts:  41%|████      | 1661/4096 [00:23<00:48, 50.54it/s, est. speed input: 72557.79 toks/s, output: 70.86 toks/s]
Processed prompts:  41%|████▏     | 1693/4096 [00:24<00:47, 50.35it/s, est. speed input: 71986.75 toks/s, output: 70.30 toks/s]
Processed prompts:  42%|████▏     | 1725/4096 [00:24<00:46, 50.62it/s, est. speed input: 71493.98 toks/s, output: 69.82 toks/s]
Processed prompts:  43%|████▎     | 1757/4096 [00:25<00:46, 50.83it/s, est. speed input: 71028.33 toks/s, output: 69.36 toks/s]
Processed prompts:  44%|████▎     | 1789/4096 [00:25<00:45, 50.62it/s, est. speed input: 70544.15 toks/s, output: 68.89 toks/s]
Processed prompts:  44%|████▍     | 1821/4096 [00:26<00:45, 50.52it/s, est. speed input: 70088.46 toks/s, output: 68.45 toks/s]
Processed prompts:  45%|████▌     | 1853/4096 [00:27<00:44, 50.36it/s, est. speed input: 69645.02 toks/s, output: 68.01 toks/s]
Processed prompts:  46%|████▌     | 1885/4096 [00:27<00:43, 50.60it/s, est. speed input: 69257.74 toks/s, output: 67.63 toks/s]
Processed prompts:  47%|████▋     | 1917/4096 [00:28<00:43, 50.48it/s, est. speed input: 68858.85 toks/s, output: 67.24 toks/s]
Processed prompts:  48%|████▊     | 1949/4096 [00:29<00:42, 50.37it/s, est. speed input: 68474.10 toks/s, output: 66.87 toks/s]
Processed prompts:  48%|████▊     | 1981/4096 [00:29<00:41, 50.60it/s, est. speed input: 68135.74 toks/s, output: 66.54 toks/s]
Processed prompts:  49%|████▉     | 2013/4096 [00:30<00:41, 50.46it/s, est. speed input: 67783.04 toks/s, output: 66.19 toks/s]
Processed prompts:  50%|████▉     | 2045/4096 [00:31<00:40, 50.63it/s, est. speed input: 67469.70 toks/s, output: 65.89 toks/s]
Processed prompts:  51%|█████     | 2077/4096 [00:31<00:40, 50.45it/s, est. speed input: 67141.88 toks/s, output: 65.57 toks/s]
Processed prompts:  51%|█████▏    | 2109/4096 [00:32<00:39, 50.32it/s, est. speed input: 66826.74 toks/s, output: 65.26 toks/s]
Processed prompts:  52%|█████▏    | 2141/4096 [00:32<00:38, 50.20it/s, est. speed input: 66521.18 toks/s, output: 64.96 toks/s]
Processed prompts:  53%|█████▎    | 2173/4096 [00:33<00:38, 50.49it/s, est. speed input: 66258.33 toks/s, output: 64.71 toks/s]
Processed prompts:  54%|█████▍    | 2205/4096 [00:34<00:37, 50.26it/s, est. speed input: 65970.05 toks/s, output: 64.42 toks/s]
Processed prompts:  55%|█████▍    | 2237/4096 [00:34<00:37, 50.24it/s, est. speed input: 65703.87 toks/s, output: 64.16 toks/s]
Processed prompts:  55%|█████▌    | 2269/4096 [00:35<00:36, 50.14it/s, est. speed input: 65439.89 toks/s, output: 63.91 toks/s]
Processed prompts:  56%|█████▌    | 2301/4096 [00:36<00:35, 50.08it/s, est. speed input: 65186.37 toks/s, output: 63.66 toks/s]
Processed prompts:  57%|█████▋    | 2333/4096 [00:36<00:35, 50.10it/s, est. speed input: 64946.81 toks/s, output: 63.42 toks/s]
Processed prompts:  58%|█████▊    | 2365/4096 [00:37<00:34, 50.07it/s, est. speed input: 64711.18 toks/s, output: 63.19 toks/s]
Processed prompts:  59%|█████▊    | 2397/4096 [00:38<00:33, 50.04it/s, est. speed input: 64483.22 toks/s, output: 62.97 toks/s]
Processed prompts:  59%|█████▉    | 2429/4096 [00:38<00:33, 50.01it/s, est. speed input: 64262.72 toks/s, output: 62.76 toks/s]
Processed prompts:  60%|██████    | 2461/4096 [00:39<00:32, 50.02it/s, est. speed input: 64051.02 toks/s, output: 62.55 toks/s]
Processed prompts:  61%|██████    | 2493/4096 [00:39<00:32, 49.98it/s, est. speed input: 63843.07 toks/s, output: 62.35 toks/s]
Processed prompts:  62%|██████▏   | 2525/4096 [00:40<00:31, 50.32it/s, est. speed input: 63666.00 toks/s, output: 62.17 toks/s]
Processed prompts:  62%|██████▏   | 2557/4096 [00:41<00:30, 50.22it/s, est. speed input: 63472.66 toks/s, output: 61.98 toks/s]
Processed prompts:  63%|██████▎   | 2589/4096 [00:41<00:29, 50.45it/s, est. speed input: 63303.66 toks/s, output: 61.82 toks/s]
Processed prompts:  64%|██████▍   | 2621/4096 [00:42<00:29, 50.26it/s, est. speed input: 63118.21 toks/s, output: 61.64 toks/s]
Processed prompts:  65%|██████▍   | 2653/4096 [00:43<00:28, 50.46it/s, est. speed input: 62958.82 toks/s, output: 61.48 toks/s]
Processed prompts:  66%|██████▌   | 2685/4096 [00:43<00:28, 50.31it/s, est. speed input: 62786.37 toks/s, output: 61.31 toks/s]
Processed prompts:  66%|██████▋   | 2717/4096 [00:44<00:27, 50.22it/s, est. speed input: 62619.51 toks/s, output: 61.15 toks/s]
Processed prompts:  67%|██████▋   | 2749/4096 [00:45<00:26, 50.44it/s, est. speed input: 62474.23 toks/s, output: 61.01 toks/s]
Processed prompts:  68%|██████▊   | 2781/4096 [00:45<00:26, 50.25it/s, est. speed input: 62312.84 toks/s, output: 60.85 toks/s]
Processed prompts:  69%|██████▊   | 2813/4096 [00:46<00:25, 50.08it/s, est. speed input: 62154.18 toks/s, output: 60.70 toks/s]
Processed prompts:  69%|██████▉   | 2845/4096 [00:46<00:25, 50.00it/s, est. speed input: 62001.66 toks/s, output: 60.55 toks/s]
Processed prompts:  70%|███████   | 2877/4096 [00:47<00:24, 50.28it/s, est. speed input: 61872.00 toks/s, output: 60.42 toks/s]
Processed prompts:  71%|███████   | 2909/4096 [00:48<00:23, 51.21it/s, est. speed input: 61784.45 toks/s, output: 60.34 toks/s]
Processed prompts:  72%|███████▏  | 2941/4096 [00:48<00:22, 50.76it/s, est. speed input: 61641.58 toks/s, output: 60.20 toks/s]
Processed prompts:  73%|███████▎  | 2973/4096 [00:49<00:22, 50.50it/s, est. speed input: 61504.71 toks/s, output: 60.06 toks/s]
Processed prompts:  73%|███████▎  | 3005/4096 [00:50<00:21, 50.29it/s, est. speed input: 61370.38 toks/s, output: 59.93 toks/s]
Processed prompts:  74%|███████▍  | 3037/4096 [00:50<00:21, 50.08it/s, est. speed input: 61236.08 toks/s, output: 59.80 toks/s]
Processed prompts:  75%|███████▍  | 3069/4096 [00:51<00:20, 50.02it/s, est. speed input: 61109.00 toks/s, output: 59.68 toks/s]
Processed prompts:  76%|███████▌  | 3101/4096 [00:52<00:19, 49.98it/s, est. speed input: 60985.74 toks/s, output: 59.56 toks/s]
Processed prompts:  76%|███████▋  | 3133/4096 [00:52<00:19, 49.96it/s, est. speed input: 60865.48 toks/s, output: 59.44 toks/s]
Processed prompts:  77%|███████▋  | 3165/4096 [00:53<00:18, 49.91it/s, est. speed input: 60746.57 toks/s, output: 59.32 toks/s]
Processed prompts:  78%|███████▊  | 3197/4096 [00:53<00:18, 49.88it/s, est. speed input: 60630.59 toks/s, output: 59.21 toks/s]
Processed prompts:  79%|███████▉  | 3229/4096 [00:54<00:17, 49.86it/s, est. speed input: 60517.32 toks/s, output: 59.10 toks/s]
Processed prompts:  80%|███████▉  | 3261/4096 [00:55<00:16, 49.78it/s, est. speed input: 60404.03 toks/s, output: 58.99 toks/s]
Processed prompts:  80%|████████  | 3293/4096 [00:55<00:16, 49.75it/s, est. speed input: 60293.99 toks/s, output: 58.88 toks/s]
Processed prompts:  81%|████████  | 3325/4096 [00:56<00:15, 49.76it/s, est. speed input: 60188.24 toks/s, output: 58.78 toks/s]
Processed prompts:  82%|████████▏ | 3357/4096 [00:57<00:14, 49.80it/s, est. speed input: 60086.42 toks/s, output: 58.68 toks/s]
Processed prompts:  83%|████████▎ | 3389/4096 [00:57<00:14, 49.77it/s, est. speed input: 59984.17 toks/s, output: 58.58 toks/s]
Processed prompts:  84%|████████▎ | 3421/4096 [00:58<00:13, 49.77it/s, est. speed input: 59884.92 toks/s, output: 58.48 toks/s]
Processed prompts:  84%|████████▍ | 3453/4096 [00:59<00:12, 49.77it/s, est. speed input: 59788.13 toks/s, output: 58.39 toks/s]
Processed prompts:  85%|████████▌ | 3485/4096 [00:59<00:12, 49.68it/s, est. speed input: 59689.10 toks/s, output: 58.29 toks/s]
Processed prompts:  86%|████████▌ | 3517/4096 [01:00<00:11, 49.74it/s, est. speed input: 59597.64 toks/s, output: 58.20 toks/s]
Processed prompts:  87%|████████▋ | 3549/4096 [01:01<00:10, 50.06it/s, est. speed input: 59519.99 toks/s, output: 58.12 toks/s]
Processed prompts:  87%|████████▋ | 3581/4096 [01:01<00:10, 49.92it/s, est. speed input: 59428.39 toks/s, output: 58.04 toks/s]
Processed prompts:  88%|████████▊ | 3613/4096 [01:02<00:09, 49.81it/s, est. speed input: 59338.52 toks/s, output: 57.95 toks/s]
Processed prompts:  89%|████████▉ | 3645/4096 [01:02<00:09, 49.79it/s, est. speed input: 59252.93 toks/s, output: 57.86 toks/s]
Processed prompts:  90%|████████▉ | 3677/4096 [01:03<00:08, 50.05it/s, est. speed input: 59179.73 toks/s, output: 57.79 toks/s]
Processed prompts:  91%|█████████ | 3709/4096 [01:04<00:07, 49.93it/s, est. speed input: 59095.91 toks/s, output: 57.71 toks/s]
Processed prompts:  91%|█████████▏| 3741/4096 [01:04<00:07, 49.90it/s, est. speed input: 59016.11 toks/s, output: 57.63 toks/s]
Processed prompts:  92%|█████████▏| 3773/4096 [01:05<00:06, 49.76it/s, est. speed input: 58933.47 toks/s, output: 57.55 toks/s]
Processed prompts:  93%|█████████▎| 3805/4096 [01:06<00:05, 49.72it/s, est. speed input: 58854.18 toks/s, output: 57.47 toks/s]
Processed prompts:  94%|█████████▎| 3837/4096 [01:06<00:05, 49.67it/s, est. speed input: 58775.84 toks/s, output: 57.40 toks/s]
Processed prompts:  94%|█████████▍| 3869/4096 [01:07<00:04, 49.64it/s, est. speed input: 58699.34 toks/s, output: 57.32 toks/s]
Processed prompts:  95%|█████████▌| 3901/4096 [01:08<00:03, 49.69it/s, est. speed input: 58626.55 toks/s, output: 57.25 toks/s]
Processed prompts:  96%|█████████▌| 3933/4096 [01:08<00:03, 50.64it/s, est. speed input: 58588.26 toks/s, output: 57.22 toks/s]
Processed prompts:  97%|█████████▋| 3965/4096 [01:09<00:02, 50.29it/s, est. speed input: 58514.53 toks/s, output: 57.14 toks/s]
Processed prompts:  98%|█████████▊| 3997/4096 [01:10<00:01, 50.45it/s, est. speed input: 58456.43 toks/s, output: 57.09 toks/s]
Processed prompts:  98%|█████████▊| 4029/4096 [01:10<00:01, 50.14it/s, est. speed input: 58384.67 toks/s, output: 57.02 toks/s]
Processed prompts:  99%|█████████▉| 4061/4096 [01:11<00:00, 50.99it/s, est. speed input: 58350.78 toks/s, output: 56.98 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:11<00:00, 50.99it/s, est. speed input: 58780.89 toks/s, output: 57.40 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:11<00:00, 57.40it/s, est. speed input: 58780.89 toks/s, output: 57.40 toks/s]
[rank0]:[W126 12:01:31.117808260 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 12:01:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:02:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1327520) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1327520) WARNING 01-26 12:02:40 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     def forward(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     raise e
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/tmp/torchinductor_root/lz/clz3zg4ny6jmlz3bbcln42xg3grk4rvj74xjviyqcxrwehjw5lv2.py", line 1090, in call
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     triton_poi_fused_mul_quant_slide_fp8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_fp8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1327520) ERROR 01-26 12:02:49 [core.py:866] 

STDERR:
[2026-01-26 12:02:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:02:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:02:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:02:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:02:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:02:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:02:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:02:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:02:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 12:02:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:02:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 12:02:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 12:02:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:02:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:02:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:02:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:02:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1327520) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1327520) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.60it/s]
(EngineCore_DP0 pid=1327520) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.91it/s]
(EngineCore_DP0 pid=1327520) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.99it/s]
(EngineCore_DP0 pid=1327520) 
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1327520) [2026-01-26 12:02:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1327520) [rank0]:W0126 12:02:46.255000 1327520 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1327520) [rank0]:W0126 12:02:46.334000 1327520 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1327520) [rank0]:W0126 12:02:47.942000 1327520 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1327520) [rank0]:W0126 12:02:48.067000 1327520 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1327520) Process EngineCore_DP0:
(EngineCore_DP0 pid=1327520) Traceback (most recent call last):
(EngineCore_DP0 pid=1327520)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1327520)     self.run()
(EngineCore_DP0 pid=1327520)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1327520)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1327520)     raise e
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1327520)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1327520)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1327520)     super().__init__(
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1327520)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1327520)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1327520)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1327520)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1327520)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1327520)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1327520)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1327520)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1327520)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1327520)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1327520)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1327520)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1327520)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1327520)     outputs = self.model(
(EngineCore_DP0 pid=1327520)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1327520)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1327520)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1327520)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1327520)     hidden_states = self.model(
(EngineCore_DP0 pid=1327520)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=1327520)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=1327520)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=1327520)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=1327520)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=1327520)     def forward(
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1327520)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=1327520)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=1327520)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=1327520)     raise e
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=1327520)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1327520)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1327520)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=1327520)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=1327520)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=1327520)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=1327520)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=1327520)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=1327520)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=1327520)     return compiled_fn(full_args)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=1327520)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=1327520)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=1327520)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=1327520)                             ^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=1327520)     outs = compiled_fn(args)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=1327520)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=1327520)     return self.current_callable(inputs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=1327520)     out = model(new_inputs)
(EngineCore_DP0 pid=1327520)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/tmp/torchinductor_root/lz/clz3zg4ny6jmlz3bbcln42xg3grk4rvj74xjviyqcxrwehjw5lv2.py", line 1090, in call
(EngineCore_DP0 pid=1327520)     triton_poi_fused_mul_quant_slide_fp8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_fp8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=1327520)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=1327520)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=1327520)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=1327520)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=1327520)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=1327520)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=1327520)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=1327520)     torch.cuda.synchronize()
(EngineCore_DP0 pid=1327520)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=1327520)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=1327520)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1327520) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1327520) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1327520) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1327520) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1327520) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1327520) 
[rank0]:[W126 12:02:50.211973298 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 14:36:50
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:36:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1487143) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1487143) WARNING 01-26 14:37:18 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.70 requests/s, 12156.70 total tokens/s, 23.70 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 14:36:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:36:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:36:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:36:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:36:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:36:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:36:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:36:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:36:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:37:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:37:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:37:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:37:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:37:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:37:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.95it/s]
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.99it/s]
(EngineCore_DP0 pid=1487143) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.96it/s]
(EngineCore_DP0 pid=1487143) 
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1487143) [2026-01-26 14:37:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1487143) 2026-01-26 14:37:33,386 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1487143) 2026-01-26 14:37:33,425 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1487143) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  1.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]
(EngineCore_DP0 pid=1487143) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  30%|██▉       | 38/128 [00:00<00:00, 379.65it/s]
Adding requests:  86%|████████▌ | 110/128 [00:00<00:00, 575.80it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 563.34it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 24.00it/s, est. speed input: 12292.20 toks/s, output: 24.01 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:05, 24.27it/s, est. speed input: 12410.83 toks/s, output: 24.24 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 24.40it/s, est. speed input: 12464.19 toks/s, output: 24.34 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:04, 24.54it/s, est. speed input: 12514.16 toks/s, output: 24.44 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:04, 24.61it/s, est. speed input: 12545.72 toks/s, output: 24.50 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:04, 24.66it/s, est. speed input: 12567.02 toks/s, output: 24.54 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:04, 24.69it/s, est. speed input: 12582.28 toks/s, output: 24.57 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:04, 24.75it/s, est. speed input: 12601.43 toks/s, output: 24.61 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:04, 24.78it/s, est. speed input: 12615.26 toks/s, output: 24.64 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:03, 24.77it/s, est. speed input: 12620.56 toks/s, output: 24.65 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 24.80it/s, est. speed input: 12629.86 toks/s, output: 24.67 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:03, 24.83it/s, est. speed input: 12640.40 toks/s, output: 24.69 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:03, 24.83it/s, est. speed input: 12646.20 toks/s, output: 24.70 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:03, 24.81it/s, est. speed input: 12647.65 toks/s, output: 24.70 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:03, 24.75it/s, est. speed input: 12645.41 toks/s, output: 24.70 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:03, 24.72it/s, est. speed input: 12643.21 toks/s, output: 24.69 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:03, 24.72it/s, est. speed input: 12644.38 toks/s, output: 24.70 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:02, 24.75it/s, est. speed input: 12647.48 toks/s, output: 24.70 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:02, 24.76it/s, est. speed input: 12650.23 toks/s, output: 24.71 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:02, 24.77it/s, est. speed input: 12651.86 toks/s, output: 24.71 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:02<00:02, 24.81it/s, est. speed input: 12656.54 toks/s, output: 24.72 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:02<00:02, 24.81it/s, est. speed input: 12658.90 toks/s, output: 24.72 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:02, 24.81it/s, est. speed input: 12661.01 toks/s, output: 24.73 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:02, 24.79it/s, est. speed input: 12661.42 toks/s, output: 24.73 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 24.81it/s, est. speed input: 12663.78 toks/s, output: 24.73 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:03<00:02, 24.78it/s, est. speed input: 12663.12 toks/s, output: 24.73 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:01, 24.76it/s, est. speed input: 12662.82 toks/s, output: 24.73 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:03<00:01, 24.75it/s, est. speed input: 12662.97 toks/s, output: 24.73 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:03<00:01, 24.76it/s, est. speed input: 12663.71 toks/s, output: 24.73 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:03<00:01, 24.78it/s, est. speed input: 12665.35 toks/s, output: 24.74 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 24.81it/s, est. speed input: 12667.83 toks/s, output: 24.74 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:01, 24.81it/s, est. speed input: 12668.72 toks/s, output: 24.74 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 24.82it/s, est. speed input: 12670.43 toks/s, output: 24.75 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:04<00:01, 24.82it/s, est. speed input: 12671.26 toks/s, output: 24.75 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:04<00:00, 24.78it/s, est. speed input: 12670.34 toks/s, output: 24.75 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:00, 24.76it/s, est. speed input: 12669.87 toks/s, output: 24.75 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:04<00:00, 24.76it/s, est. speed input: 12670.12 toks/s, output: 24.75 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:04<00:00, 24.78it/s, est. speed input: 12671.14 toks/s, output: 24.75 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:04<00:00, 24.78it/s, est. speed input: 12671.37 toks/s, output: 24.75 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:04<00:00, 24.72it/s, est. speed input: 12669.26 toks/s, output: 24.74 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:04<00:00, 24.72it/s, est. speed input: 12668.82 toks/s, output: 24.74 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:05<00:00, 24.74it/s, est. speed input: 12669.49 toks/s, output: 24.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.74it/s, est. speed input: 12670.15 toks/s, output: 24.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.74it/s, est. speed input: 12670.15 toks/s, output: 24.75 toks/s]
[rank0]:[W126 14:37:41.875908557 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 14:37:43
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:37:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1488465) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1488465) WARNING 01-26 14:38:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.28 requests/s, 21807.56 total tokens/s, 21.28 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 14:37:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:37:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:37:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:37:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:37:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:37:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:37:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:37:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:37:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:37:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:37:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:37:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:37:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:37:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.94it/s]
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.98it/s]
(EngineCore_DP0 pid=1488465) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.96it/s]
(EngineCore_DP0 pid=1488465) 
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1488465) [2026-01-26 14:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1488465) 2026-01-26 14:38:26,925 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1488465) 2026-01-26 14:38:26,998 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1488465) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.94it/s]
(EngineCore_DP0 pid=1488465) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 11.03it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▌        | 20/128 [00:00<00:00, 199.11it/s]
Adding requests:  48%|████▊     | 61/128 [00:00<00:00, 318.57it/s]
Adding requests:  77%|███████▋  | 98/128 [00:00<00:00, 337.68it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 331.97it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:07, 17.22it/s, est. speed input: 17638.69 toks/s, output: 17.22 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:05, 20.99it/s, est. speed input: 20947.75 toks/s, output: 20.45 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:05, 21.87it/s, est. speed input: 21803.03 toks/s, output: 21.29 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 22.24it/s, est. speed input: 22202.39 toks/s, output: 21.68 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 22.51it/s, est. speed input: 22473.66 toks/s, output: 21.95 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 22.63it/s, est. speed input: 22631.92 toks/s, output: 22.10 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:04, 22.70it/s, est. speed input: 22745.54 toks/s, output: 22.21 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:04, 22.70it/s, est. speed input: 22807.31 toks/s, output: 22.27 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:04, 22.75it/s, est. speed input: 22877.05 toks/s, output: 22.34 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:04, 22.80it/s, est. speed input: 22935.94 toks/s, output: 22.40 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:04, 22.81it/s, est. speed input: 22976.09 toks/s, output: 22.44 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:04, 22.85it/s, est. speed input: 23019.94 toks/s, output: 22.48 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:03, 22.85it/s, est. speed input: 23050.41 toks/s, output: 22.51 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:03, 22.87it/s, est. speed input: 23079.48 toks/s, output: 22.54 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:03, 22.86it/s, est. speed input: 23099.88 toks/s, output: 22.56 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:03, 22.89it/s, est. speed input: 23125.22 toks/s, output: 22.58 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:03, 22.85it/s, est. speed input: 23135.79 toks/s, output: 22.59 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 22.83it/s, est. speed input: 23147.80 toks/s, output: 22.60 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 22.85it/s, est. speed input: 23162.95 toks/s, output: 22.62 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:03, 22.83it/s, est. speed input: 23171.86 toks/s, output: 22.63 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:02<00:02, 22.88it/s, est. speed input: 23189.94 toks/s, output: 22.65 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:02, 22.86it/s, est. speed input: 23197.37 toks/s, output: 22.65 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:02, 22.83it/s, est. speed input: 23202.10 toks/s, output: 22.66 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:02, 22.86it/s, est. speed input: 23213.18 toks/s, output: 22.67 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 22.85it/s, est. speed input: 23220.12 toks/s, output: 22.68 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 22.84it/s, est. speed input: 23226.17 toks/s, output: 22.68 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:03<00:02, 22.87it/s, est. speed input: 23235.55 toks/s, output: 22.69 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:01, 22.85it/s, est. speed input: 23239.29 toks/s, output: 22.69 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:03<00:01, 22.81it/s, est. speed input: 23240.97 toks/s, output: 22.70 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 22.83it/s, est. speed input: 23246.31 toks/s, output: 22.70 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:01, 22.79it/s, est. speed input: 23246.84 toks/s, output: 22.70 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:01, 22.85it/s, est. speed input: 23255.60 toks/s, output: 22.71 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:04<00:01, 22.83it/s, est. speed input: 23258.02 toks/s, output: 22.71 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 22.83it/s, est. speed input: 23261.90 toks/s, output: 22.72 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:04<00:01, 22.84it/s, est. speed input: 23266.41 toks/s, output: 22.72 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:04<00:00, 22.82it/s, est. speed input: 23267.30 toks/s, output: 22.72 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:04<00:00, 22.82it/s, est. speed input: 23270.59 toks/s, output: 22.73 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:04<00:00, 22.79it/s, est. speed input: 23269.85 toks/s, output: 22.72 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:05<00:00, 22.84it/s, est. speed input: 23275.86 toks/s, output: 22.73 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 22.85it/s, est. speed input: 23279.62 toks/s, output: 22.73 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 22.83it/s, est. speed input: 23281.04 toks/s, output: 22.74 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:05<00:00, 22.84it/s, est. speed input: 23284.09 toks/s, output: 22.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.84it/s, est. speed input: 23286.44 toks/s, output: 22.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.84it/s, est. speed input: 23286.44 toks/s, output: 22.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.74it/s, est. speed input: 23286.44 toks/s, output: 22.74 toks/s]
[rank0]:[W126 14:38:35.324537106 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 14:38:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:38:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1489717) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1489717) WARNING 01-26 14:39:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.97 requests/s, 24568.89 total tokens/s, 23.97 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 14:38:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:38:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:38:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:38:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:38:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:38:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:38:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:38:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:38:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:38:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:38:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:38:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:38:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:38:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:38:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:38:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:38:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.94it/s]
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.15it/s]
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1489717) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.95it/s]
(EngineCore_DP0 pid=1489717) 
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1489717) [2026-01-26 14:38:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1489717) 2026-01-26 14:39:21,511 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1489717) 2026-01-26 14:39:21,593 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1489717) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]
(EngineCore_DP0 pid=1489717) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  2.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 20/256 [00:00<00:01, 194.35it/s]
Adding requests:  24%|██▍       | 61/256 [00:00<00:00, 315.81it/s]
Adding requests:  38%|███▊      | 97/256 [00:00<00:00, 335.57it/s]
Adding requests:  53%|█████▎    | 135/256 [00:00<00:00, 351.07it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 365.09it/s]
Adding requests:  84%|████████▍ | 215/256 [00:00<00:00, 374.18it/s]
Adding requests:  99%|█████████▉| 254/256 [00:00<00:00, 376.43it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 355.82it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:02, 84.21it/s, est. speed input: 86249.52 toks/s, output: 84.22 toks/s]
Processed prompts:   7%|▋         | 19/256 [00:00<00:05, 39.64it/s, est. speed input: 44290.61 toks/s, output: 43.25 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:00<00:07, 32.85it/s, est. speed input: 37631.09 toks/s, output: 36.75 toks/s]
Processed prompts:  11%|█▏        | 29/256 [00:00<00:07, 30.28it/s, est. speed input: 35202.87 toks/s, output: 34.38 toks/s]
Processed prompts:  13%|█▎        | 33/256 [00:01<00:07, 28.45it/s, est. speed input: 33525.34 toks/s, output: 32.74 toks/s]
Processed prompts:  14%|█▍        | 37/256 [00:01<00:08, 27.37it/s, est. speed input: 32412.76 toks/s, output: 31.65 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:08, 24.78it/s, est. speed input: 30817.52 toks/s, output: 30.09 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:08, 24.87it/s, est. speed input: 30267.07 toks/s, output: 29.56 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:08, 24.93it/s, est. speed input: 29820.74 toks/s, output: 29.12 toks/s]
Processed prompts:  20%|██        | 52/256 [00:01<00:08, 24.90it/s, est. speed input: 29429.43 toks/s, output: 28.74 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:01<00:08, 24.78it/s, est. speed input: 29072.39 toks/s, output: 28.39 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:07, 24.78it/s, est. speed input: 28792.76 toks/s, output: 28.12 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:07, 24.86it/s, est. speed input: 28572.95 toks/s, output: 27.90 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:07, 24.91it/s, est. speed input: 28380.51 toks/s, output: 27.71 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:07, 24.93it/s, est. speed input: 28209.24 toks/s, output: 27.55 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:02<00:07, 24.96it/s, est. speed input: 28060.07 toks/s, output: 27.40 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:02<00:07, 24.90it/s, est. speed input: 27911.89 toks/s, output: 27.26 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:06, 24.92it/s, est. speed input: 27790.76 toks/s, output: 27.14 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:06, 24.94it/s, est. speed input: 27681.35 toks/s, output: 27.03 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:06, 24.96it/s, est. speed input: 27584.09 toks/s, output: 26.94 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:03<00:06, 25.02it/s, est. speed input: 27503.10 toks/s, output: 26.86 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:03<00:06, 24.94it/s, est. speed input: 27410.83 toks/s, output: 26.77 toks/s]
Processed prompts:  41%|████      | 104/256 [00:03<00:06, 24.73it/s, est. speed input: 27300.91 toks/s, output: 26.66 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:05, 24.76it/s, est. speed input: 27226.40 toks/s, output: 26.59 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:05, 24.74it/s, est. speed input: 27152.36 toks/s, output: 26.52 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:04<00:05, 24.80it/s, est. speed input: 27093.14 toks/s, output: 26.46 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:04<00:05, 24.80it/s, est. speed input: 27033.56 toks/s, output: 26.40 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:04<00:05, 24.85it/s, est. speed input: 26983.84 toks/s, output: 26.35 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:04<00:05, 24.75it/s, est. speed input: 26920.65 toks/s, output: 26.29 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:05, 24.66it/s, est. speed input: 26858.89 toks/s, output: 26.23 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:05<00:04, 24.72it/s, est. speed input: 26815.63 toks/s, output: 26.19 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:05<00:04, 24.79it/s, est. speed input: 26778.42 toks/s, output: 26.15 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:05<00:04, 24.83it/s, est. speed input: 26741.45 toks/s, output: 26.11 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:05<00:04, 24.87it/s, est. speed input: 26707.75 toks/s, output: 26.08 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:05<00:04, 24.90it/s, est. speed input: 26676.87 toks/s, output: 26.05 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:05<00:04, 24.81it/s, est. speed input: 26636.24 toks/s, output: 26.01 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:06<00:03, 24.89it/s, est. speed input: 26612.01 toks/s, output: 25.99 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:06<00:03, 24.91it/s, est. speed input: 26584.61 toks/s, output: 25.96 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:06<00:03, 25.01it/s, est. speed input: 26566.73 toks/s, output: 25.94 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:06<00:03, 25.01it/s, est. speed input: 26543.87 toks/s, output: 25.92 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:06<00:03, 25.00it/s, est. speed input: 26521.08 toks/s, output: 25.90 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:06<00:03, 24.98it/s, est. speed input: 26498.50 toks/s, output: 25.88 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:07<00:02, 24.83it/s, est. speed input: 26465.56 toks/s, output: 25.85 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:07<00:02, 24.79it/s, est. speed input: 26439.84 toks/s, output: 25.82 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:07<00:02, 24.80it/s, est. speed input: 26417.69 toks/s, output: 25.80 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:07<00:02, 24.80it/s, est. speed input: 26395.81 toks/s, output: 25.78 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:07<00:02, 24.79it/s, est. speed input: 26374.62 toks/s, output: 25.76 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:07<00:01, 26.37it/s, est. speed input: 26461.50 toks/s, output: 25.84 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:08<00:01, 25.96it/s, est. speed input: 26445.50 toks/s, output: 25.83 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:08<00:01, 25.52it/s, est. speed input: 26419.72 toks/s, output: 25.80 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:08<00:01, 25.37it/s, est. speed input: 26404.88 toks/s, output: 25.79 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:08<00:01, 25.24it/s, est. speed input: 26388.62 toks/s, output: 25.77 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:08<00:01, 25.08it/s, est. speed input: 26368.44 toks/s, output: 25.75 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:08<00:01, 24.84it/s, est. speed input: 26340.81 toks/s, output: 25.72 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:09<00:00, 24.72it/s, est. speed input: 26317.24 toks/s, output: 25.70 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:09<00:00, 24.82it/s, est. speed input: 26305.59 toks/s, output: 25.69 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:09<00:00, 24.83it/s, est. speed input: 26290.66 toks/s, output: 25.67 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:09<00:00, 24.76it/s, est. speed input: 26272.19 toks/s, output: 25.66 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:09<00:00, 24.83it/s, est. speed input: 26261.08 toks/s, output: 25.65 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:09<00:00, 24.77it/s, est. speed input: 26243.54 toks/s, output: 25.63 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 26.53it/s, est. speed input: 26323.33 toks/s, output: 25.71 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 26.53it/s, est. speed input: 26323.33 toks/s, output: 25.71 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 25.71it/s, est. speed input: 26323.33 toks/s, output: 25.71 toks/s]
[rank0]:[W126 14:39:35.393951140 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 14:39:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:39:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1491028) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1491028) WARNING 01-26 14:40:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.70 requests/s, 26341.19 total tokens/s, 25.70 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 14:39:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:39:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:39:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:39:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:39:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:39:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:39:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:39:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:39:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:39:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:39:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:39:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:39:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:39:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:39:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:39:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:39:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.93it/s]
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.98it/s]
(EngineCore_DP0 pid=1491028) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.96it/s]
(EngineCore_DP0 pid=1491028) 
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1491028) [2026-01-26 14:39:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1491028) 2026-01-26 14:40:23,153 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1491028) 2026-01-26 14:40:23,216 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1491028) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 11.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  6.76it/s]
(EngineCore_DP0 pid=1491028) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:01,  1.84it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  3.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  4.04it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 20/512 [00:00<00:02, 194.12it/s]
Adding requests:  12%|█▏        | 61/512 [00:00<00:01, 316.78it/s]
Adding requests:  19%|█▉        | 98/512 [00:00<00:01, 337.04it/s]
Adding requests:  27%|██▋       | 136/512 [00:00<00:01, 352.34it/s]
Adding requests:  34%|███▍      | 175/512 [00:00<00:00, 365.22it/s]
Adding requests:  42%|████▏     | 215/512 [00:00<00:00, 375.27it/s]
Adding requests:  49%|████▉     | 253/512 [00:00<00:00, 375.67it/s]
Adding requests:  57%|█████▋    | 292/512 [00:00<00:00, 378.34it/s]
Adding requests:  65%|██████▍   | 332/512 [00:00<00:00, 383.69it/s]
Adding requests:  73%|███████▎  | 372/512 [00:01<00:00, 388.57it/s]
Adding requests:  81%|████████  | 413/512 [00:01<00:00, 392.55it/s]
Adding requests:  88%|████████▊ | 453/512 [00:01<00:00, 391.60it/s]
Adding requests:  97%|█████████▋| 496/512 [00:01<00:00, 399.70it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 375.69it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▌         | 30/512 [00:00<00:02, 239.11it/s, est. speed input: 244894.47 toks/s, output: 239.12 toks/s]
Processed prompts:  11%|█         | 54/512 [00:01<00:10, 44.45it/s, est. speed input: 52667.73 toks/s, output: 51.43 toks/s]   
Processed prompts:  13%|█▎        | 66/512 [00:01<00:11, 37.23it/s, est. speed input: 44762.16 toks/s, output: 43.71 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:01<00:12, 34.13it/s, est. speed input: 41674.78 toks/s, output: 40.70 toks/s]
Processed prompts:  16%|█▌        | 80/512 [00:01<00:12, 34.79it/s, est. speed input: 41457.54 toks/s, output: 40.49 toks/s]
Processed prompts:  17%|█▋        | 85/512 [00:02<00:12, 34.29it/s, est. speed input: 40834.40 toks/s, output: 39.88 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:15, 28.00it/s, est. speed input: 37790.86 toks/s, output: 36.90 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:02<00:15, 27.67it/s, est. speed input: 37158.61 toks/s, output: 36.29 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:02<00:15, 27.31it/s, est. speed input: 36571.71 toks/s, output: 35.71 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:02<00:15, 26.86it/s, est. speed input: 36003.44 toks/s, output: 35.16 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:15, 26.44it/s, est. speed input: 35478.88 toks/s, output: 34.65 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:15, 26.26it/s, est. speed input: 35040.30 toks/s, output: 34.22 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:03<00:15, 26.19it/s, est. speed input: 34654.63 toks/s, output: 33.84 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:15, 26.17it/s, est. speed input: 34310.81 toks/s, output: 33.51 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:03<00:14, 26.20it/s, est. speed input: 34003.73 toks/s, output: 33.21 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:03<00:14, 26.10it/s, est. speed input: 33699.92 toks/s, output: 32.91 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:03<00:14, 25.87it/s, est. speed input: 33392.83 toks/s, output: 32.61 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:14, 25.80it/s, est. speed input: 33124.01 toks/s, output: 32.35 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:04<00:14, 25.82it/s, est. speed input: 32885.46 toks/s, output: 32.11 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:14, 25.92it/s, est. speed input: 32675.16 toks/s, output: 31.91 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:04<00:14, 25.99it/s, est. speed input: 32479.27 toks/s, output: 31.72 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:04<00:13, 25.94it/s, est. speed input: 32282.93 toks/s, output: 31.53 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:13, 25.87it/s, est. speed input: 32094.20 toks/s, output: 31.34 toks/s]
Processed prompts:  31%|███       | 158/512 [00:05<00:13, 25.79it/s, est. speed input: 31913.85 toks/s, output: 31.17 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:05<00:13, 25.75it/s, est. speed input: 31744.99 toks/s, output: 31.00 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:13, 25.81it/s, est. speed input: 31596.68 toks/s, output: 30.86 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:05<00:13, 25.89it/s, est. speed input: 31460.94 toks/s, output: 30.72 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:05<00:13, 25.94it/s, est. speed input: 31331.66 toks/s, output: 30.60 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:05<00:12, 25.84it/s, est. speed input: 31195.69 toks/s, output: 30.46 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:12, 25.76it/s, est. speed input: 31065.13 toks/s, output: 30.34 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:06<00:12, 25.72it/s, est. speed input: 30942.30 toks/s, output: 30.22 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:06<00:12, 25.78it/s, est. speed input: 30835.16 toks/s, output: 30.11 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:06<00:12, 25.85it/s, est. speed input: 30734.65 toks/s, output: 30.01 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:06<00:12, 25.91it/s, est. speed input: 30640.90 toks/s, output: 29.92 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:06<00:11, 27.62it/s, est. speed input: 30691.35 toks/s, output: 29.97 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:11, 27.08it/s, est. speed input: 30597.70 toks/s, output: 29.88 toks/s]
Processed prompts:  41%|████      | 210/512 [00:07<00:11, 26.59it/s, est. speed input: 30498.84 toks/s, output: 29.78 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:07<00:11, 26.33it/s, est. speed input: 30409.59 toks/s, output: 29.70 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:07<00:11, 26.22it/s, est. speed input: 30329.28 toks/s, output: 29.62 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:07<00:11, 26.12it/s, est. speed input: 30251.24 toks/s, output: 29.54 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:10, 26.06it/s, est. speed input: 30176.21 toks/s, output: 29.47 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:10, 25.99it/s, est. speed input: 30102.65 toks/s, output: 29.40 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:10, 25.89it/s, est. speed input: 30028.17 toks/s, output: 29.32 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:08<00:10, 25.81it/s, est. speed input: 29954.95 toks/s, output: 29.25 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:10, 25.90it/s, est. speed input: 29895.80 toks/s, output: 29.19 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:08<00:10, 25.91it/s, est. speed input: 29834.65 toks/s, output: 29.14 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:08<00:10, 25.95it/s, est. speed input: 29777.82 toks/s, output: 29.08 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:09, 26.01it/s, est. speed input: 29725.88 toks/s, output: 29.03 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:09, 26.03it/s, est. speed input: 29673.83 toks/s, output: 28.98 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:09<00:09, 25.98it/s, est. speed input: 29618.96 toks/s, output: 28.92 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:09<00:09, 25.97it/s, est. speed input: 29568.21 toks/s, output: 28.88 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:09<00:09, 25.96it/s, est. speed input: 29518.82 toks/s, output: 28.83 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:09<00:09, 25.94it/s, est. speed input: 29470.15 toks/s, output: 28.78 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:09, 25.96it/s, est. speed input: 29424.99 toks/s, output: 28.74 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:08, 25.99it/s, est. speed input: 29381.85 toks/s, output: 28.69 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:08, 26.00it/s, est. speed input: 29339.65 toks/s, output: 28.65 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:08, 25.92it/s, est. speed input: 29293.89 toks/s, output: 28.61 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:10<00:08, 25.98it/s, est. speed input: 29256.01 toks/s, output: 28.57 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:10<00:08, 25.93it/s, est. speed input: 29214.22 toks/s, output: 28.53 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:08, 25.94it/s, est. speed input: 29175.82 toks/s, output: 28.49 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:07, 27.56it/s, est. speed input: 29220.40 toks/s, output: 28.54 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:07, 27.12it/s, est. speed input: 29185.96 toks/s, output: 28.50 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:11<00:07, 26.80it/s, est. speed input: 29151.95 toks/s, output: 28.47 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:11<00:07, 26.56it/s, est. speed input: 29117.25 toks/s, output: 28.43 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:07, 26.28it/s, est. speed input: 29077.92 toks/s, output: 28.40 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:07, 26.17it/s, est. speed input: 29044.12 toks/s, output: 28.36 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:06, 26.13it/s, est. speed input: 29012.61 toks/s, output: 28.33 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:11<00:06, 26.10it/s, est. speed input: 28981.57 toks/s, output: 28.30 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:11<00:06, 26.02it/s, est. speed input: 28948.93 toks/s, output: 28.27 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:12<00:06, 26.08it/s, est. speed input: 28922.67 toks/s, output: 28.24 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:06, 26.01it/s, est. speed input: 28891.48 toks/s, output: 28.21 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:06, 25.95it/s, est. speed input: 28860.82 toks/s, output: 28.18 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:12<00:06, 25.95it/s, est. speed input: 28832.84 toks/s, output: 28.16 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:12<00:05, 25.97it/s, est. speed input: 28806.14 toks/s, output: 28.13 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:12<00:05, 25.94it/s, est. speed input: 28778.66 toks/s, output: 28.10 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:13<00:05, 25.94it/s, est. speed input: 28752.47 toks/s, output: 28.08 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:05, 25.99it/s, est. speed input: 28729.10 toks/s, output: 28.06 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:05, 25.94it/s, est. speed input: 28702.55 toks/s, output: 28.03 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:13<00:05, 25.92it/s, est. speed input: 28677.05 toks/s, output: 28.00 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:13<00:05, 25.91it/s, est. speed input: 28652.66 toks/s, output: 27.98 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:13<00:04, 25.94it/s, est. speed input: 28630.08 toks/s, output: 27.96 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:13<00:04, 25.93it/s, est. speed input: 28606.92 toks/s, output: 27.94 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:04, 25.92it/s, est. speed input: 28584.20 toks/s, output: 27.91 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:04, 25.97it/s, est. speed input: 28564.14 toks/s, output: 27.89 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:14<00:04, 25.96it/s, est. speed input: 28542.53 toks/s, output: 27.87 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:14<00:04, 25.90it/s, est. speed input: 28519.70 toks/s, output: 27.85 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:14<00:03, 25.93it/s, est. speed input: 28499.91 toks/s, output: 27.83 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:14<00:03, 25.95it/s, est. speed input: 28480.24 toks/s, output: 27.81 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:03, 25.90it/s, est. speed input: 28459.09 toks/s, output: 27.79 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:15<00:03, 25.92it/s, est. speed input: 28440.07 toks/s, output: 27.77 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:15<00:03, 25.96it/s, est. speed input: 28422.32 toks/s, output: 27.76 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:15<00:03, 25.89it/s, est. speed input: 28401.64 toks/s, output: 27.74 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:15<00:03, 25.89it/s, est. speed input: 28383.06 toks/s, output: 27.72 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:15<00:02, 25.94it/s, est. speed input: 28366.39 toks/s, output: 27.70 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:15<00:02, 25.91it/s, est. speed input: 28347.89 toks/s, output: 27.68 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:16<00:02, 25.89it/s, est. speed input: 28329.78 toks/s, output: 27.67 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:16<00:02, 25.90it/s, est. speed input: 28313.06 toks/s, output: 27.65 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:16<00:02, 25.94it/s, est. speed input: 28297.36 toks/s, output: 27.63 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:16<00:02, 25.92it/s, est. speed input: 28280.56 toks/s, output: 27.62 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:16<00:01, 25.90it/s, est. speed input: 28263.75 toks/s, output: 27.60 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:16<00:01, 25.94it/s, est. speed input: 28249.18 toks/s, output: 27.59 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:17<00:01, 25.95it/s, est. speed input: 28234.24 toks/s, output: 27.57 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:17<00:01, 25.88it/s, est. speed input: 28217.11 toks/s, output: 27.56 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:17<00:01, 25.87it/s, est. speed input: 28201.58 toks/s, output: 27.54 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:17<00:01, 25.85it/s, est. speed input: 28185.85 toks/s, output: 27.53 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:17<00:01, 25.87it/s, est. speed input: 28171.55 toks/s, output: 27.51 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:17<00:00, 25.87it/s, est. speed input: 28156.88 toks/s, output: 27.50 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:17<00:00, 25.88it/s, est. speed input: 28142.81 toks/s, output: 27.48 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:18<00:00, 25.88it/s, est. speed input: 28128.82 toks/s, output: 27.47 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:18<00:00, 25.87it/s, est. speed input: 28114.80 toks/s, output: 27.46 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:18<00:00, 25.89it/s, est. speed input: 28101.63 toks/s, output: 27.44 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:18<00:00, 27.76it/s, est. speed input: 28140.90 toks/s, output: 27.48 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:18<00:00, 27.76it/s, est. speed input: 28250.78 toks/s, output: 27.59 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:18<00:00, 27.59it/s, est. speed input: 28250.78 toks/s, output: 27.59 toks/s]
[rank0]:[W126 14:40:46.457778622 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 14:40:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:41:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1492520) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1492520) WARNING 01-26 14:41:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.38 requests/s, 27039.21 total tokens/s, 26.38 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 14:41:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:41:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:41:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:41:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:41:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:41:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:41:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:41:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:41:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:41:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:41:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:41:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:41:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:41:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:41:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:41:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:41:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.93it/s]
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.16it/s]
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1492520) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.95it/s]
(EngineCore_DP0 pid=1492520) 
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1492520) [2026-01-26 14:41:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1492520) 2026-01-26 14:41:36,199 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1492520) 2026-01-26 14:41:36,281 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1492520) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  5.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.35it/s]
(EngineCore_DP0 pid=1492520) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:01,  1.79it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.55it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 217.43it/s]
Adding requests:   6%|▌         | 62/1024 [00:00<00:02, 323.37it/s]
Adding requests:  10%|▉         | 98/1024 [00:00<00:02, 338.25it/s]
Adding requests:  13%|█▎        | 136/1024 [00:00<00:02, 351.88it/s]
Adding requests:  17%|█▋        | 175/1024 [00:00<00:02, 365.03it/s]
Adding requests:  21%|██        | 215/1024 [00:00<00:02, 376.58it/s]
Adding requests:  25%|██▍       | 253/1024 [00:00<00:02, 376.25it/s]
Adding requests:  29%|██▊       | 292/1024 [00:00<00:01, 379.97it/s]
Adding requests:  32%|███▏      | 332/1024 [00:00<00:01, 386.02it/s]
Adding requests:  36%|███▋      | 373/1024 [00:01<00:01, 391.70it/s]
Adding requests:  40%|████      | 413/1024 [00:01<00:01, 394.15it/s]
Adding requests:  44%|████▍     | 453/1024 [00:01<00:01, 392.93it/s]
Adding requests:  48%|████▊     | 496/1024 [00:01<00:01, 402.03it/s]
Adding requests:  52%|█████▏    | 537/1024 [00:01<00:01, 401.89it/s]
Adding requests:  56%|█████▋    | 578/1024 [00:01<00:01, 398.70it/s]
Adding requests:  60%|██████    | 618/1024 [00:01<00:01, 390.73it/s]
Adding requests:  64%|██████▍   | 658/1024 [00:01<00:00, 383.96it/s]
Adding requests:  68%|██████▊   | 698/1024 [00:01<00:00, 386.14it/s]
Adding requests:  72%|███████▏  | 737/1024 [00:01<00:00, 380.37it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:02<00:00, 382.32it/s]
Adding requests:  80%|███████▉  | 815/1024 [00:02<00:00, 381.61it/s]
Adding requests:  84%|████████▎ | 856/1024 [00:02<00:00, 389.03it/s]
Adding requests:  88%|████████▊ | 896/1024 [00:02<00:00, 390.65it/s]
Adding requests:  91%|█████████▏| 936/1024 [00:02<00:00, 382.28it/s]
Adding requests:  95%|█████████▌| 976/1024 [00:02<00:00, 385.27it/s]
Adding requests:  99%|█████████▉| 1015/1024 [00:02<00:00, 378.27it/s]
Adding requests: 100%|██████████| 1024/1024 [00:02<00:00, 380.53it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:00<00:03, 286.68it/s, est. speed input: 293587.21 toks/s, output: 286.68 toks/s]
Processed prompts:   9%|▉         | 95/1024 [00:01<00:13, 70.24it/s, est. speed input: 85356.23 toks/s, output: 83.35 toks/s]   
Processed prompts:  11%|█         | 109/1024 [00:01<00:18, 49.06it/s, est. speed input: 63836.35 toks/s, output: 62.34 toks/s]
Processed prompts:  12%|█▏        | 118/1024 [00:02<00:20, 44.43it/s, est. speed input: 58934.42 toks/s, output: 57.55 toks/s]
Processed prompts:  12%|█▏        | 125/1024 [00:02<00:23, 39.07it/s, est. speed input: 54477.14 toks/s, output: 53.20 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:02<00:27, 32.91it/s, est. speed input: 50126.59 toks/s, output: 48.95 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:02<00:28, 31.06it/s, est. speed input: 47735.91 toks/s, output: 46.62 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:03<00:29, 29.85it/s, est. speed input: 45868.38 toks/s, output: 44.79 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:03<00:30, 28.86it/s, est. speed input: 44268.02 toks/s, output: 43.23 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:03<00:30, 28.06it/s, est. speed input: 42883.60 toks/s, output: 41.88 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:04<00:30, 27.64it/s, est. speed input: 41759.05 toks/s, output: 40.78 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:04<00:30, 27.37it/s, est. speed input: 40793.90 toks/s, output: 39.84 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:04<00:30, 27.07it/s, est. speed input: 39917.83 toks/s, output: 38.98 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:05<00:30, 26.92it/s, est. speed input: 39161.45 toks/s, output: 38.24 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:05<00:29, 27.65it/s, est. speed input: 38710.69 toks/s, output: 37.80 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:29, 27.36it/s, est. speed input: 38106.20 toks/s, output: 37.21 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:05<00:29, 27.09it/s, est. speed input: 37549.40 toks/s, output: 36.67 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:06<00:29, 26.98it/s, est. speed input: 37060.67 toks/s, output: 36.19 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:29, 26.93it/s, est. speed input: 36621.92 toks/s, output: 35.76 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:06<00:29, 26.82it/s, est. speed input: 36207.90 toks/s, output: 35.36 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:07<00:28, 26.75it/s, est. speed input: 35829.67 toks/s, output: 34.99 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:28, 26.77it/s, est. speed input: 35493.28 toks/s, output: 34.66 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:07<00:28, 26.72it/s, est. speed input: 35174.01 toks/s, output: 34.35 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:08<00:28, 26.66it/s, est. speed input: 34873.81 toks/s, output: 34.06 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:27, 26.65it/s, est. speed input: 34599.83 toks/s, output: 33.79 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:27, 26.64it/s, est. speed input: 34344.73 toks/s, output: 33.54 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:27, 26.61it/s, est. speed input: 34102.30 toks/s, output: 33.30 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:26, 27.32it/s, est. speed input: 33976.23 toks/s, output: 33.18 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:26, 27.15it/s, est. speed input: 33769.76 toks/s, output: 32.98 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:26, 26.97it/s, est. speed input: 33567.61 toks/s, output: 32.78 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:10<00:25, 26.81it/s, est. speed input: 33374.11 toks/s, output: 32.59 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:10<00:25, 26.75it/s, est. speed input: 33197.42 toks/s, output: 32.42 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:10<00:25, 26.72it/s, est. speed input: 33032.35 toks/s, output: 32.26 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:25, 26.64it/s, est. speed input: 32868.85 toks/s, output: 32.10 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:11<00:24, 26.58it/s, est. speed input: 32714.14 toks/s, output: 31.95 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:11<00:24, 26.59it/s, est. speed input: 32573.54 toks/s, output: 31.81 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:11<00:24, 26.53it/s, est. speed input: 32432.52 toks/s, output: 31.67 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:12<00:24, 26.52it/s, est. speed input: 32301.39 toks/s, output: 31.54 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:12<00:23, 26.54it/s, est. speed input: 32179.26 toks/s, output: 31.42 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:12<00:23, 26.54it/s, est. speed input: 32061.79 toks/s, output: 31.31 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:13<00:23, 26.51it/s, est. speed input: 31947.20 toks/s, output: 31.20 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:13<00:22, 26.52it/s, est. speed input: 31839.92 toks/s, output: 31.09 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:13<00:22, 26.56it/s, est. speed input: 31741.14 toks/s, output: 31.00 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:14<00:22, 26.54it/s, est. speed input: 31641.99 toks/s, output: 30.90 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:14<00:21, 26.53it/s, est. speed input: 31547.08 toks/s, output: 30.81 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:14<00:21, 26.52it/s, est. speed input: 31456.49 toks/s, output: 30.72 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:14<00:21, 26.50it/s, est. speed input: 31367.72 toks/s, output: 30.63 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:15<00:21, 26.47it/s, est. speed input: 31281.97 toks/s, output: 30.55 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:15<00:20, 26.47it/s, est. speed input: 31200.94 toks/s, output: 30.47 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:15<00:20, 26.47it/s, est. speed input: 31122.98 toks/s, output: 30.39 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:16<00:20, 26.45it/s, est. speed input: 31046.36 toks/s, output: 30.32 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:16<00:19, 26.48it/s, est. speed input: 30975.35 toks/s, output: 30.25 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:16<00:19, 26.47it/s, est. speed input: 30905.33 toks/s, output: 30.18 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:17<00:19, 26.51it/s, est. speed input: 30840.45 toks/s, output: 30.12 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:17<00:18, 26.51it/s, est. speed input: 30776.14 toks/s, output: 30.05 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:17<00:18, 26.49it/s, est. speed input: 30712.80 toks/s, output: 29.99 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:17<00:18, 26.47it/s, est. speed input: 30651.45 toks/s, output: 29.93 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:18<00:18, 26.47it/s, est. speed input: 30592.58 toks/s, output: 29.88 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:18<00:17, 26.44it/s, est. speed input: 30533.83 toks/s, output: 29.82 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:18<00:17, 26.48it/s, est. speed input: 30481.06 toks/s, output: 29.77 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:19<00:17, 26.48it/s, est. speed input: 30428.08 toks/s, output: 29.71 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:19<00:16, 26.43it/s, est. speed input: 30373.51 toks/s, output: 29.66 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:19<00:16, 26.48it/s, est. speed input: 30325.68 toks/s, output: 29.61 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:20<00:16, 26.44it/s, est. speed input: 30275.06 toks/s, output: 29.57 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:20<00:15, 26.38it/s, est. speed input: 30224.54 toks/s, output: 29.52 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:20<00:15, 26.44it/s, est. speed input: 30180.61 toks/s, output: 29.47 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:21<00:15, 26.40it/s, est. speed input: 30133.91 toks/s, output: 29.43 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:21<00:15, 26.40it/s, est. speed input: 30089.46 toks/s, output: 29.38 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:21<00:14, 26.44it/s, est. speed input: 30048.85 toks/s, output: 29.34 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:21<00:14, 26.44it/s, est. speed input: 30007.73 toks/s, output: 29.30 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:22<00:14, 26.43it/s, est. speed input: 29967.18 toks/s, output: 29.26 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:22<00:13, 26.39it/s, est. speed input: 29926.21 toks/s, output: 29.22 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:22<00:13, 26.41it/s, est. speed input: 29888.80 toks/s, output: 29.19 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:23<00:13, 26.40it/s, est. speed input: 29850.80 toks/s, output: 29.15 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:23<00:12, 26.38it/s, est. speed input: 29813.62 toks/s, output: 29.11 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:23<00:12, 26.42it/s, est. speed input: 29779.62 toks/s, output: 29.08 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:24<00:12, 26.38it/s, est. speed input: 29743.25 toks/s, output: 29.05 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:24<00:12, 26.35it/s, est. speed input: 29707.83 toks/s, output: 29.01 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:24<00:11, 26.37it/s, est. speed input: 29675.07 toks/s, output: 28.98 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:24<00:11, 26.39it/s, est. speed input: 29643.59 toks/s, output: 28.95 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:25<00:11, 26.39it/s, est. speed input: 29612.25 toks/s, output: 28.92 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:25<00:10, 26.39it/s, est. speed input: 29581.64 toks/s, output: 28.89 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:25<00:10, 26.36it/s, est. speed input: 29550.22 toks/s, output: 28.86 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:26<00:10, 26.37it/s, est. speed input: 29521.02 toks/s, output: 28.83 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:26<00:09, 26.35it/s, est. speed input: 29491.28 toks/s, output: 28.80 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:26<00:09, 26.34it/s, est. speed input: 29462.41 toks/s, output: 28.77 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:27<00:09, 26.35it/s, est. speed input: 29435.01 toks/s, output: 28.75 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:27<00:08, 27.17it/s, est. speed input: 29440.55 toks/s, output: 28.75 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:27<00:08, 26.93it/s, est. speed input: 29413.84 toks/s, output: 28.72 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:27<00:08, 26.78it/s, est. speed input: 29388.56 toks/s, output: 28.70 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:28<00:08, 26.67it/s, est. speed input: 29363.49 toks/s, output: 28.68 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:28<00:07, 26.55it/s, est. speed input: 29337.36 toks/s, output: 28.65 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:28<00:07, 26.50it/s, est. speed input: 29312.97 toks/s, output: 28.63 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:29<00:07, 26.42it/s, est. speed input: 29287.37 toks/s, output: 28.60 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:29<00:06, 26.40it/s, est. speed input: 29263.52 toks/s, output: 28.58 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:29<00:06, 26.41it/s, est. speed input: 29241.17 toks/s, output: 28.56 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:30<00:06, 26.37it/s, est. speed input: 29217.76 toks/s, output: 28.53 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:30<00:06, 26.32it/s, est. speed input: 29193.75 toks/s, output: 28.51 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:30<00:05, 26.32it/s, est. speed input: 29171.57 toks/s, output: 28.49 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:30<00:05, 26.34it/s, est. speed input: 29150.62 toks/s, output: 28.47 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:31<00:05, 26.35it/s, est. speed input: 29129.68 toks/s, output: 28.45 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:31<00:04, 26.30it/s, est. speed input: 29107.44 toks/s, output: 28.43 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:31<00:04, 26.28it/s, est. speed input: 29086.02 toks/s, output: 28.40 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:32<00:04, 26.33it/s, est. speed input: 29067.25 toks/s, output: 28.39 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:32<00:03, 26.31it/s, est. speed input: 29046.76 toks/s, output: 28.37 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:32<00:03, 26.30it/s, est. speed input: 29026.90 toks/s, output: 28.35 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:33<00:03, 26.34it/s, est. speed input: 29008.99 toks/s, output: 28.33 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:33<00:02, 26.27it/s, est. speed input: 28988.27 toks/s, output: 28.31 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:33<00:02, 26.25it/s, est. speed input: 28968.75 toks/s, output: 28.29 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:34<00:02, 26.30it/s, est. speed input: 28951.52 toks/s, output: 28.27 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:34<00:02, 26.29it/s, est. speed input: 28933.47 toks/s, output: 28.26 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:34<00:01, 26.24it/s, est. speed input: 28913.97 toks/s, output: 28.24 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:34<00:01, 26.26it/s, est. speed input: 28896.95 toks/s, output: 28.22 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:35<00:01, 26.29it/s, est. speed input: 28880.58 toks/s, output: 28.20 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:35<00:00, 26.26it/s, est. speed input: 28862.81 toks/s, output: 28.19 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:35<00:00, 26.25it/s, est. speed input: 28845.62 toks/s, output: 28.17 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:36<00:00, 27.18it/s, est. speed input: 28856.89 toks/s, output: 28.18 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 27.18it/s, est. speed input: 29026.63 toks/s, output: 28.35 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 28.35it/s, est. speed input: 29026.63 toks/s, output: 28.35 toks/s]
[rank0]:[W126 14:42:18.608177293 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 14:42:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:42:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1494295) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1494295) WARNING 01-26 14:43:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.70 requests/s, 27366.62 total tokens/s, 26.70 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 14:42:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:42:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:42:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:42:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:42:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:42:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:42:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:42:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:42:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:42:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:42:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:42:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:42:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:42:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:42:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:42:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:42:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.90it/s]
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.67it/s]
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.15it/s]
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.98it/s]
(EngineCore_DP0 pid=1494295) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.95it/s]
(EngineCore_DP0 pid=1494295) 
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1494295) [2026-01-26 14:42:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1494295) [rank0]:W0126 14:43:09.173000 1494295 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1494295) [rank0]:W0126 14:43:09.226000 1494295 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1494295) [rank0]:W0126 14:43:10.076000 1494295 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1494295) [rank0]:W0126 14:43:10.160000 1494295 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1494295) 2026-01-26 14:43:14,825 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1494295) 2026-01-26 14:43:15,000 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1494295) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 10.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  6.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  3.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  4.83it/s]
(EngineCore_DP0 pid=1494295) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.16it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 10.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.20it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 244.69it/s]
Adding requests:   3%|▎         | 65/2048 [00:00<00:05, 333.01it/s]
Adding requests:   5%|▍         | 101/2048 [00:00<00:05, 341.21it/s]
Adding requests:   7%|▋         | 139/2048 [00:00<00:05, 354.44it/s]
Adding requests:   9%|▊         | 178/2048 [00:00<00:05, 364.17it/s]
Adding requests:  11%|█         | 219/2048 [00:00<00:04, 378.03it/s]
Adding requests:  13%|█▎        | 257/2048 [00:00<00:04, 373.65it/s]
Adding requests:  14%|█▍        | 296/2048 [00:00<00:04, 378.13it/s]
Adding requests:  16%|█▋        | 337/2048 [00:00<00:04, 385.77it/s]
Adding requests:  18%|█▊        | 377/2048 [00:01<00:04, 386.95it/s]
Adding requests:  20%|██        | 418/2048 [00:01<00:04, 393.55it/s]
Adding requests:  22%|██▏       | 458/2048 [00:01<00:04, 389.11it/s]
Adding requests:  24%|██▍       | 500/2048 [00:01<00:03, 395.54it/s]
Adding requests:  26%|██▋       | 542/2048 [00:01<00:03, 401.31it/s]
Adding requests:  28%|██▊       | 583/2048 [00:01<00:03, 395.52it/s]
Adding requests:  30%|███       | 623/2048 [00:01<00:03, 389.33it/s]
Adding requests:  32%|███▏      | 662/2048 [00:01<00:03, 380.77it/s]
Adding requests:  34%|███▍      | 701/2048 [00:01<00:03, 382.63it/s]
Adding requests:  36%|███▌      | 740/2048 [00:01<00:03, 373.12it/s]
Adding requests:  38%|███▊      | 778/2048 [00:02<00:03, 365.16it/s]
Adding requests:  40%|███▉      | 816/2048 [00:02<00:03, 367.86it/s]
Adding requests:  42%|████▏     | 857/2048 [00:02<00:03, 378.72it/s]
Adding requests:  44%|████▍     | 897/2048 [00:02<00:03, 382.97it/s]
Adding requests:  46%|████▌     | 936/2048 [00:02<00:02, 374.95it/s]
Adding requests:  48%|████▊     | 975/2048 [00:02<00:02, 378.09it/s]
Adding requests:  49%|████▉     | 1013/2048 [00:02<00:02, 373.29it/s]
Adding requests:  51%|█████▏    | 1052/2048 [00:02<00:02, 375.76it/s]
Adding requests:  53%|█████▎    | 1090/2048 [00:02<00:02, 375.54it/s]
Adding requests:  55%|█████▌    | 1131/2048 [00:02<00:02, 384.78it/s]
Adding requests:  57%|█████▋    | 1170/2048 [00:03<00:02, 378.23it/s]
Adding requests:  59%|█████▉    | 1211/2048 [00:03<00:02, 385.60it/s]
Adding requests:  61%|██████    | 1250/2048 [00:03<00:02, 385.31it/s]
Adding requests:  63%|██████▎   | 1289/2048 [00:03<00:01, 380.89it/s]
Adding requests:  65%|██████▍   | 1329/2048 [00:03<00:01, 384.28it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:03<00:01, 386.74it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:03<00:01, 385.24it/s]
Adding requests:  71%|███████   | 1447/2048 [00:03<00:01, 383.74it/s]
Adding requests:  73%|███████▎  | 1488/2048 [00:03<00:01, 389.15it/s]
Adding requests:  75%|███████▍  | 1528/2048 [00:04<00:01, 389.76it/s]
Adding requests:  77%|███████▋  | 1567/2048 [00:04<00:01, 384.61it/s]
Adding requests:  78%|███████▊  | 1606/2048 [00:04<00:01, 381.01it/s]
Adding requests:  80%|████████  | 1645/2048 [00:04<00:01, 373.10it/s]
Adding requests:  82%|████████▏ | 1683/2048 [00:04<00:00, 372.85it/s]
Adding requests:  84%|████████▍ | 1722/2048 [00:04<00:00, 377.48it/s]
Adding requests:  86%|████████▌ | 1762/2048 [00:04<00:00, 381.99it/s]
Adding requests:  88%|████████▊ | 1801/2048 [00:04<00:00, 383.66it/s]
Adding requests:  90%|████████▉ | 1840/2048 [00:04<00:00, 385.25it/s]
Adding requests:  92%|█████████▏| 1879/2048 [00:04<00:00, 385.87it/s]
Adding requests:  94%|█████████▍| 1920/2048 [00:05<00:00, 382.82it/s]
Adding requests:  96%|█████████▌| 1960/2048 [00:05<00:00, 385.78it/s]
Adding requests:  98%|█████████▊| 1999/2048 [00:05<00:00, 380.66it/s]
Adding requests: 100%|█████████▉| 2038/2048 [00:05<00:00, 376.16it/s]
Adding requests: 100%|██████████| 2048/2048 [00:05<00:00, 379.41it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:00<00:02, 673.84it/s, est. speed input: 690091.88 toks/s, output: 673.86 toks/s]
Processed prompts:  10%|▉         | 198/2048 [00:02<00:28, 64.39it/s, est. speed input: 80227.22 toks/s, output: 78.35 toks/s]   
Processed prompts:  11%|█         | 228/2048 [00:03<00:37, 48.44it/s, est. speed input: 62835.32 toks/s, output: 61.36 toks/s]
Processed prompts:  12%|█▏        | 246/2048 [00:04<00:40, 44.36it/s, est. speed input: 58453.03 toks/s, output: 57.08 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:04<00:46, 38.47it/s, est. speed input: 53873.87 toks/s, output: 52.61 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:05<00:49, 35.54it/s, est. speed input: 51064.00 toks/s, output: 49.87 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:06<00:53, 33.16it/s, est. speed input: 48741.26 toks/s, output: 47.60 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:06<00:54, 32.00it/s, est. speed input: 47128.81 toks/s, output: 46.02 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:07<00:56, 30.51it/s, est. speed input: 45511.08 toks/s, output: 44.44 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:07<00:58, 29.47it/s, est. speed input: 44151.54 toks/s, output: 43.12 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:08<00:58, 28.75it/s, est. speed input: 42992.79 toks/s, output: 41.98 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:09<00:59, 28.13it/s, est. speed input: 41950.45 toks/s, output: 40.97 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:09<00:59, 27.76it/s, est. speed input: 41058.15 toks/s, output: 40.10 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:10<00:59, 27.49it/s, est. speed input: 40267.59 toks/s, output: 39.32 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:10<00:59, 27.33it/s, est. speed input: 39573.69 toks/s, output: 38.65 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:11<00:59, 27.19it/s, est. speed input: 38944.62 toks/s, output: 38.03 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:12<00:58, 27.10it/s, est. speed input: 38377.36 toks/s, output: 37.48 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:12<00:58, 27.03it/s, est. speed input: 37864.02 toks/s, output: 36.98 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:13<00:57, 27.01it/s, est. speed input: 37403.10 toks/s, output: 36.53 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:13<00:57, 26.96it/s, est. speed input: 36975.40 toks/s, output: 36.11 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:14<00:56, 26.94it/s, est. speed input: 36583.83 toks/s, output: 35.73 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:14<00:56, 26.91it/s, est. speed input: 36222.68 toks/s, output: 35.37 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:15<00:55, 26.91it/s, est. speed input: 35891.67 toks/s, output: 35.05 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:16<00:55, 26.91it/s, est. speed input: 35584.58 toks/s, output: 34.75 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:16<00:54, 26.88it/s, est. speed input: 35295.28 toks/s, output: 34.47 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:17<00:54, 26.84it/s, est. speed input: 35023.59 toks/s, output: 34.20 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:17<00:53, 26.83it/s, est. speed input: 34771.55 toks/s, output: 33.96 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:18<00:52, 26.84it/s, est. speed input: 34539.10 toks/s, output: 33.73 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:19<00:52, 26.82it/s, est. speed input: 34316.43 toks/s, output: 33.51 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:19<00:51, 26.83it/s, est. speed input: 34110.37 toks/s, output: 33.31 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:20<00:51, 26.81it/s, est. speed input: 33913.47 toks/s, output: 33.12 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:20<00:50, 26.79it/s, est. speed input: 33727.27 toks/s, output: 32.94 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:21<00:50, 26.80it/s, est. speed input: 33553.73 toks/s, output: 32.77 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:22<00:49, 26.78it/s, est. speed input: 33386.50 toks/s, output: 32.60 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:22<00:48, 26.78it/s, est. speed input: 33230.32 toks/s, output: 32.45 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:23<00:48, 26.81it/s, est. speed input: 33084.14 toks/s, output: 32.31 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:23<00:47, 26.79it/s, est. speed input: 32941.70 toks/s, output: 32.17 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:24<00:46, 27.25it/s, est. speed input: 32852.52 toks/s, output: 32.08 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:25<00:45, 27.10it/s, est. speed input: 32722.48 toks/s, output: 31.96 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:25<00:45, 27.01it/s, est. speed input: 32599.70 toks/s, output: 31.84 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:26<00:45, 26.91it/s, est. speed input: 32479.44 toks/s, output: 31.72 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:26<00:44, 26.85it/s, est. speed input: 32365.05 toks/s, output: 31.61 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:27<00:44, 26.81it/s, est. speed input: 32255.79 toks/s, output: 31.50 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:28<00:43, 26.77it/s, est. speed input: 32150.53 toks/s, output: 31.40 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:28<00:43, 26.74it/s, est. speed input: 32049.71 toks/s, output: 31.30 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:29<00:42, 26.71it/s, est. speed input: 31951.52 toks/s, output: 31.20 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:29<00:41, 26.74it/s, est. speed input: 31861.85 toks/s, output: 31.12 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:30<00:41, 26.73it/s, est. speed input: 31773.19 toks/s, output: 31.03 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:31<00:40, 26.72it/s, est. speed input: 31687.26 toks/s, output: 30.94 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:31<00:40, 26.72it/s, est. speed input: 31606.06 toks/s, output: 30.87 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:32<00:39, 26.71it/s, est. speed input: 31526.52 toks/s, output: 30.79 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:32<00:38, 26.74it/s, est. speed input: 31452.71 toks/s, output: 30.72 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:33<00:38, 26.74it/s, est. speed input: 31379.59 toks/s, output: 30.64 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:34<00:37, 26.73it/s, est. speed input: 31308.99 toks/s, output: 30.58 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:34<00:37, 26.73it/s, est. speed input: 31241.22 toks/s, output: 30.51 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:35<00:36, 26.72it/s, est. speed input: 31175.02 toks/s, output: 30.44 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:35<00:35, 26.72it/s, est. speed input: 31111.14 toks/s, output: 30.38 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:36<00:35, 26.72it/s, est. speed input: 31049.66 toks/s, output: 30.32 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:37<00:34, 26.71it/s, est. speed input: 30989.21 toks/s, output: 30.26 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:37<00:34, 26.68it/s, est. speed input: 30929.80 toks/s, output: 30.20 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:38<00:33, 26.68it/s, est. speed input: 30873.26 toks/s, output: 30.15 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:38<00:32, 26.67it/s, est. speed input: 30818.05 toks/s, output: 30.10 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:39<00:32, 26.66it/s, est. speed input: 30763.99 toks/s, output: 30.04 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:40<00:31, 26.68it/s, est. speed input: 30713.01 toks/s, output: 29.99 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:40<00:31, 26.64it/s, est. speed input: 30660.91 toks/s, output: 29.94 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:41<00:30, 26.67it/s, est. speed input: 30613.18 toks/s, output: 29.90 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:41<00:29, 26.66it/s, est. speed input: 30565.54 toks/s, output: 29.85 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:42<00:29, 26.65it/s, est. speed input: 30518.54 toks/s, output: 29.80 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:43<00:28, 26.64it/s, est. speed input: 30473.26 toks/s, output: 29.76 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:43<00:28, 26.64it/s, est. speed input: 30429.06 toks/s, output: 29.72 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:44<00:27, 26.64it/s, est. speed input: 30386.58 toks/s, output: 29.67 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:44<00:26, 26.64it/s, est. speed input: 30344.80 toks/s, output: 29.63 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:45<00:26, 26.64it/s, est. speed input: 30304.62 toks/s, output: 29.59 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:46<00:25, 26.64it/s, est. speed input: 30265.03 toks/s, output: 29.56 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:46<00:25, 26.63it/s, est. speed input: 30226.25 toks/s, output: 29.52 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:47<00:24, 26.62it/s, est. speed input: 30188.03 toks/s, output: 29.48 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:47<00:23, 26.59it/s, est. speed input: 30150.10 toks/s, output: 29.44 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:48<00:23, 26.56it/s, est. speed input: 30112.36 toks/s, output: 29.41 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:49<00:22, 26.58it/s, est. speed input: 30077.31 toks/s, output: 29.37 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:49<00:22, 26.57it/s, est. speed input: 30042.36 toks/s, output: 29.34 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:50<00:21, 26.57it/s, est. speed input: 30008.44 toks/s, output: 29.31 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:50<00:20, 26.59it/s, est. speed input: 29976.07 toks/s, output: 29.27 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:51<00:20, 26.58it/s, est. speed input: 29943.76 toks/s, output: 29.24 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:52<00:19, 26.57it/s, est. speed input: 29911.75 toks/s, output: 29.21 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:52<00:19, 26.59it/s, est. speed input: 29881.54 toks/s, output: 29.18 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:53<00:18, 27.01it/s, est. speed input: 29869.00 toks/s, output: 29.17 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:53<00:17, 26.89it/s, est. speed input: 29840.12 toks/s, output: 29.14 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:54<00:17, 26.75it/s, est. speed input: 29809.24 toks/s, output: 29.11 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:55<00:16, 26.71it/s, est. speed input: 29781.26 toks/s, output: 29.08 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:55<00:15, 27.13it/s, est. speed input: 29771.73 toks/s, output: 29.07 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:56<00:15, 26.92it/s, est. speed input: 29742.85 toks/s, output: 29.05 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:56<00:14, 26.82it/s, est. speed input: 29716.14 toks/s, output: 29.02 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:57<00:14, 26.71it/s, est. speed input: 29688.66 toks/s, output: 28.99 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:58<00:13, 26.67it/s, est. speed input: 29662.88 toks/s, output: 28.97 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:58<00:13, 26.60it/s, est. speed input: 29636.10 toks/s, output: 28.94 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:59<00:12, 26.56it/s, est. speed input: 29610.29 toks/s, output: 28.92 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:59<00:11, 26.54it/s, est. speed input: 29585.40 toks/s, output: 28.89 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:00<00:11, 26.54it/s, est. speed input: 29561.31 toks/s, output: 28.87 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:01<00:10, 26.54it/s, est. speed input: 29537.85 toks/s, output: 28.85 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:01<00:10, 26.53it/s, est. speed input: 29514.42 toks/s, output: 28.82 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:02<00:09, 26.51it/s, est. speed input: 29490.82 toks/s, output: 28.80 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:02<00:08, 26.51it/s, est. speed input: 29468.37 toks/s, output: 28.78 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:03<00:08, 26.50it/s, est. speed input: 29446.04 toks/s, output: 28.76 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:04<00:07, 26.50it/s, est. speed input: 29424.40 toks/s, output: 28.73 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:04<00:07, 26.51it/s, est. speed input: 29403.21 toks/s, output: 28.71 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:05<00:06, 26.50it/s, est. speed input: 29382.18 toks/s, output: 28.69 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:05<00:05, 26.51it/s, est. speed input: 29361.72 toks/s, output: 28.67 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:06<00:05, 26.50it/s, est. speed input: 29341.37 toks/s, output: 28.65 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:07<00:04, 26.51it/s, est. speed input: 29322.00 toks/s, output: 28.63 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:07<00:04, 26.53it/s, est. speed input: 29303.24 toks/s, output: 28.62 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:08<00:03, 26.53it/s, est. speed input: 29284.22 toks/s, output: 28.60 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:08<00:02, 26.51it/s, est. speed input: 29265.09 toks/s, output: 28.58 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:09<00:02, 26.51it/s, est. speed input: 29246.65 toks/s, output: 28.56 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:10<00:01, 26.49it/s, est. speed input: 29227.94 toks/s, output: 28.54 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:10<00:01, 26.51it/s, est. speed input: 29210.73 toks/s, output: 28.53 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:11<00:00, 27.05it/s, est. speed input: 29209.65 toks/s, output: 28.53 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:11<00:00, 27.05it/s, est. speed input: 29410.46 toks/s, output: 28.72 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:11<00:00, 28.72it/s, est. speed input: 29410.46 toks/s, output: 28.72 toks/s]
[rank0]:[W126 14:44:35.819954316 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 14:44:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:45:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1496727) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1496727) WARNING 01-26 14:45:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.81 requests/s, 27476.28 total tokens/s, 26.81 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 14:45:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:45:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:45:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:45:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:45:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:45:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:45:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:45:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:45:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:45:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:45:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:45:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:45:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:45:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:45:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:45:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:45:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.95it/s]
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.69it/s]
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.17it/s]
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.99it/s]
(EngineCore_DP0 pid=1496727) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1496727) 
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1496727) [2026-01-26 14:45:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1496727) [rank0]:W0126 14:45:36.398000 1496727 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1496727) [rank0]:W0126 14:45:36.452000 1496727 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1496727) [rank0]:W0126 14:45:37.678000 1496727 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1496727) [rank0]:W0126 14:45:37.762000 1496727 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=1496727) 2026-01-26 14:45:42,499 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1496727) 2026-01-26 14:45:42,891 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1496727) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:06,  1.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:01<00:04,  1.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:01<00:01,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:01<00:00,  5.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  7.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  6.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  4.25it/s]
(EngineCore_DP0 pid=1496727) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.38it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  9.90it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  8.25it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.65it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:16, 253.24it/s]
Adding requests:   2%|▏         | 66/4096 [00:00<00:11, 337.24it/s]
Adding requests:   3%|▎         | 103/4096 [00:00<00:11, 347.63it/s]
Adding requests:   3%|▎         | 140/4096 [00:00<00:11, 356.18it/s]
Adding requests:   4%|▍         | 179/4096 [00:00<00:10, 367.11it/s]
Adding requests:   5%|▌         | 221/4096 [00:00<00:10, 381.98it/s]
Adding requests:   6%|▋         | 260/4096 [00:00<00:10, 377.56it/s]
Adding requests:   7%|▋         | 300/4096 [00:00<00:09, 383.67it/s]
Adding requests:   8%|▊         | 340/4096 [00:00<00:09, 388.39it/s]
Adding requests:   9%|▉         | 380/4096 [00:01<00:09, 389.06it/s]
Adding requests:  10%|█         | 421/4096 [00:01<00:09, 394.66it/s]
Adding requests:  11%|█▏        | 461/4096 [00:01<00:09, 388.17it/s]
Adding requests:  12%|█▏        | 503/4096 [00:01<00:09, 395.42it/s]
Adding requests:  13%|█▎        | 544/4096 [00:01<00:08, 399.42it/s]
Adding requests:  14%|█▍        | 584/4096 [00:01<00:08, 395.14it/s]
Adding requests:  15%|█▌        | 624/4096 [00:01<00:08, 387.62it/s]
Adding requests:  16%|█▌        | 663/4096 [00:01<00:08, 381.49it/s]
Adding requests:  17%|█▋        | 702/4096 [00:01<00:08, 383.49it/s]
Adding requests:  18%|█▊        | 741/4096 [00:01<00:08, 378.52it/s]
Adding requests:  19%|█▉        | 779/4096 [00:02<00:08, 377.66it/s]
Adding requests:  20%|█▉        | 817/4096 [00:02<00:08, 376.92it/s]
Adding requests:  21%|██        | 858/4096 [00:02<00:08, 385.17it/s]
Adding requests:  22%|██▏       | 898/4096 [00:02<00:08, 386.70it/s]
Adding requests:  23%|██▎       | 937/4096 [00:02<00:08, 379.25it/s]
Adding requests:  24%|██▍       | 976/4096 [00:02<00:08, 379.88it/s]
Adding requests:  25%|██▍       | 1015/4096 [00:02<00:08, 372.77it/s]
Adding requests:  26%|██▌       | 1053/4096 [00:02<00:08, 373.83it/s]
Adding requests:  27%|██▋       | 1091/4096 [00:02<00:08, 373.04it/s]
Adding requests:  28%|██▊       | 1129/4096 [00:02<00:08, 368.76it/s]
Adding requests:  28%|██▊       | 1166/4096 [00:03<00:07, 366.73it/s]
Adding requests:  29%|██▉       | 1203/4096 [00:03<00:07, 367.23it/s]
Adding requests:  30%|███       | 1243/4096 [00:03<00:07, 375.23it/s]
Adding requests:  31%|███▏      | 1281/4096 [00:03<00:07, 372.06it/s]
Adding requests:  32%|███▏      | 1319/4096 [00:03<00:07, 371.77it/s]
Adding requests:  33%|███▎      | 1358/4096 [00:03<00:07, 376.13it/s]
Adding requests:  34%|███▍      | 1396/4096 [00:03<00:07, 376.51it/s]
Adding requests:  35%|███▌      | 1434/4096 [00:03<00:07, 375.61it/s]
Adding requests:  36%|███▌      | 1473/4096 [00:03<00:06, 377.04it/s]
Adding requests:  37%|███▋      | 1513/4096 [00:04<00:06, 383.77it/s]
Adding requests:  38%|███▊      | 1552/4096 [00:04<00:06, 380.14it/s]
Adding requests:  39%|███▉      | 1591/4096 [00:04<00:06, 374.16it/s]
Adding requests:  40%|███▉      | 1629/4096 [00:04<00:06, 368.26it/s]
Adding requests:  41%|████      | 1666/4096 [00:04<00:06, 360.32it/s]
Adding requests:  42%|████▏     | 1705/4096 [00:04<00:06, 366.95it/s]
Adding requests:  43%|████▎     | 1743/4096 [00:04<00:06, 369.83it/s]
Adding requests:  44%|████▎     | 1783/4096 [00:04<00:06, 376.71it/s]
Adding requests:  44%|████▍     | 1821/4096 [00:04<00:06, 372.36it/s]
Adding requests:  45%|████▌     | 1861/4096 [00:04<00:05, 378.62it/s]
Adding requests:  46%|████▋     | 1900/4096 [00:05<00:05, 378.74it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:05<00:05, 390.14it/s]
Adding requests:  48%|████▊     | 1982/4096 [00:05<00:05, 391.40it/s]
Adding requests:  49%|████▉     | 2022/4096 [00:05<00:05, 380.57it/s]
Adding requests:  50%|█████     | 2061/4096 [00:05<00:05, 379.13it/s]
Adding requests:  51%|█████     | 2099/4096 [00:05<00:05, 375.35it/s]
Adding requests:  52%|█████▏    | 2138/4096 [00:05<00:05, 377.65it/s]
Adding requests:  53%|█████▎    | 2176/4096 [00:05<00:05, 373.09it/s]
Adding requests:  54%|█████▍    | 2214/4096 [00:05<00:05, 372.16it/s]
Adding requests:  55%|█████▌    | 2254/4096 [00:05<00:04, 380.20it/s]
Adding requests:  56%|█████▌    | 2294/4096 [00:06<00:04, 384.36it/s]
Adding requests:  57%|█████▋    | 2333/4096 [00:06<00:04, 375.77it/s]
Adding requests:  58%|█████▊    | 2373/4096 [00:06<00:04, 382.34it/s]
Adding requests:  59%|█████▉    | 2415/4096 [00:06<00:04, 391.17it/s]
Adding requests:  60%|█████▉    | 2455/4096 [00:06<00:04, 388.10it/s]
Adding requests:  61%|██████    | 2495/4096 [00:06<00:04, 390.47it/s]
Adding requests:  62%|██████▏   | 2536/4096 [00:06<00:03, 396.12it/s]
Adding requests:  63%|██████▎   | 2579/4096 [00:06<00:03, 405.22it/s]
Adding requests:  64%|██████▍   | 2620/4096 [00:06<00:03, 399.76it/s]
Adding requests:  65%|██████▍   | 2661/4096 [00:07<00:03, 389.71it/s]
Adding requests:  66%|██████▌   | 2701/4096 [00:07<00:03, 384.78it/s]
Adding requests:  67%|██████▋   | 2740/4096 [00:07<00:03, 384.04it/s]
Adding requests:  68%|██████▊   | 2781/4096 [00:07<00:03, 391.42it/s]
Adding requests:  69%|██████▉   | 2822/4096 [00:07<00:03, 393.78it/s]
Adding requests:  70%|██████▉   | 2862/4096 [00:07<00:03, 394.11it/s]
Adding requests:  71%|███████   | 2902/4096 [00:07<00:03, 392.80it/s]
Adding requests:  72%|███████▏  | 2942/4096 [00:07<00:02, 394.56it/s]
Adding requests:  73%|███████▎  | 2982/4096 [00:07<00:02, 393.67it/s]
Adding requests:  74%|███████▍  | 3022/4096 [00:07<00:02, 395.10it/s]
Adding requests:  75%|███████▍  | 3064/4096 [00:08<00:02, 399.00it/s]
Adding requests:  76%|███████▌  | 3104/4096 [00:08<00:02, 397.02it/s]
Adding requests:  77%|███████▋  | 3144/4096 [00:08<00:02, 397.18it/s]
Adding requests:  78%|███████▊  | 3184/4096 [00:08<00:02, 388.30it/s]
Adding requests:  79%|███████▊  | 3223/4096 [00:08<00:02, 383.86it/s]
Adding requests:  80%|███████▉  | 3262/4096 [00:08<00:02, 382.91it/s]
Adding requests:  81%|████████  | 3301/4096 [00:08<00:02, 372.45it/s]
Adding requests:  82%|████████▏ | 3339/4096 [00:08<00:02, 372.99it/s]
Adding requests:  82%|████████▏ | 3378/4096 [00:08<00:01, 377.71it/s]
Adding requests:  83%|████████▎ | 3416/4096 [00:08<00:01, 377.99it/s]
Adding requests:  84%|████████▍ | 3455/4096 [00:09<00:01, 381.09it/s]
Adding requests:  85%|████████▌ | 3494/4096 [00:09<00:01, 380.03it/s]
Adding requests:  86%|████████▋ | 3537/4096 [00:09<00:01, 394.16it/s]
Adding requests:  87%|████████▋ | 3577/4096 [00:09<00:01, 392.16it/s]
Adding requests:  88%|████████▊ | 3617/4096 [00:09<00:01, 393.22it/s]
Adding requests:  89%|████████▉ | 3657/4096 [00:09<00:01, 392.91it/s]
Adding requests:  90%|█████████ | 3697/4096 [00:09<00:01, 373.07it/s]
Adding requests:  91%|█████████▏| 3738/4096 [00:09<00:00, 381.09it/s]
Adding requests:  92%|█████████▏| 3777/4096 [00:09<00:00, 372.73it/s]
Adding requests:  93%|█████████▎| 3815/4096 [00:10<00:00, 364.17it/s]
Adding requests:  94%|█████████▍| 3854/4096 [00:10<00:00, 370.41it/s]
Adding requests:  95%|█████████▌| 3892/4096 [00:10<00:00, 373.10it/s]
Adding requests:  96%|█████████▌| 3930/4096 [00:10<00:00, 367.90it/s]
Adding requests:  97%|█████████▋| 3969/4096 [00:10<00:00, 371.29it/s]
Adding requests:  98%|█████████▊| 4007/4096 [00:10<00:00, 373.09it/s]
Adding requests:  99%|█████████▉| 4045/4096 [00:10<00:00, 372.33it/s]
Adding requests: 100%|█████████▉| 4083/4096 [00:10<00:00, 373.54it/s]
Adding requests: 100%|██████████| 4096/4096 [00:10<00:00, 380.33it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:01<00:14, 263.16it/s, est. speed input: 269492.05 toks/s, output: 263.17 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:02<00:31, 120.66it/s, est. speed input: 144731.37 toks/s, output: 141.34 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:03<00:48, 77.31it/s, est. speed input: 104870.67 toks/s, output: 102.41 toks/s] 
Processed prompts:   9%|▉         | 386/4096 [00:04<01:04, 57.33it/s, est. speed input: 85281.40 toks/s, output: 83.28 toks/s]  
Processed prompts:  10%|█         | 418/4096 [00:05<01:19, 46.35it/s, est. speed input: 73603.96 toks/s, output: 71.88 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:06<01:31, 39.79it/s, est. speed input: 65874.32 toks/s, output: 64.33 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:08<01:41, 35.63it/s, est. speed input: 60371.13 toks/s, output: 58.96 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:09<01:48, 32.90it/s, est. speed input: 56249.88 toks/s, output: 54.93 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:10<01:54, 31.09it/s, est. speed input: 53058.59 toks/s, output: 51.81 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:11<01:57, 29.82it/s, est. speed input: 50490.92 toks/s, output: 49.31 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:12<02:00, 28.97it/s, est. speed input: 48399.96 toks/s, output: 47.27 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:14<02:01, 28.38it/s, est. speed input: 46658.81 toks/s, output: 45.57 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:15<02:02, 27.97it/s, est. speed input: 45187.46 toks/s, output: 44.13 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:16<02:02, 27.68it/s, est. speed input: 43925.52 toks/s, output: 42.90 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:17<02:02, 27.46it/s, est. speed input: 42827.55 toks/s, output: 41.82 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:18<02:00, 27.53it/s, est. speed input: 41939.23 toks/s, output: 40.96 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:19<02:00, 27.36it/s, est. speed input: 41086.92 toks/s, output: 40.12 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:21<01:59, 27.25it/s, est. speed input: 40334.16 toks/s, output: 39.39 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:22<01:58, 27.17it/s, est. speed input: 39661.02 toks/s, output: 38.73 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:23<01:58, 27.10it/s, est. speed input: 39051.10 toks/s, output: 38.14 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:24<01:57, 27.06it/s, est. speed input: 38502.72 toks/s, output: 37.60 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:25<01:55, 27.02it/s, est. speed input: 38001.83 toks/s, output: 37.11 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:27<01:54, 27.00it/s, est. speed input: 37545.37 toks/s, output: 36.67 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:28<01:53, 26.98it/s, est. speed input: 37126.99 toks/s, output: 36.26 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:29<01:52, 26.94it/s, est. speed input: 36738.45 toks/s, output: 35.88 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:30<01:51, 26.94it/s, est. speed input: 36383.69 toks/s, output: 35.53 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:31<01:50, 26.92it/s, est. speed input: 36053.25 toks/s, output: 35.21 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:33<01:49, 26.92it/s, est. speed input: 35747.09 toks/s, output: 34.91 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:34<01:48, 26.91it/s, est. speed input: 35461.32 toks/s, output: 34.63 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:35<01:46, 26.90it/s, est. speed input: 35194.64 toks/s, output: 34.37 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:36<01:45, 26.89it/s, est. speed input: 34944.56 toks/s, output: 34.13 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:37<01:44, 26.87it/s, est. speed input: 34709.61 toks/s, output: 33.90 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:39<01:43, 26.85it/s, est. speed input: 34487.01 toks/s, output: 33.68 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:40<01:42, 26.85it/s, est. speed input: 34279.86 toks/s, output: 33.48 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:41<01:41, 26.84it/s, est. speed input: 34083.16 toks/s, output: 33.28 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:42<01:40, 26.83it/s, est. speed input: 33897.83 toks/s, output: 33.10 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:43<01:38, 26.83it/s, est. speed input: 33722.85 toks/s, output: 32.93 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [00:44<01:37, 26.83it/s, est. speed input: 33556.74 toks/s, output: 32.77 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [00:46<01:36, 26.82it/s, est. speed input: 33398.86 toks/s, output: 32.62 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:47<01:34, 27.03it/s, est. speed input: 33270.79 toks/s, output: 32.49 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:48<01:33, 26.97it/s, est. speed input: 33128.06 toks/s, output: 32.35 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [00:49<01:31, 27.13it/s, est. speed input: 33012.35 toks/s, output: 32.24 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [00:50<01:31, 27.02it/s, est. speed input: 32880.99 toks/s, output: 32.11 toks/s]
Processed prompts:  41%|████      | 1666/4096 [00:52<01:30, 26.94it/s, est. speed input: 32754.82 toks/s, output: 31.99 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [00:53<01:29, 26.89it/s, est. speed input: 32635.07 toks/s, output: 31.87 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [00:54<01:28, 26.84it/s, est. speed input: 32519.65 toks/s, output: 31.76 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [00:55<01:27, 26.82it/s, est. speed input: 32410.00 toks/s, output: 31.65 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [00:56<01:25, 26.81it/s, est. speed input: 32305.46 toks/s, output: 31.55 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [00:58<01:24, 26.80it/s, est. speed input: 32204.88 toks/s, output: 31.45 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [00:59<01:23, 26.78it/s, est. speed input: 32107.12 toks/s, output: 31.35 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:00<01:22, 26.77it/s, est. speed input: 32013.83 toks/s, output: 31.26 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:01<01:21, 26.76it/s, est. speed input: 31923.59 toks/s, output: 31.18 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:02<01:20, 26.75it/s, est. speed input: 31836.60 toks/s, output: 31.09 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:04<01:18, 26.74it/s, est. speed input: 31753.17 toks/s, output: 31.01 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:05<01:17, 26.74it/s, est. speed input: 31673.01 toks/s, output: 30.93 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:06<01:16, 26.74it/s, est. speed input: 31595.51 toks/s, output: 30.85 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:07<01:15, 26.73it/s, est. speed input: 31520.04 toks/s, output: 30.78 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:08<01:14, 26.72it/s, est. speed input: 31447.51 toks/s, output: 30.71 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [01:10<01:12, 26.71it/s, est. speed input: 31377.21 toks/s, output: 30.64 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:11<01:11, 26.93it/s, est. speed input: 31323.37 toks/s, output: 30.59 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:12<01:10, 26.86it/s, est. speed input: 31257.38 toks/s, output: 30.52 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:13<01:09, 26.80it/s, est. speed input: 31193.17 toks/s, output: 30.46 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:14<01:08, 26.76it/s, est. speed input: 31130.76 toks/s, output: 30.40 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:15<01:06, 26.74it/s, est. speed input: 31070.63 toks/s, output: 30.34 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:17<01:05, 26.72it/s, est. speed input: 31012.13 toks/s, output: 30.29 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:18<01:04, 26.71it/s, est. speed input: 30955.71 toks/s, output: 30.23 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:19<01:03, 26.69it/s, est. speed input: 30900.21 toks/s, output: 30.18 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:20<01:02, 26.68it/s, est. speed input: 30846.94 toks/s, output: 30.12 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:21<01:01, 26.69it/s, est. speed input: 30795.56 toks/s, output: 30.07 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:23<00:59, 26.67it/s, est. speed input: 30744.72 toks/s, output: 30.02 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [01:24<00:58, 26.67it/s, est. speed input: 30695.76 toks/s, output: 29.98 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [01:25<00:57, 26.66it/s, est. speed input: 30647.74 toks/s, output: 29.93 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [01:26<00:56, 26.65it/s, est. speed input: 30601.14 toks/s, output: 29.88 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [01:28<00:55, 26.65it/s, est. speed input: 30555.61 toks/s, output: 29.84 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [01:29<00:53, 26.66it/s, est. speed input: 30512.25 toks/s, output: 29.80 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [01:30<00:52, 26.65it/s, est. speed input: 30469.38 toks/s, output: 29.76 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [01:31<00:51, 26.65it/s, est. speed input: 30427.37 toks/s, output: 29.71 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [01:32<00:50, 26.64it/s, est. speed input: 30386.29 toks/s, output: 29.67 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [01:34<00:49, 26.64it/s, est. speed input: 30346.73 toks/s, output: 29.64 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [01:35<00:47, 26.64it/s, est. speed input: 30308.13 toks/s, output: 29.60 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [01:36<00:46, 26.64it/s, est. speed input: 30270.53 toks/s, output: 29.56 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [01:37<00:45, 26.86it/s, est. speed input: 30243.62 toks/s, output: 29.53 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [01:38<00:44, 26.78it/s, est. speed input: 30206.95 toks/s, output: 29.50 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [01:39<00:43, 26.73it/s, est. speed input: 30171.54 toks/s, output: 29.46 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [01:41<00:41, 26.69it/s, est. speed input: 30136.37 toks/s, output: 29.43 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [01:42<00:40, 26.67it/s, est. speed input: 30102.67 toks/s, output: 29.40 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [01:43<00:39, 26.65it/s, est. speed input: 30069.60 toks/s, output: 29.36 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [01:44<00:38, 26.64it/s, est. speed input: 30037.27 toks/s, output: 29.33 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [01:46<00:37, 26.62it/s, est. speed input: 30005.10 toks/s, output: 29.30 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [01:47<00:36, 26.61it/s, est. speed input: 29973.94 toks/s, output: 29.27 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [01:48<00:34, 26.61it/s, est. speed input: 29943.65 toks/s, output: 29.24 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [01:49<00:33, 26.60it/s, est. speed input: 29913.79 toks/s, output: 29.21 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [01:50<00:32, 26.60it/s, est. speed input: 29884.62 toks/s, output: 29.18 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [01:52<00:31, 26.60it/s, est. speed input: 29856.32 toks/s, output: 29.16 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [01:53<00:30, 26.59it/s, est. speed input: 29828.12 toks/s, output: 29.13 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [01:54<00:28, 26.58it/s, est. speed input: 29800.45 toks/s, output: 29.10 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [01:55<00:27, 26.58it/s, est. speed input: 29773.30 toks/s, output: 29.08 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [01:56<00:26, 26.57it/s, est. speed input: 29746.72 toks/s, output: 29.05 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [01:58<00:25, 26.58it/s, est. speed input: 29721.05 toks/s, output: 29.02 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [01:59<00:23, 26.59it/s, est. speed input: 29696.19 toks/s, output: 29.00 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:00<00:22, 26.59it/s, est. speed input: 29671.59 toks/s, output: 28.98 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:01<00:21, 26.57it/s, est. speed input: 29646.72 toks/s, output: 28.95 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:02<00:20, 26.56it/s, est. speed input: 29622.45 toks/s, output: 28.93 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:04<00:19, 26.56it/s, est. speed input: 29599.04 toks/s, output: 28.91 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:05<00:17, 26.56it/s, est. speed input: 29575.87 toks/s, output: 28.88 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:06<00:16, 26.56it/s, est. speed input: 29553.34 toks/s, output: 28.86 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:07<00:15, 26.78it/s, est. speed input: 29538.70 toks/s, output: 28.85 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [02:08<00:14, 26.72it/s, est. speed input: 29517.13 toks/s, output: 28.83 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [02:10<00:13, 26.67it/s, est. speed input: 29495.49 toks/s, output: 28.80 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [02:11<00:11, 26.63it/s, est. speed input: 29474.23 toks/s, output: 28.78 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [02:12<00:10, 26.61it/s, est. speed input: 29453.66 toks/s, output: 28.76 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [02:13<00:09, 26.60it/s, est. speed input: 29433.48 toks/s, output: 28.74 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [02:14<00:08, 26.58it/s, est. speed input: 29413.14 toks/s, output: 28.72 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [02:16<00:07, 26.81it/s, est. speed input: 29401.11 toks/s, output: 28.71 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [02:17<00:05, 26.73it/s, est. speed input: 29381.59 toks/s, output: 28.69 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [02:18<00:04, 26.68it/s, est. speed input: 29362.60 toks/s, output: 28.67 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [02:19<00:03, 26.64it/s, est. speed input: 29343.91 toks/s, output: 28.66 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [02:20<00:02, 26.62it/s, est. speed input: 29325.63 toks/s, output: 28.64 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [02:22<00:01, 26.86it/s, est. speed input: 29315.50 toks/s, output: 28.63 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:22<00:00, 26.86it/s, est. speed input: 29531.60 toks/s, output: 28.84 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:22<00:00, 28.84it/s, est. speed input: 29531.60 toks/s, output: 28.84 toks/s]
[rank0]:[W126 14:48:21.147853420 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 14:48:23
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 14:49:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1500413) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1500413) WARNING 01-26 14:49:35 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.71 requests/s, 27373.87 total tokens/s, 26.71 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 14:49:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:49:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:49:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:49:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:49:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:49:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:49:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:49:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 14:49:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 14:49:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:49:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 14:49:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 14:49:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 14:49:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 14:49:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 14:49:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 14:49:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.94it/s]
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.68it/s]
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.17it/s]
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.99it/s]
(EngineCore_DP0 pid=1500413) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]
(EngineCore_DP0 pid=1500413) 
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=1500413) [2026-01-26 14:49:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=1500413) [rank0]:W0126 14:49:43.791000 1500413 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1500413) [rank0]:W0126 14:49:43.844000 1500413 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1500413) [rank0]:W0126 14:49:44.513000 1500413 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1500413) [rank0]:W0126 14:49:44.597000 1500413 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=1500413) 2026-01-26 14:49:49,805 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1500413) 2026-01-26 14:49:50,479 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1500413) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:16,  1.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:05,  2.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:04,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:05,  2.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:02<00:03,  3.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:02<00:01,  5.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:01,  6.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:00,  7.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:03<00:00,  5.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:03<00:00,  5.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:03<00:00,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:04<00:00,  5.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  5.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  4.41it/s]
(EngineCore_DP0 pid=1500413) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  7.58it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:01,  7.84it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  9.65it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00,  8.21it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  4.20it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  4.80it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  4.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.26it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 29/8192 [00:00<00:28, 282.43it/s]
Adding requests:   1%|          | 69/8192 [00:00<00:23, 350.24it/s]
Adding requests:   1%|▏         | 106/8192 [00:00<00:22, 356.23it/s]
Adding requests:   2%|▏         | 144/8192 [00:00<00:22, 361.07it/s]
Adding requests:   2%|▏         | 184/8192 [00:00<00:21, 374.54it/s]
Adding requests:   3%|▎         | 224/8192 [00:00<00:20, 379.95it/s]
Adding requests:   3%|▎         | 263/8192 [00:00<00:20, 378.51it/s]
Adding requests:   4%|▎         | 303/8192 [00:00<00:20, 383.02it/s]
Adding requests:   4%|▍         | 343/8192 [00:00<00:20, 386.63it/s]
Adding requests:   5%|▍         | 384/8192 [00:01<00:19, 390.87it/s]
Adding requests:   5%|▌         | 425/8192 [00:01<00:19, 395.44it/s]
Adding requests:   6%|▌         | 465/8192 [00:01<00:19, 391.87it/s]
Adding requests:   6%|▌         | 508/8192 [00:01<00:19, 402.00it/s]
Adding requests:   7%|▋         | 549/8192 [00:01<00:18, 403.19it/s]
Adding requests:   7%|▋         | 590/8192 [00:01<00:19, 398.64it/s]
Adding requests:   8%|▊         | 630/8192 [00:01<00:19, 389.50it/s]
Adding requests:   8%|▊         | 669/8192 [00:01<00:19, 380.23it/s]
Adding requests:   9%|▊         | 710/8192 [00:01<00:19, 387.03it/s]
Adding requests:   9%|▉         | 749/8192 [00:01<00:19, 380.40it/s]
Adding requests:  10%|▉         | 789/8192 [00:02<00:19, 383.93it/s]
Adding requests:  10%|█         | 828/8192 [00:02<00:19, 385.52it/s]
Adding requests:  11%|█         | 868/8192 [00:02<00:18, 388.09it/s]
Adding requests:  11%|█         | 909/8192 [00:02<00:18, 391.60it/s]
Adding requests:  12%|█▏        | 949/8192 [00:02<00:18, 383.16it/s]
Adding requests:  12%|█▏        | 988/8192 [00:02<00:18, 384.79it/s]
Adding requests:  13%|█▎        | 1027/8192 [00:02<00:18, 379.71it/s]
Adding requests:  13%|█▎        | 1066/8192 [00:02<00:18, 379.94it/s]
Adding requests:  13%|█▎        | 1105/8192 [00:02<00:18, 377.34it/s]
Adding requests:  14%|█▍        | 1146/8192 [00:02<00:18, 384.32it/s]
Adding requests:  14%|█▍        | 1185/8192 [00:03<00:18, 382.73it/s]
Adding requests:  15%|█▍        | 1226/8192 [00:03<00:17, 387.73it/s]
Adding requests:  15%|█▌        | 1265/8192 [00:03<00:18, 384.74it/s]
Adding requests:  16%|█▌        | 1304/8192 [00:03<00:18, 382.05it/s]
Adding requests:  16%|█▋        | 1343/8192 [00:03<00:17, 382.97it/s]
Adding requests:  17%|█▋        | 1383/8192 [00:03<00:17, 387.15it/s]
Adding requests:  17%|█▋        | 1422/8192 [00:03<00:17, 383.87it/s]
Adding requests:  18%|█▊        | 1462/8192 [00:03<00:17, 387.86it/s]
Adding requests:  18%|█▊        | 1502/8192 [00:03<00:17, 388.73it/s]
Adding requests:  19%|█▉        | 1542/8192 [00:04<00:17, 389.30it/s]
Adding requests:  19%|█▉        | 1581/8192 [00:04<00:17, 379.69it/s]
Adding requests:  20%|█▉        | 1620/8192 [00:04<00:17, 372.13it/s]
Adding requests:  20%|██        | 1658/8192 [00:04<00:17, 365.89it/s]
Adding requests:  21%|██        | 1695/8192 [00:04<00:17, 366.54it/s]
Adding requests:  21%|██        | 1735/8192 [00:04<00:17, 373.38it/s]
Adding requests:  22%|██▏       | 1776/8192 [00:04<00:16, 382.78it/s]
Adding requests:  22%|██▏       | 1815/8192 [00:04<00:17, 369.83it/s]
Adding requests:  23%|██▎       | 1854/8192 [00:04<00:16, 374.70it/s]
Adding requests:  23%|██▎       | 1893/8192 [00:04<00:16, 378.39it/s]
Adding requests:  24%|██▎       | 1933/8192 [00:05<00:16, 383.51it/s]
Adding requests:  24%|██▍       | 1973/8192 [00:05<00:16, 385.04it/s]
Adding requests:  25%|██▍       | 2012/8192 [00:05<00:16, 380.39it/s]
Adding requests:  25%|██▌       | 2051/8192 [00:05<00:16, 372.42it/s]
Adding requests:  26%|██▌       | 2089/8192 [00:05<00:16, 363.83it/s]
Adding requests:  26%|██▌       | 2129/8192 [00:05<00:16, 372.16it/s]
Adding requests:  26%|██▋       | 2167/8192 [00:05<00:16, 369.63it/s]
Adding requests:  27%|██▋       | 2205/8192 [00:05<00:16, 365.89it/s]
Adding requests:  27%|██▋       | 2244/8192 [00:05<00:16, 371.12it/s]
Adding requests:  28%|██▊       | 2284/8192 [00:06<00:15, 379.14it/s]
Adding requests:  28%|██▊       | 2324/8192 [00:06<00:15, 385.00it/s]
Adding requests:  29%|██▉       | 2364/8192 [00:06<00:15, 386.77it/s]
Adding requests:  29%|██▉       | 2405/8192 [00:06<00:14, 391.16it/s]
Adding requests:  30%|██▉       | 2445/8192 [00:06<00:14, 391.12it/s]
Adding requests:  30%|███       | 2485/8192 [00:06<00:14, 389.53it/s]
Adding requests:  31%|███       | 2526/8192 [00:06<00:14, 394.01it/s]
Adding requests:  31%|███▏      | 2569/8192 [00:06<00:13, 404.11it/s]
Adding requests:  32%|███▏      | 2610/8192 [00:06<00:13, 402.12it/s]
Adding requests:  32%|███▏      | 2651/8192 [00:06<00:14, 391.99it/s]
Adding requests:  33%|███▎      | 2691/8192 [00:07<00:14, 388.30it/s]
Adding requests:  33%|███▎      | 2730/8192 [00:07<00:14, 384.81it/s]
Adding requests:  34%|███▍      | 2771/8192 [00:07<00:13, 390.75it/s]
Adding requests:  34%|███▍      | 2812/8192 [00:07<00:13, 394.18it/s]
Adding requests:  35%|███▍      | 2852/8192 [00:07<00:13, 395.65it/s]
Adding requests:  35%|███▌      | 2892/8192 [00:07<00:13, 392.86it/s]
Adding requests:  36%|███▌      | 2932/8192 [00:07<00:13, 390.79it/s]
Adding requests:  36%|███▋      | 2972/8192 [00:07<00:13, 393.29it/s]
Adding requests:  37%|███▋      | 3013/8192 [00:07<00:13, 396.02it/s]
Adding requests:  37%|███▋      | 3054/8192 [00:07<00:12, 398.49it/s]
Adding requests:  38%|███▊      | 3094/8192 [00:08<00:12, 396.53it/s]
Adding requests:  38%|███▊      | 3134/8192 [00:08<00:13, 387.32it/s]
Adding requests:  39%|███▊      | 3173/8192 [00:08<00:13, 383.68it/s]
Adding requests:  39%|███▉      | 3212/8192 [00:08<00:12, 383.37it/s]
Adding requests:  40%|███▉      | 3254/8192 [00:08<00:12, 390.96it/s]
Adding requests:  40%|████      | 3294/8192 [00:08<00:13, 376.45it/s]
Adding requests:  41%|████      | 3332/8192 [00:08<00:12, 374.60it/s]
Adding requests:  41%|████      | 3373/8192 [00:08<00:12, 383.72it/s]
Adding requests:  42%|████▏     | 3413/8192 [00:08<00:12, 386.01it/s]
Adding requests:  42%|████▏     | 3453/8192 [00:08<00:12, 388.57it/s]
Adding requests:  43%|████▎     | 3492/8192 [00:09<00:12, 383.92it/s]
Adding requests:  43%|████▎     | 3534/8192 [00:09<00:11, 393.81it/s]
Adding requests:  44%|████▎     | 3575/8192 [00:09<00:11, 397.44it/s]
Adding requests:  44%|████▍     | 3615/8192 [00:09<00:11, 396.06it/s]
Adding requests:  45%|████▍     | 3655/8192 [00:09<00:11, 392.71it/s]
Adding requests:  45%|████▌     | 3695/8192 [00:09<00:11, 385.59it/s]
Adding requests:  46%|████▌     | 3734/8192 [00:09<00:11, 386.38it/s]
Adding requests:  46%|████▌     | 3773/8192 [00:09<00:11, 377.61it/s]
Adding requests:  47%|████▋     | 3811/8192 [00:09<00:12, 362.78it/s]
Adding requests:  47%|████▋     | 3849/8192 [00:10<00:11, 367.24it/s]
Adding requests:  47%|████▋     | 3888/8192 [00:10<00:11, 371.96it/s]
Adding requests:  48%|████▊     | 3926/8192 [00:10<00:11, 368.54it/s]
Adding requests:  48%|████▊     | 3964/8192 [00:10<00:11, 370.53it/s]
Adding requests:  49%|████▉     | 4002/8192 [00:10<00:11, 370.19it/s]
Adding requests:  49%|████▉     | 4040/8192 [00:10<00:11, 372.84it/s]
Adding requests:  50%|████▉     | 4078/8192 [00:10<00:11, 372.59it/s]
Adding requests:  50%|█████     | 4117/8192 [00:10<00:10, 376.02it/s]
Adding requests:  51%|█████     | 4155/8192 [00:10<00:10, 376.26it/s]
Adding requests:  51%|█████     | 4194/8192 [00:10<00:10, 379.06it/s]
Adding requests:  52%|█████▏    | 4232/8192 [00:11<00:10, 374.10it/s]
Adding requests:  52%|█████▏    | 4271/8192 [00:11<00:10, 375.80it/s]
Adding requests:  53%|█████▎    | 4310/8192 [00:11<00:10, 378.72it/s]
Adding requests:  53%|█████▎    | 4349/8192 [00:11<00:10, 379.77it/s]
Adding requests:  54%|█████▎    | 4388/8192 [00:11<00:09, 380.52it/s]
Adding requests:  54%|█████▍    | 4427/8192 [00:11<00:09, 381.99it/s]
Adding requests:  55%|█████▍    | 4466/8192 [00:11<00:09, 383.46it/s]
Adding requests:  55%|█████▍    | 4505/8192 [00:11<00:09, 377.79it/s]
Adding requests:  55%|█████▌    | 4545/8192 [00:11<00:09, 382.20it/s]
Adding requests:  56%|█████▌    | 4584/8192 [00:11<00:09, 381.39it/s]
Adding requests:  56%|█████▋    | 4623/8192 [00:12<00:09, 378.88it/s]
Adding requests:  57%|█████▋    | 4661/8192 [00:12<00:09, 372.42it/s]
Adding requests:  57%|█████▋    | 4699/8192 [00:12<00:09, 366.97it/s]
Adding requests:  58%|█████▊    | 4740/8192 [00:12<00:09, 378.31it/s]
Adding requests:  58%|█████▊    | 4780/8192 [00:12<00:08, 380.51it/s]
Adding requests:  59%|█████▉    | 4819/8192 [00:12<00:08, 379.97it/s]
Adding requests:  59%|█████▉    | 4858/8192 [00:12<00:08, 375.86it/s]
Adding requests:  60%|█████▉    | 4897/8192 [00:12<00:08, 377.38it/s]
Adding requests:  60%|██████    | 4938/8192 [00:12<00:08, 384.43it/s]
Adding requests:  61%|██████    | 4977/8192 [00:13<00:08, 385.01it/s]
Adding requests:  61%|██████    | 5017/8192 [00:13<00:08, 386.88it/s]
Adding requests:  62%|██████▏   | 5057/8192 [00:13<00:08, 389.75it/s]
Adding requests:  62%|██████▏   | 5096/8192 [00:13<00:07, 387.78it/s]
Adding requests:  63%|██████▎   | 5136/8192 [00:13<00:07, 388.39it/s]
Adding requests:  63%|██████▎   | 5175/8192 [00:13<00:07, 386.58it/s]
Adding requests:  64%|██████▎   | 5214/8192 [00:13<00:07, 382.97it/s]
Adding requests:  64%|██████▍   | 5253/8192 [00:13<00:07, 380.65it/s]
Adding requests:  65%|██████▍   | 5292/8192 [00:13<00:07, 381.67it/s]
Adding requests:  65%|██████▌   | 5331/8192 [00:13<00:07, 380.82it/s]
Adding requests:  66%|██████▌   | 5371/8192 [00:14<00:07, 383.44it/s]
Adding requests:  66%|██████▌   | 5410/8192 [00:14<00:07, 376.16it/s]
Adding requests:  67%|██████▋   | 5450/8192 [00:14<00:07, 380.85it/s]
Adding requests:  67%|██████▋   | 5490/8192 [00:14<00:07, 385.13it/s]
Adding requests:  67%|██████▋   | 5529/8192 [00:14<00:06, 385.23it/s]
Adding requests:  68%|██████▊   | 5568/8192 [00:14<00:06, 382.88it/s]
Adding requests:  68%|██████▊   | 5607/8192 [00:14<00:06, 382.55it/s]
Adding requests:  69%|██████▉   | 5647/8192 [00:14<00:06, 385.54it/s]
Adding requests:  69%|██████▉   | 5686/8192 [00:14<00:06, 384.18it/s]
Adding requests:  70%|██████▉   | 5725/8192 [00:14<00:06, 384.65it/s]
Adding requests:  70%|███████   | 5765/8192 [00:15<00:06, 387.96it/s]
Adding requests:  71%|███████   | 5805/8192 [00:15<00:06, 389.37it/s]
Adding requests:  71%|███████▏  | 5844/8192 [00:15<00:06, 385.94it/s]
Adding requests:  72%|███████▏  | 5883/8192 [00:15<00:06, 378.40it/s]
Adding requests:  72%|███████▏  | 5923/8192 [00:15<00:05, 384.53it/s]
Adding requests:  73%|███████▎  | 5963/8192 [00:15<00:05, 388.68it/s]
Adding requests:  73%|███████▎  | 6002/8192 [00:15<00:05, 386.87it/s]
Adding requests:  74%|███████▍  | 6042/8192 [00:15<00:05, 388.27it/s]
Adding requests:  74%|███████▍  | 6081/8192 [00:15<00:05, 387.09it/s]
Adding requests:  75%|███████▍  | 6120/8192 [00:15<00:05, 384.26it/s]
Adding requests:  75%|███████▌  | 6161/8192 [00:16<00:05, 390.37it/s]
Adding requests:  76%|███████▌  | 6201/8192 [00:16<00:05, 381.68it/s]
Adding requests:  76%|███████▌  | 6241/8192 [00:16<00:05, 383.81it/s]
Adding requests:  77%|███████▋  | 6280/8192 [00:16<00:04, 384.18it/s]
Adding requests:  77%|███████▋  | 6320/8192 [00:16<00:04, 388.51it/s]
Adding requests:  78%|███████▊  | 6361/8192 [00:16<00:04, 394.52it/s]
Adding requests:  78%|███████▊  | 6401/8192 [00:16<00:04, 389.79it/s]
Adding requests:  79%|███████▊  | 6441/8192 [00:16<00:04, 380.23it/s]
Adding requests:  79%|███████▉  | 6480/8192 [00:16<00:04, 378.01it/s]
Adding requests:  80%|███████▉  | 6520/8192 [00:17<00:04, 383.09it/s]
Adding requests:  80%|████████  | 6559/8192 [00:17<00:04, 383.78it/s]
Adding requests:  81%|████████  | 6598/8192 [00:17<00:04, 378.69it/s]
Adding requests:  81%|████████  | 6639/8192 [00:17<00:04, 385.88it/s]
Adding requests:  82%|████████▏ | 6678/8192 [00:17<00:03, 382.76it/s]
Adding requests:  82%|████████▏ | 6717/8192 [00:17<00:03, 384.05it/s]
Adding requests:  82%|████████▏ | 6757/8192 [00:17<00:03, 388.45it/s]
Adding requests:  83%|████████▎ | 6796/8192 [00:17<00:03, 384.31it/s]
Adding requests:  83%|████████▎ | 6835/8192 [00:17<00:03, 378.93it/s]
Adding requests:  84%|████████▍ | 6875/8192 [00:17<00:03, 384.07it/s]
Adding requests:  84%|████████▍ | 6914/8192 [00:18<00:03, 383.05it/s]
Adding requests:  85%|████████▍ | 6953/8192 [00:18<00:03, 383.67it/s]
Adding requests:  85%|████████▌ | 6993/8192 [00:18<00:03, 386.11it/s]
Adding requests:  86%|████████▌ | 7032/8192 [00:18<00:03, 385.61it/s]
Adding requests:  86%|████████▋ | 7071/8192 [00:18<00:02, 381.57it/s]
Adding requests:  87%|████████▋ | 7110/8192 [00:18<00:02, 380.92it/s]
Adding requests:  87%|████████▋ | 7150/8192 [00:18<00:02, 383.23it/s]
Adding requests:  88%|████████▊ | 7191/8192 [00:18<00:02, 390.14it/s]
Adding requests:  88%|████████▊ | 7231/8192 [00:18<00:02, 382.05it/s]
Adding requests:  89%|████████▉ | 7271/8192 [00:18<00:02, 387.15it/s]
Adding requests:  89%|████████▉ | 7310/8192 [00:19<00:02, 385.45it/s]
Adding requests:  90%|████████▉ | 7350/8192 [00:19<00:02, 386.84it/s]
Adding requests:  90%|█████████ | 7389/8192 [00:19<00:02, 385.95it/s]
Adding requests:  91%|█████████ | 7428/8192 [00:19<00:01, 387.10it/s]
Adding requests:  91%|█████████ | 7467/8192 [00:19<00:01, 381.50it/s]
Adding requests:  92%|█████████▏| 7507/8192 [00:19<00:01, 385.62it/s]
Adding requests:  92%|█████████▏| 7546/8192 [00:19<00:01, 383.11it/s]
Adding requests:  93%|█████████▎| 7585/8192 [00:19<00:01, 380.34it/s]
Adding requests:  93%|█████████▎| 7624/8192 [00:19<00:01, 382.32it/s]
Adding requests:  94%|█████████▎| 7665/8192 [00:20<00:01, 390.28it/s]
Adding requests:  94%|█████████▍| 7706/8192 [00:20<00:01, 394.62it/s]
Adding requests:  95%|█████████▍| 7746/8192 [00:20<00:01, 390.85it/s]
Adding requests:  95%|█████████▌| 7786/8192 [00:20<00:01, 387.27it/s]
Adding requests:  96%|█████████▌| 7825/8192 [00:20<00:00, 386.63it/s]
Adding requests:  96%|█████████▌| 7864/8192 [00:20<00:00, 381.60it/s]
Adding requests:  96%|█████████▋| 7904/8192 [00:20<00:00, 384.98it/s]
Adding requests:  97%|█████████▋| 7946/8192 [00:20<00:00, 392.67it/s]
Adding requests:  97%|█████████▋| 7987/8192 [00:20<00:00, 396.39it/s]
Adding requests:  98%|█████████▊| 8027/8192 [00:20<00:00, 390.68it/s]
Adding requests:  98%|█████████▊| 8068/8192 [00:21<00:00, 395.73it/s]
Adding requests:  99%|█████████▉| 8108/8192 [00:21<00:00, 387.83it/s]
Adding requests:  99%|█████████▉| 8147/8192 [00:21<00:00, 385.14it/s]
Adding requests: 100%|█████████▉| 8186/8192 [00:21<00:00, 377.11it/s]
Adding requests: 100%|██████████| 8192/8192 [00:21<00:00, 383.28it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 542/8192 [00:00<00:12, 600.77it/s, est. speed input: 615199.61 toks/s, output: 600.77 toks/s]
Processed prompts:   7%|▋         | 606/8192 [00:03<00:51, 147.75it/s, est. speed input: 189676.32 toks/s, output: 185.23 toks/s]
Processed prompts:   8%|▊         | 670/8192 [00:05<01:29, 83.92it/s, est. speed input: 121814.75 toks/s, output: 118.96 toks/s] 
Processed prompts:   9%|▉         | 734/8192 [00:07<02:04, 59.72it/s, est. speed input: 94319.66 toks/s, output: 92.11 toks/s]  
Processed prompts:  10%|▉         | 798/8192 [00:10<02:36, 47.22it/s, est. speed input: 79059.65 toks/s, output: 77.21 toks/s]
Processed prompts:  11%|█         | 862/8192 [00:12<03:02, 40.08it/s, est. speed input: 69472.99 toks/s, output: 67.84 toks/s]
Processed prompts:  11%|█▏        | 926/8192 [00:15<03:23, 35.71it/s, est. speed input: 62913.00 toks/s, output: 61.44 toks/s]
Processed prompts:  12%|█▏        | 990/8192 [00:17<03:38, 32.91it/s, est. speed input: 58138.76 toks/s, output: 56.78 toks/s]
Processed prompts:  13%|█▎        | 1054/8192 [00:19<03:50, 31.03it/s, est. speed input: 54485.39 toks/s, output: 53.21 toks/s]
Processed prompts:  14%|█▎        | 1118/8192 [00:22<03:57, 29.76it/s, est. speed input: 51608.39 toks/s, output: 50.40 toks/s]
Processed prompts:  14%|█▍        | 1182/8192 [00:24<04:02, 28.89it/s, est. speed input: 49284.78 toks/s, output: 48.13 toks/s]
Processed prompts:  15%|█▌        | 1246/8192 [00:26<04:05, 28.29it/s, est. speed input: 47368.93 toks/s, output: 46.26 toks/s]
Processed prompts:  16%|█▌        | 1310/8192 [00:29<04:07, 27.84it/s, est. speed input: 45749.49 toks/s, output: 44.68 toks/s]
Processed prompts:  17%|█▋        | 1374/8192 [00:31<04:07, 27.55it/s, est. speed input: 44379.64 toks/s, output: 43.34 toks/s]
Processed prompts:  18%|█▊        | 1438/8192 [00:34<04:07, 27.34it/s, est. speed input: 43199.93 toks/s, output: 42.19 toks/s]
Processed prompts:  18%|█▊        | 1502/8192 [00:36<04:05, 27.20it/s, est. speed input: 42174.84 toks/s, output: 41.19 toks/s]
Processed prompts:  19%|█▉        | 1566/8192 [00:38<04:02, 27.34it/s, est. speed input: 41350.52 toks/s, output: 40.38 toks/s]
Processed prompts:  20%|█▉        | 1630/8192 [00:41<04:01, 27.17it/s, est. speed input: 40541.39 toks/s, output: 39.59 toks/s]
Processed prompts:  21%|██        | 1694/8192 [00:43<04:00, 27.05it/s, est. speed input: 39821.55 toks/s, output: 38.89 toks/s]
Processed prompts:  21%|██▏       | 1758/8192 [00:45<03:58, 26.98it/s, est. speed input: 39179.75 toks/s, output: 38.26 toks/s]
Processed prompts:  22%|██▏       | 1822/8192 [00:48<03:56, 26.93it/s, est. speed input: 38601.62 toks/s, output: 37.70 toks/s]
Processed prompts:  23%|██▎       | 1886/8192 [00:50<03:54, 26.91it/s, est. speed input: 38080.43 toks/s, output: 37.19 toks/s]
Processed prompts:  24%|██▍       | 1950/8192 [00:53<03:52, 26.85it/s, est. speed input: 37595.28 toks/s, output: 36.71 toks/s]
Processed prompts:  25%|██▍       | 2014/8192 [00:55<03:50, 26.83it/s, est. speed input: 37157.56 toks/s, output: 36.29 toks/s]
Processed prompts:  25%|██▌       | 2078/8192 [00:57<03:48, 26.74it/s, est. speed input: 36742.34 toks/s, output: 35.88 toks/s]
Processed prompts:  26%|██▌       | 2142/8192 [01:00<03:45, 26.85it/s, est. speed input: 36390.49 toks/s, output: 35.54 toks/s]
Processed prompts:  27%|██▋       | 2206/8192 [01:02<03:43, 26.80it/s, est. speed input: 36042.61 toks/s, output: 35.20 toks/s]
Processed prompts:  28%|██▊       | 2270/8192 [01:05<03:41, 26.74it/s, est. speed input: 35717.29 toks/s, output: 34.88 toks/s]
Processed prompts:  28%|██▊       | 2334/8192 [01:07<03:39, 26.72it/s, est. speed input: 35418.05 toks/s, output: 34.59 toks/s]
Processed prompts:  29%|██▉       | 2398/8192 [01:09<03:37, 26.69it/s, est. speed input: 35137.71 toks/s, output: 34.31 toks/s]
Processed prompts:  30%|███       | 2462/8192 [01:12<03:34, 26.68it/s, est. speed input: 34877.68 toks/s, output: 34.06 toks/s]
Processed prompts:  31%|███       | 2526/8192 [01:14<03:32, 26.67it/s, est. speed input: 34633.95 toks/s, output: 33.82 toks/s]
Processed prompts:  32%|███▏      | 2590/8192 [01:17<03:29, 26.70it/s, est. speed input: 34409.06 toks/s, output: 33.60 toks/s]
Processed prompts:  32%|███▏      | 2654/8192 [01:19<03:27, 26.66it/s, est. speed input: 34190.79 toks/s, output: 33.39 toks/s]
Processed prompts:  33%|███▎      | 2718/8192 [01:21<03:25, 26.66it/s, est. speed input: 33988.65 toks/s, output: 33.19 toks/s]
Processed prompts:  34%|███▍      | 2782/8192 [01:24<03:23, 26.63it/s, est. speed input: 33795.29 toks/s, output: 33.00 toks/s]
Processed prompts:  35%|███▍      | 2846/8192 [01:26<03:20, 26.61it/s, est. speed input: 33611.70 toks/s, output: 32.82 toks/s]
Processed prompts:  36%|███▌      | 2910/8192 [01:29<03:17, 26.74it/s, est. speed input: 33454.20 toks/s, output: 32.67 toks/s]
Processed prompts:  36%|███▋      | 2974/8192 [01:31<03:15, 26.71it/s, est. speed input: 33292.27 toks/s, output: 32.51 toks/s]
Processed prompts:  37%|███▋      | 3038/8192 [01:33<03:13, 26.68it/s, est. speed input: 33137.44 toks/s, output: 32.36 toks/s]
Processed prompts:  38%|███▊      | 3102/8192 [01:36<03:10, 26.67it/s, est. speed input: 32991.00 toks/s, output: 32.22 toks/s]
Processed prompts:  39%|███▊      | 3166/8192 [01:38<03:08, 26.66it/s, est. speed input: 32851.93 toks/s, output: 32.08 toks/s]
Processed prompts:  39%|███▉      | 3230/8192 [01:41<03:06, 26.62it/s, est. speed input: 32716.67 toks/s, output: 31.95 toks/s]
Processed prompts:  40%|████      | 3294/8192 [01:43<03:04, 26.60it/s, est. speed input: 32588.19 toks/s, output: 31.82 toks/s]
Processed prompts:  41%|████      | 3358/8192 [01:45<03:01, 26.59it/s, est. speed input: 32465.15 toks/s, output: 31.70 toks/s]
Processed prompts:  42%|████▏     | 3422/8192 [01:48<02:59, 26.59it/s, est. speed input: 32348.66 toks/s, output: 31.59 toks/s]
Processed prompts:  43%|████▎     | 3486/8192 [01:50<02:57, 26.57it/s, est. speed input: 32235.91 toks/s, output: 31.48 toks/s]
Processed prompts:  43%|████▎     | 3550/8192 [01:53<02:54, 26.57it/s, est. speed input: 32128.50 toks/s, output: 31.38 toks/s]
Processed prompts:  44%|████▍     | 3614/8192 [01:55<02:52, 26.56it/s, est. speed input: 32025.60 toks/s, output: 31.27 toks/s]
Processed prompts:  45%|████▍     | 3678/8192 [01:57<02:49, 26.67it/s, est. speed input: 31935.69 toks/s, output: 31.19 toks/s]
Processed prompts:  46%|████▌     | 3742/8192 [02:00<02:47, 26.62it/s, est. speed input: 31839.91 toks/s, output: 31.09 toks/s]
Processed prompts:  46%|████▋     | 3806/8192 [02:02<02:44, 26.61it/s, est. speed input: 31748.86 toks/s, output: 31.00 toks/s]
Processed prompts:  47%|████▋     | 3870/8192 [02:05<02:42, 26.59it/s, est. speed input: 31661.00 toks/s, output: 30.92 toks/s]
Processed prompts:  48%|████▊     | 3934/8192 [02:07<02:39, 26.72it/s, est. speed input: 31586.81 toks/s, output: 30.85 toks/s]
Processed prompts:  49%|████▉     | 3998/8192 [02:09<02:37, 26.66it/s, est. speed input: 31504.88 toks/s, output: 30.77 toks/s]
Processed prompts:  50%|████▉     | 4062/8192 [02:12<02:34, 26.77it/s, est. speed input: 31436.00 toks/s, output: 30.70 toks/s]
Processed prompts:  50%|█████     | 4126/8192 [02:14<02:32, 26.72it/s, est. speed input: 31361.14 toks/s, output: 30.63 toks/s]
Processed prompts:  51%|█████     | 4190/8192 [02:17<02:30, 26.65it/s, est. speed input: 31286.84 toks/s, output: 30.55 toks/s]
Processed prompts:  52%|█████▏    | 4254/8192 [02:19<02:27, 26.62it/s, est. speed input: 31216.06 toks/s, output: 30.48 toks/s]
Processed prompts:  53%|█████▎    | 4318/8192 [02:21<02:25, 26.61it/s, est. speed input: 31147.98 toks/s, output: 30.42 toks/s]
Processed prompts:  53%|█████▎    | 4382/8192 [02:24<02:23, 26.59it/s, est. speed input: 31081.76 toks/s, output: 30.35 toks/s]
Processed prompts:  54%|█████▍    | 4446/8192 [02:26<02:20, 26.58it/s, est. speed input: 31018.14 toks/s, output: 30.29 toks/s]
Processed prompts:  55%|█████▌    | 4510/8192 [02:29<02:18, 26.57it/s, est. speed input: 30956.18 toks/s, output: 30.23 toks/s]
Processed prompts:  56%|█████▌    | 4574/8192 [02:31<02:16, 26.57it/s, est. speed input: 30896.45 toks/s, output: 30.17 toks/s]
Processed prompts:  57%|█████▋    | 4638/8192 [02:34<02:13, 26.56it/s, est. speed input: 30838.26 toks/s, output: 30.12 toks/s]
Processed prompts:  57%|█████▋    | 4702/8192 [02:36<02:11, 26.56it/s, est. speed input: 30782.40 toks/s, output: 30.06 toks/s]
Processed prompts:  58%|█████▊    | 4766/8192 [02:38<02:09, 26.56it/s, est. speed input: 30727.72 toks/s, output: 30.01 toks/s]
Processed prompts:  59%|█████▉    | 4830/8192 [02:41<02:06, 26.56it/s, est. speed input: 30675.10 toks/s, output: 29.96 toks/s]
Processed prompts:  60%|█████▉    | 4894/8192 [02:43<02:04, 26.56it/s, est. speed input: 30623.78 toks/s, output: 29.91 toks/s]
Processed prompts:  61%|██████    | 4958/8192 [02:46<02:01, 26.67it/s, est. speed input: 30580.31 toks/s, output: 29.86 toks/s]
Processed prompts:  61%|██████▏   | 5022/8192 [02:48<01:59, 26.62it/s, est. speed input: 30530.83 toks/s, output: 29.82 toks/s]
Processed prompts:  62%|██████▏   | 5086/8192 [02:50<01:56, 26.60it/s, est. speed input: 30483.77 toks/s, output: 29.77 toks/s]
Processed prompts:  63%|██████▎   | 5150/8192 [02:53<01:54, 26.59it/s, est. speed input: 30438.06 toks/s, output: 29.72 toks/s]
Processed prompts:  64%|██████▎   | 5214/8192 [02:55<01:52, 26.58it/s, est. speed input: 30393.46 toks/s, output: 29.68 toks/s]
Processed prompts:  64%|██████▍   | 5278/8192 [02:58<01:49, 26.57it/s, est. speed input: 30350.24 toks/s, output: 29.64 toks/s]
Processed prompts:  65%|██████▌   | 5342/8192 [03:00<01:47, 26.57it/s, est. speed input: 30308.20 toks/s, output: 29.60 toks/s]
Processed prompts:  66%|██████▌   | 5406/8192 [03:02<01:44, 26.56it/s, est. speed input: 30267.03 toks/s, output: 29.56 toks/s]
Processed prompts:  67%|██████▋   | 5470/8192 [03:05<01:42, 26.56it/s, est. speed input: 30226.99 toks/s, output: 29.52 toks/s]
Processed prompts:  68%|██████▊   | 5534/8192 [03:07<01:40, 26.56it/s, est. speed input: 30188.13 toks/s, output: 29.48 toks/s]
Processed prompts:  68%|██████▊   | 5598/8192 [03:10<01:37, 26.56it/s, est. speed input: 30150.10 toks/s, output: 29.44 toks/s]
Processed prompts:  69%|██████▉   | 5662/8192 [03:12<01:35, 26.56it/s, est. speed input: 30113.10 toks/s, output: 29.41 toks/s]
Processed prompts:  70%|██████▉   | 5726/8192 [03:14<01:32, 26.56it/s, est. speed input: 30077.00 toks/s, output: 29.37 toks/s]
Processed prompts:  71%|███████   | 5790/8192 [03:17<01:30, 26.56it/s, est. speed input: 30041.81 toks/s, output: 29.34 toks/s]
Processed prompts:  71%|███████▏  | 5854/8192 [03:19<01:28, 26.56it/s, est. speed input: 30007.42 toks/s, output: 29.30 toks/s]
Processed prompts:  72%|███████▏  | 5918/8192 [03:22<01:25, 26.67it/s, est. speed input: 29979.06 toks/s, output: 29.28 toks/s]
Processed prompts:  73%|███████▎  | 5982/8192 [03:24<01:22, 26.76it/s, est. speed input: 29951.50 toks/s, output: 29.25 toks/s]
Processed prompts:  74%|███████▍  | 6046/8192 [03:26<01:20, 26.69it/s, est. speed input: 29919.27 toks/s, output: 29.22 toks/s]
Processed prompts:  75%|███████▍  | 6110/8192 [03:29<01:18, 26.65it/s, est. speed input: 29887.96 toks/s, output: 29.19 toks/s]
Processed prompts:  75%|███████▌  | 6174/8192 [03:31<01:15, 26.62it/s, est. speed input: 29857.23 toks/s, output: 29.16 toks/s]
Processed prompts:  76%|███████▌  | 6238/8192 [03:34<01:13, 26.60it/s, est. speed input: 29827.17 toks/s, output: 29.13 toks/s]
Processed prompts:  77%|███████▋  | 6302/8192 [03:36<01:11, 26.59it/s, est. speed input: 29797.93 toks/s, output: 29.10 toks/s]
Processed prompts:  78%|███████▊  | 6366/8192 [03:38<01:08, 26.58it/s, est. speed input: 29769.48 toks/s, output: 29.07 toks/s]
Processed prompts:  78%|███████▊  | 6430/8192 [03:41<01:06, 26.57it/s, est. speed input: 29741.33 toks/s, output: 29.04 toks/s]
Processed prompts:  79%|███████▉  | 6494/8192 [03:43<01:03, 26.57it/s, est. speed input: 29713.83 toks/s, output: 29.02 toks/s]
Processed prompts:  80%|████████  | 6558/8192 [03:46<01:01, 26.56it/s, est. speed input: 29686.89 toks/s, output: 28.99 toks/s]
Processed prompts:  81%|████████  | 6622/8192 [03:48<00:59, 26.56it/s, est. speed input: 29660.72 toks/s, output: 28.97 toks/s]
Processed prompts:  82%|████████▏ | 6686/8192 [03:51<00:56, 26.55it/s, est. speed input: 29634.71 toks/s, output: 28.94 toks/s]
Processed prompts:  82%|████████▏ | 6750/8192 [03:53<00:54, 26.56it/s, est. speed input: 29609.82 toks/s, output: 28.92 toks/s]
Processed prompts:  83%|████████▎ | 6814/8192 [03:55<00:51, 26.55it/s, est. speed input: 29584.89 toks/s, output: 28.89 toks/s]
Processed prompts:  84%|████████▍ | 6878/8192 [03:58<00:49, 26.56it/s, est. speed input: 29560.80 toks/s, output: 28.87 toks/s]
Processed prompts:  85%|████████▍ | 6942/8192 [04:00<00:47, 26.56it/s, est. speed input: 29537.07 toks/s, output: 28.84 toks/s]
Processed prompts:  86%|████████▌ | 7006/8192 [04:03<00:44, 26.56it/s, est. speed input: 29513.88 toks/s, output: 28.82 toks/s]
Processed prompts:  86%|████████▋ | 7070/8192 [04:05<00:42, 26.55it/s, est. speed input: 29490.98 toks/s, output: 28.80 toks/s]
Processed prompts:  87%|████████▋ | 7134/8192 [04:07<00:39, 26.56it/s, est. speed input: 29468.81 toks/s, output: 28.78 toks/s]
Processed prompts:  88%|████████▊ | 7198/8192 [04:10<00:37, 26.55it/s, est. speed input: 29446.79 toks/s, output: 28.76 toks/s]
Processed prompts:  89%|████████▊ | 7262/8192 [04:12<00:35, 26.56it/s, est. speed input: 29425.34 toks/s, output: 28.74 toks/s]
Processed prompts:  89%|████████▉ | 7326/8192 [04:15<00:32, 26.55it/s, est. speed input: 29404.17 toks/s, output: 28.72 toks/s]
Processed prompts:  90%|█████████ | 7390/8192 [04:17<00:30, 26.56it/s, est. speed input: 29383.75 toks/s, output: 28.70 toks/s]
Processed prompts:  91%|█████████ | 7454/8192 [04:19<00:27, 26.55it/s, est. speed input: 29363.19 toks/s, output: 28.67 toks/s]
Processed prompts:  92%|█████████▏| 7518/8192 [04:22<00:25, 26.56it/s, est. speed input: 29343.57 toks/s, output: 28.66 toks/s]
Processed prompts:  93%|█████████▎| 7582/8192 [04:24<00:22, 26.55it/s, est. speed input: 29323.75 toks/s, output: 28.64 toks/s]
Processed prompts:  93%|█████████▎| 7646/8192 [04:27<00:20, 26.56it/s, est. speed input: 29304.58 toks/s, output: 28.62 toks/s]
Processed prompts:  94%|█████████▍| 7710/8192 [04:29<00:18, 26.55it/s, est. speed input: 29285.61 toks/s, output: 28.60 toks/s]
Processed prompts:  95%|█████████▍| 7774/8192 [04:31<00:15, 26.55it/s, est. speed input: 29267.05 toks/s, output: 28.58 toks/s]
Processed prompts:  96%|█████████▌| 7838/8192 [04:34<00:13, 26.55it/s, est. speed input: 29248.79 toks/s, output: 28.56 toks/s]
Processed prompts:  96%|█████████▋| 7902/8192 [04:36<00:10, 26.56it/s, est. speed input: 29231.02 toks/s, output: 28.55 toks/s]
Processed prompts:  97%|█████████▋| 7966/8192 [04:39<00:08, 26.56it/s, est. speed input: 29213.37 toks/s, output: 28.53 toks/s]
Processed prompts:  98%|█████████▊| 8030/8192 [04:41<00:06, 26.56it/s, est. speed input: 29196.15 toks/s, output: 28.51 toks/s]
Processed prompts:  99%|█████████▉| 8094/8192 [04:44<00:03, 26.56it/s, est. speed input: 29179.30 toks/s, output: 28.50 toks/s]
Processed prompts: 100%|█████████▉| 8158/8192 [04:45<00:01, 30.73it/s, est. speed input: 29274.08 toks/s, output: 28.59 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [04:45<00:00, 30.73it/s, est. speed input: 29395.96 toks/s, output: 28.71 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [04:45<00:00, 28.71it/s, est. speed input: 29395.96 toks/s, output: 28.71 toks/s]
[rank0]:[W126 14:55:05.580174689 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

